{"home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.__init__": [[10, 72], ["results_saver.Results._construct_controller_data", "results_saver.Results.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results._construct_controller_data", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["def", "__init__", "(", "self", ",", "\n", "controller_list", "=", "None", ",", "\n", "env_settings", "=", "None", ",", "\n", "prob_threshold", "=", "None", ",", "\n", "training_iters", "=", "None", ",", "\n", "estimation_rollouts", "=", "None", ",", "\n", "random_seed", "=", "None", ",", "\n", "load_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Either all inputs should be specified except for load_dir, \n        or load_dir must be specified.\n\n        Inputs\n        ------\n        controller_list (optional) : list\n            list of MinigridController objects\n        env_settings (optional) : dict\n            Dictionary containing the environment settings\n        prob_threshold (optional) : float\n            The required probability of overall task success\n        training_iters (optional) : int\n            The number of training steps to use when training\n            each sub-system in the main iterative compositional\n            RL loop.\n        estimation_rollouts (optional) : int\n            The number of rollouts to use when empirically estimating\n            (sub-)task success probabilities.\n        random_seed (optional) : int\n            Random seed used in the experiment.\n        load_dir (optional) : str\n            String pointing to the results file to load from a previous\n            run of the experiment.\n        \"\"\"", "\n", "\n", "if", "load_dir", "is", "None", ":", "\n", "            ", "assert", "(", "controller_list", "is", "not", "None", ")", "\n", "assert", "(", "env_settings", "is", "not", "None", ")", "\n", "assert", "(", "prob_threshold", "is", "not", "None", ")", "\n", "assert", "(", "training_iters", "is", "not", "None", ")", "\n", "assert", "(", "estimation_rollouts", "is", "not", "None", ")", "\n", "assert", "(", "random_seed", "is", "not", "None", ")", "\n", "self", ".", "data", "=", "{", "}", "# save everything in a dictionary", "\n", "self", ".", "data", "[", "'env_settings'", "]", "=", "env_settings", "\n", "self", ".", "data", "[", "'prob_threshold'", "]", "=", "prob_threshold", "\n", "self", ".", "data", "[", "'training_iters'", "]", "=", "training_iters", "\n", "self", ".", "data", "[", "'estimation_rollouts'", "]", "=", "estimation_rollouts", "\n", "self", ".", "data", "[", "'random_seed'", "]", "=", "random_seed", "\n", "\n", "self", ".", "data", "[", "'controller_elapsed_training_steps'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_rollout_mean'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_num_rollouts'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_required_probabilities'", "]", "=", "{", "}", "\n", "self", ".", "_construct_controller_data", "(", "controller_list", ")", "\n", "\n", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", "=", "[", "]", "\n", "\n", "self", ".", "data", "[", "'composition_rollout_mean'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'composition_num_rollouts'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'composition_policy'", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'composition_predicted_success_prob'", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "load", "(", "load_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results._construct_controller_data": [[73, 88], ["None"], "methods", ["None"], ["", "", "def", "_construct_controller_data", "(", "self", ",", "controller_list", ")", ":", "\n", "        ", "\"\"\"\n        Add the meta-data of a list of controllers to the saved results\n\n        Inputs\n        ------\n        controller_list : list\n            List of MiniGrid Controller objects.\n        \"\"\"", "\n", "for", "controller", "in", "controller_list", ":", "\n", "            ", "controller_ind", "=", "controller", ".", "controller_ind", "\n", "self", ".", "data", "[", "'controller_elapsed_training_steps'", "]", "[", "controller_ind", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_rollout_mean'", "]", "[", "controller_ind", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_num_rollouts'", "]", "[", "controller_ind", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "'controller_required_probabilities'", "]", "[", "controller_ind", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.update_training_steps": [[89, 104], ["results_saver.Results.data[].append"], "methods", ["None"], ["", "", "def", "update_training_steps", "(", "self", ",", "training_steps", ")", ":", "\n", "        ", "\"\"\"\n        Update the total number of elapsed training steps of the overall system.\n\n        Inputs\n        ------\n        training_steps : int\n            The number of elapsed training steps since the LAST call of update_training_steps()\n        \"\"\"", "\n", "if", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", ":", "\n", "            ", "elapsed_training_steps", "=", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "elapsed_training_steps", "=", "0", "\n", "", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", ".", "append", "(", "elapsed_training_steps", "+", "training_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.update_controllers": [[105, 121], ["None"], "methods", ["None"], ["", "def", "update_controllers", "(", "self", ",", "controller_list", ")", ":", "\n", "        ", "\"\"\"\n        Use the controller list to update results data pertaining to the sub-systems.\n\n        Inputs\n        ------\n        controller_list : list\n            List of MinigridController objects whose results data is to be updated.\n        \"\"\"", "\n", "elapsed_training_steps", "=", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", "[", "-", "1", "]", "\n", "for", "controller", "in", "controller_list", ":", "\n", "            ", "controller_ind", "=", "controller", ".", "controller_ind", "\n", "self", ".", "data", "[", "'controller_elapsed_training_steps'", "]", "[", "controller_ind", "]", "[", "elapsed_training_steps", "]", "=", "controller", ".", "data", "[", "'total_training_steps'", "]", "\n", "self", ".", "data", "[", "'controller_rollout_mean'", "]", "[", "controller_ind", "]", "[", "elapsed_training_steps", "]", "=", "controller", ".", "data", "[", "'performance_estimates'", "]", "[", "controller", ".", "data", "[", "'total_training_steps'", "]", "]", "[", "'success_rate'", "]", "\n", "self", ".", "data", "[", "'controller_num_rollouts'", "]", "[", "controller_ind", "]", "[", "elapsed_training_steps", "]", "=", "controller", ".", "data", "[", "'performance_estimates'", "]", "[", "controller", ".", "data", "[", "'total_training_steps'", "]", "]", "[", "'num_trials'", "]", "\n", "self", ".", "data", "[", "'controller_required_probabilities'", "]", "[", "controller_ind", "]", "[", "elapsed_training_steps", "]", "=", "controller", ".", "data", "[", "'required_success_prob'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.update_composition_data": [[122, 142], ["None"], "methods", ["None"], ["", "", "def", "update_composition_data", "(", "self", ",", "rollout_mean", ",", "num_rollouts", ",", "policy", ",", "predicted_success_prob", ")", ":", "\n", "        ", "\"\"\"\n        Update the data pertaining to the compostional system's performance.\n\n        Inputs\n        ------\n        rollout_mean : float\n            Empirically estimated probability of the composite system's task success.\n        num_rollouts : int\n            Number of system rollouts used to estimate the rollout_mean.\n        policy : numpy array\n            The meta-policy specifying the composite system.\n        predicted_success_prob : float\n            The HLM's predicted probability of task success.\n        \"\"\"", "\n", "elapsed_training_steps", "=", "self", ".", "data", "[", "'cparl_loop_training_steps'", "]", "[", "-", "1", "]", "\n", "self", ".", "data", "[", "'composition_rollout_mean'", "]", "[", "elapsed_training_steps", "]", "=", "rollout_mean", "\n", "self", ".", "data", "[", "'composition_num_rollouts'", "]", "[", "elapsed_training_steps", "]", "=", "num_rollouts", "\n", "self", ".", "data", "[", "'composition_policy'", "]", "[", "elapsed_training_steps", "]", "=", "policy", "\n", "self", ".", "data", "[", "'composition_predicted_success_prob'", "]", "[", "elapsed_training_steps", "]", "=", "predicted_success_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.save": [[143, 159], ["os.path.join", "os.path.isdir", "os.mkdir", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the Results object.\n\n        Inputs\n        ------\n        save_dir : string\n            Absolute path to the directory that will be used to save this results data.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "", "data_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'results_data.p'", ")", "\n", "\n", "with", "open", "(", "data_file", ",", "'wb'", ")", "as", "pickleFile", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "data", ",", "pickleFile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.results_saver.Results.load": [[160, 174], ["os.path.join", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["", "", "def", "load", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Load a Results object\n\n        Inputs\n        ------\n        save_dir : string\n            Absolute path to the directory that will be used to save this results data.\n        \"\"\"", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'results_data.p'", ")", "\n", "with", "open", "(", "data_file", ",", "'rb'", ")", "as", "pickleFile", ":", "\n", "            ", "results_data", "=", "pickle", ".", "load", "(", "pickleFile", ")", "\n", "\n", "", "self", ".", "data", "=", "results_data", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.observers.ObserverIncrementTaskSuccessCount.__init__": [[13, 16], ["observable.subscribe"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.subscribe"], ["def", "__init__", "(", "self", ",", "observable", ")", ":", "\n", "        ", "observable", ".", "subscribe", "(", "self", ")", "\n", "self", ".", "success_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.utils.observers.ObserverIncrementTaskSuccessCount.notify": [[17, 20], ["None"], "methods", ["None"], ["", "def", "notify", "(", "self", ",", "observable", ",", "message", ")", ":", "\n", "        ", "if", "message", "==", "'Completed task'", ":", "\n", "            ", "self", ".", "success_count", "=", "self", ".", "success_count", "+", "1", "", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.__init__": [[14, 40], ["numpy.arange", "side_channels[].subscribe", "unity_meta_controller.MetaController.reset", "len"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.subscribe", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset"], ["def", "__init__", "(", "self", ",", "\n", "meta_policy", ":", "np", ".", "ndarray", ",", "\n", "hlmdp", ":", "HLMDP", ",", "\n", "side_channels", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        meta_policy\n            Numpy array representing the meta-policy.\n        hlmdp\n            The high-level MDP in which this meta-controller is acting.\n        side_channels\n            Dictionary of side channel objects used to specify environment\n            settings before running.\n        \"\"\"", "\n", "self", ".", "meta_policy", "=", "meta_policy", "\n", "self", ".", "controller_list", "=", "hlmdp", ".", "controller_list", "\n", "self", ".", "controller_indeces", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "controller_list", ")", ")", "\n", "self", ".", "current_controller_ind", "=", "None", "\n", "self", ".", "successor", "=", "hlmdp", ".", "successor", "\n", "\n", "self", ".", "s_i", "=", "hlmdp", ".", "s_i", "\n", "self", ".", "s_g", "=", "hlmdp", ".", "s_g", "\n", "side_channels", "[", "'custom_side_channel'", "]", ".", "subscribe", "(", "self", ")", "\n", "\n", "self", ".", "reset", "(", "side_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.notify": [[41, 77], ["unity_meta_controller.MetaController.select_next_abstract_action", "observable.send_string"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.select_next_abstract_action", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string"], ["", "def", "notify", "(", "self", ",", "observable", ":", "CustomSideChannel", ",", "message", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Receive messages from the side information channel, and update the \n        abstract state and the current sub-task accordingly.\n\n        Inputs\n        ------\n        observable\n            An observable side channel which acts as the observable, notifying\n            this observer each time a new message is received from the \n            environment.\n        messasge\n            A string containing the message passed on by the observable.\n        \"\"\"", "\n", "if", "message", "==", "'Completed sub task: {}'", ".", "format", "(", "self", ".", "current_controller_ind", ")", ":", "\n", "# Get the new abstract state", "\n", "            ", "self", ".", "current_abstract_state", "=", "self", ".", "successor", "[", "(", "self", ".", "current_abstract_state", ",", "\n", "self", ".", "current_controller_ind", ")", "]", "\n", "\n", "if", "not", "(", "self", ".", "current_abstract_state", "==", "self", ".", "s_g", ")", ":", "\n", "# Get the next abstract action to take", "\n", "                ", "self", ".", "current_controller_ind", "=", "self", ".", "select_next_abstract_action", "(", "self", ".", "current_abstract_state", ")", "\n", "\n", "observable", ".", "send_string", "(", "'-1,{}'", ".", "format", "(", "self", ".", "current_controller_ind", ")", ")", "\n", "# print('Current controller: {}'.format(self.current_controller_ind))", "\n", "\n", "", "", "elif", "message", "==", "'Failed task'", ":", "\n", "            ", "pass", "\n", "", "elif", "message", "==", "'Completed task'", ":", "\n", "            ", "pass", "\n", "", "elif", "message", "==", "''", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# raise Exception('Unexpected message received from unity environment.')", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.unsubscribe_meta_controller": [[79, 91], ["side_channels[].unsubscribe"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.unsubscribe"], ["", "", "def", "unsubscribe_meta_controller", "(", "self", ",", "side_channels", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        A function that unsubscribes the current meta-controller to prevent it\n        from continuing to send messages to the unity enviroment.\n        \n        Inputs\n        ------\n        side_channels\n            Dictionary of side channel objects used to specify environment\n            settings before running.\n        \"\"\"", "\n", "side_channels", "[", "'custom_side_channel'", "]", ".", "unsubscribe", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.reset": [[92, 97], ["unity_meta_controller.MetaController.select_next_abstract_action", "side_channels[].send_string"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.select_next_abstract_action", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string"], ["", "def", "reset", "(", "self", ",", "side_channels", ")", ":", "\n", "        ", "self", ".", "current_abstract_state", "=", "self", ".", "s_i", "\n", "self", ".", "current_controller_ind", "=", "self", ".", "select_next_abstract_action", "(", "\n", "self", ".", "current_abstract_state", ")", "\n", "side_channels", "[", "'custom_side_channel'", "]", ".", "send_string", "(", "'-1,{}'", ".", "format", "(", "self", ".", "current_controller_ind", ")", ")", "\n", "# print('Current controller: {}'.format(self.current_controller_ind))", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.select_next_abstract_action": [[99, 113], ["numpy.random.choice", "len"], "methods", ["None"], ["", "def", "select_next_abstract_action", "(", "self", ",", "abstract_state", ")", ":", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        abstact_state : int\n            Integer representation of the current abstract state.\n        \n        Outputs\n        -------\n        abstract_action : int\n            Integer representation of the next abstract action to take.\n        \"\"\"", "\n", "return", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "controller_list", ")", ",", "\n", "p", "=", "self", ".", "meta_policy", "[", "abstract_state", ",", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.predict": [[114, 131], ["controller.predict"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict"], ["", "def", "predict", "(", "self", ",", "obs", ",", "deterministic", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Get the system's action, given the current environment observation (state)\n\n        Inputs\n        ------\n        obs : tuple\n            Tuple representing the current environment observation (state).\n        deterministic (optional) : bool\n            Flag indicating whether or not to return a deterministic action or \n            a distribution over actions.\n        \"\"\"", "\n", "# Grab the currently selected controller", "\n", "controller", "=", "self", ".", "controller_list", "[", "self", ".", "current_controller_ind", "]", "\n", "action", ",", "_states", "=", "controller", ".", "predict", "(", "obs", ",", "deterministic", "=", "deterministic", ")", "\n", "\n", "return", "action", ",", "_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.eval_performance": [[132, 186], ["side_channels[].send_string", "utils.observers.ObserverIncrementTaskSuccessCount", "range", "side_channels[].unsubscribe", "env.reset", "unity_meta_controller.MetaController.reset", "range", "unity_meta_controller.MetaController.predict", "env.step"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.unsubscribe", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "eval_performance", "(", "self", ",", "env", ",", "side_channels", ",", "n_episodes", "=", "200", ",", "n_steps", "=", "1000", ")", ":", "\n", "        ", "\"\"\"\n        Perform empirical evaluation of the performance of the meta controller.\n\n        Inputs\n        ------\n        env : environment\n            Environment to perform evaluation in.\n        side_channels : dict\n            Dictionary of side channel objects used to specify environment\n            settings before running.\n        n_episodes (optional) : int\n            Number of episodes to rollout for evaluation.\n        n_steps (optional) : int\n            Length of each episode.\n\n        Outputs\n        -------\n        success_rate : float\n            Empirically measured rate of success of the meta-controller.\n        \"\"\"", "\n", "# Set the environment task to be the overall composite task", "\n", "side_channels", "[", "'custom_side_channel'", "]", ".", "send_string", "(", "'-1,-1'", ")", "\n", "\n", "avg_num_steps", "=", "0", "\n", "trials", "=", "0", "\n", "total_steps", "=", "0", "\n", "num_steps", "=", "0", "\n", "\n", "# Instantiate an observer to keep track of the number of times", "\n", "# the (sub) task is successfully completed.", "\n", "observer", "=", "ObserverIncrementTaskSuccessCount", "(", "side_channels", "[", "'custom_side_channel'", "]", ")", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "trials", "=", "trials", "+", "1", "\n", "avg_num_steps", "=", "(", "avg_num_steps", "+", "num_steps", ")", "/", "2", "\n", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "self", ".", "reset", "(", "side_channels", ")", "\n", "\n", "num_steps", "=", "0", "\n", "for", "step_ind", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "num_steps", "=", "num_steps", "+", "1", "\n", "total_steps", "=", "total_steps", "+", "1", "\n", "action", ",", "_states", "=", "self", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "done", ":", "\n", "                    ", "break", "\n", "\n", "# Unsubscribe the observer from the side-channel to prevent it from", "\n", "# continuing to count after the test is done.", "\n", "", "", "", "side_channels", "[", "'custom_side_channel'", "]", ".", "unsubscribe", "(", "observer", ")", "\n", "\n", "return", "observer", ".", "success_count", "/", "trials", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.demonstrate_capabilities": [[187, 225], ["side_channels[].set_configuration_parameters", "side_channels[].send_string", "range", "env.reset", "unity_meta_controller.MetaController.reset", "range", "unity_meta_controller.MetaController.predict", "env.step"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "demonstrate_capabilities", "(", "self", ",", "\n", "env", ",", "\n", "side_channels", ",", "\n", "n_episodes", "=", "5", ",", "\n", "n_steps", "=", "200", ",", "\n", "render", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Run the meta-controller in an environment and visualize the results.\n\n        Inputs\n        ------\n        env : Minigrid gym environment\n            Environment to perform evaluation in.\n        side_channels : dict\n            Dictionary of side channel objects used to specify environment\n            settings before running.\n        n_episodes (optional) : int\n            Number of episodes to rollout for evaluation.\n        n_steps (optional) : int\n            Length of each episode.\n        render (optional) : bool\n            Flag indicating whether or not to render the environment.\n        \"\"\"", "\n", "# Set the timescale of the simulation back to real time", "\n", "side_channels", "[", "'engine_config_channel'", "]", ".", "set_configuration_parameters", "(", "time_scale", "=", "1.0", ")", "\n", "\n", "# Set the environment task to be the overall composite task", "\n", "side_channels", "[", "'custom_side_channel'", "]", ".", "send_string", "(", "'-1,-1'", ")", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "self", ".", "reset", "(", "side_channels", ")", "\n", "for", "step", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "action", ",", "_states", "=", "self", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "done", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.__init__": [[15, 39], ["unity_labyrinth_controller.UnityLabyrinthController._init_learning_alg", "unity_labyrinth_controller.UnityLabyrinthController.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._init_learning_alg", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["def", "__init__", "(", "self", ",", "\n", "controller_ind", ",", "\n", "env", ",", "\n", "env_settings", "=", "None", ",", "\n", "max_training_steps", "=", "1e6", ",", "\n", "load_dir", "=", "None", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "controller_ind", "=", "controller_ind", "\n", "self", ".", "env_settings", "=", "env_settings", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "max_training_steps", "=", "max_training_steps", "\n", "\n", "self", ".", "data", "=", "{", "\n", "'total_training_steps'", ":", "0", ",", "\n", "'performance_estimates'", ":", "{", "}", ",", "\n", "'required_success_prob'", ":", "0", ",", "\n", "}", "\n", "\n", "if", "load_dir", "is", "None", ":", "\n", "            ", "assert", "env_settings", "is", "not", "None", "\n", "self", ".", "_init_learning_alg", "(", "env", ",", "verbose", "=", "self", ".", "verbose", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "load", "(", "env", ",", "load_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.learn": [[40, 59], ["side_channel.send_string", "unity_labyrinth_controller.UnityLabyrinthController.model.learn"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.learn"], ["", "", "def", "learn", "(", "self", ",", "side_channel", ",", "total_timesteps", "=", "5e4", ")", ":", "\n", "        ", "\"\"\"\n        Train the sub-system for a specified number of timesteps.\n\n        Inputs\n        ------\n        side_channel : CustomSideChannel object\n            An observable object that receives methods from the unity\n            environment and notifies all subscribed observers.\n        total_timesteps : int\n            Total number of timesteps to train the sub-system for.\n        \"\"\"", "\n", "# Set the environment to the appropriate subtask", "\n", "sub_task_string", "=", "'{},{}'", ".", "format", "(", "self", ".", "controller_ind", ",", "self", ".", "controller_ind", ")", "\n", "side_channel", ".", "send_string", "(", "sub_task_string", ")", "\n", "\n", "self", ".", "model", ".", "learn", "(", "total_timesteps", "=", "total_timesteps", ")", "\n", "self", ".", "data", "[", "'total_training_steps'", "]", "=", "self", ".", "data", "[", "'total_training_steps'", "]", "+", "total_timesteps", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.predict": [[60, 74], ["unity_labyrinth_controller.UnityLabyrinthController.model.predict"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict"], ["", "def", "predict", "(", "self", ",", "obs", ",", "deterministic", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Get the sub-system's action, given the current environment state\n\n        Inputs\n        ------\n        obs : tuple\n            Tuple representing the current environment observation (state).\n        deterministic (optional) : bool\n            Flag indicating whether or not to return a deterministic action or \n            a distribution over actions.\n        \"\"\"", "\n", "action", ",", "_states", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "deterministic", ")", "\n", "return", "action", ",", "_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.eval_performance": [[75, 130], ["side_channel.send_string", "utils.observers.ObserverIncrementTaskSuccessCount", "range", "side_channel.unsubscribe", "env.reset", "range", "unity_labyrinth_controller.UnityLabyrinthController.model.predict", "env.step"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.unsubscribe", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "eval_performance", "(", "self", ",", "env", ",", "side_channel", ",", "n_episodes", "=", "400", ",", "n_steps", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Perform empirical evaluation of the performance of the learned controller.\n\n        Inputs\n        ------\n        env : Gym Environment object\n            The environment in which to evaluate the controller's performance.\n        side_channel : CustomSideChannel object\n            An observable object that receives methods from the unity\n            environment and notifies all subscribed observers.\n        n_episodes : int\n            Number of episodes to rollout for evaluation.\n        n_steps : int\n            Length of each episode.\n        \"\"\"", "\n", "\n", "# Set the environment to the appropriate subtask", "\n", "sub_task_string", "=", "'{},{}'", ".", "format", "(", "self", ".", "controller_ind", ",", "self", ".", "controller_ind", ")", "\n", "side_channel", ".", "send_string", "(", "sub_task_string", ")", "\n", "\n", "avg_num_steps", "=", "0", "\n", "trials", "=", "0", "\n", "total_steps", "=", "0", "\n", "num_steps", "=", "0", "\n", "\n", "# Instantiate an observer to keep track of the number of times", "\n", "# the (sub) task is successfully completed.", "\n", "observer", "=", "ObserverIncrementTaskSuccessCount", "(", "side_channel", ")", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "trials", "=", "trials", "+", "1", "\n", "avg_num_steps", "=", "(", "avg_num_steps", "+", "num_steps", ")", "/", "2", "\n", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "num_steps", "=", "0", "\n", "for", "step_ind", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "num_steps", "=", "num_steps", "+", "1", "\n", "total_steps", "=", "total_steps", "+", "1", "\n", "action", ",", "_", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "_", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "if", "done", ":", "\n", "                    ", "break", "\n", "\n", "# Unsubscribe the observer from the side-channel to prevent it from", "\n", "# continuing to count after the test is done.", "\n", "", "", "", "side_channel", ".", "unsubscribe", "(", "observer", ")", "\n", "\n", "# Save the resulting data", "\n", "self", ".", "data", "[", "'performance_estimates'", "]", "[", "self", ".", "data", "[", "'total_training_steps'", "]", "]", "=", "{", "\n", "'success_count'", ":", "observer", ".", "success_count", ",", "\n", "'success_rate'", ":", "observer", ".", "success_count", "/", "trials", ",", "\n", "'num_trials'", ":", "trials", ",", "\n", "'avg_num_steps'", ":", "avg_num_steps", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.save": [[142, 168], ["os.path.join", "unity_labyrinth_controller.UnityLabyrinthController.model.save", "os.path.join", "os.path.isdir", "os.mkdir", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.save"], ["", "def", "save", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the controller object.\n\n        Inputs\n        ------\n        save_dir : string\n            Absolute path to the directory that will be used to save this controller.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "", "model_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model'", ")", "\n", "self", ".", "model", ".", "save", "(", "model_file", ")", "\n", "controller_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'controller_data.p'", ")", "\n", "\n", "controller_data", "=", "{", "\n", "'controller_ind'", ":", "self", ".", "controller_ind", ",", "\n", "'env_settings'", ":", "self", ".", "env_settings", ",", "\n", "'verbose'", ":", "self", ".", "verbose", ",", "\n", "'max_training_steps'", ":", "self", ".", "max_training_steps", ",", "\n", "'data'", ":", "self", ".", "data", ",", "\n", "}", "\n", "\n", "with", "open", "(", "controller_file", ",", "'wb'", ")", "as", "pickleFile", ":", "\n", "            ", "pickle", ".", "dump", "(", "controller_data", ",", "pickleFile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.load": [[169, 193], ["os.path.join", "os.path.join", "stable_baselines3.PPO.load", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["", "", "def", "load", "(", "self", ",", "env", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Load a controller object\n\n        Inputs\n        ------\n        env : Gym Environment object\n            The environment in which the controller will be acting.\n        save_dir : string\n            Absolute path to the directory that will be used to save this controller.\n        \"\"\"", "\n", "\n", "controller_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'controller_data.p'", ")", "\n", "with", "open", "(", "controller_file", ",", "'rb'", ")", "as", "pickleFile", ":", "\n", "            ", "controller_data", "=", "pickle", ".", "load", "(", "pickleFile", ")", "\n", "\n", "", "self", ".", "controller_ind", "=", "controller_data", "[", "'controller_ind'", "]", "\n", "self", ".", "env_settings", "=", "controller_data", "[", "'env_settings'", "]", "\n", "self", ".", "max_training_steps", "=", "controller_data", "[", "'max_training_steps'", "]", "\n", "self", ".", "verbose", "=", "controller_data", "[", "'verbose'", "]", "\n", "self", ".", "data", "=", "controller_data", "[", "'data'", "]", "\n", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model'", ")", "\n", "self", ".", "model", "=", "PPO", ".", "load", "(", "model_file", ",", "env", "=", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.get_success_prob": [[194, 198], ["numpy.max", "numpy.copy", "list", "unity_labyrinth_controller.UnityLabyrinthController.data[].keys"], "methods", ["None"], ["", "def", "get_success_prob", "(", "self", ")", ":", "\n", "# Return the most recently estimated probability of success", "\n", "        ", "max_total_training_steps", "=", "np", ".", "max", "(", "list", "(", "self", ".", "data", "[", "'performance_estimates'", "]", ".", "keys", "(", ")", ")", ")", "\n", "return", "np", ".", "copy", "(", "self", ".", "data", "[", "'performance_estimates'", "]", "[", "max_total_training_steps", "]", "[", "'success_rate'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController._init_learning_alg": [[204, 216], ["stable_baselines3.PPO"], "methods", ["None"], ["", "def", "_init_learning_alg", "(", "self", ",", "env", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "self", ".", "model", "=", "PPO", "(", "\"MlpPolicy\"", ",", "\n", "env", ",", "\n", "verbose", "=", "verbose", ",", "\n", "n_steps", "=", "512", ",", "\n", "batch_size", "=", "64", ",", "\n", "gae_lambda", "=", "0.95", ",", "\n", "gamma", "=", "0.99", ",", "\n", "n_epochs", "=", "10", ",", "\n", "ent_coef", "=", "0.0", ",", "\n", "learning_rate", "=", "2.5e-4", ",", "\n", "clip_range", "=", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_labyrinth_controller.UnityLabyrinthController.demonstrate_capabilities": [[217, 254], ["side_channel.send_string", "range", "env.reset", "env.reset", "range", "unity_labyrinth_controller.UnityLabyrinthController.model.predict", "env.step"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "demonstrate_capabilities", "(", "self", ",", "\n", "env", ",", "\n", "side_channel", ",", "\n", "n_episodes", "=", "5", ",", "\n", "n_steps", "=", "100", ",", "\n", "render", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Demonstrate the capabilities of the learned controller in the \n        environment used to train it.\n\n        Inputs\n        ------\n        env : Gym Environment object\n            The environment in which to evaluate the controller's performance.\n        side_channel : CustomSideChannel object\n            An observable object that receives methods from the unity\n            environment and notifies all subscribed observers.\n        n_episodes : int\n            Number of episodes to rollout for evaluation.\n        n_steps : int\n            Length of each episode.\n        render (optional) : bool\n            Whether or not to render the environment at every timestep.\n        \"\"\"", "\n", "# Set the environment to the appropriate subtask", "\n", "sub_task_string", "=", "'{},{}'", ".", "format", "(", "self", ".", "controller_ind", ",", "self", ".", "controller_ind", ")", "\n", "side_channel", ".", "send_string", "(", "sub_task_string", ")", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "for", "step", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "action", ",", "_states", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "done", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "obs", "=", "env", ".", "reset", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.__init__": [[15, 38], ["minigrid_controller.MiniGridController._set_training_env", "minigrid_controller.MiniGridController._init_learning_alg", "minigrid_controller.MiniGridController.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._set_training_env", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._init_learning_alg", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["def", "__init__", "(", "self", ",", "controller_ind", ",", "init_states", "=", "None", ",", "final_states", "=", "None", ",", "env_settings", "=", "None", ",", "max_training_steps", "=", "1e6", ",", "load_dir", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "controller_ind", "=", "controller_ind", "\n", "self", ".", "init_states", "=", "init_states", "\n", "self", ".", "final_states", "=", "final_states", "\n", "self", ".", "env_settings", "=", "env_settings", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "max_training_steps", "=", "max_training_steps", "\n", "\n", "self", ".", "data", "=", "{", "\n", "'total_training_steps'", ":", "0", ",", "\n", "'performance_estimates'", ":", "{", "}", ",", "\n", "'required_success_prob'", ":", "0", ",", "\n", "}", "\n", "\n", "if", "load_dir", "is", "None", ":", "\n", "            ", "assert", "init_states", "is", "not", "None", "\n", "assert", "final_states", "is", "not", "None", "\n", "assert", "env_settings", "is", "not", "None", "\n", "self", ".", "_set_training_env", "(", "env_settings", ")", "\n", "self", ".", "_init_learning_alg", "(", "verbose", "=", "self", ".", "verbose", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "load", "(", "load_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.learn": [[39, 50], ["minigrid_controller.MiniGridController.model.learn"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.learn"], ["", "", "def", "learn", "(", "self", ",", "total_timesteps", "=", "5e4", ")", ":", "\n", "        ", "\"\"\"\n        Train the sub-system for a specified number of timesteps.\n\n        Inputs\n        ------\n        total_timesteps : int\n            Total number of timesteps to train the sub-system for.\n        \"\"\"", "\n", "self", ".", "model", ".", "learn", "(", "total_timesteps", "=", "total_timesteps", ")", "\n", "self", ".", "data", "[", "'total_training_steps'", "]", "=", "self", ".", "data", "[", "'total_training_steps'", "]", "+", "total_timesteps", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.predict": [[51, 65], ["minigrid_controller.MiniGridController.model.predict"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict"], ["", "def", "predict", "(", "self", ",", "obs", ",", "deterministic", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Get the sub-system's action, given the current environment observation (state)\n\n        Inputs\n        ------\n        obs : tuple\n            Tuple representing the current environment observation (state).\n        deterministic (optional) : bool\n            Flag indicating whether or not to return a deterministic action or a distribution\n            over actions.\n        \"\"\"", "\n", "action", ",", "_states", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "deterministic", ")", "\n", "return", "action", ",", "_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.eval_performance": [[66, 112], ["range", "minigrid_controller.MiniGridController.training_env.reset", "range", "minigrid_controller.MiniGridController.model.predict", "minigrid_controller.MiniGridController.training_env.step", "rollout_successes.append", "rollout_successes.append", "rollout_successes.append"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "eval_performance", "(", "self", ",", "n_episodes", "=", "400", ",", "n_steps", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        Perform empirical evaluation of the performance of the learned controller.\n\n        Inputs\n        ------\n        n_episodes : int\n            Number of episodes to rollout for evaluation.\n        n_steps : int\n            Length of each episode.\n        \"\"\"", "\n", "success_count", "=", "0", "\n", "avg_num_steps", "=", "0", "\n", "trials", "=", "0", "\n", "total_steps", "=", "0", "\n", "num_steps", "=", "0", "\n", "\n", "rollout_successes", "=", "[", "]", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "trials", "=", "trials", "+", "1", "\n", "avg_num_steps", "=", "(", "avg_num_steps", "+", "num_steps", ")", "/", "2", "\n", "\n", "obs", "=", "self", ".", "training_env", ".", "reset", "(", ")", "\n", "num_steps", "=", "0", "\n", "for", "step_ind", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "num_steps", "=", "num_steps", "+", "1", "\n", "total_steps", "=", "total_steps", "+", "1", "\n", "action", ",", "_states", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "training_env", ".", "step", "(", "action", ")", "\n", "if", "step_ind", "==", "n_steps", "-", "1", ":", "\n", "                    ", "rollout_successes", ".", "append", "(", "0", ")", "\n", "", "if", "done", ":", "\n", "                    ", "if", "info", "[", "'task_complete'", "]", ":", "\n", "                        ", "success_count", "=", "success_count", "+", "1", "\n", "rollout_successes", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "rollout_successes", ".", "append", "(", "0", ")", "\n", "", "break", "\n", "\n", "# self.data['rollout_successes'][self.data['total_training_steps']] = rollout_successes", "\n", "", "", "", "self", ".", "data", "[", "'performance_estimates'", "]", "[", "self", ".", "data", "[", "'total_training_steps'", "]", "]", "=", "{", "\n", "'success_count'", ":", "success_count", ",", "\n", "'success_rate'", ":", "success_count", "/", "trials", ",", "\n", "'num_trials'", ":", "trials", ",", "\n", "'avg_num_steps'", ":", "avg_num_steps", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.is_task_complete": [[114, 123], ["None"], "methods", ["None"], ["", "def", "is_task_complete", "(", "self", ",", "obs", ")", ":", "\n", "        ", "\"\"\"\n        Return true if the current observation indicates the agent has already reached its goal.\n        \"\"\"", "\n", "current_state", "=", "(", "obs", "[", "0", "]", ",", "obs", "[", "1", "]", ",", "obs", "[", "2", "]", ")", "\n", "if", "current_state", "in", "self", ".", "final_states", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.save": [[124, 152], ["os.path.join", "minigrid_controller.MiniGridController.model.save", "os.path.join", "os.path.isdir", "os.mkdir", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.save"], ["", "", "def", "save", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the controller object.\n\n        Inputs\n        ------\n        save_dir : string\n            Absolute path to the directory that will be used to save this controller.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "\n", "", "model_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model'", ")", "\n", "self", ".", "model", ".", "save", "(", "model_file", ")", "\n", "controller_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'controller_data.p'", ")", "\n", "\n", "controller_data", "=", "{", "\n", "'controller_ind'", ":", "self", ".", "controller_ind", ",", "\n", "'init_states'", ":", "self", ".", "init_states", ",", "\n", "'final_states'", ":", "self", ".", "final_states", ",", "\n", "'env_settings'", ":", "self", ".", "env_settings", ",", "\n", "'verbose'", ":", "self", ".", "verbose", ",", "\n", "'max_training_steps'", ":", "self", ".", "max_training_steps", ",", "\n", "'data'", ":", "self", ".", "data", ",", "\n", "}", "\n", "\n", "with", "open", "(", "controller_file", ",", "'wb'", ")", "as", "pickleFile", ":", "\n", "            ", "pickle", ".", "dump", "(", "controller_data", ",", "pickleFile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load": [[153, 179], ["os.path.join", "minigrid_controller.MiniGridController._set_training_env", "os.path.join", "stable_baselines3.PPO.load", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._set_training_env", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.load"], ["", "", "def", "load", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Load a controller object\n\n        Inputs\n        ------\n        save_dir : string\n            Absolute path to the directory that will be used to save this controller.\n        \"\"\"", "\n", "\n", "controller_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'controller_data.p'", ")", "\n", "with", "open", "(", "controller_file", ",", "'rb'", ")", "as", "pickleFile", ":", "\n", "            ", "controller_data", "=", "pickle", ".", "load", "(", "pickleFile", ")", "\n", "\n", "", "self", ".", "controller_ind", "=", "controller_data", "[", "'controller_ind'", "]", "\n", "self", ".", "init_states", "=", "controller_data", "[", "'init_states'", "]", "\n", "self", ".", "final_states", "=", "controller_data", "[", "'final_states'", "]", "\n", "self", ".", "env_settings", "=", "controller_data", "[", "'env_settings'", "]", "\n", "self", ".", "max_training_steps", "=", "controller_data", "[", "'max_training_steps'", "]", "\n", "self", ".", "verbose", "=", "controller_data", "[", "'verbose'", "]", "\n", "self", ".", "data", "=", "controller_data", "[", "'data'", "]", "\n", "\n", "self", ".", "_set_training_env", "(", "self", ".", "env_settings", ")", "\n", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model'", ")", "\n", "self", ".", "model", "=", "PPO", ".", "load", "(", "model_file", ",", "env", "=", "self", ".", "training_env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_init_states": [[180, 182], ["None"], "methods", ["None"], ["", "def", "get_init_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "init_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_final_states": [[183, 185], ["None"], "methods", ["None"], ["", "def", "get_final_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "final_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob": [[186, 190], ["numpy.max", "numpy.copy", "list", "minigrid_controller.MiniGridController.data[].keys"], "methods", ["None"], ["", "def", "get_success_prob", "(", "self", ")", ":", "\n", "# Return the most recently estimated probability of success", "\n", "        ", "max_total_training_steps", "=", "np", ".", "max", "(", "list", "(", "self", ".", "data", "[", "'performance_estimates'", "]", ".", "keys", "(", ")", ")", ")", "\n", "return", "np", ".", "copy", "(", "self", ".", "data", "[", "'performance_estimates'", "]", "[", "max_total_training_steps", "]", "[", "'success_rate'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._set_training_env": [[191, 195], ["Environments.minigrid_labyrinth.Maze"], "methods", ["None"], ["", "def", "_set_training_env", "(", "self", ",", "env_settings", ")", ":", "\n", "        ", "self", ".", "training_env", "=", "Maze", "(", "**", "env_settings", ")", "\n", "self", ".", "training_env", ".", "agent_start_states", "=", "self", ".", "init_states", "\n", "self", ".", "training_env", ".", "goal_states", "=", "self", ".", "final_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController._init_learning_alg": [[196, 208], ["stable_baselines3.PPO"], "methods", ["None"], ["", "def", "_init_learning_alg", "(", "self", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "self", ".", "model", "=", "PPO", "(", "\"MlpPolicy\"", ",", "\n", "self", ".", "training_env", ",", "\n", "verbose", "=", "verbose", ",", "\n", "n_steps", "=", "512", ",", "\n", "batch_size", "=", "64", ",", "\n", "gae_lambda", "=", "0.95", ",", "\n", "gamma", "=", "0.99", ",", "\n", "n_epochs", "=", "10", ",", "\n", "ent_coef", "=", "0.0", ",", "\n", "learning_rate", "=", "2.5e-4", ",", "\n", "clip_range", "=", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.demonstrate_capabilities": [[209, 233], ["range", "minigrid_controller.MiniGridController.training_env.reset", "minigrid_controller.MiniGridController.training_env.reset", "range", "minigrid_controller.MiniGridController.model.predict", "minigrid_controller.MiniGridController.training_env.step", "minigrid_controller.MiniGridController.training_env.render"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "demonstrate_capabilities", "(", "self", ",", "n_episodes", "=", "5", ",", "n_steps", "=", "100", ",", "render", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Demonstrate the capabilities of the learned controller in the environment used to train it.\n\n        Inputs\n        ------\n        n_episodes : int\n            Number of episodes to rollout for evaluation.\n        n_steps : int\n            Length of each episode.\n        render (optional) : bool\n            Whether or not to render the environment at every timestep.\n        \"\"\"", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "obs", "=", "self", ".", "training_env", ".", "reset", "(", ")", "\n", "for", "step", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "action", ",", "_states", "=", "self", ".", "model", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "training_env", ".", "step", "(", "action", ")", "\n", "if", "render", ":", "\n", "                    ", "self", ".", "training_env", ".", "render", "(", "highlight", "=", "False", ")", "\n", "", "if", "done", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "obs", "=", "self", ".", "training_env", ".", "reset", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.__init__": [[11, 28], ["numpy.arange", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "meta_policy", ",", "controller_list", ",", "state_list", ")", ":", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        meta_policy : numpy array\n            Numpy array representing the meta-policy.\n        controller_list : list\n            List of MinigridController objects.\n        state_list : list\n            List of HLM states. Each of these high-level states is itself\n            a list of low-level environment states.\n        \"\"\"", "\n", "self", ".", "meta_policy", "=", "meta_policy", "\n", "self", ".", "controller_list", "=", "controller_list", "\n", "self", ".", "controller_indeces", "=", "np", ".", "arange", "(", "len", "(", "controller_list", ")", ")", "\n", "self", ".", "state_list", "=", "state_list", "\n", "self", ".", "current_controller_ind", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.obs_mapping": [[29, 52], ["RuntimeError", "isinstance", "meta_controller.MetaController.state_list.index"], "methods", ["None"], ["", "def", "obs_mapping", "(", "self", ",", "obs", ")", ":", "\n", "        ", "\"\"\"\n        Map from an environment observation (state) to the corresponding \n        high-level state.\n\n        Inputs\n        ------\n        obs : tuple\n            Tuple representing the current environment observation (state).\n        \"\"\"", "\n", "state", "=", "(", "obs", "[", "0", "]", ",", "obs", "[", "1", "]", ",", "obs", "[", "2", "]", ")", "\n", "\n", "obs_in_abstract_state", "=", "False", "\n", "\n", "for", "env_state_set", "in", "self", ".", "state_list", ":", "\n", "            ", "if", "isinstance", "(", "env_state_set", ",", "list", ")", "and", "state", "in", "env_state_set", ":", "\n", "                ", "high_level_state", "=", "self", ".", "state_list", ".", "index", "(", "env_state_set", ")", "\n", "obs_in_abstract_state", "=", "True", "\n", "\n", "", "", "if", "not", "obs_in_abstract_state", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Trying to enact meta-policy from state that doesn't exist in high-level state space.\"", ")", "\n", "\n", "", "return", "high_level_state", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset": [[53, 55], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "current_controller_ind", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict": [[56, 89], ["controller.predict", "controller.is_task_complete", "meta_controller.MetaController.obs_mapping", "numpy.random.choice", "len"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.is_task_complete", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.obs_mapping"], ["", "def", "predict", "(", "self", ",", "obs", ",", "deterministic", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Get the system's action, given the current environment observation (state)\n\n        Inputs\n        ------\n        obs : tuple\n            Tuple representing the current environment observation (state).\n        deterministic (optional) : bool\n            Flag indicating whether or not to return a deterministic action or a distribution\n            over actions.\n        \"\"\"", "\n", "\n", "if", "self", ".", "current_controller_ind", "is", "not", "None", ":", "\n", "# Grab the currently selected controller", "\n", "            ", "controller", "=", "self", ".", "controller_list", "[", "self", ".", "current_controller_ind", "]", "\n", "\n", "# If the controller's task has been completed, deselect it", "\n", "if", "controller", ".", "is_task_complete", "(", "obs", ")", ":", "\n", "                ", "self", ".", "current_controller_ind", "=", "None", "\n", "\n", "# In no controller is selected, choose which controller to execute", "\n", "", "", "if", "self", ".", "current_controller_ind", "is", "None", ":", "\n", "            ", "meta_state", "=", "self", ".", "obs_mapping", "(", "obs", ")", "\n", "controller_probabilities", "=", "self", ".", "meta_policy", "[", "meta_state", ",", ":", "]", "\n", "self", ".", "current_controller_ind", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "controller_list", ")", ",", "p", "=", "controller_probabilities", ")", "\n", "\n", "# Grab the currently selected controller", "\n", "", "controller", "=", "self", ".", "controller_list", "[", "self", ".", "current_controller_ind", "]", "\n", "\n", "action", ",", "_states", "=", "controller", ".", "predict", "(", "obs", ",", "deterministic", "=", "deterministic", ")", "\n", "\n", "return", "action", ",", "_states", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.eval_performance": [[90, 133], ["range", "env.reset", "meta_controller.MetaController.reset", "range", "meta_controller.MetaController.predict", "env.step"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "eval_performance", "(", "self", ",", "env", ",", "n_episodes", "=", "200", ",", "n_steps", "=", "1000", ")", ":", "\n", "        ", "\"\"\"\n        Perform empirical evaluation of the performance of the meta controller.\n\n        Inputs\n        ------\n        env : Minigrid gym environment\n            Environment to perform evaluation in.\n        n_episodes (optional) : int\n            Number of episodes to rollout for evaluation.\n        n_steps (optional) : int\n            Length of each episode.\n\n        Outputs\n        -------\n        success_rate : float\n            Empirically measured rate of success of the meta-controller.\n        \"\"\"", "\n", "success_count", "=", "0", "\n", "avg_num_steps", "=", "0", "\n", "trials", "=", "0", "\n", "total_steps", "=", "0", "\n", "num_steps", "=", "0", "\n", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "trials", "=", "trials", "+", "1", "\n", "avg_num_steps", "=", "(", "avg_num_steps", "+", "num_steps", ")", "/", "2", "\n", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "num_steps", "=", "0", "\n", "for", "step_ind", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "num_steps", "=", "num_steps", "+", "1", "\n", "total_steps", "=", "total_steps", "+", "1", "\n", "action", ",", "_states", "=", "self", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "done", ":", "\n", "                    ", "if", "info", "[", "'task_complete'", "]", ":", "\n", "                        ", "success_count", "=", "success_count", "+", "1", "\n", "", "break", "\n", "\n", "", "", "", "return", "success_count", "/", "trials", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.demonstrate_capabilities": [[134, 159], ["range", "env.reset", "meta_controller.MetaController.reset", "range", "meta_controller.MetaController.predict", "env.step", "env.render"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.reset", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.meta_controller.MetaController.predict", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step"], ["", "def", "demonstrate_capabilities", "(", "self", ",", "env", ",", "n_episodes", "=", "5", ",", "n_steps", "=", "200", ",", "render", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Run the meta-controller in an environment and visualize the results.\n\n        Inputs\n        ------\n        env : Minigrid gym environment\n            Environment to perform evaluation in.\n        n_episodes (optional) : int\n            Number of episodes to rollout for evaluation.\n        n_steps (optional) : int\n            Length of each episode.\n        render (optional) : bool\n            Flag indicating whether or not to render the environment.\n        \"\"\"", "\n", "for", "episode_ind", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "for", "step", "in", "range", "(", "n_steps", ")", ":", "\n", "                ", "action", ",", "_states", "=", "self", ".", "predict", "(", "obs", ",", "deterministic", "=", "True", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "render", ":", "\n", "                    ", "env", ".", "render", "(", "highlight", "=", "False", ")", "\n", "", "if", "done", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_reward_opt.solve_max_reward_perfect_subsystems": [[6, 86], ["gurobipy.Model", "dict", "mdp.avail_actions.copy", "gb.Model.update", "gb.Model.setObjective", "gb.Model.optimize", "gb.Model.addConstr", "numpy.zeros", "gb.Model.addVar", "numpy.ones", "len", "numpy.sum", "str", "len", "str"], "function", ["None"], ["def", "solve_max_reward_perfect_subsystems", "(", "mdp", ",", "\n", "reward_vec", ":", "np", ".", "ndarray", ")", ":", "\n", "#initialize gurobi model", "\n", "    ", "linear_model", "=", "gb", ".", "Model", "(", "\"abs_mdp_linear\"", ")", "\n", "\n", "#dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "mdp", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#dummy action for goal state", "\n", "avail_actions", "[", "mdp", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "            ", "state_act_vars", "[", "s", ",", "a", "]", "=", "linear_model", ".", "addVar", "(", "lb", "=", "0", ",", "\n", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "#gurobi updates model", "\n", "", "", "linear_model", ".", "update", "(", ")", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "cons", "=", "0", "\n", "#add outgoing occupancy for available actions", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "            ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "mdp", ".", "predecessors", "[", "s", "]", ":", "\n", "#this if clause ensures that you dont double count reaching goal and failure", "\n", "            ", "if", "not", "s_bar", "==", "mdp", ".", "s_g", "and", "not", "s_bar", "==", "mdp", ".", "s_fail", ":", "\n", "                ", "cons", "-=", "mdp", ".", "discount", "*", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "1.0", "# optimism", "\n", "#initial state occupancy", "\n", "", "", "if", "s", "==", "mdp", ".", "s_i", ":", "\n", "            ", "cons", "=", "cons", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "linear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "", "obj", "=", "0", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "            ", "obj", "+=", "reward_vec", "[", "s", ",", "a", "]", "*", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#set the objective, solve the problem", "\n", "", "", "linear_model", ".", "setObjective", "(", "obj", ",", "gb", ".", "GRB", ".", "MAXIMIZE", ")", "\n", "linear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "linear_model", ".", "SolCount", "==", "0", ":", "\n", "        ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "        ", "feasible_flag", "=", "True", "\n", "\n", "", "if", "feasible_flag", ":", "\n", "# Construct the policy from the occupancy variables", "\n", "        ", "policy", "=", "np", ".", "zeros", "(", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "            ", "if", "len", "(", "mdp", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to ", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                    ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "                        ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "mdp", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                    ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "                        ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "        ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "reward_max", "=", "0", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "            ", "reward_max", "+=", "reward_vec", "[", "s", ",", "a", "]", "*", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "\n", "\n", "", "", "return", "policy", ",", "reward_max", ",", "feasible_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_reward_opt.solve_low_level_requirements_action": [[87, 279], ["gurobipy.Model", "dict", "dict", "dict", "dict", "gb.Model.update", "gb.Model.addConstr", "print", "gb.Model.setObjective", "gb.Model.optimize", "mdp.avail_actions[].remove", "RuntimeError", "gb.Model.addVar", "gb.Model.addVar", "gb.Model.addVar", "gb.Model.addConstr", "numpy.copy", "gb.Model.addConstr", "gb.Model.addConstr", "numpy.zeros", "gb.Model.addVar", "mdp.controller_list[].get_success_prob", "print", "numpy.max", "numpy.ones", "numpy.copy", "print", "gb.Model.addConstr", "required_success_probs.keys", "required_success_probs[].append", "len", "numpy.sum", "str", "str", "str", "mdp.controller_list[].get_success_prob", "mdp.controller_list[].get_success_prob", "numpy.copy", "str", "len", "str"], "function", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob"], ["", "def", "solve_low_level_requirements_action", "(", "mdp", ",", "\n", "reward_vec", ":", "np", ".", "ndarray", ",", "\n", "delta", ":", "float", ",", "\n", "reward_max", ":", "float", ",", "\n", "max_timesteps_per_component", ":", "int", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Find new transition probabilities guaranteeing that a feasible meta-policy \n    exists with expected reward >= delta * reward_max.\n\n    Inputs\n    ------\n    reward_vec :\n        An array with shape (mdp.N_S, mdp.N_A) that encodes the reward function.\n    delta : float\n        The required probability of reaching the target set in the HLM.\n    reward_max : float\n        The maximum achievable reward with perfect subsystems.\n    max_timesteps_per_component : int\n        Number of training steps (for an individual sub-system) beyond which its current\n        estimated performance value should be used as an upper bound on the corresponding\n        transition probability in the HLM.\n\n    Outputs\n    -------\n    policy : numpy array\n        The meta-policy satisfying the task specification, under the solution\n        transition probabilities in the HLM.\n        Returns an array of -1 if no feasible solution exists.\n    required_success_probs : list\n        List of the solution transition probabilities in the HLM.\n        Returns a list of -1 if no feasible solution exists.\n    achieved_reward : float\n        The HLM predicted expected reward under the solution\n        meta-policy and solution transition probabilities in the HLM.\n    feasibility_flag : bool\n        Flag indicating the feasibility of the bilinear program being solved.\n    \"\"\"", "\n", "if", "delta", ">", "1", "or", "delta", "<", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"delta value should be between 0 and 1\"", ")", "\n", "\n", "# initialize gurobi model", "\n", "", "bilinear_model", "=", "gb", ".", "Model", "(", "\"abs_mdp_bilinear\"", ")", "\n", "\n", "# activate gurobi nonconvex", "\n", "bilinear_model", ".", "params", ".", "NonConvex", "=", "2", "\n", "\n", "# dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for MDP prob variables", "\n", "MDP_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for slack variables", "\n", "slack_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for epigraph variables used to define objective", "\n", "MDP_prob_diff_maximizers", "=", "dict", "(", ")", "\n", "\n", "# dummy action for goal state", "\n", "mdp", ".", "avail_actions", "[", "mdp", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "# create occupancy measures, probability variables and reward variables", "\n", "#for s in self.S:", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "            ", "state_act_vars", "[", "s", ",", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "", "", "for", "a", "in", "mdp", ".", "A", ":", "\n", "        ", "MDP_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"mdp_prob_\"", "+", "str", "(", "a", ")", ")", "\n", "slack_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"slack_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "'mdp_prob_difference_maximizer_'", "+", "str", "(", "a", ")", ")", "\n", "\n", "# gurobi updates model", "\n", "", "bilinear_model", ".", "update", "(", ")", "\n", "\n", "# MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "cons", "=", "0", "\n", "# add outgoing occupancy for available actions", "\n", "\n", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "            ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "# add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "mdp", ".", "predecessors", "[", "s", "]", ":", "\n", "# # this if clause ensures that you dont double count reaching goal and failure", "\n", "# if not s_bar == mdp.s_g and not s_bar == mdp.s_fail:", "\n", "            ", "cons", "-=", "mdp", ".", "discount", "*", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "MDP_prob_vars", "[", "a_bar", "]", "\n", "# initial state occupancy", "\n", "", "if", "s", "==", "mdp", ".", "s_i", ":", "\n", "            ", "cons", "=", "cons", "-", "1", "\n", "\n", "# sets occupancy constraints", "\n", "", "bilinear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# Expected reward constraint", "\n", "", "rew_sum", "=", "0", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "            ", "rew_sum", "+=", "reward_vec", "[", "s", ",", "a", "]", "*", "state_act_vars", "[", "s", ",", "a", "]", "\n", "", "", "bilinear_model", ".", "addConstr", "(", "rew_sum", ">=", "(", "1", "-", "delta", ")", "*", "reward_max", ")", "\n", "\n", "print", "(", "\"opt\"", ")", "\n", "\n", "# For each low-level component, add constraints corresponding to", "\n", "# the existing performance.", "\n", "for", "a", "in", "mdp", ".", "A", ":", "\n", "        ", "existing_success_prob", "=", "np", ".", "copy", "(", "mdp", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", ">=", "existing_success_prob", ")", "\n", "\n", "# If one of the components exceeds the maximum allowable training steps, upper bound its success probability.", "\n", "", "if", "max_timesteps_per_component", ":", "\n", "        ", "for", "a", "in", "mdp", ".", "A", ":", "\n", "            ", "if", "mdp", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'total_training_steps'", "]", ">=", "max_timesteps_per_component", ":", "\n", "                ", "existing_success_prob", "=", "np", ".", "copy", "(", "mdp", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "print", "(", "'Controller {}, max success prob: {}'", ".", "format", "(", "a", ",", "existing_success_prob", ")", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", "<=", "existing_success_prob", "+", "slack_prob_vars", "[", "a", "]", ")", "\n", "\n", "# set up the objective", "\n", "", "", "", "obj", "=", "0", "\n", "\n", "slack_cons", "=", "1e3", "\n", "# # Minimize the sum of success probability lower bounds", "\n", "\n", "for", "a", "in", "mdp", ".", "A", ":", "\n", "        ", "obj", "+=", "MDP_prob_diff_maximizers", "[", "a", "]", "\n", "obj", "+=", "slack_cons", "*", "slack_prob_vars", "[", "a", "]", "\n", "\n", "# Minimize the sum of differences between probability objective and empirical achieved probabilities", "\n", "", "for", "a", "in", "mdp", ".", "A", ":", "\n", "        ", "bilinear_model", ".", "addConstr", "(", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", ">=", "MDP_prob_vars", "[", "a", "]", "-", "mdp", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "\n", "# set the objective, solve the problem", "\n", "", "bilinear_model", ".", "setObjective", "(", "obj", ",", "gb", ".", "GRB", ".", "MINIMIZE", ")", "\n", "bilinear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "bilinear_model", ".", "SolCount", "==", "0", ":", "\n", "        ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "        ", "feasible_flag", "=", "True", "\n", "\n", "", "for", "a", "in", "mdp", ".", "A", ":", "\n", "        ", "if", "slack_prob_vars", "[", "a", "]", ".", "x", ">", "1e-6", ":", "\n", "            ", "print", "(", "\"required slack value {} at action: {} \"", ".", "format", "(", "slack_prob_vars", "[", "a", "]", ".", "x", ",", "a", ")", ")", "\n", "\n", "", "", "if", "feasible_flag", ":", "\n", "# Update the requirements for the individual components", "\n", "        ", "required_success_probs", "=", "{", "}", "\n", "for", "a", "in", "mdp", ".", "A", ":", "\n", "            ", "if", "a", "not", "in", "required_success_probs", ".", "keys", "(", ")", ":", "\n", "                ", "required_success_probs", "[", "a", "]", "=", "[", "]", "\n", "required_success_probs", "[", "a", "]", ".", "append", "(", "np", ".", "copy", "(", "MDP_prob_vars", "[", "a", "]", ".", "x", ")", ")", "\n", "", "", "for", "a", "in", "mdp", ".", "A", ":", "\n", "            ", "mdp", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'required_success_prob'", "]", "=", "np", ".", "max", "(", "required_success_probs", "[", "a", "]", ")", "\n", "\n", "# Create a list of the required success probabilities of each of the components", "\n", "", "required_success_probs", "=", "[", "MDP_prob_vars", "[", "a", "]", ".", "x", "for", "a", "in", "mdp", ".", "A", "]", "\n", "\n", "# Save the probability of reaching the goal state under the solution", "\n", "achieved_reward", "=", "0", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "            ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "achieved_reward", "+=", "reward_vec", "[", "s", ",", "a", "]", "*", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "\n", "\n", "# Construct the policy from the occupancy variables", "\n", "", "", "policy", "=", "np", ".", "zeros", "(", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "            ", "if", "len", "(", "mdp", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                    ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "                        ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "mdp", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                    ", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", ":", "\n", "                        ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "        ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "required_success_probs", "=", "[", "[", "-", "1", "for", "a", "in", "mdp", ".", "avail_actions", "[", "s", "]", "]", "for", "s", "in", "mdp", ".", "S", "]", "\n", "achieved_reward", "=", "-", "1", "\n", "\n", "# Remove dummy action from goal state", "\n", "", "mdp", ".", "avail_actions", "[", "mdp", ".", "s_g", "]", ".", "remove", "(", "0", ")", "\n", "\n", "return", "policy", ",", "required_success_probs", ",", "achieved_reward", ",", "feasible_flag", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.solve_optimistic_irl": [[5, 58], ["high_level_irl_opt.construct_optimistic_irl_forward_pass", "irl_results[].append", "tqdm.tqdm", "numpy.zeros", "print", "range", "high_level_irl_opt.solve_optimistic_forward_problem", "irl_results[].append", "irl_results[].append", "irl_results[].append", "irl_results[].append", "high_level_irl_opt.state_act_feature_count_difference", "irl_results[].append", "irl_results[].append", "high_level_irl_opt.extract_opt_var_values", "high_level_irl_opt.extract_opt_var_values", "numpy.sum", "numpy.multiply"], "function", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.construct_optimistic_irl_forward_pass", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.solve_optimistic_forward_problem", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.state_act_feature_count_difference", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.extract_opt_var_values", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.extract_opt_var_values"], ["def", "solve_optimistic_irl", "(", "mdp", ",", "\n", "feature_counts", ":", "np", ".", "ndarray", ",", "\n", "num_iterations", ":", "int", "=", "1000", ",", "\n", "alpha", ":", "float", "=", "0.01", ",", "\n", "verbose", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Solve an inverse reinforcement learning problem.\n    \"\"\"", "\n", "irl_results", "=", "{", "\n", "'feature_counts'", ":", "feature_counts", ",", "\n", "'init_theta'", ":", "np", ".", "zeros", "(", "feature_counts", ".", "shape", ")", ",", "\n", "# np.copy(feature_counts), # As a starting guess, just use the provided empirical discounted feature counts", "\n", "'theta_list'", ":", "[", "]", ",", "\n", "'opt_val_list'", ":", "[", "]", ",", "\n", "'state_act_vars_list'", ":", "[", "]", ",", "\n", "'state_vars_list'", ":", "[", "]", ",", "\n", "'grad_list'", ":", "[", "]", ",", "\n", "'irl_objective_list'", ":", "[", "]", ",", "\n", "}", "\n", "\n", "# Begin by constructing the optimization problem", "\n", "opt_problem", "=", "construct_optimistic_irl_forward_pass", "(", "mdp", ")", "\n", "\n", "irl_results", "[", "'theta_list'", "]", ".", "append", "(", "irl_results", "[", "'init_theta'", "]", ")", "\n", "\n", "if", "verbose", ":", "print", "(", "'Solving inverse RL problem.'", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "num_iterations", ")", ")", ":", "\n", "\n", "        ", "theta", "=", "irl_results", "[", "'theta_list'", "]", "[", "-", "1", "]", "\n", "\n", "# solve the forward problem", "\n", "sol_val", "=", "solve_optimistic_forward_problem", "(", "opt_problem", ",", "theta", ")", "\n", "\n", "# save the results of the forward problem", "\n", "irl_results", "[", "'opt_val_list'", "]", ".", "append", "(", "sol_val", ")", "\n", "irl_results", "[", "'state_act_vars_list'", "]", ".", "append", "(", "extract_opt_var_values", "(", "opt_problem", "[", "'vars'", "]", "[", "'state_act_vars'", "]", ")", ")", "\n", "irl_results", "[", "'state_vars_list'", "]", ".", "append", "(", "extract_opt_var_values", "(", "opt_problem", "[", "'vars'", "]", "[", "'state_vars'", "]", ")", ")", "\n", "\n", "irl_results", "[", "'irl_objective_list'", "]", ".", "append", "(", "sol_val", "-", "np", ".", "sum", "(", "np", ".", "multiply", "(", "theta", ",", "feature_counts", ")", ")", ")", "\n", "\n", "# Calculate gradient w.r.t. theta and take a step.", "\n", "grad", "=", "state_act_feature_count_difference", "(", "feature_counts", ",", "\n", "opt_problem", "[", "'vars'", "]", "[", "'state_act_vars'", "]", ")", "\n", "irl_results", "[", "'grad_list'", "]", ".", "append", "(", "grad", ")", "\n", "\n", "new_theta", "=", "theta", "-", "alpha", "*", "grad", "\n", "\n", "# Project theta so all elements are positive", "\n", "# new_theta[np.where(new_theta < 0)] = 0", "\n", "\n", "irl_results", "[", "'theta_list'", "]", ".", "append", "(", "new_theta", ")", "\n", "\n", "", "return", "irl_results", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.extract_opt_var_values": [[59, 64], ["vars_dict.keys"], "function", ["None"], ["", "def", "extract_opt_var_values", "(", "vars_dict", ")", ":", "\n", "    ", "copy", "=", "{", "}", "\n", "for", "key", "in", "vars_dict", ".", "keys", "(", ")", ":", "\n", "        ", "copy", "[", "key", "]", "=", "vars_dict", "[", "key", "]", ".", "value", "\n", "", "return", "copy", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.extract_optimal_policy": [[65, 70], ["vars_dict[].keys", "vars_dict[].keys"], "function", ["None"], ["", "def", "extract_optimal_policy", "(", "vars_dict", ")", ":", "\n", "    ", "policy", "=", "{", "}", "\n", "for", "s", "in", "vars_dict", "[", "'state_vars'", "]", ".", "keys", "(", ")", ":", "\n", "        ", "for", "(", "s", ",", "a", ")", "in", "vars_dict", "[", "'state_act_vars'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.solve_optimistic_forward_problem": [[71, 95], ["problem[].solve"], "function", ["None"], ["", "", "", "def", "solve_optimistic_forward_problem", "(", "problem", ":", "dict", ",", "\n", "reward_vec", ":", "np", ".", "ndarray", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Solve the forward pass of the inverse reinforcement learning problem.\n    This corresponds to solving a maximum entropy dynamic programming problem \n    with a given reward vector.\n\n    Parameters\n    ----------\n    problem : \n        A dictionary containing a cvxpy optimization problem (problem['problem']),\n        its variables (problem['vars']), and its parameters (problem['params']).\n    reward_vec : \n        A (N_S, N_A) numpy array representing the reward vector to use in \n        solving the forward optimization problem.\n\n    Returns\n    -------\n    The optimal value of the optimization problem, corresponding to the \n    optimal discounted reward.\n    \"\"\"", "\n", "assert", "(", "problem", "[", "'params'", "]", "[", "'reward_vec'", "]", ".", "value", ".", "shape", "==", "reward_vec", ".", "shape", ")", "\n", "problem", "[", "'params'", "]", "[", "'reward_vec'", "]", ".", "value", "=", "reward_vec", "\n", "return", "problem", "[", "'problem'", "]", ".", "solve", "(", "verbose", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.state_act_feature_count_difference": [[96, 124], ["numpy.zeros", "opt_state_act_vars.keys"], "function", ["None"], ["", "def", "state_act_feature_count_difference", "(", "demo_feature_count", ":", "np", ".", "ndarray", ",", "\n", "opt_state_act_vars", ":", "dict", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Compute the difference between the optimal state-action discounted feature \n    counts obtained from the last optimization solve, and the empirical feature\n    counts obtained empirically.\n\n    Parameters\n    ----------\n    demo_feature_count :\n        The empirical features counts measured from demonstration.\n        demo_feature_count[s,a] returns the occupancy measure for action \"a\"\n        taken from state \"s\".\n    opt_state_act_vars : \n        The feature counts from the last optimization problem solve.\n        opt_state_act_vars[(s,a)].value returns the occupancy measure value\n        for action \"a\" taken from state \"s\".\n\n    Returns\n    -------\n    diff :\n        An array with shape (N_S, N_A) representing the difference in the \n        feature count values.\n    \"\"\"", "\n", "diff", "=", "np", ".", "zeros", "(", "demo_feature_count", ".", "shape", ")", "\n", "for", "(", "s", ",", "a", ")", "in", "opt_state_act_vars", ".", "keys", "(", ")", ":", "\n", "        ", "diff", "[", "s", ",", "a", "]", "=", "opt_state_act_vars", "[", "(", "s", ",", "a", ")", "]", ".", "value", "-", "demo_feature_count", "[", "s", ",", "a", "]", "\n", "", "return", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.optimization_problems.high_level_irl_opt.construct_optimistic_irl_forward_pass": [[130, 206], ["dict", "dict", "mdp.avail_actions.copy", "cvxpy.Parameter", "cvxpy.Maximize", "cvxpy.Problem", "cvxpy.Variable", "cons.append", "cvxpy.Variable", "numpy.zeros", "cvxpy.sum", "cons.append", "cvxpy.rel_entr", "str", "str", "str"], "function", ["None"], ["", "def", "construct_optimistic_irl_forward_pass", "(", "mdp", ")", ":", "\n", "#dictionary for state occupancy and state action occupancy", "\n", "    ", "state_vars", "=", "dict", "(", ")", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "mdp", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "state_vars", "[", "s", "]", "=", "cp", ".", "Variable", "(", "name", "=", "\"state_\"", "+", "str", "(", "s", ")", ",", "nonneg", "=", "True", ")", "\n", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "            ", "state_act_vars", "[", "(", "s", ",", "a", ")", "]", "=", "cp", ".", "Variable", "(", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ",", "\n", "nonneg", "=", "True", ")", "\n", "\n", "", "", "vars", "=", "{", "\n", "'state_act_vars'", ":", "state_act_vars", ",", "\n", "'state_vars'", ":", "state_vars", "\n", "}", "\n", "\n", "# Create problem parameters", "\n", "reward_vec", "=", "cp", ".", "Parameter", "(", "shape", "=", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ",", "\n", "name", "=", "'reward_vec'", ",", "\n", "value", "=", "np", ".", "zeros", "(", "(", "mdp", ".", "N_S", ",", "mdp", ".", "N_A", ")", ")", ")", "\n", "params", "=", "{", "\n", "'reward_vec'", ":", "reward_vec", "\n", "}", "\n", "\n", "###### define the problem constraints", "\n", "cons", "=", "[", "]", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "cons_sum", "=", "0", "\n", "\n", "cons_sum", "+=", "state_vars", "[", "s", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "for", "s_bar", ",", "a_bar", "in", "mdp", ".", "predecessors", "[", "s", "]", ":", "\n", "# #this if clause ensures that you dont double count reaching goal and failure", "\n", "# if not s_bar == mdp.s_g and not s_bar == mdp.s_fail:", "\n", "            ", "cons_sum", "-=", "mdp", ".", "discount", "*", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "1.0", "#mdp.P[s_bar, a_bar, s]", "\n", "#initial state occupancy", "\n", "", "if", "s", "==", "mdp", ".", "s_i", ":", "\n", "            ", "cons_sum", "=", "cons_sum", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "cons", ".", "append", "(", "cons_sum", "==", "0", ")", "\n", "\n", "# Define relation between state-action occupancy measures ", "\n", "# and state occupancy measures", "\n", "", "for", "s", "in", "mdp", ".", "S", ":", "\n", "# Only enforce the following constraint if outgoing actions are available.", "\n", "        ", "if", "avail_actions", "[", "s", "]", ":", "\n", "            ", "cons_sum", "=", "cp", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", "for", "a", "in", "avail_actions", "[", "s", "]", "]", ")", "\n", "cons", ".", "append", "(", "state_vars", "[", "s", "]", "==", "cons_sum", ")", "\n", "\n", "# set up the objective", "\n", "", "", "obj_sum", "=", "0", "\n", "\n", "for", "s", "in", "mdp", ".", "S", ":", "\n", "        ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "            ", "obj_sum", "-=", "cp", ".", "rel_entr", "(", "state_act_vars", "[", "s", ",", "a", "]", ",", "state_vars", "[", "s", "]", ")", "\n", "obj_sum", "+=", "reward_vec", "[", "s", ",", "a", "]", "*", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "", "", "obj", "=", "cp", ".", "Maximize", "(", "obj_sum", ")", "\n", "\n", "prob", "=", "cp", ".", "Problem", "(", "objective", "=", "obj", ",", "constraints", "=", "cons", ")", "\n", "\n", "forward_problem", "=", "{", "\n", "'problem'", ":", "prob", ",", "\n", "'vars'", ":", "vars", ",", "\n", "'params'", ":", "params", "\n", "}", "\n", "\n", "return", "forward_problem", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.__init__": [[23, 65], ["MiniGridEnv.__init__", "spaces.Discrete", "spaces.Box", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.__init__"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "agent_start_states", "=", "[", "(", "1", ",", "1", ",", "0", ")", "]", ",", "\n", "slip_p", "=", "0.0", ",", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        agent_start_states : list\n            List of tuples representing the possible initial states \n            (entry conditions) of the agent in the environment.\n        slip_p : float\n            Probability with which the agent \"slips\" on any given action,\n            and takes another action instead.\n        \"\"\"", "\n", "\n", "size", "=", "20", "\n", "width", "=", "size", "\n", "height", "=", "size", "\n", "\n", "self", ".", "agent_start_states", "=", "agent_start_states", "\n", "self", ".", "goal_states", "=", "[", "(", "1", ",", "height", "-", "2", ",", "0", ")", ",", "(", "1", ",", "height", "-", "2", ",", "1", ")", ",", "(", "1", ",", "height", "-", "2", ",", "2", ")", ",", "(", "1", ",", "height", "-", "2", ",", "3", ")", "]", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "grid_size", "=", "size", ",", "\n", "max_steps", "=", "4", "*", "size", "*", "size", ",", "\n", ")", "\n", "\n", "# Action enumeration for this environment", "\n", "self", ".", "actions", "=", "Maze", ".", "Actions", "\n", "\n", "# Actions are discrete integer values", "\n", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "len", "(", "self", ".", "actions", ")", ")", "\n", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", "]", ")", ",", "\n", "high", "=", "np", ".", "array", "(", "[", "self", ".", "width", ",", "self", ".", "height", ",", "3", "]", ")", ",", "\n", "dtype", "=", "'uint8'", "\n", ")", "\n", "\n", "self", ".", "slip_p", "=", "slip_p", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze._gen_grid": [[66, 110], ["Grid", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.grid.wall_rect", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.grid.horz_wall", "minigrid_labyrinth.Maze.grid.horz_wall", "minigrid_labyrinth.Maze.grid.horz_wall", "minigrid_labyrinth.Maze.grid.horz_wall", "Door", "Door", "Door", "Door", "Door", "Door", "Door", "minigrid_labyrinth.Maze.put_obj", "minigrid_labyrinth.Maze.place_agent", "Goal", "numpy.random.choice", "len"], "methods", ["None"], ["", "def", "_gen_grid", "(", "self", ",", "width", ",", "height", ")", ":", "\n", "# Create an empty grid", "\n", "        ", "self", ".", "grid", "=", "Grid", "(", "width", ",", "height", ")", "\n", "\n", "# Generate the surrounding walls", "\n", "self", ".", "grid", ".", "wall_rect", "(", "0", ",", "0", ",", "width", ",", "height", ")", "\n", "\n", "# Generate the rooms", "\n", "self", ".", "grid", ".", "wall_rect", "(", "0", ",", "0", ",", "6", ",", "6", ")", "\n", "self", ".", "grid", ".", "wall_rect", "(", "5", ",", "0", ",", "15", ",", "6", ")", "\n", "self", ".", "grid", ".", "wall_rect", "(", "8", ",", "5", ",", "6", ",", "11", ")", "\n", "self", ".", "grid", ".", "wall_rect", "(", "13", ",", "5", ",", "7", ",", "11", ")", "\n", "self", ".", "grid", ".", "wall_rect", "(", "0", ",", "5", ",", "9", ",", "6", ")", "\n", "self", ".", "grid", ".", "wall_rect", "(", "0", ",", "10", ",", "9", ",", "6", ")", "\n", "\n", "# Add doors", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "3", ",", "5", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "5", ",", "2", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "10", ",", "5", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "14", ",", "5", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "5", ",", "10", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "3", ",", "15", ")", "\n", "self", ".", "put_obj", "(", "Door", "(", "'grey'", ",", "is_open", "=", "True", ")", ",", "16", ",", "15", ")", "\n", "\n", "# Place a goal square", "\n", "for", "goal_state", "in", "self", ".", "goal_states", ":", "\n", "            ", "self", ".", "put_obj", "(", "Goal", "(", ")", ",", "goal_state", "[", "0", "]", ",", "goal_state", "[", "1", "]", ")", "\n", "\n", "# Place dangerous lava", "\n", "", "self", ".", "grid", ".", "horz_wall", "(", "2", ",", "7", ",", "3", ",", "obj_type", "=", "Lava", ")", "\n", "self", ".", "grid", ".", "horz_wall", "(", "6", ",", "8", ",", "2", ",", "obj_type", "=", "Lava", ")", "\n", "self", ".", "grid", ".", "horz_wall", "(", "3", ",", "12", ",", "2", ",", "obj_type", "=", "Lava", ")", "\n", "self", ".", "grid", ".", "horz_wall", "(", "6", ",", "14", ",", "2", ",", "obj_type", "=", "Lava", ")", "\n", "\n", "# Place the agent", "\n", "if", "self", ".", "agent_start_states", ":", "\n", "# Uniformly pick from the possible start states", "\n", "            ", "agent_start_state", "=", "self", ".", "agent_start_states", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "agent_start_states", ")", ")", "]", "\n", "self", ".", "agent_pos", "=", "(", "agent_start_state", "[", "0", "]", ",", "agent_start_state", "[", "1", "]", ")", "\n", "self", ".", "agent_dir", "=", "agent_start_state", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "place_agent", "(", ")", "\n", "\n", "", "self", ".", "mission", "=", "\"get to the goal square\"", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.gen_obs": [[111, 119], ["numpy.array"], "methods", ["None"], ["", "def", "gen_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate the observation of the agent, which in this environment, is its state.\n        \"\"\"", "\n", "pos", "=", "self", ".", "agent_pos", "\n", "direction", "=", "self", ".", "agent_dir", "\n", "obs_out", "=", "np", ".", "array", "(", "[", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", ",", "direction", "]", ")", "\n", "return", "obs_out", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.step": [[120, 208], ["minigrid_labyrinth.Maze.grid.get", "minigrid_labyrinth.Maze.grid.get", "minigrid_labyrinth.Maze.gen_obs", "numpy.random.rand", "numpy.random.choice", "numpy.array", "minigrid_labyrinth.Maze.can_overlap", "numpy.array", "minigrid_labyrinth.Maze.can_pickup", "numpy.array", "minigrid_labyrinth.Maze.grid.set", "minigrid_labyrinth.Maze.grid.set", "minigrid_labyrinth.Maze.toggle"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.gen_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"\n        Step the environment.\n        \"\"\"", "\n", "self", ".", "step_count", "+=", "1", "\n", "\n", "reward", "=", "0", "\n", "done", "=", "False", "\n", "\n", "info", "=", "{", "\n", "'task_complete'", ":", "False", ",", "\n", "'lava'", ":", "False", "\n", "}", "\n", "\n", "# Slip probability causes agent to randomly take the wrong action", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", "<=", "self", ".", "slip_p", ":", "\n", "            ", "action", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", "]", ")", ")", "\n", "\n", "", "current_pos", "=", "self", ".", "agent_pos", "\n", "current_cell", "=", "self", ".", "grid", ".", "get", "(", "*", "current_pos", ")", "\n", "if", "current_cell", "!=", "None", "and", "current_cell", ".", "type", "==", "'lava'", ":", "\n", "# If the agent is in lava, it can no longer do anything", "\n", "            ", "action", "=", "self", ".", "actions", ".", "done", "\n", "\n", "# Get the position in front of the agent", "\n", "", "fwd_pos", "=", "self", ".", "front_pos", "\n", "\n", "# Get the contents of the cell in front of the agent", "\n", "fwd_cell", "=", "self", ".", "grid", ".", "get", "(", "*", "fwd_pos", ")", "\n", "\n", "# Rotate left", "\n", "if", "action", "==", "self", ".", "actions", ".", "left", ":", "\n", "            ", "self", ".", "agent_dir", "-=", "1", "\n", "if", "self", ".", "agent_dir", "<", "0", ":", "\n", "                ", "self", ".", "agent_dir", "+=", "4", "\n", "\n", "# Rotate right", "\n", "", "", "elif", "action", "==", "self", ".", "actions", ".", "right", ":", "\n", "            ", "self", ".", "agent_dir", "=", "(", "self", ".", "agent_dir", "+", "1", ")", "%", "4", "\n", "\n", "# Move forward", "\n", "", "elif", "action", "==", "self", ".", "actions", ".", "forward", ":", "\n", "            ", "if", "fwd_cell", "==", "None", "or", "fwd_cell", ".", "can_overlap", "(", ")", ":", "\n", "                ", "self", ".", "agent_pos", "=", "fwd_pos", "\n", "", "if", "fwd_cell", "!=", "None", "and", "fwd_cell", ".", "type", "==", "'lava'", ":", "\n", "                ", "done", "=", "True", "\n", "max_distance", "=", "np", ".", "array", "(", "[", "self", ".", "width", ",", "self", ".", "height", "]", ")", "\n", "info", "[", "'lava'", "]", "=", "True", "\n", "\n", "# Pick up an object", "\n", "", "", "elif", "action", "==", "self", ".", "actions", ".", "pickup", ":", "\n", "            ", "if", "fwd_cell", "and", "fwd_cell", ".", "can_pickup", "(", ")", ":", "\n", "                ", "if", "self", ".", "carrying", "is", "None", ":", "\n", "                    ", "self", ".", "carrying", "=", "fwd_cell", "\n", "self", ".", "carrying", ".", "cur_pos", "=", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "self", ".", "grid", ".", "set", "(", "*", "fwd_pos", ",", "None", ")", "\n", "\n", "# Drop an object", "\n", "", "", "", "elif", "action", "==", "self", ".", "actions", ".", "drop", ":", "\n", "            ", "if", "not", "fwd_cell", "and", "self", ".", "carrying", ":", "\n", "                ", "self", ".", "grid", ".", "set", "(", "*", "fwd_pos", ",", "self", ".", "carrying", ")", "\n", "self", ".", "carrying", ".", "cur_pos", "=", "fwd_pos", "\n", "self", ".", "carrying", "=", "None", "\n", "\n", "# Toggle/activate an object", "\n", "", "", "elif", "action", "==", "self", ".", "actions", ".", "toggle", ":", "\n", "            ", "if", "fwd_cell", ":", "\n", "                ", "fwd_cell", ".", "toggle", "(", "self", ",", "fwd_pos", ")", "\n", "\n", "# Done action (not used by default)", "\n", "", "", "elif", "action", "==", "self", ".", "actions", ".", "done", ":", "\n", "            ", "pass", "\n", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"unknown action\"", "\n", "\n", "", "next_state", "=", "(", "self", ".", "agent_pos", "[", "0", "]", ",", "self", ".", "agent_pos", "[", "1", "]", ",", "self", ".", "agent_dir", ")", "\n", "if", "next_state", "in", "self", ".", "goal_states", ":", "\n", "            ", "info", "[", "'task_complete'", "]", "=", "True", "\n", "done", "=", "True", "\n", "reward", "=", "1.0", "\n", "\n", "", "if", "self", ".", "step_count", ">=", "self", ".", "max_steps", ":", "\n", "            ", "done", "=", "True", "\n", "\n", "", "obs", "=", "self", ".", "gen_obs", "(", ")", "\n", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.minigrid_labyrinth.Maze.get_num_states": [[209, 211], ["None"], "methods", ["None"], ["", "def", "get_num_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "width", "*", "self", ".", "height", "*", "4", "# position in the gridworld and also facing direction", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.__init__": [[33, 36], ["mlagents_envs.side_channel.side_channel.SideChannel.__init__", "uuid.UUID"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.__init__"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "uuid", ".", "UUID", "(", "\"621f0a70-4f87-11ea-a6bf-784f4387d1f7\"", ")", ")", "\n", "self", ".", "_observers", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.on_message_received": [[37, 46], ["msg.read_string", "obs.notify"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.unity_meta_controller.MetaController.notify"], ["", "def", "on_message_received", "(", "self", ",", "msg", ":", "IncomingMessage", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Note: We must implement this method of the SideChannel interface to\n        receive messages from Unity\n        \"\"\"", "\n", "message_string", "=", "msg", ".", "read_string", "(", ")", "\n", "# Pass the message on to all subscribed observers", "\n", "for", "obs", "in", "self", ".", "_observers", ":", "\n", "            ", "obs", ".", "notify", "(", "self", ",", "message_string", ")", "\n", "# # We simply read a string from the message and print it.", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.send_string": [[49, 55], ["mlagents_envs.side_channel.side_channel.OutgoingMessage", "mlagents_envs.side_channel.side_channel.OutgoingMessage.write_string", "super().queue_message_to_send"], "methods", ["None"], ["", "", "def", "send_string", "(", "self", ",", "data", ":", "str", ")", "->", "None", ":", "\n", "# Add the string to an OutgoingMessage", "\n", "        ", "msg", "=", "OutgoingMessage", "(", ")", "\n", "msg", ".", "write_string", "(", "data", ")", "\n", "# We call this method to queue the data we want to send", "\n", "super", "(", ")", ".", "queue_message_to_send", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.subscribe": [[56, 58], ["unity_labyrinth.CustomSideChannel._observers.append"], "methods", ["None"], ["", "def", "subscribe", "(", "self", ",", "observer", ")", ":", "\n", "        ", "self", ".", "_observers", ".", "append", "(", "observer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.CustomSideChannel.unsubscribe": [[59, 61], ["unity_labyrinth.CustomSideChannel._observers.remove"], "methods", ["None"], ["", "def", "unsubscribe", "(", "self", ",", "observer", ")", ":", "\n", "        ", "self", ".", "_observers", ".", "remove", "(", "observer", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Environments.unity_labyrinth.build_unity_labyrinth_env": [[13, 29], ["mlagents_envs.side_channel.engine_configuration_channel.EngineConfigurationChannel", "unity_labyrinth.CustomSideChannel", "mlagents_envs.environment.UnityEnvironment", "gym_unity.envs.UnityToGymWrapper"], "function", ["None"], ["def", "build_unity_labyrinth_env", "(", ")", ":", "\n", "    ", "\"\"\"\n    Method to construct the unity environment and set up the necessary\n    information channels.\n    \"\"\"", "\n", "engine_config_channel", "=", "EngineConfigurationChannel", "(", ")", "\n", "custom_side_channel", "=", "CustomSideChannel", "(", ")", "\n", "side_channels", "=", "{", "\n", "'engine_config_channel'", ":", "engine_config_channel", ",", "\n", "'custom_side_channel'", ":", "custom_side_channel", ",", "\n", "}", "\n", "unity_env", "=", "UnityEnvironment", "(", "side_channels", "=", "[", "engine_config_channel", ",", "\n", "custom_side_channel", "]", ")", "\n", "\n", "env", "=", "UnityToGymWrapper", "(", "unity_env", ")", "\n", "return", "env", ",", "side_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.plotting.plot_irl_results.plot_irl_summary": [[4, 45], ["matplotlib.figure", "numpy.arange", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.grid", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.grid", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.grid", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.grid", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.grid", "plt.figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.grid", "matplotlib.show", "len", "numpy.linalg.norm", "diff.flatten", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["def", "plot_irl_summary", "(", "irl_results", ",", "fontsize", "=", "15", ")", ":", "\n", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "\n", "gd_iterations", "=", "np", ".", "arange", "(", "len", "(", "irl_results", "[", "'opt_val_list'", "]", ")", ")", "\n", "\n", "# Plot the optimal forward value as a function of iterations.", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "231", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "irl_results", "[", "'opt_val_list'", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "set_xlabel", "(", "'Gradient Descent Iterations'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "set_ylabel", "(", "'Forward problem value'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "232", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "irl_results", "[", "'irl_objective_list'", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "set_xlabel", "(", "'Gradient Descent Iterations'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "set_ylabel", "(", "'IRL objective value'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "233", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "np", ".", "linalg", ".", "norm", "(", "diff", ".", "flatten", "(", ")", ")", "for", "diff", "in", "irl_results", "[", "'grad_list'", "]", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "set_xlabel", "(", "'Gradient Descent Iterations'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "set_ylabel", "(", "'Feature count mismatch'", ",", "fontsize", "=", "fontsize", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "234", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'feature_counts'", "]", "[", "0", ",", "1", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'--'", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'state_act_vars_list'", "]", "[", "i", "]", "[", "(", "0", ",", "1", ")", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "235", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'feature_counts'", "]", "[", "3", ",", "6", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'--'", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'state_act_vars_list'", "]", "[", "i", "]", "[", "(", "3", ",", "6", ")", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "236", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'feature_counts'", "]", "[", "4", ",", "7", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'--'", ")", "\n", "ax", ".", "plot", "(", "gd_iterations", ",", "[", "irl_results", "[", "'state_act_vars_list'", "]", "[", "i", "]", "[", "(", "4", ",", "7", ")", "]", "for", "i", "in", "range", "(", "len", "(", "gd_iterations", ")", ")", "]", ",", "linewidth", "=", "3", ")", "\n", "ax", ".", "grid", "(", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.__init__": [[9, 59], ["len", "len", "general_high_level_mdp.HLMDP._construct_avail_actions", "general_high_level_mdp.HLMDP._construct_avail_states", "numpy.zeros", "general_high_level_mdp.HLMDP._construct_transition_function", "general_high_level_mdp.HLMDP._construct_predecessor_map"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_avail_actions", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP._construct_avail_states", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_transition_function", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_predecessor_map"], ["def", "__init__", "(", "self", ",", "S", ",", "A", ",", "s_i", ",", "s_g", ",", "s_fail", ",", "\n", "controller_list", ",", "successor_map", ",", "discount", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        S : numpy array\n            State space of the high-level MDP.\n        A : numpy array\n            Action space of the high-level MDP.\n        s_i : int\n            Integer representation of the initial state in the high-level MDP.\n        s_g : int\n            Integer representation of the goal state in the high-level MDP.\n        s_fail : int\n            Integer representation of the abstract high-level failure state.\n        controller_list : list\n            List of MinigridController objects (the sub-systems being used as \n            components of the overall RL system).\n        successor_map : dict\n            Dictionary mapping high-level state-action pairs to the next\n            high-level state. \n        discount : float\n            The discount factor for the MDP.\n        \"\"\"", "\n", "self", ".", "controller_list", "=", "controller_list", "\n", "\n", "self", ".", "state_list", "=", "[", "]", "\n", "self", ".", "S", "=", "S", "\n", "self", ".", "A", "=", "A", "\n", "self", ".", "s_i", "=", "s_i", "\n", "self", ".", "s_g", "=", "s_g", "\n", "self", ".", "s_fail", "=", "s_fail", "\n", "self", ".", "discount", "=", "discount", "\n", "\n", "self", ".", "successor", "=", "successor_map", "\n", "\n", "self", ".", "N_S", "=", "len", "(", "self", ".", "S", ")", "# Number of states in the high-level MDP", "\n", "self", ".", "N_A", "=", "len", "(", "self", ".", "A", ")", "# Number of actions in the high-level MDP", "\n", "\n", "self", ".", "avail_actions", "=", "{", "}", "\n", "self", ".", "_construct_avail_actions", "(", ")", "\n", "self", ".", "avail_states", "=", "{", "}", "\n", "self", ".", "_construct_avail_states", "(", ")", "\n", "\n", "self", ".", "P", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ",", "self", ".", "N_S", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "_construct_transition_function", "(", ")", "\n", "\n", "# Using the successor map, construct a predecessor map.", "\n", "self", ".", "predecessors", "=", "{", "}", "\n", "self", ".", "_construct_predecessor_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.update_transition_function": [[60, 67], ["numpy.zeros", "general_high_level_mdp.HLMDP._construct_transition_function"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_transition_function"], ["", "def", "update_transition_function", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Re-construct the transition function to reflect any changes in the empirical \n        measurements of how likely each controller is to succeed.\n        \"\"\"", "\n", "self", ".", "P", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ",", "self", ".", "N_S", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "_construct_transition_function", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP._construct_avail_actions": [[85, 93], ["range", "general_high_level_mdp.HLMDP.successor.keys", "general_high_level_mdp.HLMDP.avail_actions[].append"], "methods", ["None"], ["", "def", "_construct_avail_actions", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "self", ".", "avail_actions", "[", "s", "]", "=", "[", "]", "\n", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "range", "(", "self", ".", "N_A", ")", ":", "\n", "                ", "if", "(", "s", ",", "a", ")", "in", "self", ".", "successor", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "avail_actions", "[", "s", "]", ".", "append", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP._construct_avail_states": [[101, 109], ["general_high_level_mdp.HLMDP.avail_states[].append"], "methods", ["None"], ["", "", "", "", "def", "_construct_avail_states", "(", "self", ")", ":", "\n", "        ", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "self", ".", "avail_states", "[", "a", "]", "=", "[", "]", "\n", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "avail_actions", "=", "self", ".", "avail_actions", "[", "s", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "                ", "self", ".", "avail_states", "[", "action", "]", ".", "append", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP._construct_transition_function": [[110, 118], ["general_high_level_mdp.HLMDP.controller_list[].get_success_prob"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob"], ["", "", "", "def", "_construct_transition_function", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "action", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "success_prob", "=", "self", ".", "controller_list", "[", "action", "]", ".", "get_success_prob", "(", ")", "\n", "next_s", "=", "self", ".", "successor", "[", "(", "s", ",", "action", ")", "]", "\n", "\n", "self", ".", "P", "[", "s", ",", "action", ",", "next_s", "]", "=", "success_prob", "\n", "self", ".", "P", "[", "s", ",", "action", ",", "self", ".", "s_fail", "]", "=", "1", "-", "success_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP._construct_predecessor_map": [[128, 136], ["general_high_level_mdp.HLMDP.predecessors[].append"], "methods", ["None"], ["", "", "", "def", "_construct_predecessor_map", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "self", ".", "predecessors", "[", "s", "]", "=", "[", "]", "\n", "for", "sp", "in", "self", ".", "S", ":", "\n", "                ", "avail_actions", "=", "self", ".", "avail_actions", "[", "sp", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "                    ", "if", "self", ".", "successor", "[", "(", "sp", ",", "action", ")", "]", "==", "s", ":", "\n", "                        ", "self", ".", "predecessors", "[", "s", "]", ".", "append", "(", "(", "sp", ",", "action", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.process_high_level_demonstrations": [[137, 175], ["len", "numpy.zeros", "numpy.zeros", "range", "range", "len"], "methods", ["None"], ["", "", "", "", "", "def", "process_high_level_demonstrations", "(", "self", ",", "demos", ":", "list", ")", "->", "tuple", ":", "\n", "        ", "\"\"\"\n        Process the high-level demonstrations into average expected \n        discounted feature counts. The features currently just correspond\n        to state-action pairs.\n\n        Inputs\n        ------\n        demos :\n            A list of demonstration trajectories. demos[i] is a trajectory\n            and trajectory[t] is a state-action pair represented as a list.\n            stateAction[0] is the state at time t and stateAction[1] is the\n            action.\n\n        Outputs\n        -------\n        state_features_counts : \n            The discounted average feature counts of the demonstrations.\n            feature_counts[i] is the discounted count of state i.\n        state_act_feature_counts :\n            The discounted average feature counts of the demonstrations.\n            feature_counts[i,j] is the count of action j in state i.\n        \"\"\"", "\n", "num_trajectories", "=", "len", "(", "demos", ")", "\n", "state_act_feature_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ")", "\n", "state_feature_counts", "=", "np", ".", "zeros", "(", "self", ".", "N_S", ")", "\n", "for", "i", "in", "range", "(", "num_trajectories", ")", ":", "\n", "            ", "traj", "=", "demos", "[", "i", "]", "\n", "for", "t", "in", "range", "(", "len", "(", "traj", ")", ")", ":", "\n", "                ", "state", ",", "action", "=", "traj", "[", "t", "]", "\n", "state_feature_counts", "[", "state", "]", "=", "state_feature_counts", "[", "state", "]", "+", "self", ".", "discount", "**", "t", "\n", "state_act_feature_counts", "[", "state", ",", "action", "]", "=", "state_act_feature_counts", "[", "state", ",", "action", "]", "+", "self", ".", "discount", "**", "t", "\n", "", "", "state_act_feature_counts", "=", "state_act_feature_counts", "/", "num_trajectories", "\n", "state_feature_counts", "=", "state_feature_counts", "/", "num_trajectories", "\n", "\n", "return", "state_feature_counts", ",", "state_act_feature_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.solve_feasible_policy": [[176, 276], ["general_high_level_mdp.HLMDP.update_transition_function", "gurobipy.Model", "dict", "general_high_level_mdp.HLMDP.avail_actions.copy", "gurobipy.Model.update", "gurobipy.Model.setObjective", "gurobipy.Model.optimize", "RuntimeError", "gurobipy.Model.addConstr", "numpy.zeros", "gurobipy.Model.addVar", "gurobipy.Model.addConstr", "numpy.ones", "len", "numpy.sum", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.update_transition_function"], ["", "def", "solve_feasible_policy", "(", "self", ",", "prob_threshold", ")", ":", "\n", "        ", "\"\"\"\n        If a meta-policy exists that reaches the goal state from the target \n        state with probability above the specified threshold, return it.\n\n        Inputs\n        ------\n        prob_threshold : float\n            Value between 0 and 1 that represents the desired probability of \n            reaching the goal.\n\n        Outputs\n        -------\n        policy : numpy (N_S, N_A) array\n            Array representing the solution policy. If there is no feasible \n            solution, an array of -1 is returned.\n        feasible_flag : bool\n            Flag indicating whether or not a feasible solution was found.\n        \"\"\"", "\n", "self", ".", "update_transition_function", "(", ")", "\n", "\n", "if", "prob_threshold", ">", "1", "or", "prob_threshold", "<", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"prob threshold is not a probability\"", ")", "\n", "\n", "#initialize gurobi model", "\n", "", "linear_model", "=", "gb", ".", "Model", "(", "\"abs_mdp_linear\"", ")", "\n", "\n", "#dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "self", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#dummy action for goal state", "\n", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "linear_model", ".", "addVar", "(", "lb", "=", "0", ",", "\n", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "#gurobi updates model", "\n", "", "", "linear_model", ".", "update", "(", ")", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "#add outgoing occupancy for available actions", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "#this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "self", ".", "P", "[", "s_bar", ",", "a_bar", ",", "s", "]", "\n", "#initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "linear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# prob threshold constraint", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "if", "s", "==", "self", ".", "s_g", ":", "\n", "                ", "linear_model", ".", "addConstr", "(", "state_act_vars", "[", "s", ",", "0", "]", ">=", "prob_threshold", ")", "\n", "\n", "# set up the objective", "\n", "", "", "obj", "=", "0", "\n", "\n", "#set the objective, solve the problem", "\n", "linear_model", ".", "setObjective", "(", "obj", ",", "gb", ".", "GRB", ".", "MINIMIZE", ")", "\n", "linear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "linear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "if", "feasible_flag", ":", "\n", "# Construct the policy from the occupancy variables", "\n", "            ", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to ", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "return", "policy", ",", "feasible_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.solve_max_reach_prob_policy": [[277, 366], ["general_high_level_mdp.HLMDP.update_transition_function", "gurobipy.Model", "dict", "general_high_level_mdp.HLMDP.avail_actions.copy", "gurobipy.Model.update", "gurobipy.Model.setObjective", "gurobipy.Model.optimize", "gurobipy.Model.addConstr", "numpy.zeros", "gurobipy.Model.addVar", "numpy.ones", "len", "numpy.sum", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.update_transition_function"], ["", "def", "solve_max_reach_prob_policy", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Find the meta-policy that maximizes probability of reaching the goal state.\n\n        Outputs\n        -------\n        policy : numpy (N_S, N_A) array\n            Array representing the solution policy. If there is no feasible solution, an array of\n            -1 is returned.\n        reach_prob : float\n            The probability of reaching the goal state under the policy.\n        feasible_flag : bool\n            Flag indicating whether or not a feasible solution was found.\n        \"\"\"", "\n", "self", ".", "update_transition_function", "(", ")", "\n", "\n", "#initialize gurobi model", "\n", "linear_model", "=", "gb", ".", "Model", "(", "\"abs_mdp_linear\"", ")", "\n", "\n", "#dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "self", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#dummy action for goal state", "\n", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "linear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "#gurobi updates model", "\n", "", "", "linear_model", ".", "update", "(", ")", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "#add outgoing occupancy for available actions", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "#this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "self", ".", "P", "[", "s_bar", ",", "a_bar", ",", "s", "]", "\n", "#initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "linear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# set up the objective", "\n", "", "obj", "=", "0", "\n", "obj", "+=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", "# Probability of reaching goal state", "\n", "\n", "#set the objective, solve the problem", "\n", "linear_model", ".", "setObjective", "(", "obj", ",", "gb", ".", "GRB", ".", "MAXIMIZE", ")", "\n", "linear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "linear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "if", "feasible_flag", ":", "\n", "# Construct the policy from the occupancy variables", "\n", "            ", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to ", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "reach_prob", "=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", ".", "x", "\n", "\n", "return", "policy", ",", "reach_prob", ",", "feasible_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.general_high_level_mdp.HLMDP.solve_low_level_requirements_action": [[367, 548], ["gurobipy.Model", "dict", "dict", "dict", "dict", "gurobipy.Model.update", "print", "gurobipy.Model.setObjective", "gurobipy.Model.optimize", "general_high_level_mdp.HLMDP.avail_actions[].remove", "RuntimeError", "gurobipy.Model.addVar", "gurobipy.Model.addVar", "gurobipy.Model.addVar", "gurobipy.Model.addConstr", "numpy.copy", "gurobipy.Model.addConstr", "gurobipy.Model.addConstr", "numpy.zeros", "gurobipy.Model.addVar", "gurobipy.Model.addConstr", "general_high_level_mdp.HLMDP.controller_list[].get_success_prob", "print", "numpy.max", "numpy.ones", "numpy.copy", "print", "gurobipy.Model.addConstr", "required_success_probs.keys", "required_success_probs[].append", "len", "numpy.sum", "str", "str", "str", "general_high_level_mdp.HLMDP.controller_list[].get_success_prob", "general_high_level_mdp.HLMDP.controller_list[].get_success_prob", "numpy.copy", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob"], ["", "def", "solve_low_level_requirements_action", "(", "self", ",", "prob_threshold", ",", "max_timesteps_per_component", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Find new transition probabilities guaranteeing that a feasible meta-policy exists.\n\n        Inputs\n        ------\n        prob_threshold : float\n            The required probability of reaching the target set in the HLM.\n        max_timesteps_per_component : int\n            Number of training steps (for an individual sub-system) beyond which its current\n            estimated performance value should be used as an upper bound on the corresponding\n            transition probability in the HLM.\n\n        Outputs\n        -------\n        policy : numpy array\n            The meta-policy satisfying the task specification, under the solution\n            transition probabilities in the HLM.\n            Returns an array of -1 if no feasible solution exists.\n        required_success_probs : list\n            List of the solution transition probabilities in the HLM.\n            Returns a list of -1 if no feasible solution exists.\n        reach_prob : float\n            The HLM predicted probability of reaching the target set under the solution\n            meta-policy and solution transition probabilities in the HLM.\n        feasibility_flag : bool\n            Flag indicating the feasibility of the bilinear program being solved.\n        \"\"\"", "\n", "if", "prob_threshold", ">", "1", "or", "prob_threshold", "<", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"prob threshold is not a probability\"", ")", "\n", "\n", "# initialize gurobi model", "\n", "", "bilinear_model", "=", "gb", ".", "Model", "(", "\"abs_mdp_bilinear\"", ")", "\n", "\n", "# activate gurobi nonconvex", "\n", "bilinear_model", ".", "params", ".", "NonConvex", "=", "2", "\n", "\n", "# dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for MDP prob variables", "\n", "MDP_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for slack variables", "\n", "slack_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for epigraph variables used to define objective", "\n", "MDP_prob_diff_maximizers", "=", "dict", "(", ")", "\n", "\n", "# dummy action for goal state", "\n", "self", ".", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "# create occupancy measures, probability variables and reward variables", "\n", "#for s in self.S:", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "MDP_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"mdp_prob_\"", "+", "str", "(", "a", ")", ")", "\n", "slack_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"slack_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "'mdp_prob_difference_maximizer_'", "+", "str", "(", "a", ")", ")", "\n", "\n", "# #epigraph variable for max probability constraint", "\n", "# prob_maximizer = bilinear_model.addVar(lb=0, name=\"prob_maximizer\")", "\n", "\n", "# gurobi updates model", "\n", "", "bilinear_model", ".", "update", "(", ")", "\n", "\n", "# MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "# add outgoing occupancy for available actions", "\n", "\n", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "# add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "# this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "MDP_prob_vars", "[", "a_bar", "]", "\n", "# initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "# sets occupancy constraints", "\n", "", "bilinear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# prob threshold constraint", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "if", "s", "==", "self", ".", "s_g", ":", "\n", "                ", "bilinear_model", ".", "addConstr", "(", "state_act_vars", "[", "s", ",", "0", "]", ">=", "prob_threshold", ")", "\n", "", "", "print", "(", "\"opt\"", ")", "\n", "\n", "# For each low-level component, add constraints corresponding to", "\n", "# the existing performance.", "\n", "#for s in self.S:", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "existing_success_prob", "=", "np", ".", "copy", "(", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", ">=", "existing_success_prob", ")", "\n", "\n", "# If one of the components exceeds the maximum allowable training steps, upper bound its success probability.", "\n", "", "if", "max_timesteps_per_component", ":", "\n", "            ", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "if", "self", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'total_training_steps'", "]", ">=", "max_timesteps_per_component", ":", "\n", "                    ", "existing_success_prob", "=", "np", ".", "copy", "(", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "print", "(", "'Controller {}, max success prob: {}'", ".", "format", "(", "a", ",", "existing_success_prob", ")", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", "<=", "existing_success_prob", "+", "slack_prob_vars", "[", "a", "]", ")", "\n", "\n", "# set up the objective", "\n", "", "", "", "obj", "=", "0", "\n", "\n", "slack_cons", "=", "1e3", "\n", "# # Minimize the sum of success probability lower bounds", "\n", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "obj", "+=", "MDP_prob_diff_maximizers", "[", "a", "]", "\n", "obj", "+=", "slack_cons", "*", "slack_prob_vars", "[", "a", "]", "\n", "\n", "# Minimize the sum of differences between probability objective and empirical achieved probabilities", "\n", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "bilinear_model", ".", "addConstr", "(", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", ">=", "MDP_prob_vars", "[", "a", "]", "-", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "\n", "# set the objective, solve the problem", "\n", "", "bilinear_model", ".", "setObjective", "(", "obj", ",", "gb", ".", "GRB", ".", "MINIMIZE", ")", "\n", "bilinear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "bilinear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "if", "slack_prob_vars", "[", "a", "]", ".", "x", ">", "1e-6", ":", "\n", "                ", "print", "(", "\"required slack value {} at action: {} \"", ".", "format", "(", "slack_prob_vars", "[", "a", "]", ".", "x", ",", "a", ")", ")", "\n", "\n", "", "", "if", "feasible_flag", ":", "\n", "# Update the requirements for the individual components", "\n", "            ", "required_success_probs", "=", "{", "}", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "if", "a", "not", "in", "required_success_probs", ".", "keys", "(", ")", ":", "\n", "                    ", "required_success_probs", "[", "a", "]", "=", "[", "]", "\n", "required_success_probs", "[", "a", "]", ".", "append", "(", "np", ".", "copy", "(", "MDP_prob_vars", "[", "a", "]", ".", "x", ")", ")", "\n", "", "", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "self", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'required_success_prob'", "]", "=", "np", ".", "max", "(", "required_success_probs", "[", "a", "]", ")", "\n", "\n", "# Create a list of the required success probabilities of each of the components", "\n", "", "required_success_probs", "=", "[", "MDP_prob_vars", "[", "a", "]", ".", "x", "for", "a", "in", "self", ".", "A", "]", "\n", "\n", "# Save the probability of reaching the goal state under the solution", "\n", "reach_prob", "=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", ".", "x", "\n", "\n", "# Construct the policy from the occupancy variables", "\n", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "required_success_probs", "=", "[", "[", "-", "1", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", "for", "s", "in", "self", ".", "S", "]", "\n", "reach_prob", "=", "-", "1", "\n", "\n", "# Remove dummy action from goal state", "\n", "", "self", ".", "avail_actions", "[", "self", ".", "s_g", "]", ".", "remove", "(", "0", ")", "\n", "\n", "return", "policy", ",", "required_success_probs", ",", "reach_prob", ",", "feasible_flag", "", "", "", ""]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.__init__": [[9, 52], ["high_level_mdp.HLMDP._construct_state_space", "numpy.arange", "high_level_mdp.HLMDP._construct_action_space", "high_level_mdp.HLMDP._construct_avail_actions", "len", "len", "numpy.zeros", "high_level_mdp.HLMDP._construct_transition_function", "high_level_mdp.HLMDP._construct_successor_map", "high_level_mdp.HLMDP._construct_predecessor_map", "len"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_state_space", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_action_space", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_avail_actions", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_transition_function", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_successor_map", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_predecessor_map"], ["def", "__init__", "(", "self", ",", "init_states", ",", "goal_states", ",", "controller_list", ")", ":", "\n", "        ", "\"\"\"\n        Inputs\n        ------\n        init_states : list\n            List of tuples representing the possible initial states of the system.\n        goal_states : list\n            List of tuples representing the target goal states of the system.\n        controller_list : list\n            List of MinigridController objects (the sub-systems being used as components \n            of the overall RL system).\n        \"\"\"", "\n", "\n", "self", ".", "init_states", "=", "init_states", "\n", "self", ".", "goal_states", "=", "goal_states", "\n", "self", ".", "controller_list", "=", "controller_list", "\n", "\n", "self", ".", "state_list", "=", "[", "]", "\n", "self", ".", "S", "=", "None", "\n", "self", ".", "s_i", "=", "None", "\n", "self", ".", "s_g", "=", "None", "\n", "self", ".", "s_fail", "=", "None", "\n", "self", ".", "_construct_state_space", "(", ")", "\n", "\n", "self", ".", "avail_actions", "=", "{", "}", "\n", "self", ".", "avail_states", "=", "{", "}", "\n", "self", ".", "A", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "controller_list", ")", ")", "\n", "self", ".", "_construct_action_space", "(", ")", "\n", "\n", "self", ".", "_construct_avail_actions", "(", ")", "\n", "\n", "\n", "self", ".", "N_S", "=", "len", "(", "self", ".", "S", ")", "# Number of states in the high-level MDP", "\n", "self", ".", "N_A", "=", "len", "(", "self", ".", "A", ")", "# Number of actions in the high-level MDP", "\n", "\n", "self", ".", "P", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ",", "self", ".", "N_S", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "_construct_transition_function", "(", ")", "\n", "\n", "self", ".", "successor", "=", "{", "}", "\n", "self", ".", "_construct_successor_map", "(", ")", "\n", "\n", "self", ".", "predecessors", "=", "{", "}", "\n", "self", ".", "_construct_predecessor_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.update_transition_function": [[53, 60], ["numpy.zeros", "high_level_mdp.HLMDP._construct_transition_function"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_transition_function"], ["", "def", "update_transition_function", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Re-construct the transition function to reflect any changes in the empirical \n        measurements of how likely each controller is to succeed.\n        \"\"\"", "\n", "self", ".", "P", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ",", "self", ".", "N_S", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "_construct_transition_function", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_state_space": [[61, 77], ["range", "high_level_mdp.HLMDP.state_list.append", "numpy.arange", "high_level_mdp.HLMDP.state_list.index", "high_level_mdp.HLMDP.state_list.index", "high_level_mdp.HLMDP.state_list.index", "len", "controller.get_init_states", "controller.get_final_states", "len", "high_level_mdp.HLMDP.state_list.append", "high_level_mdp.HLMDP.state_list.append"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_init_states", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_final_states"], ["", "def", "_construct_state_space", "(", "self", ")", ":", "\n", "        ", "for", "controller_ind", "in", "range", "(", "len", "(", "self", ".", "controller_list", ")", ")", ":", "\n", "            ", "controller", "=", "self", ".", "controller_list", "[", "controller_ind", "]", "\n", "controller_init_states", "=", "controller", ".", "get_init_states", "(", ")", "\n", "controller_final_states", "=", "controller", ".", "get_final_states", "(", ")", "\n", "if", "controller_init_states", "not", "in", "self", ".", "state_list", ":", "\n", "                ", "self", ".", "state_list", ".", "append", "(", "controller_init_states", ")", "\n", "", "if", "controller_final_states", "not", "in", "self", ".", "state_list", ":", "\n", "                ", "self", ".", "state_list", ".", "append", "(", "controller_final_states", ")", "\n", "\n", "", "", "self", ".", "state_list", ".", "append", "(", "-", "1", ")", "# Append another state representing the absorbing \"task failed\" state", "\n", "self", ".", "S", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "state_list", ")", ")", "\n", "\n", "self", ".", "s_i", "=", "self", ".", "state_list", ".", "index", "(", "self", ".", "init_states", ")", "\n", "self", ".", "s_g", "=", "self", ".", "state_list", ".", "index", "(", "self", ".", "goal_states", ")", "\n", "self", ".", "s_fail", "=", "self", ".", "state_list", ".", "index", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_action_space": [[78, 87], ["range", "len", "controller.get_init_states", "high_level_mdp.HLMDP.state_list.index", "high_level_mdp.HLMDP.avail_actions[].append"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_init_states"], ["", "def", "_construct_action_space", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "self", ".", "avail_actions", "[", "s", "]", "=", "[", "]", "\n", "\n", "", "for", "controller_ind", "in", "range", "(", "len", "(", "self", ".", "controller_list", ")", ")", ":", "\n", "            ", "controller", "=", "self", ".", "controller_list", "[", "controller_ind", "]", "\n", "controller_init_states", "=", "controller", ".", "get_init_states", "(", ")", "\n", "init_s", "=", "self", ".", "state_list", ".", "index", "(", "controller_init_states", ")", "\n", "self", ".", "avail_actions", "[", "init_s", "]", ".", "append", "(", "controller_ind", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_avail_actions": [[89, 98], ["high_level_mdp.HLMDP.avail_states[].append"], "methods", ["None"], ["", "", "def", "_construct_avail_actions", "(", "self", ")", ":", "\n", "        ", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "self", ".", "avail_states", "[", "a", "]", "=", "[", "]", "\n", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "avail_actions", "=", "self", ".", "avail_actions", "[", "s", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "\n", "                ", "self", ".", "avail_states", "[", "action", "]", ".", "append", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_transition_function": [[99, 109], ["high_level_mdp.HLMDP.controller_list[].get_success_prob", "high_level_mdp.HLMDP.controller_list[].get_final_states", "high_level_mdp.HLMDP.state_list.index"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_final_states"], ["", "", "", "def", "_construct_transition_function", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "avail_actions", "=", "self", ".", "avail_actions", "[", "s", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "                ", "success_prob", "=", "self", ".", "controller_list", "[", "action", "]", ".", "get_success_prob", "(", ")", "\n", "controller_next_states", "=", "self", ".", "controller_list", "[", "action", "]", ".", "get_final_states", "(", ")", "\n", "next_s", "=", "self", ".", "state_list", ".", "index", "(", "controller_next_states", ")", "\n", "\n", "self", ".", "P", "[", "s", ",", "action", ",", "next_s", "]", "=", "success_prob", "\n", "self", ".", "P", "[", "s", ",", "action", ",", "self", ".", "s_fail", "]", "=", "1", "-", "success_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_successor_map": [[110, 118], ["high_level_mdp.HLMDP.controller_list[].get_final_states", "high_level_mdp.HLMDP.state_list.index"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_final_states"], ["", "", "", "def", "_construct_successor_map", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "avail_actions", "=", "self", ".", "avail_actions", "[", "s", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "                ", "controller_next_states", "=", "self", ".", "controller_list", "[", "action", "]", ".", "get_final_states", "(", ")", "\n", "next_s", "=", "self", ".", "state_list", ".", "index", "(", "controller_next_states", ")", "\n", "\n", "self", ".", "successor", "[", "(", "s", ",", "action", ")", "]", "=", "next_s", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP._construct_predecessor_map": [[119, 127], ["high_level_mdp.HLMDP.predecessors[].append"], "methods", ["None"], ["", "", "", "def", "_construct_predecessor_map", "(", "self", ")", ":", "\n", "        ", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "self", ".", "predecessors", "[", "s", "]", "=", "[", "]", "\n", "for", "sp", "in", "self", ".", "S", ":", "\n", "                ", "avail_actions", "=", "self", ".", "avail_actions", "[", "sp", "]", "\n", "for", "action", "in", "avail_actions", ":", "\n", "                    ", "if", "self", ".", "successor", "[", "(", "sp", ",", "action", ")", "]", "==", "s", ":", "\n", "                        ", "self", ".", "predecessors", "[", "s", "]", ".", "append", "(", "(", "sp", ",", "action", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.solve_feasible_policy": [[128, 228], ["high_level_mdp.HLMDP.update_transition_function", "Model", "dict", "high_level_mdp.HLMDP.avail_actions.copy", "Model.update", "Model.setObjective", "Model.optimize", "RuntimeError", "Model.addConstr", "numpy.zeros", "Model.addVar", "Model.addConstr", "numpy.ones", "len", "numpy.sum", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.update_transition_function"], ["", "", "", "", "", "def", "solve_feasible_policy", "(", "self", ",", "prob_threshold", ")", ":", "\n", "        ", "\"\"\"\n        If a meta-policy exists that reaches the goal state from the target \n        state with probability above the specified threshold, return it.\n\n        Inputs\n        ------\n        prob_threshold : float\n            Value between 0 and 1 that represents the desired probability of \n            reaching the goal.\n\n        Outputs\n        -------\n        policy : numpy (N_S, N_A) array\n            Array representing the solution policy. If there is no feasible \n            solution, an array of -1 is returned.\n        feasible_flag : bool\n            Flag indicating whether or not a feasible solution was found.\n        \"\"\"", "\n", "self", ".", "update_transition_function", "(", ")", "\n", "\n", "if", "prob_threshold", ">", "1", "or", "prob_threshold", "<", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"prob threshold is not a probability\"", ")", "\n", "\n", "#initialize gurobi model", "\n", "", "linear_model", "=", "Model", "(", "\"abs_mdp_linear\"", ")", "\n", "\n", "#dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "self", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#dummy action for goal state", "\n", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "linear_model", ".", "addVar", "(", "lb", "=", "0", ",", "\n", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "#gurobi updates model", "\n", "", "", "linear_model", ".", "update", "(", ")", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "#add outgoing occupancy for available actions", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "#this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "self", ".", "P", "[", "s_bar", ",", "a_bar", ",", "s", "]", "\n", "#initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "linear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# prob threshold constraint", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "if", "s", "==", "self", ".", "s_g", ":", "\n", "                ", "linear_model", ".", "addConstr", "(", "state_act_vars", "[", "s", ",", "0", "]", ">=", "prob_threshold", ")", "\n", "\n", "# set up the objective", "\n", "", "", "obj", "=", "0", "\n", "\n", "#set the objective, solve the problem", "\n", "linear_model", ".", "setObjective", "(", "obj", ",", "GRB", ".", "MINIMIZE", ")", "\n", "linear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "linear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "if", "feasible_flag", ":", "\n", "# Construct the policy from the occupancy variables", "\n", "            ", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to ", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "return", "policy", ",", "feasible_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.solve_max_reach_prob_policy": [[229, 318], ["high_level_mdp.HLMDP.update_transition_function", "Model", "dict", "high_level_mdp.HLMDP.avail_actions.copy", "Model.update", "Model.setObjective", "Model.optimize", "Model.addConstr", "numpy.zeros", "Model.addVar", "numpy.ones", "len", "numpy.sum", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.update_transition_function"], ["", "def", "solve_max_reach_prob_policy", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Find the meta-policy that maximizes probability of reaching the goal state.\n\n        Outputs\n        -------\n        policy : numpy (N_S, N_A) array\n            Array representing the solution policy. If there is no feasible solution, an array of\n            -1 is returned.\n        reach_prob : float\n            The probability of reaching the goal state under the policy.\n        feasible_flag : bool\n            Flag indicating whether or not a feasible solution was found.\n        \"\"\"", "\n", "self", ".", "update_transition_function", "(", ")", "\n", "\n", "#initialize gurobi model", "\n", "linear_model", "=", "Model", "(", "\"abs_mdp_linear\"", ")", "\n", "\n", "#dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "avail_actions", "=", "self", ".", "avail_actions", ".", "copy", "(", ")", "\n", "\n", "#dummy action for goal state", "\n", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "#create occupancy measures, probability variables and reward variables", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "linear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "#gurobi updates model", "\n", "", "", "linear_model", ".", "update", "(", ")", "\n", "\n", "#MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "#add outgoing occupancy for available actions", "\n", "for", "a", "in", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "#add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "#this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "self", ".", "P", "[", "s_bar", ",", "a_bar", ",", "s", "]", "\n", "#initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "#sets occupancy constraints", "\n", "", "linear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# set up the objective", "\n", "", "obj", "=", "0", "\n", "obj", "+=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", "# Probability of reaching goal state", "\n", "\n", "#set the objective, solve the problem", "\n", "linear_model", ".", "setObjective", "(", "obj", ",", "GRB", ".", "MAXIMIZE", ")", "\n", "linear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "linear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "if", "feasible_flag", ":", "\n", "# Construct the policy from the occupancy variables", "\n", "            ", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to ", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "", "reach_prob", "=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", ".", "x", "\n", "\n", "return", "policy", ",", "reach_prob", ",", "feasible_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.MDP.high_level_mdp.HLMDP.solve_low_level_requirements_action": [[319, 497], ["Model", "dict", "dict", "dict", "dict", "Model.update", "print", "Model.setObjective", "Model.optimize", "RuntimeError", "Model.addVar", "Model.addVar", "Model.addVar", "Model.addConstr", "numpy.copy", "Model.addConstr", "Model.addConstr", "numpy.zeros", "Model.addVar", "Model.addConstr", "high_level_mdp.HLMDP.controller_list[].get_success_prob", "print", "numpy.max", "numpy.ones", "numpy.copy", "print", "Model.addConstr", "required_success_probs.keys", "required_success_probs[].append", "len", "numpy.sum", "str", "str", "str", "high_level_mdp.HLMDP.controller_list[].get_success_prob", "high_level_mdp.HLMDP.controller_list[].get_success_prob", "numpy.copy", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob", "home.repos.pwc.inspect_result.cyrusneary_verifiable-compositional-rl.Controllers.minigrid_controller.MiniGridController.get_success_prob"], ["", "def", "solve_low_level_requirements_action", "(", "self", ",", "prob_threshold", ",", "max_timesteps_per_component", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Find new transition probabilities guaranteeing that a feasible meta-policy exists.\n\n        Inputs\n        ------\n        prob_threshold : float\n            The required probability of reaching the target set in the HLM.\n        max_timesteps_per_component : int\n            Number of training steps (for an individual sub-system) beyond which its current\n            estimated performance value should be used as an upper bound on the corresponding\n            transition probability in the HLM.\n\n        Outputs\n        -------\n        policy : numpy array\n            The meta-policy satisfying the task specification, under the solution\n            transition probabilities in the HLM.\n            Returns an array of -1 if no feasible solution exists.\n        required_success_probs : list\n            List of the solution transition probabilities in the HLM.\n            Returns a list of -1 if no feasible solution exists.\n        reach_prob : float\n            The HLM predicted probability of reaching the target set under the solution\n            meta-policy and solution transition probabilities in the HLM.\n        feasibility_flag : bool\n            Flag indicating the feasibility of the bilinear program being solved.\n        \"\"\"", "\n", "if", "prob_threshold", ">", "1", "or", "prob_threshold", "<", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"prob threshold is not a probability\"", ")", "\n", "\n", "# initialize gurobi model", "\n", "", "bilinear_model", "=", "Model", "(", "\"abs_mdp_bilinear\"", ")", "\n", "\n", "# activate gurobi nonconvex", "\n", "bilinear_model", ".", "params", ".", "NonConvex", "=", "2", "\n", "\n", "# dictionary for state action occupancy", "\n", "state_act_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for MDP prob variables", "\n", "MDP_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for slack variables", "\n", "slack_prob_vars", "=", "dict", "(", ")", "\n", "\n", "# dictionary for epigraph variables used to define objective", "\n", "MDP_prob_diff_maximizers", "=", "dict", "(", ")", "\n", "\n", "# dummy action for goal state", "\n", "self", ".", "avail_actions", "[", "self", ".", "s_g", "]", "=", "[", "0", "]", "\n", "\n", "# create occupancy measures, probability variables and reward variables", "\n", "#for s in self.S:", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "state_act_vars", "[", "s", ",", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "\"state_act_\"", "+", "str", "(", "s", ")", "+", "\"_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "MDP_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"mdp_prob_\"", "+", "str", "(", "a", ")", ")", "\n", "slack_prob_vars", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "ub", "=", "1", ",", "name", "=", "\"slack_\"", "+", "str", "(", "a", ")", ")", "\n", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", "=", "bilinear_model", ".", "addVar", "(", "lb", "=", "0", ",", "name", "=", "'mdp_prob_difference_maximizer_'", "+", "str", "(", "a", ")", ")", "\n", "\n", "# #epigraph variable for max probability constraint", "\n", "# prob_maximizer = bilinear_model.addVar(lb=0, name=\"prob_maximizer\")", "\n", "\n", "# gurobi updates model", "\n", "", "bilinear_model", ".", "update", "(", ")", "\n", "\n", "# MDP bellman or occupancy constraints for each state", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "cons", "=", "0", "\n", "# add outgoing occupancy for available actions", "\n", "\n", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                ", "cons", "+=", "state_act_vars", "[", "s", ",", "a", "]", "\n", "\n", "# add ingoing occupancy for predecessor state actions", "\n", "", "for", "s_bar", ",", "a_bar", "in", "self", ".", "predecessors", "[", "s", "]", ":", "\n", "# this if clause ensures that you dont double count reaching goal and failure", "\n", "                ", "if", "not", "s_bar", "==", "self", ".", "s_g", "and", "not", "s_bar", "==", "self", ".", "s_fail", ":", "\n", "                    ", "cons", "-=", "state_act_vars", "[", "s_bar", ",", "a_bar", "]", "*", "MDP_prob_vars", "[", "a_bar", "]", "\n", "# initial state occupancy", "\n", "", "", "if", "s", "==", "self", ".", "s_i", ":", "\n", "                ", "cons", "=", "cons", "-", "1", "\n", "\n", "# sets occupancy constraints", "\n", "", "bilinear_model", ".", "addConstr", "(", "cons", "==", "0", ")", "\n", "\n", "# prob threshold constraint", "\n", "", "for", "s", "in", "self", ".", "S", ":", "\n", "            ", "if", "s", "==", "self", ".", "s_g", ":", "\n", "                ", "bilinear_model", ".", "addConstr", "(", "state_act_vars", "[", "s", ",", "0", "]", ">=", "prob_threshold", ")", "\n", "", "", "print", "(", "\"opt\"", ")", "\n", "\n", "# For each low-level component, add constraints corresponding to", "\n", "# the existing performance.", "\n", "#for s in self.S:", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "existing_success_prob", "=", "np", ".", "copy", "(", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", ">=", "existing_success_prob", ")", "\n", "\n", "# If one of the components exceeds the maximum allowable training steps, upper bound its success probability.", "\n", "", "if", "max_timesteps_per_component", ":", "\n", "            ", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "if", "self", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'total_training_steps'", "]", ">=", "max_timesteps_per_component", ":", "\n", "                    ", "existing_success_prob", "=", "np", ".", "copy", "(", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "assert", "(", "existing_success_prob", ">=", "0", "and", "existing_success_prob", "<=", "1", ")", "\n", "print", "(", "'Controller {}, max success prob: {}'", ".", "format", "(", "a", ",", "existing_success_prob", ")", ")", "\n", "bilinear_model", ".", "addConstr", "(", "MDP_prob_vars", "[", "a", "]", "<=", "existing_success_prob", "+", "slack_prob_vars", "[", "a", "]", ")", "\n", "\n", "# set up the objective", "\n", "", "", "", "obj", "=", "0", "\n", "\n", "slack_cons", "=", "1e3", "\n", "# # Minimize the sum of success probability lower bounds", "\n", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "obj", "+=", "MDP_prob_diff_maximizers", "[", "a", "]", "\n", "obj", "+=", "slack_cons", "*", "slack_prob_vars", "[", "a", "]", "\n", "\n", "# Minimize the sum of differences between probability objective and empirical achieved probabilities", "\n", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "bilinear_model", ".", "addConstr", "(", "\n", "MDP_prob_diff_maximizers", "[", "a", "]", ">=", "MDP_prob_vars", "[", "a", "]", "-", "self", ".", "controller_list", "[", "a", "]", ".", "get_success_prob", "(", ")", ")", "\n", "\n", "# set the objective, solve the problem", "\n", "", "bilinear_model", ".", "setObjective", "(", "obj", ",", "GRB", ".", "MINIMIZE", ")", "\n", "bilinear_model", ".", "optimize", "(", ")", "\n", "\n", "if", "bilinear_model", ".", "SolCount", "==", "0", ":", "\n", "            ", "feasible_flag", "=", "False", "\n", "", "else", ":", "\n", "            ", "feasible_flag", "=", "True", "\n", "\n", "", "for", "a", "in", "self", ".", "A", ":", "\n", "            ", "if", "slack_prob_vars", "[", "a", "]", ".", "x", ">", "1e-6", ":", "\n", "                ", "print", "(", "\"required slack value {} at action: {} \"", ".", "format", "(", "slack_prob_vars", "[", "a", "]", ".", "x", ",", "a", ")", ")", "\n", "\n", "", "", "if", "feasible_flag", ":", "\n", "# Update the requirements for the individual components", "\n", "            ", "required_success_probs", "=", "{", "}", "\n", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "if", "a", "not", "in", "required_success_probs", ".", "keys", "(", ")", ":", "\n", "                    ", "required_success_probs", "[", "a", "]", "=", "[", "]", "\n", "required_success_probs", "[", "a", "]", ".", "append", "(", "np", ".", "copy", "(", "MDP_prob_vars", "[", "a", "]", ".", "x", ")", ")", "\n", "", "", "for", "a", "in", "self", ".", "A", ":", "\n", "                ", "self", ".", "controller_list", "[", "a", "]", ".", "data", "[", "'required_success_prob'", "]", "=", "np", ".", "max", "(", "required_success_probs", "[", "a", "]", ")", "\n", "\n", "# Create a list of the required success probabilities of each of the components", "\n", "", "required_success_probs", "=", "[", "MDP_prob_vars", "[", "a", "]", ".", "x", "for", "a", "in", "self", ".", "A", "]", "\n", "\n", "# Save the probability of reaching the goal state under the solution", "\n", "reach_prob", "=", "state_act_vars", "[", "self", ".", "s_g", ",", "0", "]", ".", "x", "\n", "\n", "# Construct the policy from the occupancy variables", "\n", "policy", "=", "np", ".", "zeros", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "s", "in", "self", ".", "S", ":", "\n", "                ", "if", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "==", "0", ":", "\n", "                    ", "policy", "[", "s", ",", ":", "]", "=", "-", "1", "# If no actions are available, return garbage value", "\n", "", "else", ":", "\n", "                    ", "occupancy_state", "=", "np", ".", "sum", "(", "[", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", ")", "\n", "# If the state has no occupancy measure under the solution, set the policy to", "\n", "# be uniform over available actions", "\n", "if", "occupancy_state", "==", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "1", "/", "len", "(", "self", ".", "avail_actions", "[", "s", "]", ")", "\n", "", "", "if", "occupancy_state", ">", "0.0", ":", "\n", "                        ", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", ":", "\n", "                            ", "policy", "[", "s", ",", "a", "]", "=", "state_act_vars", "[", "s", ",", "a", "]", ".", "x", "/", "occupancy_state", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "policy", "=", "-", "1", "*", "np", ".", "ones", "(", "(", "self", ".", "N_S", ",", "self", ".", "N_A", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "required_success_probs", "=", "[", "[", "-", "1", "for", "a", "in", "self", ".", "avail_actions", "[", "s", "]", "]", "for", "s", "in", "self", ".", "S", "]", "\n", "reach_prob", "=", "-", "1", "\n", "\n", "", "return", "policy", ",", "required_success_probs", ",", "reach_prob", ",", "feasible_flag", "", "", "", ""]]}