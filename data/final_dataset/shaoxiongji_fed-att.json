{"home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.DatasetSplitLM.__init__": [[11, 14], ["list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "idxs", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "idxs", "=", "list", "(", "idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.DatasetSplitLM.__len__": [[15, 17], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.DatasetSplitLM.__getitem__": [[18, 20], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "self", ".", "idxs", "[", "item", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.LocalUpdateLM.__init__": [[23, 29], ["torch.nn.NLLLoss", "torch.utils.data.DataLoader", "Update.DatasetSplitLM", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dataset", ",", "idxs", ",", "nround", ",", "user", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "round", "=", "nround", "\n", "self", ".", "user", "=", "user", "\n", "self", ".", "loss_func", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "self", ".", "data_loader", "=", "DataLoader", "(", "DatasetSplitLM", "(", "dataset", ",", "list", "(", "idxs", ")", ")", ",", "batch_size", "=", "self", ".", "args", ".", "local_bs", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.LocalUpdateLM.update_weights": [[30, 57], ["net.cuda.cuda.train", "torch.optim.SGD", "range", "net.cuda.cuda.parameters", "enumerate", "net.cuda.cuda.cpu().state_dict", "net.cuda.cuda.zero_grad", "sents.sort", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pack_sequence", "net.cuda.cuda.", "Update.LocalUpdateLM.loss_func", "Update.LocalUpdateLM.backward", "torch.optim.SGD.step", "list_loss.append", "list_pp.append", "sum", "len", "net.cuda.cuda.cuda", "net.cuda.exp", "prob.log2().neg().mean().item", "Update.LocalUpdateLM.item", "net.cuda.cuda.cpu", "torch.nn.utils.rnn.pack_sequence.cuda", "torch.nn.utils.rnn.pack_sequence.cuda", "len", "torch.arange", "prob.log2().neg().mean", "prob.log2().neg", "prob.log2"], "methods", ["None"], ["", "def", "update_weights", "(", "self", ",", "net", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "# train and update", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "net", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "momentum", "=", "self", ".", "args", ".", "momentum", ")", "\n", "\n", "list_loss", ",", "list_pp", "=", "[", "]", ",", "[", "]", "\n", "for", "iter", "in", "range", "(", "self", ".", "args", ".", "local_ep", ")", ":", "\n", "            ", "for", "batch_ind", ",", "sents", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "                ", "net", ".", "zero_grad", "(", ")", "\n", "sents", ".", "sort", "(", "key", "=", "lambda", "l", ":", "len", "(", "l", ")", ",", "reverse", "=", "True", ")", "\n", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_sequence", "(", "[", "s", "[", ":", "-", "1", "]", "for", "s", "in", "sents", "]", ")", "\n", "y", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_sequence", "(", "[", "s", "[", "1", ":", "]", "for", "s", "in", "sents", "]", ")", "\n", "if", "self", ".", "args", ".", "gpu", "!=", "-", "1", ":", "\n", "                    ", "net", "=", "net", ".", "cuda", "(", ")", "\n", "x", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "", "out", "=", "net", "(", "x", ")", "\n", "loss", "=", "self", ".", "loss_func", "(", "out", ",", "y", ".", "data", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Calculate perplexity.", "\n", "prob", "=", "out", ".", "exp", "(", ")", "[", "torch", ".", "arange", "(", "0", ",", "y", ".", "data", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "y", ".", "data", "]", "\n", "perplexity", "=", "2", "**", "prob", ".", "log2", "(", ")", ".", "neg", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "list_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "list_pp", ".", "append", "(", "perplexity", ")", "\n", "", "", "return", "{", "'params'", ":", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "sum", "(", "list_loss", ")", "/", "len", "(", "list_loss", ")", ",", "\n", "'pp'", ":", "perplexity", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Update.LocalUpdateLM.evaluate": [[58, 75], ["model.cuda.cuda.eval", "torch.no_grad", "enumerate", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pack_sequence", "model.cuda.cuda.", "prob.log2().neg().sum().item", "model.cuda.cuda.cuda", "model.cuda.exp", "torch.nn.utils.rnn.pack_sequence.cuda", "torch.nn.utils.rnn.pack_sequence.cuda", "prob.log2().neg().sum", "torch.arange", "prob.log2().neg", "prob.log2"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "data_loader", ",", "model", ")", ":", "\n", "        ", "\"\"\" Perplexity of the given data with the given model. \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "entropy_sum", "=", "0", "\n", "word_count", "=", "0", "\n", "for", "val_idx", ",", "sents", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "                ", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_sequence", "(", "[", "s", "[", ":", "-", "1", "]", "for", "s", "in", "sents", "]", ")", "\n", "y", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_sequence", "(", "[", "s", "[", "1", ":", "]", "for", "s", "in", "sents", "]", ")", "\n", "if", "self", ".", "args", ".", "gpu", "!=", "-", "1", ":", "\n", "                    ", "x", ",", "y", "=", "x", ".", "cuda", "(", ")", ",", "y", ".", "cuda", "(", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "", "out", "=", "model", "(", "x", ")", "\n", "prob", "=", "out", ".", "exp", "(", ")", "[", "torch", ".", "arange", "(", "0", ",", "y", ".", "data", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "y", ".", "data", "]", "\n", "entropy_sum", "+=", "prob", ".", "log2", "(", ")", ".", "neg", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "word_count", "+=", "y", ".", "data", ".", "shape", "[", "0", "]", "\n", "", "", "return", "2", "**", "(", "entropy_sum", "/", "word_count", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Models.RnnLm.__init__": [[10, 18], ["torch.nn.Module.__init__", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.DatasetLM.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RnnLm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "config", "\n", "if", "not", "config", ".", "tied", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "config", ".", "nvocab", ",", "config", ".", "d_embed", ")", "\n", "", "self", ".", "encoder", "=", "nn", ".", "GRU", "(", "config", ".", "d_embed", ",", "config", ".", "rnn_hidden", ",", "config", ".", "rnn_layers", ",", "\n", "dropout", "=", "config", ".", "rnn_dropout", ",", "bias", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "config", ".", "rnn_hidden", ",", "config", ".", "nvocab", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Models.RnnLm.get_embedded": [[19, 24], ["Models.RnnLm.fc1.weight.index_select", "Models.RnnLm.embed"], "methods", ["None"], ["", "def", "get_embedded", "(", "self", ",", "word_indexes", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "tied", ":", "\n", "            ", "return", "self", ".", "fc1", ".", "weight", ".", "index_select", "(", "0", ",", "word_indexes", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "embed", "(", "word_indexes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Models.RnnLm.forward": [[25, 30], ["torch.nn.utils.rnn.PackedSequence", "Models.RnnLm.encoder", "Models.RnnLm.fc1", "torch.log_softmax", "Models.RnnLm.get_embedded"], "methods", ["home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Models.RnnLm.get_embedded"], ["", "", "def", "forward", "(", "self", ",", "packed_sents", ")", ":", "\n", "        ", "embedded_sents", "=", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", "(", "self", ".", "get_embedded", "(", "packed_sents", ".", "data", ")", ",", "packed_sents", ".", "batch_sizes", ")", "\n", "out_packed_sequence", ",", "_", "=", "self", ".", "encoder", "(", "embedded_sents", ")", "\n", "out", "=", "self", ".", "fc1", "(", "out_packed_sequence", ".", "data", ")", "\n", "return", "F", ".", "log_softmax", "(", "out", ",", "dim", "=", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__init__": [[12, 17], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.DatasetLM.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stoi", "=", "{", "}", "\n", "self", ".", "itos", "=", "[", "]", "\n", "self", ".", "_counts", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.count": [[18, 25], ["None"], "methods", ["None"], ["", "def", "count", "(", "self", ",", "word", ")", ":", "\n", "        ", "\"\"\"\n        Returns the count of a word occurs in the dict.\n        :param word: a word\n        :return: the count of the given word in the dict.\n        \"\"\"", "\n", "return", "self", ".", "_counts", "[", "self", "[", "word", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.add": [[26, 42], ["Text.Vocab.stoi.get", "len", "Text.Vocab.itos.append", "Text.Vocab._counts.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "word", ")", ":", "\n", "        ", "\"\"\"\n        Adds the given word to the dict, and returns it's index.\n        If the given word is already in the dict, increases it's count.\n        :param word: a word\n        :return: the index of the given word\n        \"\"\"", "\n", "ind", "=", "self", ".", "stoi", ".", "get", "(", "word", ",", "None", ")", "# get index, if doesn't exit, return None", "\n", "if", "ind", "is", "None", ":", "\n", "            ", "ind", "=", "len", "(", "self", ".", "itos", ")", "\n", "self", ".", "itos", ".", "append", "(", "word", ")", "\n", "self", ".", "stoi", "[", "word", "]", "=", "ind", "\n", "self", ".", "_counts", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_counts", "[", "ind", "]", "+=", "1", "\n", "", "return", "ind", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.word_counts": [[43, 46], ["sorted", "zip"], "methods", ["None"], ["", "def", "word_counts", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a list of tuples (word, count) sorted descending. \"\"\"", "\n", "return", "sorted", "(", "zip", "(", "self", ".", "itos", ",", "self", ".", "_counts", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__getitem__": [[50, 55], ["isinstance"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "isinstance", "(", "key", ",", "int", ")", ":", "\n", "            ", "return", "self", ".", "itos", "[", "key", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "stoi", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__setitem__": [[56, 58], ["Exception"], "methods", ["None"], ["", "", "def", "__setitem__", "(", "self", ",", "word", ",", "value", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Can't set items directly, use add(word) instead\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__delitem__": [[59, 61], ["Exception"], "methods", ["None"], ["", "def", "__delitem__", "(", "self", ",", "word", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Can't delete items from index.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.__contains__": [[62, 66], ["isinstance", "Exception"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "word", ",", "str", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"Presence checks only allowed with words\"", ")", "\n", "", "return", "word", "in", "self", ".", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.DatasetLM.__init__": [[69, 92], ["index.add", "os.path.join", "open", "os.path.join", "paragraph.split", "os.path.join", "sentence.split", "sentence.extend", "sentence.append", "Text.DatasetLM.list_sent.append", "index.add", "index.add", "index.add", "t.lower"], "methods", ["home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.add", "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.add", "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.add", "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.Vocab.add"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "train_val_test", ",", "index", ")", ":", "\n", "        ", "\"\"\" Loads the data at the given path using the given index (maps tokens to indices).\n        Returns a list of sentences where each is a list of token indices.\n        \"\"\"", "\n", "assert", "train_val_test", "in", "(", "'train'", ",", "'test'", ",", "'valid'", ")", "\n", "if", "'wiki'", "in", "dataset", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "'../data/{}'", ".", "format", "(", "dataset", ")", ",", "'wiki.'", "+", "train_val_test", "+", "'.tokens'", ")", "\n", "", "elif", "'ptb'", "in", "dataset", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "'../data/{}'", ".", "format", "(", "dataset", ")", ",", "'ptb.'", "+", "train_val_test", "+", "'.txt'", ")", "\n", "", "elif", "'reddit'", "in", "dataset", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "'../data/{}'", ".", "format", "(", "dataset", ")", ",", "'reddit.'", "+", "train_val_test", "+", "'.txt'", ")", "\n", "", "start", "=", "index", ".", "add", "(", "'<SOS>'", ")", "\n", "self", ".", "list_sent", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "paragraph", "in", "f", ":", "\n", "                ", "for", "sentence", "in", "paragraph", ".", "split", "(", "\" . \"", ")", ":", "\n", "                    ", "tokens", "=", "sentence", ".", "split", "(", ")", "\n", "if", "not", "tokens", ":", "\n", "                        ", "continue", "\n", "", "sentence", "=", "[", "index", ".", "add", "(", "'<SOS>'", ")", "]", "\n", "sentence", ".", "extend", "(", "index", ".", "add", "(", "t", ".", "lower", "(", ")", ")", "for", "t", "in", "tokens", ")", "\n", "sentence", ".", "append", "(", "index", ".", "add", "(", "'EOS'", ")", ")", "\n", "self", ".", "list_sent", ".", "append", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.DatasetLM.__len__": [[93, 95], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "list_sent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.Text.DatasetLM.__getitem__": [[96, 98], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "list_sent", "[", "idx", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.src.run.get_batches": [[19, 26], ["random.shuffle", "range", "len", "sentences.sort", "torch.LongTensor", "len"], "function", ["None"], ["def", "get_batches", "(", "data", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\" Yields batches of sentences from 'data', ordered on length. \"\"\"", "\n", "random", ".", "shuffle", "(", "data", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "data", ")", ",", "batch_size", ")", ":", "\n", "        ", "sentences", "=", "data", "[", "i", ":", "i", "+", "batch_size", "]", "\n", "sentences", ".", "sort", "(", "key", "=", "lambda", "l", ":", "len", "(", "l", ")", ",", "reverse", "=", "True", ")", "\n", "yield", "[", "torch", ".", "LongTensor", "(", "s", ")", "for", "s", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.utils.options.args_parser": [[8, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.getcwd"], "function", ["None"], ["def", "args_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# learning arguments", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"rounds of training\"", ")", "\n", "parser", ".", "add_argument", "(", "'--nusers'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"number of users: K\"", ")", "\n", "parser", ".", "add_argument", "(", "'--frac'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'the fraction of clients: C'", ")", "\n", "parser", ".", "add_argument", "(", "'--bs'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_ep'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"the number of local epochs: E\"", ")", "\n", "parser", ".", "add_argument", "(", "'--local_bs'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"local batch size: B\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'learning rate client'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_server'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate of server'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'SGD momentum (default: 0.5)'", ")", "\n", "parser", ".", "add_argument", "(", "'--agg'", ",", "type", "=", "str", ",", "default", "=", "'att'", ",", "help", "=", "'averaging strategy'", ")", "\n", "parser", ".", "add_argument", "(", "'--epsilon'", ",", "type", "=", "float", ",", "default", "=", "1.2", ",", "help", "=", "'stepsize'", ")", "\n", "parser", ".", "add_argument", "(", "'--ord'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'similarity metric'", ")", "\n", "parser", ".", "add_argument", "(", "'--dp'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'differential privacy'", ")", "\n", "# model arguments", "\n", "parser", ".", "add_argument", "(", "'--d_embed'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_dict'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "'size of the dictionary of embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'dropout rate'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--tied'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use tied input/output embedding weights: 1 for true\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'GRU'", ",", "help", "=", "'type of RNN'", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnn_hidden\"", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "\"RNN hidden unit dimensionality\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnn_layers\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Number of RNN layers\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnn_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "\"The rate of dropout in RNN layers\"", ")", "\n", "\n", "# other arguments", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'wikitext-2'", ",", "help", "=", "'dataset name'", ")", "\n", "parser", ".", "add_argument", "(", "'--iid'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'whether i.i.d or not, 1 for iid, 0 for non-iid'", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'do test split'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"GPU ID\"", ")", "\n", "parser", ".", "add_argument", "(", "'--stopping_rounds'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'rounds of early stopping'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'verbose print, 1 for True, 0 for False'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'random seed (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--vector_cache'", ",", "type", "=", "str", ",", "default", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "'.vector_cache/input_vectors.pt'", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--word_vectors'", ",", "type", "=", "str", ",", "default", "=", "'glove.6B.100d'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_snapshot'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.utils.sampling.partition": [[8, 15], ["int", "range", "set", "list", "numpy.random.choice", "range", "set"], "function", ["None"], ["def", "partition", "(", "len_dataset", ",", "num_users", ")", ":", "\n", "    ", "num_items", "=", "int", "(", "len_dataset", "/", "num_users", ")", "\n", "dict_users", ",", "all_idxs", "=", "{", "}", ",", "[", "i", "for", "i", "in", "range", "(", "len_dataset", ")", "]", "\n", "for", "i", "in", "range", "(", "num_users", ")", ":", "\n", "        ", "dict_users", "[", "i", "]", "=", "set", "(", "np", ".", "random", ".", "choice", "(", "all_idxs", ",", "num_items", ",", "replace", "=", "False", ")", ")", "\n", "all_idxs", "=", "list", "(", "set", "(", "all_idxs", ")", "-", "dict_users", "[", "i", "]", ")", "\n", "", "return", "dict_users", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.agg.avg.average_weights": [[9, 22], ["copy.deepcopy", "copy.deepcopy.keys", "range", "len", "torch.div", "torch.mul", "len", "torch.randn"], "function", ["None"], ["def", "average_weights", "(", "w", ",", "dp", ")", ":", "\n", "    ", "\"\"\"\n    Federated averaging\n    :param w: list of client model parameters\n    :param dp: magnitude of randomization\n    :return: updated server model parameters\n    \"\"\"", "\n", "w_avg", "=", "copy", ".", "deepcopy", "(", "w", "[", "0", "]", ")", "\n", "for", "k", "in", "w_avg", ".", "keys", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "w", ")", ")", ":", "\n", "            ", "w_avg", "[", "k", "]", "=", "w_avg", "[", "k", "]", "+", "w", "[", "i", "]", "[", "k", "]", "\n", "", "w_avg", "[", "k", "]", "=", "torch", ".", "div", "(", "w_avg", "[", "k", "]", ",", "len", "(", "w", ")", ")", "+", "torch", ".", "mul", "(", "torch", ".", "randn", "(", "w_avg", "[", "k", "]", ".", "shape", ")", ",", "dp", ")", "\n", "", "return", "w_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.shaoxiongji_fed-att.agg.aggregate.aggregate_att": [[12, 38], ["copy.deepcopy", "w_server.keys", "copy.deepcopy.keys", "copy.deepcopy.keys", "copy.deepcopy.keys", "torch.zeros_like().cpu", "torch.zeros_like().cpu", "torch.zeros().cpu", "torch.zeros().cpu", "range", "torch.softmax", "torch.zeros_like", "torch.zeros_like", "range", "len", "torch.from_numpy", "torch.from_numpy", "len", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.zeros_like", "torch.zeros_like", "torch.zeros", "torch.zeros", "numpy.array", "torch.mul", "torch.mul", "torch.randn", "torch.randn", "len", "scipy.linalg.norm"], "function", ["None"], ["def", "aggregate_att", "(", "w_clients", ",", "w_server", ",", "stepsize", ",", "metric", ",", "dp", ")", ":", "\n", "    ", "\"\"\"\n    Attentive aggregation\n    :param w_clients: list of client model parameters\n    :param w_server: server model parameters\n    :param stepsize: step size for aggregation\n    :param metric: similarity\n    :param dp: magnitude of randomization\n    :return: updated server model parameters\n    \"\"\"", "\n", "w_next", "=", "copy", ".", "deepcopy", "(", "w_server", ")", "\n", "att", ",", "att_mat", "=", "{", "}", ",", "{", "}", "\n", "for", "k", "in", "w_server", ".", "keys", "(", ")", ":", "\n", "        ", "w_next", "[", "k", "]", "=", "torch", ".", "zeros_like", "(", "w_server", "[", "k", "]", ")", ".", "cpu", "(", ")", "\n", "att", "[", "k", "]", "=", "torch", ".", "zeros", "(", "len", "(", "w_clients", ")", ")", ".", "cpu", "(", ")", "\n", "", "for", "k", "in", "w_next", ".", "keys", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "w_clients", ")", ")", ":", "\n", "            ", "att", "[", "k", "]", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "linalg", ".", "norm", "(", "w_server", "[", "k", "]", "-", "w_clients", "[", "i", "]", "[", "k", "]", ",", "ord", "=", "metric", ")", ")", ")", "\n", "", "", "for", "k", "in", "w_next", ".", "keys", "(", ")", ":", "\n", "        ", "att", "[", "k", "]", "=", "F", ".", "softmax", "(", "att", "[", "k", "]", ",", "dim", "=", "0", ")", "\n", "", "for", "k", "in", "w_next", ".", "keys", "(", ")", ":", "\n", "        ", "att_weight", "=", "torch", ".", "zeros_like", "(", "w_server", "[", "k", "]", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "w_clients", ")", ")", ":", "\n", "            ", "att_weight", "+=", "torch", ".", "mul", "(", "w_server", "[", "k", "]", "-", "w_clients", "[", "i", "]", "[", "k", "]", ",", "att", "[", "k", "]", "[", "i", "]", ")", "\n", "", "w_next", "[", "k", "]", "=", "w_server", "[", "k", "]", "-", "torch", ".", "mul", "(", "att_weight", ",", "stepsize", ")", "+", "torch", ".", "mul", "(", "torch", ".", "randn", "(", "w_server", "[", "k", "]", ".", "shape", ")", ",", "dp", ")", "\n", "", "return", "w_next", "\n", "", ""]]}