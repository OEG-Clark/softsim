{"home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords": [[387, 400], ["None"], "function", ["None"], ["def", "has_multiple_keywords", "(", "text", ",", "keywords_list", ")", ":", "\n", "    ", "has_multiple_kw", "=", "False", "\n", "for", "keywords", "in", "keywords_list", ":", "\n", "        ", "has_cur_all_kw", "=", "True", "\n", "for", "each_kw", "in", "keywords", ":", "\n", "            ", "if", "each_kw", "not", "in", "text", ":", "\n", "                ", "has_cur_all_kw", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "has_cur_all_kw", "is", "True", ":", "\n", "            ", "has_multiple_kw", "=", "True", "\n", "return", "has_multiple_kw", "\n", "", "", "return", "has_multiple_kw", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.classify_question_type": [[402, 462], ["question.lower.lower", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords", "classify_question_type_v2.has_multiple_keywords", "classify_question_type_v2.has_keywords"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_multiple_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords"], ["", "def", "classify_question_type", "(", "question", ")", ":", "\n", "    ", "question", "=", "question", ".", "lower", "(", ")", "\n", "question_type", "=", "None", "\n", "\n", "if", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel flaw'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel flaw'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Parallel flaw'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the flaw'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the flaw'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Identify the flaw'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel reasoning'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel reasoning'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Parallel reasoning'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the technique'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the technique'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Identify the technique'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Necessary assumption'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Necessary assumption'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Necessary assumption'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Sufficient assumption'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Sufficient assumption'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Sufficient assumption'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Weaken'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Weaken'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Weaken'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Strengthen'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Strengthen'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Strengthen'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Evaluate'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Evaluate'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Evaluate'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Paradox'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Paradox'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Paradox'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Entailment'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Entailment'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Entailment'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Most strongly supported'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Most strongly supported'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Most strongly supported'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Complete the passage'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Complete the passage'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Complete the passage'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Dispute'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Dispute'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Dispute'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the conclusion'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the conclusion'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Identify the conclusion'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the role'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the role'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Identify the role'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel principle'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Parallel principle'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Parallel principle'", "\n", "", "elif", "has_multiple_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the principle'", "]", "[", "0", "]", ")", "or", "has_keywords", "(", "question", ",", "question_type_keyword_dict", "[", "'Identify the principle'", "]", "[", "1", "]", ",", "is_bound", "=", "True", ")", ":", "\n", "        ", "question_type", "=", "'Identify the principle'", "\n", "\n", "", "return", "question_type", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.select_question_type_from_multiple": [[477, 482], ["None"], "function", ["None"], ["def", "select_question_type_from_multiple", "(", "type_list", ")", ":", "\n", "    ", "for", "each", "in", "type_list", ":", "\n", "        ", "if", "\"Parallel\"", "in", "each", ":", "\n", "            ", "return", "each", "\n", "", "", "return", "type_list", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.extract_our_question_type": [[484, 514], ["open", "json.load", "list", "print", "classify_question_type_v2.classify_question_type", "list", "secondary_question_type_keyword_dict.keys", "list.append", "classify_question_type_v2.has_keywords", "len", "list.append", "each_instance[].lower", "list.append", "len", "list.append", "classify_question_type_v2.has_keywords", "list.append", "list.append", "classify_question_type_v2.select_question_type_from_multiple"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.classify_question_type", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.select_question_type_from_multiple"], ["", "def", "extract_our_question_type", "(", "file_name", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "all_question_types", "=", "list", "(", ")", "\n", "none_question_type_num", "=", "0", "\n", "three_question_type_num", "=", "0", "\n", "all_instance_num", "=", "0", "\n", "\n", "for", "each_instance", "in", "lines", ":", "\n", "            ", "cur_question_type", "=", "classify_question_type", "(", "each_instance", "[", "'question'", "]", ")", "\n", "all_instance_num", "+=", "1", "\n", "if", "cur_question_type", "is", "None", ":", "\n", "                ", "candidate_question_types", "=", "list", "(", ")", "\n", "for", "each_key", "in", "secondary_question_type_keyword_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "has_keywords", "(", "each_instance", "[", "'question'", "]", ".", "lower", "(", ")", ",", "secondary_question_type_keyword_dict", "[", "each_key", "]", ")", ":", "\n", "                        ", "candidate_question_types", ".", "append", "(", "each_key", ")", "\n", "", "", "if", "len", "(", "candidate_question_types", ")", "==", "1", ":", "\n", "                    ", "all_question_types", ".", "append", "(", "candidate_question_types", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "candidate_question_types", ")", "==", "0", ":", "\n", "                    ", "none_question_type_num", "+=", "1", "\n", "all_question_types", ".", "append", "(", "\"\"", ")", "\n", "", "else", ":", "\n", "                    ", "if", "has_keywords", "(", "each_instance", "[", "'question'", "]", ",", "parallel_keywords", ")", ":", "\n", "                        ", "all_question_types", ".", "append", "(", "select_question_type_from_multiple", "(", "candidate_question_types", ")", ")", "\n", "", "else", ":", "\n", "                        ", "all_question_types", ".", "append", "(", "candidate_question_types", "[", "0", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "all_question_types", ".", "append", "(", "cur_question_type", ")", "\n", "", "", "print", "(", "none_question_type_num", ",", "three_question_type_num", ",", "all_instance_num", ")", "\n", "return", "all_question_types", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.edit_ques_type_description": [[516, 537], ["list", "list.append", "list.append", "list.append", "list.append", "list.append"], "function", ["None"], ["", "", "def", "edit_ques_type_description", "(", "ques_type_list", ")", ":", "\n", "    ", "edited_ques_type_list", "=", "list", "(", ")", "\n", "for", "each_type", "in", "ques_type_list", ":", "\n", "        ", "if", "each_type", "==", "\"Entailment\"", ":", "\n", "            ", "edited_ques_type_list", ".", "append", "(", "\"Must be true or Cannot be true\"", ")", "\n", "", "elif", "each_type", "==", "\"Dispute\"", ":", "\n", "            ", "edited_ques_type_list", ".", "append", "(", "\"Point at issue and disagreement\"", ")", "\n", "", "elif", "each_type", "==", "\"Evaluate\"", ":", "\n", "            ", "edited_ques_type_list", ".", "append", "(", "\"Useful to know to evaluate\"", ")", "\n", "", "elif", "each_type", "==", "\"Paradox\"", ":", "\n", "            ", "edited_ques_type_list", ".", "append", "(", "\"Explain or Resolve\"", ")", "\n", "", "else", ":", "\n", "            ", "edited_ques_type_list", ".", "append", "(", "each_type", ")", "\n", "# if each_type == \"Identify the principle\" or each_type == \"Parallel principle\":", "\n", "#     edited_ques_type_list.append(\"Principle\")", "\n", "# elif each_type == \"\" or each_type == \"Complete the passage\":", "\n", "#     edited_ques_type_list.append(\"Others\")", "\n", "# else:", "\n", "#     edited_ques_type_list.append(each_type)", "\n", "\n", "", "", "return", "edited_ques_type_list", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.has_keywords": [[562, 574], ["text.find", "text.find", "len", "len", "len", "len"], "function", ["None"], ["def", "has_keywords", "(", "text", ",", "keywords", ",", "is_bound", "=", "False", ")", ":", "\n", "    ", "has_kw", "=", "False", "\n", "for", "each_kw", "in", "keywords", ":", "\n", "        ", "if", "not", "is_bound", ":", "\n", "            ", "if", "each_kw", "in", "text", ":", "\n", "                ", "has_kw", "=", "True", "\n", "return", "has_kw", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "len", "(", "text", ")", "-", "len", "(", "each_kw", ")", ">=", "0", "and", "text", ".", "find", "(", "each_kw", ")", "==", "len", "(", "text", ")", "-", "len", "(", "each_kw", ")", ")", "or", "text", ".", "find", "(", "each_kw", ")", "==", "0", ":", "\n", "                ", "has_kw", "=", "True", "\n", "return", "has_kw", "\n", "", "", "", "return", "has_kw", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.calculate_question_type_distribution": [[577, 585], ["print", "len", "question_type_list.index", "numpy.round", "sum", "len"], "function", ["None"], ["", "def", "calculate_question_type_distribution", "(", "all_question_types", ")", ":", "\n", "    ", "all_question_type_nums", "=", "[", "0", ",", "]", "*", "len", "(", "question_type_list", ")", "\n", "for", "each_type", "in", "all_question_types", ":", "\n", "        ", "ques_type_index", "=", "question_type_list", ".", "index", "(", "each_type", ")", "\n", "all_question_type_nums", "[", "ques_type_index", "]", "+=", "1", "\n", "\n", "", "all_question_type_ratios", "=", "[", "np", ".", "round", "(", "each_num", "/", "len", "(", "all_question_types", ")", ",", "4", ")", "for", "each_num", "in", "all_question_type_nums", "]", "\n", "print", "(", "all_question_type_ratios", ",", "sum", "(", "all_question_type_ratios", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.classify_question_type_v2.compare_test_GT_question_type": [[591, 608], ["open", "json.load", "list", "enumerate", "print", "list.append", "len", "len", "print", "print", "print"], "function", ["None"], ["def", "compare_test_GT_question_type", "(", "file_name", ",", "our_extracted_types", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "all_question_types", "=", "list", "(", ")", "\n", "different_num", "=", "0", "\n", "\n", "for", "i", ",", "each_instance", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "cur_question_type", "=", "GT_ques_type_names", "[", "each_instance", "[", "'question_type'", "]", "]", "\n", "all_question_types", ".", "append", "(", "cur_question_type", ")", "\n", "\n", "if", "cur_question_type", "!=", "our_extracted_types", "[", "i", "]", ":", "# and cur_question_type != \"Others\":", "\n", "                ", "different_num", "+=", "1", "\n", "if", "different_num", ">", "40", "and", "different_num", "<", "60", ":", "\n", "                    ", "print", "(", "cur_question_type", ",", "\"\\t\"", ",", "our_extracted_types", "[", "i", "]", ")", "\n", "print", "(", "each_instance", "[", "'question'", "]", ")", "\n", "print", "(", "\"*\"", "*", "100", ")", "\n", "", "", "", "print", "(", "different_num", ",", "len", "(", "our_extracted_types", ")", ",", "different_num", "/", "len", "(", "our_extracted_types", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.has_keyword": [[22, 33], ["tokens.index", "len", "token_str.find", "nltk.word_tokenize", "len", "nltk.word_tokenize"], "function", ["None"], ["def", "has_keyword", "(", "keyword_list", ",", "tokens", ")", ":", "\n", "    ", "for", "each", "in", "keyword_list", ":", "\n", "        ", "if", "each", "in", "tokens", ":", "\n", "            ", "return", "tokens", ".", "index", "(", "each", ")", ",", "each", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "nltk", ".", "word_tokenize", "(", "each", ")", ")", ">", "1", ":", "\n", "                ", "token_str", "=", "\" \"", ".", "join", "(", "tokens", ")", "\n", "idx", "=", "token_str", ".", "find", "(", "each", ")", "\n", "if", "idx", ">=", "0", ":", "\n", "                    ", "return", "len", "(", "nltk", ".", "word_tokenize", "(", "token_str", "[", ":", "idx", "]", ")", ")", ",", "each", "\n", "", "", "", "", "return", "-", "1", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.has_same_logical_component": [[36, 67], ["list", "range", "list", "list", "vnp1_tokens.append", "vnp2_tokens.append", "len", "max", "len", "range", "list.append", "len", "set", "set", "len", "max", "len"], "function", ["None"], ["", "def", "has_same_logical_component", "(", "vnp1", ",", "vnp2", ",", "vnp1_compo_tags", ")", ":", "\n", "\n", "    ", "vnp1_tokens", ",", "vnp2_tokens", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "each_phrase", "in", "vnp1", ":", "\n", "        ", "vnp1_tokens", ".", "append", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "", "for", "each_phrase", "in", "vnp2", ":", "\n", "        ", "vnp2_tokens", ".", "append", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "# print(vnp1_tokens)", "\n", "# print(vnp2_tokens)", "\n", "\n", "", "vnp2_compo_tags", "=", "list", "(", ")", "\n", "if", "len", "(", "vnp1_compo_tags", ")", ">", "0", ":", "\n", "        ", "tag_record", "=", "max", "(", "vnp1_compo_tags", ")", "\n", "", "else", ":", "\n", "        ", "tag_record", "=", "-", "1", "\n", "", "for", "j", "in", "range", "(", "len", "(", "vnp2_tokens", ")", ")", ":", "\n", "        ", "has_same", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "vnp1_tokens", ")", ")", ":", "\n", "            ", "vnp1_i", "=", "set", "(", "vnp1_tokens", "[", "i", "]", ")", "\n", "vnp2_j", "=", "set", "(", "vnp2_tokens", "[", "j", "]", ")", "\n", "\n", "# hyper-parameter: 0.7", "\n", "if", "len", "(", "vnp1_i", "&", "vnp2_j", ")", "/", "max", "(", "len", "(", "vnp2_j", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "has_same", "=", "vnp1_compo_tags", "[", "i", "]", "\n", "break", "\n", "", "", "if", "has_same", "==", "-", "1", ":", "\n", "            ", "has_same", "=", "tag_record", "+", "1", "\n", "tag_record", "+=", "1", "\n", "\n", "", "vnp2_compo_tags", ".", "append", "(", "has_same", ")", "\n", "", "return", "vnp2_compo_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.identify_logical_expression": [[70, 94], ["list", "len", "Exception", "list", "range", "list.append", "range", "len", "list.append", "len", "list", "list", "range", "construct_negative_samples_v2.has_same_logical_component", "list.append", "len", "print", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_same_logical_component"], ["", "def", "identify_logical_expression", "(", "premise_vn_phrases", ")", ":", "\n", "    ", "all_component_tags", "=", "list", "(", ")", "\n", "\n", "if", "len", "(", "premise_vn_phrases", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"No premises\"", ")", "\n", "", "else", ":", "\n", "        ", "vnp1_compo_tags", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "premise_vn_phrases", "[", "0", "]", ")", ")", ":", "\n", "            ", "vnp1_compo_tags", ".", "append", "(", "i", ")", "\n", "", "all_component_tags", ".", "append", "(", "vnp1_compo_tags", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "premise_vn_phrases", ")", ")", ":", "\n", "            ", "arg_1", "=", "list", "(", ")", "\n", "arg_3", "=", "list", "(", ")", "\n", "for", "k", "in", "range", "(", "j", ")", ":", "\n", "                ", "arg_1", "+=", "premise_vn_phrases", "[", "k", "]", "\n", "arg_3", "+=", "all_component_tags", "[", "k", "]", "\n", "", "vnpj_compo_tags", "=", "has_same_logical_component", "(", "arg_1", ",", "premise_vn_phrases", "[", "j", "]", ",", "arg_3", ")", "\n", "all_component_tags", ".", "append", "(", "vnpj_compo_tags", ")", "\n", "\n", "", "if", "len", "(", "premise_vn_phrases", ")", ">", "7", ":", "\n", "            ", "print", "(", "\"Exception: more than 6 premises\"", ",", "len", "(", "premise_vn_phrases", ")", ")", "\n", "\n", "", "", "return", "all_component_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.extract_logical_variables": [[96, 132], ["list", "list", "list", "list", "construct_negative_samples_v2.extract_np_vnp_constituents", "construct_negative_samples_v2.identify_positive_negative_vnp", "all_prem_vn_phrases.append", "all_prem_negative_tags.append", "list", "list", "construct_negative_samples_v2.extract_np_vnp_constituents", "construct_negative_samples_v2.identify_positive_negative_vnp", "all_ans_vn_phrases.append", "all_ans_negative_tags.append", "construct_negative_samples_v2.extract_np_vnp_constituents", "construct_negative_samples_v2.identify_positive_negative_vnp", "all_conc_vn_phrases.append", "all_conc_negative_tags.append"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp"], ["", "def", "extract_logical_variables", "(", "conclusions", ",", "premises", ",", "answer_list", ")", ":", "\n", "    ", "all_conc_vn_phrases", ",", "all_conc_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Conclusion ......................................\")", "\n", "for", "each_conclusion", "in", "conclusions", ":", "\n", "        ", "if", "each_conclusion", "is", "not", "None", ":", "\n", "            ", "conc_all_verb_nouns_phrases", ",", "conc_all_vnp_scales", ",", "conc_token_list", "=", "extract_np_vnp_constituents", "(", "each_conclusion", ")", "\n", "conc_vn_phrases", ",", "conc_negative_tags", "=", "identify_positive_negative_vnp", "(", "conc_all_verb_nouns_phrases", ",", "conc_all_vnp_scales", ",", "conc_token_list", ")", "\n", "# print(conc_vn_phrases)", "\n", "# print(conc_negative_tags)", "\n", "all_conc_vn_phrases", ".", "append", "(", "conc_vn_phrases", ")", "\n", "all_conc_negative_tags", ".", "append", "(", "conc_negative_tags", ")", "\n", "\n", "\n", "", "", "all_prem_vn_phrases", ",", "all_prem_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Premise ......................................\")", "\n", "for", "each_premise", "in", "premises", ":", "\n", "        ", "each_prem_all_verb_nouns_phrases", ",", "each_prem_all_vnp_scales", ",", "premise_token_list", "=", "extract_np_vnp_constituents", "(", "each_premise", ")", "\n", "each_prem_vn_phrases", ",", "each_prem_negative_tags", "=", "identify_positive_negative_vnp", "(", "each_prem_all_verb_nouns_phrases", ",", "each_prem_all_vnp_scales", ",", "premise_token_list", ")", "\n", "# print(each_prem_vn_phrases)", "\n", "# print(each_prem_negative_tags)", "\n", "all_prem_vn_phrases", ".", "append", "(", "each_prem_vn_phrases", ")", "\n", "all_prem_negative_tags", ".", "append", "(", "each_prem_negative_tags", ")", "\n", "\n", "", "all_ans_vn_phrases", ",", "all_ans_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Answer ......................................\")", "\n", "for", "each_answer", "in", "answer_list", ":", "\n", "        ", "each_ans_all_verb_nouns_phrases", ",", "each_ans_all_vnp_scales", ",", "answer_token_list", "=", "extract_np_vnp_constituents", "(", "each_answer", ")", "\n", "each_ans_vn_phrases", ",", "each_ans_negative_tags", "=", "identify_positive_negative_vnp", "(", "each_ans_all_verb_nouns_phrases", ",", "each_ans_all_vnp_scales", ",", "answer_token_list", ")", "\n", "# print(each_ans_vn_phrases)", "\n", "# print(each_ans_negative_tags)", "\n", "all_ans_vn_phrases", ".", "append", "(", "each_ans_vn_phrases", ")", "\n", "all_ans_negative_tags", ".", "append", "(", "each_ans_negative_tags", ")", "\n", "\n", "", "return", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "all_conc_vn_phrases", ",", "all_conc_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.extract_np_vnp_constituents": [[135, 171], ["list", "list", "constituent_strs.count", "constituent_strs.count", "nltk.tree.Tree.fromstring", "construct_negative_samples_v2.recursive_extract_np_vnp", "len", "Tree.fromstring.leaves", "cur_sent.find", "len", "list.append", "each.label", "list.append", "nltk.word_tokenize", "each.lower", "list.pop", "list.append", "each.pos", "Tree.fromstring.leaves", "extracted_trees[].label", "extracted_trees[].label", "len", "len", "extracted_trees[].pos", "each.pos"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp"], ["", "def", "extract_np_vnp_constituents", "(", "constituent_strs", ")", ":", "\n", "    ", "all_np_vnp_phrases", "=", "list", "(", ")", "\n", "all_np_vnp_scales", "=", "list", "(", ")", "\n", "\n", "left_pare_num", "=", "constituent_strs", ".", "count", "(", "'('", ")", "\n", "right_pare_num", "=", "constituent_strs", ".", "count", "(", "')'", ")", "\n", "if", "left_pare_num", ">", "right_pare_num", ":", "\n", "        ", "constituent_strs", "=", "constituent_strs", "+", "')'", "\n", "", "elif", "left_pare_num", "<", "right_pare_num", ":", "\n", "        ", "constituent_strs", "=", "'('", "+", "constituent_strs", "\n", "", "constituent_trees", "=", "Tree", ".", "fromstring", "(", "constituent_strs", ")", "\n", "extracted_trees", "=", "recursive_extract_np_vnp", "(", "constituent_trees", ")", "\n", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "extracted_trees", ")", ":", "\n", "        ", "each", "=", "extracted_trees", "[", "i", "]", "\n", "\n", "if", "each", ".", "label", "(", ")", "==", "'HYPH'", ":", "\n", "            ", "if", "i", ">", "0", "and", "extracted_trees", "[", "i", "-", "1", "]", ".", "label", "(", ")", "==", "'NP'", "and", "i", "<", "(", "len", "(", "extracted_trees", ")", "-", "1", ")", "and", "extracted_trees", "[", "i", "+", "1", "]", ".", "label", "(", ")", "==", "'NP'", ":", "\n", "                ", "poped_phrase", "=", "all_np_vnp_phrases", ".", "pop", "(", ")", "\n", "all_np_vnp_phrases", ".", "append", "(", "poped_phrase", "+", "each", ".", "pos", "(", ")", "+", "extracted_trees", "[", "i", "+", "1", "]", ".", "pos", "(", ")", ")", "\n", "i", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "all_np_vnp_phrases", ".", "append", "(", "each", ".", "pos", "(", ")", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "cur_sent", "=", "\" \"", ".", "join", "(", "constituent_trees", ".", "leaves", "(", ")", ")", "\n", "for", "each_phrase", "in", "all_np_vnp_phrases", ":", "\n", "        ", "cur_phrase", "=", "\" \"", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "# print(cur_phrase)", "\n", "idx", "=", "cur_sent", ".", "find", "(", "cur_phrase", ")", "\n", "start", "=", "len", "(", "nltk", ".", "word_tokenize", "(", "cur_sent", "[", ":", "idx", "]", ")", ")", "\n", "all_np_vnp_scales", ".", "append", "(", "[", "start", ",", "start", "+", "len", "(", "each_phrase", ")", "]", ")", "\n", "# print(all_np_vnp_scales[-1])", "\n", "\n", "", "return", "all_np_vnp_phrases", ",", "all_np_vnp_scales", ",", "[", "each", ".", "lower", "(", ")", "for", "each", "in", "constituent_trees", ".", "leaves", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.recursive_extract_np_vnp": [[174, 210], ["list", "each.label", "each.label", "each[].label", "len", "list.append", "list.append", "each[].label", "list.append", "range", "construct_negative_samples_v2.recursive_extract_np_vnp", "isinstance", "[].lower", "each[].label", "len", "list.append", "len", "construct_negative_samples_v2.recursive_extract_np_vnp", "each.label", "each.label", "each.label", "list.append", "[].label", "isinstance", "[].lower"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp"], ["", "def", "recursive_extract_np_vnp", "(", "constituent_trees", ")", ":", "\n", "    ", "extracted_trees", "=", "list", "(", ")", "\n", "for", "each", "in", "constituent_trees", ":", "\n", "# print(each)", "\n", "        ", "if", "each", ".", "label", "(", ")", "==", "'NP'", ":", "\n", "            ", "if", "each", "[", "0", "]", ".", "label", "(", ")", "==", "'PRP'", "or", "(", "not", "isinstance", "(", "each", "[", "0", "]", "[", "0", "]", ",", "Tree", ")", "and", "each", "[", "0", "]", "[", "0", "]", ".", "lower", "(", ")", "in", "PRP_words", ")", ":", "\n", "                ", "if", "len", "(", "each", ")", ">", "1", ":", "\n", "                    ", "extracted_trees", ".", "append", "(", "each", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "elif", "each", "[", "0", "]", ".", "label", "(", ")", "==", "'NP'", "and", "(", "each", "[", "0", "]", "[", "0", "]", ".", "label", "(", ")", "==", "'PRP'", "or", "(", "not", "isinstance", "(", "each", "[", "0", "]", "[", "0", "]", "[", "0", "]", ",", "Tree", ")", "and", "each", "[", "0", "]", "[", "0", "]", "[", "0", "]", ".", "lower", "(", ")", "in", "PRP_words", ")", ")", ":", "\n", "                ", "if", "len", "(", "each", ")", ">", "1", ":", "\n", "                    ", "extracted_trees", ".", "append", "(", "each", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "else", ":", "\n", "                ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "", "elif", "each", ".", "label", "(", ")", "==", "'VP'", ":", "\n", "            ", "if", "'VB'", "in", "each", "[", "0", "]", ".", "label", "(", ")", ":", "\n", "                ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "each", ")", ")", ":", "\n", "# print(each[i])", "\n", "# if each[i].label() == 'VP':", "\n", "                    ", "extracted_trees", "+=", "recursive_extract_np_vnp", "(", "each", "[", "i", ":", "i", "+", "1", "]", ")", "\n", "", "", "", "elif", "each", ".", "label", "(", ")", "==", "'SBAR'", "or", "each", ".", "label", "(", ")", "==", "'S'", ":", "\n", "# print('SBAR', len(each))", "\n", "            ", "extracted_trees", "+=", "recursive_extract_np_vnp", "(", "each", ")", "\n", "", "elif", "each", ".", "label", "(", ")", "==", "'HYPH'", ":", "\n", "            ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print('Other', each)", "\n", "\n", "", "", "return", "extracted_trees", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.identify_positive_negative_vnp": [[213, 257], ["list", "list", "range", "list", "len", "construct_negative_samples_v2.has_keyword", "construct_negative_samples_v2.has_keyword", "list.append", "list.append", "len", "each_token[].lower", "list.append", "list.append", "bool", "len", "list.append", "bool", "len", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "identify_positive_negative_vnp", "(", "all_vn_phrases", ",", "all_vn_scales", ",", "token_list", ")", ":", "\n", "    ", "vn_phrases", "=", "list", "(", ")", "\n", "negative_tags", "=", "list", "(", ")", "\n", "index_start", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_vn_phrases", ")", ")", ":", "\n", "        ", "cur_neg_tag", "=", "False", "\n", "cur_reverse_tag", "=", "False", "\n", "cur_vnp_tokens", "=", "[", "each_token", "[", "0", "]", ".", "lower", "(", ")", "for", "each_token", "in", "all_vn_phrases", "[", "i", "]", "]", "\n", "cur_vn_phrase", "=", "all_vn_phrases", "[", "i", "]", "\n", "\n", "nega_kw_index", ",", "nega_kw", "=", "has_keyword", "(", "negative_words", "+", "reverse_negative_words", ",", "cur_vnp_tokens", ")", "\n", "if", "nega_kw_index", ">=", "0", ":", "\n", "            ", "cur_neg_tag", "=", "True", "\n", "# print(cur_vnp_tokens)", "\n", "# print(nega_kw_index, nega_kw)", "\n", "if", "nega_kw", "in", "reverse_negative_words", "and", "nega_kw_index", "==", "0", ":", "\n", "                ", "cur_reverse_tag", "=", "True", "\n", "", "cur_vn_phrase", "=", "cur_vn_phrase", "[", ":", "nega_kw_index", "]", "+", "cur_vn_phrase", "[", "nega_kw_index", "+", "len", "(", "nltk", ".", "word_tokenize", "(", "nega_kw", ")", ")", ":", "]", "\n", "\n", "", "outer_nega_kw_index", ",", "outer_nega_kw", "=", "has_keyword", "(", "negative_words", "+", "reverse_negative_words", ",", "token_list", "[", "index_start", ":", "all_vn_scales", "[", "i", "]", "[", "0", "]", "]", ")", "\n", "if", "outer_nega_kw_index", ">=", "0", ":", "\n", "            ", "if", "cur_neg_tag", ":", "\n", "                ", "cur_neg_tag", "=", "False", "\n", "", "else", ":", "\n", "                ", "cur_neg_tag", "=", "True", "\n", "\n", "", "", "index_start", "=", "all_vn_scales", "[", "i", "]", "[", "1", "]", "\n", "vn_phrases", ".", "append", "(", "cur_vn_phrase", ")", "\n", "negative_tags", ".", "append", "(", "[", "cur_neg_tag", ",", "cur_reverse_tag", "]", ")", "\n", "\n", "", "reverse_negative_tags", "=", "list", "(", ")", "\n", "j", "=", "0", "\n", "while", "j", "<", "len", "(", "vn_phrases", ")", ":", "\n", "        ", "if", "negative_tags", "[", "j", "]", "[", "1", "]", ":", "\n", "            ", "reverse_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "negative_tags", "[", "j", "]", "[", "0", "]", ")", ")", "\n", "if", "j", "+", "1", "<", "len", "(", "vn_phrases", ")", ":", "\n", "                ", "reverse_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "negative_tags", "[", "j", "+", "1", "]", "[", "0", "]", ")", ")", "\n", "", "j", "+=", "1", "\n", "", "else", ":", "\n", "            ", "reverse_negative_tags", ".", "append", "(", "negative_tags", "[", "j", "]", "[", "0", "]", ")", "\n", "", "j", "+=", "1", "\n", "\n", "", "return", "vn_phrases", ",", "reverse_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.identify_condition": [[260, 317], ["enumerate", "list", "list", "list", "list", "list", "enumerate", "list", "list", "all_conditioned_vn_phrases.append", "all_conditioned_negative_tags.append", "construct_negative_samples_v2.has_keyword", "len", "each[].lower", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "len", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "bool", "len", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "identify_condition", "(", "all_vn_phrases", ",", "all_negative_tags", ")", ":", "\n", "    ", "all_conditioned_vn_phrases", ",", "all_conditioned_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "i", ",", "each_sent_phrases", "in", "enumerate", "(", "all_vn_phrases", ")", ":", "\n", "        ", "cur_sent_all_phrases", "=", "list", "(", ")", "\n", "cur_sent_all_negative_tags", "=", "list", "(", ")", "\n", "cur_sent_vn_reverse_tags", "=", "list", "(", ")", "\n", "\n", "for", "j", ",", "cur_vn_phrase", "in", "enumerate", "(", "each_sent_phrases", ")", ":", "\n", "            ", "token_list", "=", "[", "each", "[", "0", "]", ".", "lower", "(", ")", "for", "each", "in", "cur_vn_phrase", "]", "\n", "condi_kw_index", ",", "condi_kw", "=", "has_keyword", "(", "condition_keywords", "+", "reverse_condition_keywords", ",", "token_list", ")", "\n", "\n", "if", "condi_kw_index", ">=", "0", ":", "\n", "                ", "if", "cur_vn_phrase", "[", "condi_kw_index", "-", "1", "]", "[", "0", "]", "==", "','", ":", "\n", "                    ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", ":", "condi_kw_index", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", ":", "condi_kw_index", "]", ")", "\n", "", "if", "condi_kw", "==", "'unless'", ":", "\n", "                    ", "cur_sent_all_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "", "if", "condi_kw", "in", "reverse_condition_keywords", ":", "\n", "                    ", "cur_sent_vn_reverse_tags", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", "condi_kw_index", "+", "len", "(", "nltk", ".", "word_tokenize", "(", "condi_kw", ")", ")", ":", "]", ")", "\n", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "", "else", ":", "\n", "                ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", ")", "\n", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "\n", "", "", "reverse_all_vn_phrases", "=", "list", "(", ")", "\n", "reverse_all_negative_tags", "=", "list", "(", ")", "\n", "k", "=", "0", "\n", "while", "k", "<", "len", "(", "cur_sent_all_phrases", ")", ":", "\n", "            ", "if", "cur_sent_vn_reverse_tags", "[", "k", "]", ":", "\n", "                ", "if", "k", "+", "1", "<", "len", "(", "cur_sent_all_phrases", ")", ":", "\n", "                    ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "+", "1", "]", ")", "\n", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "+", "1", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "k", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "", "k", "+=", "1", "\n", "# print(reverse_all_vn_phrases)", "\n", "# print(reverse_all_negative_tags)", "\n", "\n", "", "all_conditioned_vn_phrases", ".", "append", "(", "reverse_all_vn_phrases", ")", "\n", "all_conditioned_negative_tags", ".", "append", "(", "reverse_all_negative_tags", ")", "\n", "\n", "", "return", "all_conditioned_vn_phrases", ",", "all_conditioned_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.spread_logical_expressions": [[319, 336], ["list", "list", "list", "enumerate", "len", "range", "len", "list.append", "list.append", "list.append", "len", "list.append", "list.append", "list.append"], "function", ["None"], ["", "def", "spread_logical_expressions", "(", "all_vn_phrases", ",", "all_negative_tags", ",", "all_compo_tags", ")", ":", "\n", "    ", "spread_all_vn_phrases", "=", "list", "(", ")", "\n", "spread_all_negative_tags", "=", "list", "(", ")", "\n", "spread_all_compo_tags", "=", "list", "(", ")", "\n", "\n", "for", "i", ",", "each_vn", "in", "enumerate", "(", "all_vn_phrases", ")", ":", "\n", "        ", "if", "len", "(", "each_vn", ")", ">", "2", ":", "\n", "            ", "for", "j", "in", "range", "(", "1", ",", "len", "(", "each_vn", ")", ")", ":", "\n", "                ", "spread_all_vn_phrases", ".", "append", "(", "each_vn", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "spread_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "spread_all_compo_tags", ".", "append", "(", "all_compo_tags", "[", "i", "]", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "", "", "elif", "len", "(", "each_vn", ")", "==", "2", ":", "\n", "            ", "spread_all_vn_phrases", ".", "append", "(", "each_vn", ")", "\n", "spread_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", ")", "\n", "spread_all_compo_tags", ".", "append", "(", "all_compo_tags", "[", "i", "]", ")", "\n", "\n", "", "", "return", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.infer_logical_expression": [[339, 396], ["list", "list", "range", "list", "list", "len", "list.append", "list.append", "list", "list", "range", "list", "list", "range", "construct_negative_samples_v2.infer_logical_expression.reverse_logic"], "function", ["None"], ["", "def", "infer_logical_expression", "(", "all_vn_phrases", ",", "all_negative_tags", ",", "all_compo_tags", ")", ":", "\n", "    ", "all_logical_expressions", "=", "list", "(", ")", "\n", "all_textual_vn_phrases", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "all_compo_tags", ")", ")", ":", "\n", "        ", "all_logical_expressions", ".", "append", "(", "[", "[", "x", ",", "y", "]", "for", "x", ",", "y", "in", "zip", "(", "all_compo_tags", "[", "i", "]", ",", "all_negative_tags", "[", "i", "]", ")", "]", ")", "\n", "all_textual_vn_phrases", ".", "append", "(", "all_vn_phrases", "[", "i", "]", ")", "\n", "\n", "", "extended_logical_expression", "=", "list", "(", ")", "\n", "extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "def", "reverse_logic", "(", "all_textual_vn_phrases", ",", "all_logical_expressions", ")", ":", "\n", "        ", "cur_extended_logical_expression", "=", "list", "(", ")", "\n", "cur_extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_logical_expressions", ")", ")", ":", "\n", "            ", "if", "len", "(", "all_logical_expressions", "[", "i", "]", ")", "==", "2", ":", "\n", "                ", "rever_cur_logical_expression", "=", "[", "[", "x", ",", "bool", "(", "1", "-", "y", ")", "]", "for", "x", ",", "y", "in", "all_logical_expressions", "[", "i", "]", "[", ":", ":", "-", "1", "]", "]", "\n", "if", "rever_cur_logical_expression", "not", "in", "all_logical_expressions", "+", "cur_extended_logical_expression", ":", "\n", "# all_logical_expressions.append(rever_cur_logical_expression)", "\n", "# all_vn_phrases.append(all_vn_phrases[i][::-1])", "\n", "                    ", "cur_extended_logical_expression", ".", "append", "(", "rever_cur_logical_expression", ")", "\n", "cur_extended_textual_vn_phrases", ".", "append", "(", "all_textual_vn_phrases", "[", "i", "]", "[", ":", ":", "-", "1", "]", ")", "\n", "\n", "", "", "", "return", "cur_extended_logical_expression", ",", "cur_extended_textual_vn_phrases", "\n", "\n", "", "def", "transfer_logic", "(", "all_textual_vn_phrases", ",", "all_logical_expressions", ")", ":", "\n", "\n", "        ", "cur_extended_logical_expression", "=", "list", "(", ")", "\n", "cur_extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_logical_expressions", ")", ")", ":", "\n", "            ", "other_logical_expressions", "=", "all_logical_expressions", "[", ":", "i", "]", "+", "all_logical_expressions", "[", "i", "+", "1", ":", "]", "\n", "other_textual_vn_phrases", "=", "all_textual_vn_phrases", "[", ":", "i", "]", "+", "all_textual_vn_phrases", "[", "i", "+", "1", ":", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "other_logical_expressions", ")", ")", ":", "\n", "                ", "if", "all_logical_expressions", "[", "i", "]", "[", "1", "]", "==", "other_logical_expressions", "[", "j", "]", "[", "0", "]", ":", "\n", "                    ", "trans_cur_logical_expression", "=", "[", "all_logical_expressions", "[", "i", "]", "[", "0", "]", ",", "other_logical_expressions", "[", "j", "]", "[", "1", "]", "]", "\n", "if", "trans_cur_logical_expression", "not", "in", "all_logical_expressions", "+", "cur_extended_logical_expression", ":", "\n", "                        ", "cur_extended_logical_expression", ".", "append", "(", "trans_cur_logical_expression", ")", "\n", "cur_extended_textual_vn_phrases", ".", "append", "(", "[", "all_textual_vn_phrases", "[", "i", "]", "[", "0", "]", ",", "other_textual_vn_phrases", "[", "j", "]", "[", "1", "]", "]", ")", "\n", "\n", "", "", "", "", "return", "cur_extended_logical_expression", ",", "cur_extended_textual_vn_phrases", "\n", "\n", "", "whether_continue", "=", "True", "\n", "\n", "while", "whether_continue", ":", "\n", "        ", "cur_rever_extended_logical_expression", ",", "cur_rever_extended_textual_vn_phrases", "=", "reverse_logic", "(", "all_textual_vn_phrases", "+", "extended_textual_vn_phrases", ",", "all_logical_expressions", "+", "extended_logical_expression", ")", "\n", "extended_logical_expression", "+=", "cur_rever_extended_logical_expression", "\n", "extended_textual_vn_phrases", "+=", "cur_rever_extended_textual_vn_phrases", "\n", "\n", "cur_trans_extended_logical_expression", ",", "cur_trans_extended_textual_vn_phrases", "=", "transfer_logic", "(", "all_textual_vn_phrases", "+", "extended_textual_vn_phrases", ",", "all_logical_expressions", "+", "extended_logical_expression", ")", "\n", "extended_logical_expression", "+=", "cur_trans_extended_logical_expression", "\n", "extended_textual_vn_phrases", "+=", "cur_trans_extended_textual_vn_phrases", "\n", "\n", "if", "len", "(", "cur_rever_extended_logical_expression", ")", "+", "len", "(", "cur_trans_extended_logical_expression", ")", "==", "0", ":", "\n", "            ", "whether_continue", "=", "False", "\n", "\n", "", "", "return", "all_logical_expressions", ",", "all_textual_vn_phrases", ",", "extended_logical_expression", ",", "extended_textual_vn_phrases", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.logical_expression_to_text": [[399, 459], ["len", "len"], "function", ["None"], ["", "def", "logical_expression_to_text", "(", "logical_expression", ",", "vn_phrases", ")", ":", "\n", "\n", "    ", "first_phrase", ",", "first_nega_tag", "=", "vn_phrases", "[", "0", "]", ",", "logical_expression", "[", "0", "]", "[", "1", "]", "\n", "second_phrase", ",", "second_nega_tag", "=", "vn_phrases", "[", "1", "]", ",", "logical_expression", "[", "1", "]", "[", "1", "]", "\n", "\n", "# first_verb_type = nltk.pos_tag([first_phrase[0][0]])[0][1]", "\n", "# second_verb_type = nltk.pos_tag([second_phrase[0][0]])[0][1]", "\n", "\n", "first_text", "=", "\"If \"", "\n", "if", "len", "(", "first_phrase", ")", ">", "0", ":", "\n", "        ", "if", "'VB'", "in", "first_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "            ", "if", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                ", "first_text", "+=", "\"it \"", "\n", "", "else", ":", "\n", "                ", "first_text", "+=", "\"you \"", "\n", "", "", "else", ":", "\n", "            ", "first_text", "+=", "\"it is \"", "\n", "\n", "", "if", "first_nega_tag", "is", "True", ":", "\n", "            ", "if", "'VB'", "in", "first_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "                ", "if", "first_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                    ", "if", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                        ", "first_text", "+=", "\"does not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "elif", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBD\"", ":", "\n", "                        ", "first_text", "+=", "\"did not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "else", ":", "\n", "                        ", "first_text", "+=", "\"do not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "                    ", "first_text", "+=", "first_phrase", "[", "0", "]", "[", "0", "]", "+", "\" not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "[", "1", ":", "]", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "                ", "first_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "            ", "first_text", "+=", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "\n", "", "", "second_text", "=", "\"then \"", "\n", "if", "len", "(", "second_phrase", ")", ">", "0", ":", "\n", "\n", "        ", "if", "'VB'", "in", "second_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "            ", "if", "second_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                ", "second_text", "+=", "\"it will \"", "\n", "", "else", ":", "\n", "                ", "second_text", "+=", "\"you will \"", "\n", "", "", "else", ":", "\n", "            ", "second_text", "+=", "\"it will be \"", "\n", "\n", "", "if", "second_nega_tag", "is", "True", ":", "\n", "            ", "if", "'VB'", "in", "second_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "                ", "if", "second_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                    ", "second_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "else", ":", "\n", "                    ", "second_text", "+=", "\"be not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "[", "1", ":", "]", "]", ")", "+", "\".\"", "\n", "", "", "else", ":", "\n", "                ", "second_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "", "else", ":", "\n", "            ", "if", "second_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                ", "second_text", "+=", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "else", ":", "\n", "                ", "second_text", "+=", "\"be \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "[", "1", ":", "]", "]", ")", "+", "\".\"", "\n", "\n", "", "", "", "return", "first_text", "+", "\" \"", "+", "second_text", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.has_overlap_logical_component": [[462, 480], ["range", "len", "set", "range", "construct_negative_samples_v2.has_keyword", "len", "set", "list", "construct_negative_samples_v2.has_keyword", "list", "len", "max", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "has_overlap_logical_component", "(", "answer_vnps", ",", "prem_vnps", ",", "answer_nega_tags", ",", "prem_nega_tags", ")", ":", "\n", "# print(answer_vnps, answer_nega_tags)", "\n", "# print(prem_vnps, prem_nega_tags)", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "answer_vnps", ")", ")", ":", "\n", "        ", "answ_vnp_i", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "answer_vnps", "[", "i", "]", "]", ")", "\n", "answ_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "answ_vnp_i", ")", ")", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "prem_vnps", ")", ")", ":", "\n", "            ", "prem_vnp_j", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "prem_vnps", "[", "j", "]", "]", ")", "\n", "\n", "# hyper-parameter: 0.7", "\n", "prem_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "prem_vnp_j", ")", ")", "[", "0", "]", "\n", "if", "(", "answ_degree_kw_index", ">=", "0", "and", "prem_degree_kw_index", "<", "0", ")", "or", "(", "answ_degree_kw_index", "<", "0", "and", "prem_degree_kw_index", ">=", "0", ")", ":", "\n", "                ", "return", "False", "\n", "", "if", "len", "(", "answ_vnp_i", "&", "prem_vnp_j", ")", "/", "max", "(", "len", "(", "answ_vnp_i", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "if", "answer_nega_tags", "[", "i", "]", "==", "prem_nega_tags", "[", "j", "]", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.has_overlap_logical_component_rate": [[483, 502], ["range", "len", "set", "range", "construct_negative_samples_v2.has_keyword", "len", "set", "list", "construct_negative_samples_v2.has_keyword", "list", "len", "max", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "has_overlap_logical_component_rate", "(", "answer_vnps", ",", "prem_vnps", ",", "answer_nega_tags", ",", "prem_nega_tags", ")", ":", "\n", "    ", "overlap_num", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "answer_vnps", ")", ")", ":", "\n", "        ", "answ_vnp_i", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "answer_vnps", "[", "i", "]", "]", ")", "\n", "answ_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "answ_vnp_i", ")", ")", "[", "0", "]", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "prem_vnps", ")", ")", ":", "\n", "            ", "prem_vnp_j", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "prem_vnps", "[", "j", "]", "]", ")", "\n", "\n", "prem_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "prem_vnp_j", ")", ")", "[", "0", "]", "\n", "if", "(", "answ_degree_kw_index", ">=", "0", "and", "prem_degree_kw_index", "<", "0", ")", "or", "(", "answ_degree_kw_index", "<", "0", "and", "prem_degree_kw_index", ">=", "0", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "len", "(", "answ_vnp_i", "&", "prem_vnp_j", ")", "/", "max", "(", "len", "(", "answ_vnp_i", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "if", "answer_nega_tags", "[", "i", "]", "==", "prem_nega_tags", "[", "j", "]", ":", "\n", "                    ", "overlap_num", "+=", "1", "\n", "break", "\n", "\n", "", "", "", "", "return", "overlap_num", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_logical_expression": [[505, 554], ["random.random", "len", "zip", "random.random", "len", "bool", "bool", "bool", "bool"], "function", ["None"], ["", "def", "get_negative_logical_expression", "(", "vn_phrases", ",", "negative_tags", ",", "compo_tags", ")", ":", "\n", "    ", "logical_expressions", "=", "[", "[", "x", ",", "y", "]", "for", "x", ",", "y", "in", "zip", "(", "compo_tags", ",", "negative_tags", ")", "]", "\n", "random_num", "=", "random", ".", "random", "(", ")", "\n", "is_delete", ",", "is_reverse", ",", "first_negative", "=", "False", ",", "False", ",", "False", "\n", "# if random_num > 0.65:", "\n", "#     is_delete = True", "\n", "# elif random_num > 0.3 and random_num <= 0.65:", "\n", "#     is_reverse = True", "\n", "# else:", "\n", "#     first_negative = random.random() > 0.5", "\n", "\n", "if", "random_num", ">", "0.75", ":", "\n", "        ", "is_delete", "=", "True", "\n", "", "elif", "random_num", ">", "0.35", "and", "random_num", "<=", "0.75", ":", "\n", "        ", "is_reverse", "=", "True", "\n", "", "else", ":", "\n", "        ", "first_negative", "=", "random", ".", "random", "(", ")", ">", "0.5", "\n", "\n", "", "if", "len", "(", "vn_phrases", ")", "<", "2", ":", "\n", "        ", "negative_logical_expression", "=", "None", "\n", "negative_textual_vn_phrases", "=", "None", "\n", "", "elif", "is_delete", ":", "\n", "        ", "negative_logical_expression", "=", "None", "\n", "negative_textual_vn_phrases", "=", "None", "\n", "", "elif", "len", "(", "vn_phrases", ")", "==", "2", ":", "\n", "        ", "if", "is_reverse", ":", "\n", "            ", "negative_logical_expression", "=", "logical_expressions", "[", ":", ":", "-", "1", "]", "\n", "negative_textual_vn_phrases", "=", "vn_phrases", "[", ":", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "if", "first_negative", ":", "\n", "                ", "negative_logical_expression", "=", "[", "[", "logical_expressions", "[", "0", "]", "[", "0", "]", ",", "bool", "(", "1", "-", "logical_expressions", "[", "0", "]", "[", "1", "]", ")", "]", ",", "logical_expressions", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "                ", "negative_logical_expression", "=", "[", "logical_expressions", "[", "0", "]", ",", "[", "logical_expressions", "[", "1", "]", "[", "0", "]", ",", "bool", "(", "1", "-", "logical_expressions", "[", "1", "]", "[", "1", "]", ")", "]", "]", "\n", "", "negative_textual_vn_phrases", "=", "vn_phrases", "\n", "", "", "else", ":", "\n", "        ", "if", "is_reverse", ":", "\n", "            ", "negative_logical_expression", "=", "logical_expressions", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", "\n", "negative_textual_vn_phrases", "=", "vn_phrases", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "if", "first_negative", ":", "\n", "                ", "negative_logical_expression", "=", "[", "[", "logical_expressions", "[", "0", "]", "[", "0", "]", ",", "bool", "(", "1", "-", "logical_expressions", "[", "0", "]", "[", "1", "]", ")", "]", ",", "logical_expressions", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "                ", "negative_logical_expression", "=", "[", "logical_expressions", "[", "0", "]", ",", "[", "logical_expressions", "[", "1", "]", "[", "0", "]", ",", "bool", "(", "1", "-", "logical_expressions", "[", "1", "]", "[", "1", "]", ")", "]", "]", "\n", "", "negative_textual_vn_phrases", "=", "vn_phrases", "[", ":", "2", "]", "\n", "\n", "# print(\"*\"*100)", "\n", "# print(negative_logical_expression)", "\n", "# print(negative_textual_vn_phrases)", "\n", "", "", "return", "negative_logical_expression", ",", "negative_textual_vn_phrases", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_context_for_each_prem": [[557, 588], ["construct_negative_samples_v2.get_negative_logical_expression", "context.find", "nltk.sent_tokenize", "set", "range", "len", "construct_negative_samples_v2.logical_expression_to_text", "nltk.word_tokenize", "len", "len", "len", "len", "set", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.logical_expression_to_text"], ["", "def", "get_negative_context_for_each_prem", "(", "prem_vn_phrases", ",", "prem_negative_tags", ",", "prem_compo_tags", ",", "each_premise", ",", "context", ")", ":", "\n", "    ", "negative_logical_expression", ",", "negative_textual_vn_phrases", "=", "get_negative_logical_expression", "(", "prem_vn_phrases", ",", "prem_negative_tags", ",", "prem_compo_tags", ")", "\n", "if", "negative_logical_expression", "is", "not", "None", ":", "\n", "        ", "negative_sentence", "=", "logical_expression_to_text", "(", "negative_logical_expression", ",", "negative_textual_vn_phrases", ")", "+", "\" \"", "\n", "", "else", ":", "\n", "        ", "negative_sentence", "=", "\"\"", "\n", "\n", "", "not_find", "=", "1", "\n", "prem_location", "=", "context", ".", "find", "(", "each_premise", ")", "\n", "if", "prem_location", ">=", "0", ":", "\n", "        ", "negative_context", "=", "context", "[", ":", "prem_location", "]", "+", "negative_sentence", "+", "context", "[", "prem_location", "+", "len", "(", "each_premise", ")", "+", "1", ":", "]", "\n", "", "else", ":", "\n", "        ", "context_sents", "=", "nltk", ".", "sent_tokenize", "(", "context", ")", "\n", "prem_tokens", "=", "set", "(", "nltk", ".", "word_tokenize", "(", "each_premise", ")", ")", "\n", "prem_index", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "context_sents", ")", ")", ":", "\n", "            ", "if", "len", "(", "set", "(", "nltk", ".", "word_tokenize", "(", "context_sents", "[", "i", "]", ")", ")", "&", "prem_tokens", ")", "/", "len", "(", "prem_tokens", ")", ">", "0.8", ":", "\n", "                ", "prem_index", "=", "i", "\n", "break", "\n", "", "", "if", "prem_index", ">=", "0", ":", "\n", "            ", "negative_context", "=", "\" \"", ".", "join", "(", "context_sents", "[", ":", "prem_index", "]", ")", "+", "\" \"", "+", "negative_sentence", "+", "\" \"", ".", "join", "(", "context_sents", "[", "prem_index", "+", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "# print(\"context\", context)", "\n", "# print(\"premise\", each_premise)", "\n", "# print(\"*\"*100)", "\n", "# print(set(nltk.word_tokenize(context_sents[0])) & prem_tokens)", "\n", "# print(len(set(nltk.word_tokenize(context_sents[0])) & prem_tokens), len(prem_tokens))", "\n", "            ", "negative_context", "=", "\" \"", "\n", "not_find", "=", "0", "\n", "\n", "", "", "return", "negative_context", ",", "len", "(", "negative_sentence", ")", ",", "not_find", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_cur_negative_context": [[591, 631], ["construct_negative_samples_v2.extract_logical_variables", "construct_negative_samples_v2.identify_condition", "construct_negative_samples_v2.identify_logical_expression", "nltk.sent_tokenize", "construct_negative_samples_v2.extract_logical_variables", "construct_negative_samples_v2.identify_condition", "construct_negative_samples_v2.identify_logical_expression", "construct_negative_samples_v2.get_negative_context_for_each_prem", "nltk.sent_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_condition", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_condition", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_context_for_each_prem"], ["", "def", "get_cur_negative_context", "(", "conclusion", ",", "premises", ",", "answer_list", ",", "context", ",", "which_prem", ",", "none_premise", "=", "False", ")", ":", "\n", "# context_sents = nltk.sent_tokenize(context)", "\n", "# return \" \".join(context_sents[:-2]), 1, 1", "\n", "\n", "# if len(premises) == 0:", "\n", "    ", "if", "none_premise", ":", "\n", "        ", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "conc_vn_phrases", ",", "conc_negative_tags", "=", "extract_logical_variables", "(", "conclusion", ",", "premises", ",", "answer_list", ")", "\n", "\n", "all_prem_vn_phrases", "=", "all_prem_vn_phrases", "+", "conc_vn_phrases", "\n", "all_prem_negative_tags", "=", "all_prem_negative_tags", "+", "conc_negative_tags", "\n", "all_prem_vn_phrases", ",", "all_prem_negative_tags", "=", "identify_condition", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ")", "\n", "\n", "all_prem_compo_tags", "=", "identify_logical_expression", "(", "all_prem_vn_phrases", ")", "\n", "left_logical_expressions", "=", "[", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", "]", "\n", "\n", "context_sents", "=", "nltk", ".", "sent_tokenize", "(", "context", ")", "\n", "return", "\" \"", ".", "join", "(", "context_sents", "[", ":", "which_prem", "]", "+", "context_sents", "[", "which_prem", "+", "1", ":", "]", ")", ",", "1", ",", "1", ",", "left_logical_expressions", "\n", "", "else", ":", "\n", "        ", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "conc_vn_phrases", ",", "conc_negative_tags", "=", "extract_logical_variables", "(", "conclusion", ",", "premises", ",", "answer_list", ")", "\n", "\n", "all_prem_vn_phrases", "=", "all_prem_vn_phrases", "+", "conc_vn_phrases", "\n", "all_prem_negative_tags", "=", "all_prem_negative_tags", "+", "conc_negative_tags", "\n", "all_prem_vn_phrases", ",", "all_prem_negative_tags", "=", "identify_condition", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ")", "\n", "\n", "all_prem_compo_tags", "=", "identify_logical_expression", "(", "all_prem_vn_phrases", ")", "\n", "\n", "cur_premise", "=", "nltk", ".", "sent_tokenize", "(", "context", ")", "[", "which_prem", "]", "\n", "negative_context", ",", "negative_sent_len", ",", "not_find", "=", "get_negative_context_for_each_prem", "(", "all_prem_vn_phrases", "[", "which_prem", "]", ",", "all_prem_negative_tags", "[", "which_prem", "]", ",", "all_prem_compo_tags", "[", "which_prem", "]", ",", "cur_premise", ",", "context", ")", "\n", "\n", "left_prem_vn_phrases", "=", "all_prem_vn_phrases", "[", ":", "which_prem", "]", "+", "all_prem_vn_phrases", "[", "which_prem", "+", "1", ":", "]", "\n", "left_prem_negative_tags", "=", "all_prem_negative_tags", "[", ":", "which_prem", "]", "+", "all_prem_negative_tags", "[", "which_prem", "+", "1", ":", "]", "\n", "left_prem_compo_tags", "=", "all_prem_compo_tags", "[", ":", "which_prem", "]", "+", "all_prem_compo_tags", "[", "which_prem", "+", "1", ":", "]", "\n", "\n", "left_logical_expressions", "=", "[", "left_prem_vn_phrases", ",", "left_prem_negative_tags", ",", "left_prem_compo_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", "]", "\n", "\n", "return", "negative_context", ",", "negative_sent_len", ",", "not_find", ",", "left_logical_expressions", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_cur_negative_context_degree_two": [[634, 702], ["len", "nltk.sent_tokenize", "len", "nltk.sent_tokenize", "set", "range", "construct_negative_samples_v2.extract_logical_variables", "construct_negative_samples_v2.identify_logical_expression", "construct_negative_samples_v2.get_negative_context_for_each_prem", "construct_negative_samples_v2.extract_logical_variables", "construct_negative_samples_v2.identify_logical_expression", "random.sample", "construct_negative_samples_v2.get_negative_context_for_each_prem", "nltk.word_tokenize", "len", "print", "print", "len", "range", "len", "construct_negative_samples_v2.get_negative_context_for_each_prem", "len", "len", "len", "len", "min", "min", "set", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_context_for_each_prem", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_context_for_each_prem", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_negative_context_for_each_prem"], ["", "", "def", "get_cur_negative_context_degree_two", "(", "conclusion", ",", "premises", ",", "answer_list", ",", "context", ")", ":", "\n", "    ", "if", "len", "(", "premises", ")", "==", "0", ":", "\n", "        ", "context_sents", "=", "nltk", ".", "sent_tokenize", "(", "context", ")", "\n", "return", "\" \"", ".", "join", "(", "context_sents", "[", ":", "-", "2", "]", ")", ",", "1", ",", "1", "\n", "", "elif", "len", "(", "premises", ")", "==", "1", ":", "\n", "        ", "context_sents", "=", "nltk", ".", "sent_tokenize", "(", "context", ")", "\n", "prem_tokens", "=", "set", "(", "nltk", ".", "word_tokenize", "(", "premises", "[", "0", "]", ")", ")", "\n", "delete_index", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "context_sents", ")", ")", ":", "\n", "            ", "if", "len", "(", "set", "(", "nltk", ".", "word_tokenize", "(", "context_sents", "[", "i", "]", ")", ")", "&", "prem_tokens", ")", "/", "len", "(", "prem_tokens", ")", "<=", "0.8", ":", "\n", "                ", "delete_index", "=", "i", "\n", "break", "\n", "", "", "if", "delete_index", ">=", "0", ":", "\n", "            ", "context", "=", "\" \"", ".", "join", "(", "context_sents", "[", ":", "delete_index", "]", ")", "+", "\" \"", "+", "\" \"", ".", "join", "(", "context_sents", "[", "delete_index", "+", "1", ":", "]", ")", "\n", "\n", "", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "conc_vn_phrases", ",", "conc_negative_tags", "=", "extract_logical_variables", "(", "conclusion", ",", "premises", ",", "answer_list", ")", "\n", "all_prem_compo_tags", "=", "identify_logical_expression", "(", "all_prem_vn_phrases", ")", "\n", "\n", "which_prem", "=", "0", "\n", "negative_context", ",", "negative_sent_len", ",", "not_find", "=", "get_negative_context_for_each_prem", "(", "all_prem_vn_phrases", "[", "which_prem", "]", ",", "all_prem_negative_tags", "[", "which_prem", "]", ",", "all_prem_compo_tags", "[", "which_prem", "]", ",", "premises", "[", "which_prem", "]", ",", "context", ")", "\n", "if", "not", "not_find", ":", "\n", "            ", "print", "(", "'not find'", ",", "negative_context", ")", "\n", "print", "(", "premises", "[", "which_prem", "]", ")", "\n", "", "if", "len", "(", "negative_context", ")", "==", "0", ":", "\n", "            ", "negative_context", "=", "\" \"", ".", "join", "(", "context_sents", "[", ":", "-", "1", "]", ")", "\n", "", "return", "negative_context", ",", "negative_sent_len", ",", "not_find", "\n", "", "else", ":", "\n", "        ", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "conc_vn_phrases", ",", "conc_negative_tags", "=", "extract_logical_variables", "(", "conclusion", ",", "premises", ",", "answer_list", ")", "\n", "\n", "all_prem_compo_tags", "=", "identify_logical_expression", "(", "all_prem_vn_phrases", ")", "\n", "\n", "# which_prem = [0, 1]", "\n", "\n", "# which_prem = -1", "\n", "# for k in range(len(all_prem_vn_phrases)):", "\n", "#     if len(all_prem_vn_phrases[k]) >= 2:", "\n", "#         which_prem = k", "\n", "#         break", "\n", "# if which_prem < 0:", "\n", "#     which_prem = 0", "\n", "\n", "which_prem", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "all_prem_vn_phrases", ")", ")", ",", "2", ")", "\n", "\n", "# valid_list = list()", "\n", "# for k in range(len(all_prem_vn_phrases)):", "\n", "#     if len(all_prem_vn_phrases[k]) >= 2:", "\n", "#         valid_list.append(k)", "\n", "# if len(valid_list) > 0:", "\n", "#     which_prem = random.sample(valid_list, 1)[0]", "\n", "# else:", "\n", "#     which_prem = 0", "\n", "\n", "negative_context", ",", "negative_sent_len_1", ",", "not_find_1", "=", "get_negative_context_for_each_prem", "(", "all_prem_vn_phrases", "[", "which_prem", "[", "0", "]", "]", ",", "all_prem_negative_tags", "[", "which_prem", "[", "0", "]", "]", ",", "all_prem_compo_tags", "[", "which_prem", "[", "0", "]", "]", ",", "premises", "[", "which_prem", "[", "0", "]", "]", ",", "context", ")", "\n", "if", "len", "(", "negative_context", ")", ">", "0", ":", "\n", "            ", "negative_context_2", ",", "negative_sent_len_2", ",", "not_find_2", "=", "get_negative_context_for_each_prem", "(", "all_prem_vn_phrases", "[", "which_prem", "[", "1", "]", "]", ",", "all_prem_negative_tags", "[", "which_prem", "[", "1", "]", "]", ",", "all_prem_compo_tags", "[", "which_prem", "[", "1", "]", "]", ",", "premises", "[", "which_prem", "[", "1", "]", "]", ",", "negative_context", ")", "\n", "# if not not_find_2:", "\n", "#     print(\"context\", context)", "\n", "#     print(\"premise\", premises[:2])", "\n", "if", "len", "(", "negative_context_2", ")", "==", "0", ":", "\n", "                ", "return", "negative_context", ",", "negative_sent_len_1", ",", "not_find_1", "\n", "", "else", ":", "\n", "                ", "return", "negative_context_2", ",", "min", "(", "negative_sent_len_1", ",", "negative_sent_len_2", ")", ",", "min", "(", "not_find_1", ",", "not_find_2", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "negative_context", ",", "negative_sent_len_1", ",", "not_find_1", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_cur_all_extended_text": [[722, 791], ["list", "list", "construct_negative_samples_v2.spread_logical_expressions", "construct_negative_samples_v2.infer_logical_expression", "list", "range", "max", "max", "len", "len", "construct_negative_samples_v2.has_overlap_logical_component", "len", "list.append", "len", "list.append", "construct_negative_samples_v2.logical_expression_to_text", "list.append", "len", "list.append", "random.sample", "list.append", "len", "list.append", "len", "len", "range", "len", "list.append", "random.sample", "list.append", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.spread_logical_expressions", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.infer_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_overlap_logical_component", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.logical_expression_to_text"], ["def", "get_cur_all_extended_text", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", ",", "cur_ans_vn_phrases", ",", "cur_ans_negative_tags", ")", ":", "\n", "    ", "all_extended_contexts_2", "=", "list", "(", ")", "\n", "all_extended_contexts_3", "=", "list", "(", ")", "\n", "\n", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", "=", "spread_logical_expressions", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", ")", "\n", "all_logical_expressions", ",", "all_textual_vn_phrases", ",", "extended_logical_expression", ",", "extended_textual_vn_phrases", "=", "infer_logical_expression", "(", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", ")", "\n", "\n", "if", "len", "(", "extended_logical_expression", ")", ">", "0", ":", "\n", "        ", "has_extended", "=", "1", "\n", "", "else", ":", "\n", "        ", "has_extended", "=", "0", "\n", "\n", "", "cur_answ_extended_contexts", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "extended_logical_expression", ")", ")", ":", "\n", "        ", "extended_negative_tags", "=", "[", "each", "[", "1", "]", "for", "each", "in", "extended_logical_expression", "[", "i", "]", "]", "\n", "whether_extend", "=", "has_overlap_logical_component", "(", "cur_ans_vn_phrases", ",", "extended_textual_vn_phrases", "[", "i", "]", ",", "cur_ans_negative_tags", ",", "extended_negative_tags", ")", "\n", "\n", "if", "whether_extend", ":", "\n", "            ", "extended_text", "=", "logical_expression_to_text", "(", "extended_logical_expression", "[", "i", "]", ",", "extended_textual_vn_phrases", "[", "i", "]", ")", "\n", "cur_answ_extended_contexts", ".", "append", "(", "extended_text", ")", "\n", "\n", "# if len(extended_logical_expression) == 0:", "\n", "#     all_extended_contexts.append(\"\")", "\n", "# elif len(extended_logical_expression) == 1:", "\n", "#     extended_text = logical_expression_to_text(extended_logical_expression[0], extended_textual_vn_phrases[0])", "\n", "#     all_extended_contexts.append(extended_text)", "\n", "# elif len(extended_logical_expression) >= 2:", "\n", "#     sample_index = random.sample(range(len(extended_logical_expression)), 2)", "\n", "#     extended_text_1 = logical_expression_to_text(extended_logical_expression[sample_index[0]], extended_textual_vn_phrases[sample_index[0]])", "\n", "#     extended_text_2 = logical_expression_to_text(extended_logical_expression[sample_index[1]], extended_textual_vn_phrases[sample_index[1]])", "\n", "#     all_extended_contexts.append(extended_text_1 + \" \" + extended_text_2)", "\n", "\n", "# if len(extended_logical_expression) == 0:", "\n", "#     all_extended_contexts.append(\"\")", "\n", "# elif len(extended_logical_expression) == 1:", "\n", "#     extended_text = logical_expression_to_text(extended_logical_expression[0], extended_textual_vn_phrases[0])", "\n", "#     all_extended_contexts.append(extended_text)", "\n", "# elif len(extended_logical_expression) == 2:", "\n", "#     extended_text_1 = logical_expression_to_text(extended_logical_expression[0], extended_textual_vn_phrases[0])", "\n", "#     extended_text_2 = logical_expression_to_text(extended_logical_expression[1], extended_textual_vn_phrases[1])", "\n", "#     all_extended_contexts.append(extended_text_1 + \" \" + extended_text_2)", "\n", "# elif len(extended_logical_expression) >= 3:", "\n", "#     sample_index = random.sample(range(len(extended_logical_expression)), 3)", "\n", "#     extended_text_1 = logical_expression_to_text(extended_logical_expression[sample_index[0]], extended_textual_vn_phrases[sample_index[0]])", "\n", "#     extended_text_2 = logical_expression_to_text(extended_logical_expression[sample_index[1]], extended_textual_vn_phrases[sample_index[1]])", "\n", "#     extended_text_3 = logical_expression_to_text(extended_logical_expression[sample_index[2]], extended_textual_vn_phrases[sample_index[2]])", "\n", "#     all_extended_contexts.append(extended_text_1 + \" \" + extended_text_2 + \" \" + extended_text_3)", "\n", "\n", "", "", "if", "len", "(", "cur_answ_extended_contexts", ")", "==", "0", ":", "\n", "        ", "all_extended_contexts_2", ".", "append", "(", "\"\"", ")", "\n", "", "elif", "len", "(", "cur_answ_extended_contexts", ")", "==", "1", ":", "\n", "        ", "all_extended_contexts_2", ".", "append", "(", "cur_answ_extended_contexts", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "sample_index", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "cur_answ_extended_contexts", ")", ")", ",", "2", ")", "\n", "all_extended_contexts_2", ".", "append", "(", "cur_answ_extended_contexts", "[", "sample_index", "[", "0", "]", "]", "+", "\" \"", "+", "cur_answ_extended_contexts", "[", "sample_index", "[", "1", "]", "]", ")", "\n", "\n", "", "if", "len", "(", "cur_answ_extended_contexts", ")", "==", "0", ":", "\n", "        ", "all_extended_contexts_3", ".", "append", "(", "\"\"", ")", "\n", "", "elif", "len", "(", "cur_answ_extended_contexts", ")", "==", "1", ":", "\n", "        ", "all_extended_contexts_3", ".", "append", "(", "cur_answ_extended_contexts", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "cur_answ_extended_contexts", ")", "==", "2", ":", "\n", "        ", "all_extended_contexts_3", ".", "append", "(", "cur_answ_extended_contexts", "[", "0", "]", "+", "\" \"", "+", "cur_answ_extended_contexts", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "sample_index", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "cur_answ_extended_contexts", ")", ")", ",", "3", ")", "\n", "all_extended_contexts_3", ".", "append", "(", "cur_answ_extended_contexts", "[", "sample_index", "[", "0", "]", "]", "+", "\" \"", "+", "cur_answ_extended_contexts", "[", "sample_index", "[", "1", "]", "]", "+", "\" \"", "+", "cur_answ_extended_contexts", "[", "sample_index", "[", "2", "]", "]", ")", "\n", "\n", "", "max_length_2", "=", "max", "(", "[", "len", "(", "each", ")", "for", "each", "in", "all_extended_contexts_2", "]", ")", "\n", "max_length_3", "=", "max", "(", "[", "len", "(", "each", ")", "for", "each", "in", "all_extended_contexts_3", "]", ")", "\n", "return", "all_extended_contexts_2", "[", "0", "]", ",", "all_extended_contexts_3", "[", "0", "]", ",", "(", "max_length_2", ",", "max_length_3", ",", "has_extended", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.save_all_negative_context": [[792, 918], ["numpy.load", "numpy.load", "list", "list", "list", "list", "list", "tqdm.tqdm", "print", "print", "numpy.save", "numpy.save", "numpy.save", "open", "json.load", "range", "list", "list", "list", "zip", "list.append", "list.append", "list.append", "len", "list.append", "len", "len", "nltk.sent_tokenize", "random.sample", "random.sample", "construct_negative_samples_v2.get_cur_negative_context", "list.append", "construct_negative_samples_v2.get_cur_all_extended_text", "list.append", "list.append", "list.append", "list.append", "range", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.construct_negative_samples_v2.get_cur_negative_context", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.get_cur_all_extended_text"], ["", "def", "save_all_negative_context", "(", "data_type", "=", "0", ")", ":", "\n", "    ", "if", "data_type", "==", "0", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/train_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/train_options_constituents_file.npy'", "\n", "negative_context_file", "=", "'../reclor-data/train_negative_context_cp_v19.npy'", "\n", "# negative_context_file = '../reclor-data/train_negative_context_cp_v103.npy'", "\n", "extended_context_file_2", "=", "'../reclor-data/train_extended_context_cp_v195.npy'", "\n", "extended_context_file_3", "=", "'../reclor-data/train_extended_context_cp_v196.npy'", "\n", "lr_file", "=", "'../reclor-data/train.json'", "\n", "", "elif", "data_type", "==", "1", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/val_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/val_options_constituents_file.npy'", "\n", "negative_context_file", "=", "'../reclor-data/val_negative_context_cp_v19.npy'", "\n", "# negative_context_file = '../reclor-data/val_negative_context_cp_v103.npy'", "\n", "extended_context_file_2", "=", "'../reclor-data/val_extended_context_cp_v195.npy'", "\n", "extended_context_file_3", "=", "'../reclor-data/val_extended_context_cp_v196.npy'", "\n", "lr_file", "=", "'../reclor-data/val.json'", "\n", "", "else", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/test_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/test_options_constituents_file.npy'", "\n", "negative_context_file", "=", "'../reclor-data/test_negative_context_cp_v19.npy'", "\n", "# negative_context_file = '../reclor-data/test_negative_context_cp_v103.npy'", "\n", "extended_context_file_2", "=", "'../reclor-data/test_extended_context_cp_v195.npy'", "\n", "extended_context_file_3", "=", "'../reclor-data/test_extended_context_cp_v196.npy'", "\n", "lr_file", "=", "'../reclor-data/test.json'", "\n", "\n", "", "conclusions_premises_constituents", "=", "np", ".", "load", "(", "all_context_constituents_file", ")", "\n", "answers_constituents", "=", "np", ".", "load", "(", "all_options_constituents_file", ")", "\n", "\n", "contexts", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "with", "open", "(", "lr_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "each", "in", "lines", ":", "\n", "            ", "contexts", ".", "append", "(", "each", "[", "\"context\"", "]", ")", "\n", "if", "data_type", "==", "2", ":", "\n", "                ", "labels", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "labels", ".", "append", "(", "each", "[", "\"label\"", "]", ")", "\n", "\n", "", "", "", "not_find_num", ",", "delete_num", ",", "same_num", ",", "none_negative_context_num", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "all_negative_contexts", "=", "list", "(", ")", "\n", "all_extended_contexts_2", "=", "list", "(", ")", "\n", "all_extended_contexts_3", "=", "list", "(", ")", "\n", "has_extend_instance_num", ",", "has_extend_context_num", "=", "0", ",", "0", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "conclusions_premises_constituents", ")", ")", ")", ":", "\n", "        ", "conclusions", "=", "[", "]", "\n", "premises", "=", "conclusions_premises_constituents", "[", "i", "]", "\n", "answer_list", "=", "answers_constituents", "[", "i", "]", "\n", "\n", "# if len(premises) == 0:", "\n", "#     context_sents = nltk.sent_tokenize(contexts[i])", "\n", "#     if len(context_sents) >= 2:", "\n", "#         which_prem_list = random.sample(range(len(context_sents)), 2)", "\n", "#     else:", "\n", "#         which_prem_list = [0, 0]", "\n", "#     none_premise_list = [True, True]", "\n", "# elif len(premises) == 1:", "\n", "#     context_sents = nltk.sent_tokenize(contexts[i])", "\n", "#     which_prem_list = [0,] + random.sample(range(len(context_sents)), 1)", "\n", "#     none_premise_list = [False, True]", "\n", "# else:", "\n", "#     which_prem_list = random.sample(range(len(premises)), 2)", "\n", "#     none_premise_list = [False, False]", "\n", "\n", "if", "len", "(", "premises", ")", "==", "0", ":", "\n", "            ", "context_sents", "=", "nltk", ".", "sent_tokenize", "(", "contexts", "[", "i", "]", ")", "\n", "which_prem_list", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "context_sents", ")", ")", ",", "1", ")", "\n", "none_premise_list", "=", "[", "True", "]", "\n", "", "else", ":", "\n", "            ", "which_prem_list", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "premises", ")", ")", ",", "1", ")", "\n", "none_premise_list", "=", "[", "False", "]", "\n", "\n", "# context_sents = nltk.sent_tokenize(contexts[i])", "\n", "# which_prem_list = random.sample(range(len(context_sents)), 1)", "\n", "# # which_prem_list = random.sample(list(range(i))+list(range(i+1, len(contexts))), 1)", "\n", "# none_premise_list = [True]", "\n", "\n", "", "cur_inst_negative_contexts", "=", "list", "(", ")", "\n", "cur_inst_extended_contexts_2", "=", "list", "(", ")", "\n", "cur_inst_extended_contexts_3", "=", "list", "(", ")", "\n", "\n", "for", "which_premise", ",", "none_premise", "in", "zip", "(", "which_prem_list", ",", "none_premise_list", ")", ":", "\n", "\n", "            ", "negative_context", ",", "delete", ",", "not_find", ",", "left_logical_expressions", "=", "get_cur_negative_context", "(", "conclusions", ",", "premises", ",", "answer_list", ",", "contexts", "[", "i", "]", ",", "which_premise", ",", "none_premise", ")", "\n", "if", "delete", "==", "0", ":", "\n", "                ", "delete_num", "+=", "1", "\n", "", "if", "not_find", "==", "0", ":", "\n", "                ", "not_find_num", "+=", "1", "\n", "", "if", "negative_context", "==", "contexts", ":", "\n", "                ", "same_num", "+=", "1", "\n", "", "if", "len", "(", "negative_context", ")", "==", "0", ":", "\n", "                ", "none_negative_context_num", "+=", "1", "\n", "\n", "# negative_context = contexts[which_premise]", "\n", "\n", "", "cur_inst_negative_contexts", ".", "append", "(", "negative_context", ")", "\n", "\n", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", "=", "left_logical_expressions", "[", ":", "3", "]", "\n", "cur_ans_vn_phrases", "=", "left_logical_expressions", "[", "3", "]", "[", "labels", "[", "i", "]", "]", "\n", "cur_ans_negative_tags", "=", "left_logical_expressions", "[", "4", "]", "[", "labels", "[", "i", "]", "]", "\n", "\n", "cur_all_extended_context_2", ",", "cur_all_extended_context_3", ",", "max_length", "=", "get_cur_all_extended_text", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", ",", "cur_ans_vn_phrases", ",", "cur_ans_negative_tags", ")", "\n", "\n", "if", "max_length", "[", "0", "]", ">", "0", ":", "\n", "                ", "has_extend_instance_num", "+=", "1", "\n", "", "if", "max_length", "[", "-", "1", "]", ">", "0", ":", "\n", "                ", "has_extend_context_num", "+=", "1", "\n", "\n", "", "cur_inst_extended_contexts_2", ".", "append", "(", "cur_all_extended_context_2", ")", "\n", "cur_inst_extended_contexts_3", ".", "append", "(", "cur_all_extended_context_3", ")", "\n", "\n", "", "all_negative_contexts", ".", "append", "(", "cur_inst_negative_contexts", ")", "\n", "all_extended_contexts_2", ".", "append", "(", "cur_inst_extended_contexts_2", ")", "\n", "all_extended_contexts_3", ".", "append", "(", "cur_inst_extended_contexts_3", ")", "\n", "\n", "", "print", "(", "\"negative\"", ",", "none_negative_context_num", ",", "delete_num", ",", "not_find_num", ",", "same_num", ",", "len", "(", "contexts", ")", ")", "\n", "print", "(", "\"extend\"", ",", "has_extend_instance_num", ",", "has_extend_context_num", ")", "\n", "\n", "# print(all_negative_contexts)", "\n", "# print(all_extended_contexts_2)", "\n", "\n", "np", ".", "save", "(", "negative_context_file", ",", "all_negative_contexts", ")", "\n", "np", ".", "save", "(", "extended_context_file_2", ",", "all_extended_contexts_2", ")", "\n", "np", ".", "save", "(", "extended_context_file_3", ",", "all_extended_contexts_3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword": [[23, 34], ["tokens.index", "len", "token_str.find", "nltk.word_tokenize", "len", "nltk.word_tokenize"], "function", ["None"], ["def", "has_keyword", "(", "keyword_list", ",", "tokens", ")", ":", "\n", "    ", "for", "each", "in", "keyword_list", ":", "\n", "        ", "if", "each", "in", "tokens", ":", "\n", "            ", "return", "tokens", ".", "index", "(", "each", ")", ",", "each", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "nltk", ".", "word_tokenize", "(", "each", ")", ")", ">", "1", ":", "\n", "                ", "token_str", "=", "\" \"", ".", "join", "(", "tokens", ")", "\n", "idx", "=", "token_str", ".", "find", "(", "each", ")", "\n", "if", "idx", ">=", "0", ":", "\n", "                    ", "return", "len", "(", "nltk", ".", "word_tokenize", "(", "token_str", "[", ":", "idx", "]", ")", ")", ",", "each", "\n", "", "", "", "", "return", "-", "1", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_same_logical_component": [[37, 68], ["list", "range", "list", "list", "vnp1_tokens.append", "vnp2_tokens.append", "len", "max", "len", "range", "list.append", "len", "set", "set", "len", "max", "len"], "function", ["None"], ["", "def", "has_same_logical_component", "(", "vnp1", ",", "vnp2", ",", "vnp1_compo_tags", ")", ":", "\n", "\n", "    ", "vnp1_tokens", ",", "vnp2_tokens", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "each_phrase", "in", "vnp1", ":", "\n", "        ", "vnp1_tokens", ".", "append", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "", "for", "each_phrase", "in", "vnp2", ":", "\n", "        ", "vnp2_tokens", ".", "append", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "# print(vnp1_tokens)", "\n", "# print(vnp2_tokens)", "\n", "\n", "", "vnp2_compo_tags", "=", "list", "(", ")", "\n", "if", "len", "(", "vnp1_compo_tags", ")", ">", "0", ":", "\n", "        ", "tag_record", "=", "max", "(", "vnp1_compo_tags", ")", "\n", "", "else", ":", "\n", "        ", "tag_record", "=", "-", "1", "\n", "", "for", "j", "in", "range", "(", "len", "(", "vnp2_tokens", ")", ")", ":", "\n", "        ", "has_same", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "vnp1_tokens", ")", ")", ":", "\n", "            ", "vnp1_i", "=", "set", "(", "vnp1_tokens", "[", "i", "]", ")", "\n", "vnp2_j", "=", "set", "(", "vnp2_tokens", "[", "j", "]", ")", "\n", "\n", "# hyper-parameter: 0.7", "\n", "if", "len", "(", "vnp1_i", "&", "vnp2_j", ")", "/", "max", "(", "len", "(", "vnp2_j", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "has_same", "=", "vnp1_compo_tags", "[", "i", "]", "\n", "break", "\n", "", "", "if", "has_same", "==", "-", "1", ":", "\n", "            ", "has_same", "=", "tag_record", "+", "1", "\n", "tag_record", "+=", "1", "\n", "\n", "", "vnp2_compo_tags", ".", "append", "(", "has_same", ")", "\n", "", "return", "vnp2_compo_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression": [[71, 95], ["list", "len", "Exception", "list", "range", "list.append", "range", "len", "list.append", "len", "list", "list", "range", "extract_logical_expressions_v2.has_same_logical_component", "list.append", "len", "print", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_same_logical_component"], ["", "def", "identify_logical_expression", "(", "premise_vn_phrases", ")", ":", "\n", "    ", "all_component_tags", "=", "list", "(", ")", "\n", "\n", "if", "len", "(", "premise_vn_phrases", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"No premises\"", ")", "\n", "", "else", ":", "\n", "        ", "vnp1_compo_tags", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "premise_vn_phrases", "[", "0", "]", ")", ")", ":", "\n", "            ", "vnp1_compo_tags", ".", "append", "(", "i", ")", "\n", "", "all_component_tags", ".", "append", "(", "vnp1_compo_tags", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "premise_vn_phrases", ")", ")", ":", "\n", "            ", "arg_1", "=", "list", "(", ")", "\n", "arg_3", "=", "list", "(", ")", "\n", "for", "k", "in", "range", "(", "j", ")", ":", "\n", "                ", "arg_1", "+=", "premise_vn_phrases", "[", "k", "]", "\n", "arg_3", "+=", "all_component_tags", "[", "k", "]", "\n", "", "vnpj_compo_tags", "=", "has_same_logical_component", "(", "arg_1", ",", "premise_vn_phrases", "[", "j", "]", ",", "arg_3", ")", "\n", "all_component_tags", ".", "append", "(", "vnpj_compo_tags", ")", "\n", "\n", "", "if", "len", "(", "premise_vn_phrases", ")", ">", "7", ":", "\n", "            ", "print", "(", "\"Exception: more than 6 premises\"", ",", "len", "(", "premise_vn_phrases", ")", ")", "\n", "\n", "", "", "return", "all_component_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables": [[97, 133], ["list", "list", "list", "list", "extract_logical_expressions_v2.extract_np_vnp_constituents", "extract_logical_expressions_v2.identify_positive_negative_vnp", "all_prem_vn_phrases.append", "all_prem_negative_tags.append", "list", "list", "extract_logical_expressions_v2.extract_np_vnp_constituents", "extract_logical_expressions_v2.identify_positive_negative_vnp", "all_ans_vn_phrases.append", "all_ans_negative_tags.append", "extract_logical_expressions_v2.extract_np_vnp_constituents", "extract_logical_expressions_v2.identify_positive_negative_vnp", "all_conc_vn_phrases.append", "all_conc_negative_tags.append"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp"], ["", "def", "extract_logical_variables", "(", "conclusions", ",", "premises", ",", "answer_list", ")", ":", "\n", "    ", "all_conc_vn_phrases", ",", "all_conc_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Conclusion ......................................\")", "\n", "for", "each_conclusion", "in", "conclusions", ":", "\n", "        ", "if", "each_conclusion", "is", "not", "None", ":", "\n", "            ", "conc_all_verb_nouns_phrases", ",", "conc_all_vnp_scales", ",", "conc_token_list", "=", "extract_np_vnp_constituents", "(", "each_conclusion", ")", "\n", "conc_vn_phrases", ",", "conc_negative_tags", "=", "identify_positive_negative_vnp", "(", "conc_all_verb_nouns_phrases", ",", "conc_all_vnp_scales", ",", "conc_token_list", ")", "\n", "# print(conc_vn_phrases)", "\n", "# print(conc_negative_tags)", "\n", "all_conc_vn_phrases", ".", "append", "(", "conc_vn_phrases", ")", "\n", "all_conc_negative_tags", ".", "append", "(", "conc_negative_tags", ")", "\n", "\n", "\n", "", "", "all_prem_vn_phrases", ",", "all_prem_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Premise ......................................\")", "\n", "for", "each_premise", "in", "premises", ":", "\n", "        ", "each_prem_all_verb_nouns_phrases", ",", "each_prem_all_vnp_scales", ",", "premise_token_list", "=", "extract_np_vnp_constituents", "(", "each_premise", ")", "\n", "each_prem_vn_phrases", ",", "each_prem_negative_tags", "=", "identify_positive_negative_vnp", "(", "each_prem_all_verb_nouns_phrases", ",", "each_prem_all_vnp_scales", ",", "premise_token_list", ")", "\n", "# print(each_prem_vn_phrases)", "\n", "# print(each_prem_negative_tags)", "\n", "all_prem_vn_phrases", ".", "append", "(", "each_prem_vn_phrases", ")", "\n", "all_prem_negative_tags", ".", "append", "(", "each_prem_negative_tags", ")", "\n", "\n", "", "all_ans_vn_phrases", ",", "all_ans_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# print(\"Answer ......................................\")", "\n", "for", "each_answer", "in", "answer_list", ":", "\n", "        ", "each_ans_all_verb_nouns_phrases", ",", "each_ans_all_vnp_scales", ",", "answer_token_list", "=", "extract_np_vnp_constituents", "(", "each_answer", ")", "\n", "each_ans_vn_phrases", ",", "each_ans_negative_tags", "=", "identify_positive_negative_vnp", "(", "each_ans_all_verb_nouns_phrases", ",", "each_ans_all_vnp_scales", ",", "answer_token_list", ")", "\n", "# print(each_ans_vn_phrases)", "\n", "# print(each_ans_negative_tags)", "\n", "all_ans_vn_phrases", ".", "append", "(", "each_ans_vn_phrases", ")", "\n", "all_ans_negative_tags", ".", "append", "(", "each_ans_negative_tags", ")", "\n", "\n", "", "return", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "all_conc_vn_phrases", ",", "all_conc_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_np_vnp_constituents": [[136, 172], ["list", "list", "constituent_strs.count", "constituent_strs.count", "nltk.tree.Tree.fromstring", "extract_logical_expressions_v2.recursive_extract_np_vnp", "len", "Tree.fromstring.leaves", "cur_sent.find", "len", "list.append", "each.label", "list.append", "nltk.word_tokenize", "each.lower", "list.pop", "list.append", "each.pos", "Tree.fromstring.leaves", "extracted_trees[].label", "extracted_trees[].label", "len", "len", "extracted_trees[].pos", "each.pos"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp"], ["", "def", "extract_np_vnp_constituents", "(", "constituent_strs", ")", ":", "\n", "    ", "all_np_vnp_phrases", "=", "list", "(", ")", "\n", "all_np_vnp_scales", "=", "list", "(", ")", "\n", "\n", "left_pare_num", "=", "constituent_strs", ".", "count", "(", "'('", ")", "\n", "right_pare_num", "=", "constituent_strs", ".", "count", "(", "')'", ")", "\n", "if", "left_pare_num", ">", "right_pare_num", ":", "\n", "        ", "constituent_strs", "=", "constituent_strs", "+", "')'", "\n", "", "elif", "left_pare_num", "<", "right_pare_num", ":", "\n", "        ", "constituent_strs", "=", "'('", "+", "constituent_strs", "\n", "", "constituent_trees", "=", "Tree", ".", "fromstring", "(", "constituent_strs", ")", "\n", "extracted_trees", "=", "recursive_extract_np_vnp", "(", "constituent_trees", ")", "\n", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "extracted_trees", ")", ":", "\n", "        ", "each", "=", "extracted_trees", "[", "i", "]", "\n", "\n", "if", "each", ".", "label", "(", ")", "==", "'HYPH'", ":", "\n", "            ", "if", "i", ">", "0", "and", "extracted_trees", "[", "i", "-", "1", "]", ".", "label", "(", ")", "==", "'NP'", "and", "i", "<", "(", "len", "(", "extracted_trees", ")", "-", "1", ")", "and", "extracted_trees", "[", "i", "+", "1", "]", ".", "label", "(", ")", "==", "'NP'", ":", "\n", "                ", "poped_phrase", "=", "all_np_vnp_phrases", ".", "pop", "(", ")", "\n", "all_np_vnp_phrases", ".", "append", "(", "poped_phrase", "+", "each", ".", "pos", "(", ")", "+", "extracted_trees", "[", "i", "+", "1", "]", ".", "pos", "(", ")", ")", "\n", "i", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "all_np_vnp_phrases", ".", "append", "(", "each", ".", "pos", "(", ")", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "cur_sent", "=", "\" \"", ".", "join", "(", "constituent_trees", ".", "leaves", "(", ")", ")", "\n", "for", "each_phrase", "in", "all_np_vnp_phrases", ":", "\n", "        ", "cur_phrase", "=", "\" \"", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "each_phrase", "]", ")", "\n", "# print(cur_phrase)", "\n", "idx", "=", "cur_sent", ".", "find", "(", "cur_phrase", ")", "\n", "start", "=", "len", "(", "nltk", ".", "word_tokenize", "(", "cur_sent", "[", ":", "idx", "]", ")", ")", "\n", "all_np_vnp_scales", ".", "append", "(", "[", "start", ",", "start", "+", "len", "(", "each_phrase", ")", "]", ")", "\n", "# print(all_np_vnp_scales[-1])", "\n", "\n", "", "return", "all_np_vnp_phrases", ",", "all_np_vnp_scales", ",", "[", "each", ".", "lower", "(", ")", "for", "each", "in", "constituent_trees", ".", "leaves", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp": [[175, 211], ["list", "each.label", "each.label", "each[].label", "len", "list.append", "list.append", "each[].label", "list.append", "range", "extract_logical_expressions_v2.recursive_extract_np_vnp", "isinstance", "[].lower", "each[].label", "len", "list.append", "len", "extract_logical_expressions_v2.recursive_extract_np_vnp", "each.label", "each.label", "each.label", "list.append", "[].label", "isinstance", "[].lower"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.recursive_extract_np_vnp"], ["", "def", "recursive_extract_np_vnp", "(", "constituent_trees", ")", ":", "\n", "    ", "extracted_trees", "=", "list", "(", ")", "\n", "for", "each", "in", "constituent_trees", ":", "\n", "# print(each)", "\n", "        ", "if", "each", ".", "label", "(", ")", "==", "'NP'", ":", "\n", "            ", "if", "each", "[", "0", "]", ".", "label", "(", ")", "==", "'PRP'", "or", "(", "not", "isinstance", "(", "each", "[", "0", "]", "[", "0", "]", ",", "Tree", ")", "and", "each", "[", "0", "]", "[", "0", "]", ".", "lower", "(", ")", "in", "PRP_words", ")", ":", "\n", "                ", "if", "len", "(", "each", ")", ">", "1", ":", "\n", "                    ", "extracted_trees", ".", "append", "(", "each", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "elif", "each", "[", "0", "]", ".", "label", "(", ")", "==", "'NP'", "and", "(", "each", "[", "0", "]", "[", "0", "]", ".", "label", "(", ")", "==", "'PRP'", "or", "(", "not", "isinstance", "(", "each", "[", "0", "]", "[", "0", "]", "[", "0", "]", ",", "Tree", ")", "and", "each", "[", "0", "]", "[", "0", "]", "[", "0", "]", ".", "lower", "(", ")", "in", "PRP_words", ")", ")", ":", "\n", "                ", "if", "len", "(", "each", ")", ">", "1", ":", "\n", "                    ", "extracted_trees", ".", "append", "(", "each", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "", "else", ":", "\n", "                ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "", "elif", "each", ".", "label", "(", ")", "==", "'VP'", ":", "\n", "            ", "if", "'VB'", "in", "each", "[", "0", "]", ".", "label", "(", ")", ":", "\n", "                ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "each", ")", ")", ":", "\n", "# print(each[i])", "\n", "# if each[i].label() == 'VP':", "\n", "                    ", "extracted_trees", "+=", "recursive_extract_np_vnp", "(", "each", "[", "i", ":", "i", "+", "1", "]", ")", "\n", "", "", "", "elif", "each", ".", "label", "(", ")", "==", "'SBAR'", "or", "each", ".", "label", "(", ")", "==", "'S'", ":", "\n", "# print('SBAR', len(each))", "\n", "            ", "extracted_trees", "+=", "recursive_extract_np_vnp", "(", "each", ")", "\n", "", "elif", "each", ".", "label", "(", ")", "==", "'HYPH'", ":", "\n", "            ", "extracted_trees", ".", "append", "(", "each", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print('Other', each)", "\n", "\n", "", "", "return", "extracted_trees", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_positive_negative_vnp": [[214, 258], ["list", "list", "range", "list", "len", "extract_logical_expressions_v2.has_keyword", "extract_logical_expressions_v2.has_keyword", "list.append", "list.append", "len", "each_token[].lower", "list.append", "list.append", "bool", "len", "list.append", "bool", "len", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "identify_positive_negative_vnp", "(", "all_vn_phrases", ",", "all_vn_scales", ",", "token_list", ")", ":", "\n", "    ", "vn_phrases", "=", "list", "(", ")", "\n", "negative_tags", "=", "list", "(", ")", "\n", "index_start", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_vn_phrases", ")", ")", ":", "\n", "        ", "cur_neg_tag", "=", "False", "\n", "cur_reverse_tag", "=", "False", "\n", "cur_vnp_tokens", "=", "[", "each_token", "[", "0", "]", ".", "lower", "(", ")", "for", "each_token", "in", "all_vn_phrases", "[", "i", "]", "]", "\n", "cur_vn_phrase", "=", "all_vn_phrases", "[", "i", "]", "\n", "\n", "nega_kw_index", ",", "nega_kw", "=", "has_keyword", "(", "negative_words", "+", "reverse_negative_words", ",", "cur_vnp_tokens", ")", "\n", "if", "nega_kw_index", ">=", "0", ":", "\n", "            ", "cur_neg_tag", "=", "True", "\n", "# print(cur_vnp_tokens)", "\n", "# print(nega_kw_index, nega_kw)", "\n", "if", "nega_kw", "in", "reverse_negative_words", "and", "nega_kw_index", "==", "0", ":", "\n", "                ", "cur_reverse_tag", "=", "True", "\n", "", "cur_vn_phrase", "=", "cur_vn_phrase", "[", ":", "nega_kw_index", "]", "+", "cur_vn_phrase", "[", "nega_kw_index", "+", "len", "(", "nltk", ".", "word_tokenize", "(", "nega_kw", ")", ")", ":", "]", "\n", "\n", "", "outer_nega_kw_index", ",", "outer_nega_kw", "=", "has_keyword", "(", "negative_words", "+", "reverse_negative_words", ",", "token_list", "[", "index_start", ":", "all_vn_scales", "[", "i", "]", "[", "0", "]", "]", ")", "\n", "if", "outer_nega_kw_index", ">=", "0", ":", "\n", "            ", "if", "cur_neg_tag", ":", "\n", "                ", "cur_neg_tag", "=", "False", "\n", "", "else", ":", "\n", "                ", "cur_neg_tag", "=", "True", "\n", "\n", "", "", "index_start", "=", "all_vn_scales", "[", "i", "]", "[", "1", "]", "\n", "vn_phrases", ".", "append", "(", "cur_vn_phrase", ")", "\n", "negative_tags", ".", "append", "(", "[", "cur_neg_tag", ",", "cur_reverse_tag", "]", ")", "\n", "\n", "", "reverse_negative_tags", "=", "list", "(", ")", "\n", "j", "=", "0", "\n", "while", "j", "<", "len", "(", "vn_phrases", ")", ":", "\n", "        ", "if", "negative_tags", "[", "j", "]", "[", "1", "]", ":", "\n", "            ", "reverse_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "negative_tags", "[", "j", "]", "[", "0", "]", ")", ")", "\n", "if", "j", "+", "1", "<", "len", "(", "vn_phrases", ")", ":", "\n", "                ", "reverse_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "negative_tags", "[", "j", "+", "1", "]", "[", "0", "]", ")", ")", "\n", "", "j", "+=", "1", "\n", "", "else", ":", "\n", "            ", "reverse_negative_tags", ".", "append", "(", "negative_tags", "[", "j", "]", "[", "0", "]", ")", "\n", "", "j", "+=", "1", "\n", "\n", "", "return", "vn_phrases", ",", "reverse_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_condition": [[261, 318], ["enumerate", "list", "list", "list", "list", "list", "enumerate", "list", "list", "all_conditioned_vn_phrases.append", "all_conditioned_negative_tags.append", "extract_logical_expressions_v2.has_keyword", "len", "each[].lower", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "len", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "bool", "len", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "identify_condition", "(", "all_vn_phrases", ",", "all_negative_tags", ")", ":", "\n", "    ", "all_conditioned_vn_phrases", ",", "all_conditioned_negative_tags", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "i", ",", "each_sent_phrases", "in", "enumerate", "(", "all_vn_phrases", ")", ":", "\n", "        ", "cur_sent_all_phrases", "=", "list", "(", ")", "\n", "cur_sent_all_negative_tags", "=", "list", "(", ")", "\n", "cur_sent_vn_reverse_tags", "=", "list", "(", ")", "\n", "\n", "for", "j", ",", "cur_vn_phrase", "in", "enumerate", "(", "each_sent_phrases", ")", ":", "\n", "            ", "token_list", "=", "[", "each", "[", "0", "]", ".", "lower", "(", ")", "for", "each", "in", "cur_vn_phrase", "]", "\n", "condi_kw_index", ",", "condi_kw", "=", "has_keyword", "(", "condition_keywords", "+", "reverse_condition_keywords", ",", "token_list", ")", "\n", "\n", "if", "condi_kw_index", ">=", "0", ":", "\n", "                ", "if", "cur_vn_phrase", "[", "condi_kw_index", "-", "1", "]", "[", "0", "]", "==", "','", ":", "\n", "                    ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", ":", "condi_kw_index", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", ":", "condi_kw_index", "]", ")", "\n", "", "if", "condi_kw", "==", "'unless'", ":", "\n", "                    ", "cur_sent_all_negative_tags", ".", "append", "(", "bool", "(", "1", "-", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "", "if", "condi_kw", "in", "reverse_condition_keywords", ":", "\n", "                    ", "cur_sent_vn_reverse_tags", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", "[", "condi_kw_index", "+", "len", "(", "nltk", ".", "word_tokenize", "(", "condi_kw", ")", ")", ":", "]", ")", "\n", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "", "else", ":", "\n", "                ", "cur_sent_all_phrases", ".", "append", "(", "cur_vn_phrase", ")", "\n", "cur_sent_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "]", ")", "\n", "cur_sent_vn_reverse_tags", ".", "append", "(", "False", ")", "\n", "\n", "", "", "reverse_all_vn_phrases", "=", "list", "(", ")", "\n", "reverse_all_negative_tags", "=", "list", "(", ")", "\n", "k", "=", "0", "\n", "while", "k", "<", "len", "(", "cur_sent_all_phrases", ")", ":", "\n", "            ", "if", "cur_sent_vn_reverse_tags", "[", "k", "]", ":", "\n", "                ", "if", "k", "+", "1", "<", "len", "(", "cur_sent_all_phrases", ")", ":", "\n", "                    ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "+", "1", "]", ")", "\n", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "+", "1", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "k", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "reverse_all_vn_phrases", ".", "append", "(", "cur_sent_all_phrases", "[", "k", "]", ")", "\n", "reverse_all_negative_tags", ".", "append", "(", "cur_sent_all_negative_tags", "[", "k", "]", ")", "\n", "", "k", "+=", "1", "\n", "# print(reverse_all_vn_phrases)", "\n", "# print(reverse_all_negative_tags)", "\n", "\n", "", "all_conditioned_vn_phrases", ".", "append", "(", "reverse_all_vn_phrases", ")", "\n", "all_conditioned_negative_tags", ".", "append", "(", "reverse_all_negative_tags", ")", "\n", "\n", "", "return", "all_conditioned_vn_phrases", ",", "all_conditioned_negative_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.spread_logical_expressions": [[320, 337], ["list", "list", "list", "enumerate", "len", "range", "len", "list.append", "list.append", "list.append", "len", "list.append", "list.append", "list.append"], "function", ["None"], ["", "def", "spread_logical_expressions", "(", "all_vn_phrases", ",", "all_negative_tags", ",", "all_compo_tags", ")", ":", "\n", "    ", "spread_all_vn_phrases", "=", "list", "(", ")", "\n", "spread_all_negative_tags", "=", "list", "(", ")", "\n", "spread_all_compo_tags", "=", "list", "(", ")", "\n", "\n", "for", "i", ",", "each_vn", "in", "enumerate", "(", "all_vn_phrases", ")", ":", "\n", "        ", "if", "len", "(", "each_vn", ")", ">", "2", ":", "\n", "            ", "for", "j", "in", "range", "(", "1", ",", "len", "(", "each_vn", ")", ")", ":", "\n", "                ", "spread_all_vn_phrases", ".", "append", "(", "each_vn", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "spread_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "spread_all_compo_tags", ".", "append", "(", "all_compo_tags", "[", "i", "]", "[", "j", "-", "1", ":", "j", "+", "1", "]", ")", "\n", "", "", "elif", "len", "(", "each_vn", ")", "==", "2", ":", "\n", "            ", "spread_all_vn_phrases", ".", "append", "(", "each_vn", ")", "\n", "spread_all_negative_tags", ".", "append", "(", "all_negative_tags", "[", "i", "]", ")", "\n", "spread_all_compo_tags", ".", "append", "(", "all_compo_tags", "[", "i", "]", ")", "\n", "\n", "", "", "return", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.infer_logical_expression": [[340, 404], ["list", "list", "range", "list", "list", "len", "list.append", "list.append", "list", "list", "range", "list", "list", "range", "extract_logical_expressions_v2.infer_logical_expression.reverse_logic"], "function", ["None"], ["", "def", "infer_logical_expression", "(", "all_vn_phrases", ",", "all_negative_tags", ",", "all_compo_tags", ")", ":", "\n", "    ", "all_logical_expressions", "=", "list", "(", ")", "\n", "all_textual_vn_phrases", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "all_compo_tags", ")", ")", ":", "\n", "        ", "all_logical_expressions", ".", "append", "(", "[", "[", "x", ",", "y", "]", "for", "x", ",", "y", "in", "zip", "(", "all_compo_tags", "[", "i", "]", ",", "all_negative_tags", "[", "i", "]", ")", "]", ")", "\n", "all_textual_vn_phrases", ".", "append", "(", "all_vn_phrases", "[", "i", "]", ")", "\n", "\n", "", "extended_logical_expression", "=", "list", "(", ")", "\n", "extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "def", "reverse_logic", "(", "all_textual_vn_phrases", ",", "all_logical_expressions", ")", ":", "\n", "        ", "cur_extended_logical_expression", "=", "list", "(", ")", "\n", "cur_extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_logical_expressions", ")", ")", ":", "\n", "            ", "if", "len", "(", "all_logical_expressions", "[", "i", "]", ")", "==", "2", ":", "\n", "                ", "rever_cur_logical_expression", "=", "[", "[", "x", ",", "bool", "(", "1", "-", "y", ")", "]", "for", "x", ",", "y", "in", "all_logical_expressions", "[", "i", "]", "[", ":", ":", "-", "1", "]", "]", "\n", "if", "rever_cur_logical_expression", "not", "in", "all_logical_expressions", "+", "cur_extended_logical_expression", ":", "\n", "# all_logical_expressions.append(rever_cur_logical_expression)", "\n", "# all_vn_phrases.append(all_vn_phrases[i][::-1])", "\n", "                    ", "cur_extended_logical_expression", ".", "append", "(", "rever_cur_logical_expression", ")", "\n", "cur_extended_textual_vn_phrases", ".", "append", "(", "all_textual_vn_phrases", "[", "i", "]", "[", ":", ":", "-", "1", "]", ")", "\n", "\n", "", "", "", "return", "cur_extended_logical_expression", ",", "cur_extended_textual_vn_phrases", "\n", "\n", "", "def", "transfer_logic", "(", "all_textual_vn_phrases", ",", "all_logical_expressions", ")", ":", "\n", "# print(\"all + extended\", \"*\"*100)", "\n", "# print(all_logical_expressions)", "\n", "# print(all_textual_vn_phrases)", "\n", "\n", "        ", "cur_extended_logical_expression", "=", "list", "(", ")", "\n", "cur_extended_textual_vn_phrases", "=", "list", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "all_logical_expressions", ")", ")", ":", "\n", "            ", "other_logical_expressions", "=", "all_logical_expressions", "[", ":", "i", "]", "+", "all_logical_expressions", "[", "i", "+", "1", ":", "]", "\n", "other_textual_vn_phrases", "=", "all_textual_vn_phrases", "[", ":", "i", "]", "+", "all_textual_vn_phrases", "[", "i", "+", "1", ":", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "other_logical_expressions", ")", ")", ":", "\n", "                ", "if", "all_logical_expressions", "[", "i", "]", "[", "1", "]", "==", "other_logical_expressions", "[", "j", "]", "[", "0", "]", ":", "\n", "                    ", "trans_cur_logical_expression", "=", "[", "all_logical_expressions", "[", "i", "]", "[", "0", "]", ",", "other_logical_expressions", "[", "j", "]", "[", "1", "]", "]", "\n", "if", "trans_cur_logical_expression", "not", "in", "all_logical_expressions", "+", "cur_extended_logical_expression", ":", "\n", "                        ", "cur_extended_logical_expression", ".", "append", "(", "trans_cur_logical_expression", ")", "\n", "cur_extended_textual_vn_phrases", ".", "append", "(", "[", "all_textual_vn_phrases", "[", "i", "]", "[", "0", "]", ",", "other_textual_vn_phrases", "[", "j", "]", "[", "1", "]", "]", ")", "\n", "\n", "", "", "", "", "return", "cur_extended_logical_expression", ",", "cur_extended_textual_vn_phrases", "\n", "\n", "", "whether_continue", "=", "True", "\n", "\n", "while", "whether_continue", ":", "\n", "        ", "cur_rever_extended_logical_expression", ",", "cur_rever_extended_textual_vn_phrases", "=", "reverse_logic", "(", "all_textual_vn_phrases", "+", "extended_textual_vn_phrases", ",", "all_logical_expressions", "+", "extended_logical_expression", ")", "\n", "extended_logical_expression", "+=", "cur_rever_extended_logical_expression", "\n", "extended_textual_vn_phrases", "+=", "cur_rever_extended_textual_vn_phrases", "\n", "\n", "cur_trans_extended_logical_expression", ",", "cur_trans_extended_textual_vn_phrases", "=", "transfer_logic", "(", "all_textual_vn_phrases", "+", "extended_textual_vn_phrases", ",", "all_logical_expressions", "+", "extended_logical_expression", ")", "\n", "extended_logical_expression", "+=", "cur_trans_extended_logical_expression", "\n", "extended_textual_vn_phrases", "+=", "cur_trans_extended_textual_vn_phrases", "\n", "\n", "# print(\"Cur transfer extended\", \"*\"*100)", "\n", "# print(extended_logical_expression)", "\n", "# print(extended_textual_vn_phrases)", "\n", "\n", "if", "len", "(", "cur_rever_extended_logical_expression", ")", "+", "len", "(", "cur_trans_extended_logical_expression", ")", "==", "0", ":", "\n", "            ", "whether_continue", "=", "False", "\n", "\n", "", "", "return", "all_logical_expressions", ",", "all_textual_vn_phrases", ",", "extended_logical_expression", ",", "extended_textual_vn_phrases", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.logical_expression_to_text": [[407, 467], ["len", "len"], "function", ["None"], ["", "def", "logical_expression_to_text", "(", "logical_expression", ",", "vn_phrases", ")", ":", "\n", "\n", "    ", "first_phrase", ",", "first_nega_tag", "=", "vn_phrases", "[", "0", "]", ",", "logical_expression", "[", "0", "]", "[", "1", "]", "\n", "second_phrase", ",", "second_nega_tag", "=", "vn_phrases", "[", "1", "]", ",", "logical_expression", "[", "1", "]", "[", "1", "]", "\n", "\n", "# first_verb_type = nltk.pos_tag([first_phrase[0][0]])[0][1]", "\n", "# second_verb_type = nltk.pos_tag([second_phrase[0][0]])[0][1]", "\n", "\n", "first_text", "=", "\"If \"", "\n", "if", "len", "(", "first_phrase", ")", ">", "0", ":", "\n", "        ", "if", "'VB'", "in", "first_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "            ", "if", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                ", "first_text", "+=", "\"it \"", "\n", "", "else", ":", "\n", "                ", "first_text", "+=", "\"you \"", "\n", "", "", "else", ":", "\n", "            ", "first_text", "+=", "\"it is \"", "\n", "\n", "", "if", "first_nega_tag", "is", "True", ":", "\n", "            ", "if", "'VB'", "in", "first_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "                ", "if", "first_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                    ", "if", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                        ", "first_text", "+=", "\"does not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "elif", "first_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBD\"", ":", "\n", "                        ", "first_text", "+=", "\"did not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "else", ":", "\n", "                        ", "first_text", "+=", "\"do not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "                    ", "first_text", "+=", "first_phrase", "[", "0", "]", "[", "0", "]", "+", "\" not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "[", "1", ":", "]", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "                ", "first_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "", "", "else", ":", "\n", "            ", "first_text", "+=", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "first_phrase", "]", ")", "+", "\",\"", "\n", "\n", "", "", "second_text", "=", "\"then \"", "\n", "if", "len", "(", "second_phrase", ")", ">", "0", ":", "\n", "\n", "        ", "if", "'VB'", "in", "second_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "            ", "if", "second_phrase", "[", "0", "]", "[", "1", "]", "==", "\"VBZ\"", ":", "\n", "                ", "second_text", "+=", "\"it will \"", "\n", "", "else", ":", "\n", "                ", "second_text", "+=", "\"you will \"", "\n", "", "", "else", ":", "\n", "            ", "second_text", "+=", "\"it will be \"", "\n", "\n", "", "if", "second_nega_tag", "is", "True", ":", "\n", "            ", "if", "'VB'", "in", "second_phrase", "[", "0", "]", "[", "1", "]", ":", "\n", "                ", "if", "second_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                    ", "second_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "else", ":", "\n", "                    ", "second_text", "+=", "\"be not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "[", "1", ":", "]", "]", ")", "+", "\".\"", "\n", "", "", "else", ":", "\n", "                ", "second_text", "+=", "\"not \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "", "else", ":", "\n", "            ", "if", "second_phrase", "[", "0", "]", "[", "0", "]", "not", "in", "be_verbs", ":", "\n", "                ", "second_text", "+=", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "]", ")", "+", "\".\"", "\n", "", "else", ":", "\n", "                ", "second_text", "+=", "\"be \"", "+", "' '", ".", "join", "(", "[", "each", "[", "0", "]", "for", "each", "in", "second_phrase", "[", "1", ":", "]", "]", ")", "+", "\".\"", "\n", "\n", "", "", "", "return", "first_text", "+", "\" \"", "+", "second_text", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_overlap_logical_component": [[470, 488], ["range", "len", "set", "range", "extract_logical_expressions_v2.has_keyword", "len", "set", "list", "extract_logical_expressions_v2.has_keyword", "list", "len", "max", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "has_overlap_logical_component", "(", "answer_vnps", ",", "prem_vnps", ",", "answer_nega_tags", ",", "prem_nega_tags", ")", ":", "\n", "# print(answer_vnps, answer_nega_tags)", "\n", "# print(prem_vnps, prem_nega_tags)", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "answer_vnps", ")", ")", ":", "\n", "        ", "answ_vnp_i", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "answer_vnps", "[", "i", "]", "]", ")", "\n", "answ_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "answ_vnp_i", ")", ")", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "prem_vnps", ")", ")", ":", "\n", "            ", "prem_vnp_j", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "prem_vnps", "[", "j", "]", "]", ")", "\n", "\n", "# hyper-parameter: 0.7", "\n", "prem_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "prem_vnp_j", ")", ")", "[", "0", "]", "\n", "if", "(", "answ_degree_kw_index", ">=", "0", "and", "prem_degree_kw_index", "<", "0", ")", "or", "(", "answ_degree_kw_index", "<", "0", "and", "prem_degree_kw_index", ">=", "0", ")", ":", "\n", "                ", "return", "False", "\n", "", "if", "len", "(", "answ_vnp_i", "&", "prem_vnp_j", ")", "/", "max", "(", "len", "(", "answ_vnp_i", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "if", "answer_nega_tags", "[", "i", "]", "==", "prem_nega_tags", "[", "j", "]", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_overlap_logical_component_rate": [[491, 510], ["range", "len", "set", "range", "extract_logical_expressions_v2.has_keyword", "len", "set", "list", "extract_logical_expressions_v2.has_keyword", "list", "len", "max", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_keyword"], ["", "def", "has_overlap_logical_component_rate", "(", "answer_vnps", ",", "prem_vnps", ",", "answer_nega_tags", ",", "prem_nega_tags", ")", ":", "\n", "    ", "overlap_num", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "answer_vnps", ")", ")", ":", "\n", "        ", "answ_vnp_i", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "answer_vnps", "[", "i", "]", "]", ")", "\n", "answ_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "answ_vnp_i", ")", ")", "[", "0", "]", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "prem_vnps", ")", ")", ":", "\n", "            ", "prem_vnp_j", "=", "set", "(", "[", "each", "[", "0", "]", "for", "each", "in", "prem_vnps", "[", "j", "]", "]", ")", "\n", "\n", "prem_degree_kw_index", "=", "has_keyword", "(", "degree_indicator", ",", "list", "(", "prem_vnp_j", ")", ")", "[", "0", "]", "\n", "if", "(", "answ_degree_kw_index", ">=", "0", "and", "prem_degree_kw_index", "<", "0", ")", "or", "(", "answ_degree_kw_index", "<", "0", "and", "prem_degree_kw_index", ">=", "0", ")", ":", "\n", "                ", "pass", "\n", "", "elif", "len", "(", "answ_vnp_i", "&", "prem_vnp_j", ")", "/", "max", "(", "len", "(", "answ_vnp_i", ")", ",", "1", ")", ">", "0.5", ":", "\n", "                ", "if", "answer_nega_tags", "[", "i", "]", "==", "prem_nega_tags", "[", "j", "]", ":", "\n", "                    ", "overlap_num", "+=", "1", "\n", "break", "\n", "\n", "", "", "", "", "return", "overlap_num", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.get_cur_all_extended_text": [[513, 609], ["list", "extract_logical_expressions_v2.extract_logical_variables", "extract_logical_expressions_v2.identify_condition", "extract_logical_expressions_v2.identify_logical_expression", "extract_logical_expressions_v2.spread_logical_expressions", "extract_logical_expressions_v2.infer_logical_expression", "list", "range", "max", "len", "len", "list", "range", "len", "extract_logical_expressions_v2.has_overlap_logical_component", "len", "list.append", "len", "sum", "extract_logical_expressions_v2.logical_expression_to_text", "list.append", "len", "list.append", "random.sample", "list.append", "range", "len"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.extract_logical_variables", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_condition", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.identify_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.spread_logical_expressions", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.infer_logical_expression", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.has_overlap_logical_component", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.logical_expression_to_text"], ["", "def", "get_cur_all_extended_text", "(", "conclusion", ",", "premises", ",", "answer_list", ")", ":", "\n", "    ", "all_extended_contexts", "=", "list", "(", ")", "\n", "\n", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_ans_vn_phrases", ",", "all_ans_negative_tags", ",", "conc_vn_phrases", ",", "conc_negative_tags", "=", "extract_logical_variables", "(", "conclusion", ",", "premises", ",", "answer_list", ")", "\n", "\n", "all_prem_vn_phrases", "=", "all_prem_vn_phrases", "+", "conc_vn_phrases", "\n", "all_prem_negative_tags", "=", "all_prem_negative_tags", "+", "conc_negative_tags", "\n", "\n", "all_prem_vn_phrases", ",", "all_prem_negative_tags", "=", "identify_condition", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ")", "\n", "\n", "all_prem_compo_tags", "=", "identify_logical_expression", "(", "all_prem_vn_phrases", ")", "\n", "# print(all_prem_compo_tags)", "\n", "# print(len(all_prem_compo_tags))", "\n", "# if len(all_prem_vn_phrases) > 6:", "\n", "#     all_prem_vn_phrases = all_prem_vn_phrases[:6]", "\n", "#     all_prem_negative_tags = all_prem_negative_tags[:6]", "\n", "\n", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", "=", "spread_logical_expressions", "(", "all_prem_vn_phrases", ",", "all_prem_negative_tags", ",", "all_prem_compo_tags", ")", "\n", "\n", "all_logical_expressions", ",", "all_textual_vn_phrases", ",", "extended_logical_expression", ",", "extended_textual_vn_phrases", "=", "infer_logical_expression", "(", "spread_all_vn_phrases", ",", "spread_all_negative_tags", ",", "spread_all_compo_tags", ")", "\n", "\n", "if", "len", "(", "extended_logical_expression", ")", ">", "0", ":", "\n", "        ", "has_extended", "=", "1", "\n", "", "else", ":", "\n", "        ", "has_extended", "=", "0", "\n", "\n", "# answer_extend_num = list()", "\n", "# for j in range(len(all_ans_vn_phrases)):", "\n", "#     cur_answ_extended_contexts = list()", "\n", "#     for i in range(len(extended_logical_expression)):", "\n", "#         extended_negative_tags = [each[1] for each in extended_logical_expression[i]]", "\n", "#         whether_extend = has_overlap_logical_component_rate(all_ans_vn_phrases[j], extended_textual_vn_phrases[i],", "\n", "#                                                        all_ans_negative_tags[j], extended_negative_tags)", "\n", "#", "\n", "#         if whether_extend > 0:", "\n", "#             extended_text = logical_expression_to_text(extended_logical_expression[i],", "\n", "#                                                        extended_textual_vn_phrases[i])", "\n", "#             cur_answ_extended_contexts.append((extended_text, whether_extend))", "\n", "#", "\n", "#     sorted_cur_answ_extended_contexts = [each[0] for each in sorted(cur_answ_extended_contexts, key=lambda x: x[1], reverse=True)]", "\n", "#     answer_extend_num.append(len(sorted_cur_answ_extended_contexts))", "\n", "#", "\n", "#     if len(sorted_cur_answ_extended_contexts) == 0:", "\n", "#         all_extended_contexts.append(\"\")", "\n", "#     elif len(sorted_cur_answ_extended_contexts) == 1:", "\n", "#         all_extended_contexts.append(sorted_cur_answ_extended_contexts[0])", "\n", "#     else:", "\n", "#         all_extended_contexts.append(", "\n", "#             sorted_cur_answ_extended_contexts[0] + \" \" + sorted_cur_answ_extended_contexts[1])", "\n", "#", "\n", "#     if len(sorted_cur_answ_extended_contexts) == 0:", "\n", "#         all_extended_contexts.append(\"\")", "\n", "#     elif len(sorted_cur_answ_extended_contexts) == 1:", "\n", "#         all_extended_contexts.append(sorted_cur_answ_extended_contexts[0])", "\n", "#     elif len(sorted_cur_answ_extended_contexts) == 2:", "\n", "#         all_extended_contexts.append(sorted_cur_answ_extended_contexts[0] + \" \" + sorted_cur_answ_extended_contexts[1])", "\n", "#     else:", "\n", "#         all_extended_contexts.append(sorted_cur_answ_extended_contexts[0] + \" \" + sorted_cur_answ_extended_contexts[1] + \" \" + sorted_cur_answ_extended_contexts[2])", "\n", "\n", "", "answer_extend_num", "=", "list", "(", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "all_ans_vn_phrases", ")", ")", ":", "\n", "        ", "cur_answ_extended_contexts", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "extended_logical_expression", ")", ")", ":", "\n", "            ", "extended_negative_tags", "=", "[", "each", "[", "1", "]", "for", "each", "in", "extended_logical_expression", "[", "i", "]", "]", "\n", "whether_extend", "=", "has_overlap_logical_component", "(", "all_ans_vn_phrases", "[", "j", "]", ",", "extended_textual_vn_phrases", "[", "i", "]", ",", "all_ans_negative_tags", "[", "j", "]", ",", "extended_negative_tags", ")", "\n", "\n", "if", "whether_extend", ":", "\n", "                ", "extended_text", "=", "logical_expression_to_text", "(", "extended_logical_expression", "[", "i", "]", ",", "extended_textual_vn_phrases", "[", "i", "]", ")", "\n", "cur_answ_extended_contexts", ".", "append", "(", "extended_text", ")", "\n", "\n", "\n", "", "", "if", "len", "(", "cur_answ_extended_contexts", ")", "==", "0", ":", "\n", "            ", "all_extended_contexts", ".", "append", "(", "\"\"", ")", "\n", "", "elif", "len", "(", "cur_answ_extended_contexts", ")", "==", "1", ":", "\n", "            ", "all_extended_contexts", ".", "append", "(", "cur_answ_extended_contexts", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "sample_index", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "cur_answ_extended_contexts", ")", ")", ",", "2", ")", "\n", "all_extended_contexts", ".", "append", "(", "cur_answ_extended_contexts", "[", "sample_index", "[", "0", "]", "]", "+", "\" \"", "+", "cur_answ_extended_contexts", "[", "sample_index", "[", "1", "]", "]", ")", "\n", "\n", "# answer_extend_num.append(len(cur_answ_extended_contexts))", "\n", "# if len(cur_answ_extended_contexts) == 0:", "\n", "#     all_extended_contexts.append(\"\")", "\n", "# elif len(cur_answ_extended_contexts) == 1:", "\n", "#     all_extended_contexts.append(cur_answ_extended_contexts[0])", "\n", "# elif len(cur_answ_extended_contexts) == 2:", "\n", "#     all_extended_contexts.append(cur_answ_extended_contexts[0] + \" \" + cur_answ_extended_contexts[1])", "\n", "# else:", "\n", "#     sample_index = random.sample(range(len(cur_answ_extended_contexts)), 3)", "\n", "#     all_extended_contexts.append(cur_answ_extended_contexts[sample_index[0]] + \" \" + cur_answ_extended_contexts[sample_index[1]] + \" \" + cur_answ_extended_contexts[sample_index[2]])", "\n", "\n", "", "", "max_length", "=", "max", "(", "[", "len", "(", "each", ")", "for", "each", "in", "all_extended_contexts", "]", ")", "\n", "\n", "return", "all_extended_contexts", ",", "(", "max_length", ",", "has_extended", ",", "sum", "(", "answer_extend_num", ")", ")", ",", "(", "all_logical_expressions", ",", "all_textual_vn_phrases", ",", "extended_logical_expression", ",", "extended_textual_vn_phrases", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.save_all_extended_context": [[628, 683], ["list", "numpy.load", "numpy.load", "list", "tqdm.tqdm", "print", "numpy.save", "range", "extract_logical_expressions_v2.get_cur_all_extended_text", "list.append", "list.append", "len", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.get_cur_all_extended_text"], ["def", "save_all_extended_context", "(", "data_type", "=", "0", ")", ":", "\n", "    ", "if", "data_type", "==", "0", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/train_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/train_options_constituents_file.npy'", "\n", "# extended_logic_file = '../reclor-data/train_extended_logic.npy'", "\n", "extended_context_file", "=", "'../reclor-data/train_extended_context_cp_v5.npy'", "\n", "", "elif", "data_type", "==", "1", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/val_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/val_options_constituents_file.npy'", "\n", "# extended_logic_file = '../reclor-data/val_extended_logic.npy'", "\n", "extended_context_file", "=", "'../reclor-data/val_extended_context_cp_v5.npy'", "\n", "", "else", ":", "\n", "        ", "all_context_constituents_file", "=", "'../reclor-data/test_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/test_options_constituents_file.npy'", "\n", "# extended_logic_file = '../reclor-data/test_extended_logic.npy'", "\n", "extended_context_file", "=", "'../reclor-data/test_extended_context_cp_v5.npy'", "\n", "\n", "# v3: same for all question type (prem) + extend num 2", "\n", "# v4: same for all question type (prem) + extend num 3", "\n", "\n", "# v5: same for all question type (prem + conclusion) + extend num 2", "\n", "# v6: same for all question type (prem + conclusion) + extend num 3", "\n", "\n", "# v7: same for all question type (prem + conclusion) + extend num 2, rank related extension", "\n", "# v8: same for all question type (prem + conclusion) + extend num 3, rank related extension", "\n", "\n", "", "all_extended_contexts", "=", "list", "(", ")", "\n", "# all_extended_logic = list()", "\n", "\n", "conclusions_premises_constituents", "=", "np", ".", "load", "(", "all_context_constituents_file", ")", "\n", "answers_constituents", "=", "np", ".", "load", "(", "all_options_constituents_file", ")", "\n", "\n", "has_extend_instance_num", "=", "0", "\n", "has_extend_context_num", "=", "0", "\n", "answer_extend_num", "=", "list", "(", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "conclusions_premises_constituents", ")", ")", ")", ":", "\n", "        ", "conclusions", "=", "[", "]", "\n", "premises", "=", "conclusions_premises_constituents", "[", "i", "]", "\n", "answer_list", "=", "answers_constituents", "[", "i", "]", "\n", "\n", "cur_all_extended_context", ",", "max_length", ",", "logic_result", "=", "get_cur_all_extended_text", "(", "conclusions", ",", "premises", ",", "answer_list", ")", "\n", "# all_extended_logic.append(logic_result)", "\n", "\n", "if", "max_length", "[", "0", "]", ">", "0", ":", "\n", "            ", "has_extend_instance_num", "+=", "1", "\n", "", "if", "max_length", "[", "1", "]", ">", "0", ":", "\n", "            ", "has_extend_context_num", "+=", "1", "\n", "", "answer_extend_num", ".", "append", "(", "max_length", "[", "2", "]", ")", "\n", "\n", "all_extended_contexts", ".", "append", "(", "cur_all_extended_context", ")", "\n", "\n", "", "print", "(", "has_extend_instance_num", ",", "has_extend_context_num", ",", "np", ".", "mean", "(", "answer_extend_num", ")", "/", "4", ")", "\n", "\n", "np", ".", "save", "(", "extended_context_file", ",", "all_extended_contexts", ")", "\n", "# np.save(extended_logic_file, all_extended_logic)", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.DataPreprocess.extract_logical_expressions_v2.get_all_constituents": [[687, 729], ["open", "json.load", "list", "list", "tqdm.tqdm", "numpy.save", "numpy.save", "list", "list", "nltk.sent_tokenize", "list.append", "list.append", "predictor.predict", "list.append", "predictor.predict", "list.append"], "function", ["None"], ["", "def", "get_all_constituents", "(", "data_type", "=", "0", ")", ":", "\n", "    ", "if", "data_type", "==", "0", ":", "\n", "        ", "lr_file", "=", "'../reclor-data/train.json'", "\n", "all_context_constituents_file", "=", "'../reclor-data/train_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/train_options_constituents_file.npy'", "\n", "", "elif", "data_type", "==", "1", ":", "\n", "        ", "lr_file", "=", "'../reclor-data/val.json'", "\n", "all_context_constituents_file", "=", "'../reclor-data/val_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/val_options_constituents_file.npy'", "\n", "", "else", ":", "\n", "        ", "lr_file", "=", "'../reclor-data/test.json'", "\n", "all_context_constituents_file", "=", "'../reclor-data/test_context_constituents_file.npy'", "\n", "all_options_constituents_file", "=", "'../reclor-data/test_options_constituents_file.npy'", "\n", "\n", "", "with", "open", "(", "lr_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lr_data", "=", "json", ".", "load", "(", "f", ")", "\n", "all_context_constituents", "=", "list", "(", ")", "\n", "all_options_constituents", "=", "list", "(", ")", "\n", "\n", "for", "each", "in", "tqdm", "(", "lr_data", ")", ":", "\n", "            ", "cur_context_constituents", "=", "list", "(", ")", "\n", "cur_options_constituents", "=", "list", "(", ")", "\n", "sentences", "=", "nltk", ".", "sent_tokenize", "(", "each", "[", "\"context\"", "]", ")", "\n", "options", "=", "each", "[", "\"answers\"", "]", "\n", "\n", "for", "each_sent", "in", "sentences", ":", "\n", "                ", "sent_result", "=", "predictor", ".", "predict", "(", "\n", "sentence", "=", "each_sent", "\n", ")", "\n", "cur_context_constituents", ".", "append", "(", "sent_result", "[", "'trees'", "]", ")", "\n", "\n", "", "for", "each_option", "in", "options", ":", "\n", "                ", "option_result", "=", "predictor", ".", "predict", "(", "\n", "sentence", "=", "each_option", "\n", ")", "\n", "cur_options_constituents", ".", "append", "(", "option_result", "[", "'trees'", "]", ")", "\n", "\n", "", "all_context_constituents", ".", "append", "(", "cur_context_constituents", ")", "\n", "all_options_constituents", ".", "append", "(", "cur_options_constituents", ")", "\n", "\n", "", "np", ".", "save", "(", "all_context_constituents_file", ",", "all_context_constituents", ")", "\n", "np", ".", "save", "(", "all_options_constituents_file", ",", "all_options_constituents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.InputExample.__init__": [[20, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "example_id", ",", "question", ",", "contexts", ",", "endings", ",", "label", "=", "None", ",", "ques_types", "=", "\"\"", ",", "extend_context", "=", "[", "]", ",", "contras_contexts", "=", "[", "]", ",", "contras_label", "=", "0", ",", "contras_endings", "=", "[", "]", ",", "contras_extend_context", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "contexts", "=", "contexts", "\n", "self", ".", "endings", "=", "endings", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "ques_types", "=", "ques_types", "\n", "self", ".", "extend_context", "=", "extend_context", "\n", "self", ".", "contras_contexts", "=", "contras_contexts", "\n", "self", ".", "contras_label", "=", "contras_label", "\n", "self", ".", "contras_endings", "=", "contras_endings", "\n", "self", ".", "contras_extend_context", "=", "contras_extend_context", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.InputFeatures.__init__": [[45, 57], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "choices_features", ",", "contras_choices_features", ",", "label", ",", "contras_label", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "choices_features", "=", "[", "\n", "{", "\"input_ids\"", ":", "input_ids", ",", "\"input_mask\"", ":", "input_mask", ",", "\"segment_ids\"", ":", "segment_ids", "}", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", "in", "choices_features", "\n", "]", "\n", "self", ".", "contras_choices_features", "=", "[", "\n", "{", "\"contras_input_ids\"", ":", "input_ids", ",", "\"contras_input_mask\"", ":", "input_mask", ",", "\"contras_segment_ids\"", ":", "segment_ids", "}", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", "in", "contras_choices_features", "\n", "]", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "contras_label", "=", "contras_label", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.DataProcessor.get_train_examples": [[62, 65], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.DataProcessor.get_dev_examples": [[66, 69], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.DataProcessor.get_test_examples": [[70, 73], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.DataProcessor.get_labels": [[74, 77], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor.get_train_examples": [[82, 90], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor.get_dev_examples": [[91, 99], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor.get_test_examples": [[100, 108], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._read_txt", "utils_multiple_choice_contrastive.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor.get_labels": [[109, 112], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor._read_txt": [[113, 122], ["glob.glob", "tqdm.tqdm", "open", "json.load", "lines.append"], "methods", ["None"], ["", "def", "_read_txt", "(", "self", ",", "input_dir", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "files", "=", "glob", ".", "glob", "(", "input_dir", "+", "\"/*txt\"", ")", "\n", "for", "file", "in", "tqdm", ".", "tqdm", "(", "files", ",", "desc", "=", "\"read files\"", ")", ":", "\n", "            ", "with", "open", "(", "file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fin", ":", "\n", "                ", "data_raw", "=", "json", ".", "load", "(", "fin", ")", "\n", "data_raw", "[", "\"race_id\"", "]", "=", "file", "\n", "lines", ".", "append", "(", "data_raw", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.RaceProcessor._create_examples": [[123, 144], ["enumerate", "range", "len", "str", "examples.append", "utils_multiple_choice_contrastive.InputExample", "ord", "ord"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "_", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "race_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "data_raw", "[", "\"race_id\"", "]", ")", "\n", "article", "=", "data_raw", "[", "\"article\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data_raw", "[", "\"answers\"", "]", ")", ")", ":", "\n", "                ", "truth", "=", "str", "(", "ord", "(", "data_raw", "[", "\"answers\"", "]", "[", "i", "]", ")", "-", "ord", "(", "\"A\"", ")", ")", "\n", "question", "=", "data_raw", "[", "\"questions\"", "]", "[", "i", "]", "\n", "options", "=", "data_raw", "[", "\"options\"", "]", "[", "i", "]", "\n", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "race_id", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "article", ",", "article", ",", "article", ",", "article", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "options", "[", "0", "]", ",", "options", "[", "1", "]", ",", "options", "[", "2", "]", ",", "options", "[", "3", "]", "]", ",", "\n", "label", "=", "truth", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor.get_train_examples": [[149, 157], ["logger.info", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "utils_multiple_choice_contrastive.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.ReclorProcessor._read_json", "os.path.join", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ",", "negative_version", "=", "1", ",", "negative_extend_version", "=", "91", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_ques_types.npy\"", ")", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_negative_context_cp_v\"", "+", "str", "(", "negative_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_extended_context_cp_v\"", "+", "str", "(", "negative_extend_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.json\"", ")", ")", ",", "\"train\"", ",", "ques_types", ",", "extend_context", ",", "negative_context", ",", "negative_extend_context", ",", "negative_version", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor.get_dev_examples": [[158, 166], ["logger.info", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "utils_multiple_choice_contrastive.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.ReclorProcessor._read_json", "os.path.join", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ",", "negative_version", "=", "1", ",", "negative_extend_version", "=", "91", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_ques_types.npy\"", ")", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_negative_context_cp_v\"", "+", "str", "(", "negative_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_extended_context_cp_v\"", "+", "str", "(", "negative_extend_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val.json\"", ")", ")", ",", "\"dev\"", ",", "ques_types", ",", "extend_context", ",", "negative_context", ",", "negative_extend_context", ",", "negative_version", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor.get_test_examples": [[167, 174], ["logger.info", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "utils_multiple_choice_contrastive.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils_multiple_choice_contrastive.ReclorProcessor._read_json", "os.path.join", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ",", "negative_version", "=", "1", ",", "negative_extend_version", "=", "91", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_ques_types.npy\"", ")", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_negative_context_cp_v\"", "+", "str", "(", "negative_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "negative_extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_extended_context_cp_v\"", "+", "str", "(", "negative_extend_version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.json\"", ")", ")", ",", "\"test\"", ",", "ques_types", ",", "extend_context", ",", "negative_context", ",", "negative_extend_context", ",", "negative_version", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor.get_labels": [[175, 178], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "0", ",", "1", ",", "2", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor._read_json": [[179, 183], ["open", "json.load"], "methods", ["None"], ["", "def", "_read_json", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.ReclorProcessor._create_examples": [[184, 223], ["enumerate", "examples.append", "utils_multiple_choice_contrastive.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "type", ",", "question_types", ",", "extend_contexts", ",", "negative_contexts", ",", "negative_extend_context", ",", "negative_version", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "context", "=", "d", "[", "'context'", "]", "\n", "question", "=", "d", "[", "'question'", "]", "\n", "answers", "=", "d", "[", "'answers'", "]", "\n", "label", "=", "0", "if", "type", "==", "\"test\"", "else", "d", "[", "'label'", "]", "# for test set, there is no label. Just use 0 for convenience.", "\n", "# label = d['label'] # for test set, there is no label. Just use 0 for convenience.", "\n", "id_string", "=", "d", "[", "'id_string'", "]", "\n", "\n", "if", "label", ">", "2", ":", "\n", "# if label < 2:", "\n", "                ", "contras_contexts", "=", "[", "negative_contexts", "[", "i", "]", "[", "0", "]", ",", "context", "]", "\n", "contras_label", "=", "1", "\n", "contras_extend_context", "=", "[", "negative_extend_context", "[", "i", "]", "[", "0", "]", ",", "extend_contexts", "[", "i", "]", "[", "label", "]", "]", "\n", "", "else", ":", "\n", "                ", "contras_contexts", "=", "[", "context", ",", "negative_contexts", "[", "i", "]", "[", "0", "]", "]", "\n", "contras_label", "=", "0", "\n", "contras_extend_context", "=", "[", "extend_contexts", "[", "i", "]", "[", "label", "]", ",", "negative_extend_context", "[", "i", "]", "[", "0", "]", "]", "\n", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "id_string", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "context", ",", "context", ",", "context", ",", "context", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "answers", "[", "0", "]", ",", "answers", "[", "1", "]", ",", "answers", "[", "2", "]", ",", "answers", "[", "3", "]", "]", ",", "\n", "label", "=", "label", ",", "\n", "ques_types", "=", "question_types", "[", "i", "]", ",", "\n", "extend_context", "=", "[", "extend_contexts", "[", "i", "]", "[", "0", "]", ",", "extend_contexts", "[", "i", "]", "[", "1", "]", ",", "extend_contexts", "[", "i", "]", "[", "2", "]", ",", "extend_contexts", "[", "i", "]", "[", "3", "]", "]", ",", "\n", "contras_contexts", "=", "contras_contexts", ",", "\n", "contras_label", "=", "contras_label", ",", "\n", "# contras_endings = [answers[label], answers[label], answers[label]],", "\n", "contras_endings", "=", "[", "answers", "[", "label", "]", ",", "answers", "[", "label", "]", "]", ",", "\n", "contras_extend_context", "=", "contras_extend_context", ",", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice_contrastive.convert_examples_to_features": [[225, 331], ["tqdm.tqdm", "enumerate", "enumerate", "enumerate", "features.append", "enumerate", "logger.info", "zip", "tokenizer.encode_plus", "choices_features.append", "zip", "tokenizer.encode_plus", "contras_choices_features.append", "utils_multiple_choice_contrastive.InputFeatures", "example.question.find", "logger.info", "len", "len", "len", "example.question.find", "logger.info", "len", "len", "len", "example.question.replace", "example.question.replace", "example.question.replace", "example.question.replace", "len"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "\n", "examples", ":", "List", "[", "InputExample", "]", ",", "\n", "label_list", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "ques_type_before", "=", "1", ",", "\n", "whether_extend_context", "=", "False", ",", "\n", ")", "->", "List", "[", "InputFeatures", "]", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "examples", ")", ",", "desc", "=", "\"convert examples to features\"", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "", "choices_features", "=", "[", "]", "\n", "for", "ending_idx", ",", "(", "context", ",", "ending", ")", "in", "enumerate", "(", "zip", "(", "example", ".", "contexts", ",", "example", ".", "endings", ")", ")", ":", "\n", "            ", "text_a", "=", "context", "\n", "if", "example", ".", "question", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "# this is for cloze question", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question.replace(\"_\", ending)", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "ending", ")", "\n", "", "else", ":", "\n", "# text_b = example.question.replace(\"_\", ending) + \" \" + example.ques_types", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "ending", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "ending", "\n", "", "else", ":", "\n", "# text_b = example.question + \" \" + example.ques_types + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "ending", "\n", "\n", "", "", "if", "whether_extend_context", ":", "\n", "                ", "text_b", "=", "text_b", "+", "\" \"", "+", "tokenizer", ".", "additional_special_tokens", "[", "0", "]", "+", "\" \"", "+", "example", ".", "extend_context", "[", "ending_idx", "]", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "text_a", ",", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "pad_to_max_length", "=", "True", ",", "return_attention_mask", "=", "True", ",", "return_token_type_ids", "=", "True", ")", "\n", "if", "\"num_truncated_tokens\"", "in", "inputs", "and", "inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens (swag task is ok). \"", "\n", "\"If you are training ARC and race-data and you are poping question + options,\"", "\n", "\"you need to try to use a bigger max seq length!\"", "\n", ")", "\n", "\n", "", "input_ids", ",", "attention_mask", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "'attention_mask'", "]", "\n", "token_type_ids", "=", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_length", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", "\n", "\n", "choices_features", ".", "append", "(", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ")", ")", "\n", "\n", "", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "contras_choices_features", "=", "[", "]", "\n", "for", "ending_idx", ",", "(", "cont_context", ",", "cont_ending", ")", "in", "enumerate", "(", "zip", "(", "example", ".", "contras_contexts", ",", "example", ".", "contras_endings", ")", ")", ":", "\n", "            ", "text_a", "=", "cont_context", "\n", "if", "example", ".", "question", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question.replace(\"_\", ending)", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "cont_ending", ")", "\n", "", "else", ":", "\n", "# text_b = example.question.replace(\"_\", ending) + \" \" + example.ques_types", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "cont_ending", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "cont_ending", "\n", "", "else", ":", "\n", "# text_b = example.question + \" \" + example.ques_types + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "cont_ending", "\n", "\n", "", "", "if", "whether_extend_context", ":", "\n", "                ", "text_b", "=", "text_b", "+", "\" \"", "+", "tokenizer", ".", "additional_special_tokens", "[", "0", "]", "+", "\" \"", "+", "example", ".", "contras_extend_context", "[", "ending_idx", "]", "\n", "\n", "", "contras_inputs", "=", "tokenizer", ".", "encode_plus", "(", "text_a", ",", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "pad_to_max_length", "=", "True", ",", "return_attention_mask", "=", "True", ",", "return_token_type_ids", "=", "True", ")", "\n", "if", "\"num_truncated_tokens\"", "in", "contras_inputs", "and", "contras_inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens (swag task is ok). \"", "\n", "\"If you are training ARC and race-data and you are poping question + options,\"", "\n", "\"you need to try to use a bigger max seq length!\"", "\n", ")", "\n", "\n", "", "contras_input_ids", ",", "contras_attention_mask", "=", "contras_inputs", "[", "\"input_ids\"", "]", ",", "contras_inputs", "[", "'attention_mask'", "]", "\n", "contras_token_type_ids", "=", "contras_inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "assert", "len", "(", "contras_input_ids", ")", "==", "max_length", "\n", "assert", "len", "(", "contras_attention_mask", ")", "==", "max_length", "\n", "assert", "len", "(", "contras_token_type_ids", ")", "==", "max_length", "\n", "\n", "contras_choices_features", ".", "append", "(", "(", "contras_input_ids", ",", "contras_attention_mask", ",", "contras_token_type_ids", ")", ")", "\n", "\n", "", "contras_label", "=", "example", ".", "contras_label", "\n", "\n", "features", ".", "append", "(", "InputFeatures", "(", "example_id", "=", "example", ".", "example_id", ",", "choices_features", "=", "choices_features", ",", "contras_choices_features", "=", "contras_choices_features", ",", "label", "=", "label", ",", "contras_label", "=", "contras_label", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.init_args": [[46, 212], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "MODEL_CLASSES.keys"], "function", ["None"], ["def", "init_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", ",", "# + \", \".join(ALL_MODELS),", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run test on the test set\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "type", "=", "str", ",", "help", "=", "'betas for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_clip_grad_norm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether not to clip grad norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Linear warmup over warmup ratios.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ques_type_before\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Whether to place question type before question\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--whether_extend_context\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to utilize the logic-driven context extension framework\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--extended_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of extended context\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--negative_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of negative context\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--negative_entend_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of negative entend context\"", ",", "\n", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.set_seed": [[214, 220], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.select_field": [[222, 224], ["None"], "function", ["None"], ["", "", "def", "select_field", "(", "features", ",", "field", ")", ":", "\n", "    ", "return", "[", "[", "choice", "[", "field", "]", "for", "choice", "in", "feature", ".", "choices_features", "]", "for", "feature", "in", "features", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.select_contras_field": [[225, 227], ["None"], "function", ["None"], ["", "def", "select_contras_field", "(", "features", ",", "field", ")", ":", "\n", "    ", "return", "[", "[", "choice", "[", "field", "]", "for", "choice", "in", "feature", ".", "contras_choices_features", "]", "for", "feature", "in", "features", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.simple_accuracy": [[228, 230], ["None"], "function", ["None"], ["", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.load_and_cache_examples": [[232, 299], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "logger.info", "utils_multiple_choice_contrastive.convert_examples_to_features", "torch.distributed.barrier", "main_large_contrastive.select_field", "main_large_contrastive.select_field", "main_large_contrastive.select_field", "main_large_contrastive.select_contras_field", "main_large_contrastive.select_contras_field", "main_large_contrastive.select_contras_field", "list().pop", "str", "str", "processor.get_dev_examples", "str", "logger.info", "torch.save", "processor.get_test_examples", "processor.get_train_examples", "len", "bool", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.convert_examples_to_features", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.select_contras_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.select_contras_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.select_contras_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_dev_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_test_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_train_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "if", "evaluate", ":", "\n", "        ", "cached_mode", "=", "\"dev\"", "\n", "", "elif", "test", ":", "\n", "        ", "cached_mode", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "cached_mode", "=", "\"train\"", "\n", "", "assert", "not", "(", "evaluate", "and", "test", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}_contras_extn\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "evaluate", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ",", "args", ".", "negative_context_version", ",", "args", ".", "negative_entend_context_version", ")", "\n", "", "elif", "test", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ",", "args", ".", "negative_context_version", ",", "args", ".", "negative_entend_context_version", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ",", "args", ".", "negative_context_version", ",", "args", ".", "negative_entend_context_version", ")", "\n", "", "logger", ".", "info", "(", "\"Training number: %s\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "ques_type_before", "=", "args", ".", "ques_type_before", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "whether_extend_context", "=", "args", ".", "whether_extend_context", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_mask\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"segment_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# augmented data", "\n", "all_contras_input_ids", "=", "torch", ".", "tensor", "(", "select_contras_field", "(", "features", ",", "\"contras_input_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_contras_input_mask", "=", "torch", ".", "tensor", "(", "select_contras_field", "(", "features", ",", "\"contras_input_mask\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_contras_segment_ids", "=", "torch", ".", "tensor", "(", "select_contras_field", "(", "features", ",", "\"contras_segment_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_contras_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "contras_label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ",", "all_contras_input_ids", ",", "all_contras_input_mask", ",", "all_contras_segment_ids", ",", "all_contras_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.train": [[301, 553], ["torch.utils.data.DataLoader", "exec", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "main_large_contrastive.load_and_cache_examples", "torch.nn.parallel.DistributedDataParallel.zero_grad", "main_large_contrastive.set_seed", "range", "str().split", "os.path.join", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "int", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "numpy.argmax", "main_large_contrastive.simple_accuracy", "main_large_contrastive.evaluate", "logger.info", "SummaryWriter.add_scalar", "evaluate.items", "logger.info", "int", "logger.info", "logger.info", "enumerate", "main_large_contrastive.train.evaluate_model"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.set_seed", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.simple_accuracy", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", "=", "None", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "str_list", "=", "str", "(", "args", ".", "output_dir", ")", ".", "split", "(", "'/'", ")", "\n", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "'summaries'", ",", "str_list", "[", "-", "1", "]", ")", "\n", "tb_writer", "=", "SummaryWriter", "(", "tb_log_dir", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "exec", "(", "'args.adam_betas = '", "+", "args", ".", "adam_betas", ")", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "betas", "=", "args", ".", "adam_betas", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "assert", "not", "(", "(", "args", ".", "warmup_steps", ">", "0", ")", "and", "(", "args", ".", "warmup_proportion", ">", "0", ")", ")", ",", "\"--only can set one of --warmup_steps and --warm_ratio \"", "\n", "if", "args", ".", "warmup_proportion", ">", "0", ":", "\n", "        ", "args", ".", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_proportion", ")", "\n", "", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"************************* Running training *************************\"", ")", "\n", "logger", ".", "info", "(", "\"Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "# logger.info(\"Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)", "\n", "logger", ".", "info", "(", "\"Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "val_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "test", "=", "False", ")", "\n", "\n", "def", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", ":", "\n", "        ", "train_preds", "=", "np", ".", "argmax", "(", "train_preds", ",", "axis", "=", "1", ")", "\n", "train_acc", "=", "simple_accuracy", "(", "train_preds", ",", "train_label_ids", ")", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "val_dataset", ")", "\n", "logger", ".", "info", "(", "\n", "\"dev acc: %s, loss: %s, global steps: %s\"", ",", "\n", "str", "(", "results", "[", "\"eval_acc\"", "]", ")", ",", "\n", "str", "(", "results", "[", "\"eval_loss\"", "]", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/acc\"", ",", "train_acc", ",", "global_step", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "if", "results", "[", "\"eval_acc\"", "]", ">", "best_dev_acc", ":", "\n", "            ", "best_dev_acc", "=", "results", "[", "\"eval_acc\"", "]", "\n", "best_steps", "=", "global_step", "\n", "logger", ".", "info", "(", "\"!!!!!!!!!!!!!!!!!!!! achieve BEST dev acc: %s at global step: %s\"", ",", "\n", "str", "(", "best_dev_acc", ")", ",", "\n", "str", "(", "best_steps", ")", "\n", ")", "\n", "\n", "# save best dev acc model", "\n", "output_dir", "=", "args", ".", "output_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "logger", ".", "info", "(", "\"Current local rank %s\"", ",", "args", ".", "local_rank", ")", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_vocabulary", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "txt_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'best_dev_results.txt'", ")", "\n", "with", "open", "(", "txt_dir", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "rs", "=", "'global_steps: {}; dev_acc: {}'", ".", "format", "(", "global_step", ",", "best_dev_acc", ")", "\n", "f", ".", "write", "(", "rs", ")", "\n", "tb_writer", ".", "add_text", "(", "'best_results'", ",", "rs", ",", "global_step", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"current BEST dev acc: %s at global step: %s\"", ",", "\n", "str", "(", "best_dev_acc", ")", ",", "\n", "str", "(", "best_steps", ")", "\n", ")", "\n", "\n", "return", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "\n", "\n", "", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_acc", "=", "0.0", "\n", "best_steps", "=", "0", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "model", ".", "zero_grad", "(", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "epoch_index", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "''", ")", "\n", "logger", ".", "info", "(", "'%s Epoch: %d %s'", ",", "'*'", "*", "50", ",", "epoch_index", ",", "'*'", "*", "50", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "\n", "else", "None", ",", "# XLM, Roberta don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "logits_1", "=", "outputs", "[", "1", "]", "\n", "\n", "# inputs_2 = {", "\n", "#     \"input_ids\": batch[4],", "\n", "#     \"attention_mask\": batch[5],", "\n", "#     \"token_type_ids\": batch[6]", "\n", "#     if args.model_type in [\"bert\", \"xlnet\", \"albert\"]", "\n", "#     else None,", "\n", "#     \"labels\": batch[7],", "\n", "# }", "\n", "# outputs_2 = model(**inputs_2)", "\n", "# loss_2 = outputs_2[0]", "\n", "# loss = loss + loss_2", "\n", "\n", "################# work only gpu = 1 ######################", "\n", "if", "train_preds", "is", "None", ":", "\n", "                ", "train_preds", "=", "logits_1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "train_label_ids", "=", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "train_preds", "=", "np", ".", "append", "(", "train_preds", ",", "logits_1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "train_label_ids", "=", "np", ".", "append", "(", "train_label_ids", ",", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "###########################################################", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "# scaled_loss.backward(retain_graph=True)", "\n", "", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "# loss.backward(retain_graph=True)", "\n", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "\n", "\n", "inputs_2", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "4", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "5", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "6", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "\n", "else", "None", ",", "\n", "\"labels\"", ":", "batch", "[", "7", "]", ",", "\n", "}", "\n", "outputs_2", "=", "model", "(", "**", "inputs_2", ")", "\n", "loss_2", "=", "outputs_2", "[", "0", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss_2", "=", "loss_2", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss_2", "=", "loss_2", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss_2", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "", "else", ":", "\n", "                ", "loss_2", ".", "backward", "(", ")", "\n", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "", "tr_loss", "+=", "loss_2", ".", "item", "(", ")", "\n", "\n", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"********** Iteration %d: current loss: %s\"", ",", "step", ",", "str", "(", "round", "(", "loss", ".", "item", "(", ")", ",", "4", ")", ")", ",", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "# optimizer.zero_grad()", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# if (args.local_rank == -1 and args.evaluate_during_training):  # Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"Average loss: %s, average acc: %s at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "train_acc", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:", "\n", "#     save_model(args, model, tokenizer)", "\n", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "train_preds", "is", "not", "None", ":", "\n", "        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", "\n", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.evaluate": [[555, 625], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.argmax", "main_large_contrastive.simple_accuracy", "results.update", "logger.info", "os.makedirs", "max", "torch.nn.DataParallel", "len", "tuple", "sorted", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "result.keys", "logger.info", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "str", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.simple_accuracy"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "val_dataset", "=", "None", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", "=", "val_dataset", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"************************* Running evaluation {} *************************\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "acc", "=", "simple_accuracy", "(", "preds", ",", "out_label_ids", ")", "\n", "\n", "result", "=", "{", "\"eval_acc\"", ":", "acc", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "str", "(", "prefix", ")", "+", "\"----is test:\"", "+", "str", "(", "test", ")", ")", ")", "\n", "if", "test", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"%s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "\n", "", "", "", "if", "test", ":", "\n", "        ", "return", "results", ",", "preds", "\n", "", "else", ":", "\n", "        ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large_contrastive.main": [[627, 748], ["main_large_contrastive.init_args", "print", "main_large_contrastive.set_seed", "logging.basicConfig", "logger.warning", "init_args.task_name.lower", "processor.get_labels", "len", "init_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "print", "model_class.from_pretrained.to", "logger.info", "main_large_contrastive.load_and_cache_examples", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.cuda.device_count", "print", "torch.distributed.init_process_group", "logger.warning", "torch.distributed.get_rank", "torch.cuda.set_device", "torch.device", "bool", "ValueError", "torch.distributed.barrier", "tokenizer_class.from_pretrained.add_special_tokens", "model_class.from_pretrained.resize_token_embeddings", "torch.distributed.barrier", "main_large_contrastive.load_and_cache_examples", "main_large_contrastive.train", "logger.info", "logger.info", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "main_large_contrastive.evaluate", "numpy.save", "torch.distributed.get_rank", "torch.cuda.device_count", "bool", "len", "os.path.join", "logger.info", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.init_args", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.set_seed", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.train", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.evaluate"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "init_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "print", "(", "args", ".", "local_rank", ")", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "print", "(", "\"num gpu\"", ",", "args", ".", "n_gpu", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "logger", ".", "warning", "(", "'local_rank: %s, gpu_num: %s'", ",", "torch", ".", "distributed", ".", "get_rank", "(", ")", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", ")", "\n", "args", ".", "local_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# set random seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "print", "(", "config", ")", "\n", "\n", "if", "args", ".", "whether_extend_context", ":", "\n", "# add special token [EXT]", "\n", "        ", "special_tokens_dict", "=", "{", "'additional_special_tokens'", ":", "[", "'<ext>'", "]", "}", "\n", "num_added_toks", "=", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "best_steps", "=", "0", "\n", "\n", "test_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "True", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "global_step", ",", "tr_loss", ",", "best_steps", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", ")", "\n", "logger", ".", "info", "(", "\"global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Test", "\n", "\n", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "checkpoint_dir", "=", "args", ".", "model_name_or_path", "\n", "", "if", "args", ".", "evaluate_during_training", ":", "\n", "            ", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ")", "\n", "", "logger", ".", "info", "(", "'load checkpoint_dir: %s'", ",", "checkpoint_dir", ")", "\n", "logger", ".", "info", "(", "'current local rank: %s'", ",", "args", ".", "local_rank", ")", "\n", "if", "best_steps", ":", "\n", "            ", "logger", ".", "info", "(", "\"best steps of eval acc is the following checkpoints: %s\"", ",", "best_steps", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "preds", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "test_dataset", ",", "test", "=", "True", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"test_preds.npy\"", "if", "args", ".", "output_dir", "is", "not", "None", "else", "\"test_preds.npy\"", ")", ",", "preds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.InputExample.__init__": [[18, 36], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "example_id", ",", "question", ",", "contexts", ",", "endings", ",", "label", "=", "None", ",", "ques_types", "=", "\"\"", ",", "extend_context", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "contexts", "=", "contexts", "\n", "self", ".", "endings", "=", "endings", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "ques_types", "=", "ques_types", "\n", "self", ".", "extend_context", "=", "extend_context", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.InputFeatures.__init__": [[39, 46], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "choices_features", ",", "label", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "choices_features", "=", "[", "\n", "{", "\"input_ids\"", ":", "input_ids", ",", "\"input_mask\"", ":", "input_mask", ",", "\"segment_ids\"", ":", "segment_ids", "}", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", "in", "choices_features", "\n", "]", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.DataProcessor.get_train_examples": [[51, 54], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.DataProcessor.get_dev_examples": [[55, 58], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.DataProcessor.get_test_examples": [[59, 62], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.DataProcessor.get_labels": [[63, 66], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor.get_train_examples": [[71, 79], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor.get_dev_examples": [[80, 88], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor.get_test_examples": [[89, 97], ["logger.info", "os.path.join", "os.path.join", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._read_txt", "utils_multiple_choice.RaceProcessor._create_examples"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "high", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/high\"", ")", "\n", "middle", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test/middle\"", ")", "\n", "high", "=", "self", ".", "_read_txt", "(", "high", ")", "\n", "middle", "=", "self", ".", "_read_txt", "(", "middle", ")", "\n", "return", "self", ".", "_create_examples", "(", "high", "+", "middle", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor.get_labels": [[98, 101], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._read_txt": [[102, 111], ["glob.glob", "tqdm.tqdm", "open", "json.load", "lines.append"], "methods", ["None"], ["", "def", "_read_txt", "(", "self", ",", "input_dir", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "files", "=", "glob", ".", "glob", "(", "input_dir", "+", "\"/*txt\"", ")", "\n", "for", "file", "in", "tqdm", ".", "tqdm", "(", "files", ",", "desc", "=", "\"read files\"", ")", ":", "\n", "            ", "with", "open", "(", "file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fin", ":", "\n", "                ", "data_raw", "=", "json", ".", "load", "(", "fin", ")", "\n", "data_raw", "[", "\"race_id\"", "]", "=", "file", "\n", "lines", ".", "append", "(", "data_raw", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.RaceProcessor._create_examples": [[112, 133], ["enumerate", "range", "len", "str", "examples.append", "utils_multiple_choice.InputExample", "ord", "ord"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "_", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "race_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "data_raw", "[", "\"race_id\"", "]", ")", "\n", "article", "=", "data_raw", "[", "\"article\"", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data_raw", "[", "\"answers\"", "]", ")", ")", ":", "\n", "                ", "truth", "=", "str", "(", "ord", "(", "data_raw", "[", "\"answers\"", "]", "[", "i", "]", ")", "-", "ord", "(", "\"A\"", ")", ")", "\n", "question", "=", "data_raw", "[", "\"questions\"", "]", "[", "i", "]", "\n", "options", "=", "data_raw", "[", "\"options\"", "]", "[", "i", "]", "\n", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "race_id", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "article", ",", "article", ",", "article", ",", "article", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "options", "[", "0", "]", ",", "options", "[", "1", "]", ",", "options", "[", "2", "]", ",", "options", "[", "3", "]", "]", ",", "\n", "label", "=", "truth", ",", "\n", ")", "\n", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_train_examples": [[138, 145], ["logger.info", "numpy.load", "print", "numpy.load", "utils_multiple_choice.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_ques_types.npy\"", ")", ")", "\n", "print", "(", "\"load context cp data\"", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.json\"", ")", ")", ",", "\"train\"", ",", "ques_types", ",", "extend_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_dev_examples": [[146, 152], ["logger.info", "numpy.load", "numpy.load", "utils_multiple_choice.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_ques_types.npy\"", ")", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val.json\"", ")", ")", ",", "\"dev\"", ",", "ques_types", ",", "extend_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_test_examples": [[153, 158], ["logger.info", "numpy.load", "numpy.load", "utils_multiple_choice.ReclorProcessor._create_examples", "os.path.join", "os.path.join", "utils_multiple_choice.ReclorProcessor._read_json", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ",", "version", "=", "1", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "ques_types", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_ques_types.npy\"", ")", ")", "\n", "extend_context", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test_extended_context_cp_v\"", "+", "str", "(", "version", ")", "+", "\".npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_json", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.json\"", ")", ")", ",", "\"test\"", ",", "ques_types", ",", "extend_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_labels": [[159, 162], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "0", ",", "1", ",", "2", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._read_json": [[163, 167], ["open", "json.load"], "methods", ["None"], ["", "def", "_read_json", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "with", "open", "(", "input_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor._create_examples": [[168, 190], ["enumerate", "examples.append", "utils_multiple_choice.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "type", ",", "question_types", ",", "extend_contexts", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "context", "=", "d", "[", "'context'", "]", "\n", "question", "=", "d", "[", "'question'", "]", "\n", "answers", "=", "d", "[", "'answers'", "]", "\n", "label", "=", "0", "if", "type", "==", "\"test\"", "else", "d", "[", "'label'", "]", "# for test set, there is no label. Just use 0 for convenience.", "\n", "# label = d['label'] # for test set, there is no label. Just use 0 for convenience.", "\n", "id_string", "=", "d", "[", "'id_string'", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "id_string", ",", "\n", "question", "=", "question", ",", "\n", "contexts", "=", "[", "context", ",", "context", ",", "context", ",", "context", "]", ",", "# this is not efficient but convenient", "\n", "endings", "=", "[", "answers", "[", "0", "]", ",", "answers", "[", "1", "]", ",", "answers", "[", "2", "]", ",", "answers", "[", "3", "]", "]", ",", "\n", "label", "=", "label", ",", "\n", "ques_types", "=", "question_types", "[", "i", "]", ",", "\n", "extend_context", "=", "[", "extend_contexts", "[", "i", "]", "[", "0", "]", ",", "extend_contexts", "[", "i", "]", "[", "1", "]", ",", "extend_contexts", "[", "i", "]", "[", "2", "]", ",", "extend_contexts", "[", "i", "]", "[", "3", "]", "]", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.convert_examples_to_features": [[192, 259], ["list", "tqdm.tqdm", "enumerate", "enumerate", "features.append", "enumerate", "logger.info", "zip", "tokenizer.encode_plus", "choices_features.append", "utils_multiple_choice.InputFeatures", "example.question.find", "logger.info", "len", "len", "len", "example.question.replace", "example.question.replace", "len"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "\n", "examples", ":", "List", "[", "InputExample", "]", ",", "\n", "label_list", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "ques_type_before", "=", "1", ",", "\n", "whether_extend_context", "=", "False", ",", "\n", ")", "->", "List", "[", "InputFeatures", "]", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "all_length", "=", "list", "(", ")", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "examples", ")", ",", "desc", "=", "\"convert examples to features\"", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "", "choices_features", "=", "[", "]", "\n", "for", "ending_idx", ",", "(", "context", ",", "ending", ")", "in", "enumerate", "(", "zip", "(", "example", ".", "contexts", ",", "example", ".", "endings", ")", ")", ":", "\n", "            ", "text_a", "=", "context", "\n", "if", "example", ".", "question", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "# this is for cloze question", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question.replace(\"_\", ending)", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "ending", ")", "\n", "", "else", ":", "\n", "# text_b = example.question.replace(\"_\", ending) + \" \" + example.ques_types", "\n", "                    ", "text_b", "=", "example", ".", "question", ".", "replace", "(", "\"_\"", ",", "ending", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "ques_type_before", ":", "\n", "# text_b = example.ques_types + \" \" + example.question + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "ending", "\n", "", "else", ":", "\n", "# text_b = example.question + \" \" + example.ques_types + \" \" + ending", "\n", "                    ", "text_b", "=", "example", ".", "question", "+", "\" \"", "+", "ending", "\n", "\n", "", "", "if", "whether_extend_context", ":", "\n", "                ", "text_b", "=", "text_b", "+", "\" \"", "+", "tokenizer", ".", "additional_special_tokens", "[", "0", "]", "+", "\" \"", "+", "example", ".", "extend_context", "[", "ending_idx", "]", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "text_a", ",", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "pad_to_max_length", "=", "True", ",", "return_attention_mask", "=", "True", ",", "return_token_type_ids", "=", "True", ")", "\n", "if", "\"num_truncated_tokens\"", "in", "inputs", "and", "inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens (swag task is ok). \"", "\n", "\"If you are training ARC and race-data and you are poping question + options,\"", "\n", "\"you need to try to use a bigger max seq length!\"", "\n", ")", "\n", "\n", "", "input_ids", ",", "attention_mask", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "'attention_mask'", "]", "\n", "token_type_ids", "=", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_length", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", "\n", "\n", "choices_features", ".", "append", "(", "(", "input_ids", ",", "attention_mask", ",", "token_type_ids", ")", ")", "\n", "\n", "", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "features", ".", "append", "(", "InputFeatures", "(", "example_id", "=", "example", ".", "example_id", ",", "choices_features", "=", "choices_features", ",", "label", "=", "label", ",", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.init_args": [[47, 210], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "MODEL_CLASSES.keys"], "function", ["None"], ["def", "init_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", ",", "# + \", \".join(ALL_MODELS),", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run test on the test set\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_betas'", ",", "default", "=", "'(0.9, 0.999)'", ",", "type", "=", "str", ",", "help", "=", "'betas for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_clip_grad_norm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"whether not to clip grad norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Linear warmup over warmup ratios.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ques_type_before\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Whether to place question type before question\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--whether_extend_context\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to utilize the logic-driven context extension framework\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--extended_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of extended context\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--negative_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of negative context\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--negative_entend_context_version\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The version of negative entend context\"", ",", "\n", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.set_seed": [[212, 218], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field": [[220, 222], ["None"], "function", ["None"], ["", "", "def", "select_field", "(", "features", ",", "field", ")", ":", "\n", "    ", "return", "[", "[", "choice", "[", "field", "]", "for", "choice", "in", "feature", ".", "choices_features", "]", "for", "feature", "in", "features", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.simple_accuracy": [[224, 226], ["None"], "function", ["None"], ["", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples": [[228, 289], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "logger.info", "utils_multiple_choice.convert_examples_to_features", "torch.distributed.barrier", "main_large.select_field", "main_large.select_field", "main_large.select_field", "list().pop", "str", "str", "processor.get_dev_examples", "str", "logger.info", "torch.save", "processor.get_test_examples", "processor.get_train_examples", "len", "bool", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.convert_examples_to_features", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.select_field", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_dev_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_test_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_train_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "if", "evaluate", ":", "\n", "        ", "cached_mode", "=", "\"dev\"", "\n", "", "elif", "test", ":", "\n", "        ", "cached_mode", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "cached_mode", "=", "\"train\"", "\n", "", "assert", "not", "(", "evaluate", "and", "test", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}_questype_extn\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "evaluate", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ")", "\n", "", "elif", "test", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "args", ".", "extended_context_version", ")", "\n", "", "logger", ".", "info", "(", "\"Training number: %s\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "ques_type_before", "=", "args", ".", "ques_type_before", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "whether_extend_context", "=", "args", ".", "whether_extend_context", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"input_mask\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "select_field", "(", "features", ",", "\"segment_ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.train": [[291, 496], ["torch.utils.data.DataLoader", "exec", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "main_large.load_and_cache_examples", "torch.nn.parallel.DistributedDataParallel.zero_grad", "main_large.set_seed", "range", "str().split", "os.path.join", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "int", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "numpy.argmax", "main_large.simple_accuracy", "main_large.evaluate", "logger.info", "SummaryWriter.add_scalar", "evaluate.items", "logger.info", "int", "logger.info", "logger.info", "enumerate", "main_large.train.evaluate_model"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.set_seed", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.simple_accuracy", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", "=", "None", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "str_list", "=", "str", "(", "args", ".", "output_dir", ")", ".", "split", "(", "'/'", ")", "\n", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "'summaries'", ",", "str_list", "[", "-", "1", "]", ")", "\n", "tb_writer", "=", "SummaryWriter", "(", "tb_log_dir", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "exec", "(", "'args.adam_betas = '", "+", "args", ".", "adam_betas", ")", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "betas", "=", "args", ".", "adam_betas", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "assert", "not", "(", "(", "args", ".", "warmup_steps", ">", "0", ")", "and", "(", "args", ".", "warmup_proportion", ">", "0", ")", ")", ",", "\"--only can set one of --warmup_steps and --warm_ratio \"", "\n", "if", "args", ".", "warmup_proportion", ">", "0", ":", "\n", "        ", "args", ".", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_proportion", ")", "\n", "", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"************************* Running training *************************\"", ")", "\n", "logger", ".", "info", "(", "\"Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "# logger.info(\"Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)", "\n", "logger", ".", "info", "(", "\"Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "val_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "test", "=", "False", ")", "\n", "\n", "def", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", ":", "\n", "        ", "train_preds", "=", "np", ".", "argmax", "(", "train_preds", ",", "axis", "=", "1", ")", "\n", "train_acc", "=", "simple_accuracy", "(", "train_preds", ",", "train_label_ids", ")", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "val_dataset", ")", "\n", "logger", ".", "info", "(", "\n", "\"dev acc: %s, loss: %s, global steps: %s\"", ",", "\n", "str", "(", "results", "[", "\"eval_acc\"", "]", ")", ",", "\n", "str", "(", "results", "[", "\"eval_loss\"", "]", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/acc\"", ",", "train_acc", ",", "global_step", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "if", "results", "[", "\"eval_acc\"", "]", ">", "best_dev_acc", ":", "\n", "            ", "best_dev_acc", "=", "results", "[", "\"eval_acc\"", "]", "\n", "best_steps", "=", "global_step", "\n", "logger", ".", "info", "(", "\"!!!!!!!!!!!!!!!!!!!! achieve BEST dev acc: %s at global step: %s\"", ",", "\n", "str", "(", "best_dev_acc", ")", ",", "\n", "str", "(", "best_steps", ")", "\n", ")", "\n", "\n", "# save best dev acc model", "\n", "output_dir", "=", "args", ".", "output_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "logger", ".", "info", "(", "\"Current local rank %s\"", ",", "args", ".", "local_rank", ")", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_vocabulary", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "txt_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'best_dev_results.txt'", ")", "\n", "with", "open", "(", "txt_dir", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "rs", "=", "'global_steps: {}; dev_acc: {}'", ".", "format", "(", "global_step", ",", "best_dev_acc", ")", "\n", "f", ".", "write", "(", "rs", ")", "\n", "tb_writer", ".", "add_text", "(", "'best_results'", ",", "rs", ",", "global_step", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"current BEST dev acc: %s at global step: %s\"", ",", "\n", "str", "(", "best_dev_acc", ")", ",", "\n", "str", "(", "best_steps", ")", "\n", ")", "\n", "\n", "return", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "\n", "\n", "", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_acc", "=", "0.0", "\n", "best_steps", "=", "0", "\n", "train_preds", "=", "None", "\n", "train_label_ids", "=", "None", "\n", "model", ".", "zero_grad", "(", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "epoch_index", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "''", ")", "\n", "logger", ".", "info", "(", "'%s Epoch: %d %s'", ",", "'*'", "*", "50", ",", "epoch_index", ",", "'*'", "*", "50", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "\n", "else", "None", ",", "# XLM, Roberta don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "logits", "=", "outputs", "[", "1", "]", "\n", "\n", "################# work only gpu = 1 ######################", "\n", "if", "train_preds", "is", "None", ":", "\n", "                ", "train_preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "train_label_ids", "=", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "train_preds", "=", "np", ".", "append", "(", "train_preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "train_label_ids", "=", "np", ".", "append", "(", "train_label_ids", ",", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "###########################################################", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "if", "not", "args", ".", "no_clip_grad_norm", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "step", "%", "20", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"********** Iteration %d: current loss: %s\"", ",", "step", ",", "str", "(", "round", "(", "loss", ".", "item", "(", ")", ",", "4", ")", ")", ",", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "# optimizer.zero_grad()", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# if (args.local_rank == -1 and args.evaluate_during_training):  # Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"training/loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"Average loss: %s, average acc: %s at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "train_acc", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:", "\n", "#     save_model(args, model, tokenizer)", "\n", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "train_preds", "is", "not", "None", ":", "\n", "        ", "train_preds", ",", "train_label_ids", ",", "train_acc", ",", "best_steps", ",", "best_dev_acc", "=", "evaluate_model", "(", "train_preds", ",", "train_label_ids", ",", "tb_writer", ",", "args", ",", "model", ",", "tokenizer", ",", "best_steps", ",", "best_dev_acc", ",", "val_dataset", ")", "\n", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.evaluate": [[498, 567], ["zip", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.argmax", "main_large.simple_accuracy", "results.update", "logger.info", "os.makedirs", "max", "torch.nn.DataParallel", "len", "tuple", "sorted", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "result.keys", "logger.info", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "str", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.simple_accuracy"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "val_dataset", "=", "None", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", "=", "val_dataset", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"************************* Running evaluation {} *************************\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"labels\"", ":", "batch", "[", "3", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "acc", "=", "simple_accuracy", "(", "preds", ",", "out_label_ids", ")", "\n", "\n", "result", "=", "{", "\"eval_acc\"", ":", "acc", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "str", "(", "prefix", ")", "+", "\"----is test:\"", "+", "str", "(", "test", ")", ")", ")", "\n", "if", "test", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"%s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "\n", "", "", "", "if", "test", ":", "\n", "        ", "return", "results", ",", "preds", "\n", "", "else", ":", "\n", "        ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.main": [[569, 689], ["main_large.init_args", "main_large.set_seed", "logging.basicConfig", "logger.warning", "init_args.task_name.lower", "processor.get_labels", "len", "init_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "main_large.load_and_cache_examples", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.cuda.device_count", "torch.distributed.init_process_group", "logger.warning", "torch.distributed.get_rank", "torch.cuda.set_device", "torch.device", "bool", "ValueError", "torch.distributed.barrier", "tokenizer_class.from_pretrained.add_special_tokens", "model_class.from_pretrained.resize_token_embeddings", "torch.distributed.barrier", "main_large.load_and_cache_examples", "main_large.train", "logger.info", "logger.info", "logger.info", "model_class.from_pretrained", "model_class.from_pretrained.to", "main_large.evaluate", "numpy.save", "torch.distributed.get_rank", "torch.cuda.device_count", "bool", "len", "os.path.join", "logger.info", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.init_args", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.set_seed", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.utils_multiple_choice.ReclorProcessor.get_labels", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.load_and_cache_examples", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.train", "home.repos.pwc.inspect_result.WangsyGit_LReasoner.Scripts.main_large.evaluate"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "init_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "logger", ".", "warning", "(", "'local_rank: %s, gpu_num: %s'", ",", "torch", ".", "distributed", ".", "get_rank", "(", ")", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ",", ")", "\n", "args", ".", "local_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# set random seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# logger.info('n_gpu: %s, world_size: %s', args.n_gpu, torch.distributed.get_world_size())", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "whether_extend_context", ":", "\n", "# add special token [EXT]", "\n", "        ", "special_tokens_dict", "=", "{", "'additional_special_tokens'", ":", "[", "'<ext>'", "]", "}", "\n", "num_added_toks", "=", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "best_steps", "=", "0", "\n", "\n", "test_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "True", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "global_step", ",", "tr_loss", ",", "best_steps", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", ")", "\n", "logger", ".", "info", "(", "\"global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Test", "\n", "\n", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "checkpoint_dir", "=", "args", ".", "model_name_or_path", "\n", "", "if", "args", ".", "evaluate_during_training", ":", "\n", "            ", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ")", "\n", "", "logger", ".", "info", "(", "'load checkpoint_dir: %s'", ",", "checkpoint_dir", ")", "\n", "logger", ".", "info", "(", "'current local rank: %s'", ",", "args", ".", "local_rank", ")", "\n", "if", "best_steps", ":", "\n", "            ", "logger", ".", "info", "(", "\"best steps of eval acc is the following checkpoints: %s\"", ",", "best_steps", ")", "\n", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "preds", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "test_dataset", ",", "test", "=", "True", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"test_preds.npy\"", "if", "args", ".", "output_dir", "is", "not", "None", "else", "\"test_preds.npy\"", ")", ",", "preds", ")", "\n", "\n"]]}