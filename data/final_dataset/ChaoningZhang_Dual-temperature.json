{"home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.None.main_pretrain.main": [[59, 212], ["pytorch_lightning.seed_everything", "solo.args.setup.parse_args_pretrain", "type.", "pytorch_lightning.Trainer.from_argparse_args", "os.path.exists", "shutil.copytree", "shutil.copytree", "shutil.copyfile", "type", "solo.utils.pretrain_dataloader.prepare_datasets", "solo.utils.pretrain_dataloader.prepare_dataloader", "pytorch_lightning.loggers.WandbLogger", "pytorch_lightning.loggers.WandbLogger.watch", "pytorch_lightning.loggers.WandbLogger.log_hyperparams", "pytorch_lightning.callbacks.LearningRateMonitor", "callbacks.append", "solo.utils.checkpointer.Checkpointer", "callbacks.append", "os.path.exists", "os.mkdir", "print", "shutil.rmtree", "os.mkdir", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "Trainer.from_argparse_args.fit", "Trainer.from_argparse_args.fit", "solo.methods.METHODS.keys", "solo.utils.pretrain_dataloader.prepare_transform", "print", "pprint.pprint", "solo.utils.pretrain_dataloader.prepare_multicrop_transform", "solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.classification_dataloader.prepare_data", "AutoUMAP", "callbacks.append", "pytorch_lightning.plugins.DDPPlugin", "solo.utils.pretrain_dataloader.prepare_transform", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.setup.parse_args_pretrain", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_dataloader", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_multicrop_transform", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_data", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_transform"], ["def", "main", "(", ")", ":", "\n", "    ", "seed_everything", "(", "15", ")", "\n", "\n", "args", "=", "parse_args_pretrain", "(", ")", "\n", "\n", "assert", "args", ".", "method", "in", "METHODS", ",", "f\"Choose from {METHODS.keys()}\"", "\n", "\n", "MethodClass", "=", "METHODS", "[", "args", ".", "method", "]", "\n", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "(", "\n", "_dali_avaliable", "\n", ")", ",", "\"Dali is not currently avaiable, please install it first with [dali].\"", "\n", "MethodClass", "=", "type", "(", "f\"Dali{MethodClass.__name__}\"", ",", "(", "MethodClass", ",", "PretrainABC", ")", ",", "{", "}", ")", "\n", "\n", "# import pdb; pdb.set_trace()", "\n", "", "model", "=", "MethodClass", "(", "**", "args", ".", "__dict__", ")", "\n", "\n", "# contrastive dataloader", "\n", "if", "not", "args", ".", "dali", ":", "\n", "# asymmetric augmentations", "\n", "        ", "if", "args", ".", "unique_augs", ">", "1", ":", "\n", "            ", "transform", "=", "[", "\n", "prepare_transform", "(", "args", ".", "dataset", ",", "multicrop", "=", "args", ".", "multicrop", ",", "**", "kwargs", ")", "\n", "for", "kwargs", "in", "args", ".", "transform_kwargs", "\n", "]", "\n", "", "else", ":", "\n", "            ", "transform", "=", "prepare_transform", "(", "\n", "args", ".", "dataset", ",", "multicrop", "=", "args", ".", "multicrop", ",", "**", "args", ".", "transform_kwargs", "\n", ")", "\n", "\n", "", "if", "args", ".", "debug_augmentations", ":", "\n", "            ", "print", "(", "\"Transforms:\"", ")", "\n", "pprint", "(", "transform", ")", "\n", "\n", "", "if", "args", ".", "multicrop", ":", "\n", "            ", "assert", "not", "args", ".", "unique_augs", "==", "1", "\n", "\n", "if", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "                ", "size_crops", "=", "[", "32", ",", "24", "]", "\n", "", "elif", "args", ".", "dataset", "==", "\"stl10\"", ":", "\n", "                ", "size_crops", "=", "[", "96", ",", "58", "]", "\n", "# imagenet or custom dataset", "\n", "", "else", ":", "\n", "                ", "size_crops", "=", "[", "224", ",", "96", "]", "\n", "\n", "", "transform", "=", "prepare_multicrop_transform", "(", "\n", "transform", ",", "size_crops", "=", "size_crops", ",", "num_crops", "=", "[", "args", ".", "num_crops", ",", "args", ".", "num_small_crops", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "num_crops", "!=", "2", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "                ", "assert", "args", ".", "method", "==", "\"wmse\"", "or", "args", ".", "method", "==", "\"simsiam_eoa\"", "or", "args", ".", "method", "==", "\"simclr_neg_size\"", "\n", "\n", "", "transform", "=", "prepare_n_crop_transform", "(", "transform", ",", "num_crops", "=", "args", ".", "num_crops", ")", "\n", "\n", "", "train_dataset", "=", "prepare_datasets", "(", "\n", "args", ".", "dataset", ",", "\n", "transform", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "no_labels", "=", "args", ".", "no_labels", ",", "\n", ")", "\n", "train_loader", "=", "prepare_dataloader", "(", "\n", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", "\n", ")", "\n", "\n", "# normal dataloader for when it is available", "\n", "", "if", "args", ".", "dataset", "==", "\"custom\"", "and", "(", "args", ".", "no_labels", "or", "args", ".", "val_dir", "is", "None", ")", ":", "\n", "        ", "val_loader", "=", "None", "\n", "", "elif", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", "and", "args", ".", "val_dir", "is", "None", ":", "\n", "        ", "val_loader", "=", "None", "\n", "", "else", ":", "\n", "        ", "_", ",", "val_loader", "=", "prepare_data_classification", "(", "\n", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", "\n", "\n", "", "callbacks", "=", "[", "]", "\n", "\n", "# wandb logging", "\n", "if", "args", ".", "wandb", ":", "\n", "        ", "wandb_logger", "=", "WandbLogger", "(", "\n", "name", "=", "args", ".", "name", ",", "\n", "project", "=", "args", ".", "project", ",", "\n", "entity", "=", "args", ".", "entity", ",", "\n", "offline", "=", "args", ".", "offline", ",", "\n", ")", "\n", "wandb_logger", ".", "watch", "(", "model", ",", "log", "=", "\"gradients\"", ",", "log_freq", "=", "100", ")", "\n", "wandb_logger", ".", "log_hyperparams", "(", "args", ")", "\n", "\n", "# lr logging", "\n", "lr_monitor", "=", "LearningRateMonitor", "(", "logging_interval", "=", "\"epoch\"", ")", "\n", "callbacks", ".", "append", "(", "lr_monitor", ")", "\n", "\n", "# save checkpoint on last epoch only", "\n", "ckpt", "=", "Checkpointer", "(", "\n", "args", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "args", ".", "method", ")", ",", "\n", "frequency", "=", "args", ".", "checkpoint_frequency", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "ckpt", ")", "\n", "\n", "if", "args", ".", "auto_umap", ":", "\n", "            ", "assert", "(", "\n", "_umap_available", "\n", ")", ",", "\"UMAP is not currently avaiable, please install it first with [umap].\"", "\n", "auto_umap", "=", "AutoUMAP", "(", "\n", "args", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "auto_umap_dir", ",", "args", ".", "method", ")", ",", "\n", "frequency", "=", "args", ".", "auto_umap_frequency", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "auto_umap", ")", "\n", "\n", "", "", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "logger", "=", "wandb_logger", "if", "args", ".", "wandb", "else", "None", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "plugins", "=", "DDPPlugin", "(", "find_unused_parameters", "=", "True", ")", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "terminate_on_nan", "=", "True", ",", "\n", "accelerator", "=", "\"ddp\"", ",", "\n", "log_every_n_steps", "=", "args", ".", "log_frenquence", ",", "\n", ")", "\n", "\n", "# save code for each run", "\n", "if", "args", ".", "wandb", ":", "\n", "        ", "experimentdir", "=", "f\"code/{args.method}_{args.project}_{args.name}_{trainer.logger.version}\"", "\n", "args", ".", "codepath", "=", "experimentdir", "\n", "", "else", ":", "\n", "        ", "experimentdir", "=", "f\"code/{args.method}_{args.project}_{args.name}_test\"", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "\"code\"", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "\"code\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "experimentdir", ")", ":", "\n", "        ", "print", "(", "experimentdir", "+", "' : exists. overwrite it.'", ")", "\n", "shutil", ".", "rmtree", "(", "experimentdir", ")", "\n", "os", ".", "mkdir", "(", "experimentdir", ")", "\n", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "experimentdir", ")", "\n", "\n", "", "shutil", ".", "copytree", "(", "f\"solo\"", ",", "os", ".", "path", ".", "join", "(", "experimentdir", ",", "'solo'", ")", ")", "\n", "shutil", ".", "copytree", "(", "f\"bash_files\"", ",", "os", ".", "path", ".", "join", "(", "experimentdir", ",", "'bash_files'", ")", ")", "\n", "shutil", ".", "copyfile", "(", "f\"main_pretrain.py\"", ",", "os", ".", "path", ".", "join", "(", "experimentdir", ",", "'main_pretrain.py'", ")", ")", "\n", "\n", "if", "args", ".", "dali", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "val_dataloaders", "=", "val_loader", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "train_loader", ",", "val_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.__init__": [[29, 64], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "Optimizer", ",", "\n", "eta", ":", "float", "=", "1e-3", ",", "\n", "clip", ":", "bool", "=", "False", ",", "\n", "eps", ":", "float", "=", "1e-8", ",", "\n", "exclude_bias_n_norm", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Wrapper that adds LARS scheduling to any optimizer.\n        This helps stability with huge batch sizes.\n\n        Args:\n            optimizer (Optimizer): torch optimizer.\n            eta (float, optional): trust coefficient. Defaults to 1e-3.\n            clip (bool, optional): clip gradient values. Defaults to False.\n            eps (float, optional): adaptive_lr stability coefficient. Defaults to 1e-8.\n            exclude_bias_n_norm (bool, optional): exclude bias and normalization layers from lars.\n                Defaults to False.\n        \"\"\"", "\n", "\n", "self", ".", "optim", "=", "optimizer", "\n", "self", ".", "eta", "=", "eta", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "clip", "=", "clip", "\n", "self", ".", "exclude_bias_n_norm", "=", "exclude_bias_n_norm", "\n", "\n", "# transfer optim methods", "\n", "self", ".", "state_dict", "=", "self", ".", "optim", ".", "state_dict", "\n", "self", ".", "load_state_dict", "=", "self", ".", "optim", ".", "load_state_dict", "\n", "self", ".", "zero_grad", "=", "self", ".", "optim", ".", "zero_grad", "\n", "self", ".", "add_param_group", "=", "self", ".", "optim", ".", "add_param_group", "\n", "\n", "self", ".", "__setstate__", "=", "self", ".", "optim", ".", "__setstate__", "# type: ignore", "\n", "self", ".", "__getstate__", "=", "self", ".", "optim", ".", "__getstate__", "# type: ignore", "\n", "self", ".", "__repr__", "=", "self", ".", "optim", ".", "__repr__", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.defaults": [[69, 72], ["None"], "methods", ["None"], ["", "@", "defaults", ".", "setter", "\n", "def", "defaults", "(", "self", ",", "defaults", ")", ":", "\n", "        ", "self", ".", "optim", ".", "defaults", "=", "defaults", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.__class__": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "# type: ignore", "\n", "def", "__class__", "(", "self", ")", ":", "\n", "        ", "return", "Optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.state": [[81, 84], ["None"], "methods", ["None"], ["", "@", "state", ".", "setter", "\n", "def", "state", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "optim", ".", "state", "=", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.param_groups": [[89, 92], ["None"], "methods", ["None"], ["", "@", "param_groups", ".", "setter", "\n", "def", "param_groups", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "optim", ".", "param_groups", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.step": [[93, 115], ["torch.no_grad", "lars.LARSWrapper.optim.step", "enumerate", "group.get", "weight_decays.append", "lars.LARSWrapper.update_p"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.update_p"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "weight_decays", "=", "[", "]", "\n", "\n", "for", "group", "in", "self", ".", "optim", ".", "param_groups", ":", "\n", "            ", "weight_decay", "=", "group", ".", "get", "(", "\"weight_decay\"", ",", "0", ")", "\n", "weight_decays", ".", "append", "(", "weight_decay", ")", "\n", "\n", "# reset weight decay", "\n", "group", "[", "\"weight_decay\"", "]", "=", "0", "\n", "\n", "# update the parameters", "\n", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "not", "None", "and", "(", "p", ".", "ndim", "!=", "1", "or", "not", "self", ".", "exclude_bias_n_norm", ")", ":", "\n", "                    ", "self", ".", "update_p", "(", "p", ",", "group", ",", "weight_decay", ")", "\n", "\n", "# update the optimizer", "\n", "", "", "", "self", ".", "optim", ".", "step", "(", "closure", "=", "closure", ")", "\n", "\n", "# return weight decay control to optimizer", "\n", "for", "group_idx", ",", "group", "in", "enumerate", "(", "self", ".", "optim", ".", "param_groups", ")", ":", "\n", "            ", "group", "[", "\"weight_decay\"", "]", "=", "weight_decays", "[", "group_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.lars.LARSWrapper.update_p": [[116, 132], ["torch.norm", "torch.norm", "min"], "methods", ["None"], ["", "", "def", "update_p", "(", "self", ",", "p", ",", "group", ",", "weight_decay", ")", ":", "\n", "# calculate new norms", "\n", "        ", "p_norm", "=", "torch", ".", "norm", "(", "p", ".", "data", ")", "\n", "g_norm", "=", "torch", ".", "norm", "(", "p", ".", "grad", ".", "data", ")", "\n", "\n", "if", "p_norm", "!=", "0", "and", "g_norm", "!=", "0", ":", "\n", "# calculate new lr", "\n", "            ", "new_lr", "=", "(", "self", ".", "eta", "*", "p_norm", ")", "/", "(", "g_norm", "+", "p_norm", "*", "weight_decay", "+", "self", ".", "eps", ")", "\n", "\n", "# clip lr", "\n", "if", "self", ".", "clip", ":", "\n", "                ", "new_lr", "=", "min", "(", "new_lr", "/", "group", "[", "\"lr\"", "]", ",", "1", ")", "\n", "\n", "# update params with clipped lr", "\n", "", "p", ".", "grad", ".", "data", "+=", "weight_decay", "*", "p", ".", "data", "\n", "p", ".", "grad", ".", "data", "*=", "new_lr", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.accuracy_at_k": [[25, 53], ["torch.no_grad", "max", "targets.size", "outputs.topk", "pred.t.t", "pred.t.eq", "targets.view().expand_as", "correct[].contiguous().view().float().sum", "res.append", "correct[].contiguous().view().float().sum.mul_", "targets.view", "correct[].contiguous().view().float", "correct[].contiguous().view", "correct[].contiguous"], "function", ["None"], ["def", "accuracy_at_k", "(", "\n", "outputs", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ",", "top_k", ":", "Sequence", "[", "int", "]", "=", "(", "1", ",", "5", ")", "\n", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k.\n\n    Args:\n        outputs (torch.Tensor): output of a classifier (logits or probabilities).\n        targets (torch.Tensor): ground truth labels.\n        top_k (Sequence[int], optional): sequence of top k values to compute the accuracy over.\n            Defaults to (1, 5).\n\n    Returns:\n        Sequence[int]:  accuracies at the desired k.\n    \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "top_k", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "outputs", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "top_k", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean": [[55, 74], ["value.squeeze"], "function", ["None"], ["", "", "def", "weighted_mean", "(", "outputs", ":", "List", "[", "Dict", "]", ",", "key", ":", "str", ",", "batch_size_key", ":", "str", ")", "->", "float", ":", "\n", "    ", "\"\"\"Computes the mean of the values of a key weighted by the batch size.\n\n    Args:\n        outputs (List[Dict]): list of dicts containing the outputs of a validation step.\n        key (str): key of the metric of interest.\n        batch_size_key (str): key of batch size values.\n\n    Returns:\n        float: weighted mean of the values of a key\n    \"\"\"", "\n", "\n", "value", "=", "0", "\n", "n", "=", "0", "\n", "for", "out", "in", "outputs", ":", "\n", "        ", "value", "+=", "out", "[", "batch_size_key", "]", "*", "out", "[", "key", "]", "\n", "n", "+=", "out", "[", "batch_size_key", "]", "\n", "", "value", "=", "value", "/", "n", "\n", "return", "value", ".", "squeeze", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.sinkhorn_knopp.SinkhornKnopp.__init__": [[27, 44], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_iters", ":", "int", "=", "3", ",", "epsilon", ":", "float", "=", "0.05", ",", "world_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "\"\"\"Approximates optimal transport using the Sinkhorn-Knopp algorithm.\n\n        A simple iterative method to approach the double stochastic matrix is to alternately rescale\n        rows and columns of the matrix to sum to 1.\n\n        Args:\n            num_iters (int, optional):  number of times to perform row and column normalization.\n                Defaults to 3.\n            epsilon (float, optional): weight for the entropy regularization term. Defaults to 0.05.\n            world_size (int, optional): number of nodes for distributed training. Defaults to 1.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_iters", "=", "num_iters", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "world_size", "=", "world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.sinkhorn_knopp.SinkhornKnopp.forward": [[45, 85], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.exp().t", "torch.exp().t", "torch.exp().t", "torch.exp().t", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "range", "torch.exp().t.t", "torch.exp().t.t", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "self", ",", "Q", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Produces assignments using Sinkhorn-Knopp algorithm.\n\n        Applies the entropy regularization, normalizes the Q matrix and then normalizes rows and\n        columns in an alternating fashion for num_iter times. Before returning it normalizes again\n        the columns in order for the output to be an assignment of samples to prototypes.\n\n        Args:\n            Q (torch.Tensor): cosine similarities between the features of the\n                samples and the prototypes.\n\n        Returns:\n            torch.Tensor: assignment of samples to prototypes according to optimal transport.\n        \"\"\"", "\n", "\n", "Q", "=", "torch", ".", "exp", "(", "Q", "/", "self", ".", "epsilon", ")", ".", "t", "(", ")", "\n", "B", "=", "Q", ".", "shape", "[", "1", "]", "*", "self", ".", "world_size", "\n", "K", "=", "Q", ".", "shape", "[", "0", "]", "# num prototypes", "\n", "\n", "# make the matrix sums to 1", "\n", "sum_Q", "=", "torch", ".", "sum", "(", "Q", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "sum_Q", ")", "\n", "", "Q", "/=", "sum_Q", "\n", "\n", "for", "it", "in", "range", "(", "self", ".", "num_iters", ")", ":", "\n", "# normalize each row: total weight per prototype must be 1/K", "\n", "            ", "sum_of_rows", "=", "torch", ".", "sum", "(", "Q", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "dist", ".", "all_reduce", "(", "sum_of_rows", ")", "\n", "", "Q", "/=", "sum_of_rows", "\n", "Q", "/=", "K", "\n", "\n", "# normalize each column: total weight per sample must be 1/B", "\n", "Q", "/=", "torch", ".", "sum", "(", "Q", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "Q", "/=", "B", "\n", "\n", "", "Q", "*=", "B", "# the colomns must sum to 1 so that Q is an assignment", "\n", "return", "Q", ".", "t", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.swin_tiny": [[28, 40], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["@", "register_model", "\n", "def", "swin_tiny", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\"swin_tiny_patch4_window7_224\"", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.swin_small": [[42, 55], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_small", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_small_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.swin_base": [[58, 71], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_base", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "128", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_base_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.swin_large": [[74, 87], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_large", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "192", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_large_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.vit_tiny": [[90, 98], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_tiny", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ViT-Tiny (Vit-Ti/16)\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_tiny_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.vit_small": [[100, 107], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_small", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_small_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.vit_base": [[109, 116], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_base", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_base_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.backbones.vit_large": [[118, 125], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_large", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_large_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__init__": [[53, 57], ["pathlib.Path", "os.listdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "Path", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "images", "=", "os", ".", "listdir", "(", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__getitem__": [[58, 64], ["PIL.Image.open().convert", "pretrain_dataloader.CustomDatasetWithoutLabels.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "root", "/", "self", ".", "images", "[", "index", "]", "\n", "x", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "x", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.GaussianBlur.__init__": [[70, 79], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sigma", ":", "Sequence", "[", "float", "]", "=", "[", "0.1", ",", "2.0", "]", ")", ":", "\n", "        ", "\"\"\"Gaussian blur as a callable object.\n\n        Args:\n            sigma (Sequence[float]): range to sample the radius of the gaussian blur filter.\n                Defaults to [0.1, 2.0].\n        \"\"\"", "\n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.GaussianBlur.__call__": [[80, 93], ["random.uniform", "x.filter.filter.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Applies gaussian blur to an input image.\n\n        Args:\n            x (torch.Tensor): an image in the tensor format.\n\n        Returns:\n            torch.Tensor: returns a blurred image.\n        \"\"\"", "\n", "\n", "sigma", "=", "random", ".", "uniform", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "sigma", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.Solarization.__call__": [[98, 109], ["PIL.ImageOps.solarize"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ":", "Image", ")", "->", "Image", ":", "\n", "        ", "\"\"\"Applies solarization to an input image.\n\n        Args:\n            img (Image): an image in the PIL.Image format.\n\n        Returns:\n            Image: a solarized image.\n        \"\"\"", "\n", "\n", "return", "ImageOps", ".", "solarize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.NCropAugmentation.__init__": [[112, 131], ["isinstance", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transform", ":", "Union", "[", "Callable", ",", "Sequence", "]", ",", "num_crops", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates a pipeline that apply a transformation pipeline multiple times.\n\n        Args:\n            transform (Union[Callable, Sequence]): transformation pipeline or list of\n                transformation pipelines.\n            num_crops: if transformation pipeline is not a list, applies the same\n                pipeline num_crops times, if it is a list, this is ignored and each\n                element of the list is applied once.\n        \"\"\"", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "if", "isinstance", "(", "transform", ",", "Iterable", ")", ":", "\n", "            ", "self", ".", "one_transform_per_crop", "=", "True", "\n", "assert", "num_crops", "==", "len", "(", "transform", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "one_transform_per_crop", "=", "False", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.NCropAugmentation.__call__": [[132, 146], ["transform", "pretrain_dataloader.NCropAugmentation.transform", "range"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Applies transforms n times to generate n crops.\n\n        Args:\n            x (Image): an image in the PIL.Image format.\n\n        Returns:\n            List[torch.Tensor]: an image in the tensor format.\n        \"\"\"", "\n", "\n", "if", "self", ".", "one_transform_per_crop", ":", "\n", "            ", "return", "[", "transform", "(", "x", ")", "for", "transform", "in", "self", ".", "transform", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "transform", "(", "x", ")", "for", "_", "in", "range", "(", "self", ".", "num_crops", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.BaseTransform.__call__": [[151, 153], ["pretrain_dataloader.BaseTransform.transform"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "transform", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.BaseTransform.__repr__": [[154, 156], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "self", ".", "transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CifarTransform.__init__": [[159, 200], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.0", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies cifar transformations.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "(", "32", ",", "32", ")", ",", "\n", "scale", "=", "(", "min_scale", ",", "1.0", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "p", "=", "0.8", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.STLTransform.__init__": [[205, 245], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.0", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies STL10 transformations.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "(", "96", ",", "96", ")", ",", "\n", "scale", "=", "(", "min_scale", ",", "1.0", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "p", "=", "0.8", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.ImagenetTransform.__init__": [[250, 293], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "size", ":", "int", "=", "224", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies Imagenet transformations.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            size (int, optional): size of the crop. Defaults to 224.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "size", ",", "\n", "scale", "=", "(", "min_scale", ",", "1.0", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CustomTransform.__init__": [[298, 348], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "size", ":", "int", "=", "224", ",", "\n", "mean", ":", "Sequence", "[", "float", "]", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", ":", "Sequence", "[", "float", "]", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies Custom transformations.\n        If you want to do exoteric augmentations, you can just re-write this class.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            size (int, optional): size of the crop. Defaults to 224.\n            mean (Sequence[float], optional): mean values for normalization.\n                Defaults to (0.485, 0.456, 0.406).\n            std (Sequence[float], optional): std values for normalization.\n                Defaults to (0.228, 0.224, 0.225).\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "size", ",", "\n", "scale", "=", "(", "min_scale", ",", "1.0", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropAugmentation.__init__": [[353, 387], ["range", "len", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.Compose", "pretrain_dataloader.MulticropAugmentation.transforms.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "transform", ":", "Callable", ",", "\n", "size_crops", ":", "Sequence", "[", "int", "]", ",", "\n", "num_crops", ":", "Sequence", "[", "int", "]", ",", "\n", "min_scales", ":", "Sequence", "[", "float", "]", ",", "\n", "max_scale_crops", ":", "Sequence", "[", "float", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies multi crop augmentation.\n\n        Args:\n            transform (Callable): transformation callable without cropping.\n            size_crops (Sequence[int]): a sequence of sizes of the crops.\n            num_crops (Sequence[int]): a sequence number of crops per crop size.\n            min_scales (Sequence[float]): sequence of minimum crop scales per crop\n                size.\n            max_scale_crops (Sequence[float]): sequence of maximum crop scales per crop\n                size.\n        \"\"\"", "\n", "\n", "self", ".", "size_crops", "=", "size_crops", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "self", ".", "min_scales", "=", "min_scales", "\n", "self", ".", "max_scale_crops", "=", "max_scale_crops", "\n", "\n", "self", ".", "transforms", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "size_crops", ")", ")", ":", "\n", "            ", "rrc", "=", "transforms", ".", "RandomResizedCrop", "(", "\n", "size_crops", "[", "i", "]", ",", "\n", "scale", "=", "(", "min_scales", "[", "i", "]", ",", "max_scale_crops", "[", "i", "]", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", "\n", "full_transform", "=", "transforms", ".", "Compose", "(", "[", "rrc", ",", "transform", "]", ")", "\n", "self", ".", "transforms", ".", "append", "(", "full_transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropAugmentation.__call__": [[388, 402], ["zip", "imgs.extend", "transform", "range"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Applies multi crop augmentations.\n\n        Args:\n            x (Image): an image in the PIL.Image format.\n\n        Returns:\n            List[torch.Tensor]: a list of crops in the tensor format.\n        \"\"\"", "\n", "\n", "imgs", "=", "[", "]", "\n", "for", "n", ",", "transform", "in", "zip", "(", "self", ".", "num_crops", ",", "self", ".", "transforms", ")", ":", "\n", "            ", "imgs", ".", "extend", "(", "[", "transform", "(", "x", ")", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropCifarTransform.__init__": [[405, 417], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Class that applies multicrop transform for CIFAR\"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropSTLTransform.__init__": [[422, 433], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Class that applies multicrop transform for STL10\"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropImagenetTransform.__init__": [[438, 471], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies multicrop transform for Imagenet.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.5.\n            solarization_prob (float, optional): minimum scale of the crops. Defaults to 0.0.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.MulticropCustomTransform.__init__": [[476, 516], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "mean", ":", "Sequence", "[", "float", "]", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", ":", "Sequence", "[", "float", "]", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies multicrop transform for Custom Datasets.\n        If you want to do exoteric augmentations, you can just re-write this class.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.5.\n            solarization_prob (float, optional): minimum scale of the crops. Defaults to 0.0.\n            mean (Sequence[float], optional): mean values for normalization.\n                Defaults to (0.485, 0.456, 0.406).\n            std (Sequence[float], optional): std values for normalization.\n                Defaults to (0.228, 0.224, 0.225).\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.dataset_with_index": [[34, 50], ["super().__getitem__", "torchvision.datasets.STL10", "torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__getitem__"], ["def", "dataset_with_index", "(", "DatasetClass", ":", "Type", "[", "Dataset", "]", ")", "->", "Type", "[", "Dataset", "]", ":", "\n", "    ", "\"\"\"Factory for datasets that also returns the data index.\n\n    Args:\n        DatasetClass (Type[Dataset]): Dataset class to be wrapped.\n\n    Returns:\n        Type[Dataset]: dataset with index.\n    \"\"\"", "\n", "\n", "class", "DatasetWithIndex", "(", "DatasetClass", ")", ":", "\n", "        ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "            ", "data", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "return", "(", "index", ",", "*", "data", ")", "\n", "\n", "", "", "return", "DatasetWithIndex", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_transform": [[520, 541], ["pretrain_dataloader.CifarTransform", "pretrain_dataloader.MulticropCifarTransform", "pretrain_dataloader.STLTransform", "pretrain_dataloader.MulticropSTLTransform", "pretrain_dataloader.ImagenetTransform", "pretrain_dataloader.MulticropImagenetTransform", "pretrain_dataloader.CustomTransform", "pretrain_dataloader.MulticropCustomTransform"], "function", ["None"], ["", "", "def", "prepare_transform", "(", "dataset", ":", "str", ",", "multicrop", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "Any", ":", "\n", "    ", "\"\"\"Prepares transforms for a specific dataset. Optionally uses multi crop.\n\n    Args:\n        dataset (str): name of the dataset.\n        multicrop (bool, optional): whether or not to use multi crop. Defaults to False.\n\n    Returns:\n        Any: a transformation for a specific dataset.\n    \"\"\"", "\n", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "return", "CifarTransform", "(", "**", "kwargs", ")", "if", "not", "multicrop", "else", "MulticropCifarTransform", "(", ")", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "return", "STLTransform", "(", "**", "kwargs", ")", "if", "not", "multicrop", "else", "MulticropSTLTransform", "(", ")", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", "]", ":", "\n", "        ", "return", "(", "\n", "ImagenetTransform", "(", "**", "kwargs", ")", "if", "not", "multicrop", "else", "MulticropImagenetTransform", "(", "**", "kwargs", ")", "\n", ")", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "        ", "return", "CustomTransform", "(", "**", "kwargs", ")", "if", "not", "multicrop", "else", "MulticropCustomTransform", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_n_crop_transform": [[543, 557], ["pretrain_dataloader.NCropAugmentation"], "function", ["None"], ["", "", "def", "prepare_n_crop_transform", "(", "\n", "transform", ":", "Callable", ",", "num_crops", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", "->", "NCropAugmentation", ":", "\n", "    ", "\"\"\"Turns a single crop transformation to an N crops transformation.\n\n    Args:\n        transform (Callable): a transformation.\n        num_crops (Optional[int], optional): number of crops. Defaults to None.\n\n    Returns:\n        NCropAugmentation: an N crop transformation.\n    \"\"\"", "\n", "\n", "return", "NCropAugmentation", "(", "transform", ",", "num_crops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_multicrop_transform": [[559, 595], ["pretrain_dataloader.MulticropAugmentation"], "function", ["None"], ["", "def", "prepare_multicrop_transform", "(", "\n", "transform", ":", "Callable", ",", "\n", "size_crops", ":", "Sequence", "[", "int", "]", ",", "\n", "num_crops", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "min_scales", ":", "Optional", "[", "Sequence", "[", "float", "]", "]", "=", "None", ",", "\n", "max_scale_crops", ":", "Optional", "[", "Sequence", "[", "float", "]", "]", "=", "None", ",", "\n", ")", "->", "MulticropAugmentation", ":", "\n", "    ", "\"\"\"Prepares multicrop transformations by creating custom crops given the parameters.\n\n    Args:\n        transform (Callable): transformation callable without cropping.\n        size_crops (Sequence[int]): a sequence of sizes of the crops.\n        num_crops (Optional[Sequence[int]]): list of number of crops per crop size.\n        min_scales (Optional[Sequence[float]]): sequence of minimum crop scales per crop\n            size.\n        max_scale_crops (Optional[Sequence[float]]): sequence of maximum crop scales per crop\n            size.\n\n    Returns:\n        MulticropAugmentation: prepared augmentation pipeline that supports multicrop with\n            different sizes.\n    \"\"\"", "\n", "\n", "if", "num_crops", "is", "None", ":", "\n", "        ", "num_crops", "=", "[", "2", ",", "6", "]", "\n", "", "if", "min_scales", "is", "None", ":", "\n", "        ", "min_scales", "=", "[", "0.14", ",", "0.05", "]", "\n", "", "if", "max_scale_crops", "is", "None", ":", "\n", "        ", "max_scale_crops", "=", "[", "1.0", ",", "0.14", "]", "\n", "\n", "", "return", "MulticropAugmentation", "(", "\n", "transform", ",", "\n", "size_crops", "=", "size_crops", ",", "\n", "num_crops", "=", "num_crops", ",", "\n", "min_scales", "=", "min_scales", ",", "\n", "max_scale_crops", "=", "max_scale_crops", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_datasets": [[598, 661], ["pathlib.Path", "pathlib.Path", "pathlib.Path", "os.path.dirname", "vars", "pretrain_dataloader.dataset_with_index", "os.path.dirname", "dataset.upper", "pretrain_dataloader.dataset_with_index", "os.path.realpath", "pretrain_dataloader.dataset_with_index", "pretrain_dataloader.dataset_with_index"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.dataset_with_index"], ["", "def", "prepare_datasets", "(", "\n", "dataset", ":", "str", ",", "\n", "transform", ":", "Callable", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "no_labels", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "False", ",", "\n", ")", "->", "Dataset", ":", "\n", "    ", "\"\"\"Prepares the desired dataset.\n\n    Args:\n        dataset (str): the name of the dataset.\n        transform (Callable): a transformation.\n        data_dir (Optional[Union[str, Path]], optional): the directory to load data from.\n            Defaults to None.\n        train_dir (Optional[Union[str, Path]], optional): training data directory\n            to be appended to data_dir. Defaults to None.\n        no_labels (Optional[bool], optional): if the custom dataset has no labels.\n\n    Returns:\n        Dataset: the desired dataset with transformations.\n    \"\"\"", "\n", "\n", "if", "data_dir", "is", "None", ":", "\n", "        ", "sandbox_folder", "=", "Path", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", ")", "\n", "data_dir", "=", "sandbox_folder", "/", "\"datasets\"", "\n", "\n", "", "if", "train_dir", "is", "None", ":", "\n", "        ", "train_dir", "=", "Path", "(", "f\"{dataset}/train\"", ")", "\n", "", "else", ":", "\n", "        ", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "\n", "", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "DatasetClass", "=", "vars", "(", "torchvision", ".", "datasets", ")", "[", "dataset", ".", "upper", "(", ")", "]", "\n", "train_dataset", "=", "dataset_with_index", "(", "DatasetClass", ")", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "train_dataset", "=", "dataset_with_index", "(", "STL10", ")", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "split", "=", "\"train+unlabeled\"", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", "]", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "train_dataset", "=", "dataset_with_index", "(", "ImageFolder", ")", "(", "train_dir", ",", "transform", ")", "\n", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "\n", "if", "no_labels", ":", "\n", "            ", "dataset_class", "=", "CustomDatasetWithoutLabels", "\n", "", "else", ":", "\n", "            ", "dataset_class", "=", "ImageFolder", "\n", "\n", "", "train_dataset", "=", "dataset_with_index", "(", "dataset_class", ")", "(", "train_dir", ",", "transform", ")", "\n", "\n", "", "return", "train_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.pretrain_dataloader.prepare_dataloader": [[663, 686], ["torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "prepare_dataloader", "(", "\n", "train_dataset", ":", "Dataset", ",", "batch_size", ":", "int", "=", "64", ",", "num_workers", ":", "int", "=", "4", "\n", ")", "->", "DataLoader", ":", "\n", "    ", "\"\"\"Prepares the training dataloader for pretraining.\n\n    Args:\n        train_dataset (Dataset): the name of the dataset.\n        batch_size (int, optional): batch size. Defaults to 64.\n        num_workers (int, optional): number of workers. Defaults to 4.\n\n    Returns:\n        DataLoader: the training dataloader with the desired dataset.\n    \"\"\"", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "return", "train_loader", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.FilterInfNNan.__init__": [[90, 104], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Layer that filters out inf and nans from any tensor.\n        This is usefull when there are instability issues,\n        which cause a small number of values to go bad.\n\n        Args:\n            tensor (List): tensor to remove nans and infs from.\n\n        Returns:\n            torch.Tensor: filtered view of the tensor without nans or infs.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.FilterInfNNan.forward": [[105, 109], ["misc.FilterInfNNan.module", "misc.filter_inf_n_nan"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.filter_inf_n_nan"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "out", "=", "self", ".", "module", "(", "x", ")", "\n", "out", "=", "filter_inf_n_nan", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.FilterInfNNan.__getattr__": [[110, 117], ["super().__getattr__", "getattr", "AttributeError"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.FilterInfNNan.__getattr__"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "if", "name", "==", "\"module\"", ":", "\n", "                ", "raise", "AttributeError", "(", ")", "\n", "", "return", "getattr", "(", "self", ".", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.GatherLayer.forward": [[171, 180], ["ctx.save_for_backward", "tuple", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "input", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "output", "=", "[", "torch", ".", "zeros_like", "(", "input", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "output", ",", "input", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "[", "input", "]", "\n", "", "return", "tuple", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.GatherLayer.backward": [[181, 190], ["torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.get_rank", "torch.get_rank", "torch.get_rank"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grads", ")", ":", "\n", "        ", "(", "input", ",", ")", "=", "ctx", ".", "saved_tensors", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "grad_out", "=", "torch", ".", "zeros_like", "(", "input", ")", "\n", "grad_out", "[", ":", "]", "=", "grads", "[", "dist", ".", "get_rank", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "grad_out", "=", "grads", "[", "0", "]", "\n", "", "return", "grad_out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._1d_filter": [[29, 31], ["tensor.isfinite"], "function", ["None"], ["def", "_1d_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "tensor", ".", "isfinite", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._2d_filter": [[33, 35], ["tensor.isfinite().all", "tensor.isfinite"], "function", ["None"], ["", "def", "_2d_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "tensor", ".", "isfinite", "(", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._single_input_filter": [[37, 49], ["filter_func", "len", "tensor.size", "len", "RuntimeError", "tensor.size"], "function", ["None"], ["", "def", "_single_input_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "        ", "filter_func", "=", "_1d_filter", "\n", "", "elif", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "filter_func", "=", "_2d_filter", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Only 1d and 2d tensors are supported.\"", ")", "\n", "\n", "", "selected", "=", "filter_func", "(", "tensor", ")", "\n", "tensor", "=", "tensor", "[", "selected", "]", "\n", "\n", "return", "tensor", ",", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._multi_input_filter": [[51, 65], ["filter_func", "len", "torch.logical_and", "torch.logical_and", "torch.logical_and", "tensors[].size", "len", "RuntimeError", "filter_func", "tensors[].size"], "function", ["None"], ["", "def", "_multi_input_filter", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "len", "(", "tensors", "[", "0", "]", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "        ", "filter_func", "=", "_1d_filter", "\n", "", "elif", "len", "(", "tensors", "[", "0", "]", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "filter_func", "=", "_2d_filter", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Only 1d and 2d tensors are supported.\"", ")", "\n", "\n", "", "selected", "=", "filter_func", "(", "tensors", "[", "0", "]", ")", "\n", "for", "tensor", "in", "tensors", "[", "1", ":", "]", ":", "\n", "        ", "selected", "=", "torch", ".", "logical_and", "(", "selected", ",", "filter_func", "(", "tensor", ")", ")", "\n", "", "tensors", "=", "[", "tensor", "[", "selected", "]", "for", "tensor", "in", "tensors", "]", "\n", "\n", "return", "tensors", ",", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.filter_inf_n_nan": [[67, 87], ["isinstance", "misc._single_input_filter", "misc._multi_input_filter"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._single_input_filter", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._multi_input_filter"], ["", "def", "filter_inf_n_nan", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "return_indexes", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Filters out inf and nans from any tensor.\n    This is usefull when there are instability issues,\n    which cause a small number of values to go bad.\n\n    Args:\n        tensor (List): tensor to remove nans and infs from.\n\n    Returns:\n        torch.Tensor: filtered view of the tensor without nans or infs.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensors", ",", "selected", "=", "_single_input_filter", "(", "tensors", ")", "\n", "", "else", ":", "\n", "        ", "tensors", ",", "selected", "=", "_multi_input_filter", "(", "tensors", ")", "\n", "\n", "", "if", "return_indexes", ":", "\n", "        ", "return", "tensors", ",", "selected", "\n", "", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._no_grad_trunc_normal_": [[119, 158], ["warnings.warn", "torch.no_grad", "torch.no_grad", "torch.no_grad", "misc._no_grad_trunc_normal_.norm_cdf"], "function", ["None"], ["", "", "", "def", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Copy & paste from PyTorch official master until it's in a few official releases - RW\n    Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    \"\"\"", "\n", "\n", "def", "norm_cdf", "(", "x", ")", ":", "\n", "        ", "\"\"\"Computes standard normal cumulative distribution function\"\"\"", "\n", "\n", "return", "(", "1.0", "+", "math", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "/", "2.0", "\n", "\n", "", "if", "(", "mean", "<", "a", "-", "2", "*", "std", ")", "or", "(", "mean", ">", "b", "+", "2", "*", "std", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"", "\n", "\"The distribution of values may be incorrect.\"", ",", "\n", "stacklevel", "=", "2", ",", "\n", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Values are generated by using a truncated uniform distribution and", "\n", "# then using the inverse CDF for the normal distribution.", "\n", "# Get upper and lower cdf values", "\n", "        ", "l", "=", "norm_cdf", "(", "(", "a", "-", "mean", ")", "/", "std", ")", "\n", "u", "=", "norm_cdf", "(", "(", "b", "-", "mean", ")", "/", "std", ")", "\n", "\n", "# Uniformly fill tensor with values from [l, u], then translate to", "\n", "# [2l-1, 2u-1].", "\n", "tensor", ".", "uniform_", "(", "2", "*", "l", "-", "1", ",", "2", "*", "u", "-", "1", ")", "\n", "\n", "# Use inverse cdf transform for normal distribution to get truncated", "\n", "# standard normal", "\n", "tensor", ".", "erfinv_", "(", ")", "\n", "\n", "# Transform to proper mean, std", "\n", "tensor", ".", "mul_", "(", "std", "*", "math", ".", "sqrt", "(", "2.0", ")", ")", "\n", "tensor", ".", "add_", "(", "mean", ")", "\n", "\n", "# Clamp to ensure it's in the proper range", "\n", "tensor", ".", "clamp_", "(", "min", "=", "a", ",", "max", "=", "b", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.trunc_normal_": [[160, 166], ["misc._no_grad_trunc_normal_"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc._no_grad_trunc_normal_"], ["", "", "def", "trunc_normal_", "(", "tensor", ",", "mean", "=", "0.0", ",", "std", "=", "1.0", ",", "a", "=", "-", "2.0", ",", "b", "=", "2.0", ")", ":", "\n", "    ", "\"\"\"Copy & paste from PyTorch official master until it's in a few official releases - RW\n    Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    \"\"\"", "\n", "\n", "return", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather": [[192, 195], ["torch.cat", "torch.cat", "torch.cat", "GatherLayer.apply"], "function", ["None"], ["", "", "def", "gather", "(", "X", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"Gathers tensors from all processes, supporting backward propagation.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "GatherLayer", ".", "apply", "(", "X", ")", ",", "dim", "=", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.Mux.__init__": [[31, 40], ["nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", ")", ":", "\n", "        ", "\"\"\"Implements mutex operation for dali in order to support probabilitic augmentations.\n\n        Args:\n            prob (float): probability value\n        \"\"\"", "\n", "\n", "self", ".", "to_bool", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "DALIDataType", ".", "BOOL", ")", "\n", "self", ".", "rng", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.Mux.__call__": [[41, 45], ["dali_dataloader.Mux.to_bool", "dali_dataloader.Mux.rng"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "true_case", ",", "false_case", ")", ":", "\n", "        ", "condition", "=", "self", ".", "to_bool", "(", "self", ".", "rng", "(", ")", ")", "\n", "neg_condition", "=", "condition", "^", "True", "\n", "return", "condition", "*", "true_case", "+", "neg_condition", "*", "false_case", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomGrayScaleConversion.__init__": [[48, 60], ["dali_dataloader.Mux", "nvidia.ColorSpaceConversion", "nvidia.ColorSpaceConversion", "nvidia.ColorSpaceConversion"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", "=", "0.2", ",", "device", ":", "str", "=", "\"gpu\"", ")", ":", "\n", "        ", "\"\"\"Converts image to greyscale with probability.\n\n        Args:\n            prob (float, optional): probability of conversion. Defaults to 0.2.\n            device (str, optional): device on which the operation will be performed.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "self", ".", "grayscale", "=", "ops", ".", "ColorSpaceConversion", "(", "\n", "device", "=", "device", ",", "image_type", "=", "types", ".", "RGB", ",", "output_type", "=", "types", ".", "GRAY", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomGrayScaleConversion.__call__": [[62, 66], ["dali_dataloader.RandomGrayScaleConversion.grayscale", "nvidia.cat", "nvidia.cat", "nvidia.cat", "dali_dataloader.RandomGrayScaleConversion.mux"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "grayscale", "(", "images", ")", "\n", "out", "=", "fn", ".", "cat", "(", "out", ",", "out", ",", "out", ",", "axis", "=", "2", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomColorJitter.__init__": [[69, 121], ["dali_dataloader.Mux", "nvidia.ColorTwist", "nvidia.ColorTwist", "nvidia.ColorTwist", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "max", "max", "max"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "prob", ":", "float", "=", "0.8", ",", "\n", "device", ":", "str", "=", "\"gpu\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies random color jittering with probability.\n\n        Args:\n            brightness (float): brightness value for samplying uniformly\n                in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): contrast value for samplying uniformly\n                in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): saturation value for samplying uniformly\n                in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): hue value for samplying uniformly in [-hue, hue].\n            prob (float, optional): probability of applying jitter. Defaults to 0.8.\n            device (str, optional): device on which the operation will be performed.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "assert", "0", "<=", "hue", "<=", "0.5", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "\n", "self", ".", "color", "=", "ops", ".", "ColorTwist", "(", "device", "=", "device", ")", "\n", "\n", "# look at torchvision docs to see how colorjitter samples stuff", "\n", "# for bright, cont and sat, it samples from [1-v, 1+v]", "\n", "# for hue, it samples from [-hue, hue]", "\n", "\n", "self", ".", "brightness", "=", "1", "\n", "self", ".", "contrast", "=", "1", "\n", "self", ".", "saturation", "=", "1", "\n", "self", ".", "hue", "=", "0", "\n", "\n", "if", "brightness", ":", "\n", "            ", "self", ".", "brightness", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", "]", ")", "\n", "\n", "", "if", "contrast", ":", "\n", "            ", "self", ".", "contrast", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", "]", ")", "\n", "\n", "", "if", "saturation", ":", "\n", "            ", "self", ".", "saturation", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", "]", ")", "\n", "\n", "", "if", "hue", ":", "\n", "# dali uses hue in degrees for some reason...", "\n", "            ", "hue", "=", "360", "*", "hue", "\n", "self", ".", "hue", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "-", "hue", ",", "hue", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomColorJitter.__call__": [[122, 131], ["dali_dataloader.RandomColorJitter.color", "dali_dataloader.RandomColorJitter.mux", "callable", "dali_dataloader.RandomColorJitter.brightness", "callable", "dali_dataloader.RandomColorJitter.contrast", "callable", "dali_dataloader.RandomColorJitter.saturation", "callable", "dali_dataloader.RandomColorJitter.hue"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "color", "(", "\n", "images", ",", "\n", "brightness", "=", "self", ".", "brightness", "(", ")", "if", "callable", "(", "self", ".", "brightness", ")", "else", "self", ".", "brightness", ",", "\n", "contrast", "=", "self", ".", "contrast", "(", ")", "if", "callable", "(", "self", ".", "contrast", ")", "else", "self", ".", "contrast", ",", "\n", "saturation", "=", "self", ".", "saturation", "(", ")", "if", "callable", "(", "self", ".", "saturation", ")", "else", "self", ".", "saturation", ",", "\n", "hue", "=", "self", ".", "hue", "(", ")", "if", "callable", "(", "self", ".", "hue", ")", "else", "self", ".", "hue", ",", "\n", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomGaussianBlur.__init__": [[134, 148], ["dali_dataloader.Mux", "nvidia.GaussianBlur", "nvidia.GaussianBlur", "nvidia.GaussianBlur", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", "=", "0.5", ",", "window_size", ":", "int", "=", "23", ",", "device", ":", "str", "=", "\"gpu\"", ")", ":", "\n", "        ", "\"\"\"Applies random gaussian blur with probability.\n\n        Args:\n            prob (float, optional): probability of applying random gaussian blur. Defaults to 0.5.\n            window_size (int, optional): window size for gaussian blur. Defaults to 23.\n            device (str, optional): device on which the operation will be performe.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "# gaussian blur", "\n", "self", ".", "gaussian_blur", "=", "ops", ".", "GaussianBlur", "(", "device", "=", "device", ",", "window_size", "=", "(", "window_size", ",", "window_size", ")", ")", "\n", "self", ".", "sigma", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "0", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomGaussianBlur.__call__": [[149, 153], ["dali_dataloader.RandomGaussianBlur.gaussian_blur", "dali_dataloader.RandomGaussianBlur.mux", "dali_dataloader.RandomGaussianBlur.sigma"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "sigma", "=", "self", ".", "sigma", "(", ")", "*", "1.9", "+", "0.1", "\n", "out", "=", "self", ".", "gaussian_blur", "(", "images", ",", "sigma", "=", "sigma", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomSolarize.__init__": [[156, 167], ["dali_dataloader.Mux"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "threshold", ":", "int", "=", "128", ",", "prob", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Applies random solarization with probability.\n\n        Args:\n            threshold (int, optional): threshold for inversion. Defaults to 128.\n            prob (float, optional): probability of solarization. Defaults to 0.0.\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.RandomSolarize.__call__": [[168, 173], ["dali_dataloader.RandomSolarize.mux"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "inverted_img", "=", "255", "-", "images", "\n", "mask", "=", "images", ">=", "self", ".", "threshold", "\n", "out", "=", "mask", "*", "inverted_img", "+", "(", "True", "^", "mask", ")", "*", "images", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.NormalPipeline.__init__": [[176, 264], ["nvidia.dali.pipeline.Pipeline.__init__", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "nvidia.Resize", "nvidia.Resize", "nvidia.Resize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_path", ":", "str", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "str", ",", "\n", "validation", ":", "bool", "=", "False", ",", "\n", "device_id", ":", "int", "=", "0", ",", "\n", "shard_id", ":", "int", "=", "0", ",", "\n", "num_shards", ":", "int", "=", "1", ",", "\n", "num_threads", ":", "int", "=", "4", ",", "\n", "seed", ":", "int", "=", "12", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializes the pipeline for validation or linear eval training.\n\n        If validation is set to True then images will only be resized to 256px and center cropped\n        to 224px, otherwise random resized crop, horizontal flip are applied. In both cases images\n        are normalized.\n\n        Args:\n            data_path (str): directory that contains the data.\n            batch_size (int): batch size.\n            device (str): device on which the operation will be performed.\n            validation (bool): whether it is validation or training. Defaults to False. Defaults to\n                False.\n            device_id (int): id of the device used to initialize the seed and for parent class.\n                Defaults to 0.\n            shard_id (int): id of the shard (chuck of samples). Defaults to 0.\n            num_shards (int): total number of shards. Defaults to 1.\n            num_threads (int): number of threads to run in parallel. Defaults to 4.\n            seed (int): seed for random number generation. Defaults to 12.\n        \"\"\"", "\n", "\n", "seed", "+=", "device_id", "\n", "super", "(", ")", ".", "__init__", "(", "batch_size", ",", "num_threads", ",", "device_id", ",", "seed", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "validation", "=", "validation", "\n", "\n", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "file_root", "=", "data_path", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "True", "if", "not", "self", ".", "validation", "else", "False", ",", "\n", ")", "\n", "decoder_device", "=", "\"mixed\"", "if", "self", ".", "device", "==", "\"gpu\"", "else", "\"cpu\"", "\n", "device_memory_padding", "=", "211025920", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "host_memory_padding", "=", "140544512", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "self", ".", "decode", "=", "ops", ".", "decoders", ".", "Image", "(", "\n", "device", "=", "decoder_device", ",", "\n", "output_type", "=", "types", ".", "RGB", ",", "\n", "device_memory_padding", "=", "device_memory_padding", ",", "\n", "host_memory_padding", "=", "host_memory_padding", ",", "\n", ")", "\n", "\n", "# crop operations", "\n", "if", "self", ".", "validation", ":", "\n", "            ", "self", ".", "resize", "=", "ops", ".", "Resize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "resize_shorter", "=", "256", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "# center crop and normalize", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "crop", "=", "(", "224", ",", "224", ")", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "resize", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "size", "=", "224", ",", "\n", "random_area", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "\n", "", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "0.5", ")", "\n", "self", ".", "to_int64", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "INT64", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.NormalPipeline.define_graph": [[265, 288], ["dali_dataloader.NormalPipeline.reader", "dali_dataloader.NormalPipeline.decode", "dali_dataloader.NormalPipeline.resize", "dali_dataloader.NormalPipeline.to_int64", "dali_dataloader.NormalPipeline.cmn", "dali_dataloader.NormalPipeline.cmn", "labels.gpu.gpu.gpu", "dali_dataloader.NormalPipeline.coin05"], "methods", ["None"], ["", "def", "define_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the computational graph for dali operations.\"\"\"", "\n", "\n", "# read images from memory", "\n", "inputs", ",", "labels", "=", "self", ".", "reader", "(", "name", "=", "\"Reader\"", ")", "\n", "images", "=", "self", ".", "decode", "(", "inputs", ")", "\n", "\n", "# crop into large and small images", "\n", "images", "=", "self", ".", "resize", "(", "images", ")", "\n", "\n", "if", "self", ".", "validation", ":", "\n", "# crop and normalize", "\n", "            ", "images", "=", "self", ".", "cmn", "(", "images", ")", "\n", "", "else", ":", "\n", "# normalize and maybe apply horizontal flip with 0.5 chance", "\n", "            ", "images", "=", "self", ".", "cmn", "(", "images", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "device", "==", "\"gpu\"", ":", "\n", "            ", "labels", "=", "labels", ".", "gpu", "(", ")", "\n", "# PyTorch expects labels as INT64", "\n", "", "labels", "=", "self", ".", "to_int64", "(", "labels", ")", "\n", "\n", "return", "(", "images", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.ImagenetTransform.__init__": [[300, 369], ["nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "dali_dataloader.RandomColorJitter", "dali_dataloader.RandomGrayScaleConversion", "dali_dataloader.RandomGaussianBlur", "dali_dataloader.RandomSolarize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "device", ":", "str", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "size", ":", "int", "=", "224", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies Imagenet transformations to a batch of images.\n\n        Args:\n            device (str): device on which the operations will be performed.\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.5.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            size (int, optional): size of the side of the image after transformation. Defaults\n                to 224.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n        \"\"\"", "\n", "\n", "# random crop", "\n", "self", ".", "random_crop", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "device", ",", "\n", "size", "=", "size", ",", "\n", "random_area", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "\n", "# color jitter", "\n", "self", ".", "random_color_jitter", "=", "RandomColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "prob", "=", "0.8", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "# grayscale conversion", "\n", "self", ".", "random_grayscale", "=", "RandomGrayScaleConversion", "(", "prob", "=", "0.2", ",", "device", "=", "device", ")", "\n", "\n", "# gaussian blur", "\n", "self", ".", "random_gaussian_blur", "=", "RandomGaussianBlur", "(", "prob", "=", "gaussian_prob", ",", "device", "=", "device", ")", "\n", "\n", "# solarization", "\n", "self", ".", "random_solarization", "=", "RandomSolarize", "(", "prob", "=", "solarization_prob", ")", "\n", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "0.5", ")", "\n", "\n", "self", ".", "str", "=", "(", "\n", "\"ImagenetTransform(\"", "\n", "f\"random_crop({min_scale}, {max_scale}), \"", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.ImagenetTransform.__str__": [[377, 379], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.ImagenetTransform.__call__": [[380, 388], ["dali_dataloader.ImagenetTransform.random_crop", "dali_dataloader.ImagenetTransform.random_color_jitter", "dali_dataloader.ImagenetTransform.random_grayscale", "dali_dataloader.ImagenetTransform.random_gaussian_blur", "dali_dataloader.ImagenetTransform.random_solarization", "dali_dataloader.ImagenetTransform.cmn", "dali_dataloader.ImagenetTransform.coin05"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "random_crop", "(", "images", ")", "\n", "out", "=", "self", ".", "random_color_jitter", "(", "out", ")", "\n", "out", "=", "self", ".", "random_grayscale", "(", "out", ")", "\n", "out", "=", "self", ".", "random_gaussian_blur", "(", "out", ")", "\n", "out", "=", "self", ".", "random_solarization", "(", "out", ")", "\n", "out", "=", "self", ".", "cmn", "(", "out", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.CustomTransform.__init__": [[391, 467], ["nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "dali_dataloader.RandomColorJitter", "dali_dataloader.RandomGrayScaleConversion", "dali_dataloader.RandomGaussianBlur", "dali_dataloader.RandomSolarize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "device", ":", "str", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "size", ":", "int", "=", "224", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "mean", ":", "Sequence", "[", "float", "]", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", ":", "Sequence", "[", "float", "]", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies Custom transformations.\n        If you want to do exoteric augmentations, you can just re-write this class.\n\n        Args:\n            device (str): device on which the operations will be performed.\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.5.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            size (int, optional): size of the side of the image after transformation. Defaults\n                to 224.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            mean (Sequence[float], optional): mean values for normalization.\n                Defaults to (0.485, 0.456, 0.406).\n            std (Sequence[float], optional): std values for normalization.\n                Defaults to (0.228, 0.224, 0.225).\n        \"\"\"", "\n", "\n", "# random crop", "\n", "self", ".", "random_crop", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "device", ",", "\n", "size", "=", "size", ",", "\n", "random_area", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "\n", "# color jitter", "\n", "self", ".", "random_color_jitter", "=", "RandomColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "prob", "=", "0.8", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "# grayscale conversion", "\n", "self", ".", "random_grayscale", "=", "RandomGrayScaleConversion", "(", "prob", "=", "0.2", ",", "device", "=", "device", ")", "\n", "\n", "# gaussian blur", "\n", "self", ".", "random_gaussian_blur", "=", "RandomGaussianBlur", "(", "prob", "=", "gaussian_prob", ",", "device", "=", "device", ")", "\n", "\n", "# solarization", "\n", "self", ".", "random_solarization", "=", "RandomSolarize", "(", "prob", "=", "solarization_prob", ")", "\n", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "v", "*", "255", "for", "v", "in", "mean", "]", ",", "\n", "std", "=", "[", "v", "*", "255", "for", "v", "in", "std", "]", ",", "\n", ")", "\n", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "0.5", ")", "\n", "\n", "self", ".", "str", "=", "(", "\n", "\"CustomTransform(\"", "\n", "f\"random_crop({min_scale}, {max_scale}), \"", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.CustomTransform.__call__": [[475, 483], ["dali_dataloader.CustomTransform.random_crop", "dali_dataloader.CustomTransform.random_color_jitter", "dali_dataloader.CustomTransform.random_grayscale", "dali_dataloader.CustomTransform.random_gaussian_blur", "dali_dataloader.CustomTransform.random_solarization", "dali_dataloader.CustomTransform.cmn", "dali_dataloader.CustomTransform.coin05"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "random_crop", "(", "images", ")", "\n", "out", "=", "self", ".", "random_color_jitter", "(", "out", ")", "\n", "out", "=", "self", ".", "random_grayscale", "(", "out", ")", "\n", "out", "=", "self", ".", "random_gaussian_blur", "(", "out", ")", "\n", "out", "=", "self", ".", "random_solarization", "(", "out", ")", "\n", "out", "=", "self", ".", "cmn", "(", "out", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.CustomTransform.__str__": [[484, 486], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.PretrainPipeline.__init__": [[489, 609], ["nvidia.dali.pipeline.Pipeline.__init__", "pathlib.Path", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "isinstance", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "len", "sorted", "enumerate", "zip", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "sorted", "files.append", "sorted.append", "true_labels.append", "dali_dataloader.PretrainPipeline.conversion_map.append", "os.listdir", "pathlib.Path", "enumerate", "sorted", "os.scandir", "entry.is_dir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "str", ",", "\n", "transform", ":", "Union", "[", "Callable", ",", "Iterable", "]", ",", "\n", "num_crops", ":", "int", "=", "2", ",", "\n", "random_shuffle", ":", "bool", "=", "True", ",", "\n", "device_id", ":", "int", "=", "0", ",", "\n", "shard_id", ":", "int", "=", "0", ",", "\n", "num_shards", ":", "int", "=", "1", ",", "\n", "num_threads", ":", "int", "=", "4", ",", "\n", "seed", ":", "int", "=", "12", ",", "\n", "no_labels", ":", "bool", "=", "False", ",", "\n", "encode_indexes_into_labels", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializes the pipeline for pretraining.\n\n        Args:\n            data_path (str): directory that contains the data.\n            batch_size (int): batch size.\n            device (str): device on which the operation will be performed.\n            transform (Union[Callable, Iterable]): a transformation or a sequence\n                of transformations to be applied.\n            num_crops (int, optional): number of crops. Defaults to 2.\n            random_shuffle (bool, optional): whether to randomly shuffle the samples.\n                Defaults to True.\n            device_id (int, optional): id of the device used to initialize the seed and\n                for parent class. Defaults to 0.\n            shard_id (int, optional): id of the shard (chuck of samples). Defaults to 0.\n            num_shards (int, optional): total number of shards. Defaults to 1.\n            num_threads (int, optional): number of threads to run in parallel. Defaults to 4.\n            seed (int, optional): seed for random number generation. Defaults to 12.\n            no_labels (bool, optional): if the data has no labels. Defaults to False.\n            encode_indexes_into_labels (bool, optional): uses sample indexes as labels\n                and then gets the labels from a lookup table. This may use more CPU memory,\n                so just use when needed. Defaults to False.\n        \"\"\"", "\n", "\n", "seed", "+=", "device_id", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "device_id", "=", "device_id", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "data_path", "=", "Path", "(", "data_path", ")", "\n", "if", "no_labels", ":", "\n", "            ", "files", "=", "[", "data_path", "/", "f", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", ")", ")", "]", "\n", "labels", "=", "[", "-", "1", "]", "*", "len", "(", "files", ")", "\n", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", "labels", "=", "labels", ",", "\n", ")", "\n", "", "elif", "encode_indexes_into_labels", ":", "\n", "            ", "labels", "=", "sorted", "(", "Path", "(", "entry", ".", "name", ")", "for", "entry", "in", "os", ".", "scandir", "(", "data_path", ")", "if", "entry", ".", "is_dir", "(", ")", ")", "\n", "\n", "data", "=", "[", "\n", "(", "data_path", "/", "label", "/", "file", ",", "label_idx", ")", "\n", "for", "label_idx", ",", "label", "in", "enumerate", "(", "labels", ")", "\n", "for", "file", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", "/", "label", ")", ")", "\n", "]", "\n", "\n", "files", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "# for debugging", "\n", "true_labels", "=", "[", "]", "\n", "\n", "self", ".", "conversion_map", "=", "[", "]", "\n", "for", "file_idx", ",", "(", "file", ",", "label_idx", ")", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "files", ".", "append", "(", "file", ")", "\n", "labels", ".", "append", "(", "file_idx", ")", "\n", "true_labels", ".", "append", "(", "label_idx", ")", "\n", "self", ".", "conversion_map", ".", "append", "(", "label_idx", ")", "\n", "\n", "# debugging", "\n", "", "for", "file", ",", "file_idx", ",", "label_idx", "in", "zip", "(", "files", ",", "labels", ",", "true_labels", ")", ":", "\n", "                ", "assert", "self", ".", "conversion_map", "[", "file_idx", "]", "==", "label_idx", "\n", "\n", "", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "file_root", "=", "data_path", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "\n", "", "decoder_device", "=", "\"mixed\"", "if", "self", ".", "device", "==", "\"gpu\"", "else", "\"cpu\"", "\n", "device_memory_padding", "=", "211025920", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "host_memory_padding", "=", "140544512", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "self", ".", "decode", "=", "ops", ".", "decoders", ".", "Image", "(", "\n", "device", "=", "decoder_device", ",", "\n", "output_type", "=", "types", ".", "RGB", ",", "\n", "device_memory_padding", "=", "device_memory_padding", ",", "\n", "host_memory_padding", "=", "host_memory_padding", ",", "\n", ")", "\n", "self", ".", "to_int64", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "INT64", ",", "device", "=", "device", ")", "\n", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "\n", "# transformations", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "if", "isinstance", "(", "transform", ",", "Iterable", ")", ":", "\n", "            ", "self", ".", "one_transform_per_crop", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "one_transform_per_crop", "=", "False", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.PretrainPipeline.define_graph": [[610, 629], ["dali_dataloader.PretrainPipeline.reader", "dali_dataloader.PretrainPipeline.decode", "dali_dataloader.PretrainPipeline.to_int64", "labels.gpu.gpu.gpu", "transform", "dali_dataloader.PretrainPipeline.transform", "range"], "methods", ["None"], ["", "", "def", "define_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the computational graph for dali operations.\"\"\"", "\n", "\n", "# read images from memory", "\n", "inputs", ",", "labels", "=", "self", ".", "reader", "(", "name", "=", "\"Reader\"", ")", "\n", "\n", "images", "=", "self", ".", "decode", "(", "inputs", ")", "\n", "\n", "if", "self", ".", "one_transform_per_crop", ":", "\n", "            ", "crops", "=", "[", "transform", "(", "images", ")", "for", "transform", "in", "self", ".", "transform", "]", "\n", "", "else", ":", "\n", "            ", "crops", "=", "[", "self", ".", "transform", "(", "images", ")", "for", "i", "in", "range", "(", "self", ".", "num_crops", ")", "]", "\n", "\n", "", "if", "self", ".", "device", "==", "\"gpu\"", ":", "\n", "            ", "labels", "=", "labels", ".", "gpu", "(", ")", "\n", "# PyTorch expects labels as INT64", "\n", "", "labels", "=", "self", ".", "to_int64", "(", "labels", ")", "\n", "\n", "return", "(", "*", "crops", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.MulticropPretrainPipeline.__init__": [[632, 745], ["nvidia.dali.pipeline.Pipeline.__init__", "pathlib.Path", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "len", "len", "len", "sorted", "enumerate", "zip", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "sorted", "files.append", "sorted.append", "true_labels.append", "dali_dataloader.MulticropPretrainPipeline.conversion_map.append", "os.listdir", "pathlib.Path", "enumerate", "sorted", "os.scandir", "entry.is_dir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "str", ",", "\n", "transforms", ":", "List", ",", "\n", "num_crops", ":", "List", "[", "int", "]", ",", "\n", "random_shuffle", ":", "bool", "=", "True", ",", "\n", "device_id", ":", "int", "=", "0", ",", "\n", "shard_id", ":", "int", "=", "0", ",", "\n", "num_shards", ":", "int", "=", "1", ",", "\n", "num_threads", ":", "int", "=", "4", ",", "\n", "seed", ":", "int", "=", "12", ",", "\n", "no_labels", ":", "bool", "=", "False", ",", "\n", "encode_indexes_into_labels", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializes the pipeline for pretraining with multicrop.\n\n        Args:\n            data_path (str): directory that contains the data.\n            batch_size (int): batch size.\n            device (str): device on which the operation will be performed.\n            transforms (List): list of transformations to be applied.\n            num_crops (List[int]): number of crops.\n            random_shuffle (bool, optional): whether to randomly shuffle the samples.\n                Defaults to True.\n            device_id (int, optional): id of the device used to initialize the seed and\n                for parent class. Defaults to 0.\n            shard_id (int, optional): id of the shard (chuck of samples). Defaults to 0.\n            num_shards (int, optional): total number of shards. Defaults to 1.\n            num_threads (int, optional): number of threads to run in parallel. Defaults to 4.\n            seed (int, optional): seed for random number generation. Defaults to 12.\n            no_labels (bool, optional): if the data has no labels. Defaults to False.\n            encode_indexes_into_labels (bool, optional): uses sample indexes as labels\n                and then gets the labels from a lookup table. This may use more CPU memory,\n                so just use when needed. Defaults to False.\n        \"\"\"", "\n", "\n", "seed", "+=", "device_id", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "num_threads", ",", "\n", "device_id", "=", "device_id", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "data_path", "=", "Path", "(", "data_path", ")", "\n", "if", "no_labels", ":", "\n", "            ", "files", "=", "[", "data_path", "/", "f", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", ")", ")", "]", "\n", "labels", "=", "[", "-", "1", "]", "*", "len", "(", "files", ")", "\n", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", "labels", "=", "labels", ",", "\n", ")", "\n", "", "elif", "encode_indexes_into_labels", ":", "\n", "            ", "labels", "=", "sorted", "(", "Path", "(", "entry", ".", "name", ")", "for", "entry", "in", "os", ".", "scandir", "(", "data_path", ")", "if", "entry", ".", "is_dir", "(", ")", ")", "\n", "\n", "data", "=", "[", "\n", "(", "data_path", "/", "label", "/", "file", ",", "label_idx", ")", "\n", "for", "label_idx", ",", "label", "in", "enumerate", "(", "labels", ")", "\n", "for", "file", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", "/", "label", ")", ")", "\n", "]", "\n", "\n", "files", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "# for debugging", "\n", "true_labels", "=", "[", "]", "\n", "\n", "self", ".", "conversion_map", "=", "[", "]", "\n", "for", "file_idx", ",", "(", "file", ",", "label_idx", ")", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "files", ".", "append", "(", "file", ")", "\n", "labels", ".", "append", "(", "file_idx", ")", "\n", "true_labels", ".", "append", "(", "label_idx", ")", "\n", "self", ".", "conversion_map", ".", "append", "(", "label_idx", ")", "\n", "\n", "# debugging", "\n", "", "for", "file", ",", "file_idx", ",", "label_idx", "in", "zip", "(", "files", ",", "labels", ",", "true_labels", ")", ":", "\n", "                ", "assert", "self", ".", "conversion_map", "[", "file_idx", "]", "==", "label_idx", "\n", "\n", "", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "file_root", "=", "data_path", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "\n", "", "decoder_device", "=", "\"mixed\"", "if", "self", ".", "device", "==", "\"gpu\"", "else", "\"cpu\"", "\n", "device_memory_padding", "=", "211025920", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "host_memory_padding", "=", "140544512", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "self", ".", "decode", "=", "ops", ".", "decoders", ".", "Image", "(", "\n", "device", "=", "decoder_device", ",", "\n", "output_type", "=", "types", ".", "RGB", ",", "\n", "device_memory_padding", "=", "device_memory_padding", ",", "\n", "host_memory_padding", "=", "host_memory_padding", ",", "\n", ")", "\n", "self", ".", "to_int64", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "INT64", ",", "device", "=", "device", ")", "\n", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n", "assert", "len", "(", "transforms", ")", "==", "len", "(", "num_crops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.dali_dataloader.MulticropPretrainPipeline.define_graph": [[746, 766], ["dali_dataloader.MulticropPretrainPipeline.reader", "dali_dataloader.MulticropPretrainPipeline.decode", "enumerate", "dali_dataloader.MulticropPretrainPipeline.to_int64", "range", "labels.gpu.gpu.gpu", "transform", "crops.append"], "methods", ["None"], ["", "def", "define_graph", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the computational graph for dali operations.\"\"\"", "\n", "\n", "# read images from memory", "\n", "inputs", ",", "labels", "=", "self", ".", "reader", "(", "name", "=", "\"Reader\"", ")", "\n", "images", "=", "self", ".", "decode", "(", "inputs", ")", "\n", "\n", "# crop into large and small images", "\n", "crops", "=", "[", "]", "\n", "for", "i", ",", "transform", "in", "enumerate", "(", "self", ".", "transforms", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "self", ".", "num_crops", "[", "i", "]", ")", ":", "\n", "                ", "crop", "=", "transform", "(", "images", ")", "\n", "crops", ".", "append", "(", "crop", ")", "\n", "\n", "", "", "if", "self", ".", "device", "==", "\"gpu\"", ":", "\n", "            ", "labels", "=", "labels", ".", "gpu", "(", ")", "\n", "# PyTorch expects labels as INT64", "\n", "", "labels", "=", "self", ".", "to_int64", "(", "labels", ")", "\n", "\n", "return", "(", "*", "crops", ",", "labels", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.__init__": [[39, 67], ["pathlib.Path", "pytorch_lightning.callbacks.Callback.__init__", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "args", ":", "Namespace", ",", "\n", "logdir", ":", "Union", "[", "str", ",", "Path", "]", "=", "Path", "(", "\"auto_umap\"", ")", ",", "\n", "frequency", ":", "int", "=", "1", ",", "\n", "keep_previous", ":", "bool", "=", "False", ",", "\n", "color_palette", ":", "str", "=", "\"hls\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"UMAP callback that automatically runs UMAP on the validation dataset and uploads the\n        figure to wandb.\n\n        Args:\n            args (Namespace): namespace object containing at least an attribute name.\n            logdir (Union[str, Path], optional): base directory to store checkpoints.\n                Defaults to Path(\"auto_umap\").\n            frequency (int, optional): number of epochs between each UMAP. Defaults to 1.\n            color_palette (str, optional): color scheme for the classes. Defaults to \"hls\".\n            keep_previous (bool, optional): whether to keep previous plots or not.\n                Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "logdir", "=", "Path", "(", "logdir", ")", "\n", "self", ".", "frequency", "=", "frequency", "\n", "self", ".", "color_palette", "=", "color_palette", "\n", "self", ".", "keep_previous", "=", "keep_previous", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.add_auto_umap_args": [[68, 80], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_auto_umap_args", "(", "parent_parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"Adds user-required arguments to a parser.\n\n        Args:\n            parent_parser (ArgumentParser): parser to add new args to.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"auto_umap\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_umap_dir\"", ",", "default", "=", "Path", "(", "\"auto_umap\"", ")", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_umap_frequency\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.initial_setup": [[81, 103], ["str", "os.makedirs"], "methods", ["None"], ["", "def", "initial_setup", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Creates the directories and does the initial setup needed.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "logger", "is", "None", ":", "\n", "            ", "version", "=", "None", "\n", "", "else", ":", "\n", "            ", "version", "=", "str", "(", "trainer", ".", "logger", ".", "version", ")", "\n", "", "if", "version", "is", "not", "None", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "/", "version", "\n", "self", ".", "umap_placeholder", "=", "f\"{self.args.name}-{version}\"", "+", "\"-ep={}.pdf\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "\n", "self", ".", "umap_placeholder", "=", "f\"{self.args.name}\"", "+", "\"-ep={}.pdf\"", "\n", "", "self", ".", "last_ckpt", ":", "Optional", "[", "str", "]", "=", "None", "\n", "\n", "# create logging dirs", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.on_train_start": [[104, 112], ["auto_umap.AutoUMAP.initial_setup"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.initial_setup"], ["", "", "def", "on_train_start", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Performs initial setup on training start.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "self", ".", "initial_setup", "(", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.plot": [[113, 187], ["module.eval", "module.train", "torch.no_grad", "len", "torch.cat().numpy", "torch.cat", "len", "Y.numpy.numpy.numpy", "umap.UMAP().fit_transform", "pandas.DataFrame", "matplotlib.pyplot.figure", "seaborn.scatterplot", "seaborn.scatterplot.set", "seaborn.scatterplot.tick_params", "matplotlib.pyplot.legend", "matplotlib.pyplot.tight_layout", "isinstance", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "x.to.to.to", "misc.gather.to", "misc.gather", "misc.gather", "umap.UMAP().fit_transform.append", "Y.numpy.numpy.append", "torch.unique", "wandb.log", "module", "misc.gather.cpu", "misc.gather.cpu", "torch.cat", "umap.UMAP", "seaborn.color_palette", "math.ceil", "auto_umap.AutoUMAP.umap_placeholder.format", "wandb.Image"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather"], ["", "def", "plot", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "\"\"\"Produces a UMAP visualization by forwarding all data of the\n        first validation dataloader through the module.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n            module (pl.LightningModule): current module object.\n        \"\"\"", "\n", "\n", "device", "=", "module", ".", "device", "\n", "data", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "\n", "# set module to eval model and collect all feature representations", "\n", "module", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "x", ",", "y", "in", "trainer", ".", "val_dataloaders", "[", "0", "]", ":", "\n", "                ", "x", "=", "x", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "y", "=", "y", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "feats", "=", "module", "(", "x", ")", "[", "\"feats\"", "]", "\n", "\n", "feats", "=", "gather", "(", "feats", ")", "\n", "y", "=", "gather", "(", "y", ")", "\n", "\n", "data", ".", "append", "(", "feats", ".", "cpu", "(", ")", ")", "\n", "Y", ".", "append", "(", "y", ".", "cpu", "(", ")", ")", "\n", "", "", "module", ".", "train", "(", ")", "\n", "\n", "if", "trainer", ".", "is_global_zero", "and", "len", "(", "data", ")", ":", "\n", "            ", "data", "=", "torch", ".", "cat", "(", "data", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "Y", "=", "torch", ".", "cat", "(", "Y", ",", "dim", "=", "0", ")", "\n", "num_classes", "=", "len", "(", "torch", ".", "unique", "(", "Y", ")", ")", "\n", "Y", "=", "Y", ".", "numpy", "(", ")", "\n", "\n", "data", "=", "umap", ".", "UMAP", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "data", ")", "\n", "\n", "# passing to dataframe", "\n", "df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "df", "[", "\"feat_1\"", "]", "=", "data", "[", ":", ",", "0", "]", "\n", "df", "[", "\"feat_2\"", "]", "=", "data", "[", ":", ",", "1", "]", "\n", "df", "[", "\"Y\"", "]", "=", "Y", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "9", ",", "9", ")", ")", "\n", "ax", "=", "sns", ".", "scatterplot", "(", "\n", "x", "=", "\"feat_1\"", ",", "\n", "y", "=", "\"feat_2\"", ",", "\n", "hue", "=", "\"Y\"", ",", "\n", "palette", "=", "sns", ".", "color_palette", "(", "self", ".", "color_palette", ",", "num_classes", ")", ",", "\n", "data", "=", "df", ",", "\n", "legend", "=", "\"full\"", ",", "\n", "alpha", "=", "0.3", ",", "\n", ")", "\n", "ax", ".", "set", "(", "xlabel", "=", "\"\"", ",", "ylabel", "=", "\"\"", ",", "xticklabels", "=", "[", "]", ",", "yticklabels", "=", "[", "]", ")", "\n", "ax", ".", "tick_params", "(", "left", "=", "False", ",", "right", "=", "False", ",", "bottom", "=", "False", ",", "top", "=", "False", ")", "\n", "\n", "# manually improve quality of imagenet umaps", "\n", "if", "num_classes", ">", "100", ":", "\n", "                ", "anchor", "=", "(", "0.5", ",", "1.8", ")", "\n", "", "else", ":", "\n", "                ", "anchor", "=", "(", "0.5", ",", "1.35", ")", "\n", "\n", "", "plt", ".", "legend", "(", "loc", "=", "\"upper center\"", ",", "bbox_to_anchor", "=", "anchor", ",", "ncol", "=", "math", ".", "ceil", "(", "num_classes", "/", "10", ")", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "if", "isinstance", "(", "trainer", ".", "logger", ",", "pl", ".", "loggers", ".", "WandbLogger", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "\n", "{", "\"validation_umap\"", ":", "wandb", ".", "Image", "(", "ax", ")", "}", ",", "\n", "commit", "=", "False", ",", "\n", ")", "\n", "\n", "# save plot locally as well", "\n", "", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "plt", ".", "savefig", "(", "self", ".", "path", "/", "self", ".", "umap_placeholder", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.on_validation_end": [[188, 199], ["auto_umap.AutoUMAP.plot"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.plot"], ["", "", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "\"\"\"Tries to generate an up-to-date UMAP visualization of the features\n        at the end of each validation epoch.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "if", "epoch", "%", "self", ".", "frequency", "==", "0", "and", "not", "trainer", ".", "sanity_checking", ":", "\n", "            ", "self", ".", "plot", "(", "trainer", ",", "module", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.knn.WeightedKNNClassifier.__init__": [[27, 63], ["torchmetrics.metric.Metric.__init__", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "k", ":", "int", "=", "20", ",", "\n", "T", ":", "float", "=", "0.07", ",", "\n", "num_chunks", ":", "int", "=", "100", ",", "\n", "distance_fx", ":", "str", "=", "\"cosine\"", ",", "\n", "epsilon", ":", "float", "=", "0.00001", ",", "\n", "dist_sync_on_step", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implements the weighted k-NN classifier used for evaluation.\n\n        Args:\n            k (int, optional): number of neighbors. Defaults to 20.\n            T (float, optional): temperature for the exponential. Only used with cosine\n                distance. Defaults to 0.07.\n            num_chunks (int, optional): number of chunks of test features. Defaults to 100.\n            distance_fx (str, optional): Distance function. Accepted arguments: \"cosine\" or\n                \"euclidean\". Defaults to \"cosine\".\n            epsilon (float, optional): Small value for numerical stability. Only used with\n                euclidean distance. Defaults to 0.00001.\n            dist_sync_on_step (bool, optional): whether to sync distributed values at every\n                step. Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dist_sync_on_step", "=", "dist_sync_on_step", ",", "compute_on_step", "=", "False", ")", "\n", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "num_chunks", "=", "num_chunks", "\n", "self", ".", "distance_fx", "=", "distance_fx", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n", "self", ".", "add_state", "(", "\"train_features\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"train_targets\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"test_features\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"test_targets\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.knn.WeightedKNNClassifier.update": [[64, 92], ["knn.WeightedKNNClassifier.train_features.append", "knn.WeightedKNNClassifier.train_targets.append", "knn.WeightedKNNClassifier.test_features.append", "knn.WeightedKNNClassifier.test_targets.append", "train_features.size", "train_targets.size", "test_features.size", "test_targets.size"], "methods", ["None"], ["", "def", "update", "(", "\n", "self", ",", "\n", "train_features", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "train_targets", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "test_features", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "test_targets", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Updates the memory banks. If train (test) features are passed as input, the\n        corresponding train (test) targets must be passed as well.\n\n        Args:\n            train_features (torch.Tensor, optional): a batch of train features. Defaults to None.\n            train_targets (torch.Tensor, optional): a batch of train targets. Defaults to None.\n            test_features (torch.Tensor, optional): a batch of test features. Defaults to None.\n            test_targets (torch.Tensor, optional): a batch of test targets. Defaults to None.\n        \"\"\"", "\n", "assert", "(", "train_features", "is", "None", ")", "==", "(", "train_targets", "is", "None", ")", "\n", "assert", "(", "test_features", "is", "None", ")", "==", "(", "test_targets", "is", "None", ")", "\n", "\n", "if", "train_features", "is", "not", "None", ":", "\n", "            ", "assert", "train_features", ".", "size", "(", "0", ")", "==", "train_targets", ".", "size", "(", "0", ")", "\n", "self", ".", "train_features", ".", "append", "(", "train_features", ")", "\n", "self", ".", "train_targets", ".", "append", "(", "train_targets", ")", "\n", "\n", "", "if", "test_features", "is", "not", "None", ":", "\n", "            ", "assert", "test_features", ".", "size", "(", "0", ")", "==", "test_targets", ".", "size", "(", "0", ")", "\n", "self", ".", "test_features", ".", "append", "(", "test_features", ")", "\n", "self", ".", "test_targets", ".", "append", "(", "test_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.knn.WeightedKNNClassifier.compute": [[93, 164], ["torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.unique().numel", "torch.cat.size", "max", "min", "torch.zeros().to", "range", "knn.WeightedKNNClassifier.reset", "torch.cat.size", "targets.size", "torch.mm.topk", "torch.cat.view().expand", "torch.gather", "torch.zeros().to.resize_().zero_", "torch.zeros().to.scatter_", "torch.sum", "torch.sum.sort", "predictions.eq", "targets.size", "torch.unique", "torch.zeros", "torch.mm", "torch.gather.view", "distances.clone().div_().exp_.clone().div_().exp_.clone().div_().exp_", "torch.mul", "targets.data.view", "predictions.eq.narrow().sum().item", "predictions.eq.narrow().sum().item", "min", "torch.cat.t", "torch.cat.view", "torch.zeros().to.resize_", "torch.zeros().to.view", "distances.clone().div_().exp_.clone().div_().exp_.view", "min", "distances.clone().div_().exp_.clone().div_().exp_.clone().div_", "predictions.eq.narrow().sum", "predictions.eq.narrow().sum", "torch.cdist", "distances.clone().div_().exp_.clone().div_().exp_.clone", "predictions.eq.narrow", "predictions.eq.narrow", "min"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute", "(", "self", ")", "->", "Sequence", "[", "float", "]", ":", "\n", "        ", "\"\"\"Computes weighted k-NN accuracy @1 and @5. If cosine distance is selected,\n        the weight is computed using the exponential of the temperature scaled cosine\n        distance of the samples. If euclidean distance is selected, the weight corresponds\n        to the inverse of the euclidean distance.\n\n        Returns:\n            Sequence[float]: k-NN accuracy @1 and @5.\n        \"\"\"", "\n", "train_features", "=", "torch", ".", "cat", "(", "self", ".", "train_features", ")", "\n", "train_targets", "=", "torch", ".", "cat", "(", "self", ".", "train_targets", ")", "\n", "test_features", "=", "torch", ".", "cat", "(", "self", ".", "test_features", ")", "\n", "test_targets", "=", "torch", ".", "cat", "(", "self", ".", "test_targets", ")", "\n", "\n", "top1", ",", "top5", ",", "total", "=", "0.0", ",", "0.0", ",", "0", "\n", "num_classes", "=", "torch", ".", "unique", "(", "test_targets", ")", ".", "numel", "(", ")", "\n", "num_test_images", "=", "test_targets", ".", "size", "(", "0", ")", "\n", "chunk_size", "=", "max", "(", "1", ",", "num_test_images", "//", "self", ".", "num_chunks", ")", "\n", "k", "=", "min", "(", "self", ".", "k", ",", "train_targets", ".", "size", "(", "0", ")", ")", "\n", "retrieval_one_hot", "=", "torch", ".", "zeros", "(", "k", ",", "num_classes", ")", ".", "to", "(", "train_features", ".", "device", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "num_test_images", ",", "chunk_size", ")", ":", "\n", "# get the features for test images", "\n", "            ", "features", "=", "test_features", "[", "idx", ":", "min", "(", "(", "idx", "+", "chunk_size", ")", ",", "num_test_images", ")", ",", ":", "]", "\n", "targets", "=", "test_targets", "[", "idx", ":", "min", "(", "(", "idx", "+", "chunk_size", ")", ",", "num_test_images", ")", "]", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "# calculate the dot product and compute top-k neighbors", "\n", "if", "self", ".", "distance_fx", "==", "\"cosine\"", ":", "\n", "                ", "similarity", "=", "torch", ".", "mm", "(", "features", ",", "train_features", ".", "t", "(", ")", ")", "\n", "", "elif", "self", ".", "distance_fx", "==", "\"euclidean\"", ":", "\n", "                ", "similarity", "=", "1", "/", "(", "torch", ".", "cdist", "(", "features", ",", "train_features", ")", "+", "self", ".", "epsilon", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "distances", ",", "indices", "=", "similarity", ".", "topk", "(", "k", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "candidates", "=", "train_targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "retrieved_neighbors", "=", "torch", ".", "gather", "(", "candidates", ",", "1", ",", "indices", ")", "\n", "\n", "retrieval_one_hot", ".", "resize_", "(", "batch_size", "*", "k", ",", "num_classes", ")", ".", "zero_", "(", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "retrieval_one_hot", ".", "scatter_", "(", "1", ",", "retrieved_neighbors", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "\n", "if", "self", ".", "distance_fx", "==", "\"cosine\"", ":", "\n", "                ", "distances", "=", "distances", ".", "clone", "(", ")", ".", "div_", "(", "self", ".", "T", ")", ".", "exp_", "(", ")", "\n", "\n", "", "probs", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "mul", "(", "\n", "retrieval_one_hot", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_classes", ")", ",", "\n", "distances", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", ",", "\n", ")", ",", "\n", "1", ",", "\n", ")", "\n", "_", ",", "predictions", "=", "probs", ".", "sort", "(", "1", ",", "True", ")", "\n", "\n", "# find the predictions that match the target", "\n", "correct", "=", "predictions", ".", "eq", "(", "targets", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "top1", "=", "top1", "+", "correct", ".", "narrow", "(", "1", ",", "0", ",", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "top5", "=", "(", "\n", "top5", "+", "correct", ".", "narrow", "(", "1", ",", "0", ",", "min", "(", "5", ",", "k", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "# top5 does not make sense if k < 5", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "", "top1", "=", "top1", "*", "100.0", "/", "total", "\n", "top5", "=", "top5", "*", "100.0", "/", "total", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "return", "top1", ",", "top5", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.kmeans.KMeans.__init__": [[30, 59], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "world_size", ":", "int", ",", "\n", "rank", ":", "int", ",", "\n", "num_crops", ":", "int", ",", "\n", "dataset_size", ":", "int", ",", "\n", "proj_features_dim", ":", "int", ",", "\n", "num_prototypes", ":", "int", ",", "\n", "kmeans_iters", ":", "int", "=", "10", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that performs K-Means on the hypersphere.\n\n        Args:\n            world_size (int): world size.\n            rank (int): rank of the current process.\n            num_crops (int): number of crops.\n            dataset_size (int): total size of the dataset (number of samples).\n            proj_features_dim (int): number of dimensions of the projected features.\n            num_prototypes (int): number of prototypes.\n            kmeans_iters (int, optional): number of iterations for the k-means clustering.\n                Defaults to 10.\n        \"\"\"", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "self", ".", "dataset_size", "=", "dataset_size", "\n", "self", ".", "proj_features_dim", "=", "proj_features_dim", "\n", "self", ".", "num_prototypes", "=", "num_prototypes", "\n", "self", ".", "kmeans_iters", "=", "kmeans_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.kmeans.KMeans.get_indices_sparse": [[60, 65], ["numpy.arange", "scipy.sparse.csr_matrix", "numpy.unravel_index", "data.ravel", "int", "data.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_indices_sparse", "(", "data", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "cols", "=", "np", ".", "arange", "(", "data", ".", "size", ")", "\n", "M", "=", "csr_matrix", "(", "(", "cols", ",", "(", "data", ".", "ravel", "(", ")", ",", "cols", ")", ")", ",", "shape", "=", "(", "int", "(", "data", ".", "max", "(", ")", ")", "+", "1", ",", "data", ".", "size", ")", ")", "\n", "return", "[", "np", ".", "unravel_index", "(", "row", ".", "data", ",", "data", ".", "shape", ")", "for", "row", "in", "M", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.kmeans.KMeans.cluster_memory": [[66, 171], ["torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "range", "centroids_list.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.broadcast", "torch.broadcast", "torch.broadcast", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm.max", "torch.mm.max", "torch.mm.max", "kmeans.KMeans.get_indices_sparse", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.normalize", "torch.normalize", "torch.normalize", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "list", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.all_gather.wait", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "list", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.all_gather.wait", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len", "torch.normalize.t", "local_assignments.cpu().numpy", "len", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "counts[].unsqueeze", "local_assignments.size", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "local_memory_index.size", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "len", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "local_assignments.cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.kmeans.KMeans.get_indices_sparse"], ["", "def", "cluster_memory", "(", "\n", "self", ",", "\n", "local_memory_index", ":", "torch", ".", "Tensor", ",", "\n", "local_memory_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Sequence", "[", "Any", "]", ":", "\n", "        ", "\"\"\"Performs K-Means clustering on the hypersphere and returns centroids and\n        assignments for each sample.\n\n        Args:\n            local_memory_index (torch.Tensor): memory bank cointaining indices of the\n                samples.\n            local_memory_embeddings (torch.Tensor): memory bank cointaining embeddings\n                of the samples.\n\n        Returns:\n            Sequence[Any]: assignments and centroids.\n        \"\"\"", "\n", "j", "=", "0", "\n", "device", "=", "local_memory_embeddings", ".", "device", "\n", "assignments", "=", "-", "torch", ".", "ones", "(", "len", "(", "self", ".", "num_prototypes", ")", ",", "self", ".", "dataset_size", ")", ".", "long", "(", ")", "\n", "centroids_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_K", ",", "K", "in", "enumerate", "(", "self", ".", "num_prototypes", ")", ":", "\n", "# run distributed k-means", "\n", "\n", "# init centroids with elements from memory bank of rank 0", "\n", "                ", "centroids", "=", "torch", ".", "empty", "(", "K", ",", "self", ".", "proj_features_dim", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "                    ", "random_idx", "=", "torch", ".", "randperm", "(", "len", "(", "local_memory_embeddings", "[", "j", "]", ")", ")", "[", ":", "K", "]", "\n", "assert", "len", "(", "random_idx", ")", ">=", "K", ",", "\"please reduce the number of centroids\"", "\n", "centroids", "=", "local_memory_embeddings", "[", "j", "]", "[", "random_idx", "]", "\n", "", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                    ", "dist", ".", "broadcast", "(", "centroids", ",", "0", ")", "\n", "\n", "", "for", "n_iter", "in", "range", "(", "self", ".", "kmeans_iters", "+", "1", ")", ":", "\n", "\n", "# E step", "\n", "                    ", "dot_products", "=", "torch", ".", "mm", "(", "local_memory_embeddings", "[", "j", "]", ",", "centroids", ".", "t", "(", ")", ")", "\n", "_", ",", "local_assignments", "=", "dot_products", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "# finish", "\n", "if", "n_iter", "==", "self", ".", "kmeans_iters", ":", "\n", "                        ", "break", "\n", "\n", "# M step", "\n", "", "where_helper", "=", "self", ".", "get_indices_sparse", "(", "local_assignments", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "counts", "=", "torch", ".", "zeros", "(", "K", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "int", "(", ")", "\n", "emb_sums", "=", "torch", ".", "zeros", "(", "K", ",", "self", ".", "proj_features_dim", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "for", "k", "in", "range", "(", "len", "(", "where_helper", ")", ")", ":", "\n", "                        ", "if", "len", "(", "where_helper", "[", "k", "]", "[", "0", "]", ")", ">", "0", ":", "\n", "                            ", "emb_sums", "[", "k", "]", "=", "torch", ".", "sum", "(", "\n", "local_memory_embeddings", "[", "j", "]", "[", "where_helper", "[", "k", "]", "[", "0", "]", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "counts", "[", "k", "]", "=", "len", "(", "where_helper", "[", "k", "]", "[", "0", "]", ")", "\n", "", "", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                        ", "dist", ".", "all_reduce", "(", "counts", ")", "\n", "dist", ".", "all_reduce", "(", "emb_sums", ")", "\n", "", "mask", "=", "counts", ">", "0", "\n", "centroids", "[", "mask", "]", "=", "emb_sums", "[", "mask", "]", "/", "counts", "[", "mask", "]", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# normalize centroids", "\n", "centroids", "=", "F", ".", "normalize", "(", "centroids", ",", "dim", "=", "1", ",", "p", "=", "2", ")", "\n", "\n", "", "centroids_list", ".", "append", "(", "centroids", ")", "\n", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "# gather the assignments", "\n", "                    ", "assignments_all", "=", "torch", ".", "empty", "(", "\n", "self", ".", "world_size", ",", "\n", "local_assignments", ".", "size", "(", "0", ")", ",", "\n", "dtype", "=", "local_assignments", ".", "dtype", ",", "\n", "device", "=", "local_assignments", ".", "device", ",", "\n", ")", "\n", "assignments_all", "=", "list", "(", "assignments_all", ".", "unbind", "(", "0", ")", ")", "\n", "\n", "dist_process", "=", "dist", ".", "all_gather", "(", "\n", "assignments_all", ",", "local_assignments", ",", "async_op", "=", "True", "\n", ")", "\n", "dist_process", ".", "wait", "(", ")", "\n", "assignments_all", "=", "torch", ".", "cat", "(", "assignments_all", ")", ".", "cpu", "(", ")", "\n", "\n", "# gather the indexes", "\n", "indexes_all", "=", "torch", ".", "empty", "(", "\n", "self", ".", "world_size", ",", "\n", "local_memory_index", ".", "size", "(", "0", ")", ",", "\n", "dtype", "=", "local_memory_index", ".", "dtype", ",", "\n", "device", "=", "local_memory_index", ".", "device", ",", "\n", ")", "\n", "indexes_all", "=", "list", "(", "indexes_all", ".", "unbind", "(", "0", ")", ")", "\n", "dist_process", "=", "dist", ".", "all_gather", "(", "indexes_all", ",", "local_memory_index", ",", "async_op", "=", "True", ")", "\n", "dist_process", ".", "wait", "(", ")", "\n", "indexes_all", "=", "torch", ".", "cat", "(", "indexes_all", ")", ".", "cpu", "(", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "assignments_all", "=", "local_assignments", "\n", "indexes_all", "=", "local_memory_index", "\n", "\n", "# log assignments", "\n", "", "assignments", "[", "i_K", "]", "[", "indexes_all", "]", "=", "assignments_all", "\n", "\n", "# next memory bank to use", "\n", "j", "=", "(", "j", "+", "1", ")", "%", "self", ".", "num_crops", "\n", "\n", "", "", "return", "assignments", ",", "centroids_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.__init__": [[31, 55], ["pathlib.Path", "pytorch_lightning.callbacks.Callback.__init__", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "args", ":", "Namespace", ",", "\n", "logdir", ":", "Union", "[", "str", ",", "Path", "]", "=", "Path", "(", "\"trained_models\"", ")", ",", "\n", "frequency", ":", "int", "=", "1", ",", "\n", "keep_previous_checkpoints", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Custom checkpointer callback that stores checkpoints in an easier to access way.\n\n        Args:\n            args (Namespace): namespace object containing at least an attribute name.\n            logdir (Union[str, Path], optional): base directory to store checkpoints.\n                Defaults to \"trained_models\".\n            frequency (int, optional): number of epochs between each checkpoint. Defaults to 1.\n            keep_previous_checkpoints (bool, optional): whether to keep previous checkpoints or not.\n                Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "logdir", "=", "Path", "(", "logdir", ")", "\n", "self", ".", "frequency", "=", "frequency", "\n", "self", ".", "keep_previous_checkpoints", "=", "keep_previous_checkpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.add_checkpointer_args": [[56, 68], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_checkpointer_args", "(", "parent_parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"Adds user-required arguments to a parser.\n\n        Args:\n            parent_parser (ArgumentParser): parser to add new args to.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"checkpointer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_dir\"", ",", "default", "=", "Path", "(", "\"trained_models\"", ")", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_frequency\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.initial_setup": [[69, 91], ["str", "os.makedirs"], "methods", ["None"], ["", "def", "initial_setup", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Creates the directories and does the initial setup needed.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "logger", "is", "None", ":", "\n", "            ", "version", "=", "None", "\n", "", "else", ":", "\n", "            ", "version", "=", "str", "(", "trainer", ".", "logger", ".", "version", ")", "\n", "", "if", "version", "is", "not", "None", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "/", "version", "\n", "self", ".", "ckpt_placeholder", "=", "f\"{self.args.name}-{version}\"", "+", "\"-ep={}.ckpt\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "\n", "self", ".", "ckpt_placeholder", "=", "f\"{self.args.name}\"", "+", "\"-ep={}.ckpt\"", "\n", "", "self", ".", "last_ckpt", ":", "Optional", "[", "str", "]", "=", "None", "\n", "\n", "# create logging dirs", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.save_args": [[92, 103], ["vars", "json.dump", "open"], "methods", ["None"], ["", "", "def", "save_args", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Stores arguments into a json file.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "args", "=", "vars", "(", "self", ".", "args", ")", "\n", "json_path", "=", "self", ".", "path", "/", "\"args.json\"", "\n", "json", ".", "dump", "(", "args", ",", "open", "(", "json_path", ",", "\"w\"", ")", ",", "default", "=", "lambda", "o", ":", "\"<not serializable>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.save": [[104, 119], ["trainer.save_checkpoint", "checkpointer.Checkpointer.ckpt_placeholder.format", "os.remove"], "methods", ["None"], ["", "", "def", "save", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Saves current checkpoint.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "is_global_zero", "and", "not", "trainer", ".", "sanity_checking", ":", "\n", "            ", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "ckpt", "=", "self", ".", "path", "/", "self", ".", "ckpt_placeholder", ".", "format", "(", "epoch", ")", "\n", "trainer", ".", "save_checkpoint", "(", "ckpt", ")", "\n", "\n", "if", "self", ".", "last_ckpt", "and", "self", ".", "last_ckpt", "!=", "ckpt", "and", "not", "self", ".", "keep_previous_checkpoints", ":", "\n", "                ", "os", ".", "remove", "(", "self", ".", "last_ckpt", ")", "\n", "", "self", ".", "last_ckpt", "=", "ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.on_train_start": [[120, 129], ["checkpointer.Checkpointer.initial_setup", "checkpointer.Checkpointer.save_args"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.initial_setup", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.save_args"], ["", "", "def", "on_train_start", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Executes initial setup and saves arguments.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "self", ".", "initial_setup", "(", "trainer", ")", "\n", "self", ".", "save_args", "(", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.on_validation_end": [[130, 140], ["checkpointer.Checkpointer.save"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.save"], ["", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Tries to save current checkpoint at the end of each validation epoch.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "if", "epoch", "%", "self", ".", "frequency", "==", "0", ":", "\n", "            ", "self", ".", "save", "(", "trainer", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.build_custom_pipeline": [[31, 56], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "build_custom_pipeline", "(", ")", ":", "\n", "    ", "\"\"\"Builds augmentation pipelines for custom data.\n    If you want to do exoteric augmentations, you can just re-write this function.\n    Needs to return a dict with the same structure.\n    \"\"\"", "\n", "\n", "pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "224", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "# resize shorter", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "# take center crop", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "return", "pipeline", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_transforms": [[58, 140], ["classification_dataloader.build_custom_pipeline", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.build_custom_pipeline"], ["", "def", "prepare_transforms", "(", "dataset", ":", "str", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Module", "]", ":", "\n", "    ", "\"\"\"Prepares pre-defined train and test transformation pipelines for some datasets.\n\n    Args:\n        dataset (str): dataset name.\n\n    Returns:\n        Tuple[nn.Module, nn.Module]: training and validation transformation pipelines.\n    \"\"\"", "\n", "\n", "cifar_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "32", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "stl_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "96", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "(", "96", ",", "96", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "imagenet_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "224", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "# resize shorter", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "# take center crop", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "custom_pipeline", "=", "build_custom_pipeline", "(", ")", "\n", "\n", "pipelines", "=", "{", "\n", "\"cifar10\"", ":", "cifar_pipeline", ",", "\n", "\"cifar100\"", ":", "cifar_pipeline", ",", "\n", "\"stl10\"", ":", "stl_pipeline", ",", "\n", "\"imagenet100\"", ":", "imagenet_pipeline", ",", "\n", "\"imagenet\"", ":", "imagenet_pipeline", ",", "\n", "\"custom\"", ":", "custom_pipeline", ",", "\n", "}", "\n", "\n", "assert", "dataset", "in", "pipelines", "\n", "\n", "pipeline", "=", "pipelines", "[", "dataset", "]", "\n", "T_train", "=", "pipeline", "[", "\"T_train\"", "]", "\n", "T_val", "=", "pipeline", "[", "\"T_val\"", "]", "\n", "\n", "return", "T_train", ",", "T_val", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_datasets": [[142, 220], ["pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "DatasetClass", "DatasetClass", "os.path.dirname", "vars", "torchvision.datasets.STL10", "torchvision.datasets.STL10", "os.path.dirname", "dataset.upper", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "os.path.realpath"], "function", ["None"], ["", "def", "prepare_datasets", "(", "\n", "dataset", ":", "str", ",", "\n", "T_train", ":", "Callable", ",", "\n", "T_val", ":", "Callable", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "val_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Dataset", ",", "Dataset", "]", ":", "\n", "    ", "\"\"\"Prepares train and val datasets.\n\n    Args:\n        dataset (str): dataset name.\n        T_train (Callable): pipeline of transformations for training dataset.\n        T_val (Callable): pipeline of transformations for validation dataset.\n        data_dir Optional[Union[str, Path]]: path where to download/locate the dataset.\n        train_dir Optional[Union[str, Path]]: subpath where the training data is located.\n        val_dir Optional[Union[str, Path]]: subpath where the validation data is located.\n\n    Returns:\n        Tuple[Dataset, Dataset]: training dataset and validation dataset.\n    \"\"\"", "\n", "\n", "if", "data_dir", "is", "None", ":", "\n", "        ", "sandbox_dir", "=", "Path", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", ")", "\n", "data_dir", "=", "sandbox_dir", "/", "\"datasets\"", "\n", "", "else", ":", "\n", "        ", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "\n", "", "if", "train_dir", "is", "None", ":", "\n", "        ", "train_dir", "=", "Path", "(", "f\"{dataset}/train\"", ")", "\n", "", "else", ":", "\n", "        ", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "\n", "", "if", "val_dir", "is", "None", ":", "\n", "        ", "val_dir", "=", "Path", "(", "f\"{dataset}/val\"", ")", "\n", "", "else", ":", "\n", "        ", "val_dir", "=", "Path", "(", "val_dir", ")", "\n", "\n", "", "assert", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"stl10\"", ",", "\"imagenet\"", ",", "\"imagenet100\"", ",", "\"custom\"", "]", "\n", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "DatasetClass", "=", "vars", "(", "torchvision", ".", "datasets", ")", "[", "dataset", ".", "upper", "(", ")", "]", "\n", "train_dataset", "=", "DatasetClass", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "T_train", ",", "\n", ")", "\n", "\n", "val_dataset", "=", "DatasetClass", "(", "\n", "data_dir", "/", "val_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "T_val", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "train_dataset", "=", "STL10", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "split", "=", "\"train\"", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "T_train", ",", "\n", ")", "\n", "val_dataset", "=", "STL10", "(", "\n", "data_dir", "/", "val_dir", ",", "\n", "split", "=", "\"test\"", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "T_val", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", ",", "\"custom\"", "]", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "val_dir", "=", "data_dir", "/", "val_dir", "\n", "\n", "train_dataset", "=", "ImageFolder", "(", "train_dir", ",", "T_train", ")", "\n", "val_dataset", "=", "ImageFolder", "(", "val_dir", ",", "T_val", ")", "\n", "\n", "", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_dataloaders": [[222, 252], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "\n", "train_dataset", ":", "Dataset", ",", "val_dataset", ":", "Dataset", ",", "batch_size", ":", "int", "=", "64", ",", "num_workers", ":", "int", "=", "4", "\n", ")", "->", "Tuple", "[", "DataLoader", ",", "DataLoader", "]", ":", "\n", "    ", "\"\"\"Wraps a train and a validation dataset with a DataLoader.\n\n    Args:\n        train_dataset (Dataset): object containing training data.\n        val_dataset (Dataset): object containing validation data.\n        batch_size (int): batch size.\n        num_workers (int): number of parallel workers.\n    Returns:\n        Tuple[DataLoader, DataLoader]: training dataloader and validation dataloader.\n    \"\"\"", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_data": [[254, 295], ["classification_dataloader.prepare_transforms", "classification_dataloader.prepare_datasets", "classification_dataloader.prepare_dataloaders"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.classification_dataloader.prepare_dataloaders"], ["", "def", "prepare_data", "(", "\n", "dataset", ":", "str", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "val_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", ")", "->", "Tuple", "[", "DataLoader", ",", "DataLoader", "]", ":", "\n", "    ", "\"\"\"Prepares transformations, creates dataset objects and wraps them in dataloaders.\n\n    Args:\n        dataset (str): dataset name.\n        data_dir (Optional[Union[str, Path]], optional): path where to download/locate the dataset.\n            Defaults to None.\n        train_dir (Optional[Union[str, Path]], optional): subpath where the\n            training data is located. Defaults to None.\n        val_dir (Optional[Union[str, Path]], optional): subpath where the\n            validation data is located. Defaults to None.\n        batch_size (int, optional): batch size. Defaults to 64.\n        num_workers (int, optional): number of parallel workers. Defaults to 4.\n\n    Returns:\n        Tuple[DataLoader, DataLoader]: prepared training and validation dataloader;.\n    \"\"\"", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "dataset", ")", "\n", "train_dataset", ",", "val_dataset", "=", "prepare_datasets", "(", "\n", "dataset", ",", "\n", "T_train", ",", "\n", "T_val", ",", "\n", "data_dir", "=", "data_dir", ",", "\n", "train_dir", "=", "train_dir", ",", "\n", "val_dir", "=", "val_dir", ",", "\n", ")", "\n", "train_loader", ",", "val_loader", "=", "prepare_dataloaders", "(", "\n", "train_dataset", ",", "\n", "val_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.__init__": [[44, 62], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_tau", ":", "float", "=", "0.996", ",", "final_tau", ":", "float", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Updates momentum parameters using exponential moving average.\n\n        Args:\n            base_tau (float, optional): base value of the weight decrease coefficient\n                (should be in [0,1]). Defaults to 0.996.\n            final_tau (float, optional): final value of the weight decrease coefficient\n                (should be in [0,1]). Defaults to 1.0.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "0", "<=", "base_tau", "<=", "1", "\n", "assert", "0", "<=", "final_tau", "<=", "1", "and", "base_tau", "<=", "final_tau", "\n", "\n", "self", ".", "base_tau", "=", "base_tau", "\n", "self", ".", "cur_tau", "=", "base_tau", "\n", "self", ".", "final_tau", "=", "final_tau", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update": [[63, 75], ["torch.no_grad", "zip", "online_net.parameters", "momentum_net.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "online_net", ":", "nn", ".", "Module", ",", "momentum_net", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "\"\"\"Performs the momentum update for each param group.\n\n        Args:\n            online_net (nn.Module): online network (e.g. online encoder, online projection, etc...).\n            momentum_net (nn.Module): momentum network (e.g. momentum encoder,\n                momentum projection, etc...).\n        \"\"\"", "\n", "\n", "for", "op", ",", "mp", "in", "zip", "(", "online_net", ".", "parameters", "(", ")", ",", "momentum_net", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "mp", ".", "data", "=", "self", ".", "cur_tau", "*", "mp", ".", "data", "+", "(", "1", "-", "self", ".", "cur_tau", ")", "*", "op", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update_tau": [[76, 87], ["math.cos"], "methods", ["None"], ["", "", "def", "update_tau", "(", "self", ",", "cur_step", ":", "int", ",", "max_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"Computes the next value for the weighting decrease coefficient tau using cosine annealing.\n\n        Args:\n            cur_step (int): number of gradient steps so far.\n            max_steps (int): overall number of gradient steps in the whole training.\n        \"\"\"", "\n", "\n", "self", ".", "cur_tau", "=", "(", "\n", "self", ".", "final_tau", "\n", "-", "(", "self", ".", "final_tau", "-", "self", ".", "base_tau", ")", "*", "(", "math", ".", "cos", "(", "math", ".", "pi", "*", "cur_step", "/", "max_steps", ")", "+", "1", ")", "/", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params": [[26, 41], ["torch.no_grad", "online_net.parameters", "momentum_net.parameters", "zip", "pm.data.copy_"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "initialize_momentum_params", "(", "online_net", ":", "nn", ".", "Module", ",", "momentum_net", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Copies the parameters of the online network to the momentum network.\n\n    Args:\n        online_net (nn.Module): online network (e.g. online encoder, online projection, etc...).\n        momentum_net (nn.Module): momentum network (e.g. momentum encoder,\n            momentum projection, etc...).\n    \"\"\"", "\n", "\n", "params_online", "=", "online_net", ".", "parameters", "(", ")", "\n", "params_momentum", "=", "momentum_net", ".", "parameters", "(", ")", "\n", "for", "po", ",", "pm", "in", "zip", "(", "params_online", ",", "params_momentum", ")", ":", "\n", "        ", "pm", ".", "data", ".", "copy_", "(", "po", ".", "data", ")", "\n", "pm", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.whitening.Whitening2d.__init__": [[28, 40], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_dim", ":", "int", ",", "eps", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Layer that computes hard whitening for W-MSE using the Cholesky decomposition.\n\n        Args:\n            output_dim (int): number of dimension of projected features.\n            eps (float, optional): eps for numerical stability in Cholesky decomposition. Defaults\n                to 0.0.\n        \"\"\"", "\n", "\n", "super", "(", "Whitening2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.whitening.Whitening2d.forward": [[41, 69], ["torch.cuda.amp.custom_fwd", "torch.cuda.amp.custom_fwd", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view().mean().view", "xn.permute().contiguous().view", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "inv_sqrt.contiguous().view.contiguous().view.contiguous().view", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d.squeeze().squeeze", "torch.nn.functional.conv2d.squeeze().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "f_cov.type", "torch.triangular_solve", "torch.triangular_solve", "torch.triangular_solve", "torch.triangular_solve", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view().mean", "xn.permute().contiguous", "xn.permute().contiguous().view.permute", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.cholesky", "torch.cholesky", "torch.cholesky", "torch.cholesky", "inv_sqrt.contiguous().view.contiguous().view.contiguous", "torch.nn.functional.conv2d.squeeze", "torch.nn.functional.conv2d.squeeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view", "xn.permute", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean"], "methods", ["None"], ["", "@", "custom_fwd", "(", "cast_inputs", "=", "torch", ".", "float32", ")", "\n", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs whitening using the Cholesky decomposition.\n\n        Args:\n            x (torch.Tensor): a batch or slice of projected features.\n\n        Returns:\n            torch.Tensor: a batch or slice of whitened features.\n        \"\"\"", "\n", "\n", "x", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "m", "=", "x", ".", "mean", "(", "0", ")", ".", "view", "(", "self", ".", "output_dim", ",", "-", "1", ")", ".", "mean", "(", "-", "1", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "xn", "=", "x", "-", "m", "\n", "\n", "T", "=", "xn", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "output_dim", ",", "-", "1", ")", "\n", "f_cov", "=", "torch", ".", "mm", "(", "T", ",", "T", ".", "permute", "(", "1", ",", "0", ")", ")", "/", "(", "T", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "\n", "eye", "=", "torch", ".", "eye", "(", "self", ".", "output_dim", ")", ".", "type", "(", "f_cov", ".", "type", "(", ")", ")", "\n", "\n", "f_cov_shrinked", "=", "(", "1", "-", "self", ".", "eps", ")", "*", "f_cov", "+", "self", ".", "eps", "*", "eye", "\n", "\n", "inv_sqrt", "=", "torch", ".", "triangular_solve", "(", "eye", ",", "torch", ".", "cholesky", "(", "f_cov_shrinked", ")", ",", "upper", "=", "False", ")", "[", "0", "]", "\n", "inv_sqrt", "=", "inv_sqrt", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "output_dim", ",", "self", ".", "output_dim", ",", "1", ",", "1", ")", "\n", "\n", "decorrelated", "=", "conv2d", "(", "xn", ",", "inv_sqrt", ")", "\n", "\n", "return", "decorrelated", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func": [[23, 58], ["query.size", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum", "torch.einsum", "torch.ones_like", "torch.ones_like", "torch.ones_like.fill_diagonal_", "neg[].reshape", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "loss.mean.mean", "neg[].reshape.size", "inter_intra.detach", "torch.einsum", "torch.einsum", "neg[].reshape.size", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax"], "function", ["None"], ["def", "dual_temperature_loss_func", "(", "\n", "query", ":", "torch", ".", "Tensor", ",", "\n", "key", ":", "torch", ".", "Tensor", ",", "\n", "temperature", "=", "0.1", ",", "\n", "dt_m", "=", "10", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "# intra-anchor hardness-awareness", "\n", "    ", "b", "=", "query", ".", "size", "(", "0", ")", "\n", "pos", "=", "torch", ".", "einsum", "(", "\"nc,nc->n\"", ",", "[", "query", ",", "key", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Selecte the intra negative samples according the updata time, ", "\n", "neg", "=", "torch", ".", "einsum", "(", "\"nc,ck->nk\"", ",", "[", "query", ",", "key", ".", "T", "]", ")", "\n", "mask_neg", "=", "torch", ".", "ones_like", "(", "neg", ",", "dtype", "=", "bool", ")", "\n", "mask_neg", ".", "fill_diagonal_", "(", "False", ")", "\n", "neg", "=", "neg", "[", "mask_neg", "]", ".", "reshape", "(", "neg", ".", "size", "(", "0", ")", ",", "neg", ".", "size", "(", "1", ")", "-", "1", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "pos", ",", "neg", "]", ",", "dim", "=", "1", ")", "\n", "\n", "logits_intra", "=", "logits", "/", "temperature", "\n", "prob_intra", "=", "F", ".", "softmax", "(", "logits_intra", ",", "dim", "=", "1", ")", "\n", "\n", "# inter-anchor hardness-awareness", "\n", "logits_inter", "=", "logits", "/", "(", "temperature", "*", "dt_m", ")", "\n", "prob_inter", "=", "F", ".", "softmax", "(", "logits_inter", ",", "dim", "=", "1", ")", "\n", "\n", "# hardness-awareness factor", "\n", "inter_intra", "=", "(", "1", "-", "prob_inter", "[", ":", ",", "0", "]", ")", "/", "(", "1", "-", "prob_intra", "[", ":", ",", "0", "]", ")", "\n", "\n", "loss", "=", "-", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits_intra", ",", "dim", "=", "-", "1", ")", "[", ":", ",", "0", "]", "\n", "\n", "# final loss", "\n", "loss", "=", "inter_intra", ".", "detach", "(", ")", "*", "loss", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.moco.moco_loss_func": [[24, 47], ["torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum", "torch.einsum", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.cross_entropy", "query.size", "torch.einsum", "torch.einsum"], "function", ["None"], ["def", "moco_loss_func", "(", "\n", "query", ":", "torch", ".", "Tensor", ",", "key", ":", "torch", ".", "Tensor", ",", "queue", ":", "torch", ".", "Tensor", ",", "temperature", "=", "0.1", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes MoCo's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n    queue of past elements.\n\n    Args:\n        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n        key (torch.Tensor): NxD Tensor containing the queries from view 2.\n        queue (torch.Tensor): a queue of negative samples for the contrastive loss.\n        temperature (float, optional): [description]. temperature of the softmax in the contrastive\n            loss. Defaults to 0.1.\n\n    Returns:\n        torch.Tensor: MoCo loss.\n    \"\"\"", "\n", "\n", "pos", "=", "torch", ".", "einsum", "(", "\"nc,nc->n\"", ",", "[", "query", ",", "key", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "neg", "=", "torch", ".", "einsum", "(", "\"nc,ck->nk\"", ",", "[", "query", ",", "queue", "]", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "pos", ",", "neg", "]", ",", "dim", "=", "1", ")", "\n", "logits", "/=", "temperature", "\n", "targets", "=", "torch", ".", "zeros", "(", "query", ".", "size", "(", "0", ")", ",", "device", "=", "query", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.setup.parse_args_pretrain": [[37, 94], ["argparse.ArgumentParser", "AutoUMAP.add_auto_umap_args.add_argument", "AutoUMAP.add_auto_umap_args.add_argument", "AutoUMAP.add_auto_umap_args.add_argument", "solo.args.dataset.dataset_args", "solo.args.dataset.augmentations_args", "pytorch_lightning.Trainer.add_argparse_args", "AutoUMAP.add_auto_umap_args.add_argument", "AutoUMAP.add_auto_umap_args.parse_known_args", "METHODS[].add_model_specific_args", "AutoUMAP.add_auto_umap_args.add_argument", "AutoUMAP.add_auto_umap_args.parse_known_args", "AutoUMAP.add_auto_umap_args.parse_args", "solo.args.utils.additional_setup_pretrain", "solo.utils.checkpointer.Checkpointer.add_checkpointer_args", "AutoUMAP.add_auto_umap_args", "os.getcwd", "os.getcwd"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.dataset.dataset_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.dataset.augmentations_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.add_checkpointer_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.auto_umap.AutoUMAP.add_auto_umap_args"], ["def", "parse_args_pretrain", "(", ")", "->", "argparse", ".", "Namespace", ":", "\n", "    ", "\"\"\"Parses dataset, augmentation, pytorch lightning, model specific and additional args.\n\n    First adds shared args such as dataset, augmentation and pytorch lightning args, then pulls the\n    model name from the command and proceeds to add model specific args from the desired class. If\n    wandb is enabled, it adds checkpointer args. Finally, adds additional non-user given parameters.\n\n    Returns:\n        argparse.Namespace: a namespace containing all args needed for pretraining.\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# add current working path", "\n", "parser", ".", "add_argument", "(", "\"--runpath\"", ",", "default", "=", "os", ".", "getcwd", "(", ")", ",", "type", "=", "str", ")", "\n", "\n", "# add code saving path", "\n", "parser", ".", "add_argument", "(", "\"--codepath\"", ",", "default", "=", "os", ".", "getcwd", "(", ")", ",", "type", "=", "str", ")", "\n", "\n", "# add current working path", "\n", "parser", ".", "add_argument", "(", "\"--log_frenquence\"", ",", "default", "=", "50", ",", "type", "=", "int", ")", "\n", "\n", "# add shared arguments", "\n", "dataset_args", "(", "parser", ")", "\n", "augmentations_args", "(", "parser", ")", "\n", "\n", "# add pytorch lightning trainer args", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "\n", "# add method-specific arguments", "\n", "parser", ".", "add_argument", "(", "\"--method\"", ",", "type", "=", "str", ")", "\n", "\n", "# THIS LINE IS KEY TO PULL THE MODEL NAME", "\n", "temp_args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# add model specific args", "\n", "parser", "=", "METHODS", "[", "temp_args", ".", "method", "]", ".", "add_model_specific_args", "(", "parser", ")", "\n", "\n", "# add auto umap args", "\n", "parser", ".", "add_argument", "(", "\"--auto_umap\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# optionally add checkpointer and AutoUMAP args", "\n", "temp_args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "if", "temp_args", ".", "wandb", ":", "\n", "        ", "parser", "=", "Checkpointer", ".", "add_checkpointer_args", "(", "parser", ")", "\n", "\n", "", "if", "_umap_available", "and", "temp_args", ".", "auto_umap", ":", "\n", "        ", "parser", "=", "AutoUMAP", ".", "add_auto_umap_args", "(", "parser", ")", "\n", "\n", "# parse args", "\n", "", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "# prepare arguments with additional setup", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.setup.parse_args_linear": [[96, 132], ["argparse.ArgumentParser", "Checkpointer.add_checkpointer_args.add_argument", "solo.args.dataset.dataset_args", "pytorch_lightning.Trainer.add_argparse_args", "METHODS[].add_model_specific_args", "Checkpointer.add_checkpointer_args.parse_known_args", "Checkpointer.add_checkpointer_args.parse_args", "solo.args.utils.additional_setup_linear", "solo.utils.checkpointer.Checkpointer.add_checkpointer_args"], "function", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.dataset.dataset_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.utils.additional_setup_linear", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.checkpointer.Checkpointer.add_checkpointer_args"], ["", "def", "parse_args_linear", "(", ")", "->", "argparse", ".", "Namespace", ":", "\n", "    ", "\"\"\"Parses feature extractor, dataset, pytorch lightning, linear eval specific and additional args.\n\n    First adds and arg for the pretrained feature extractor, then adds dataset, pytorch lightning\n    and linear eval specific args. If wandb is enabled, it adds checkpointer args. Finally, adds\n    additional non-user given parameters.\n\n    Returns:\n        argparse.Namespace: a namespace containing all args needed for pretraining.\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--pretrained_feature_extractor\"", ",", "type", "=", "str", ")", "\n", "\n", "# add shared arguments", "\n", "dataset_args", "(", "parser", ")", "\n", "\n", "# add pytorch lightning trainer args", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "\n", "# linear model", "\n", "parser", "=", "METHODS", "[", "\"linear\"", "]", ".", "add_model_specific_args", "(", "parser", ")", "\n", "\n", "# THIS LINE IS KEY TO PULL WANDB", "\n", "temp_args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# add checkpointer args (only if logging is enabled)", "\n", "if", "temp_args", ".", "wandb", ":", "\n", "        ", "parser", "=", "Checkpointer", ".", "add_checkpointer_args", "(", "parser", ")", "\n", "\n", "# parse args", "\n", "", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "additional_setup_linear", "(", "args", ")", "\n", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.dataset.dataset_args": [[24, 53], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "dataset_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"Adds dataset-related arguments to a parser.\n\n    Args:\n        parser (ArgumentParser): parser to add dataset args to.\n    \"\"\"", "\n", "\n", "SUPPORTED_DATASETS", "=", "[", "\n", "\"cifar10\"", ",", "\n", "\"cifar100\"", ",", "\n", "\"stl10\"", ",", "\n", "\"imagenet\"", ",", "\n", "\"imagenet100\"", ",", "\n", "\"custom\"", ",", "\n", "]", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "SUPPORTED_DATASETS", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "\n", "# dataset path", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_dir\"", ",", "type", "=", "Path", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_dir\"", ",", "type", "=", "Path", ",", "default", "=", "None", ")", "\n", "\n", "# dali (imagenet-100/imagenet/custom only)", "\n", "parser", ".", "add_argument", "(", "\"--dali\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dali_device\"", ",", "type", "=", "str", ",", "default", "=", "\"gpu\"", ")", "\n", "\n", "# custom dataset only", "\n", "parser", ".", "add_argument", "(", "\"--no_labels\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.dataset.augmentations_args": [[55, 85], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "augmentations_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"Adds augmentation-related arguments to a parser.\n\n    Args:\n        parser (ArgumentParser): parser to add augmentation args to.\n    \"\"\"", "\n", "\n", "# cropping", "\n", "parser", ".", "add_argument", "(", "\"--multicrop\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_crops\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_small_crops\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "# augmentations", "\n", "parser", ".", "add_argument", "(", "\"--brightness\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--contrast\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--saturation\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hue\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gaussian_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.5", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--solarization_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.0", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_scale\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.08", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# for imagenet or custom dataset", "\n", "parser", ".", "add_argument", "(", "\"--size\"", ",", "type", "=", "int", ",", "default", "=", "[", "224", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# for custom dataset", "\n", "parser", ".", "add_argument", "(", "\"--mean\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--std\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.228", ",", "0.224", ",", "0.225", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# debug", "\n", "parser", ".", "add_argument", "(", "\"--debug_augmentations\"", ",", "action", "=", "\"store_true\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.utils.additional_setup_pretrain": [[32, 213], ["max", "isinstance", "max", "getattr", "len", "isinstance", "isinstance", "isinstance", "len", "len", "setattr", "dict", "dict", "dict", "len", "zip", "int", "getattr", "args.gpus.split", "os.scandir", "isinstance"], "function", ["None"], ["def", "additional_setup_pretrain", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"Provides final setup for pretraining to non-user given parameters by changing args.\n\n    Parsers arguments to extract the number of classes of a dataset, create\n    transformations kwargs, correctly parse gpus, identify if a cifar dataset\n    is being used and adjust the lr.\n\n    Args:\n        args (Namespace): object that needs to contain, at least:\n        - dataset: dataset name.\n        - brightness, contrast, saturation, hue, min_scale: required augmentations\n            settings.\n        - multicrop: flag to use multicrop.\n        - dali: flag to use dali.\n        - optimizer: optimizer name being used.\n        - gpus: list of gpus to use.\n        - lr: learning rate.\n\n        [optional]\n        - gaussian_prob, solarization_prob: optional augmentations settings.\n    \"\"\"", "\n", "\n", "if", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", ":", "\n", "        ", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "# hack to maintain the current pipeline", "\n", "# even if the custom dataset doesn't have any labels", "\n", "        ", "dir_path", "=", "args", ".", "data_dir", "/", "args", ".", "train_dir", "\n", "args", ".", "num_classes", "=", "max", "(", "\n", "1", ",", "\n", "len", "(", "[", "entry", ".", "name", "for", "entry", "in", "os", ".", "scandir", "(", "dir_path", ")", "if", "entry", ".", "is_dir", "]", ")", ",", "\n", ")", "\n", "\n", "", "unique_augs", "=", "max", "(", "\n", "len", "(", "p", ")", "\n", "for", "p", "in", "[", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "size", ",", "\n", "]", "\n", ")", "\n", "# if args.method != \"simclr_interintra_neg\":", "\n", "#     assert unique_augs == args.num_crops or unique_augs == 1", "\n", "\n", "# assert that either all unique augmentation pipelines have a unique", "\n", "# parameter or that a single parameter is replicated to all pipelines", "\n", "for", "p", "in", "[", "\n", "\"brightness\"", ",", "\n", "\"contrast\"", ",", "\n", "\"saturation\"", ",", "\n", "\"hue\"", ",", "\n", "\"gaussian_prob\"", ",", "\n", "\"solarization_prob\"", ",", "\n", "\"min_scale\"", ",", "\n", "\"size\"", ",", "\n", "]", ":", "\n", "        ", "values", "=", "getattr", "(", "args", ",", "p", ")", "\n", "n", "=", "len", "(", "values", ")", "\n", "assert", "n", "==", "unique_augs", "or", "n", "==", "1", "\n", "\n", "if", "n", "==", "1", ":", "\n", "            ", "setattr", "(", "args", ",", "p", ",", "getattr", "(", "args", ",", "p", ")", "*", "unique_augs", ")", "\n", "\n", "", "", "args", ".", "unique_augs", "=", "unique_augs", "\n", "\n", "if", "unique_augs", ">", "1", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "[", "\n", "dict", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "gaussian_prob", "=", "gaussian_prob", ",", "\n", "solarization_prob", "=", "solarization_prob", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "size", "=", "size", ",", "\n", ")", "\n", "for", "(", "\n", "brightness", ",", "\n", "contrast", ",", "\n", "saturation", ",", "\n", "hue", ",", "\n", "gaussian_prob", ",", "\n", "solarization_prob", ",", "\n", "min_scale", ",", "\n", "size", ",", "\n", ")", "in", "zip", "(", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "size", ",", "\n", ")", "\n", "]", "\n", "\n", "", "elif", "not", "args", ".", "multicrop", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "dict", "(", "\n", "brightness", "=", "args", ".", "brightness", "[", "0", "]", ",", "\n", "contrast", "=", "args", ".", "contrast", "[", "0", "]", ",", "\n", "saturation", "=", "args", ".", "saturation", "[", "0", "]", ",", "\n", "hue", "=", "args", ".", "hue", "[", "0", "]", ",", "\n", "gaussian_prob", "=", "args", ".", "gaussian_prob", "[", "0", "]", ",", "\n", "solarization_prob", "=", "args", ".", "solarization_prob", "[", "0", "]", ",", "\n", "min_scale", "=", "args", ".", "min_scale", "[", "0", "]", ",", "\n", "size", "=", "args", ".", "size", "[", "0", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "dict", "(", "\n", "brightness", "=", "args", ".", "brightness", "[", "0", "]", ",", "\n", "contrast", "=", "args", ".", "contrast", "[", "0", "]", ",", "\n", "saturation", "=", "args", ".", "saturation", "[", "0", "]", ",", "\n", "hue", "=", "args", ".", "hue", "[", "0", "]", ",", "\n", "gaussian_prob", "=", "args", ".", "gaussian_prob", "[", "0", "]", ",", "\n", "solarization_prob", "=", "args", ".", "solarization_prob", "[", "0", "]", ",", "\n", ")", "\n", "\n", "# add support for custom mean and std", "\n", "", "if", "args", ".", "dataset", "==", "\"custom\"", ":", "\n", "        ", "if", "isinstance", "(", "args", ".", "transform_kwargs", ",", "dict", ")", ":", "\n", "            ", "args", ".", "transform_kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "args", ".", "transform_kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "", "else", ":", "\n", "            ", "for", "kwargs", "in", "args", ".", "transform_kwargs", ":", "\n", "                ", "kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "\n", "", "", "", "if", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"stl10\"", "]", ":", "\n", "        ", "if", "isinstance", "(", "args", ".", "transform_kwargs", ",", "dict", ")", ":", "\n", "            ", "del", "args", ".", "transform_kwargs", "[", "\"size\"", "]", "\n", "", "else", ":", "\n", "            ", "for", "kwargs", "in", "args", ".", "transform_kwargs", ":", "\n", "                ", "del", "kwargs", "[", "\"size\"", "]", "\n", "\n", "# create backbone-specific arguments", "\n", "", "", "", "args", ".", "backbone_args", "=", "{", "\"cifar\"", ":", "True", "if", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", "else", "False", "}", "\n", "if", "\"resnet\"", "in", "args", ".", "encoder", ":", "\n", "        ", "args", ".", "backbone_args", "[", "\"zero_init_residual\"", "]", "=", "args", ".", "zero_init_residual", "\n", "", "else", ":", "\n", "# dataset related for all transformers", "\n", "        ", "dataset", "=", "args", ".", "dataset", "\n", "if", "\"cifar\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "32", "\n", "", "elif", "\"stl\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "96", "\n", "", "elif", "\"imagenet\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "224", "\n", "", "elif", "\"custom\"", "in", "dataset", ":", "\n", "            ", "transform_kwargs", "=", "args", ".", "transform_kwargs", "\n", "if", "isinstance", "(", "transform_kwargs", ",", "list", ")", ":", "\n", "                ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "transform_kwargs", "[", "0", "]", "[", "\"size\"", "]", "\n", "", "else", ":", "\n", "                ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "transform_kwargs", "[", "\"size\"", "]", "\n", "\n", "", "", "if", "\"vit\"", "in", "args", ".", "encoder", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"patch_size\"", "]", "=", "args", ".", "patch_size", "\n", "\n", "", "", "del", "args", ".", "zero_init_residual", "\n", "del", "args", ".", "patch_size", "\n", "\n", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", ",", "\"custom\"", "]", "\n", "\n", "", "args", ".", "extra_optimizer_args", "=", "{", "}", "\n", "if", "args", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "\n", "", "if", "isinstance", "(", "args", ".", "gpus", ",", "int", ")", ":", "\n", "        ", "args", ".", "gpus", "=", "[", "args", ".", "gpus", "]", "\n", "", "elif", "isinstance", "(", "args", ".", "gpus", ",", "str", ")", ":", "\n", "        ", "args", ".", "gpus", "=", "[", "int", "(", "gpu", ")", "for", "gpu", "in", "args", ".", "gpus", ".", "split", "(", "\",\"", ")", "if", "gpu", "]", "\n", "\n", "# adjust lr according to batch size", "\n", "", "args", ".", "lr", "=", "args", ".", "lr", "*", "args", ".", "batch_size", "*", "len", "(", "args", ".", "gpus", ")", "/", "256", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.args.utils.additional_setup_linear": [[215, 267], ["isinstance", "isinstance", "int", "args.gpus.split", "isinstance"], "function", ["None"], ["", "def", "additional_setup_linear", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"Provides final setup for linear evaluation to non-user given parameters by changing args.\n\n    Parsers arguments to extract the number of classes of a dataset, correctly parse gpus, identify\n    if a cifar dataset is being used and adjust the lr.\n\n    Args:\n        args: Namespace object that needs to contain, at least:\n        - dataset: dataset name.\n        - optimizer: optimizer name being used.\n        - gpus: list of gpus to use.\n        - lr: learning rate.\n    \"\"\"", "\n", "\n", "assert", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", "\n", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n", "\n", "# create backbone-specific arguments", "\n", "args", ".", "backbone_args", "=", "{", "\"cifar\"", ":", "True", "if", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", "else", "False", "}", "\n", "\n", "if", "\"resnet\"", "not", "in", "args", ".", "encoder", ":", "\n", "# dataset related for all transformers", "\n", "        ", "dataset", "=", "args", ".", "dataset", "\n", "if", "\"cifar\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "32", "\n", "", "elif", "\"stl\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "96", "\n", "", "elif", "\"imagenet\"", "in", "dataset", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "224", "\n", "", "elif", "\"custom\"", "in", "dataset", ":", "\n", "            ", "transform_kwargs", "=", "args", ".", "transform_kwargs", "\n", "if", "isinstance", "(", "transform_kwargs", ",", "list", ")", ":", "\n", "                ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "transform_kwargs", "[", "0", "]", "[", "\"size\"", "]", "\n", "", "else", ":", "\n", "                ", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "transform_kwargs", "[", "\"size\"", "]", "\n", "\n", "", "", "if", "\"vit\"", "in", "args", ".", "encoder", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"patch_size\"", "]", "=", "args", ".", "patch_size", "\n", "\n", "", "", "del", "args", ".", "patch_size", "\n", "\n", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", "\n", "\n", "", "args", ".", "extra_optimizer_args", "=", "{", "}", "\n", "if", "args", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "\n", "", "if", "isinstance", "(", "args", ".", "gpus", ",", "int", ")", ":", "\n", "        ", "args", ".", "gpus", "=", "[", "args", ".", "gpus", "]", "\n", "", "elif", "isinstance", "(", "args", ".", "gpus", ",", "str", ")", ":", "\n", "        ", "args", ".", "gpus", "=", "[", "int", "(", "gpu", ")", "for", "gpu", "in", "args", ".", "gpus", ".", "split", "(", "\",\"", ")", "if", "gpu", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.__init__": [[34, 71], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "dt_m", ":", "float", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Implements MoCo V2+ (https://arxiv.org/abs/2011.10566).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            temperature (float): temperature for the softmax in the contrastive loss.\n            queue_size (int): number of samples to keep in the queue.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dt_m", "=", "dt_m", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# momentum projector", "\n", "self", ".", "momentum_projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "initialize_momentum_params", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.add_model_specific_args": [[73, 87], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "SimCo_DualTemperature", ",", "SimCo_DualTemperature", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"simco_dual_temperature\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--dt_m\"", ",", "type", "=", "float", ",", "default", "=", "10", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.learnable_params": [[88, 98], ["simco_dual_temperature.SimCo_DualTemperature.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters together with parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.momentum_pairs": [[99, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs.\n        \"\"\"", "\n", "\n", "extra_momentum_pairs", "=", "[", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "]", "\n", "return", "super", "(", ")", ".", "momentum_pairs", "+", "extra_momentum_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.forward": [[111, 124], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "simco_dual_temperature.SimCo_DualTemperature.projector"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.forward"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the online encoder and the online projection.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "q", "=", "F", ".", "normalize", "(", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "{", "**", "out", ",", "\"q\"", ":", "q", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simco_dual_temperature.SimCo_DualTemperature.training_step": [[125, 172], ["super().training_step", "simco_dual_temperature.SimCo_DualTemperature.projector", "simco_dual_temperature.SimCo_DualTemperature.projector", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "simco_dual_temperature.SimCo_DualTemperature.log_dict", "solo.losses.dual_temperature_loss.dual_temperature_loss_func", "solo.losses.dual_temperature_loss.dual_temperature_loss_func", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Training step for MoCo reusing BaseMomentumMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the\n                format of [img_indexes, [X], Y], where [X] is a list of size self.num_crops\n                containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of MOCO loss and classification loss.\n\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "feats1", ",", "feats2", "=", "out", "[", "\"feats\"", "]", "\n", "\n", "q1", "=", "self", ".", "projector", "(", "feats1", ")", "\n", "q2", "=", "self", ".", "projector", "(", "feats2", ")", "\n", "\n", "q1", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", "\n", "q2", "=", "F", ".", "normalize", "(", "q2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "\n", "nce_loss", "=", "(", "\n", "dual_temperature_loss_func", "(", "q1", ",", "q2", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "dt_m", "=", "self", ".", "dt_m", ")", "\n", "+", "dual_temperature_loss_func", "(", "q2", ",", "q1", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "dt_m", "=", "self", ".", "dt_m", ")", "\n", ")", "/", "2", "\n", "\n", "# calculate std of features", "\n", "z1_std", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z2_std", "=", "F", ".", "normalize", "(", "q2", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z_std", "=", "(", "z1_std", "+", "z2_std", ")", "/", "2", "\n", "\n", "metrics", "=", "{", "\n", "\"train_nce_loss\"", ":", "nce_loss", ",", "\n", "\"train_z_std\"", ":", "z_std", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.__init__": [[61, 250], ["pytorch_lightning.LightningModule.__init__", "base.BaseMethod.backbone_args.copy", "base.BaseMethod.pop", "base.BaseMethod.base_model", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "solo.utils.knn.WeightedKNNClassifier", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoder", ":", "str", ",", "\n", "num_classes", ":", "int", ",", "\n", "backbone_args", ":", "dict", ",", "\n", "max_epochs", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "\n", "optimizer", ":", "str", ",", "\n", "lars", ":", "bool", ",", "\n", "lr", ":", "float", ",", "\n", "weight_decay", ":", "float", ",", "\n", "classifier_lr", ":", "float", ",", "\n", "exclude_bias_n_norm", ":", "bool", ",", "\n", "accumulate_grad_batches", ":", "int", ",", "\n", "extra_optimizer_args", ":", "Dict", ",", "\n", "scheduler", ":", "str", ",", "\n", "min_lr", ":", "float", ",", "\n", "warmup_start_lr", ":", "float", ",", "\n", "warmup_epochs", ":", "float", ",", "\n", "multicrop", ":", "bool", ",", "\n", "num_crops", ":", "int", ",", "\n", "num_small_crops", ":", "int", ",", "\n", "eta_lars", ":", "float", "=", "1e-3", ",", "\n", "grad_clip_lars", ":", "bool", "=", "False", ",", "\n", "lr_decay_steps", ":", "Sequence", "=", "None", ",", "\n", "disable_knn_eval", ":", "bool", "=", "True", ",", "\n", "knn_k", ":", "int", "=", "20", ",", "\n", "static_lr", ":", "float", "=", "0.1", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Base model that implements all basic operations for all self-supervised methods.\n        It adds shared arguments, extract basic learnable parameters, creates optimizers\n        and schedulers, implements basic training_step for any number of crops,\n        trains the online classifier and implements validation_step.\n\n        Args:\n            encoder (str): architecture of the base encoder.\n            num_classes (int): number of classes.\n            backbone_params (dict): dict containing extra backbone args, namely:\n                #! optional, if it's not present, it is considered as False\n                cifar (bool): flag indicating if cifar is being used.\n                #! only for resnet\n                zero_init_residual (bool): change the initialization of the resnet encoder.\n                #! only for vit\n                patch_size (int): size of the patches for ViT.\n            max_epochs (int): number of training epochs.\n            batch_size (int): number of samples in the batch.\n            optimizer (str): name of the optimizer.\n            lars (bool): flag indicating if lars should be used.\n            lr (float): learning rate.\n            weight_decay (float): weight decay for optimizer.\n            classifier_lr (float): learning rate for the online linear classifier.\n            exclude_bias_n_norm (bool): flag indicating if bias and norms should be excluded from\n                lars.\n            accumulate_grad_batches (int): number of batches for gradient accumulation.\n            extra_optimizer_args (Dict): extra named arguments for the optimizer.\n            scheduler (str): name of the scheduler.\n            min_lr (float): minimum learning rate for warmup scheduler.\n            warmup_start_lr (float): initial learning rate for warmup scheduler.\n            warmup_epochs (float): number of warmup epochs.\n            multicrop (bool): flag indicating if multi-resolution crop is being used.\n            num_crops (int): number of big crops\n            num_small_crops (int): number of small crops (will be set to 0 if multicrop is False).\n            eta_lars (float): eta parameter for lars.\n            grad_clip_lars (bool): whether to clip the gradients in lars.\n            lr_decay_steps (Sequence, optional): steps to decay the learning rate if scheduler is\n                step. Defaults to None.\n            disable_knn_eval (bool): disables online knn evaluation while training.\n            knn_k (int): the number of neighbors to use for knn.\n\n        .. note::\n            When using distributed data parallel, the batch size and the number of workers are\n            specified on a per process basis. Therefore, the total batch size (number of workers)\n            is calculated as the product of the number of GPUs with the batch size (number of\n            workers).\n\n        .. note::\n            The learning rate (base, min and warmup) is automatically scaled linearly based on the\n            batch size and gradient accumulation.\n\n        .. note::\n            For CIFAR10/100, the first convolutional and maxpooling layers of the ResNet encoder\n            are slightly adjusted to handle lower resolution images (32x32 instead of 224x224).\n\n        .. note::\n            If multicrop is activated, the number of small crops must be greater than zero. When\n            multicrop is deactivated (default) the number of small crops is ignored.\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# resnet backbone related", "\n", "self", ".", "backbone_args", "=", "backbone_args", "\n", "\n", "# training related", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "max_epochs", "=", "max_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lars", "=", "lars", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "self", ".", "classifier_lr", "=", "classifier_lr", "\n", "self", ".", "exclude_bias_n_norm", "=", "exclude_bias_n_norm", "\n", "self", ".", "accumulate_grad_batches", "=", "accumulate_grad_batches", "\n", "self", ".", "extra_optimizer_args", "=", "extra_optimizer_args", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "lr_decay_steps", "=", "lr_decay_steps", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "self", ".", "warmup_start_lr", "=", "warmup_start_lr", "\n", "self", ".", "warmup_epochs", "=", "warmup_epochs", "\n", "self", ".", "multicrop", "=", "multicrop", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "self", ".", "num_small_crops", "=", "num_small_crops", "\n", "self", ".", "eta_lars", "=", "eta_lars", "\n", "self", ".", "grad_clip_lars", "=", "grad_clip_lars", "\n", "self", ".", "disable_knn_eval", "=", "disable_knn_eval", "\n", "self", ".", "knn_k", "=", "knn_k", "\n", "self", ".", "static_lr", "=", "lr", "\n", "\n", "# sanity checks on multicrop", "\n", "if", "self", ".", "multicrop", ":", "\n", "            ", "assert", "num_small_crops", ">", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_small_crops", "=", "0", "\n", "\n", "# all the other parameters", "\n", "", "self", ".", "extra_args", "=", "kwargs", "\n", "\n", "# if accumulating gradient then scale lr", "\n", "if", "self", ".", "accumulate_grad_batches", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "classifier_lr", "=", "self", ".", "classifier_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "min_lr", "=", "self", ".", "min_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "warmup_start_lr", "=", "self", ".", "warmup_start_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "\n", "", "assert", "encoder", "in", "BaseMethod", ".", "_SUPPORTED_ENCODERS", "\n", "from", "solo", ".", "utils", ".", "backbones", "import", "(", "\n", "swin_base", ",", "\n", "swin_large", ",", "\n", "swin_small", ",", "\n", "swin_tiny", ",", "\n", "vit_base", ",", "\n", "vit_large", ",", "\n", "vit_small", ",", "\n", "vit_tiny", ",", "\n", ")", "\n", "from", "torchvision", ".", "models", "import", "resnet18", ",", "resnet50", "\n", "\n", "self", ".", "base_model", "=", "{", "\n", "\"resnet18\"", ":", "resnet18", ",", "\n", "\"resnet50\"", ":", "resnet50", ",", "\n", "\"vit_tiny\"", ":", "vit_tiny", ",", "\n", "\"vit_small\"", ":", "vit_small", ",", "\n", "\"vit_base\"", ":", "vit_base", ",", "\n", "\"vit_large\"", ":", "vit_large", ",", "\n", "\"swin_tiny\"", ":", "swin_tiny", ",", "\n", "\"swin_small\"", ":", "swin_small", ",", "\n", "\"swin_base\"", ":", "swin_base", ",", "\n", "\"swin_large\"", ":", "swin_large", ",", "\n", "}", "[", "encoder", "]", "\n", "\n", "self", ".", "encoder_name", "=", "encoder", "\n", "\n", "# initialize encoder", "\n", "kwargs", "=", "self", ".", "backbone_args", ".", "copy", "(", ")", "\n", "cifar", "=", "kwargs", ".", "pop", "(", "\"cifar\"", ",", "False", ")", "\n", "# swin specific", "\n", "if", "\"swin\"", "in", "self", ".", "encoder_name", "and", "cifar", ":", "\n", "            ", "kwargs", "[", "\"window_size\"", "]", "=", "4", "\n", "\n", "", "self", ".", "encoder", "=", "self", ".", "base_model", "(", "**", "kwargs", ")", "\n", "if", "\"resnet\"", "in", "self", ".", "encoder_name", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "encoder", ".", "inplanes", "\n", "# remove fc layer", "\n", "self", ".", "encoder", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "cifar", ":", "\n", "                ", "self", ".", "encoder", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "encoder", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "encoder", ".", "num_features", "\n", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "num_classes", ")", "\n", "\n", "if", "not", "self", ".", "disable_knn_eval", ":", "\n", "            ", "self", ".", "knn", "=", "WeightedKNNClassifier", "(", "k", "=", "self", ".", "knn_k", ",", "distance_fx", "=", "\"euclidean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.add_model_specific_args": [[251, 325], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "\"\"\"Adds shared basic arguments that are shared for all methods.\n\n        Args:\n            parent_parser (ArgumentParser): argument parser that is used to create a\n                argument group.\n\n        Returns:\n            ArgumentParser: same as the argument, used to avoid errors.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"base\"", ")", "\n", "\n", "# encoder args", "\n", "SUPPORTED_ENCODERS", "=", "BaseMethod", ".", "_SUPPORTED_ENCODERS", "\n", "\n", "parser", ".", "add_argument", "(", "\"--encoder\"", ",", "choices", "=", "SUPPORTED_ENCODERS", ",", "type", "=", "str", ")", "\n", "# extra args for resnet", "\n", "parser", ".", "add_argument", "(", "\"--zero_init_residual\"", ",", "action", "=", "\"store_true\"", ")", "\n", "# extra args for ViT", "\n", "parser", ".", "add_argument", "(", "\"--patch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "# general train", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier_lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "\n", "# wandb", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--project\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--entity\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--wandb\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--offline\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# optimizer", "\n", "SUPPORTED_OPTIMIZERS", "=", "[", "\"sgd\"", ",", "\"adam\"", ",", "\"adamw\"", "]", "\n", "\n", "parser", ".", "add_argument", "(", "\"--optimizer\"", ",", "choices", "=", "SUPPORTED_OPTIMIZERS", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--lars\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--grad_clip_lars\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eta_lars\"", ",", "default", "=", "1e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--exclude_bias_n_norm\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# scheduler", "\n", "SUPPORTED_SCHEDULERS", "=", "[", "\n", "\"reduce\"", ",", "\n", "\"cosine\"", ",", "\n", "\"warmup_cosine\"", ",", "\n", "\"step\"", ",", "\n", "\"exponential\"", ",", "\n", "\"none\"", ",", "\n", "]", "\n", "\n", "parser", ".", "add_argument", "(", "\"--scheduler\"", ",", "choices", "=", "SUPPORTED_SCHEDULERS", ",", "type", "=", "str", ",", "default", "=", "\"reduce\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_decay_steps\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_lr\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_start_lr\"", ",", "default", "=", "0.003", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "\n", "# DALI only", "\n", "# uses sample indexes as labels and then gets the labels from a lookup table", "\n", "# this may use more CPU memory, so just use when needed.", "\n", "parser", ".", "add_argument", "(", "\"--encode_indexes_into_labels\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# online knn eval", "\n", "parser", ".", "add_argument", "(", "\"--disable_knn_eval\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--knn_k\"", ",", "default", "=", "20", ",", "type", "=", "int", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--static_lr\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.learnable_params": [[326, 342], ["base.BaseMethod.encoder.parameters", "base.BaseMethod.classifier.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Defines learnable parameters for the base class.\n\n        Returns:\n            List[Dict[str, Any]]:\n                list of dicts containing learnable parameters and possible settings.\n        \"\"\"", "\n", "\n", "return", "[", "\n", "{", "\"name\"", ":", "\"encoder\"", ",", "\"params\"", ":", "self", ".", "encoder", ".", "parameters", "(", ")", "}", ",", "\n", "{", "\n", "\"name\"", ":", "\"classifier\"", ",", "\n", "\"params\"", ":", "self", ".", "classifier", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "classifier_lr", ",", "\n", "\"weight_decay\"", ":", "0", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.configure_optimizers": [[345, 412], ["solo.utils.lars.LARSWrapper.", "solo.utils.lars.LARSWrapper", "enumerate", "m.pop", "pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR", "functools.partial", "ValueError", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "ValueError", "len"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", ",", "List", "]", ":", "\n", "        ", "\"\"\"Collects learnable parameters and configures the optimizer and learning rate scheduler.\n\n        Returns:\n            Tuple[List, List]: two lists containing the optimizer and the scheduler.\n        \"\"\"", "\n", "\n", "# collect learnable parameters", "\n", "idxs_no_scheduler", "=", "[", "\n", "i", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "learnable_params", ")", "if", "m", ".", "pop", "(", "\"static_lr\"", ",", "False", ")", "\n", "]", "\n", "\n", "# select optimizer", "\n", "if", "self", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "\n", "", "elif", "self", ".", "optimizer", "==", "\"adam\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "\n", "", "elif", "self", ".", "optimizer", "==", "\"adamw\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.optimizer} not in (sgd, adam, adamw)\"", ")", "\n", "\n", "# create optimizer", "\n", "", "optimizer", "=", "optimizer", "(", "\n", "self", ".", "learnable_params", ",", "\n", "lr", "=", "self", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", "**", "self", ".", "extra_optimizer_args", ",", "\n", ")", "\n", "# optionally wrap with lars", "\n", "if", "self", ".", "lars", ":", "\n", "            ", "assert", "self", ".", "optimizer", "==", "\"sgd\"", ",", "\"LARS is only compatible with SGD.\"", "\n", "optimizer", "=", "LARSWrapper", "(", "\n", "optimizer", ",", "\n", "eta", "=", "self", ".", "eta_lars", ",", "\n", "clip", "=", "self", ".", "grad_clip_lars", ",", "\n", "exclude_bias_n_norm", "=", "self", ".", "exclude_bias_n_norm", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "scheduler", "==", "\"none\"", ":", "\n", "            ", "return", "optimizer", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "scheduler", "==", "\"warmup_cosine\"", ":", "\n", "                ", "scheduler", "=", "LinearWarmupCosineAnnealingLR", "(", "\n", "optimizer", ",", "\n", "warmup_epochs", "=", "self", ".", "warmup_epochs", ",", "\n", "max_epochs", "=", "self", ".", "max_epochs", ",", "\n", "warmup_start_lr", "=", "self", ".", "warmup_start_lr", ",", "\n", "eta_min", "=", "self", ".", "min_lr", ",", "\n", ")", "\n", "", "elif", "self", ".", "scheduler", "==", "\"cosine\"", ":", "\n", "                ", "scheduler", "=", "CosineAnnealingLR", "(", "optimizer", ",", "self", ".", "max_epochs", ",", "eta_min", "=", "self", ".", "min_lr", ")", "\n", "", "elif", "self", ".", "scheduler", "==", "\"step\"", ":", "\n", "                ", "scheduler", "=", "MultiStepLR", "(", "optimizer", ",", "self", ".", "lr_decay_steps", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{self.scheduler} not in (warmup_cosine, cosine, step)\"", ")", "\n", "\n", "", "if", "idxs_no_scheduler", ":", "\n", "                ", "partial_fn", "=", "partial", "(", "\n", "static_lr", ",", "\n", "get_lr", "=", "scheduler", ".", "get_lr", ",", "\n", "param_group_indexes", "=", "idxs_no_scheduler", ",", "\n", "lrs_to_replace", "=", "[", "self", ".", "static_lr", "]", "*", "len", "(", "idxs_no_scheduler", ")", ",", "\n", ")", "\n", "scheduler", ".", "get_lr", "=", "partial_fn", "\n", "\n", "", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.forward": [[413, 417], ["base.BaseMethod.base_forward"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.base_forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Dummy forward, calls base forward.\"\"\"", "\n", "\n", "return", "self", ".", "base_forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.base_forward": [[418, 431], ["base.BaseMethod.encoder", "base.BaseMethod.classifier", "base.BaseMethod.detach"], "methods", ["None"], ["", "def", "base_forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Basic forward that allows children classes to override forward().\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict: dict of logits and features.\n        \"\"\"", "\n", "\n", "feats", "=", "self", ".", "encoder", "(", "X", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "feats", ".", "detach", "(", ")", ")", "\n", "return", "{", "\"logits\"", ":", "logits", ",", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod._shared_step": [[432, 453], ["base.BaseMethod.base_forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "min", "solo.utils.metrics.accuracy_at_k", "logits.size"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.base_forward", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.accuracy_at_k"], ["", "def", "_shared_step", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Forwards a batch of images X and computes the classification loss, the logits, the\n        features, acc@1 and acc@5.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format\n            targets (torch.Tensor): batch of labels for X\n\n        Returns:\n            Dict: dict containing the classification loss, logits, features, acc@1 and acc@5\n        \"\"\"", "\n", "\n", "out", "=", "self", ".", "base_forward", "(", "X", ")", "\n", "logits", "=", "out", "[", "\"logits\"", "]", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "# handle when the number of classes is smaller than 5", "\n", "top_k_max", "=", "min", "(", "5", ",", "logits", ".", "size", "(", "1", ")", ")", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "logits", ",", "targets", ",", "top_k", "=", "(", "1", ",", "top_k_max", ")", ")", "\n", "\n", "return", "{", "**", "out", ",", "\"loss\"", ":", "loss", ",", "\"acc1\"", ":", "acc1", ",", "\"acc5\"", ":", "acc5", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.training_step": [[454, 530], ["isinstance", "base.BaseMethod.log_dict", "base.BaseMethod.log_dict", "base.BaseMethod._shared_step", "outs[].extend", "sum", "sum", "sum", "base.BaseMethod.knn", "base.BaseMethod._shared_step", "outs[].extend", "sum", "sum", "sum", "base.BaseMethod.knn", "outs[].keys", "outs[].keys", "base.BaseMethod.encoder", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "targets.repeat", "base.BaseMethod.encoder", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "targets.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod._shared_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod._shared_step"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "List", "[", "Any", "]", ",", "batch_idx", ":", "int", ",", "one_branch", "=", "False", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Training step for pytorch lightning. It does all the shared operations, such as\n        forwarding the crops, computing logits and computing statistics.\n\n        Args:\n            batch (List[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images\n            batch_idx (int): index of the batch\n\n        Returns:\n            Dict[str, Any]: dict with the classification loss, features and logits\n        \"\"\"", "\n", "\n", "_", ",", "X", ",", "targets", "=", "batch", "\n", "\n", "X", "=", "[", "X", "]", "if", "isinstance", "(", "X", ",", "torch", ".", "Tensor", ")", "else", "X", "\n", "\n", "if", "not", "one_branch", ":", "\n", "# check that we received the desired number of crops", "\n", "# assert len(X) == self.num_crops + self.num_small_crops", "\n", "\n", "            ", "outs", "=", "[", "self", ".", "_shared_step", "(", "x", ",", "targets", ")", "for", "x", "in", "X", "[", ":", "self", ".", "num_crops", "]", "]", "\n", "outs", "=", "{", "k", ":", "[", "out", "[", "k", "]", "for", "out", "in", "outs", "]", "for", "k", "in", "outs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "if", "self", ".", "multicrop", ":", "\n", "                ", "outs", "[", "\"feats\"", "]", ".", "extend", "(", "[", "self", ".", "encoder", "(", "x", ")", "for", "x", "in", "X", "[", "self", ".", "num_crops", ":", "]", "]", ")", "\n", "\n", "# loss and stats", "\n", "", "outs", "[", "\"loss\"", "]", "=", "sum", "(", "outs", "[", "\"loss\"", "]", ")", "/", "self", ".", "num_crops", "\n", "outs", "[", "\"acc1\"", "]", "=", "sum", "(", "outs", "[", "\"acc1\"", "]", ")", "/", "self", ".", "num_crops", "\n", "outs", "[", "\"acc5\"", "]", "=", "sum", "(", "outs", "[", "\"acc5\"", "]", ")", "/", "self", ".", "num_crops", "\n", "metrics", "=", "{", "\n", "\"ACC/train_class_loss\"", ":", "outs", "[", "\"loss\"", "]", ",", "\n", "\"ACC/train_acc1\"", ":", "outs", "[", "\"acc1\"", "]", ",", "\n", "\"ACC/train_acc5\"", ":", "outs", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "if", "not", "self", ".", "disable_knn_eval", ":", "\n", "                ", "self", ".", "knn", "(", "\n", "train_features", "=", "torch", ".", "cat", "(", "outs", "[", "\"feats\"", "]", "[", ":", "self", ".", "num_crops", "]", ")", ".", "detach", "(", ")", ",", "\n", "train_targets", "=", "targets", ".", "repeat", "(", "self", ".", "num_crops", ")", ",", "\n", ")", "\n", "\n", "", "return", "outs", "\n", "", "else", ":", "\n", "# check that we received the desired number of crops", "\n", "# assert len(X) == self.num_crops + self.num_small_crops-1", "\n", "            ", "self", ".", "num_crops", "=", "1", "\n", "\n", "outs", "=", "[", "self", ".", "_shared_step", "(", "x", ",", "targets", ")", "for", "x", "in", "X", "[", ":", "self", ".", "num_crops", "]", "]", "\n", "outs", "=", "{", "k", ":", "[", "out", "[", "k", "]", "for", "out", "in", "outs", "]", "for", "k", "in", "outs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "if", "self", ".", "multicrop", ":", "\n", "                ", "outs", "[", "\"feats\"", "]", ".", "extend", "(", "[", "self", ".", "encoder", "(", "x", ")", "for", "x", "in", "X", "[", "self", ".", "num_crops", ":", "]", "]", ")", "\n", "\n", "# loss and stats", "\n", "", "outs", "[", "\"loss\"", "]", "=", "sum", "(", "outs", "[", "\"loss\"", "]", ")", "/", "self", ".", "num_crops", "\n", "outs", "[", "\"acc1\"", "]", "=", "sum", "(", "outs", "[", "\"acc1\"", "]", ")", "/", "self", ".", "num_crops", "\n", "outs", "[", "\"acc5\"", "]", "=", "sum", "(", "outs", "[", "\"acc5\"", "]", ")", "/", "self", ".", "num_crops", "\n", "metrics", "=", "{", "\n", "\"ACC/train_class_loss\"", ":", "outs", "[", "\"loss\"", "]", ",", "\n", "\"ACC/train_acc1\"", ":", "outs", "[", "\"acc1\"", "]", ",", "\n", "\"ACC/train_acc5\"", ":", "outs", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "if", "not", "self", ".", "disable_knn_eval", ":", "\n", "                ", "self", ".", "knn", "(", "\n", "train_features", "=", "torch", ".", "cat", "(", "outs", "[", "\"feats\"", "]", "[", ":", "self", ".", "num_crops", "]", ")", ".", "detach", "(", ")", ",", "\n", "train_targets", "=", "targets", ".", "repeat", "(", "self", ".", "num_crops", ")", ",", "\n", ")", "\n", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.validation_step": [[532, 561], ["targets.size", "base.BaseMethod._shared_step", "base.BaseMethod.knn", "base.BaseMethod.pop().detach", "base.BaseMethod.pop"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod._shared_step"], ["", "", "def", "validation_step", "(", "self", ",", "batch", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Validation step for pytorch lightning. It does all the shared operations, such as\n        forwarding a batch of images, computing logits and computing metrics.\n\n        Args:\n            batch (List[torch.Tensor]):a batch of data in the format of [img_indexes, X, Y]\n            batch_idx (int): index of the batch\n\n        Returns:\n            Dict[str, Any]:\n                dict with the batch_size (used for averaging),\n                the classification loss and accuracies\n        \"\"\"", "\n", "\n", "X", ",", "targets", "=", "batch", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "out", "=", "self", ".", "_shared_step", "(", "X", ",", "targets", ")", "\n", "\n", "if", "not", "self", ".", "disable_knn_eval", "and", "not", "self", ".", "trainer", ".", "sanity_checking", ":", "\n", "            ", "self", ".", "knn", "(", "test_features", "=", "out", ".", "pop", "(", "\"feats\"", ")", ".", "detach", "(", ")", ",", "test_targets", "=", "targets", ")", "\n", "\n", "", "metrics", "=", "{", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"val_loss\"", ":", "out", "[", "\"loss\"", "]", ",", "\n", "\"val_acc1\"", ":", "out", "[", "\"acc1\"", "]", ",", "\n", "\"val_acc5\"", ":", "out", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMethod.validation_epoch_end": [[562, 582], ["solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "base.BaseMethod.log_dict", "base.BaseMethod.knn.compute", "log.update"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.knn.WeightedKNNClassifier.compute", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", ":", "\n", "        ", "\"\"\"Averages the losses and accuracies of all the validation batches.\n        This is needed because the last batch can be smaller than the others,\n        slightly skewing the metrics.\n\n        Args:\n            outs (List[Dict[str, Any]]): list of outputs of the validation step.\n        \"\"\"", "\n", "\n", "val_loss", "=", "weighted_mean", "(", "outs", ",", "\"val_loss\"", ",", "\"batch_size\"", ")", "\n", "val_acc1", "=", "weighted_mean", "(", "outs", ",", "\"val_acc1\"", ",", "\"batch_size\"", ")", "\n", "val_acc5", "=", "weighted_mean", "(", "outs", ",", "\"val_acc5\"", ",", "\"batch_size\"", ")", "\n", "\n", "log", "=", "{", "\"ACC/val_loss\"", ":", "val_loss", ",", "\"ACC/val_acc1\"", ":", "val_acc1", ",", "\"ACC/val_acc5\"", ":", "val_acc5", "}", "\n", "\n", "if", "not", "self", ".", "disable_knn_eval", "and", "not", "self", ".", "trainer", ".", "sanity_checking", ":", "\n", "            ", "val_knn_acc1", ",", "val_knn_acc5", "=", "self", ".", "knn", ".", "compute", "(", ")", "\n", "log", ".", "update", "(", "{", "\"ACC/val_knn_acc1\"", ":", "val_knn_acc1", ",", "\"ACC/val_knn_acc5\"", ":", "val_knn_acc5", "}", ")", "\n", "\n", "", "self", ".", "log_dict", "(", "log", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.__init__": [[585, 641], ["base.BaseMethod.__init__", "base.BaseMomentumMethod.backbone_args.copy", "base.BaseMomentumMethod.pop", "base.BaseMomentumMethod.base_model", "solo.utils.momentum.initialize_momentum_params", "solo.utils.momentum.MomentumUpdater", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "base_tau_momentum", ":", "float", ",", "\n", "final_tau_momentum", ":", "float", ",", "\n", "momentum_classifier", ":", "bool", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Base momentum model that implements all basic operations for all self-supervised methods\n        that use a momentum encoder. It adds shared momentum arguments, adds basic learnable\n        parameters, implements basic training and validation steps for the momentum encoder and\n        classifier. Also implements momentum update using exponential moving average and cosine\n        annealing of the weighting decrease coefficient.\n\n        Args:\n            base_tau_momentum (float): base value of the weighting decrease coefficient (should be\n                in [0,1]).\n            final_tau_momentum (float): final value of the weighting decrease coefficient (should be\n                in [0,1]).\n            momentum_classifier (bool): whether or not to train a classifier on top of the momentum\n                encoder.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "# momentum encoder", "\n", "kwargs", "=", "self", ".", "backbone_args", ".", "copy", "(", ")", "\n", "cifar", "=", "kwargs", ".", "pop", "(", "\"cifar\"", ",", "False", ")", "\n", "# swin specific", "\n", "if", "\"swin\"", "in", "self", ".", "encoder_name", "and", "cifar", ":", "\n", "            ", "kwargs", "[", "\"window_size\"", "]", "=", "4", "\n", "\n", "", "self", ".", "momentum_encoder", "=", "self", ".", "base_model", "(", "**", "kwargs", ")", "\n", "if", "\"resnet\"", "in", "self", ".", "encoder_name", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "momentum_encoder", ".", "inplanes", "\n", "# remove fc layer", "\n", "self", ".", "momentum_encoder", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "cifar", ":", "\n", "                ", "self", ".", "momentum_encoder", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "momentum_encoder", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "momentum_encoder", ".", "num_features", "\n", "\n", "", "initialize_momentum_params", "(", "self", ".", "encoder", ",", "self", ".", "momentum_encoder", ")", "\n", "\n", "# momentum classifier", "\n", "if", "momentum_classifier", ":", "\n", "            ", "self", ".", "momentum_classifier", ":", "Any", "=", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "self", ".", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "momentum_classifier", "=", "None", "\n", "\n", "# momentum updater", "\n", "", "self", ".", "momentum_updater", "=", "MomentumUpdater", "(", "base_tau_momentum", ",", "final_tau_momentum", ")", "\n", "\n", "self", ".", "simclr", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.learnable_params": [[643, 663], ["momentum_learnable_parameters.append", "base.BaseMomentumMethod.momentum_classifier.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds momentum classifier parameters to the parameters of the base class.\n\n        Returns:\n            List[Dict[str, Any]]:\n                list of dicts containing learnable parameters and possible settings.\n        \"\"\"", "\n", "\n", "momentum_learnable_parameters", "=", "[", "]", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "momentum_learnable_parameters", ".", "append", "(", "\n", "{", "\n", "\"name\"", ":", "\"momentum_classifier\"", ",", "\n", "\"params\"", ":", "self", ".", "momentum_classifier", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "classifier_lr", ",", "\n", "\"weight_decay\"", ":", "0", ",", "\n", "}", "\n", ")", "\n", "", "return", "super", "(", ")", ".", "learnable_params", "+", "momentum_learnable_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.momentum_pairs": [[664, 673], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Defines base momentum pairs that will be updated using exponential moving average.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs (two element tuples).\n        \"\"\"", "\n", "\n", "return", "[", "(", "self", ".", "encoder", ",", "self", ".", "momentum_encoder", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.add_model_specific_args": [[674, 697], ["base.BaseMethod.add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "\"\"\"Adds basic momentum arguments that are shared for all methods.\n\n        Args:\n            parent_parser (ArgumentParser): argument parser that is used to create a\n                argument group.\n\n        Returns:\n            ArgumentParser: same as the argument, used to avoid errors.\n        \"\"\"", "\n", "\n", "parent_parser", "=", "super", "(", "BaseMomentumMethod", ",", "BaseMomentumMethod", ")", ".", "add_model_specific_args", "(", "\n", "parent_parser", "\n", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"base\"", ")", "\n", "\n", "# momentum settings", "\n", "parser", ".", "add_argument", "(", "\"--base_tau_momentum\"", ",", "default", "=", "0.99", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_tau_momentum\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--momentum_classifier\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.on_train_start": [[698, 701], ["None"], "methods", ["None"], ["", "def", "on_train_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the step counter at the beginning of training.\"\"\"", "\n", "self", ".", "last_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.base_momentum_forward": [[702, 713], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "base.BaseMomentumMethod.momentum_encoder"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "base_momentum_forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Momentum forward that allows children classes to override how the momentum encoder is used.\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n        Returns:\n            Dict: dict of logits and features.\n        \"\"\"", "\n", "\n", "feats", "=", "self", ".", "momentum_encoder", "(", "X", ")", "\n", "return", "{", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod._shared_step_momentum": [[714, 739], ["base.BaseMomentumMethod.base_momentum_forward", "base.BaseMomentumMethod.momentum_classifier", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "solo.utils.metrics.accuracy_at_k", "base.BaseMomentumMethod.update"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.base_momentum_forward", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.accuracy_at_k", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update"], ["", "def", "_shared_step_momentum", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Forwards a batch of images X in the momentum encoder and optionally computes the\n        classification loss, the logits, the features, acc@1 and acc@5 for of momentum classifier.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n            targets (torch.Tensor): batch of labels for X.\n\n        Returns:\n            Dict[str, Any]:\n                a dict containing the classification loss, logits, features, acc@1 and\n                acc@5 of the momentum encoder / classifier.\n        \"\"\"", "\n", "\n", "out", "=", "self", ".", "base_momentum_forward", "(", "X", ")", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "feats", "=", "out", "[", "\"feats\"", "]", "\n", "logits", "=", "self", ".", "momentum_classifier", "(", "feats", ")", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "logits", ",", "targets", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "out", ".", "update", "(", "{", "\"logits\"", ":", "logits", ",", "\"loss\"", ":", "loss", ",", "\"acc1\"", ":", "acc1", ",", "\"acc5\"", ":", "acc5", "}", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.training_step": [[740, 785], ["base.BaseMethod.training_step", "isinstance", "base.BaseMomentumMethod._shared_step_momentum", "base.BaseMomentumMethod.log_dict", "momentum_outs[].keys", "sum", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod._shared_step_momentum"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "List", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Training step for pytorch lightning. It performs all the shared operations for the\n        momentum encoder and classifier, such as forwarding the crops in the momentum encoder\n        and classifier, and computing statistics.\n\n        Args:\n            batch (List[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            Dict[str, Any]: a dict with the features of the momentum encoder and the classification\n                loss and logits of the momentum classifier.\n        \"\"\"", "\n", "\n", "outs", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "_", ",", "X", ",", "targets", "=", "batch", "\n", "X", "=", "[", "X", "]", "if", "isinstance", "(", "X", ",", "torch", ".", "Tensor", ")", "else", "X", "\n", "\n", "# remove small crops", "\n", "X", "=", "X", "[", ":", "self", ".", "num_crops", "]", "\n", "\n", "momentum_outs", "=", "[", "self", ".", "_shared_step_momentum", "(", "x", ",", "targets", ")", "for", "x", "in", "X", "]", "\n", "momentum_outs", "=", "{", "\n", "\"momentum_\"", "+", "k", ":", "[", "out", "[", "k", "]", "for", "out", "in", "momentum_outs", "]", "for", "k", "in", "momentum_outs", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "# momentum loss and stats", "\n", "            ", "momentum_outs", "[", "\"momentum_loss\"", "]", "=", "sum", "(", "momentum_outs", "[", "\"momentum_loss\"", "]", ")", "/", "self", ".", "num_crops", "\n", "momentum_outs", "[", "\"momentum_acc1\"", "]", "=", "sum", "(", "momentum_outs", "[", "\"momentum_acc1\"", "]", ")", "/", "self", ".", "num_crops", "\n", "momentum_outs", "[", "\"momentum_acc5\"", "]", "=", "sum", "(", "momentum_outs", "[", "\"momentum_acc5\"", "]", ")", "/", "self", ".", "num_crops", "\n", "\n", "metrics", "=", "{", "\n", "\"ACC/train_momentum_class_loss\"", ":", "momentum_outs", "[", "\"momentum_loss\"", "]", ",", "\n", "\"ACC/train_momentum_acc1\"", ":", "momentum_outs", "[", "\"momentum_acc1\"", "]", ",", "\n", "\"ACC/train_momentum_acc5\"", ":", "momentum_outs", "[", "\"momentum_acc5\"", "]", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "# adds the momentum classifier loss together with the general loss", "\n", "outs", "[", "\"loss\"", "]", "+=", "momentum_outs", "[", "\"momentum_loss\"", "]", "\n", "\n", "", "return", "{", "**", "outs", ",", "**", "momentum_outs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.on_train_batch_end": [[786, 817], ["base.BaseMomentumMethod.log", "base.BaseMomentumMethod.momentum_updater.update_tau", "base.BaseMomentumMethod.momentum_updater.update", "len"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update_tau", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.MomentumUpdater.update"], ["", "def", "on_train_batch_end", "(", "\n", "self", ",", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ",", "dataloader_idx", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"Performs the momentum update of momentum pairs using exponential moving average at the\n        end of the current training step if an optimizer step was performed.\n\n        Args:\n            outputs (Dict[str, Any]): the outputs of the training step.\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n            dataloader_idx (int): index of the dataloader.\n        \"\"\"", "\n", "if", "self", ".", "simclr", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "trainer", ".", "global_step", ">", "self", ".", "last_step", ":", "\n", "# update momentum encoder and projector", "\n", "            ", "momentum_pairs", "=", "self", ".", "momentum_pairs", "\n", "for", "mp", "in", "momentum_pairs", ":", "\n", "                ", "self", ".", "momentum_updater", ".", "update", "(", "*", "mp", ")", "\n", "# log tau momentum", "\n", "", "self", ".", "log", "(", "\"tau\"", ",", "self", ".", "momentum_updater", ".", "cur_tau", ")", "\n", "# update tau", "\n", "cur_step", "=", "self", ".", "trainer", ".", "global_step", "\n", "if", "self", ".", "trainer", ".", "accumulate_grad_batches", ":", "\n", "                ", "cur_step", "=", "cur_step", "*", "self", ".", "trainer", ".", "accumulate_grad_batches", "\n", "", "self", ".", "momentum_updater", ".", "update_tau", "(", "\n", "cur_step", "=", "cur_step", ",", "\n", "max_steps", "=", "len", "(", "self", ".", "trainer", ".", "train_dataloader", ")", "*", "self", ".", "trainer", ".", "max_epochs", ",", "\n", ")", "\n", "", "self", ".", "last_step", "=", "self", ".", "trainer", ".", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.validation_step": [[818, 852], ["base.BaseMethod.validation_step", "targets.size", "base.BaseMomentumMethod._shared_step_momentum"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.validation_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod._shared_step_momentum"], ["", "def", "validation_step", "(", "\n", "self", ",", "batch", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", "\n", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Validation step for pytorch lightning. It performs all the shared operations for the\n        momentum encoder and classifier, such as forwarding a batch of images in the momentum\n        encoder and classifier and computing statistics.\n\n        Args:\n            batch (List[torch.Tensor]): a batch of data in the format of [X, Y].\n            batch_idx (int): index of the batch.\n\n        Returns:\n            Tuple(Dict[str, Any], Dict[str, Any]): tuple of dicts containing the batch_size (used\n                for averaging), the classification loss and accuracies for both the online and the\n                momentum classifiers.\n        \"\"\"", "\n", "\n", "parent_metrics", "=", "super", "(", ")", ".", "validation_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "X", ",", "targets", "=", "batch", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "out", "=", "self", ".", "_shared_step_momentum", "(", "X", ",", "targets", ")", "\n", "\n", "metrics", "=", "None", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "metrics", "=", "{", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"momentum_val_loss\"", ":", "out", "[", "\"loss\"", "]", ",", "\n", "\"momentum_val_acc1\"", ":", "out", "[", "\"acc1\"", "]", ",", "\n", "\"momentum_val_acc5\"", ":", "out", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "\n", "", "return", "parent_metrics", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.validation_epoch_end": [[853, 879], ["base.BaseMethod.validation_epoch_end", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "base.BaseMomentumMethod.log_dict"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.BaseMomentumMethod.validation_epoch_end", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.metrics.weighted_mean"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ":", "Tuple", "[", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"Averages the losses and accuracies of the momentum encoder / classifier for all the\n        validation batches. This is needed because the last batch can be smaller than the others,\n        slightly skewing the metrics.\n\n        Args:\n            outs (Tuple[List[Dict[str, Any]]]):): list of outputs of the validation step for self\n                and the parent.\n        \"\"\"", "\n", "\n", "parent_outs", "=", "[", "out", "[", "0", "]", "for", "out", "in", "outs", "]", "\n", "super", "(", ")", ".", "validation_epoch_end", "(", "parent_outs", ")", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "momentum_outs", "=", "[", "out", "[", "1", "]", "for", "out", "in", "outs", "]", "\n", "\n", "val_loss", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_loss\"", ",", "\"batch_size\"", ")", "\n", "val_acc1", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_acc1\"", ",", "\"batch_size\"", ")", "\n", "val_acc5", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_acc5\"", ",", "\"batch_size\"", ")", "\n", "\n", "log", "=", "{", "\n", "\"ACC/momentum_val_loss\"", ":", "val_loss", ",", "\n", "\"ACC/momentum_val_acc1\"", ":", "val_acc1", ",", "\n", "\"ACC/momentum_val_acc5\"", ":", "val_acc5", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "log", ",", "sync_dist", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.base.static_lr": [[36, 43], ["get_lr", "zip"], "function", ["None"], ["def", "static_lr", "(", "\n", "get_lr", ":", "Callable", ",", "param_group_indexes", ":", "Sequence", "[", "int", "]", ",", "lrs_to_replace", ":", "Sequence", "[", "float", "]", "\n", ")", ":", "\n", "    ", "lrs", "=", "get_lr", "(", ")", "\n", "for", "idx", ",", "lr", "in", "zip", "(", "param_group_indexes", ",", "lrs_to_replace", ")", ":", "\n", "        ", "lrs", "[", "idx", "]", "=", "lr", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.__init__": [[35, 76], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "mocov2plus.MoCoV2Plus.register_buffer", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "mocov2plus.MoCoV2Plus.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "queue_size", ":", "int", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Implements MoCo V2+ (https://arxiv.org/abs/2011.10566).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            temperature (float): temperature for the softmax in the contrastive loss.\n            queue_size (int): number of samples to keep in the queue.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "queue_size", "=", "queue_size", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# momentum projector", "\n", "self", ".", "momentum_projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "initialize_momentum_params", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "\n", "\n", "# create the queue", "\n", "self", ".", "register_buffer", "(", "\"queue\"", ",", "torch", ".", "randn", "(", "2", ",", "proj_output_dim", ",", "queue_size", ")", ")", "\n", "self", ".", "queue", "=", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "queue", ",", "dim", "=", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_ptr\"", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.add_model_specific_args": [[77, 93], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "MoCoV2Plus", ",", "MoCoV2Plus", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"mocov2plus\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "# queue settings", "\n", "parser", ".", "add_argument", "(", "\"--queue_size\"", ",", "default", "=", "65536", ",", "type", "=", "int", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.learnable_params": [[94, 104], ["mocov2plus.MoCoV2Plus.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters together with parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.momentum_pairs": [[105, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs.\n        \"\"\"", "\n", "\n", "extra_momentum_pairs", "=", "[", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "]", "\n", "return", "super", "(", ")", ".", "momentum_pairs", "+", "extra_momentum_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus._dequeue_and_enqueue": [[116, 133], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "int", "keys.permute.permute.permute"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_dequeue_and_enqueue", "(", "self", ",", "keys", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Adds new samples and removes old samples from the queue in a fifo manner.\n\n        Args:\n            keys (torch.Tensor): output features of the momentum encoder.\n        \"\"\"", "\n", "\n", "batch_size", "=", "keys", ".", "shape", "[", "1", "]", "\n", "ptr", "=", "int", "(", "self", ".", "queue_ptr", ")", "# type: ignore", "\n", "assert", "self", ".", "queue_size", "%", "batch_size", "==", "0", "# for simplicity", "\n", "\n", "# replace the keys at ptr (dequeue and enqueue)", "\n", "keys", "=", "keys", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "self", ".", "queue", "[", ":", ",", ":", ",", "ptr", ":", "ptr", "+", "batch_size", "]", "=", "keys", "\n", "ptr", "=", "(", "ptr", "+", "batch_size", ")", "%", "self", ".", "queue_size", "# move pointer", "\n", "self", ".", "queue_ptr", "[", "0", "]", "=", "ptr", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.forward": [[134, 147], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2plus.MoCoV2Plus.projector"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.forward"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the online encoder and the online projection.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "q", "=", "F", ".", "normalize", "(", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "{", "**", "out", ",", "\"q\"", ":", "q", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2plus.MoCoV2Plus.training_step": [[148, 194], ["super().training_step", "mocov2plus.MoCoV2Plus.projector", "mocov2plus.MoCoV2Plus.projector", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2plus.MoCoV2Plus.queue.clone().detach", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "mocov2plus.MoCoV2Plus._dequeue_and_enqueue", "mocov2plus.MoCoV2Plus.log", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mocov2plus.MoCoV2Plus.momentum_projector", "mocov2plus.MoCoV2Plus.momentum_projector", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2plus.MoCoV2Plus.queue.clone", "solo.losses.moco.moco_loss_func", "solo.losses.moco.moco_loss_func", "solo.utils.misc.gather", "solo.utils.misc.gather"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2._dequeue_and_enqueue", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.moco.moco_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.moco.moco_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Training step for MoCo reusing BaseMomentumMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the\n                format of [img_indexes, [X], Y], where [X] is a list of size self.num_crops\n                containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of MOCO loss and classification loss.\n\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "feats1", ",", "feats2", "=", "out", "[", "\"feats\"", "]", "\n", "momentum_feats1", ",", "momentum_feats2", "=", "out", "[", "\"momentum_feats\"", "]", "\n", "\n", "q1", "=", "self", ".", "projector", "(", "feats1", ")", "\n", "q2", "=", "self", ".", "projector", "(", "feats2", ")", "\n", "q1", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", "\n", "q2", "=", "F", ".", "normalize", "(", "q2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k1", "=", "self", ".", "momentum_projector", "(", "momentum_feats1", ")", "\n", "k2", "=", "self", ".", "momentum_projector", "(", "momentum_feats2", ")", "\n", "k1", "=", "F", ".", "normalize", "(", "k1", ",", "dim", "=", "-", "1", ")", "\n", "k2", "=", "F", ".", "normalize", "(", "k2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# ------- contrastive loss -------", "\n", "# symmetric", "\n", "", "queue", "=", "self", ".", "queue", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "nce_loss", "=", "(", "\n", "moco_loss_func", "(", "q1", ",", "k2", ",", "queue", "[", "1", "]", ",", "self", ".", "temperature", ")", "\n", "+", "moco_loss_func", "(", "q2", ",", "k1", ",", "queue", "[", "0", "]", ",", "self", ".", "temperature", ")", "\n", ")", "/", "2", "\n", "\n", "# ------- update queue -------", "\n", "keys", "=", "torch", ".", "stack", "(", "(", "gather", "(", "k1", ")", ",", "gather", "(", "k2", ")", ")", ")", "\n", "self", ".", "_dequeue_and_enqueue", "(", "keys", ")", "\n", "\n", "self", ".", "log", "(", "\"train_nce_loss\"", ",", "nce_loss", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.BaseWrapper.__len__": [[41, 57], ["math.ceil", "math.ceil"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "size", "=", "(", "\n", "self", ".", "_size_no_pad", "//", "self", ".", "_shards_num", "\n", "if", "self", ".", "_last_batch_policy", "==", "LastBatchPolicy", ".", "DROP", "\n", "else", "self", ".", "size", "\n", ")", "\n", "if", "self", ".", "_reader_name", ":", "\n", "            ", "if", "self", ".", "_last_batch_policy", "!=", "LastBatchPolicy", ".", "DROP", ":", "\n", "                ", "return", "math", ".", "ceil", "(", "size", "/", "self", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "                ", "return", "size", "//", "self", ".", "batch_size", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "_last_batch_policy", "!=", "LastBatchPolicy", ".", "DROP", ":", "\n", "                ", "return", "math", ".", "ceil", "(", "size", "/", "(", "self", ".", "_num_gpus", "*", "self", ".", "batch_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "return", "size", "//", "(", "self", ".", "_num_gpus", "*", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.PretrainWrapper.__init__": [[60, 90], ["nvidia.dali.plugin.pytorch.DALIGenericIterator.__init__", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_batch_size", ":", "int", ",", "\n", "model_rank", ":", "int", ",", "\n", "model_device", ":", "str", ",", "\n", "conversion_map", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Adds indices to a batch fetched from the parent.\n\n        Args:\n            model_batch_size (int): batch size.\n            model_rank (int): rank of the current process.\n            model_device (str): id of the current device.\n            conversion_map  (List[int], optional): list of integeres that map each index\n                to a class label. If nothing is passed, no label mapping needs to be done.\n                Defaults to None.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "model_batch_size", "=", "model_batch_size", "\n", "self", ".", "model_rank", "=", "model_rank", "\n", "self", ".", "model_device", "=", "model_device", "\n", "self", ".", "conversion_map", "=", "conversion_map", "\n", "if", "self", ".", "conversion_map", "is", "not", "None", ":", "\n", "            ", "self", ".", "conversion_map", "=", "torch", ".", "tensor", "(", "\n", "self", ".", "conversion_map", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "model_device", "\n", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "self", ".", "conversion_map", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "self", ".", "conversion_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.PretrainWrapper.__next__": [[91, 117], ["super().__next__", "dali.PretrainWrapper.conversion_map().flatten().long().detach().clone", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long().detach().clone", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long().detach().clone", "x.detach().clone", "dali.PretrainWrapper.conversion_map().flatten().long().detach", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long().detach", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long().detach", "x.detach", "dali.PretrainWrapper.conversion_map().flatten().long", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dali.PretrainWrapper.conversion_map().flatten", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze", "dali.PretrainWrapper.conversion_map"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.Wrapper.__next__"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "super", "(", ")", ".", "__next__", "(", ")", "[", "0", "]", "\n", "# PyTorch Lightning does double buffering", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/issues/1316,", "\n", "# and as DALI owns the tensors it returns the content of it is trashed so the copy needs,", "\n", "# to be made before returning.", "\n", "\n", "if", "self", ".", "conversion_map", "is", "not", "None", ":", "\n", "            ", "*", "all_X", ",", "indexes", "=", "[", "batch", "[", "v", "]", "for", "v", "in", "self", ".", "output_map", "]", "\n", "targets", "=", "self", ".", "conversion_map", "(", "indexes", ")", ".", "flatten", "(", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "indexes", "=", "indexes", ".", "flatten", "(", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "*", "all_X", ",", "targets", "=", "[", "batch", "[", "v", "]", "for", "v", "in", "self", ".", "output_map", "]", "\n", "targets", "=", "targets", ".", "squeeze", "(", "-", "1", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "# creates dummy indexes", "\n", "indexes", "=", "(", "\n", "(", "\n", "torch", ".", "arange", "(", "self", ".", "model_batch_size", ",", "device", "=", "self", ".", "model_device", ")", "\n", "+", "(", "self", ".", "model_rank", "*", "self", ".", "model_batch_size", ")", "\n", ")", "\n", ".", "detach", "(", ")", "\n", ".", "clone", "(", ")", "\n", ")", "\n", "\n", "", "all_X", "=", "[", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", "for", "x", "in", "all_X", "]", "\n", "return", "[", "indexes", ",", "all_X", ",", "targets", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.Wrapper.__next__": [[120, 131], ["super().__next__", "target.detach().clone.detach().clone.squeeze().long", "x.detach().clone.detach().clone.detach().clone", "target.detach().clone.detach().clone.detach().clone", "target.detach().clone.detach().clone.squeeze", "x.detach().clone.detach().clone.detach", "target.detach().clone.detach().clone.detach"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.Wrapper.__next__"], ["    ", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "super", "(", ")", ".", "__next__", "(", ")", "\n", "x", ",", "target", "=", "batch", "[", "0", "]", "[", "\"x\"", "]", ",", "batch", "[", "0", "]", "[", "\"label\"", "]", "\n", "target", "=", "target", ".", "squeeze", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "# PyTorch Lightning does double buffering", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/issues/1316,", "\n", "# and as DALI owns the tensors it returns the content of it is trashed so the copy needs,", "\n", "# to be made before returning.", "\n", "x", "=", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "target", "=", "target", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "return", "x", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.PretrainABC.train_dataloader": [[136, 254], ["pathlib.Path", "pathlib.Path", "dali.PretrainWrapper", "solo.utils.dali_dataloader.PretrainPipeline.epoch_size", "zip", "solo.utils.dali_dataloader.MulticropPretrainPipeline", "solo.utils.dali_dataloader.PretrainPipeline", "ValueError", "transform_pipeline", "transforms.append", "transform_pipeline", "transform_pipeline", "range", "range", "range"], "methods", ["None"], ["def", "train_dataloader", "(", "self", ")", "->", "DALIGenericIterator", ":", "\n", "        ", "\"\"\"Returns a train dataloader using dali. Supports multi-crop and asymmetric augmentations.\n\n        Returns:\n            DALIGenericIterator: a train dataloader in the form of a dali pipeline object wrapped\n                with PretrainWrapper.\n        \"\"\"", "\n", "\n", "device_id", "=", "self", ".", "local_rank", "\n", "shard_id", "=", "self", ".", "global_rank", "\n", "num_shards", "=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "# get data arguments from model", "\n", "dali_device", "=", "self", ".", "extra_args", "[", "\"dali_device\"", "]", "\n", "\n", "# data augmentations", "\n", "unique_augs", "=", "self", ".", "extra_args", "[", "\"unique_augs\"", "]", "\n", "transform_kwargs", "=", "self", ".", "extra_args", "[", "\"transform_kwargs\"", "]", "\n", "\n", "num_workers", "=", "self", ".", "extra_args", "[", "\"num_workers\"", "]", "\n", "data_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"data_dir\"", "]", ")", "\n", "train_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"train_dir\"", "]", ")", "\n", "\n", "# hack to encode image indexes into the labels", "\n", "self", ".", "encode_indexes_into_labels", "=", "self", ".", "extra_args", "[", "\"encode_indexes_into_labels\"", "]", "\n", "\n", "# handle custom data by creating the needed pipeline", "\n", "dataset", "=", "self", ".", "extra_args", "[", "\"dataset\"", "]", "\n", "if", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", ":", "\n", "            ", "transform_pipeline", "=", "ImagenetTransform", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "            ", "transform_pipeline", "=", "CustomTransform", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset", ",", "\"is not supported, used [imagenet, imagenet100 or custom]\"", ")", "\n", "\n", "", "if", "self", ".", "multicrop", ":", "\n", "            ", "num_crops", "=", "[", "self", ".", "num_crops", ",", "self", ".", "num_small_crops", "]", "\n", "size_crops", "=", "[", "224", ",", "96", "]", "\n", "min_scales", "=", "[", "0.14", ",", "0.05", "]", "\n", "max_scale_crops", "=", "[", "1.0", ",", "0.14", "]", "\n", "\n", "transforms", "=", "[", "]", "\n", "for", "size", ",", "min_scale", ",", "max_scale", "in", "zip", "(", "size_crops", ",", "min_scales", ",", "max_scale_crops", ")", ":", "\n", "                ", "transform", "=", "transform_pipeline", "(", "\n", "device", "=", "dali_device", ",", "\n", "**", "transform_kwargs", ",", "\n", "size", "=", "size", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", ")", "\n", "transforms", ".", "append", "(", "transform", ")", "\n", "", "train_pipeline", "=", "MulticropPretrainPipeline", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "transforms", "=", "transforms", ",", "\n", "num_crops", "=", "num_crops", ",", "\n", "device", "=", "dali_device", ",", "\n", "device_id", "=", "device_id", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "num_threads", "=", "num_workers", ",", "\n", "no_labels", "=", "self", ".", "extra_args", "[", "\"no_labels\"", "]", ",", "\n", "encode_indexes_into_labels", "=", "self", ".", "encode_indexes_into_labels", ",", "\n", ")", "\n", "output_map", "=", "[", "\n", "*", "[", "f\"large{i}\"", "for", "i", "in", "range", "(", "num_crops", "[", "0", "]", ")", "]", ",", "\n", "*", "[", "f\"small{i}\"", "for", "i", "in", "range", "(", "num_crops", "[", "1", "]", ")", "]", ",", "\n", "\"label\"", ",", "\n", "]", "\n", "\n", "", "else", ":", "\n", "            ", "if", "unique_augs", ">", "1", ":", "\n", "                ", "transform", "=", "[", "\n", "transform_pipeline", "(", "\n", "device", "=", "dali_device", ",", "\n", "**", "kwargs", ",", "\n", "max_scale", "=", "1.0", ",", "\n", ")", "\n", "for", "kwargs", "in", "transform_kwargs", "\n", "]", "\n", "", "else", ":", "\n", "                ", "transform", "=", "transform_pipeline", "(", "\n", "device", "=", "dali_device", ",", "\n", "**", "transform_kwargs", ",", "\n", "max_scale", "=", "1.0", ",", "\n", ")", "\n", "\n", "", "train_pipeline", "=", "PretrainPipeline", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "transform", "=", "transform", ",", "\n", "device", "=", "dali_device", ",", "\n", "device_id", "=", "device_id", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "num_threads", "=", "num_workers", ",", "\n", "no_labels", "=", "self", ".", "extra_args", "[", "\"no_labels\"", "]", ",", "\n", "encode_indexes_into_labels", "=", "self", ".", "encode_indexes_into_labels", ",", "\n", ")", "\n", "output_map", "=", "[", "f\"large{i}\"", "for", "i", "in", "range", "(", "self", ".", "num_crops", ")", "]", "+", "[", "\"label\"", "]", "\n", "\n", "", "policy", "=", "LastBatchPolicy", ".", "DROP", "\n", "conversion_map", "=", "train_pipeline", ".", "conversion_map", "if", "self", ".", "encode_indexes_into_labels", "else", "None", "\n", "train_loader", "=", "PretrainWrapper", "(", "\n", "model_batch_size", "=", "self", ".", "batch_size", ",", "\n", "model_rank", "=", "device_id", ",", "\n", "model_device", "=", "self", ".", "device", ",", "\n", "conversion_map", "=", "conversion_map", ",", "\n", "pipelines", "=", "train_pipeline", ",", "\n", "output_map", "=", "output_map", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "policy", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "dali_epoch_size", "=", "train_pipeline", ".", "epoch_size", "(", "\"Reader\"", ")", "\n", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.ClassificationABC.train_dataloader": [[260, 297], ["pathlib.Path", "pathlib.Path", "pipeline_class", "dali.Wrapper", "ValueError"], "methods", ["None"], ["def", "train_dataloader", "(", "self", ")", "->", "DALIGenericIterator", ":", "\n", "        ", "device_id", "=", "self", ".", "local_rank", "\n", "shard_id", "=", "self", ".", "global_rank", "\n", "num_shards", "=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "num_workers", "=", "self", ".", "extra_args", "[", "\"num_workers\"", "]", "\n", "dali_device", "=", "self", ".", "extra_args", "[", "\"dali_device\"", "]", "\n", "data_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"data_dir\"", "]", ")", "\n", "train_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"train_dir\"", "]", ")", "\n", "\n", "# handle custom data by creating the needed pipeline", "\n", "dataset", "=", "self", ".", "extra_args", "[", "\"dataset\"", "]", "\n", "if", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", ":", "\n", "            ", "pipeline_class", "=", "NormalPipeline", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "            ", "pipeline_class", "=", "CustomNormalPipeline", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset", ",", "\"is not supported, used [imagenet, imagenet100 or custom]\"", ")", "\n", "\n", "", "train_pipeline", "=", "pipeline_class", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "validation", "=", "False", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "device", "=", "dali_device", ",", "\n", "device_id", "=", "device_id", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "num_threads", "=", "num_workers", ",", "\n", ")", "\n", "train_loader", "=", "Wrapper", "(", "\n", "train_pipeline", ",", "\n", "output_map", "=", "[", "\"x\"", ",", "\"label\"", "]", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "LastBatchPolicy", ".", "DROP", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.dali.ClassificationABC.val_dataloader": [[298, 336], ["pathlib.Path", "pathlib.Path", "pipeline_class", "dali.Wrapper", "ValueError"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", "->", "DALIGenericIterator", ":", "\n", "        ", "device_id", "=", "self", ".", "local_rank", "\n", "shard_id", "=", "self", ".", "global_rank", "\n", "num_shards", "=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "num_workers", "=", "self", ".", "extra_args", "[", "\"num_workers\"", "]", "\n", "dali_device", "=", "self", ".", "extra_args", "[", "\"dali_device\"", "]", "\n", "data_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"data_dir\"", "]", ")", "\n", "val_dir", "=", "Path", "(", "self", ".", "extra_args", "[", "\"val_dir\"", "]", ")", "\n", "\n", "# handle custom data by creating the needed pipeline", "\n", "dataset", "=", "self", ".", "extra_args", "[", "\"dataset\"", "]", "\n", "if", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", ":", "\n", "            ", "pipeline_class", "=", "NormalPipeline", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "            ", "pipeline_class", "=", "CustomNormalPipeline", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset", ",", "\"is not supported, used [imagenet, imagenet100 or custom]\"", ")", "\n", "\n", "", "val_pipeline", "=", "pipeline_class", "(", "\n", "data_dir", "/", "val_dir", ",", "\n", "validation", "=", "True", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "device", "=", "dali_device", ",", "\n", "device_id", "=", "device_id", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "num_threads", "=", "num_workers", ",", "\n", ")", "\n", "\n", "val_loader", "=", "Wrapper", "(", "\n", "val_pipeline", ",", "\n", "output_map", "=", "[", "\"x\"", ",", "\"label\"", "]", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "LastBatchPolicy", ".", "PARTIAL", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "return", "val_loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.__init__": [[35, 76], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "mocov2.MoCoV2.register_buffer", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "mocov2.MoCoV2.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "queue_size", ":", "int", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Implements MoCo V2+ (https://arxiv.org/abs/2011.10566).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            temperature (float): temperature for the softmax in the contrastive loss.\n            queue_size (int): number of samples to keep in the queue.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "queue_size", "=", "queue_size", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# momentum projector", "\n", "self", ".", "momentum_projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "initialize_momentum_params", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "\n", "\n", "# create the queue", "\n", "self", ".", "register_buffer", "(", "\"queue\"", ",", "torch", ".", "randn", "(", "2", ",", "proj_output_dim", ",", "queue_size", ")", ")", "\n", "self", ".", "queue", "=", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "queue", ",", "dim", "=", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_ptr\"", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.add_model_specific_args": [[77, 93], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "MoCoV2", ",", "MoCoV2", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"mocov2\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "# queue settings", "\n", "parser", ".", "add_argument", "(", "\"--queue_size\"", ",", "default", "=", "65536", ",", "type", "=", "int", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.learnable_params": [[94, 104], ["mocov2.MoCoV2.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters together with parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.momentum_pairs": [[105, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs.\n        \"\"\"", "\n", "\n", "extra_momentum_pairs", "=", "[", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "]", "\n", "return", "super", "(", ")", ".", "momentum_pairs", "+", "extra_momentum_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2._dequeue_and_enqueue": [[116, 133], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "int", "keys.permute.permute.permute"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_dequeue_and_enqueue", "(", "self", ",", "keys", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Adds new samples and removes old samples from the queue in a fifo manner.\n\n        Args:\n            keys (torch.Tensor): output features of the momentum encoder.\n        \"\"\"", "\n", "\n", "batch_size", "=", "keys", ".", "shape", "[", "1", "]", "\n", "ptr", "=", "int", "(", "self", ".", "queue_ptr", ")", "# type: ignore", "\n", "assert", "self", ".", "queue_size", "%", "batch_size", "==", "0", "# for simplicity", "\n", "\n", "# replace the keys at ptr (dequeue and enqueue)", "\n", "keys", "=", "keys", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "self", ".", "queue", "[", ":", ",", ":", ",", "ptr", ":", "ptr", "+", "batch_size", "]", "=", "keys", "\n", "ptr", "=", "(", "ptr", "+", "batch_size", ")", "%", "self", ".", "queue_size", "# move pointer", "\n", "self", ".", "queue_ptr", "[", "0", "]", "=", "ptr", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.forward": [[134, 147], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2.MoCoV2.projector"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.forward"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the online encoder and the online projection.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "q", "=", "F", ".", "normalize", "(", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "{", "**", "out", ",", "\"q\"", ":", "q", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2.training_step": [[148, 187], ["super().training_step", "mocov2.MoCoV2.projector", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2.MoCoV2.queue.clone().detach", "solo.losses.moco.moco_loss_func", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "mocov2.MoCoV2._dequeue_and_enqueue", "mocov2.MoCoV2.log", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mocov2.MoCoV2.momentum_projector", "torch.normalize", "torch.normalize", "torch.normalize", "mocov2.MoCoV2.queue.clone", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "solo.utils.misc.gather", "solo.utils.misc.gather"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.moco.moco_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.mocov2.MoCoV2._dequeue_and_enqueue", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.misc.gather"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Training step for MoCo reusing BaseMomentumMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the\n                format of [img_indexes, [X], Y], where [X] is a list of size self.num_crops\n                containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of MOCO loss and classification loss.\n\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "feats1", ",", "_", "=", "out", "[", "\"feats\"", "]", "\n", "_", ",", "momentum_feats2", "=", "out", "[", "\"momentum_feats\"", "]", "\n", "\n", "q1", "=", "self", ".", "projector", "(", "feats1", ")", "\n", "q1", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k2", "=", "self", ".", "momentum_projector", "(", "momentum_feats2", ")", "\n", "k2", "=", "F", ".", "normalize", "(", "k2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# ------- contrastive loss -------", "\n", "# symmetric", "\n", "", "queue", "=", "self", ".", "queue", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "nce_loss", "=", "moco_loss_func", "(", "q1", ",", "k2", ",", "queue", "[", "1", "]", ",", "self", ".", "temperature", ")", "\n", "\n", "# ------- update queue -------", "\n", "keys", "=", "torch", ".", "stack", "(", "(", "torch", ".", "zeros_like", "(", "gather", "(", "k2", ")", ")", ",", "gather", "(", "k2", ")", ")", ")", "\n", "self", ".", "_dequeue_and_enqueue", "(", "keys", ")", "\n", "\n", "self", ".", "log", "(", "\"train_nce_loss\"", ",", "nce_loss", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__": [[34, 74], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.__init__", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.utils.momentum.initialize_momentum_params"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "dt_m", ":", "float", ",", "\n", "plus_version", ":", "bool", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Implements MoCo V2+ (https://arxiv.org/abs/2011.10566).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            temperature (float): temperature for the softmax in the contrastive loss.\n            queue_size (int): number of samples to keep in the queue.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dt_m", "=", "dt_m", "\n", "self", ".", "plus_version", "=", "plus_version", "\n", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# momentum projector", "\n", "self", ".", "momentum_projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "initialize_momentum_params", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args": [[76, 93], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "SimMoCo_DualTemperature", ",", "SimMoCo_DualTemperature", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"simmoco_dual_temperature\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--dt_m\"", ",", "type", "=", "float", ",", "default", "=", "10", ")", "\n", "\n", "# train the plus version which uses symmetric loss", "\n", "parser", ".", "add_argument", "(", "\"--plus_version\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.learnable_params": [[94, 104], ["simmoco_dual_temperature.SimMoCo_DualTemperature.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters together with parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.momentum_pairs": [[105, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs.\n        \"\"\"", "\n", "\n", "extra_momentum_pairs", "=", "[", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "]", "\n", "return", "super", "(", ")", ".", "momentum_pairs", "+", "extra_momentum_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.forward": [[117, 130], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "simmoco_dual_temperature.SimMoCo_DualTemperature.projector"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.forward"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the online encoder and the online projection.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "q", "=", "F", ".", "normalize", "(", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "{", "**", "out", ",", "\"q\"", ":", "q", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step": [[131, 215], ["super().training_step", "simmoco_dual_temperature.SimMoCo_DualTemperature.projector", "simmoco_dual_temperature.SimMoCo_DualTemperature.projector", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "simmoco_dual_temperature.SimMoCo_DualTemperature.log_dict", "super().training_step", "simmoco_dual_temperature.SimMoCo_DualTemperature.projector", "torch.normalize", "torch.normalize", "torch.normalize", "solo.losses.dual_temperature_loss.dual_temperature_loss_func", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "simmoco_dual_temperature.SimMoCo_DualTemperature.log_dict", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "simmoco_dual_temperature.SimMoCo_DualTemperature.momentum_projector", "simmoco_dual_temperature.SimMoCo_DualTemperature.momentum_projector", "torch.normalize().detach", "torch.normalize().detach", "torch.normalize().detach", "torch.normalize().detach", "torch.normalize().detach", "torch.normalize().detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "simmoco_dual_temperature.SimMoCo_DualTemperature.momentum_projector", "torch.normalize().detach", "torch.normalize().detach", "torch.normalize().detach", "solo.losses.dual_temperature_loss.dual_temperature_loss_func", "solo.losses.dual_temperature_loss.dual_temperature_loss_func", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.methods.simmoco_dual_temperature.SimMoCo_DualTemperature.training_step", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func", "home.repos.pwc.inspect_result.ChaoningZhang_Dual-temperature.losses.dual_temperature_loss.dual_temperature_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Training step for MoCo reusing BaseMomentumMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the\n                format of [img_indexes, [X], Y], where [X] is a list of size self.num_crops\n                containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of MOCO loss and classification loss.\n\n        \"\"\"", "\n", "\n", "if", "self", ".", "plus_version", ":", "\n", "            ", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "feats1", ",", "feats2", "=", "out", "[", "\"feats\"", "]", "\n", "momentum_feats1", ",", "momentum_feats2", "=", "out", "[", "\"momentum_feats\"", "]", "\n", "\n", "q1", "=", "self", ".", "projector", "(", "feats1", ")", "\n", "q2", "=", "self", ".", "projector", "(", "feats2", ")", "\n", "\n", "q1", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", "\n", "q2", "=", "F", ".", "normalize", "(", "q2", ",", "dim", "=", "-", "1", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "k1", "=", "self", ".", "momentum_projector", "(", "momentum_feats1", ")", "\n", "k2", "=", "self", ".", "momentum_projector", "(", "momentum_feats2", ")", "\n", "k1", "=", "F", ".", "normalize", "(", "k1", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "k2", "=", "F", ".", "normalize", "(", "k2", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n", "\n", "", "nce_loss", "=", "(", "\n", "dual_temperature_loss_func", "(", "q1", ",", "k2", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "dt_m", "=", "self", ".", "dt_m", ")", "\n", "+", "dual_temperature_loss_func", "(", "q2", ",", "k1", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "dt_m", "=", "self", ".", "dt_m", ")", "\n", ")", "/", "2", "\n", "\n", "# calculate std of features", "\n", "z1_std", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z2_std", "=", "F", ".", "normalize", "(", "q2", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z_std", "=", "(", "z1_std", "+", "z2_std", ")", "/", "2", "\n", "\n", "metrics", "=", "{", "\n", "\"train_nce_loss\"", ":", "nce_loss", ",", "\n", "\"train_z_std\"", ":", "z_std", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "\n", "", "else", ":", "\n", "            ", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "feats1", ",", "_", "=", "out", "[", "\"feats\"", "]", "\n", "_", ",", "momentum_feats2", "=", "out", "[", "\"momentum_feats\"", "]", "\n", "\n", "q1", "=", "self", ".", "projector", "(", "feats1", ")", "\n", "\n", "q1", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "k2", "=", "self", ".", "momentum_projector", "(", "momentum_feats2", ")", "\n", "k2", "=", "F", ".", "normalize", "(", "k2", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n", "", "nce_loss", "=", "dual_temperature_loss_func", "(", "q1", ",", "k2", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "dt_m", "=", "self", ".", "dt_m", ")", "\n", "\n", "# calculate std of features", "\n", "z1_std", "=", "F", ".", "normalize", "(", "q1", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z_std", "=", "z1_std", "\n", "\n", "metrics", "=", "{", "\n", "\"train_nce_loss\"", ":", "nce_loss", ",", "\n", "\"train_z_std\"", ":", "z_std", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "", "", "", ""]]}