{"home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.__init__": [[31, 57], ["os.path.isfile", "open", "print", "json.load", "print", "triviaqa.TriviaQADataset._get_qid", "enumerate"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.load", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset._get_qid"], ["def", "__init__", "(", "self", ",", "file_path", ",", "tokenizer", ",", "max_seq_len", ",", "max_doc_len", ",", "doc_stride", ",", "\n", "max_num_answers", ",", "ignore_seq_with_no_answers", ",", "max_question_len", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "self", ".", "file_path", "=", "file_path", "\n", "with", "open", "(", "self", ".", "file_path", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "print", "(", "f'reading file: {self.file_path}'", ")", "\n", "self", ".", "data_json", "=", "json", ".", "load", "(", "f", ")", "#[:2]#['data'][:1000]", "\n", "print", "(", "f'done reading file: {self.file_path}'", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "max_doc_len", "=", "max_doc_len", "\n", "self", ".", "doc_stride", "=", "doc_stride", "\n", "self", ".", "max_num_answers", "=", "max_num_answers", "\n", "self", ".", "ignore_seq_with_no_answers", "=", "ignore_seq_with_no_answers", "\n", "self", ".", "max_question_len", "=", "max_question_len", "\n", "\n", "# A mapping from qid to an int, which can be synched across gpus using `torch.distributed`", "\n", "if", "'train'", "not", "in", "self", ".", "file_path", ":", "# only for the evaluation set", "\n", "            ", "self", ".", "val_qid_string_to_int_map", "=", "{", "\n", "self", ".", "_get_qid", "(", "entry", "[", "\"paragraphs\"", "]", "[", "0", "]", "[", "'qas'", "]", "[", "0", "]", "[", "'id'", "]", ")", ":", "index", "\n", "for", "index", ",", "entry", "in", "enumerate", "(", "self", ".", "data_json", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "val_qid_string_to_int_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset._normalize_text": [[58, 64], ["text.lower().strip().split", "text.lower().strip", "text.lower"], "methods", ["None"], ["", "", "def", "_normalize_text", "(", "self", ",", "text", ":", "str", ")", "->", "str", ":", "# copied from the official triviaqa repo", "\n", "        ", "return", "\" \"", ".", "join", "(", "\n", "[", "\n", "token", "\n", "for", "token", "in", "text", ".", "lower", "(", ")", ".", "strip", "(", "self", ".", "STRIPPED_CHARACTERS", ")", ".", "split", "(", ")", "\n", "if", "token", "not", "in", "self", ".", "IGNORED_TOKENS", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.__len__": [[69, 71], ["len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_json", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.__getitem__": [[72, 77], ["triviaqa.TriviaQADataset.one_example_to_tensors", "len"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.one_example_to_tensors"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "entry", "=", "self", ".", "data_json", "[", "idx", "]", "\n", "tensors_list", "=", "self", ".", "one_example_to_tensors", "(", "entry", ",", "idx", ")", "\n", "assert", "len", "(", "tensors_list", ")", "==", "1", "\n", "return", "tensors_list", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.one_example_to_tensors": [[78, 252], ["triviaqa.TriviaQADataset.one_example_to_tensors.is_whitespace"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_document_to_chunk.is_whitespace"], ["", "def", "one_example_to_tensors", "(", "self", ",", "example", ",", "idx", ")", ":", "\n", "        ", "def", "is_whitespace", "(", "c", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "                ", "return", "True", "\n", "", "return", "False", "\n", "", "tensors_list", "=", "[", "]", "\n", "for", "paragraph", "in", "example", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "paragraph_text", "=", "paragraph", "[", "\"context\"", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "question_text", "=", "qa", "[", "\"question\"", "]", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "answer_spans", "=", "[", "]", "\n", "for", "answer", "in", "qa", "[", "\"answers\"", "]", ":", "\n", "                    ", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "0", "#answer[\"answer_start\"]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "try", ":", "\n", "                        ", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "token_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "orig_answer_text", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                        ", "print", "(", "f'Reading example {idx} failed'", ")", "\n", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "", "answer_spans", ".", "append", "(", "{", "'start'", ":", "start_position", ",", "'end'", ":", "end_position", ",", "\n", "'text'", ":", "orig_answer_text", ",", "'token_ids'", ":", "token_ids", "}", ")", "\n", "\n", "# ===== Given an example, convert it into tensors  =============", "\n", "", "query_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "question_text", ")", "\n", "query_tokens", "=", "query_tokens", "[", ":", "self", ".", "max_question_len", "]", "\n", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "doc_tokens", ")", ":", "\n", "                    ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "# hack: the line below should have been `self.tokenizer.tokenize(token')`", "\n", "# but roberta tokenizer uses a different subword if the token is the beginning of the string", "\n", "# or in the middle. So for all tokens other than the first, simulate that it is not the first", "\n", "# token by prepending a period before tokenizing, then dropping the period afterwards", "\n", "sub_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "f'. {token}'", ")", "[", "1", ":", "]", "if", "i", ">", "0", "else", "self", ".", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                        ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "all_doc_tokens", "=", "all_doc_tokens", "[", ":", "self", ".", "max_doc_len", "]", "\n", "\n", "# The -3 accounts for [CLS], [SEP] and [SEP]", "\n", "max_tokens_per_doc_slice", "=", "self", ".", "max_seq_len", "-", "len", "(", "query_tokens", ")", "-", "3", "\n", "assert", "max_tokens_per_doc_slice", ">", "0", "\n", "if", "self", ".", "doc_stride", "<", "0", ":", "\n", "# negative doc_stride indicates no sliding window, but using first slice", "\n", "                    ", "self", ".", "doc_stride", "=", "-", "100", "*", "len", "(", "all_doc_tokens", ")", "# large -ve value for the next loop to execute once", "\n", "", "input_ids_list", "=", "[", "]", "\n", "input_mask_list", "=", "[", "]", "\n", "segment_ids_list", "=", "[", "]", "\n", "start_positions_list", "=", "[", "]", "\n", "end_positions_list", "=", "[", "]", "\n", "answer_token_ids_list", "=", "[", "]", "\n", "for", "slice_start", "in", "range", "(", "0", ",", "len", "(", "all_doc_tokens", ")", ",", "max_tokens_per_doc_slice", "-", "self", ".", "doc_stride", ")", ":", "\n", "                    ", "slice_end", "=", "min", "(", "slice_start", "+", "max_tokens_per_doc_slice", ",", "len", "(", "all_doc_tokens", ")", ")", "\n", "\n", "doc_slice_tokens", "=", "all_doc_tokens", "[", "slice_start", ":", "slice_end", "]", "\n", "tokens", "=", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "+", "query_tokens", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "+", "doc_slice_tokens", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "(", "len", "(", "query_tokens", ")", "+", "2", ")", "+", "[", "1", "]", "*", "(", "len", "(", "doc_slice_tokens", ")", "+", "1", ")", "\n", "assert", "len", "(", "segment_ids", ")", "==", "len", "(", "tokens", ")", "\n", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "if", "self", ".", "doc_stride", ">=", "0", ":", "# no need to pad if document is not strided", "\n", "# Zero-pad up to the sequence length.", "\n", "                        ", "padding_len", "=", "self", ".", "max_seq_len", "-", "len", "(", "input_ids", ")", "\n", "input_ids", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_len", ")", "\n", "input_mask", ".", "extend", "(", "[", "0", "]", "*", "padding_len", ")", "\n", "segment_ids", ".", "extend", "(", "[", "0", "]", "*", "padding_len", ")", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "self", ".", "max_seq_len", "\n", "assert", "len", "(", "input_mask", ")", "==", "self", ".", "max_seq_len", "\n", "assert", "len", "(", "segment_ids", ")", "==", "self", ".", "max_seq_len", "\n", "\n", "", "doc_offset", "=", "len", "(", "query_tokens", ")", "+", "2", "-", "slice_start", "\n", "start_positions", "=", "[", "]", "\n", "end_positions", "=", "[", "]", "\n", "answer_token_ids", "=", "[", "]", "\n", "for", "answer_span", "in", "answer_spans", ":", "\n", "                        ", "start_position", "=", "answer_span", "[", "'start'", "]", "\n", "end_position", "=", "answer_span", "[", "'end'", "]", "\n", "tok_start_position_in_doc", "=", "orig_to_tok_index", "[", "start_position", "]", "\n", "not_end_of_doc", "=", "int", "(", "end_position", "+", "1", "<", "len", "(", "orig_to_tok_index", ")", ")", "\n", "tok_end_position_in_doc", "=", "orig_to_tok_index", "[", "end_position", "+", "not_end_of_doc", "]", "-", "not_end_of_doc", "\n", "if", "tok_start_position_in_doc", "<", "slice_start", "or", "tok_end_position_in_doc", ">", "slice_end", ":", "\n", "# this answer is outside the current slice", "\n", "                            ", "continue", "\n", "", "start_positions", ".", "append", "(", "tok_start_position_in_doc", "+", "doc_offset", ")", "\n", "end_positions", ".", "append", "(", "tok_end_position_in_doc", "+", "doc_offset", ")", "\n", "answer_token_ids", ".", "append", "(", "answer_span", "[", "'token_ids'", "]", ")", "\n", "", "assert", "len", "(", "start_positions", ")", "==", "len", "(", "end_positions", ")", "\n", "if", "self", ".", "ignore_seq_with_no_answers", "and", "len", "(", "start_positions", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "# answers from start_positions and end_positions if > self.max_num_answers", "\n", "", "start_positions", "=", "start_positions", "[", ":", "self", ".", "max_num_answers", "]", "\n", "end_positions", "=", "end_positions", "[", ":", "self", ".", "max_num_answers", "]", "\n", "answer_token_ids", "=", "answer_token_ids", "[", ":", "self", ".", "max_num_answers", "]", "\n", "\n", "# -1 padding up to self.max_num_answers", "\n", "padding_len", "=", "self", ".", "max_num_answers", "-", "len", "(", "start_positions", ")", "\n", "start_positions", ".", "extend", "(", "[", "-", "1", "]", "*", "padding_len", ")", "\n", "end_positions", ".", "extend", "(", "[", "-", "1", "]", "*", "padding_len", ")", "\n", "answer_token_ids", ".", "extend", "(", "[", "[", "]", "]", "*", "padding_len", ")", "\n", "\n", "# replace duplicate start/end positions with `-1` because duplicates can result into -ve loss values", "\n", "found_start_positions", "=", "set", "(", ")", "\n", "found_end_positions", "=", "set", "(", ")", "\n", "found_answer_token_ids", "=", "set", "(", ")", "\n", "for", "i", ",", "(", "start_position", ",", "end_position", ",", "answer_tokens", ")", "in", "enumerate", "(", "\n", "zip", "(", "start_positions", ",", "end_positions", ",", "answer_token_ids", ")", "\n", ")", ":", "\n", "                        ", "if", "start_position", "in", "found_start_positions", ":", "\n", "                            ", "start_positions", "[", "i", "]", "=", "-", "1", "\n", "", "if", "end_position", "in", "found_end_positions", ":", "\n", "                            ", "end_positions", "[", "i", "]", "=", "-", "1", "\n", "", "answer_tokens_as_str", "=", "','", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "answer_tokens", "]", ")", "\n", "if", "answer_tokens_as_str", "in", "found_answer_token_ids", ":", "\n", "                            ", "answer_token_ids", "[", "i", "]", "=", "[", "]", "\n", "", "found_start_positions", ".", "add", "(", "start_position", ")", "\n", "found_end_positions", ".", "add", "(", "end_position", ")", "\n", "found_answer_token_ids", ".", "add", "(", "answer_tokens_as_str", ")", "\n", "\n", "", "input_ids_list", ".", "append", "(", "input_ids", ")", "\n", "input_mask_list", ".", "append", "(", "input_mask", ")", "\n", "segment_ids_list", ".", "append", "(", "segment_ids", ")", "\n", "start_positions_list", ".", "append", "(", "start_positions", ")", "\n", "end_positions_list", ".", "append", "(", "end_positions", ")", "\n", "answer_token_ids_list", ".", "append", "(", "answer_token_ids", ")", "\n", "\n", "# pad answers in answer_token_ids_list to the longest answer", "\n", "", "max_answer_len", "=", "max", "(", "[", "len", "(", "item", ")", "for", "sublist", "in", "answer_token_ids_list", "for", "item", "in", "sublist", "]", ")", "# flat list", "\n", "if", "max_answer_len", "==", "0", ":", "\n", "                    ", "max_answer_len", "=", "2", "\n", "", "for", "answers_of_one_slice", "in", "answer_token_ids_list", ":", "\n", "                    ", "for", "answer_tokens", "in", "answers_of_one_slice", ":", "\n", "                        ", "if", "len", "(", "answer_tokens", ")", "==", "0", ":", "\n", "# TODO: <s></s><pad><pad><pad> or <pad><pad><pad><pad><pad> ?", "\n", "                            ", "padding_len", "=", "max_answer_len", "-", "len", "(", "answer_tokens", ")", "-", "2", "\n", "answer_tokens", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "bos_token_id", ",", "self", ".", "tokenizer", ".", "eos_token_id", "]", "+", "\n", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_len", ")", ")", "\n", "", "else", ":", "\n", "                            ", "padding_len", "=", "max_answer_len", "-", "len", "(", "answer_tokens", ")", "\n", "answer_tokens", ".", "extend", "(", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "*", "padding_len", ")", "\n", "\n", "", "", "", "tensors_list", ".", "append", "(", "(", "torch", ".", "tensor", "(", "input_ids_list", ")", ",", "torch", ".", "tensor", "(", "input_mask_list", ")", ",", "\n", "torch", ".", "tensor", "(", "segment_ids_list", ")", ",", "\n", "torch", ".", "tensor", "(", "start_positions_list", ")", ",", "torch", ".", "tensor", "(", "end_positions_list", ")", ",", "\n", "torch", ".", "tensor", "(", "answer_token_ids_list", ")", ",", "\n", "self", ".", "_get_qid", "(", "qa", "[", "'id'", "]", ")", ",", "qa", "[", "'id'", "]", ",", "qa", "[", "\"aliases\"", "]", ")", ")", "# for eval", "\n", "", "", "return", "tensors_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset._get_qid": [[253, 267], ["qid.split", "RuntimeError"], "methods", ["None"], ["", "def", "_get_qid", "(", "self", ",", "qid", ")", ":", "\n", "        ", "\"\"\"all input qids are formatted uniqueID__evidenceFile, but for wikipedia, qid = uniqueID,\n        and for web, qid = uniqueID__evidenceFile. This function takes care of this conversion.\n        \"\"\"", "\n", "if", "'wikipedia'", "in", "self", ".", "file_path", ":", "\n", "# for evaluation on wikipedia, every question has one answer even if multiple evidence documents are given", "\n", "            ", "return", "qid", ".", "split", "(", "'--'", ")", "[", "0", "]", "\n", "", "elif", "'web'", "in", "self", ".", "file_path", ":", "\n", "# for evaluation on web, every question/document pair have an answer", "\n", "            ", "return", "qid", "\n", "", "elif", "'sample'", "in", "self", ".", "file_path", ":", "\n", "            ", "return", "qid", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Unexpected filename'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQADataset.collate_one_doc_and_lists": [[268, 280], ["stacked_fields.extend", "torch.stack", "len", "zip"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "collate_one_doc_and_lists", "(", "batch", ")", ":", "\n", "        ", "num_metadata_fields", "=", "3", "# qids and aliases", "\n", "fields", "=", "[", "x", "for", "x", "in", "zip", "(", "*", "batch", ")", "]", "\n", "stacked_fields", "=", "[", "torch", ".", "stack", "(", "field", ")", "for", "field", "in", "fields", "[", ":", "-", "num_metadata_fields", "]", "]", "# don't stack metadata fields", "\n", "stacked_fields", ".", "extend", "(", "fields", "[", "-", "num_metadata_fields", ":", "]", ")", "# add them as lists not torch tensors", "\n", "\n", "# always use batch_size=1 where each batch is one document", "\n", "# will use grad_accum to increase effective batch size", "\n", "assert", "len", "(", "batch", ")", "==", "1", "\n", "fields_with_batch_size_one", "=", "[", "f", "[", "0", "]", "for", "f", "in", "stacked_fields", "]", "\n", "return", "fields_with_batch_size_one", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.__init__": [[284, 296], ["pytorch_lightning.LightningModule.__init__", "transformers.RobertaTokenizer.from_pretrained", "triviaqa.TriviaQA.load_model", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.load_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "TriviaQA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "hparams", "=", "args", "\n", "\n", "self", ".", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "'/export/users/zhaojing/longformer-master/roberta.large'", ")", "\n", "self", ".", "tokenizer", ".", "model_max_length", "=", "self", ".", "args", ".", "max_seq_len", "\n", "self", ".", "model", "=", "self", ".", "load_model", "(", ")", "\n", "self", ".", "num_labels", "=", "2", "\n", "if", "not", "self", ".", "args", ".", "seq2seq", ":", "\n", "            ", "self", ".", "qa_outputs", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "model", ".", "config", ".", "hidden_size", ",", "self", ".", "num_labels", ")", "\n", "", "self", ".", "train_dataloader_object", "=", "self", ".", "val_dataloader_object", "=", "self", ".", "test_dataloader_object", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.load_model": [[297, 334], ["print", "print", "transformers.AutoModel.from_pretrained.parameters", "transformers.AutoModel.from_pretrained.train", "longformer.longformer.Longformer.from_pretrained", "p.requires_grad_", "torch.hub.load", "transformers.AutoConfig.from_pretrained", "transformers.AutoModelWithLMHead.from_pretrained", "transformers.AutoModel.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoModel.from_pretrained", "transformers.AutoModelWithLMHead.from_pretrained", "transformers.AutoModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.load"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "if", "'longformer'", "in", "self", ".", "args", ".", "model_path", ":", "\n", "            ", "model", "=", "Longformer", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "for", "layer", "in", "model", ".", "encoder", ".", "layer", ":", "\n", "                ", "layer", ".", "attention", ".", "self", ".", "attention_mode", "=", "self", ".", "args", ".", "attention_mode", "\n", "self", ".", "args", ".", "attention_window", "=", "layer", ".", "attention", ".", "self", ".", "attention_window", "\n", "", "", "elif", "self", ".", "args", ".", "model_path", "in", "[", "'bart.large'", ",", "'bart.base'", "]", ":", "\n", "            ", "model", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq'", ",", "self", ".", "args", ".", "model_path", ")", "\n", "model", ".", "config", "=", "model", ".", "args", "\n", "model", ".", "config", ".", "hidden_size", "=", "model", ".", "config", ".", "decoder_output_dim", "\n", "", "elif", "'bart'", "in", "self", ".", "args", ".", "model_path", "and", "'base'", "in", "self", ".", "args", ".", "model_path", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "config", ".", "encoder_attention_heads", "=", "12", "\n", "config", ".", "decoder_attention_heads", "=", "12", "\n", "config", ".", "attention_dropout", "=", "0.1", "\n", "if", "self", ".", "args", ".", "seq2seq", ":", "\n", "                ", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "                ", "model", "=", "AutoModel", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "", "elif", "'bart'", "in", "self", ".", "args", ".", "model_path", "and", "'large'", "in", "self", ".", "args", ".", "model_path", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "config", ".", "attention_dropout", "=", "0.1", "\n", "config", ".", "gradient_checkpointing", "=", "True", "\n", "if", "self", ".", "args", ".", "seq2seq", ":", "\n", "                ", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "                ", "model", "=", "AutoModel", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "", "else", ":", "\n", "            ", "model", "=", "AutoModel", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "\n", "", "print", "(", "\"Loaded model with config:\"", ")", "\n", "print", "(", "model", ".", "config", ")", "\n", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad_", "(", "True", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.forward": [[335, 411], ["triviaqa.TriviaQA.qa_outputs", "triviaqa.TriviaQA.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "triviaqa.TriviaQA._get_question_end_index", "torch.ones", "longformer.sliding_chunks.pad_to_window_size", "input_ids[].eq().sum", "triviaqa.TriviaQA.model", "triviaqa.TriviaQA.model.extract_features", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "triviaqa.TriviaQA.or_softmax_cross_entropy_loss_one_doc", "triviaqa.TriviaQA.or_softmax_cross_entropy_loss_one_doc", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "input_ids[].eq", "answer_token_ids[].clone", "answer_token_ids[].contiguous", "triviaqa.TriviaQA.model", "[].sum", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size", "question_end_index[].float", "triviaqa.TriviaQA.float().mean", "triviaqa.TriviaQA.item", "triviaqa.TriviaQA.model", "triviaqa.TriviaQA.float", "outputs[].softmax"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA._get_question_end_index", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.pad_to_window_size", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.or_softmax_cross_entropy_loss_one_doc", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.or_softmax_cross_entropy_loss_one_doc"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "segment_ids", ",", "start_positions", ",", "end_positions", ",", "answer_token_ids", ")", ":", "\n", "        ", "if", "'longformer'", "in", "self", ".", "args", ".", "model_path", ":", "\n", "            ", "question_end_index", "=", "self", ".", "_get_question_end_index", "(", "input_ids", ")", "\n", "# Each batch is one document, and each row of the batch is a chunck of the document.", "\n", "# Make sure all rows have the same question length.", "\n", "assert", "(", "question_end_index", "[", "0", "]", ".", "float", "(", ")", "==", "question_end_index", ".", "float", "(", ")", ".", "mean", "(", ")", ")", ".", "item", "(", ")", "\n", "\n", "# local attention everywhere", "\n", "attention_mask", "=", "torch", ".", "ones", "(", "input_ids", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "# global attention for the question tokens", "\n", "attention_mask", "[", ":", ",", ":", "question_end_index", ".", "item", "(", ")", "]", "=", "2", "\n", "\n", "# sliding_chunks implemenation of selfattention requires that seqlen is multiple of window size", "\n", "input_ids", ",", "attention_mask", "=", "pad_to_window_size", "(", "\n", "input_ids", ",", "attention_mask", ",", "self", ".", "args", ".", "attention_window", ",", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "sequence_output", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "[", "0", "]", "\n", "\n", "# The pretrained TriviaQA model wasn't trained with padding, so remove padding tokens", "\n", "# before computing loss and decoding.", "\n", "padding_len", "=", "input_ids", "[", "0", "]", ".", "eq", "(", "self", ".", "tokenizer", ".", "pad_token_id", ")", ".", "sum", "(", ")", "\n", "if", "padding_len", ">", "0", ":", "\n", "                ", "sequence_output", "=", "sequence_output", "[", ":", ",", ":", "-", "padding_len", "]", "\n", "", "", "elif", "self", ".", "args", ".", "model_path", "in", "[", "'bart.large'", ",", "'bart.base'", "]", ":", "\n", "            ", "sequence_output", "=", "self", ".", "model", ".", "extract_features", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "seq2seq", ":", "\n", "                ", "decoder_input_ids", "=", "answer_token_ids", "[", ":", ",", "0", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "decoder_input_ids", "[", "decoder_input_ids", "==", "self", ".", "tokenizer", ".", "eos_token_id", "]", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "decoder_attention_mask", "=", "(", "decoder_input_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "answer_token_ids", "[", ":", ",", "0", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "labels", "[", "answer_token_ids", "[", ":", ",", "0", ",", "1", ":", "]", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "logit_scores", "=", "outputs", "[", "1", "]", ".", "softmax", "(", "dim", "=", "2", ")", "[", ":", ",", ":", ",", "0", "]", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "[", "loss", ",", "logit_scores", "]", "\n", "", "else", ":", "\n", "                ", "sequence_output", "=", "self", ".", "model", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "[", "0", "]", "\n", "\n", "", "", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "args", ".", "regular_softmax_loss", ":", "\n", "# loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf", "\n", "# NOTE: this returns sum of losses, not mean, so loss won't be normalized across different batch sizes", "\n", "# but batch size is always 1, so this is not a problem", "\n", "                ", "start_loss", "=", "self", ".", "or_softmax_cross_entropy_loss_one_doc", "(", "start_logits", ",", "start_positions", ",", "ignore_index", "=", "-", "1", ")", "\n", "end_loss", "=", "self", ".", "or_softmax_cross_entropy_loss_one_doc", "(", "end_logits", ",", "end_positions", ",", "ignore_index", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "0", ":", "1", "]", "\n", "end_positions", "=", "end_positions", "[", ":", ",", "0", ":", "1", "]", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", "[", ":", ",", "0", "]", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", "[", ":", ",", "0", "]", ")", "\n", "\n", "", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.or_softmax_cross_entropy_loss_one_doc": [[412, 446], ["logits.view.view.gather", "float", "gathered_logits.view.view.view", "logits.view.view.view", "torch.logsumexp", "torch.logsumexp", "loss[].sum", "logits.view.view.size", "target.size", "target_mask.long", "torch.isinf"], "methods", ["None"], ["", "def", "or_softmax_cross_entropy_loss_one_doc", "(", "self", ",", "logits", ",", "target", ",", "ignore_index", "=", "-", "1", ",", "dim", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"loss function suggested in section 2.2 here https://arxiv.org/pdf/1710.10723.pdf\"\"\"", "\n", "assert", "logits", ".", "ndim", "==", "2", "\n", "assert", "target", ".", "ndim", "==", "2", "\n", "assert", "logits", ".", "size", "(", "0", ")", "==", "target", ".", "size", "(", "0", ")", "\n", "\n", "# with regular CrossEntropyLoss, the numerator is only one of the logits specified by the target", "\n", "# here, the numerator is the sum of a few potential targets, where some of them is the correct answer", "\n", "\n", "# compute a target mask", "\n", "target_mask", "=", "target", "==", "ignore_index", "\n", "# replaces ignore_index with 0, so `gather` will select logit at index 0 for the msked targets", "\n", "masked_target", "=", "target", "*", "(", "1", "-", "target_mask", ".", "long", "(", ")", ")", "\n", "# gather logits", "\n", "gathered_logits", "=", "logits", ".", "gather", "(", "dim", "=", "dim", ",", "index", "=", "masked_target", ")", "\n", "# Apply the mask to gathered_logits. Use a mask of -inf because exp(-inf) = 0", "\n", "gathered_logits", "[", "target_mask", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "# each batch is one example", "\n", "gathered_logits", "=", "gathered_logits", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "logits", "=", "logits", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "# numerator = log(sum(exp(gathered logits)))", "\n", "log_score", "=", "torch", ".", "logsumexp", "(", "gathered_logits", ",", "dim", "=", "dim", ",", "keepdim", "=", "False", ")", "\n", "# denominator = log(sum(exp(logits)))", "\n", "log_norm", "=", "torch", ".", "logsumexp", "(", "logits", ",", "dim", "=", "dim", ",", "keepdim", "=", "False", ")", "\n", "\n", "# compute the loss", "\n", "loss", "=", "-", "(", "log_score", "-", "log_norm", ")", "\n", "\n", "# some of the examples might have a loss of `inf` when `target` is all `ignore_index`.", "\n", "# remove those from the loss before computing the sum. Use sum instead of mean because", "\n", "# it is easier to compute", "\n", "return", "loss", "[", "~", "torch", ".", "isinf", "(", "loss", ")", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.training_step": [[447, 456], ["triviaqa.TriviaQA.forward", "loss.new_zeros", "input_ids.numel", "torch.cuda.memory_allocated"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ",", "qids", ",", "ids", ",", "aliases", "=", "batch", "\n", "output", "=", "self", ".", "forward", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ")", "\n", "loss", "=", "output", "[", "0", "]", "\n", "lr", "=", "loss", ".", "new_zeros", "(", "1", ")", "+", "self", ".", "trainer", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "tensorboard_logs", "=", "{", "'train_loss'", ":", "loss", ",", "'lr'", ":", "lr", ",", "\n", "'input_size'", ":", "input_ids", ".", "numel", "(", ")", ",", "\n", "'mem'", ":", "torch", ".", "cuda", ".", "memory_allocated", "(", "input_ids", ".", "device", ")", "/", "1024", "**", "3", "}", "\n", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.validation_step": [[457, 508], ["triviaqa.TriviaQA.forward", "triviaqa.TriviaQA.decode", "start_logits.argmax", "end_logits.argmax", "triviaqa.TriviaQA.model.generate", "scripts.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "scripts.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "sorted", "scripts.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "scripts.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "len", "len", "len", "len", "len", "exact_match.mean", "logit_scores.sort", "[].item", "triviaqa.TriviaQA.tokenizer.decode", "generated_answer_ids.new_zeros().float", "zip", "zip", "generated_answer_ids.new_zeros", "subword_ends[].squeeze", "subword_starts[].squeeze"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.decode", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.decode"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ",", "qids", ",", "ids", ",", "aliases", "=", "batch", "\n", "output", "=", "self", ".", "forward", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ")", "\n", "if", "self", ".", "args", ".", "seq2seq", ":", "\n", "            ", "logit_scores", "=", "output", "[", "1", "]", "\n", "answer_score_indices", "=", "logit_scores", ".", "sort", "(", ")", ".", "indices", "\n", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "input_mask", ",", "use_cache", "=", "True", ",", ")", "\n", "answer_text", "=", "''", "\n", "best_answer_score", "=", "0", "\n", "for", "i", "in", "answer_score_indices", ":", "\n", "                ", "generated_answer_ids", "=", "generated_ids", "[", "answer_score_indices", "[", "i", "]", "]", "\n", "generated_answer_ids", "[", "-", "1", "]", "=", "self", ".", "tokenizer", ".", "eos_token_id", "\n", "index_of_eos_token", "=", "(", "generated_answer_ids", "==", "self", ".", "tokenizer", ".", "eos_token_id", ")", ".", "nonzero", "(", ")", "[", "0", ",", "0", "]", ".", "item", "(", ")", "\n", "generated_answer_ids", "=", "generated_answer_ids", "[", "1", ":", "index_of_eos_token", "]", "\n", "answer_text", "=", "self", ".", "tokenizer", ".", "decode", "(", "generated_answer_ids", ")", "\n", "if", "answer_text", "!=", "''", ":", "\n", "                    ", "best_answer_score", "=", "logit_scores", "[", "answer_score_indices", "[", "i", "]", "]", "\n", "break", "\n", "", "", "f1_score", "=", "evaluation_utils", ".", "metric_max_over_ground_truths", "(", "evaluation_utils", ".", "f1_score", ",", "answer_text", ",", "aliases", ")", "\n", "em_score", "=", "evaluation_utils", ".", "metric_max_over_ground_truths", "(", "evaluation_utils", ".", "exact_match_score", ",", "answer_text", ",", "aliases", ")", "\n", "return", "{", "'vloss'", ":", "output", "[", "0", "]", ",", "'vem'", ":", "generated_answer_ids", ".", "new_zeros", "(", "[", "1", "]", ")", ".", "float", "(", ")", ",", "\n", "'qids'", ":", "[", "qids", "]", ",", "'answer_scores'", ":", "[", "best_answer_score", "]", ",", "\n", "'f1'", ":", "[", "f1_score", "]", ",", "'em'", ":", "[", "em_score", "]", "}", "\n", "\n", "", "loss", ",", "start_logits", ",", "end_logits", "=", "output", "[", ":", "3", "]", "\n", "answers", "=", "self", ".", "decode", "(", "input_ids", ",", "start_logits", ",", "end_logits", ")", "\n", "\n", "# each batch is one document", "\n", "answers", "=", "sorted", "(", "answers", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "[", "0", ":", "1", "]", "\n", "qids", "=", "[", "qids", "]", "\n", "aliases", "=", "[", "aliases", "]", "\n", "\n", "f1_scores", "=", "[", "evaluation_utils", ".", "metric_max_over_ground_truths", "(", "evaluation_utils", ".", "f1_score", ",", "answer", "[", "'text'", "]", ",", "\n", "aliase_list", ")", "\n", "for", "answer", ",", "aliase_list", "in", "zip", "(", "answers", ",", "aliases", ")", "]", "\n", "# TODO: if slow, skip em_scores, and use (f1_score == 1.0) instead", "\n", "em_scores", "=", "[", "evaluation_utils", ".", "metric_max_over_ground_truths", "(", "evaluation_utils", ".", "exact_match_score", ",", "answer", "[", "'text'", "]", ",", "\n", "aliase_list", ")", "\n", "for", "answer", ",", "aliase_list", "in", "zip", "(", "answers", ",", "aliases", ")", "]", "\n", "answer_scores", "=", "[", "answer", "[", "'score'", "]", "for", "answer", "in", "answers", "]", "# start_logit + end_logit", "\n", "assert", "len", "(", "answer_scores", ")", "==", "len", "(", "f1_scores", ")", "==", "len", "(", "em_scores", ")", "==", "len", "(", "qids", ")", "==", "len", "(", "aliases", ")", "==", "1", "\n", "\n", "# TODO: delete this metric", "\n", "pred_subword_starts", "=", "start_logits", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "pred_subword_ends", "=", "end_logits", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "exact_match", "=", "(", "subword_ends", "[", ":", ",", "0", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "==", "pred_subword_ends", ")", ".", "float", "(", ")", "*", "(", "subword_starts", "[", ":", ",", "0", "]", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "==", "pred_subword_starts", ")", ".", "float", "(", ")", "\n", "\n", "return", "{", "'vloss'", ":", "loss", ",", "'vem'", ":", "exact_match", ".", "mean", "(", ")", ",", "\n", "'qids'", ":", "qids", ",", "'answer_scores'", ":", "answer_scores", ",", "\n", "'f1'", ":", "f1_scores", ",", "'em'", ":", "em_scores", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA._get_question_end_index": [[509, 515], ["eos_token_indices.size", "eos_token_indices.size", "eos_token_indices.view", "input_ids.size", "input_ids.size"], "methods", ["None"], ["", "def", "_get_question_end_index", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "eos_token_indices", "=", "(", "input_ids", "==", "self", ".", "tokenizer", ".", "eos_token_id", ")", ".", "nonzero", "(", ")", "\n", "assert", "eos_token_indices", ".", "ndim", "==", "2", "\n", "assert", "eos_token_indices", ".", "size", "(", "0", ")", "==", "2", "*", "input_ids", ".", "size", "(", "0", ")", "\n", "assert", "eos_token_indices", ".", "size", "(", "1", ")", "==", "2", "\n", "return", "eos_token_indices", ".", "view", "(", "input_ids", ".", "size", "(", "0", ")", ",", "2", ",", "2", ")", "[", ":", ",", "0", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.decode": [[516, 557], ["triviaqa.TriviaQA._get_question_end_index", "range", "start_logits.topk", "end_logits.topk", "start_logits_indices.size", "sorted", "len", "answers.append", "potential_answers.append", "triviaqa.TriviaQA.tokenizer.convert_ids_to_tokens", "triviaqa.TriviaQA.tokenizer.convert_tokens_to_string", "answer_token_ids.tolist", "answers.append", "answers.append", "[].item", "[].item"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA._get_question_end_index"], ["", "def", "decode", "(", "self", ",", "input_ids", ",", "start_logits", ",", "end_logits", ",", "ids", "=", "None", ")", ":", "\n", "# find beginning of document", "\n", "        ", "question_end_index", "=", "self", ".", "_get_question_end_index", "(", "input_ids", ")", "\n", "\n", "# bsz x seqlen => bsz x n_best_size", "\n", "start_logits_indices", "=", "start_logits", ".", "topk", "(", "k", "=", "self", ".", "args", ".", "n_best_size", ",", "dim", "=", "-", "1", ")", ".", "indices", "\n", "end_logits_indices", "=", "end_logits", ".", "topk", "(", "k", "=", "self", ".", "args", ".", "n_best_size", ",", "dim", "=", "-", "1", ")", ".", "indices", "\n", "\n", "answers", "=", "[", "]", "\n", "# This loop can't be vectorized, so loop over each example in the batch separetly", "\n", "for", "i", "in", "range", "(", "start_logits_indices", ".", "size", "(", "0", ")", ")", ":", "# bsz", "\n", "            ", "potential_answers", "=", "[", "]", "\n", "for", "start_logit_index", "in", "start_logits_indices", "[", "i", "]", ":", "# n_best_size", "\n", "                ", "for", "end_logit_index", "in", "end_logits_indices", "[", "i", "]", ":", "# n_best_size", "\n", "                    ", "if", "start_logit_index", "<=", "question_end_index", "[", "i", "]", ":", "\n", "                        ", "continue", "\n", "", "if", "end_logit_index", "<=", "question_end_index", "[", "i", "]", ":", "\n", "                        ", "continue", "\n", "", "if", "start_logit_index", ">", "end_logit_index", ":", "\n", "                        ", "continue", "\n", "", "answer_len", "=", "end_logit_index", "-", "start_logit_index", "+", "1", "\n", "if", "answer_len", ">", "self", ".", "args", ".", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "", "potential_answers", ".", "append", "(", "{", "'start'", ":", "start_logit_index", ",", "'end'", ":", "end_logit_index", ",", "\n", "'start_logit'", ":", "start_logits", "[", "i", "]", "[", "start_logit_index", "]", ".", "item", "(", ")", ",", "\n", "'end_logit'", ":", "end_logits", "[", "i", "]", "[", "end_logit_index", "]", ".", "item", "(", ")", "}", ")", "\n", "", "", "sorted_answers", "=", "sorted", "(", "potential_answers", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "'start_logit'", "]", "+", "x", "[", "'end_logit'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "if", "len", "(", "sorted_answers", ")", "==", "0", ":", "\n", "                ", "answers", ".", "append", "(", "{", "'text'", ":", "'NoAnswerFound'", ",", "'score'", ":", "-", "1000000", "}", ")", "\n", "", "else", ":", "\n", "                ", "for", "answer", "in", "sorted_answers", ":", "\n", "# answer = sorted_answers[0]", "\n", "                    ", "answer_token_ids", "=", "input_ids", "[", "i", ",", "answer", "[", "'start'", "]", ":", "answer", "[", "'end'", "]", "+", "1", "]", "\n", "answer_tokens", "=", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "answer_token_ids", ".", "tolist", "(", ")", ")", "\n", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_string", "(", "answer_tokens", ")", "\n", "score", "=", "answer", "[", "'start_logit'", "]", "+", "answer", "[", "'end_logit'", "]", "\n", "if", "not", "ids", ":", "\n", "                        ", "answers", ".", "append", "(", "{", "'text'", ":", "text", ",", "'score'", ":", "score", "}", ")", "\n", "", "else", ":", "\n", "                        ", "answers", ".", "append", "(", "{", "'text'", ":", "text", ",", "'score'", ":", "score", ",", "'ids'", ":", "ids", "}", ")", "\n", "", "", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.sync_list_across_gpus": [[558, 563], ["torch.tensor", "torch.distributed.all_gather", "torch.cat().tolist", "torch.ones_like", "range", "torch.cat"], "methods", ["None"], ["", "def", "sync_list_across_gpus", "(", "self", ",", "list_to_sync", ",", "device", ",", "dtype", ")", ":", "\n", "        ", "l_tensor", "=", "torch", ".", "tensor", "(", "list_to_sync", ",", "device", "=", "device", ",", "dtype", "=", "dtype", ")", "\n", "gather_l_tensor", "=", "[", "torch", ".", "ones_like", "(", "l_tensor", ")", "for", "_", "in", "range", "(", "self", ".", "trainer", ".", "world_size", ")", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "gather_l_tensor", ",", "l_tensor", ")", "\n", "return", "torch", ".", "cat", "(", "gather_l_tensor", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.validation_end": [[564, 602], ["torch.stack().mean", "torch.stack().mean", "print", "print", "collections.defaultdict", "zip", "collections.defaultdict.items", "torch.distributed.all_reduce", "torch.distributed.all_reduce", "triviaqa.TriviaQA.sync_list_across_gpus", "triviaqa.TriviaQA.sync_list_across_gpus", "triviaqa.TriviaQA.sync_list_across_gpus", "triviaqa.TriviaQA.sync_list_across_gpus", "qa_with_duplicates[].append", "triviaqa.TriviaQA.append", "triviaqa.TriviaQA.append", "sum", "len", "sum", "len", "torch.stack", "torch.stack", "sorted", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.sync_list_across_gpus", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.sync_list_across_gpus", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.sync_list_across_gpus", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.sync_list_across_gpus"], ["", "def", "validation_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "'vloss'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "avg_em", "=", "torch", ".", "stack", "(", "[", "x", "[", "'vem'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "string_qids", "=", "[", "item", "for", "sublist", "in", "outputs", "for", "item", "in", "sublist", "[", "'qids'", "]", "]", "\n", "int_qids", "=", "[", "self", ".", "val_dataloader_object", ".", "dataset", ".", "val_qid_string_to_int_map", "[", "qid", "]", "for", "qid", "in", "string_qids", "]", "\n", "answer_scores", "=", "[", "item", "for", "sublist", "in", "outputs", "for", "item", "in", "sublist", "[", "'answer_scores'", "]", "]", "\n", "f1_scores", "=", "[", "item", "for", "sublist", "in", "outputs", "for", "item", "in", "sublist", "[", "'f1'", "]", "]", "\n", "em_scores", "=", "[", "item", "for", "sublist", "in", "outputs", "for", "item", "in", "sublist", "[", "'em'", "]", "]", "\n", "print", "(", "f'before sync --> sizes: {len(int_qids)}, {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}'", ")", "\n", "if", "self", ".", "trainer", ".", "use_ddp", ":", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "avg_loss", ",", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "avg_loss", "/=", "self", ".", "trainer", ".", "world_size", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "avg_em", ",", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "avg_em", "/=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "int_qids", "=", "self", ".", "sync_list_across_gpus", "(", "int_qids", ",", "avg_loss", ".", "device", ",", "torch", ".", "int", ")", "\n", "answer_scores", "=", "self", ".", "sync_list_across_gpus", "(", "answer_scores", ",", "avg_loss", ".", "device", ",", "torch", ".", "float", ")", "\n", "f1_scores", "=", "self", ".", "sync_list_across_gpus", "(", "f1_scores", ",", "avg_loss", ".", "device", ",", "torch", ".", "float", ")", "\n", "em_scores", "=", "self", ".", "sync_list_across_gpus", "(", "em_scores", ",", "avg_loss", ".", "device", ",", "torch", ".", "int", ")", "\n", "", "print", "(", "f'after sync --> sizes: {len(int_qids)}, {len(answer_scores)}, {len(f1_scores)}, {len(em_scores)}'", ")", "\n", "\n", "# Because of having multiple documents per questions, some questions might have multiple corresponding answers", "\n", "# Here, we only keep the answer with the highest answer_score", "\n", "qa_with_duplicates", "=", "defaultdict", "(", "list", ")", "\n", "for", "qid", ",", "answer_score", ",", "f1_score", ",", "em_score", "in", "zip", "(", "int_qids", ",", "answer_scores", ",", "f1_scores", ",", "em_scores", ")", ":", "\n", "            ", "qa_with_duplicates", "[", "qid", "]", ".", "append", "(", "{", "'answer_score'", ":", "answer_score", ",", "'f1'", ":", "f1_score", ",", "'em'", ":", "em_score", "}", ")", "\n", "", "f1_scores", "=", "[", "]", "\n", "em_scores", "=", "[", "]", "\n", "for", "qid", ",", "answer_metrics", "in", "qa_with_duplicates", ".", "items", "(", ")", ":", "\n", "            ", "top_answer", "=", "sorted", "(", "answer_metrics", ",", "key", "=", "lambda", "x", ":", "x", "[", "'answer_score'", "]", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "f1_scores", ".", "append", "(", "top_answer", "[", "'f1'", "]", ")", "\n", "em_scores", ".", "append", "(", "top_answer", "[", "'em'", "]", ")", "\n", "", "avg_val_f1", "=", "sum", "(", "f1_scores", ")", "/", "len", "(", "f1_scores", ")", "\n", "avg_val_em", "=", "sum", "(", "em_scores", ")", "/", "len", "(", "em_scores", ")", "\n", "\n", "logs", "=", "{", "'val_loss'", ":", "avg_loss", ",", "'val_em'", ":", "avg_em", ",", "'avg_val_f1'", ":", "avg_val_f1", ",", "'avg_val_em'", ":", "avg_val_em", "}", "\n", "\n", "return", "{", "'avg_val_loss'", ":", "avg_loss", ",", "'log'", ":", "logs", ",", "'progress_bar'", ":", "logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.test_step": [[603, 614], ["triviaqa.TriviaQA.forward", "triviaqa.TriviaQA.decode", "sorted"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.decode"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ",", "qids", ",", "ids", ",", "aliases", "=", "batch", "\n", "output", "=", "self", ".", "forward", "(", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "subword_starts", ",", "subword_ends", ",", "answer_token_ids", ")", "\n", "if", "self", ".", "args", ".", "seq2seq", ":", "\n", "            ", "raise", "NotImplemented", "\n", "\n", "", "loss", ",", "start_logits", ",", "end_logits", "=", "output", "[", ":", "3", "]", "\n", "answers", "=", "self", ".", "decode", "(", "input_ids", ",", "start_logits", ",", "end_logits", ",", "ids", ")", "\n", "\n", "answers", "=", "sorted", "(", "answers", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "return", "{", "'qids'", ":", "qids", ",", "'answers'", ":", "answers", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.test_end": [[615, 639], ["collections.defaultdict", "zip", "collections.defaultdict.items", "qa_with_duplicates[].extend", "sorted", "open", "json.dump", "len"], "methods", ["None"], ["", "def", "test_end", "(", "self", ",", "outputs", ")", ":", "\n", "\n", "        ", "qids", "=", "[", "item", "[", "'qids'", "]", "for", "item", "in", "outputs", "]", "\n", "answers", "=", "[", "item", "[", "'answers'", "]", "for", "item", "in", "outputs", "]", "\n", "\n", "\n", "qa_with_duplicates", "=", "defaultdict", "(", "list", ")", "\n", "for", "qid", ",", "answer", "in", "zip", "(", "qids", ",", "answers", ")", ":", "\n", "            ", "qa_with_duplicates", "[", "qid", "]", ".", "extend", "(", "answer", ")", "\n", "\n", "", "qid_to_answer_text", "=", "{", "}", "\n", "qid_to_all_answer", "=", "{", "}", "\n", "for", "qid", ",", "answer", "in", "qa_with_duplicates", ".", "items", "(", ")", ":", "\n", "            ", "sort_answer", "=", "sorted", "(", "answer", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ",", "reverse", "=", "True", ")", "\n", "qid_to_answer_text", "[", "qid", "]", "=", "sort_answer", "[", "0", "]", "[", "'text'", "]", "\n", "qid_to_all_answer", "[", "qid", "]", "=", "sort_answer", "\n", "\n", "#with open('predictions.json', 'w') as f:", "\n", "#    json.dump(qid_to_answer_text, f, indent =4)", "\n", "\n", "", "with", "open", "(", "self", ".", "args", ".", "prediction_file", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "qid_to_all_answer", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "return", "{", "'count'", ":", "len", "(", "qid_to_answer_text", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.configure_optimizers": [[640, 648], ["torch.optim.Adam", "torch.optim.lr_scheduler.LambdaLR", "max", "triviaqa.TriviaQA.parameters", "float", "float", "float", "float", "max", "max"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "            ", "if", "current_step", "<", "self", ".", "args", ".", "warmup", ":", "\n", "                ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "args", ".", "warmup", ")", ")", "\n", "", "return", "max", "(", "0.0", ",", "float", "(", "self", ".", "args", ".", "steps", "-", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "args", ".", "steps", "-", "self", ".", "args", ".", "warmup", ")", ")", ")", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "scheduler", "=", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", "=", "-", "1", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.train_dataloader": [[649, 665], ["triviaqa.TriviaQADataset", "torch.utils.data.DataLoader", "torch.utils.data.distributed.DistributedSampler"], "methods", ["None"], ["", "@", "pl", ".", "data_loader", "\n", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train_dataloader_object", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "train_dataloader_object", "\n", "", "dataset", "=", "TriviaQADataset", "(", "file_path", "=", "self", ".", "args", ".", "train_dataset", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_seq_len", "=", "self", ".", "args", ".", "max_seq_len", ",", "max_doc_len", "=", "self", ".", "args", ".", "max_doc_len", ",", "\n", "doc_stride", "=", "self", ".", "args", ".", "doc_stride", ",", "\n", "max_num_answers", "=", "self", ".", "args", ".", "max_num_answers", ",", "\n", "max_question_len", "=", "self", ".", "args", ".", "max_question_len", ",", "\n", "ignore_seq_with_no_answers", "=", "self", ".", "args", ".", "ignore_seq_with_no_answers", ")", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "True", ")", "if", "self", ".", "trainer", ".", "use_ddp", "else", "None", "\n", "dl", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "TriviaQADataset", ".", "collate_one_doc_and_lists", ")", "\n", "self", ".", "train_dataloader_object", "=", "dl", "\n", "return", "self", ".", "train_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.val_dataloader": [[666, 682], ["triviaqa.TriviaQADataset", "torch.utils.data.DataLoader", "torch.utils.data.distributed.DistributedSampler"], "methods", ["None"], ["", "@", "pl", ".", "data_loader", "\n", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "val_dataloader_object", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "val_dataloader_object", "\n", "", "dataset", "=", "TriviaQADataset", "(", "file_path", "=", "self", ".", "args", ".", "dev_dataset", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_seq_len", "=", "self", ".", "args", ".", "max_seq_len", ",", "max_doc_len", "=", "self", ".", "args", ".", "max_doc_len", ",", "\n", "doc_stride", "=", "self", ".", "args", ".", "doc_stride", ",", "\n", "max_num_answers", "=", "self", ".", "args", ".", "max_num_answers", ",", "\n", "max_question_len", "=", "self", ".", "args", ".", "max_question_len", ",", "\n", "ignore_seq_with_no_answers", "=", "False", ")", "# evaluation data should keep all examples", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "False", ")", "if", "self", ".", "trainer", ".", "use_ddp", "else", "None", "\n", "dl", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "TriviaQADataset", ".", "collate_one_doc_and_lists", ")", "\n", "self", ".", "val_dataloader_object", "=", "dl", "\n", "return", "self", ".", "val_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.test_dataloader": [[683, 699], ["triviaqa.TriviaQADataset", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "@", "pl", ".", "data_loader", "\n", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "test_dataloader_object", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "test_dataloader_object", "\n", "", "dataset", "=", "TriviaQADataset", "(", "file_path", "=", "self", ".", "args", ".", "dev_dataset", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_seq_len", "=", "self", ".", "args", ".", "max_seq_len", ",", "max_doc_len", "=", "self", ".", "args", ".", "max_doc_len", ",", "\n", "doc_stride", "=", "self", ".", "args", ".", "doc_stride", ",", "\n", "max_num_answers", "=", "self", ".", "args", ".", "max_num_answers", ",", "\n", "max_question_len", "=", "self", ".", "args", ".", "max_question_len", ",", "\n", "ignore_seq_with_no_answers", "=", "False", ")", "# evaluation data should keep all examples", "\n", "\n", "dl", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "sampler", "=", "None", ",", "\n", "collate_fn", "=", "TriviaQADataset", ".", "collate_one_doc_and_lists", ")", "\n", "self", ".", "test_dataloader_object", "=", "dl", "\n", "return", "self", ".", "test_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.configure_ddp": [[700, 707], ["pytorch_lightning.overrides.data_parallel.LightningDistributedDataParallel"], "methods", ["None"], ["", "def", "configure_ddp", "(", "self", ",", "model", ",", "device_ids", ")", ":", "\n", "        ", "model", "=", "LightningDistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "device_ids", ",", "\n", "find_unused_parameters", "=", "False", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.add_model_specific_args": [[708, 755], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "default", "=", "'triviaqa'", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_prefix\"", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_dataset\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "\"Path to the training squad-format\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_dataset\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "\"Path to the dev squad-format\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"Batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpus\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of gpus. 0 for CPU\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup\"", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "\"Number of warmup steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "\"Maximum learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_every\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"Number of training steps between validations\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_percent_check\"", ",", "default", "=", "1.00", ",", "type", "=", "float", ",", "help", "=", "'Percent of validation data used'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "\"Number of data loader workers\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "\"Seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Number of epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_len\"", ",", "type", "=", "int", ",", "default", "=", "4096", ",", "\n", "help", "=", "\"Maximum length of seq passed to the transformer model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_doc_len\"", ",", "type", "=", "int", ",", "default", "=", "4096", ",", "\n", "help", "=", "\"Maximum number of wordpieces of the input document\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_num_answers\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"Maximum number of answer spans per document (64 => 94%)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_question_len\"", ",", "type", "=", "int", ",", "default", "=", "55", ",", "\n", "help", "=", "\"Maximum length of the question\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--doc_stride\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Overlap between document chunks. Use -1 to only use the first chunk\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ignore_seq_with_no_answers\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"each example should have at least one answer. Default is False\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--disable_checkpointing\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"No logging or checkpointing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_best_size\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"Number of answer candidates. Used at decoding time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_answer_length\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "\"maximum num of wordpieces/answer. Used at decoding time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--regular_softmax_loss\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"IF true, use regular softmax. Default is using ORed softmax loss\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Test only, no training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_path\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "\"Path to the checkpoint directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_progress_bar\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"no progress bar. Good for printing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention_mode\"", ",", "type", "=", "str", ",", "choices", "=", "[", "'tvm'", ",", "'sliding_chunks'", "]", ",", "\n", "default", "=", "'sliding_chunks'", ",", "help", "=", "'Which implementation of selfattention to use'", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp32\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"default is fp16. Use --fp32 to switch to fp32\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seq2seq\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use an answer generation model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_ckpt\"", ",", "type", "=", "str", ",", "help", "=", "\"Path of a checkpoint to resume from\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--prediction_file\"", ",", "type", "=", "str", ",", "help", "=", "\"Path of prediction file\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.main": [[757, 807], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "triviaqa.TriviaQA", "pytorch_lightning.logging.TestTubeLogger", "pytorch_lightning.callbacks.ModelCheckpoint", "print", "print", "pytorch_lightning.Trainer", "pl.Trainer.test", "torch.cuda.manual_seed_all", "pl.Trainer.fit", "os.path.join", "max"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "model", "=", "TriviaQA", "(", "args", ")", "\n", "#model = TriviaQA.load_from_checkpoint(checkpoint_path='triviaqa/triviaqa-longformer-large/checkpoints/_ckpt_epoch_4_v2.ckpt')", "\n", "\n", "logger", "=", "TestTubeLogger", "(", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "name", "=", "args", ".", "save_prefix", ",", "\n", "version", "=", "0", "# always use version=0", "\n", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "args", ".", "save_prefix", ",", "\"checkpoints\"", ")", ",", "\n", "save_top_k", "=", "5", ",", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "'avg_val_loss'", ",", "\n", "# save_last=True,", "\n", "mode", "=", "'min'", ",", "\n", "period", "=", "-", "1", ",", "\n", "prefix", "=", "''", "\n", ")", "\n", "\n", "print", "(", "args", ")", "\n", "train_set_size", "=", "110648", "# hardcode dataset size. Needed to compute number of steps for the lr scheduler", "\n", "args", ".", "steps", "=", "args", ".", "epochs", "*", "train_set_size", "/", "(", "args", ".", "batch_size", "*", "max", "(", "args", ".", "gpus", ",", "1", ")", ")", "\n", "print", "(", "f'>>>>>>> #steps: {args.steps}, #epochs: {args.epochs}, batch_size: {args.batch_size * args.gpus} <<<<<<<'", ")", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "gpus", "=", "[", "4", "]", ",", "distributed_backend", "=", "'ddp'", "if", "args", ".", "gpus", "and", "args", ".", "gpus", ">", "1", "else", "None", ",", "\n", "track_grad_norm", "=", "-", "1", ",", "max_epochs", "=", "args", ".", "epochs", ",", "early_stop_callback", "=", "None", ",", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "batch_size", ",", "\n", "val_check_interval", "=", "args", ".", "val_every", ",", "\n", "num_sanity_val_steps", "=", "2", ",", "\n", "# check_val_every_n_epoch=2,", "\n", "val_percent_check", "=", "args", ".", "val_percent_check", ",", "\n", "test_percent_check", "=", "args", ".", "val_percent_check", ",", "\n", "logger", "=", "logger", "if", "not", "args", ".", "disable_checkpointing", "else", "False", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", "if", "not", "args", ".", "disable_checkpointing", "else", "False", ",", "\n", "show_progress_bar", "=", "not", "args", ".", "no_progress_bar", ",", "\n", "use_amp", "=", "not", "args", ".", "fp32", ",", "amp_level", "=", "'O2'", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "resume_ckpt", ",", "\n", ")", "\n", "if", "not", "args", ".", "test", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "", "trainer", ".", "test", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._skew": [[6, 11], ["torch.pad", "x_padded.view.view", "x_padded.view.size", "x_padded.view.size", "x_padded.view.size"], "function", ["None"], ["def", "_skew", "(", "x", ",", "direction", ",", "padding_value", ")", ":", "\n", "    ", "'''Convert diagonals into columns (or columns into diagonals depending on `direction`'''", "\n", "x_padded", "=", "F", ".", "pad", "(", "x", ",", "direction", ",", "value", "=", "padding_value", ")", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded", ".", "size", "(", ")", "[", ":", "-", "2", "]", ",", "x_padded", ".", "size", "(", "-", "1", ")", ",", "x_padded", ".", "size", "(", "-", "2", ")", ")", "\n", "return", "x_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._skew2": [[13, 23], ["x.view.size", "torch.pad", "x.view.view", "x.view.view"], "function", ["None"], ["", "def", "_skew2", "(", "x", ",", "padding_value", ")", ":", "\n", "    ", "'''shift every row 1 step to right converting columns into diagonals'''", "\n", "# X = B x C x M x L", "\n", "B", ",", "C", ",", "M", ",", "L", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "M", "+", "1", ")", ",", "value", "=", "padding_value", ")", "# B x C x M x (L+M+1)", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "C", ",", "-", "1", ")", "# B x C x ML+MM+M", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", "-", "M", "]", "# B x C x ML+MM", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "C", ",", "M", ",", "M", "+", "L", ")", "# B x C, M x L+M", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._chunk": [[25, 38], ["x.view.view", "list", "list", "x.view.as_strided", "x.view.size", "x.view.size", "x.view.size", "x.view.stride", "x.view.size"], "function", ["None"], ["", "def", "_chunk", "(", "x", ",", "w", ")", ":", "\n", "    ", "'''convert into overlapping chunkings. Chunk size = 2w, overlap size = w'''", "\n", "\n", "# non-overlapping chunks of size = 2w", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", "//", "(", "w", "*", "2", ")", ",", "w", "*", "2", ",", "x", ".", "size", "(", "2", ")", ")", "\n", "\n", "# use `as_strided` to make the chunks overlap with an overlap size = w", "\n", "chunk_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "chunk_size", "[", "1", "]", "=", "chunk_size", "[", "1", "]", "*", "2", "-", "1", "\n", "\n", "chunk_stride", "=", "list", "(", "x", ".", "stride", "(", ")", ")", "\n", "chunk_stride", "[", "1", "]", "=", "chunk_stride", "[", "1", "]", "//", "2", "\n", "return", "x", ".", "as_strided", "(", "size", "=", "chunk_size", ",", "stride", "=", "chunk_stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_matmul_qk": [[40, 86], ["q.transpose().reshape.size", "q.transpose().reshape.transpose().reshape", "k.transpose().reshape.transpose().reshape", "sliding_chunks._chunk", "sliding_chunks._chunk", "torch.einsum", "torch.einsum", "sliding_chunks._skew", "_skew.new_empty", "diagonal_attn.view().transpose.view().transpose", "longformer.diagonaled_mm_tvm.mask_invalid_locations", "q.transpose().reshape.size", "k.transpose().reshape.size", "q.transpose().reshape.transpose", "k.transpose().reshape.transpose", "diagonal_attn.view().transpose.view"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._chunk", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._chunk", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._skew", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.mask_invalid_locations"], ["", "def", "sliding_chunks_matmul_qk", "(", "q", ":", "torch", ".", "Tensor", ",", "k", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ",", "padding_value", ":", "float", ")", ":", "\n", "    ", "'''Matrix multiplicatio of query x key tensors using with a sliding window attention pattern.\n    This implementation splits the input into overlapping chunks of size 2w (e.g. 512 for pretrained Longformer)\n    with an overlap of size w'''", "\n", "bsz", ",", "seqlen", ",", "num_heads", ",", "head_dim", "=", "q", ".", "size", "(", ")", "\n", "assert", "seqlen", "%", "(", "w", "*", "2", ")", "==", "0", "\n", "assert", "q", ".", "size", "(", ")", "==", "k", ".", "size", "(", ")", "\n", "\n", "chunks_count", "=", "seqlen", "//", "w", "-", "1", "\n", "\n", "# group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size w * 2", "\n", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "bsz", "*", "num_heads", ",", "seqlen", ",", "head_dim", ")", "\n", "k", "=", "k", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "bsz", "*", "num_heads", ",", "seqlen", ",", "head_dim", ")", "\n", "\n", "chunk_q", "=", "_chunk", "(", "q", ",", "w", ")", "\n", "chunk_k", "=", "_chunk", "(", "k", ",", "w", ")", "\n", "\n", "# matrix multipication", "\n", "# bcxd: bsz*num_heads x chunks x 2w x head_dim", "\n", "# bcyd: bsz*num_heads x chunks x 2w x head_dim", "\n", "# bcxy: bsz*num_heads x chunks x 2w x 2w", "\n", "chunk_attn", "=", "torch", ".", "einsum", "(", "'bcxd,bcyd->bcxy'", ",", "(", "chunk_q", ",", "chunk_k", ")", ")", "# multiply", "\n", "\n", "# convert diagonals into columns", "\n", "diagonal_chunk_attn", "=", "_skew", "(", "chunk_attn", ",", "direction", "=", "(", "0", ",", "0", ",", "0", ",", "1", ")", ",", "padding_value", "=", "padding_value", ")", "\n", "\n", "# allocate space for the overall attention matrix where the chunks are compined. The last dimension", "\n", "# has (w * 2 + 1) columns. The first (w) columns are the w lower triangles (attention from a word to", "\n", "# w previous words). The following column is attention score from each word to itself, then", "\n", "# followed by w columns for the upper triangle.", "\n", "\n", "diagonal_attn", "=", "diagonal_chunk_attn", ".", "new_empty", "(", "(", "bsz", "*", "num_heads", ",", "chunks_count", "+", "1", ",", "w", ",", "w", "*", "2", "+", "1", ")", ")", "\n", "\n", "# copy parts from diagonal_chunk_attn into the compined matrix of attentions", "\n", "# - copying the main diagonal and the upper triangle", "\n", "diagonal_attn", "[", ":", ",", ":", "-", "1", ",", ":", ",", "w", ":", "]", "=", "diagonal_chunk_attn", "[", ":", ",", ":", ",", ":", "w", ",", ":", "w", "+", "1", "]", "\n", "diagonal_attn", "[", ":", ",", "-", "1", ",", ":", ",", "w", ":", "]", "=", "diagonal_chunk_attn", "[", ":", ",", "-", "1", ",", "w", ":", ",", ":", "w", "+", "1", "]", "\n", "# - copying the lower triangle", "\n", "diagonal_attn", "[", ":", ",", "1", ":", ",", ":", ",", ":", "w", "]", "=", "diagonal_chunk_attn", "[", ":", ",", ":", ",", "-", "(", "w", "+", "1", ")", ":", "-", "1", ",", "w", "+", "1", ":", "]", "\n", "diagonal_attn", "[", ":", ",", "0", ",", "1", ":", "w", ",", "1", ":", "w", "]", "=", "diagonal_chunk_attn", "[", ":", ",", "0", ",", ":", "w", "-", "1", ",", "1", "-", "w", ":", "]", "\n", "\n", "# separate bsz and num_heads dimensions again", "\n", "diagonal_attn", "=", "diagonal_attn", ".", "view", "(", "bsz", ",", "num_heads", ",", "seqlen", ",", "2", "*", "w", "+", "1", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "mask_invalid_locations", "(", "diagonal_attn", ",", "w", ",", "1", ",", "False", ")", "\n", "return", "diagonal_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_matmul_pv": [[88, 115], ["v.transpose().reshape.size", "prob.transpose().reshape", "v.transpose().reshape.transpose().reshape", "torch.pad", "F.pad.stride", "F.pad.as_strided", "sliding_chunks._skew2", "torch.einsum", "torch.einsum", "torch.einsum.view().transpose", "prob.size", "prob.size", "v.transpose().reshape.size", "prob.transpose", "v.transpose().reshape.transpose", "torch.einsum.view"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks._skew2"], ["", "def", "sliding_chunks_matmul_pv", "(", "prob", ":", "torch", ".", "Tensor", ",", "v", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ")", ":", "\n", "    ", "'''Same as sliding_chunks_matmul_qk but for prob and value tensors. It is expecting the same output\n    format from sliding_chunks_matmul_qk'''", "\n", "bsz", ",", "seqlen", ",", "num_heads", ",", "head_dim", "=", "v", ".", "size", "(", ")", "\n", "assert", "seqlen", "%", "(", "w", "*", "2", ")", "==", "0", "\n", "assert", "prob", ".", "size", "(", ")", "[", ":", "3", "]", "==", "v", ".", "size", "(", ")", "[", ":", "3", "]", "\n", "assert", "prob", ".", "size", "(", "3", ")", "==", "2", "*", "w", "+", "1", "\n", "chunks_count", "=", "seqlen", "//", "w", "-", "1", "\n", "# group bsz and num_heads dimensions into one, then chunk seqlen into chunks of size 2w", "\n", "chunk_prob", "=", "prob", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "bsz", "*", "num_heads", ",", "seqlen", "//", "w", ",", "w", ",", "2", "*", "w", "+", "1", ")", "\n", "\n", "# group bsz and num_heads dimensions into one", "\n", "v", "=", "v", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "bsz", "*", "num_heads", ",", "seqlen", ",", "head_dim", ")", "\n", "\n", "# pad seqlen with w at the beginning of the sequence and another w at the end", "\n", "padded_v", "=", "F", ".", "pad", "(", "v", ",", "(", "0", ",", "0", ",", "w", ",", "w", ")", ",", "value", "=", "-", "1", ")", "\n", "\n", "# chunk padded_v into chunks of size 3w and an overlap of size w", "\n", "chunk_v_size", "=", "(", "bsz", "*", "num_heads", ",", "chunks_count", "+", "1", ",", "3", "*", "w", ",", "head_dim", ")", "\n", "chunk_v_stride", "=", "padded_v", ".", "stride", "(", ")", "\n", "chunk_v_stride", "=", "chunk_v_stride", "[", "0", "]", ",", "w", "*", "chunk_v_stride", "[", "1", "]", ",", "chunk_v_stride", "[", "1", "]", ",", "chunk_v_stride", "[", "2", "]", "\n", "chunk_v", "=", "padded_v", ".", "as_strided", "(", "size", "=", "chunk_v_size", ",", "stride", "=", "chunk_v_stride", ")", "\n", "\n", "skewed_prob", "=", "_skew2", "(", "chunk_prob", ",", "padding_value", "=", "0", ")", "\n", "\n", "context", "=", "torch", ".", "einsum", "(", "'bcwd,bcdh->bcwh'", ",", "(", "skewed_prob", ",", "chunk_v", ")", ")", "\n", "return", "context", ".", "view", "(", "bsz", ",", "num_heads", ",", "seqlen", ",", "head_dim", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.pad_to_window_size": [[117, 134], ["int", "F.pad.size", "torch.pad", "torch.pad"], "function", ["None"], ["", "def", "pad_to_window_size", "(", "input_ids", ":", "torch", ".", "Tensor", ",", "attention_mask", ":", "torch", ".", "Tensor", ",", "\n", "one_sided_window_size", ":", "int", ",", "pad_token_id", ":", "int", ")", ":", "\n", "    ", "'''A helper function to pad tokens and mask to work with the sliding_chunks implementation of Longformer selfattention.\n    Input:\n        input_ids = torch.Tensor(bsz x seqlen): ids of wordpieces\n        attention_mask = torch.Tensor(bsz x seqlen): attention mask\n        one_sided_window_size = int: window size on one side of each token\n        pad_token_id = int: tokenizer.pad_token_id\n    Returns\n        (input_ids, attention_mask) padded to length divisible by 2 * one_sided_window_size\n    '''", "\n", "w", "=", "int", "(", "2", "*", "one_sided_window_size", ")", "\n", "seqlen", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "padding_len", "=", "(", "w", "-", "seqlen", "%", "w", ")", "%", "w", "\n", "input_ids", "=", "F", ".", "pad", "(", "input_ids", ",", "(", "0", ",", "padding_len", ")", ",", "value", "=", "pad_token_id", ")", "\n", "attention_mask", "=", "F", ".", "pad", "(", "attention_mask", ",", "(", "0", ",", "padding_len", ")", ",", "value", "=", "False", ")", "# no attention on the padding tokens", "\n", "return", "input_ids", ",", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk": [[150, 164], ["q.size", "q.view", "k.view", "torch.stack", "torch.stack", "torch.einsum", "torch.einsum", "torch.einsum.reshape", "q.size", "k.size", "torch.pad", "torch.pad"], "function", ["None"], ["", "def", "sliding_chunks_no_overlap_matmul_qk", "(", "q", ":", "torch", ".", "Tensor", ",", "k", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ",", "padding_value", ":", "float", ")", ":", "\n", "    ", "bsz", ",", "seqlen", ",", "num_heads", ",", "head_dim", "=", "q", ".", "size", "(", ")", "\n", "assert", "seqlen", "%", "w", "==", "0", "\n", "assert", "q", ".", "size", "(", ")", "==", "k", ".", "size", "(", ")", "\n", "# chunk seqlen into non-overlapping chunks of size w", "\n", "chunk_q", "=", "q", ".", "view", "(", "bsz", ",", "seqlen", "//", "w", ",", "w", ",", "num_heads", ",", "head_dim", ")", "\n", "chunk_k", "=", "k", ".", "view", "(", "bsz", ",", "seqlen", "//", "w", ",", "w", ",", "num_heads", ",", "head_dim", ")", "\n", "chunk_k_expanded", "=", "torch", ".", "stack", "(", "(", "\n", "F", ".", "pad", "(", "chunk_k", "[", ":", ",", ":", "-", "1", "]", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ")", ",", "value", "=", "0.0", ")", ",", "\n", "chunk_k", ",", "\n", "F", ".", "pad", "(", "chunk_k", "[", ":", ",", "1", ":", "]", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ")", ",", "value", "=", "0.0", ")", ",", "\n", ")", ",", "dim", "=", "-", "1", ")", "\n", "diagonal_attn", "=", "torch", ".", "einsum", "(", "'bcxhd,bcyhde->bcxhey'", ",", "(", "chunk_q", ",", "chunk_k_expanded", ")", ")", "# multiply", "\n", "return", "diagonal_attn", ".", "reshape", "(", "bsz", ",", "seqlen", ",", "num_heads", ",", "3", "*", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_pv": [[166, 177], ["v.size", "prob.view", "v.view", "torch.stack", "torch.stack", "torch.einsum", "torch.einsum", "torch.einsum.reshape", "torch.pad", "torch.pad"], "function", ["None"], ["", "def", "sliding_chunks_no_overlap_matmul_pv", "(", "prob", ":", "torch", ".", "Tensor", ",", "v", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ")", ":", "\n", "    ", "bsz", ",", "seqlen", ",", "num_heads", ",", "head_dim", "=", "v", ".", "size", "(", ")", "\n", "chunk_prob", "=", "prob", ".", "view", "(", "bsz", ",", "seqlen", "//", "w", ",", "w", ",", "num_heads", ",", "3", ",", "w", ")", "\n", "chunk_v", "=", "v", ".", "view", "(", "bsz", ",", "seqlen", "//", "w", ",", "w", ",", "num_heads", ",", "head_dim", ")", "\n", "chunk_v_extended", "=", "torch", ".", "stack", "(", "(", "\n", "F", ".", "pad", "(", "chunk_v", "[", ":", ",", ":", "-", "1", "]", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ")", ",", "value", "=", "0.0", ")", ",", "\n", "chunk_v", ",", "\n", "F", ".", "pad", "(", "chunk_v", "[", ":", ",", "1", ":", "]", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ")", ",", "value", "=", "0.0", ")", ",", "\n", ")", ",", "dim", "=", "-", "1", ")", "\n", "context", "=", "torch", ".", "einsum", "(", "'bcwhpd,bcdhep->bcwhe'", ",", "(", "chunk_prob", ",", "chunk_v_extended", ")", ")", "\n", "return", "context", ".", "reshape", "(", "bsz", ",", "seqlen", ",", "num_heads", ",", "head_dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._compile_function": [[15, 112], ["tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.var", "tvm.placeholder", "tvm.placeholder", "tvm.reduce_axis", "tvm.placeholder", "tvm.compute", "tvm.create_schedule", "print", "s[].split", "tvm.create_schedule.rfactor", "s[].split", "s[].split", "s[].bind", "s[].bind", "s[].bind", "s[].bind", "tvm.thread_axis", "s[].bind", "s[].compute_at", "s[].set_store_predicate", "print", "tvm.build", "nvcc.compile_cuda", "tvm.sum", "tvm.thread_axis", "tvm.thread_axis", "tvm.thread_axis", "tvm.thread_axis", "tvm.thread_axis.var.equal", "tvm.if_then_else", "tvm.lower", "tvm.lower", "tvm.if_then_else", "tvm.if_then_else", "tvm.if_then_else", "tvm.if_then_else", "tvm.all", "tvm.all", "tvm.all"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "_compile_function", "(", "dtype", ":", "str", ",", "device", ":", "str", ",", "b0", ":", "int", "=", "4", ",", "b1", ":", "int", "=", "4", ",", "b2", ":", "int", "=", "16", ")", ":", "\n", "        ", "'''Compiles a tvm function that computes diagonal_mm\n        args:\n        dtype: str in ['float64', 'float32', 'float16']\n        device: str in ['cpu' or 'cuda']\n        b0, b1, b2: size of tensor tiles. Very important for good performance\n\n        '''", "\n", "import", "tvm", "# import the full tvm library here for compilation. Don't import at the top of the file in case we don't need to compile", "\n", "from", "tvm", ".", "contrib", "import", "nvcc", "\n", "@", "tvm", ".", "register_func", "\n", "def", "tvm_callback_cuda_compile", "(", "code", ")", ":", "\n", "            ", "\"\"\"Use nvcc compiler for better perf.\"\"\"", "\n", "ptx", "=", "nvcc", ".", "compile_cuda", "(", "code", ",", "target", "=", "\"ptx\"", ",", "arch", "=", "'sm_52'", ")", "# use old arch for this to work on old GPUs", "\n", "return", "ptx", "\n", "\n", "", "assert", "dtype", "in", "[", "'float16'", ",", "'float32'", ",", "'float64'", "]", "\n", "assert", "device", "in", "[", "'cpu'", ",", "'cuda'", "]", "\n", "device", "=", "None", "if", "device", "==", "'cpu'", "else", "device", "\n", "tgt_host", "=", "\"llvm\"", "\n", "\n", "b", "=", "tvm", ".", "var", "(", "'b'", ")", "# batch size", "\n", "n", "=", "tvm", ".", "var", "(", "'n'", ")", "# sequence length", "\n", "h", "=", "tvm", ".", "var", "(", "'h'", ")", "# number of heads", "\n", "m", "=", "tvm", ".", "var", "(", "'m'", ")", "# hidden dimension", "\n", "w", "=", "tvm", ".", "var", "(", "'w'", ")", "# window size", "\n", "w_upper", "=", "tvm", ".", "var", "(", "'w_upper'", ")", "# window size to the right of the word. Should be `0` or `w`", "\n", "padding", "=", "tvm", ".", "var", "(", "'padding'", ")", "# padding", "\n", "transpose_t1", "=", "tvm", ".", "var", "(", "'transpose_t1'", ")", "# t1 should be transposed", "\n", "t1d3", "=", "tvm", ".", "var", "(", "'t1d3'", ")", "# last dimension of t1", "\n", "t3d3", "=", "tvm", ".", "var", "(", "'t3d3'", ")", "# last dimension of t3 (the result tensor)", "\n", "X", "=", "tvm", ".", "placeholder", "(", "(", "b", ",", "n", ",", "h", ",", "t1d3", ")", ",", "name", "=", "'X'", ",", "dtype", "=", "dtype", ")", "# first tensor", "\n", "Y", "=", "tvm", ".", "placeholder", "(", "(", "b", ",", "n", ",", "h", ",", "m", ")", ",", "name", "=", "'Y'", ",", "dtype", "=", "dtype", ")", "# second tensor", "\n", "k", "=", "tvm", ".", "reduce_axis", "(", "(", "0", ",", "t1d3", ")", ",", "name", "=", "'k'", ")", "# dimension to sum over", "\n", "D", "=", "tvm", ".", "placeholder", "(", "(", "h", ")", ",", "name", "=", "'D'", ",", "dtype", "=", "'int'", ")", "# dilation per head", "\n", "output_shape", "=", "(", "b", ",", "n", ",", "h", ",", "t3d3", ")", "# shape of the result tensor", "\n", "algorithm", "=", "lambda", "l", ",", "i", ",", "q", ",", "j", ":", "tvm", ".", "sum", "(", "\n", "tvm", ".", "if_then_else", "(", "\n", "t3d3", "==", "m", ",", "# if output dimension == m, then t1 is diagonaled (FIXME: This breaks if t3d3 == m == t1d3)", "\n", "tvm", ".", "if_then_else", "(", "\n", "transpose_t1", "==", "0", ",", "\n", "tvm", ".", "if_then_else", "(", "\n", "tvm", ".", "all", "(", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w", ")", ">=", "0", ",", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w", ")", "<", "n", ",", "\n", ")", ",", "\n", "X", "[", "l", ",", "i", ",", "q", ",", "k", "]", "*", "Y", "[", "l", ",", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w", ")", ",", "q", ",", "j", "]", ",", "# t1 is diagonaled", "\n", "padding", "\n", ")", ",", "\n", "tvm", ".", "if_then_else", "(", "\n", "tvm", ".", "all", "(", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w_upper", ")", ">=", "0", ",", "# `w_upper` to handle the case `autoregressive=True`", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w_upper", ")", "<", "n", ",", "\n", ")", ",", "\n", "X", "[", "l", ",", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w_upper", ")", ",", "q", ",", "(", "w_upper", "+", "w", ")", "-", "k", "]", "*", "Y", "[", "l", ",", "i", "+", "D", "[", "q", "]", "*", "(", "k", "-", "w_upper", ")", ",", "q", ",", "j", "]", ",", "# # t1 is diagonaled and should be transposed", "\n", "padding", "\n", ")", ",", "\n", ")", ",", "\n", "tvm", ".", "if_then_else", "(", "\n", "tvm", ".", "all", "(", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "j", "-", "w", ")", ">=", "0", ",", "\n", "i", "+", "D", "[", "q", "]", "*", "(", "j", "-", "w", ")", "<", "n", ",", "\n", ")", ",", "\n", "X", "[", "l", ",", "i", ",", "q", ",", "k", "]", "*", "Y", "[", "l", ",", "i", "+", "D", "[", "q", "]", "*", "(", "j", "-", "w", ")", ",", "q", ",", "k", "]", ",", "# t1 is not diagonaled, but the output tensor is going to be", "\n", "padding", "\n", ")", "\n", ")", ",", "axis", "=", "k", ")", "\n", "\n", "Z", "=", "tvm", ".", "compute", "(", "output_shape", ",", "algorithm", ",", "name", "=", "'Z'", ")", "# automatically generate cuda code", "\n", "s", "=", "tvm", ".", "create_schedule", "(", "Z", ".", "op", ")", "\n", "\n", "print", "(", "'Lowering: \\n ===================== \\n{}'", ".", "format", "(", "tvm", ".", "lower", "(", "s", ",", "[", "X", ",", "Y", ",", "D", "]", ",", "simple_mode", "=", "True", ")", ")", ")", "\n", "\n", "# split long axis into smaller chunks and assing each one to a separate GPU thread/block", "\n", "ko", ",", "ki", "=", "s", "[", "Z", "]", ".", "split", "(", "Z", ".", "op", ".", "reduce_axis", "[", "0", "]", ",", "factor", "=", "b0", ")", "\n", "ZF", "=", "s", ".", "rfactor", "(", "Z", ",", "ki", ")", "\n", "\n", "j_outer", ",", "j_inner", "=", "s", "[", "Z", "]", ".", "split", "(", "s", "[", "Z", "]", ".", "op", ".", "axis", "[", "-", "1", "]", ",", "factor", "=", "b1", ")", "\n", "i_outer", ",", "i_inner", "=", "s", "[", "Z", "]", ".", "split", "(", "s", "[", "Z", "]", ".", "op", ".", "axis", "[", "1", "]", ",", "factor", "=", "b2", ")", "\n", "\n", "s", "[", "Z", "]", ".", "bind", "(", "j_outer", ",", "tvm", ".", "thread_axis", "(", "\"blockIdx.x\"", ")", ")", "\n", "s", "[", "Z", "]", ".", "bind", "(", "j_inner", ",", "tvm", ".", "thread_axis", "(", "\"threadIdx.y\"", ")", ")", "\n", "\n", "s", "[", "Z", "]", ".", "bind", "(", "i_outer", ",", "tvm", ".", "thread_axis", "(", "\"blockIdx.y\"", ")", ")", "\n", "s", "[", "Z", "]", ".", "bind", "(", "i_inner", ",", "tvm", ".", "thread_axis", "(", "\"threadIdx.z\"", ")", ")", "\n", "\n", "tx", "=", "tvm", ".", "thread_axis", "(", "\"threadIdx.x\"", ")", "\n", "s", "[", "Z", "]", ".", "bind", "(", "s", "[", "Z", "]", ".", "op", ".", "reduce_axis", "[", "0", "]", ",", "tx", ")", "\n", "s", "[", "ZF", "]", ".", "compute_at", "(", "s", "[", "Z", "]", ",", "s", "[", "Z", "]", ".", "op", ".", "reduce_axis", "[", "0", "]", ")", "\n", "s", "[", "Z", "]", ".", "set_store_predicate", "(", "tx", ".", "var", ".", "equal", "(", "0", ")", ")", "\n", "\n", "print", "(", "'Lowering with GPU splits: \\n ===================== \\n{}'", ".", "format", "(", "tvm", ".", "lower", "(", "s", ",", "[", "X", ",", "Y", ",", "D", "]", ",", "simple_mode", "=", "True", ")", ")", ")", "\n", "\n", "# compiling the automatically generated cuda code", "\n", "diagonaled_mm", "=", "tvm", ".", "build", "(", "s", ",", "[", "X", ",", "Y", ",", "Z", ",", "D", ",", "w", ",", "w_upper", ",", "padding", ",", "transpose_t1", ",", "t3d3", "]", ",", "target", "=", "device", ",", "target_host", "=", "tgt_host", ",", "name", "=", "'diagonaled_mm'", ")", "\n", "return", "diagonaled_mm", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_lib_filename": [[113, 117], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_lib_filename", "(", "dtype", ":", "str", ",", "device", ":", "str", ")", ":", "\n", "        ", "base_filename", "=", "'longformer/lib/lib_diagonaled_mm'", "\n", "return", "'{}_{}_{}.so'", ".", "format", "(", "base_filename", ",", "dtype", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._save_compiled_function": [[118, 123], ["f.export_library", "os.path.exists", "os.makedirs", "diagonaled_mm_tvm.DiagonaledMM._get_lib_filename"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.export_library", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_lib_filename"], ["", "@", "staticmethod", "\n", "def", "_save_compiled_function", "(", "f", ",", "dtype", ":", "str", ",", "device", ":", "str", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "'longformer/lib/'", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "'longformer/lib/'", ")", "\n", "", "f", ".", "export_library", "(", "DiagonaledMM", ".", "_get_lib_filename", "(", "dtype", ",", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._load_compiled_function": [[124, 136], ["diagonaled_mm_tvm.DiagonaledMM._get_lib_filename", "os.path.dirname", "os.path.abspath", "os.path.isfile", "print", "load"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_lib_filename", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.load"], ["", "@", "staticmethod", "\n", "def", "_load_compiled_function", "(", "dtype", ":", "str", ",", "device", ":", "str", ")", ":", "\n", "        ", "from", "tvm", ".", "module", "import", "load", "# this can be the small runtime python library, and doesn't need to be the whole thing", "\n", "filename", "=", "DiagonaledMM", ".", "_get_lib_filename", "(", "dtype", ",", "device", ")", "\n", "current_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "potential_dirs", "=", "[", "'../../'", ",", "'../'", ",", "'./'", ",", "f'{current_dir}/'", ",", "f'{current_dir}/../'", "]", "\n", "for", "potential_dir", "in", "potential_dirs", ":", "\n", "            ", "filepath", "=", "'{}{}'", ".", "format", "(", "potential_dir", ",", "filename", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "filepath", ")", ":", "\n", "                ", "print", "(", "'Loading tvm binary from: {}'", ".", "format", "(", "filepath", ")", ")", "\n", "return", "load", "(", "filepath", ")", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_function": [[137, 154], ["diagonaled_mm_tvm.DiagonaledMM._load_compiled_function", "dlpack.to_pytorch_func", "print", "diagonaled_mm_tvm.DiagonaledMM._compile_function", "diagonaled_mm_tvm.DiagonaledMM._save_compiled_function"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._load_compiled_function", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.contrib.dlpack.to_pytorch_func", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._compile_function", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._save_compiled_function"], ["", "@", "staticmethod", "\n", "def", "_get_function", "(", "dtype", ":", "str", ",", "device", ":", "str", ")", ":", "\n", "        ", "'''Loads the function from the disk or compile it'''", "\n", "# A list of arguments that define the function", "\n", "args", "=", "(", "dtype", ",", "device", ")", "\n", "if", "args", "not", "in", "DiagonaledMM", ".", "function_dict", ":", "\n", "            ", "diagonaled_mm", "=", "DiagonaledMM", ".", "_load_compiled_function", "(", "dtype", ",", "device", ")", "# try to load from disk", "\n", "if", "not", "diagonaled_mm", ":", "\n", "                ", "print", "(", "'Tvm binary not found. Compiling ...'", ")", "\n", "diagonaled_mm", "=", "DiagonaledMM", ".", "_compile_function", "(", "dtype", ",", "device", ")", "# compile", "\n", "DiagonaledMM", ".", "_save_compiled_function", "(", "diagonaled_mm", ",", "dtype", ",", "device", ")", "# save to disk", "\n", "# convert the tvm function into a pytorch function", "\n", "", "from", "tvm", ".", "contrib", "import", "dlpack", "\n", "diagonaled_mm_pytorch", "=", "dlpack", ".", "to_pytorch_func", "(", "diagonaled_mm", ")", "# wrap it as a pytorch function", "\n", "# save the function into a dictionary to be reused", "\n", "DiagonaledMM", ".", "function_dict", "[", "args", "]", "=", "diagonaled_mm_pytorch", "# save it in a dictionary for next time", "\n", "", "return", "DiagonaledMM", ".", "function_dict", "[", "args", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm": [[155, 204], ["isinstance", "diagonaled_mm_tvm.DiagonaledMM._get_function", "diagonaled_mm_tvm.DiagonaledMM._get_function", "str().split", "len", "len", "len", "t1.new_full", "len", "t1.new_empty", "t1.new_empty", "print", "str"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_function", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._get_function"], ["", "@", "staticmethod", "\n", "def", "_diagonaled_mm", "(", "t1", ":", "torch", ".", "Tensor", ",", "t2", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ",", "d", ":", "Union", "[", "torch", ".", "Tensor", ",", "int", "]", ",", "\n", "is_t1_diagonaled", ":", "bool", "=", "False", ",", "transpose_t1", ":", "bool", "=", "False", ",", "padding", ":", "int", "=", "0", ",", "\n", "autoregressive", ":", "bool", "=", "False", ")", ":", "\n", "        ", "'''Calls the compiled function after checking the input format. This function is called in three different modes.\n        t1 x t2 = r ==> t1 and t2 are not diagonaled, but r is. Useful for query x key = attention_scores\n        t1 x t2 = r ==> t1 is diagonaled, but t2 and r are not. Useful to compuate attantion_scores x value = context\n        t1 x t2 = r ==> t1 is diagonaled and it should be transposed, but t2 and r are not diagonaled. Useful in some of\n                            the calculations in the backward pass.\n        '''", "\n", "dtype", "=", "str", "(", "t1", ".", "dtype", ")", ".", "split", "(", "'.'", ")", "[", "1", "]", "\n", "device", "=", "t1", ".", "device", ".", "type", "\n", "assert", "len", "(", "t1", ".", "shape", ")", "==", "4", "\n", "assert", "len", "(", "t1", ".", "shape", ")", "==", "len", "(", "t2", ".", "shape", ")", "\n", "assert", "t1", ".", "shape", "[", ":", "3", "]", "==", "t2", ".", "shape", "[", ":", "3", "]", "\n", "if", "isinstance", "(", "d", ",", "int", ")", ":", "# if d is an integer, replace it with a tensor of the same length", "\n", "# as number of heads, and it is filled with the same dilation value", "\n", "            ", "d", "=", "t1", ".", "new_full", "(", "size", "=", "(", "t1", ".", "shape", "[", "2", "]", ",", ")", ",", "fill_value", "=", "d", ",", "dtype", "=", "torch", ".", "int", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "assert", "len", "(", "d", ".", "shape", ")", "==", "1", "\n", "assert", "d", ".", "shape", "[", "0", "]", "==", "t1", ".", "shape", "[", "2", "]", "# number of dilation scores should match number of heads", "\n", "b", "=", "t1", ".", "shape", "[", "0", "]", "# batch size", "\n", "n", "=", "t1", ".", "shape", "[", "1", "]", "# sequence length", "\n", "h", "=", "t1", ".", "shape", "[", "2", "]", "# number of heads", "\n", "m", "=", "t2", ".", "shape", "[", "3", "]", "# hidden dimension", "\n", "w_upper", "=", "0", "if", "autoregressive", "else", "w", "\n", "c", "=", "w_upper", "+", "w", "+", "1", "# number of diagonals", "\n", "if", "is_t1_diagonaled", ":", "\n", "            ", "assert", "t1", ".", "shape", "[", "3", "]", "==", "c", "\n", "r", "=", "t1", ".", "new_empty", "(", "b", ",", "n", ",", "h", ",", "m", ")", "# allocate spase for the result tensor", "\n", "", "else", ":", "\n", "            ", "assert", "not", "transpose_t1", "\n", "assert", "t1", ".", "shape", "[", "3", "]", "==", "m", "\n", "r", "=", "t1", ".", "new_empty", "(", "b", ",", "n", ",", "h", ",", "c", ")", "# allocate spase for the result tensor", "\n", "\n", "# gets function from memory, from disk or compiles it from scratch", "\n", "", "_diagonaled_mm_function", "=", "DiagonaledMM", ".", "_get_function", "(", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "\n", "# The last argument to this function is a little hacky. It is the size of the last dimension of the result tensor", "\n", "# We use it as a proxy to tell if t1_is_diagonaled or not (if t1 is diagonaled, result is not, and vice versa).", "\n", "# The second reason is that the lambda expression in `_compile_function` is easier to express when the shape", "\n", "# of the output is known", "\n", "# This functions computes diagonal_mm then saves the result in `r`", "\n", "if", "m", "==", "c", ":", "\n", "# FIXME", "\n", "            ", "print", "(", "'Error: the hidden dimension {m} shouldn\\'t match number of diagonals {c}'", ")", "\n", "assert", "False", "\n", "", "_diagonaled_mm_function", "(", "t1", ",", "t2", ",", "r", ",", "d", ",", "w", ",", "w_upper", ",", "padding", ",", "transpose_t1", ",", "m", "if", "is_t1_diagonaled", "else", "c", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors": [[205, 229], ["t.as_strided.as_strided.is_contiguous", "list", "list", "t.as_strided.as_strided.stride", "t.as_strided.as_strided.size", "t.as_strided.as_strided.as_strided"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_prepare_tensors", "(", "t", ")", ":", "\n", "        ", "'''Fix `stride()` information of input tensor. This addresses some inconsistency in stride information in PyTorch.\n        For a tensor t, if t.size(0) == 1, then the value of t.stride()[0] doesn't matter.\n        TVM expects this value to be the `product(t.size()[1:])` but PyTorch some times sets it to `t.stride()[1]`.\n        Here's an example to reporduce this issue:\n            import torch\n            print(torch.randn(1, 10).stride())\n            > (10, 1)\n            print(torch.randn(10, 1).t().contiguous().stride())\n            > (1, 1)  # expected it to be (10, 1) as above\n            print(torch.randn(10, 2).t().contiguous().stride())\n            > (10, 1) # but gets the expected stride if the first dimension is > 1\n        '''", "\n", "assert", "t", ".", "is_contiguous", "(", ")", "\n", "t_stride", "=", "list", "(", "t", ".", "stride", "(", ")", ")", "\n", "t_size", "=", "list", "(", "t", ".", "size", "(", ")", ")", "\n", "# Fix wrong stride information for the first dimension. This occures when batch_size=1", "\n", "if", "t_size", "[", "0", "]", "==", "1", "and", "t_stride", "[", "0", "]", "==", "t_stride", "[", "1", "]", ":", "\n", "# In this case, the stride of the first dimension should be the product", "\n", "# of the sizes  of all other dimensions", "\n", "            ", "t_stride", "[", "0", "]", "=", "t_size", "[", "1", "]", "*", "t_size", "[", "2", "]", "*", "t_size", "[", "3", "]", "\n", "t", "=", "t", ".", "as_strided", "(", "size", "=", "t_size", ",", "stride", "=", "t_stride", ")", "\n", "", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM.forward": [[232, 263], ["diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "ctx.save_for_backward", "diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "t1", ":", "torch", ".", "Tensor", ",", "t2", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ",", "d", ":", "Union", "[", "torch", ".", "Tensor", ",", "int", "]", ",", "is_t1_diagonaled", ":", "bool", "=", "False", ",", "padding", ":", "int", "=", "0", ",", "autoregressive", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "'''Compuates diagonal_mm of t1 and t2.\n        args: \n        t1: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size|number_of_diagonals).\n            t1 can be a regular tensor (e.g. `query_layer`) or a diagonaled one (e.g. `attention_scores`)\n        t2: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size). This is always a non-diagonaled\n            tensor, e.g. `key_layer` or `value_layer`\n        w: int = window size; number of attentions on each side of the word\n        d: torch.Tensor or int = dilation of attentions per attention head. If int, the same dilation value will be used for all\n            heads. If torch.Tensor, it should be 1D of lenth=number of attention heads\n        is_t1_diagonaled: is t1 a diagonaled or a regular tensor\n        padding: the padding value to use when accessing invalid locations. This is mainly useful when the padding\n            needs to be a very large negative value (to compute softmax of attentions). For other usecases,\n            please use zero padding.\n        autoregressive: if true, return only the lower triangle\n        returns: torch.Tensor = (batch_size, seq_len, num_attention_heads, hidden_size|number_of_diagonals)\n            if t1 is diagonaed, result is non-diagonaled, and vice versa\n        '''", "\n", "batch_size", ",", "seq_len", ",", "num_attention_heads", ",", "hidden_size", "=", "t1", ".", "size", "(", ")", "\n", "assert", "seq_len", ">=", "DiagonaledMM", ".", "min_seq_len", ",", "'avoid splitting errors by using seq_len >= {}'", ".", "format", "(", "DiagonaledMM", ".", "min_seq_len", ")", "# FIXME", "\n", "ctx", ".", "save_for_backward", "(", "t1", ",", "t2", ")", "\n", "ctx", ".", "w", "=", "w", "\n", "ctx", ".", "d", "=", "d", "\n", "ctx", ".", "is_t1_diagonaled", "=", "is_t1_diagonaled", "\n", "ctx", ".", "autoregressive", "=", "autoregressive", "\n", "t1", "=", "DiagonaledMM", ".", "_prepare_tensors", "(", "t1", ")", "\n", "t2", "=", "DiagonaledMM", ".", "_prepare_tensors", "(", "t2", ")", "\n", "# output = t1.mm(t2)  # what would have been called if this was a regular matmul", "\n", "output", "=", "DiagonaledMM", ".", "_diagonaled_mm", "(", "t1", ",", "t2", ",", "w", ",", "d", ",", "is_t1_diagonaled", "=", "is_t1_diagonaled", ",", "padding", "=", "padding", ",", "autoregressive", "=", "autoregressive", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM.backward": [[264, 286], ["diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm", "grad_output.contiguous.contiguous.is_contiguous", "grad_output.contiguous.contiguous.contiguous", "diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm", "diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._prepare_tensors", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.DiagonaledMM._diagonaled_mm"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "t1", ",", "t2", "=", "ctx", ".", "saved_tensors", "\n", "w", "=", "ctx", ".", "w", "\n", "d", "=", "ctx", ".", "d", "\n", "is_t1_diagonaled", "=", "ctx", ".", "is_t1_diagonaled", "\n", "autoregressive", "=", "ctx", ".", "autoregressive", "\n", "if", "not", "grad_output", ".", "is_contiguous", "(", ")", ":", "\n", "            ", "grad_output", "=", "grad_output", ".", "contiguous", "(", ")", "# tvm requires all input tensors to be contiguous", "\n", "", "grad_output", "=", "DiagonaledMM", ".", "_prepare_tensors", "(", "grad_output", ")", "\n", "t1", "=", "DiagonaledMM", ".", "_prepare_tensors", "(", "t1", ")", "\n", "t2", "=", "DiagonaledMM", ".", "_prepare_tensors", "(", "t2", ")", "\n", "# http://cs231n.github.io/optimization-2/", "\n", "# https://pytorch.org/docs/master/notes/extending.html", "\n", "# grad_t1 = grad_output.mm(t2)  # what would have been called if this was a regular matmul", "\n", "grad_t1", "=", "DiagonaledMM", ".", "_diagonaled_mm", "(", "grad_output", ",", "t2", ",", "w", ",", "d", ",", "is_t1_diagonaled", "=", "not", "is_t1_diagonaled", ",", "autoregressive", "=", "autoregressive", ")", "\n", "# grad_t2 = grad_output.t().mm(t1)  # or `grad_t2 = t1.t().mm(grad_output).t()` because `(AB)^T = B^TA^T`", "\n", "if", "is_t1_diagonaled", ":", "\n", "            ", "grad_t2", "=", "DiagonaledMM", ".", "_diagonaled_mm", "(", "t1", ",", "grad_output", ",", "w", ",", "d", ",", "is_t1_diagonaled", "=", "True", ",", "transpose_t1", "=", "True", ",", "autoregressive", "=", "autoregressive", ")", "\n", "", "else", ":", "\n", "            ", "grad_t2", "=", "DiagonaledMM", ".", "_diagonaled_mm", "(", "grad_output", ",", "t1", ",", "w", ",", "d", ",", "is_t1_diagonaled", "=", "True", ",", "transpose_t1", "=", "True", ",", "autoregressive", "=", "autoregressive", ")", "\n", "", "return", "grad_t1", ",", "grad_t2", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm._get_invalid_locations_mask_fixed_dilation": [[288, 295], ["range", "torch.stack", "torch.zeros", "diagonals_list.append"], "function", ["None"], ["", "", "def", "_get_invalid_locations_mask_fixed_dilation", "(", "seq_len", ":", "int", ",", "w", ":", "int", ",", "d", ":", "int", ")", ":", "\n", "    ", "diagonals_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "-", "d", "*", "w", ",", "d", ",", "d", ")", ":", "\n", "        ", "diagonal_mask", "=", "torch", ".", "zeros", "(", "seq_len", ",", "device", "=", "'cpu'", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "diagonal_mask", "[", ":", "-", "j", "]", "=", "1", "\n", "diagonals_list", ".", "append", "(", "diagonal_mask", ")", "\n", "", "return", "torch", ".", "stack", "(", "diagonals_list", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm._get_invalid_locations_mask": [[296, 314], ["functools.lru_cache", "isinstance", "diagonaled_mm_tvm._get_invalid_locations_mask_fixed_dilation", "d.cpu().numpy().tolist", "torch.stack", "torch.stack.flip().bool().to", "torch.stack.bool().to", "d.max", "diagonaled_mm_tvm._get_invalid_locations_mask_fixed_dilation", "head_masks.append", "d.cpu().numpy", "torch.stack.flip().bool", "torch.stack.bool", "d.cpu", "torch.stack.flip"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm._get_invalid_locations_mask_fixed_dilation", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.to", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.to", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm._get_invalid_locations_mask_fixed_dilation", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.cpu"], ["", "@", "lru_cache", "(", ")", "\n", "def", "_get_invalid_locations_mask", "(", "w", ":", "int", ",", "d", ":", "Union", "[", "torch", ".", "Tensor", ",", "int", "]", ",", "autoregressive", ":", "bool", ",", "device", ":", "str", ")", ":", "\n", "    ", "if", "isinstance", "(", "d", ",", "int", ")", ":", "\n", "        ", "affected_seq_len", "=", "w", "*", "d", "\n", "mask", "=", "_get_invalid_locations_mask_fixed_dilation", "(", "affected_seq_len", ",", "w", ",", "d", ")", "\n", "mask", "=", "mask", "[", "None", ",", ":", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "        ", "affected_seq_len", "=", "w", "*", "d", ".", "max", "(", ")", "\n", "head_masks", "=", "[", "]", "\n", "d_list", "=", "d", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "for", "d", "in", "d_list", ":", "\n", "            ", "one_head_mask", "=", "_get_invalid_locations_mask_fixed_dilation", "(", "affected_seq_len", ",", "w", ",", "d", ")", "\n", "head_masks", ".", "append", "(", "one_head_mask", ")", "\n", "", "mask", "=", "torch", ".", "stack", "(", "head_masks", ",", "dim", "=", "-", "2", ")", "\n", "mask", "=", "mask", "[", "None", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "", "ending_mask", "=", "None", "if", "autoregressive", "else", "mask", ".", "flip", "(", "dims", "=", "(", "1", ",", "3", ")", ")", ".", "bool", "(", ")", ".", "to", "(", "device", ")", "\n", "return", "affected_seq_len", ",", "mask", ".", "bool", "(", ")", ".", "to", "(", "device", ")", ",", "ending_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.mask_invalid_locations": [[315, 325], ["diagonaled_mm_tvm._get_invalid_locations_mask", "input_tensor.size", "beginning_mask[].expand", "beginning_input.masked_fill_", "beginning_input.size", "ending_mask[].expand", "ending_input.masked_fill_", "float", "ending_input.size", "float"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm._get_invalid_locations_mask"], ["", "def", "mask_invalid_locations", "(", "input_tensor", ":", "torch", ".", "Tensor", ",", "w", ":", "int", ",", "d", ":", "Union", "[", "torch", ".", "Tensor", ",", "int", "]", ",", "autoregressive", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "affected_seq_len", ",", "beginning_mask", ",", "ending_mask", "=", "_get_invalid_locations_mask", "(", "w", ",", "d", ",", "autoregressive", ",", "input_tensor", ".", "device", ")", "\n", "seq_len", "=", "input_tensor", ".", "size", "(", "1", ")", "\n", "beginning_input", "=", "input_tensor", "[", ":", ",", ":", "affected_seq_len", ",", ":", ",", ":", "w", "+", "1", "]", "\n", "beginning_mask", "=", "beginning_mask", "[", ":", ",", ":", "seq_len", "]", ".", "expand", "(", "beginning_input", ".", "size", "(", ")", ")", "\n", "beginning_input", ".", "masked_fill_", "(", "beginning_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "if", "not", "autoregressive", ":", "\n", "        ", "ending_input", "=", "input_tensor", "[", ":", ",", "-", "affected_seq_len", ":", ",", ":", ",", "-", "(", "w", "+", "1", ")", ":", "]", "\n", "ending_mask", "=", "ending_mask", "[", ":", ",", "-", "seq_len", ":", "]", ".", "expand", "(", "ending_input", ".", "size", "(", ")", ")", "\n", "ending_input", ".", "masked_fill_", "(", "ending_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer.Longformer.__init__": [[13, 20], ["transformers.modeling_roberta.RobertaModel.__init__", "enumerate", "longformer.LongformerSelfAttention"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Longformer", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "if", "config", ".", "attention_mode", "==", "'n2'", ":", "\n", "            ", "pass", "# do nothing, use BertSelfAttention instead", "\n", "", "else", ":", "\n", "            ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "encoder", ".", "layer", ")", ":", "\n", "                ", "layer", ".", "attention", ".", "self", "=", "LongformerSelfAttention", "(", "config", ",", "layer_id", "=", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer.LongformerForMaskedLM.__init__": [[23, 30], ["transformers.modeling_roberta.RobertaForMaskedLM.__init__", "enumerate", "longformer.LongformerSelfAttention"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "LongformerForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "if", "config", ".", "attention_mode", "==", "'n2'", ":", "\n", "            ", "pass", "# do nothing, use BertSelfAttention instead", "\n", "", "else", ":", "\n", "            ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "roberta", ".", "encoder", ".", "layer", ")", ":", "\n", "                ", "layer", ".", "attention", ".", "self", "=", "LongformerSelfAttention", "(", "config", ",", "layer_id", "=", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer.LongformerConfig.__init__": [[33, 53], ["transformers.modeling_roberta.RobertaConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_window", ":", "List", "[", "int", "]", "=", "None", ",", "attention_dilation", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "autoregressive", ":", "bool", "=", "False", ",", "attention_mode", ":", "str", "=", "'sliding_chunks'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            attention_window: list of attention window sizes of length = number of layers.\n                window size = number of attention locations on each side.\n                For an affective window size of 512, use `attention_window=[256]*num_layers`\n                which is 256 on each side.\n            attention_dilation: list of attention dilation of length = number of layers.\n                attention dilation of `1` means no dilation.\n            autoregressive: do autoregressive attention or have attention of both sides\n            attention_mode: 'n2' for regular n^2 self-attention, 'tvm' for TVM implemenation of Longformer\n                selfattention, 'sliding_chunks' for another implementation of Longformer selfattention\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention_window", "=", "attention_window", "\n", "self", ".", "attention_dilation", "=", "attention_dilation", "\n", "self", ".", "autoregressive", "=", "autoregressive", "\n", "self", ".", "attention_mode", "=", "attention_mode", "\n", "assert", "self", ".", "attention_mode", "in", "[", "'tvm'", ",", "'sliding_chunks'", ",", "'n2'", ",", "'sliding_chunks_no_overlap'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer.LongformerSelfAttention.__init__": [[56, 87], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "layer_id", ")", ":", "\n", "        ", "super", "(", "LongformerSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "head_dim", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "hidden_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "query_global", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "key_global", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "value_global", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "attention_probs_dropout_prob", "\n", "\n", "self", ".", "layer_id", "=", "layer_id", "\n", "self", ".", "attention_window", "=", "config", ".", "attention_window", "[", "self", ".", "layer_id", "]", "\n", "self", ".", "attention_dilation", "=", "config", ".", "attention_dilation", "[", "self", ".", "layer_id", "]", "\n", "self", ".", "attention_mode", "=", "config", ".", "attention_mode", "\n", "self", ".", "autoregressive", "=", "config", ".", "autoregressive", "\n", "assert", "self", ".", "attention_window", ">", "0", "\n", "assert", "self", ".", "attention_dilation", ">", "0", "\n", "assert", "self", ".", "attention_mode", "in", "[", "'tvm'", ",", "'sliding_chunks'", ",", "'sliding_chunks_no_overlap'", "]", "\n", "if", "self", ".", "attention_mode", "in", "[", "'sliding_chunks'", ",", "'sliding_chunks_no_overlap'", "]", ":", "\n", "            ", "assert", "not", "self", ".", "autoregressive", "# not supported", "\n", "assert", "self", ".", "attention_dilation", "==", "1", "# dilation is not supported", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer.LongformerSelfAttention.forward": [[88, 270], ["hidden_states.transpose.transpose.transpose", "hidden_states.transpose.transpose.size", "longformer.LongformerSelfAttention.query", "longformer.LongformerSelfAttention.key", "longformer.LongformerSelfAttention.value", "math.sqrt", "q.contiguous().view().transpose.contiguous().view().transpose.view().transpose", "k.contiguous().view().transpose.contiguous().view().transpose.view().transpose", "longformer.diagonaled_mm_tvm.mask_invalid_locations", "torch.softmax", "torch.softmax", "torch.softmax.type_as", "torch.dropout", "torch.dropout", "v.contiguous().view().transpose.contiguous().view().transpose.view().transpose", "torch.matmul().transpose.type_as", "torch.matmul().transpose.type_as", "torch.matmul().transpose.transpose().reshape().contiguous", "torch.matmul().transpose.transpose().reshape().contiguous", "torch.matmul().transpose.transpose", "torch.matmul().transpose.transpose", "attention_mask.squeeze().squeeze.squeeze().squeeze.squeeze().squeeze", "extra_attention_mask.long().sum", "extra_attention_mask.long().sum.max", "q.contiguous().view().transpose.contiguous().view().transpose.float().contiguous", "k.contiguous().view().transpose.contiguous().view().transpose.float().contiguous", "longformer.diagonaled_mm_tvm.diagonaled_mm", "remove_from_windowed_attention_mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "remove_from_windowed_attention_mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.type_as().masked_fill", "float_mask.repeat.repeat.repeat", "float_mask.repeat.repeat.new_ones", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.size", "k.contiguous().view().transpose.contiguous().view().transpose.new_zeros", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.masked_fill", "torch.softmax.type_as", "torch.dropout.narrow", "v.contiguous().view().transpose.contiguous().view().transpose.new_zeros", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.dropout.narrow().contiguous", "v.contiguous().view().transpose.contiguous().view().transpose.float().contiguous", "longformer.diagonaled_mm_tvm.diagonaled_mm", "list", "hidden_states.transpose.transpose.new_zeros", "longformer.LongformerSelfAttention.query_global", "longformer.LongformerSelfAttention.key_global", "longformer.LongformerSelfAttention.value_global", "math.sqrt", "q.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "k.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "v.contiguous().view().transpose.contiguous().view().transpose.contiguous().view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.view", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.view", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.view", "torch.bmm.view", "nonzero_selected_attn.view().type_as", "extra_attention_mask.nonzero", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "selection_padding_mask.nonzero", "q.contiguous().view().transpose.contiguous().view().transpose.view", "k.contiguous().view().transpose.contiguous().view().transpose.view", "longformer.sliding_chunks.sliding_chunks_matmul_qk", "isinstance", "len", "longformer.diagonaled_mm_tvm.diagonaled_mm", "list", "key_padding_mask.unsqueeze().unsqueeze", "v.contiguous().view().transpose.contiguous().view().transpose.view", "longformer.sliding_chunks.sliding_chunks_matmul_pv", "torch.matmul().transpose.size", "torch.matmul().transpose.size", "torch.matmul().transpose.transpose().reshape", "torch.matmul().transpose.transpose().reshape", "k.contiguous().view().transpose.contiguous().view().transpose.transpose", "list", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.masked_fill", "torch.softmax.type_as", "list", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.view", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.permute", "attention_mask.squeeze().squeeze.squeeze().squeeze.squeeze", "extra_attention_mask.long", "extra_attention_mask.long().sum.unsqueeze", "q.contiguous().view().transpose.contiguous().view().transpose.float", "k.contiguous().view().transpose.contiguous().view().transpose.float", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk", "remove_from_windowed_attention_mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "remove_from_windowed_attention_mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.type_as", "float_mask.repeat.repeat.size", "longformer.sliding_chunks.sliding_chunks_matmul_qk", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.dropout.narrow", "v.contiguous().view().transpose.contiguous().view().transpose.float", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_pv", "q.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "k.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "v.contiguous().view().transpose.contiguous().view().transpose.contiguous().view", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk.size", "key_padding_mask.unsqueeze().unsqueeze", "torch.bmm.size", "torch.bmm.size", "nonzero_selected_attn.view", "longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk", "key_padding_mask.unsqueeze", "F.dropout.narrow.transpose", "v.contiguous().view().transpose.new_zeros.transpose().type_as", "torch.matmul().transpose.transpose", "torch.matmul().transpose.transpose", "len", "torch.dropout.size", "q.contiguous().view().transpose.contiguous().view().transpose.contiguous", "k.contiguous().view().transpose.contiguous().view().transpose.contiguous", "v.contiguous().view().transpose.contiguous().view().transpose.contiguous", "key_padding_mask.unsqueeze", "v.contiguous().view().transpose.new_zeros.transpose"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.diagonaled_mm_tvm.mask_invalid_locations", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_matmul_qk", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_matmul_pv", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_matmul_qk", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_pv", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.sliding_chunks_no_overlap_matmul_qk"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "'''\n        The `attention_mask` is changed in `BertModel.forward` from 0, 1, 2 to\n            -ve: no attention\n              0: local attention\n            +ve: global attention\n        '''", "\n", "assert", "encoder_hidden_states", "is", "None", ",", "\"`encoder_hidden_states` is not supported and should be None\"", "\n", "assert", "encoder_attention_mask", "is", "None", ",", "\"`encoder_attention_mask` is not supported and shiould be None\"", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "squeeze", "(", "dim", "=", "2", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "key_padding_mask", "=", "attention_mask", "<", "0", "\n", "extra_attention_mask", "=", "attention_mask", ">", "0", "\n", "remove_from_windowed_attention_mask", "=", "attention_mask", "!=", "0", "\n", "\n", "num_extra_indices_per_batch", "=", "extra_attention_mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "max_num_extra_indices_per_batch", "=", "num_extra_indices_per_batch", ".", "max", "(", ")", "\n", "if", "max_num_extra_indices_per_batch", "<=", "0", ":", "\n", "                ", "extra_attention_mask", "=", "None", "\n", "", "else", ":", "\n", "# To support the case of variable number of global attention in the rows of a batch,", "\n", "# we use the following three selection masks to select global attention embeddings", "\n", "# in a 3d tensor and pad it to `max_num_extra_indices_per_batch`", "\n", "# 1) selecting embeddings that correspond to global attention", "\n", "                ", "extra_attention_mask_nonzeros", "=", "extra_attention_mask", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "zero_to_max_range", "=", "torch", ".", "arange", "(", "0", ",", "max_num_extra_indices_per_batch", ",", "\n", "device", "=", "num_extra_indices_per_batch", ".", "device", ")", "\n", "# mask indicating which values are actually going to be padding", "\n", "selection_padding_mask", "=", "zero_to_max_range", "<", "num_extra_indices_per_batch", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", "\n", "# 2) location of the non-padding values in the selected global attention", "\n", "selection_padding_mask_nonzeros", "=", "selection_padding_mask", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "# 3) location of the padding values in the selected global attention", "\n", "selection_padding_mask_zeros", "=", "(", "selection_padding_mask", "==", "0", ")", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "", "", "else", ":", "\n", "            ", "remove_from_windowed_attention_mask", "=", "None", "\n", "extra_attention_mask", "=", "None", "\n", "key_padding_mask", "=", "None", "\n", "\n", "", "hidden_states", "=", "hidden_states", ".", "transpose", "(", "0", ",", "1", ")", "\n", "seq_len", ",", "bsz", ",", "embed_dim", "=", "hidden_states", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "q", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "k", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "v", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "q", "/=", "math", ".", "sqrt", "(", "self", ".", "head_dim", ")", "\n", "\n", "q", "=", "q", ".", "view", "(", "seq_len", ",", "bsz", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "view", "(", "seq_len", ",", "bsz", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# attn_weights = (bsz, seq_len, num_heads, window*2+1)", "\n", "if", "self", ".", "attention_mode", "==", "'tvm'", ":", "\n", "            ", "q", "=", "q", ".", "float", "(", ")", ".", "contiguous", "(", ")", "\n", "k", "=", "k", ".", "float", "(", ")", ".", "contiguous", "(", ")", "\n", "attn_weights", "=", "diagonaled_mm_tvm", "(", "q", ",", "k", ",", "self", ".", "attention_window", ",", "self", ".", "attention_dilation", ",", "False", ",", "0", ",", "False", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks\"", ":", "\n", "            ", "attn_weights", "=", "sliding_chunks_matmul_qk", "(", "q", ",", "k", ",", "self", ".", "attention_window", ",", "padding_value", "=", "0", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks_no_overlap\"", ":", "\n", "            ", "attn_weights", "=", "sliding_chunks_no_overlap_matmul_qk", "(", "q", ",", "k", ",", "self", ".", "attention_window", ",", "padding_value", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "False", "\n", "", "mask_invalid_locations", "(", "attn_weights", ",", "self", ".", "attention_window", ",", "self", ".", "attention_dilation", ",", "False", ")", "\n", "if", "remove_from_windowed_attention_mask", "is", "not", "None", ":", "\n", "# This implementation is fast and takes very little memory because num_heads x hidden_size = 1", "\n", "# from (bsz x seq_len) to (bsz x seq_len x num_heads x hidden_size)", "\n", "            ", "remove_from_windowed_attention_mask", "=", "remove_from_windowed_attention_mask", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", "\n", "# cast to float/half then replace 1's with -inf", "\n", "float_mask", "=", "remove_from_windowed_attention_mask", ".", "type_as", "(", "q", ")", ".", "masked_fill", "(", "remove_from_windowed_attention_mask", ",", "-", "10000.0", ")", "\n", "repeat_size", "=", "1", "if", "isinstance", "(", "self", ".", "attention_dilation", ",", "int", ")", "else", "len", "(", "self", ".", "attention_dilation", ")", "\n", "float_mask", "=", "float_mask", ".", "repeat", "(", "1", ",", "1", ",", "repeat_size", ",", "1", ")", "\n", "ones", "=", "float_mask", ".", "new_ones", "(", "size", "=", "float_mask", ".", "size", "(", ")", ")", "# tensor of ones", "\n", "# diagonal mask with zeros everywhere and -inf inplace of padding", "\n", "if", "self", ".", "attention_mode", "==", "'tvm'", ":", "\n", "                ", "d_mask", "=", "diagonaled_mm_tvm", "(", "ones", ",", "float_mask", ",", "self", ".", "attention_window", ",", "self", ".", "attention_dilation", ",", "False", ",", "0", ",", "False", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks\"", ":", "\n", "                ", "d_mask", "=", "sliding_chunks_matmul_qk", "(", "ones", ",", "float_mask", ",", "self", ".", "attention_window", ",", "padding_value", "=", "0", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks_no_overlap\"", ":", "\n", "                ", "d_mask", "=", "sliding_chunks_no_overlap_matmul_qk", "(", "ones", ",", "float_mask", ",", "self", ".", "attention_window", ",", "padding_value", "=", "0", ")", "\n", "\n", "", "attn_weights", "+=", "d_mask", "\n", "", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "[", ":", "3", "]", "==", "[", "bsz", ",", "seq_len", ",", "self", ".", "num_heads", "]", "\n", "assert", "attn_weights", ".", "size", "(", "dim", "=", "3", ")", "in", "[", "self", ".", "attention_window", "*", "2", "+", "1", ",", "self", ".", "attention_window", "*", "3", "]", "\n", "\n", "# the extra attention", "\n", "if", "extra_attention_mask", "is", "not", "None", ":", "\n", "            ", "selected_k", "=", "k", ".", "new_zeros", "(", "bsz", ",", "max_num_extra_indices_per_batch", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "selected_k", "[", "selection_padding_mask_nonzeros", "]", "=", "k", "[", "extra_attention_mask_nonzeros", "]", "\n", "# (bsz, seq_len, num_heads, max_num_extra_indices_per_batch)", "\n", "selected_attn_weights", "=", "torch", ".", "einsum", "(", "'blhd,bshd->blhs'", ",", "(", "q", ",", "selected_k", ")", ")", "\n", "selected_attn_weights", "[", "selection_padding_mask_zeros", "[", "0", "]", ",", ":", ",", ":", ",", "selection_padding_mask_zeros", "[", "1", "]", "]", "=", "-", "10000", "\n", "# concat to attn_weights", "\n", "# (bsz, seq_len, num_heads, extra attention count + 2*window+1)", "\n", "attn_weights", "=", "torch", ".", "cat", "(", "(", "selected_attn_weights", ",", "attn_weights", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "attn_weights_float", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "# use fp32 for numerical stability", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# softmax sometimes inserts NaN if all positions are masked, replace them with 0", "\n", "            ", "attn_weights_float", "=", "torch", ".", "masked_fill", "(", "attn_weights_float", ",", "key_padding_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "0.0", ")", "\n", "", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "v", "=", "v", ".", "view", "(", "seq_len", ",", "bsz", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "0", "\n", "if", "extra_attention_mask", "is", "not", "None", ":", "\n", "            ", "selected_attn_probs", "=", "attn_probs", ".", "narrow", "(", "-", "1", ",", "0", ",", "max_num_extra_indices_per_batch", ")", "\n", "selected_v", "=", "v", ".", "new_zeros", "(", "bsz", ",", "max_num_extra_indices_per_batch", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", "\n", "selected_v", "[", "selection_padding_mask_nonzeros", "]", "=", "v", "[", "extra_attention_mask_nonzeros", "]", "\n", "# use `matmul` because `einsum` crashes sometimes with fp16", "\n", "# attn = torch.einsum('blhs,bshd->blhd', (selected_attn_probs, selected_v))", "\n", "attn", "=", "torch", ".", "matmul", "(", "selected_attn_probs", ".", "transpose", "(", "1", ",", "2", ")", ",", "selected_v", ".", "transpose", "(", "1", ",", "2", ")", ".", "type_as", "(", "selected_attn_probs", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "attn_probs", "=", "attn_probs", ".", "narrow", "(", "-", "1", ",", "max_num_extra_indices_per_batch", ",", "attn_probs", ".", "size", "(", "-", "1", ")", "-", "max_num_extra_indices_per_batch", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "self", ".", "attention_mode", "==", "'tvm'", ":", "\n", "            ", "v", "=", "v", ".", "float", "(", ")", ".", "contiguous", "(", ")", "\n", "attn", "+=", "diagonaled_mm_tvm", "(", "attn_probs", ",", "v", ",", "self", ".", "attention_window", ",", "self", ".", "attention_dilation", ",", "True", ",", "0", ",", "False", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks\"", ":", "\n", "            ", "attn", "+=", "sliding_chunks_matmul_pv", "(", "attn_probs", ",", "v", ",", "self", ".", "attention_window", ")", "\n", "", "elif", "self", ".", "attention_mode", "==", "\"sliding_chunks_no_overlap\"", ":", "\n", "            ", "attn", "+=", "sliding_chunks_no_overlap_matmul_pv", "(", "attn_probs", ",", "v", ",", "self", ".", "attention_window", ")", "\n", "", "else", ":", "\n", "            ", "raise", "False", "\n", "\n", "", "attn", "=", "attn", ".", "type_as", "(", "hidden_states", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", ",", "seq_len", ",", "self", ".", "num_heads", ",", "self", ".", "head_dim", "]", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "seq_len", ",", "bsz", ",", "embed_dim", ")", ".", "contiguous", "(", ")", "\n", "\n", "# For this case, we'll just recompute the attention for these indices", "\n", "# and overwrite the attn tensor. TODO: remove the redundant computation", "\n", "if", "extra_attention_mask", "is", "not", "None", ":", "\n", "            ", "selected_hidden_states", "=", "hidden_states", ".", "new_zeros", "(", "max_num_extra_indices_per_batch", ",", "bsz", ",", "embed_dim", ")", "\n", "selected_hidden_states", "[", "selection_padding_mask_nonzeros", "[", ":", ":", "-", "1", "]", "]", "=", "hidden_states", "[", "extra_attention_mask_nonzeros", "[", ":", ":", "-", "1", "]", "]", "\n", "\n", "q", "=", "self", ".", "query_global", "(", "selected_hidden_states", ")", "\n", "k", "=", "self", ".", "key_global", "(", "hidden_states", ")", "\n", "v", "=", "self", ".", "value_global", "(", "hidden_states", ")", "\n", "q", "/=", "math", ".", "sqrt", "(", "self", ".", "head_dim", ")", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "max_num_extra_indices_per_batch", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "# (bsz*self.num_heads, max_num_extra_indices_per_batch, head_dim)", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "# bsz * self.num_heads, seq_len, head_dim)", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "# bsz * self.num_heads, seq_len, head_dim)", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "seq_len", "]", "\n", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "seq_len", ")", "\n", "attn_weights", "[", "selection_padding_mask_zeros", "[", "0", "]", ",", ":", ",", "selection_padding_mask_zeros", "[", "1", "]", ",", ":", "]", "=", "-", "10000.0", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "-", "10000.0", ",", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "seq_len", ")", "\n", "attn_weights_float", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "# use fp32 for numerical stability", "\n", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "selected_attn", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "list", "(", "selected_attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "self", ".", "head_dim", "]", "\n", "\n", "selected_attn_4d", "=", "selected_attn", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "self", ".", "head_dim", ")", "\n", "nonzero_selected_attn", "=", "selected_attn_4d", "[", "selection_padding_mask_nonzeros", "[", "0", "]", ",", ":", ",", "selection_padding_mask_nonzeros", "[", "1", "]", "]", "\n", "attn", "[", "extra_attention_mask_nonzeros", "[", ":", ":", "-", "1", "]", "]", "=", "nonzero_selected_attn", ".", "view", "(", "len", "(", "selection_padding_mask_nonzeros", "[", "0", "]", ")", ",", "-", "1", ")", ".", "type_as", "(", "hidden_states", ")", "\n", "\n", "", "context_layer", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "output_attentions", ":", "\n", "            ", "if", "extra_attention_mask", "is", "not", "None", ":", "\n", "# With global attention, return global attention probabilities only", "\n", "# batch_size x num_heads x max_num_global_attention_tokens x sequence_length", "\n", "# which is the attention weights from tokens with global attention to all tokens", "\n", "# It doesn't not return local attention", "\n", "# In case of variable number of global attantion in the rows of a batch,", "\n", "# attn_weights are padded with -10000.0 attention scores", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "max_num_extra_indices_per_batch", ",", "seq_len", ")", "\n", "", "else", ":", "\n", "# without global attention, return local attention probabilities", "\n", "# batch_size x num_heads x sequence_length x window_size", "\n", "# which is the attention weights of every token attending to its neighbours", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "", "", "outputs", "=", "(", "context_layer", ",", "attn_weights", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer_encoder_decoder.LongformerEncoderDecoderForConditionalGeneration.__init__": [[8, 15], ["transformers.modeling_bart.BartForConditionalGeneration.__init__", "enumerate", "longformer_encoder_decoder.LongformerSelfAttentionForBart"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "if", "config", ".", "attention_mode", "==", "'n2'", ":", "\n", "            ", "pass", "# do nothing, use BertSelfAttention instead", "\n", "", "else", ":", "\n", "            ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ".", "encoder", ".", "layers", ")", ":", "\n", "                ", "layer", ".", "self_attn", "=", "LongformerSelfAttentionForBart", "(", "config", ",", "layer_id", "=", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer_encoder_decoder.LongformerEncoderDecoderConfig.__init__": [[18, 40], ["transformers.modeling_bart.BartConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_window", ":", "List", "[", "int", "]", "=", "None", ",", "attention_dilation", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "autoregressive", ":", "bool", "=", "False", ",", "attention_mode", ":", "str", "=", "'sliding_chunks'", ",", "\n", "gradient_checkpointing", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            attention_window: list of attention window sizes of length = number of layers.\n                window size = number of attention locations on each side.\n                For an affective window size of 512, use `attention_window=[256]*num_layers`\n                which is 256 on each side.\n            attention_dilation: list of attention dilation of length = number of layers.\n                attention dilation of `1` means no dilation.\n            autoregressive: do autoregressive attention or have attention of both sides\n            attention_mode: 'n2' for regular n^2 self-attention, 'tvm' for TVM implemenation of Longformer\n                selfattention, 'sliding_chunks' for another implementation of Longformer selfattention\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention_window", "=", "attention_window", "\n", "self", ".", "attention_dilation", "=", "attention_dilation", "\n", "self", ".", "autoregressive", "=", "autoregressive", "\n", "self", ".", "attention_mode", "=", "attention_mode", "\n", "self", ".", "gradient_checkpointing", "=", "gradient_checkpointing", "\n", "assert", "self", ".", "attention_mode", "in", "[", "'tvm'", ",", "'sliding_chunks'", ",", "'n2'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer_encoder_decoder.LongformerSelfAttentionForBart.__init__": [[43, 48], ["torch.nn.Module.__init__", "longformer.longformer.LongformerSelfAttention", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "layer_id", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "longformer_self_attn", "=", "LongformerSelfAttention", "(", "config", ",", "layer_id", "=", "layer_id", ")", "\n", "self", ".", "output", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.longformer_encoder_decoder.LongformerSelfAttentionForBart.forward": [[49, 77], ["query.size", "longformer_encoder_decoder.LongformerSelfAttentionForBart.longformer_self_attn", "longformer_encoder_decoder.LongformerSelfAttentionForBart.output", "list", "query.transpose", "outputs[].transpose", "query.size", "len", "key_padding_mask.unsqueeze().unsqueeze", "key_padding_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "layer_state", ":", "Optional", "[", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "=", "None", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "need_weights", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "\n", "        ", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "attn_mask", "is", "None", "\n", "\n", "outputs", "=", "self", ".", "longformer_self_attn", "(", "\n", "query", ".", "transpose", "(", "0", ",", "1", ")", ",", "# LongformerSelfAttention expects (bsz, seqlen, embd_dim)", "\n", "attention_mask", "=", "key_padding_mask", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "-", "1", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "\n", "attn_output", "=", "self", ".", "output", "(", "outputs", "[", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n", "return", "(", "attn_output", ",", ")", "+", "outputs", "[", "1", ":", "]", "if", "len", "(", "outputs", ")", "==", "2", "else", "(", "attn_output", ",", "None", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.__repr__": [[33, 35], ["None"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Module(%s, %x)\"", "%", "(", "self", ".", "type_key", ",", "self", ".", "handle", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.type_key": [[36, 40], ["_GetTypeKey"], "methods", ["None"], ["", "@", "property", "\n", "def", "type_key", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get type key of the module.\"\"\"", "\n", "return", "_GetTypeKey", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.get_source": [[41, 55], ["_GetSource"], "methods", ["None"], ["", "def", "get_source", "(", "self", ",", "fmt", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Get source code from module, if available.\n\n        Parameters\n        ----------\n        fmt : str, optional\n            The specified format.\n\n        Returns\n        -------\n        source : str\n            The result source code.\n        \"\"\"", "\n", "return", "_GetSource", "(", "self", ",", "fmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.imported_modules": [[56, 67], ["_ImportsSize", "_GetImport", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "imported_modules", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get imported modules\n\n        Returns\n        ----------\n        modules : list of Module\n            The module\n        \"\"\"", "\n", "nmod", "=", "_ImportsSize", "(", "self", ")", "\n", "return", "[", "_GetImport", "(", "self", ",", "i", ")", "for", "i", "in", "range", "(", "nmod", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.save": [[68, 86], ["_SaveToFile"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "file_name", ",", "fmt", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Save the module to file.\n\n        This do not save the dependent device modules.\n        See also export_shared\n\n        Parameters\n        ----------\n        file_name : str\n            The name of the file.\n        fmt : str\n            The format of the file.\n\n        See Also\n        --------\n        Module.export_library : export the module to shared library.\n        \"\"\"", "\n", "_SaveToFile", "(", "self", ",", "file_name", ",", "fmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.export_library": [[87, 148], ["isinstance", "_util.tempdir", "_util.tempdir.relpath", "module.Module.save", "fcompile", "str", "module.Module.save", "ValueError", "hasattr", "_util.tempdir.relpath", "files.append", "str.endswith", "kwargs.update", "str.endswith", "ValueError", "module.Module.get_function", "open", "f.write", "_PackImportsToC", "find_include_path"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.save", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.save", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.get_function", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.find_include_path"], ["", "def", "export_library", "(", "self", ",", "\n", "file_name", ",", "\n", "fcompile", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Export the module and its imported device code one library.\n\n        This function only works on host llvm modules.\n        It will pack all the imported modules\n\n        Parameters\n        ----------\n        file_name : str\n            The name of the shared library.\n\n        fcompile : function(target, file_list, kwargs), optional\n            Compilation function to use create dynamic library.\n            If fcompile has attribute object_format, will compile host library\n            to that format. Otherwise, will use default format \"o\".\n\n        kwargs : dict, optional\n            Additional arguments passed to fcompile\n        \"\"\"", "\n", "from", "pathlib", "import", "Path", "\n", "if", "isinstance", "(", "file_name", ",", "Path", ")", ":", "\n", "            ", "file_name", "=", "str", "(", "file_name", ")", "\n", "\n", "", "if", "self", ".", "type_key", "==", "\"stackvm\"", ":", "\n", "            ", "if", "not", "file_name", ".", "endswith", "(", "\".stackvm\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Module[%s]: can only be saved as stackvm format.\"", "\n", "\"did you build with LLVM enabled?\"", "%", "self", ".", "type_key", ")", "\n", "", "self", ".", "save", "(", "file_name", ")", "\n", "return", "\n", "\n", "", "if", "not", "(", "self", ".", "type_key", "==", "\"llvm\"", "or", "self", ".", "type_key", "==", "\"c\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Module[%s]: Only llvm and c support export shared\"", "%", "self", ".", "type_key", ")", "\n", "", "temp", "=", "_util", ".", "tempdir", "(", ")", "\n", "if", "fcompile", "is", "not", "None", "and", "hasattr", "(", "fcompile", ",", "\"object_format\"", ")", ":", "\n", "            ", "object_format", "=", "fcompile", ".", "object_format", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "type_key", "==", "\"llvm\"", ":", "\n", "                ", "object_format", "=", "\"o\"", "\n", "", "else", ":", "\n", "                ", "assert", "self", ".", "type_key", "==", "\"c\"", "\n", "object_format", "=", "\"cc\"", "\n", "", "", "path_obj", "=", "temp", ".", "relpath", "(", "\"lib.\"", "+", "object_format", ")", "\n", "self", ".", "save", "(", "path_obj", ")", "\n", "files", "=", "[", "path_obj", "]", "\n", "is_system_lib", "=", "self", ".", "type_key", "==", "\"llvm\"", "and", "self", ".", "get_function", "(", "\"__tvm_is_system_module\"", ")", "(", ")", "\n", "if", "self", ".", "imported_modules", ":", "\n", "            ", "path_cc", "=", "temp", ".", "relpath", "(", "\"devc.cc\"", ")", "\n", "with", "open", "(", "path_cc", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "_PackImportsToC", "(", "self", ",", "is_system_lib", ")", ")", "\n", "", "files", ".", "append", "(", "path_cc", ")", "\n", "", "if", "not", "fcompile", ":", "\n", "            ", "if", "file_name", ".", "endswith", "(", "\".tar\"", ")", ":", "\n", "                ", "fcompile", "=", "_tar", ".", "tar", "\n", "", "else", ":", "\n", "                ", "fcompile", "=", "_cc", ".", "create_shared", "\n", "", "", "if", "self", ".", "type_key", "==", "\"c\"", ":", "\n", "            ", "kwargs", ".", "update", "(", "{", "'options'", ":", "[", "\"-I\"", "+", "path", "for", "path", "in", "find_include_path", "(", ")", "]", "}", ")", "\n", "", "fcompile", "(", "file_name", ",", "files", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.Module.time_evaluator": [[149, 206], ["_RPCTimeEvaluator", "_RPCTimeEvaluator.", "struct.unpack", "ProfileResult", "NameError", "sum", "float"], "methods", ["None"], ["", "def", "time_evaluator", "(", "self", ",", "func_name", ",", "ctx", ",", "number", "=", "10", ",", "repeat", "=", "1", ",", "min_repeat_ms", "=", "0", ")", ":", "\n", "        ", "\"\"\"Get an evaluator that measures time cost of running function.\n\n        Parameters\n        ----------\n        func_name: str\n            The name of the function in the module.\n\n        ctx: TVMContext\n            The context we should run this function on.\n\n        number: int\n            The number of times to run this function for taking average.\n            We call these runs as one `repeat` of measurement.\n\n        repeat: int, optional\n            The number of times to repeat the measurement.\n            In total, the function will be invoked (1 + number x repeat) times,\n            where the first one is warm up and will be discarded.\n            The returned result contains `repeat` costs,\n            each of which is an average of `number` costs.\n\n        min_repeat_ms: int, optional\n            The minimum duration of one `repeat` in milliseconds.\n            By default, one `repeat` contains `number` runs. If this parameter is set,\n            the parameters `number` will be dynamically adjusted to meet the\n            minimum duration requirement of one `repeat`.\n            i.e., When the run time of one `repeat` falls below this time, the `number` parameter\n            will be automatically increased.\n\n        Note\n        ----\n        The function will be invoked  (1 + number x repeat) times,\n        with the first call discarded in case there is lazy initialization.\n\n        Returns\n        -------\n        ftimer : Function\n            The function that takes same argument as func and returns a ProfileResult.\n            The ProfileResult reports `repeat` time costs in seconds.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "feval", "=", "_RPCTimeEvaluator", "(", "\n", "self", ",", "func_name", ",", "ctx", ".", "device_type", ",", "ctx", ".", "device_id", ",", "number", ",", "repeat", ",", "min_repeat_ms", ")", "\n", "\n", "def", "evaluator", "(", "*", "args", ")", ":", "\n", "                ", "\"\"\"Internal wrapped evaluator.\"\"\"", "\n", "# Wrap feval so we can add more stats in future.", "\n", "blob", "=", "feval", "(", "*", "args", ")", "\n", "fmt", "=", "\"@\"", "+", "(", "\"d\"", "*", "repeat", ")", "\n", "results", "=", "struct", ".", "unpack", "(", "fmt", ",", "blob", ")", "\n", "mean", "=", "sum", "(", "results", ")", "/", "float", "(", "repeat", ")", "\n", "return", "ProfileResult", "(", "mean", "=", "mean", ",", "results", "=", "results", ")", "\n", "\n", "", "return", "evaluator", "\n", "", "except", "NameError", ":", "\n", "            ", "raise", "NameError", "(", "\"time_evaluate is only supported when RPC is enabled\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.system_lib": [[208, 227], ["_GetSystemLib"], "function", ["None"], ["", "", "", "def", "system_lib", "(", ")", ":", "\n", "    ", "\"\"\"Get system-wide library module singleton.\n\n    System lib is a global module that contains self register functions in startup.\n    Unlike normal dso modules which need to be loaded explicitly.\n    It is useful in environments where dynamic loading api like dlopen is banned.\n\n    To build system lib function, simply specify target option ```llvm --system-lib```\n    The system lib will be available as long as the result code is linked by the program.\n\n    The system lib is intended to be linked and loaded during the entire life-cyle of the program.\n    If you want dynamic loading features, use dso modules instead.\n\n    Returns\n    -------\n    module : Module\n        The system-wide library module.\n    \"\"\"", "\n", "return", "_GetSystemLib", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.load": [[229, 264], ["path.endswith", "_LoadFromFile", "_cc.create_shared", "path.endswith", "_util.tempdir", "_tar.untar", "_cc.create_shared", "_util.tempdir.relpath", "path.replace", "_util.tempdir.listdir"], "function", ["None"], ["", "def", "load", "(", "path", ",", "fmt", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Load module from file.\n\n    Parameters\n    ----------\n    path : str\n        The path to the module file.\n\n    fmt : str, optional\n        The format of the file, if not specified\n        it will be inferred from suffix of the file.\n\n    Returns\n    -------\n    module : Module\n        The loaded module\n\n    Note\n    ----\n    This function will automatically call\n    cc.create_shared if the path is in format .o or .tar\n    \"\"\"", "\n", "# High level handling for .o and .tar file.", "\n", "# We support this to be consistent with RPC module load.", "\n", "if", "path", ".", "endswith", "(", "\".o\"", ")", ":", "\n", "        ", "_cc", ".", "create_shared", "(", "path", "+", "\".so\"", ",", "path", ")", "\n", "path", "+=", "\".so\"", "\n", "", "elif", "path", ".", "endswith", "(", "\".tar\"", ")", ":", "\n", "        ", "tar_temp", "=", "_util", ".", "tempdir", "(", "custom_path", "=", "path", ".", "replace", "(", "'.tar'", ",", "''", ")", ")", "\n", "_tar", ".", "untar", "(", "path", ",", "tar_temp", ".", "temp_dir", ")", "\n", "files", "=", "[", "tar_temp", ".", "relpath", "(", "x", ")", "for", "x", "in", "tar_temp", ".", "listdir", "(", ")", "]", "\n", "_cc", ".", "create_shared", "(", "path", "+", "\".so\"", ",", "files", ")", "\n", "path", "+=", "\".so\"", "\n", "# Redirect to the load API", "\n", "", "return", "_LoadFromFile", "(", "path", ",", "fmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.enabled": [[266, 286], ["_Enabled"], "function", ["None"], ["", "def", "enabled", "(", "target", ")", ":", "\n", "    ", "\"\"\"Whether module runtime is enabled for target\n\n    Parameters\n    ----------\n    target : str\n        The target device type.\n\n    Returns\n    -------\n    enabled : bool\n        Whether runtime is enabled.\n\n    Examples\n    --------\n    The following code checks if gpu is enabled.\n\n    >>> tvm.module.enabled(\"gpu\")\n    \"\"\"", "\n", "return", "_Enabled", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.cpu": [[44, 58], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "cpu", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a CPU device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "1", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.gpu": [[60, 74], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "gpu", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a CPU device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "2", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.rocm": [[75, 89], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "rocm", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a ROCM device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "10", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.opencl": [[91, 105], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "opencl", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a OpenCL device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "4", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.metal": [[107, 121], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "metal", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a metal device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "8", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.vpi": [[123, 137], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "vpi", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a VPI simulated device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "9", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.vulkan": [[139, 153], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "vulkan", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a Vulkan device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "7", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.opengl": [[155, 169], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "opengl", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a OpenGL device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "11", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.ext_dev": [[171, 190], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "ext_dev", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a extension device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n\n    Note\n    ----\n    This API is reserved for quick testing of new\n    device by plugin device API as ext_dev.\n    \"\"\"", "\n", "return", "TVMContext", "(", "12", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.micro_dev": [[192, 206], ["_ffi.ndarray.TVMContext"], "function", ["None"], ["", "def", "micro_dev", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a micro device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "13", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.array": [[212, 231], ["ndarray.cpu", "_ffi.ndarray.empty().copyfrom", "isinstance", "numpy.array", "_ffi.ndarray.empty"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.cpu", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyfrom", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.array", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.empty"], ["def", "array", "(", "arr", ",", "ctx", "=", "cpu", "(", "0", ")", ")", ":", "\n", "    ", "\"\"\"Create an array from source arr.\n\n    Parameters\n    ----------\n    arr : numpy.ndarray\n        The array to be copied from\n\n    ctx : TVMContext, optional\n        The device context to create the array\n\n    Returns\n    -------\n    ret : NDArray\n        The created array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "arr", ",", "(", "_np", ".", "ndarray", ",", "NDArray", ")", ")", ":", "\n", "        ", "arr", "=", "_np", ".", "array", "(", "arr", ")", "\n", "", "return", "empty", "(", "arr", ".", "shape", ",", "arr", ".", "dtype", ",", "ctx", ")", ".", "copyfrom", "(", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.contrib.dlpack.convert_func": [[20, 43], ["callable", "tuple", "tvm_func", "isinstance", "ndarray.from_dlpack", "to_dlpack_func"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.from_dlpack"], ["def", "convert_func", "(", "tvm_func", ",", "tensor_type", ",", "to_dlpack_func", ")", ":", "\n", "    ", "\"\"\"Convert a tvm function into one that accepts a tensor from another\n       framework, provided the other framework supports DLPACK\n\n    Parameters\n    ----------\n    tvm_func: Function\n        Built tvm function operating on arrays\n\n    tensor_type: Type\n        Type of the tensors of the target framework\n\n    to_dlpack_func: Function\n        Function to convert the source tensors to DLPACK\n    \"\"\"", "\n", "assert", "callable", "(", "tvm_func", ")", "\n", "\n", "def", "_wrapper", "(", "*", "args", ")", ":", "\n", "        ", "args", "=", "tuple", "(", "ndarray", ".", "from_dlpack", "(", "to_dlpack_func", "(", "arg", ")", ")", "if", "isinstance", "(", "arg", ",", "tensor_type", ")", "else", "arg", "for", "arg", "in", "args", ")", "\n", "return", "tvm_func", "(", "*", "args", ")", "\n", "\n", "", "return", "_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.contrib.dlpack.to_pytorch_func": [[44, 60], ["dlpack.convert_func"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.contrib.dlpack.convert_func"], ["", "def", "to_pytorch_func", "(", "tvm_func", ")", ":", "\n", "    ", "\"\"\"Convert a tvm function into one that accepts PyTorch tensors\n\n    Parameters\n    ----------\n    tvm_func: Function\n        Built tvm function operating on arrays\n\n    Returns\n    -------\n    wrapped_func: Function\n        Wrapped tvm function that operates on PyTorch tensors\n    \"\"\"", "\n", "import", "torch", "\n", "import", "torch", ".", "utils", ".", "dlpack", "\n", "return", "convert_func", "(", "tvm_func", ",", "torch", ".", "Tensor", ",", "torch", ".", "utils", ".", "dlpack", ".", "to_dlpack", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._load_lib": [[49, 56], ["libinfo.find_lib_path", "ctypes.CDLL", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.find_lib_path"], ["", "def", "_load_lib", "(", ")", ":", "\n", "    ", "\"\"\"Load libary by searching possible path.\"\"\"", "\n", "lib_path", "=", "libinfo", ".", "find_lib_path", "(", ")", "\n", "lib", "=", "ctypes", ".", "CDLL", "(", "lib_path", "[", "0", "]", ",", "ctypes", ".", "RTLD_GLOBAL", ")", "\n", "# DMatrix functions", "\n", "lib", ".", "TVMGetLastError", ".", "restype", "=", "ctypes", ".", "c_char_p", "\n", "return", "lib", ",", "os", ".", "path", ".", "basename", "(", "lib_path", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str": [[71, 84], ["ctypes.c_char_p", "string.encode"], "function", ["None"], ["def", "c_str", "(", "string", ")", ":", "\n", "    ", "\"\"\"Create ctypes char * from a python string\n    Parameters\n    ----------\n    string : string type\n        python string\n\n    Returns\n    -------\n    str : c_char_p\n        A char pointer that can be passed to C API\n    \"\"\"", "\n", "return", "ctypes", ".", "c_char_p", "(", "string", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_array": [[86, 103], ["len"], "function", ["None"], ["", "def", "c_array", "(", "ctype", ",", "values", ")", ":", "\n", "    ", "\"\"\"Create ctypes array from a python array\n\n    Parameters\n    ----------\n    ctype : ctypes data type\n        data type of the array we want to convert to\n\n    values : tuple or list\n        data content\n\n    Returns\n    -------\n    out : ctypes array\n        Created ctypes array\n    \"\"\"", "\n", "return", "(", "ctype", "*", "len", "(", "values", ")", ")", "(", "*", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.decorate": [[105, 118], ["decorator.decorate"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.decorate"], ["", "def", "decorate", "(", "func", ",", "fwrapped", ")", ":", "\n", "    ", "\"\"\"A wrapper call of decorator package, differs to call time\n\n    Parameters\n    ----------\n    func : function\n        The original function\n\n    fwrapped : function\n        The wrapped function\n    \"\"\"", "\n", "import", "decorator", "\n", "return", "decorator", ".", "decorate", "(", "func", ",", "fwrapped", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.register_error": [[134, 173], ["callable", "base.register_error.register"], "function", ["None"], ["", "def", "register_error", "(", "func_name", "=", "None", ",", "cls", "=", "None", ")", ":", "\n", "    ", "\"\"\"Register an error class so it can be recognized by the ffi error handler.\n\n    Parameters\n    ----------\n    func_name : str or function or class\n        The name of the error function.\n\n    cls : function\n        The function to create the class\n\n    Returns\n    -------\n    fregister : function\n        Register function if f is not specified.\n\n    Examples\n    --------\n    .. code-block:: python\n\n      @tvm.error.register_error\n      class MyError(RuntimeError):\n          pass\n\n      err_inst = tvm.error.create_ffi_error(\"MyError: xyz\")\n      assert isinstance(err_inst, MyError)\n    \"\"\"", "\n", "if", "callable", "(", "func_name", ")", ":", "\n", "        ", "cls", "=", "func_name", "\n", "func_name", "=", "cls", ".", "__name__", "\n", "\n", "", "def", "register", "(", "mycls", ")", ":", "\n", "        ", "\"\"\"internal register function\"\"\"", "\n", "err_name", "=", "func_name", "if", "isinstance", "(", "func_name", ",", "str", ")", "else", "mycls", ".", "__name__", "\n", "ERROR_TYPE", "[", "err_name", "]", "=", "mycls", "\n", "return", "mycls", "\n", "", "if", "cls", "is", "None", ":", "\n", "        ", "return", "register", "\n", "", "return", "register", "(", "cls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._valid_error_name": [[175, 178], ["all", "x.isalnum"], "function", ["None"], ["", "def", "_valid_error_name", "(", "name", ")", ":", "\n", "    ", "\"\"\"Check whether name is a valid error name.\"\"\"", "\n", "return", "all", "(", "x", ".", "isalnum", "(", ")", "or", "x", "in", "\"_.\"", "for", "x", "in", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._find_error_type": [[180, 199], ["line.find", "base._valid_error_name"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._valid_error_name"], ["", "def", "_find_error_type", "(", "line", ")", ":", "\n", "    ", "\"\"\"Find the error name given the first line of the error message.\n\n    Parameters\n    ----------\n    line : str\n        The first line of error message.\n\n    Returns\n    -------\n    name : str The error name\n    \"\"\"", "\n", "end_pos", "=", "line", ".", "find", "(", "\":\"", ")", "\n", "if", "end_pos", "==", "-", "1", ":", "\n", "        ", "return", "None", "\n", "", "err_name", "=", "line", "[", ":", "end_pos", "]", "\n", "if", "_valid_error_name", "(", "err_name", ")", ":", "\n", "        ", "return", "err_name", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c2pyerror": [[201, 241], ["err_msg.split", "base._find_error_type", "err_msg.split.pop", "line.startswith", "line.startswith", "stack_trace.append", "message.append", "reversed"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._find_error_type"], ["", "def", "c2pyerror", "(", "err_msg", ")", ":", "\n", "    ", "\"\"\"Translate C API error message to python style.\n\n    Parameters\n    ----------\n    err_msg : str\n        The error message.\n\n    Returns\n    -------\n    new_msg : str\n        Translated message.\n\n    err_type : str\n        Detected error type.\n    \"\"\"", "\n", "arr", "=", "err_msg", ".", "split", "(", "\"\\n\"", ")", "\n", "if", "arr", "[", "-", "1", "]", "==", "\"\"", ":", "\n", "        ", "arr", ".", "pop", "(", ")", "\n", "", "err_type", "=", "_find_error_type", "(", "arr", "[", "0", "]", ")", "\n", "trace_mode", "=", "False", "\n", "stack_trace", "=", "[", "]", "\n", "message", "=", "[", "]", "\n", "for", "line", "in", "arr", ":", "\n", "        ", "if", "trace_mode", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"  \"", ")", ":", "\n", "                ", "stack_trace", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "                ", "trace_mode", "=", "False", "\n", "", "", "if", "not", "trace_mode", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"Stack trace\"", ")", ":", "\n", "                ", "trace_mode", "=", "True", "\n", "", "else", ":", "\n", "                ", "message", ".", "append", "(", "line", ")", "\n", "", "", "", "out_msg", "=", "\"\"", "\n", "if", "stack_trace", ":", "\n", "        ", "out_msg", "+=", "\"Traceback (most recent call last):\\n\"", "\n", "out_msg", "+=", "\"\\n\"", ".", "join", "(", "reversed", "(", "stack_trace", ")", ")", "+", "\"\\n\"", "\n", "", "out_msg", "+=", "\"\\n\"", ".", "join", "(", "message", ")", "\n", "return", "out_msg", ",", "err_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.py2cerror": [[243, 285], ["err_msg.split", "message[].split", "err_msg.split.pop", "base._valid_error_name", "head_arr[].strip", "line.startswith", "len", "head_arr[].strip", "stack_trace.append", "line.find", "message.append", "reversed"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base._valid_error_name"], ["", "def", "py2cerror", "(", "err_msg", ")", ":", "\n", "    ", "\"\"\"Translate python style error message to C style.\n\n    Parameters\n    ----------\n    err_msg : str\n        The error message.\n\n    Returns\n    -------\n    new_msg : str\n        Translated message.\n    \"\"\"", "\n", "arr", "=", "err_msg", ".", "split", "(", "\"\\n\"", ")", "\n", "if", "arr", "[", "-", "1", "]", "==", "\"\"", ":", "\n", "        ", "arr", ".", "pop", "(", ")", "\n", "", "trace_mode", "=", "False", "\n", "stack_trace", "=", "[", "]", "\n", "message", "=", "[", "]", "\n", "for", "line", "in", "arr", ":", "\n", "        ", "if", "trace_mode", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"  \"", ")", ":", "\n", "                ", "stack_trace", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "                ", "trace_mode", "=", "False", "\n", "", "", "if", "not", "trace_mode", ":", "\n", "            ", "if", "line", ".", "find", "(", "\"Traceback\"", ")", "!=", "-", "1", ":", "\n", "                ", "trace_mode", "=", "True", "\n", "", "else", ":", "\n", "                ", "message", ".", "append", "(", "line", ")", "\n", "# Remove the first error name if there are two of them.", "\n", "# RuntimeError: MyErrorName: message => MyErrorName: message", "\n", "", "", "", "head_arr", "=", "message", "[", "0", "]", ".", "split", "(", "\":\"", ",", "3", ")", "\n", "if", "len", "(", "head_arr", ")", ">=", "3", "and", "_valid_error_name", "(", "head_arr", "[", "1", "]", ".", "strip", "(", ")", ")", ":", "\n", "        ", "head_arr", "[", "1", "]", "=", "head_arr", "[", "1", "]", ".", "strip", "(", ")", "\n", "message", "[", "0", "]", "=", "\":\"", ".", "join", "(", "head_arr", "[", "1", ":", "]", ")", "\n", "# reverse the stack trace.", "\n", "", "out_msg", "=", "\"\\n\"", ".", "join", "(", "message", ")", "\n", "if", "stack_trace", ":", "\n", "        ", "out_msg", "+=", "\"\\nStack trace:\\n\"", "\n", "out_msg", "+=", "\"\\n\"", ".", "join", "(", "reversed", "(", "stack_trace", ")", ")", "+", "\"\\n\"", "\n", "", "return", "out_msg", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error": [[287, 300], ["py_str", "base.c2pyerror", "_LIB.TVMGetLastError", "err_type.startswith", "ERROR_TYPE.get"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c2pyerror"], ["", "def", "get_last_ffi_error", "(", ")", ":", "\n", "    ", "\"\"\"Create error object given result of TVMGetLastError.\n\n    Returns\n    -------\n    err : object\n        The error object based on the err_msg\n    \"\"\"", "\n", "c_err_msg", "=", "py_str", "(", "_LIB", ".", "TVMGetLastError", "(", ")", ")", "\n", "py_err_msg", ",", "err_type", "=", "c2pyerror", "(", "c_err_msg", ")", "\n", "if", "err_type", "is", "not", "None", "and", "err_type", ".", "startswith", "(", "\"tvm.error.\"", ")", ":", "\n", "        ", "err_type", "=", "err_type", "[", "10", ":", "]", "\n", "", "return", "ERROR_TYPE", ".", "get", "(", "err_type", ",", "TVMError", ")", "(", "py_err_msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call": [[302, 315], ["base.get_last_ffi_error"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error"], ["", "def", "check_call", "(", "ret", ")", ":", "\n", "    ", "\"\"\"Check the return value of C API call\n\n    This function will raise exception when error occurs.\n    Wrap every API call with this function\n\n    Parameters\n    ----------\n    ret : int\n        return value from API calls\n    \"\"\"", "\n", "if", "ret", "!=", "0", ":", "\n", "        ", "raise", "get_last_ffi_error", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var": [[22, 41], ["os.environ.get", "p.strip", "os.environ[].split"], "function", ["None"], ["def", "split_env_var", "(", "env_var", ",", "split", ")", ":", "\n", "    ", "\"\"\"Splits environment variable string.\n\n    Parameters\n    ----------\n    env_var : str\n        Name of environment variable.\n\n    split : str\n        String to split env_var on.\n\n    Returns\n    -------\n    splits : list(string)\n        If env_var exists, split env_var. Otherwise, empty list.\n    \"\"\"", "\n", "if", "os", ".", "environ", ".", "get", "(", "env_var", ",", "None", ")", ":", "\n", "        ", "return", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "os", ".", "environ", "[", "env_var", "]", ".", "split", "(", "split", ")", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.find_lib_path": [[42, 139], ["os.environ.get", "os.path.dirname", "os.path.join", "os.path.join", "os.environ.get", "sys.platform.startswith", "dll_path.append", "dll_path.append", "dll_path.append", "dll_path.append", "dll_path.append", "os.path.realpath", "dll_path.append", "dll_path.extend", "dll_path.extend", "sys.platform.startswith", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.realpath", "isinstance", "sys.platform.startswith", "sys.stderr.write", "sys.stderr.flush", "os.path.expanduser", "libinfo.split_env_var", "libinfo.split_env_var", "dll_path.extend", "dll_path.extend", "sys.platform.startswith", "dll_path.append", "sys.platform.startswith", "str", "RuntimeError", "libinfo.split_env_var", "libinfo.split_env_var", "dll_path.extend", "os.path.join", "libinfo.split_env_var", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.isfile", "os.path.exists", "os.path.isfile", "os.path.exists", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.split_env_var"], ["", "def", "find_lib_path", "(", "name", "=", "None", ",", "search_path", "=", "None", ",", "optional", "=", "False", ")", ":", "\n", "    ", "\"\"\"Find dynamic library files.\n\n    Parameters\n    ----------\n    name : list of str\n        List of names to be found.\n\n    Returns\n    -------\n    lib_path : list(string)\n        List of all found path to the libraries\n    \"\"\"", "\n", "use_runtime", "=", "os", ".", "environ", ".", "get", "(", "\"TVM_USE_RUNTIME_LIB\"", ",", "False", ")", "\n", "\n", "# See https://github.com/dmlc/tvm/issues/281 for some background.", "\n", "\n", "# NB: This will either be the source directory (if TVM is run", "\n", "# inplace) or the install directory (if TVM is installed).", "\n", "# An installed TVM's curr_path will look something like:", "\n", "#   $PREFIX/lib/python3.6/site-packages/tvm/_ffi", "\n", "ffi_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "os", ".", "path", ".", "expanduser", "(", "__file__", ")", ")", ")", "\n", "source_dir", "=", "os", ".", "path", ".", "join", "(", "ffi_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ")", "\n", "install_lib_dir", "=", "os", ".", "path", ".", "join", "(", "ffi_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ")", "\n", "\n", "dll_path", "=", "[", "]", "\n", "\n", "if", "os", ".", "environ", ".", "get", "(", "'TVM_LIBRARY_PATH'", ",", "None", ")", ":", "\n", "        ", "dll_path", ".", "append", "(", "os", ".", "environ", "[", "'TVM_LIBRARY_PATH'", "]", ")", "\n", "\n", "", "if", "sys", ".", "platform", ".", "startswith", "(", "'linux'", ")", ":", "\n", "        ", "dll_path", ".", "extend", "(", "split_env_var", "(", "'LD_LIBRARY_PATH'", ",", "':'", ")", ")", "\n", "dll_path", ".", "extend", "(", "split_env_var", "(", "'PATH'", ",", "':'", ")", ")", "\n", "", "elif", "sys", ".", "platform", ".", "startswith", "(", "'darwin'", ")", ":", "\n", "        ", "dll_path", ".", "extend", "(", "split_env_var", "(", "'DYLD_LIBRARY_PATH'", ",", "':'", ")", ")", "\n", "dll_path", ".", "extend", "(", "split_env_var", "(", "'PATH'", ",", "':'", ")", ")", "\n", "", "elif", "sys", ".", "platform", ".", "startswith", "(", "'win32'", ")", ":", "\n", "        ", "dll_path", ".", "extend", "(", "split_env_var", "(", "'PATH'", ",", "';'", ")", ")", "\n", "\n", "# Pip lib directory", "\n", "", "dll_path", ".", "append", "(", "os", ".", "path", ".", "join", "(", "ffi_dir", ",", "\"..\"", ")", ")", "\n", "# Default cmake build directory", "\n", "dll_path", ".", "append", "(", "os", ".", "path", ".", "join", "(", "source_dir", ",", "\"build\"", ")", ")", "\n", "dll_path", ".", "append", "(", "os", ".", "path", ".", "join", "(", "source_dir", ",", "\"build\"", ",", "\"Release\"", ")", ")", "\n", "# Default make build directory", "\n", "dll_path", ".", "append", "(", "os", ".", "path", ".", "join", "(", "source_dir", ",", "\"lib\"", ")", ")", "\n", "\n", "dll_path", ".", "append", "(", "install_lib_dir", ")", "\n", "\n", "dll_path", "=", "[", "os", ".", "path", ".", "realpath", "(", "x", ")", "for", "x", "in", "dll_path", "]", "\n", "if", "search_path", "is", "not", "None", ":", "\n", "        ", "if", "search_path", "is", "list", ":", "\n", "            ", "dll_path", "=", "dll_path", "+", "search_path", "\n", "", "else", ":", "\n", "            ", "dll_path", ".", "append", "(", "search_path", ")", "\n", "", "", "if", "name", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "name", ",", "list", ")", ":", "\n", "            ", "lib_dll_path", "=", "[", "]", "\n", "for", "n", "in", "name", ":", "\n", "                ", "lib_dll_path", "+=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "n", ")", "for", "p", "in", "dll_path", "]", "\n", "", "", "else", ":", "\n", "            ", "lib_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "name", ")", "for", "p", "in", "dll_path", "]", "\n", "", "runtime_dll_path", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "platform", ".", "startswith", "(", "'win32'", ")", ":", "\n", "            ", "lib_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm.dll'", ")", "for", "p", "in", "dll_path", "]", "+", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'tvm.dll'", ")", "for", "p", "in", "dll_path", "]", "\n", "runtime_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm_runtime.dll'", ")", "for", "p", "in", "dll_path", "]", "+", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'tvm_runtime.dll'", ")", "for", "p", "in", "dll_path", "]", "\n", "", "elif", "sys", ".", "platform", ".", "startswith", "(", "'darwin'", ")", ":", "\n", "            ", "lib_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm.dylib'", ")", "for", "p", "in", "dll_path", "]", "\n", "runtime_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm_runtime.dylib'", ")", "for", "p", "in", "dll_path", "]", "\n", "", "else", ":", "\n", "            ", "lib_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm.so'", ")", "for", "p", "in", "dll_path", "]", "\n", "runtime_dll_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'libtvm_runtime.so'", ")", "for", "p", "in", "dll_path", "]", "\n", "\n", "", "", "if", "not", "use_runtime", ":", "\n", "# try to find lib_dll_path", "\n", "        ", "lib_found", "=", "[", "p", "for", "p", "in", "lib_dll_path", "if", "os", ".", "path", ".", "exists", "(", "p", ")", "and", "os", ".", "path", ".", "isfile", "(", "p", ")", "]", "\n", "lib_found", "+=", "[", "p", "for", "p", "in", "runtime_dll_path", "if", "os", ".", "path", ".", "exists", "(", "p", ")", "and", "os", ".", "path", ".", "isfile", "(", "p", ")", "]", "\n", "", "else", ":", "\n", "# try to find runtime_dll_path", "\n", "        ", "use_runtime", "=", "True", "\n", "lib_found", "=", "[", "p", "for", "p", "in", "runtime_dll_path", "if", "os", ".", "path", ".", "exists", "(", "p", ")", "and", "os", ".", "path", ".", "isfile", "(", "p", ")", "]", "\n", "\n", "", "if", "not", "lib_found", ":", "\n", "        ", "message", "=", "(", "'Cannot find the files.\\n'", "+", "\n", "'List of candidates:\\n'", "+", "\n", "str", "(", "'\\n'", ".", "join", "(", "lib_dll_path", "+", "runtime_dll_path", ")", ")", ")", "\n", "if", "not", "optional", ":", "\n", "            ", "raise", "RuntimeError", "(", "message", ")", "\n", "", "return", "None", "\n", "\n", "", "if", "use_runtime", ":", "\n", "        ", "sys", ".", "stderr", ".", "write", "(", "\"Loading runtime library %s... exec only\\n\"", "%", "lib_found", "[", "0", "]", ")", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "", "return", "lib_found", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.libinfo.find_include_path": [[141, 199], ["os.path.dirname", "os.path.join", "os.path.join", "os.path.join", "os.environ.get", "header_path.append", "header_path.append", "header_path.append", "os.path.abspath", "header_path.append", "os.path.abspath", "isinstance", "os.path.expanduser", "header_path.append", "os.path.join", "os.path.join", "str", "RuntimeError", "os.path.join", "os.path.join", "os.path.exists", "os.path.isdir", "os.path.exists", "os.path.isdir"], "function", ["None"], ["", "def", "find_include_path", "(", "name", "=", "None", ",", "search_path", "=", "None", ",", "optional", "=", "False", ")", ":", "\n", "    ", "\"\"\"Find header files for C compilation.\n\n    Parameters\n    ----------\n    name : list of str\n        List of directory names to be searched.\n\n    Returns\n    -------\n    include_path : list(string)\n        List of all found paths to header files.\n    \"\"\"", "\n", "ffi_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "__file__", ")", ")", ")", "\n", "source_dir", "=", "os", ".", "path", ".", "join", "(", "ffi_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ")", "\n", "install_include_dir", "=", "os", ".", "path", ".", "join", "(", "ffi_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ",", "\"..\"", ")", "\n", "third_party_dir", "=", "os", ".", "path", ".", "join", "(", "source_dir", ",", "\"3rdparty\"", ")", "\n", "\n", "header_path", "=", "[", "]", "\n", "\n", "if", "os", ".", "environ", ".", "get", "(", "'TVM_INCLUDE_PATH'", ",", "None", ")", ":", "\n", "        ", "header_path", ".", "append", "(", "os", ".", "environ", "[", "'TVM_INCLUDE_PATH'", "]", ")", "\n", "\n", "", "header_path", ".", "append", "(", "install_include_dir", ")", "\n", "header_path", ".", "append", "(", "source_dir", ")", "\n", "header_path", ".", "append", "(", "third_party_dir", ")", "\n", "\n", "header_path", "=", "[", "os", ".", "path", ".", "abspath", "(", "x", ")", "for", "x", "in", "header_path", "]", "\n", "if", "search_path", "is", "not", "None", ":", "\n", "        ", "if", "search_path", "is", "list", ":", "\n", "            ", "header_path", "=", "header_path", "+", "search_path", "\n", "", "else", ":", "\n", "            ", "header_path", ".", "append", "(", "search_path", ")", "\n", "", "", "if", "name", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "name", ",", "list", ")", ":", "\n", "            ", "tvm_include_path", "=", "[", "]", "\n", "for", "n", "in", "name", ":", "\n", "                ", "tvm_include_path", "+=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "n", ")", "for", "p", "in", "header_path", "]", "\n", "", "", "else", ":", "\n", "            ", "tvm_include_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "name", ")", "for", "p", "in", "header_path", "]", "\n", "", "dlpack_include_path", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "tvm_include_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'include'", ")", "for", "p", "in", "header_path", "]", "\n", "dlpack_include_path", "=", "[", "os", ".", "path", ".", "join", "(", "p", ",", "'dlpack/include'", ")", "for", "p", "in", "header_path", "]", "\n", "\n", "# try to find include path", "\n", "include_found", "=", "[", "p", "for", "p", "in", "tvm_include_path", "if", "os", ".", "path", ".", "exists", "(", "p", ")", "and", "os", ".", "path", ".", "isdir", "(", "p", ")", "]", "\n", "include_found", "+=", "[", "p", "for", "p", "in", "dlpack_include_path", "if", "os", ".", "path", ".", "exists", "(", "p", ")", "and", "os", ".", "path", ".", "isdir", "(", "p", ")", "]", "\n", "\n", "", "if", "not", "include_found", ":", "\n", "        ", "message", "=", "(", "'Cannot find the files.\\n'", "+", "\n", "'List of candidates:\\n'", "+", "\n", "str", "(", "'\\n'", ".", "join", "(", "tvm_include_path", "+", "dlpack_include_path", ")", ")", ")", "\n", "if", "not", "optional", ":", "\n", "            ", "raise", "RuntimeError", "(", "message", ")", "\n", "", "return", "None", "\n", "\n", "", "return", "include_found", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__repr__": [[48, 50], ["_api_internal._format_str"], "methods", ["None"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "_api_internal", ".", "_format_str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__dir__": [[51, 60], ["ctypes.c_uint", "base.check_call", "range", "ctypes.POINTER", "base._LIB.TVMNodeListAttrNames", "names.append", "ctypes.byref", "ctypes.byref", "base.py_str"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "__dir__", "(", "self", ")", ":", "\n", "        ", "plist", "=", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_char_p", ")", "(", ")", "\n", "size", "=", "ctypes", ".", "c_uint", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMNodeListAttrNames", "(", "\n", "self", ".", "handle", ",", "ctypes", ".", "byref", "(", "size", ")", ",", "ctypes", ".", "byref", "(", "plist", ")", ")", ")", "\n", "names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "size", ".", "value", ")", ":", "\n", "            ", "names", ".", "append", "(", "py_str", "(", "plist", "[", "i", "]", ")", ")", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__hash__": [[61, 63], ["_api_internal._raw_ptr"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "_api_internal", ".", "_raw_ptr", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__eq__": [[64, 66], ["node.NodeBase.same_as"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.same_as"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "same_as", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__ne__": [[67, 69], ["node.NodeBase.__eq__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__reduce__": [[70, 73], ["type", "node.NodeBase.__getstate__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__getstate__"], ["", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "cls", "=", "type", "(", "self", ")", "\n", "return", "(", "_new_object", ",", "(", "cls", ",", ")", ",", "self", ".", "__getstate__", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__getstate__": [[74, 79], ["_api_internal._save_json"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "handle", "=", "self", ".", "handle", "\n", "if", "handle", "is", "not", "None", ":", "\n", "            ", "return", "{", "'handle'", ":", "_api_internal", ".", "_save_json", "(", "self", ")", "}", "\n", "", "return", "{", "'handle'", ":", "None", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.__setstate__": [[80, 90], ["_api_internal._load_json"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "# pylint: disable=assigning-non-slot", "\n", "        ", "handle", "=", "state", "[", "'handle'", "]", "\n", "if", "handle", "is", "not", "None", ":", "\n", "            ", "json_str", "=", "handle", "\n", "other", "=", "_api_internal", ".", "_load_json", "(", "json_str", ")", "\n", "self", ".", "handle", "=", "other", ".", "handle", "\n", "other", ".", "handle", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "handle", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.NodeBase.same_as": [[91, 96], ["isinstance", "node.NodeBase.__hash__", "other.__hash__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__hash__", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__hash__"], ["", "", "def", "same_as", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"check object identity equality\"\"\"", "\n", "if", "not", "isinstance", "(", "other", ",", "NodeBase", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "__hash__", "(", ")", "==", "other", ".", "__hash__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node._new_object": [[41, 44], ["cls.__new__"], "function", ["None"], ["", "def", "_new_object", "(", "cls", ")", ":", "\n", "    ", "\"\"\"Helper function for pickle\"\"\"", "\n", "return", "cls", ".", "__new__", "(", "cls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node.register_node": [[98, 119], ["isinstance", "node.register_node.register"], "function", ["None"], ["", "", "def", "register_node", "(", "type_key", "=", "None", ")", ":", "\n", "    ", "\"\"\"register node type\n\n    Parameters\n    ----------\n    type_key : str or cls\n        The type key of the node\n    \"\"\"", "\n", "node_name", "=", "type_key", "if", "isinstance", "(", "type_key", ",", "str", ")", "else", "type_key", ".", "__name__", "\n", "\n", "def", "register", "(", "cls", ")", ":", "\n", "        ", "\"\"\"internal register function\"\"\"", "\n", "tindex", "=", "ctypes", ".", "c_int", "(", ")", "\n", "ret", "=", "_LIB", ".", "TVMNodeTypeKey2Index", "(", "c_str", "(", "node_name", ")", ",", "ctypes", ".", "byref", "(", "tindex", ")", ")", "\n", "if", "ret", "==", "0", ":", "\n", "            ", "_register_node", "(", "tindex", ".", "value", ",", "cls", ")", "\n", "", "return", "cls", "\n", "\n", "", "if", "isinstance", "(", "type_key", ",", "str", ")", ":", "\n", "        ", "return", "register", "\n", "", "return", "register", "(", "type_key", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.shape": [[157, 161], ["tuple", "range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.dtype": [[162, 166], ["str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.ctx": [[167, 171], ["None"], "methods", ["None"], ["\n", "return", "TVMContext", "(", "11", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "ext_dev", "(", "dev_id", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.context": [[172, 176], ["None"], "methods", ["None"], ["    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__hash__": [[177, 179], ["ctypes.cast"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__eq__": [[180, 182], ["ndarray.NDArrayBase.same_as"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.same_as"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__ne__": [[183, 185], ["ndarray.NDArrayBase.__eq__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__eq__"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.same_as": [[186, 202], ["isinstance", "ndarray.NDArrayBase.__hash__", "other.__hash__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__hash__", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__hash__"], ["\n", "return", "TVMContext", "(", "12", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "micro_dev", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__setitem__": [[203, 216], ["isinstance", "ValueError", "isinstance", "isinstance", "value.copyto", "ndarray.NDArrayBase.copyfrom", "TypeError", "str", "type"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyto", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyfrom"], ["\n", "return", "TVMContext", "(", "13", ",", "dev_id", ")", "\n", "\n", "\n", "", "cl", "=", "opencl", "\n", "mtl", "=", "metal", "\n", "\n", "\n", "def", "array", "(", "arr", ",", "ctx", "=", "cpu", "(", "0", ")", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyfrom": [[217, 256], ["isinstance", "runtime_ctypes.TVMType", "numpy.ascontiguousarray", "numpy.array.ctypes.data_as", "ctypes.c_size_t", "base.check_call", "numpy.array.copyto", "isinstance", "str", "ValueError", "base._LIB.TVMArrayCopyFromBytes", "numpy.array", "TypeError", "str", "type"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyto", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.ndarray.array"], ["\n", "if", "not", "isinstance", "(", "arr", ",", "(", "_np", ".", "ndarray", ",", "NDArray", ")", ")", ":", "\n", "        ", "arr", "=", "_np", ".", "array", "(", "arr", ")", "\n", "", "return", "empty", "(", "arr", ".", "shape", ",", "arr", ".", "dtype", ",", "ctx", ")", ".", "copyfrom", "(", "arr", ")", "\n", "\n", "", "_set_class_ndarray", "(", "NDArray", ")", "\n", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__repr__": [[257, 261], ["ndarray.NDArrayBase.asnumpy().__repr__", "ndarray.NDArrayBase.asnumpy"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__repr__", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.asnumpy"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.__str__": [[262, 264], ["str", "ndarray.NDArrayBase.asnumpy"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.asnumpy"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.asnumpy": [[265, 285], ["runtime_ctypes.TVMType", "numpy.empty", "numpy.empty.ctypes.data_as", "ctypes.c_size_t", "base.check_call", "str", "base._LIB.TVMArrayCopyToBytes"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.empty", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.copyto": [[286, 302], ["isinstance", "isinstance", "ndarray.empty", "base.check_call", "ValueError", "base._LIB.TVMArrayCopyFromTo", "str", "type"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.empty", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.context": [[50, 83], ["isinstance", "runtime_ctypes.TVMContext", "dev_type.split", "ValueError"], "function", ["None"], ["\n", "return", "TVMContext", "(", "1", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "gpu", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a CPU device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "2", ",", "dev_id", ")", "\n", "\n", "", "def", "rocm", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.numpyasarray": [[85, 100], ["runtime_ctypes.TVMArray", "base.c_array", "data.ctypes.data_as", "runtime_ctypes.TVMType", "ndarray.context", "numpy.dtype"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_array", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.context", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.NDArrayBase.dtype"], ["\n", "return", "TVMContext", "(", "10", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "opencl", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.empty": [[102, 134], ["ndarray.context", "base.c_array", "ctypes.c_int", "runtime_ctypes.TVMArrayHandle", "runtime_ctypes.TVMType", "base.check_call", "_make_array", "len", "base._LIB.TVMArrayAlloc", "ctypes.c_int", "ctypes.c_int", "ctypes.c_int", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.context", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_array", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._make_array"], ["\n", "return", "TVMContext", "(", "4", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "metal", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a metal device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "8", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "vpi", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.from_dlpack": [[136, 153], ["_from_dlpack"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._from_dlpack"], ["return", "TVMContext", "(", "9", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "vulkan", "(", "dev_id", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct a Vulkan device\n\n    Parameters\n    ----------\n    dev_id : int, optional\n        The integer device id\n\n    Returns\n    -------\n    ctx : TVMContext\n        The created context\n    \"\"\"", "\n", "return", "TVMContext", "(", "7", ",", "dev_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.free_extension_handle": [[304, 316], ["base.check_call", "base._LIB.TVMExtTypeFree", "ctypes.c_int"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.register_extension": [[318, 377], ["issubclass", "hasattr", "_reg_ndarray", "hasattr", "_reg_extension", "ValueError"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._reg_ndarray", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._reg_extension"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.__init__": [[78, 82], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "handle", ")", ":", "\n", "        ", "self", ".", "handle", "=", "handle", "\n", "self", ".", "_entry", "=", "None", "\n", "self", ".", "entry_name", "=", "\"__tvm_main__\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.__del__": [[83, 85], ["base.check_call", "base._LIB.TVMModFree"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "check_call", "(", "_LIB", ".", "TVMModFree", "(", "self", ".", "handle", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.entry_func": [[86, 99], ["function.ModuleBase.get_function"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.get_function"], ["", "@", "property", "\n", "def", "entry_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the entry function\n\n        Returns\n        -------\n        f : Function\n            The entry function if exist\n        \"\"\"", "\n", "if", "self", ".", "_entry", ":", "\n", "            ", "return", "self", ".", "_entry", "\n", "", "self", ".", "_entry", "=", "self", ".", "get_function", "(", "self", ".", "entry_name", ")", "\n", "return", "self", ".", "_entry", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.get_function": [[100, 125], ["FunctionHandle", "base.check_call", "function.Function", "base._LIB.TVMModGetFunction", "AttributeError", "base.c_str", "ctypes.c_int", "ctypes.byref"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str"], ["", "def", "get_function", "(", "self", ",", "name", ",", "query_imports", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get function from the module.\n\n        Parameters\n        ----------\n        name : str\n            The name of the function\n\n        query_imports : bool\n            Whether also query modules imported by this module.\n\n        Returns\n        -------\n        f : Function\n            The result function.\n        \"\"\"", "\n", "ret_handle", "=", "FunctionHandle", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMModGetFunction", "(", "\n", "self", ".", "handle", ",", "c_str", "(", "name", ")", ",", "\n", "ctypes", ".", "c_int", "(", "query_imports", ")", ",", "\n", "ctypes", ".", "byref", "(", "ret_handle", ")", ")", ")", "\n", "if", "not", "ret_handle", ".", "value", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"Module has no function '%s'\"", "%", "name", ")", "\n", "", "return", "Function", "(", "ret_handle", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.import_module": [[126, 135], ["base.check_call", "base._LIB.TVMModImport"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "import_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Add module to the import list of current one.\n\n        Parameters\n        ----------\n        module : Module\n            The other module.\n        \"\"\"", "\n", "check_call", "(", "_LIB", ".", "TVMModImport", "(", "self", ".", "handle", ",", "module", ".", "handle", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.__getitem__": [[136, 140], ["function.ModuleBase.get_function", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.get_function"], ["", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "name", ",", "string_types", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Can only take string as function name\"", ")", "\n", "", "return", "self", ".", "get_function", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.ModuleBase.__call__": [[141, 146], ["f", "function.ModuleBase._entry"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "if", "self", ".", "_entry", ":", "\n", "            ", "return", "self", ".", "_entry", "(", "*", "args", ")", "\n", "", "f", "=", "self", ".", "entry_func", "\n", "return", "f", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.register_func": [[148, 205], ["callable", "ctypes.c_int", "isinstance", "ValueError", "base.check_call", "function.register_func.register"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "", "def", "register_func", "(", "func_name", ",", "f", "=", "None", ",", "override", "=", "False", ")", ":", "\n", "    ", "\"\"\"Register global function\n\n    Parameters\n    ----------\n    func_name : str or function\n        The function name\n\n    f : function, optional\n        The function to be registered.\n\n    override: boolean optional\n        Whether override existing entry.\n\n    Returns\n    -------\n    fregister : function\n        Register function if f is not specified.\n\n    Examples\n    --------\n    The following code registers my_packed_func as global function.\n    Note that we simply get it back from global function table to invoke\n    it from python side. However, we can also invoke the same function\n    from C++ backend, or in the compiled TVM code.\n\n    .. code-block:: python\n\n      targs = (10, 10.0, \"hello\")\n      @tvm.register_func\n      def my_packed_func(*args):\n          assert(tuple(args) == targs)\n          return 10\n      # Get it out from global function table\n      f = tvm.get_global_func(\"my_packed_func\")\n      assert isinstance(f, tvm.nd.Function)\n      y = f(*targs)\n      assert y == 10\n    \"\"\"", "\n", "if", "callable", "(", "func_name", ")", ":", "\n", "        ", "f", "=", "func_name", "\n", "func_name", "=", "f", ".", "__name__", "\n", "\n", "", "if", "not", "isinstance", "(", "func_name", ",", "str", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"expect string function name\"", ")", "\n", "\n", "", "ioverride", "=", "ctypes", ".", "c_int", "(", "override", ")", "\n", "def", "register", "(", "myf", ")", ":", "\n", "        ", "\"\"\"internal register function\"\"\"", "\n", "if", "not", "isinstance", "(", "myf", ",", "Function", ")", ":", "\n", "            ", "myf", "=", "convert_to_tvm_func", "(", "myf", ")", "\n", "", "check_call", "(", "_LIB", ".", "TVMFuncRegisterGlobal", "(", "\n", "c_str", "(", "func_name", ")", ",", "myf", ".", "handle", ",", "ioverride", ")", ")", "\n", "return", "myf", "\n", "", "if", "f", ":", "\n", "        ", "return", "register", "(", "f", ")", "\n", "", "return", "register", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.get_global_func": [[207, 232], ["FunctionHandle", "base.check_call", "ValueError", "base._LIB.TVMFuncGetGlobal", "function.Function", "base.c_str", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str"], ["", "def", "get_global_func", "(", "name", ",", "allow_missing", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get a global function by name\n\n    Parameters\n    ----------\n    name : str\n        The name of the global function\n\n    allow_missing : bool\n        Whether allow missing function or raise an error.\n\n    Returns\n    -------\n    func : tvm.Function\n        The function to be returned, None if function is missing.\n    \"\"\"", "\n", "handle", "=", "FunctionHandle", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMFuncGetGlobal", "(", "c_str", "(", "name", ")", ",", "ctypes", ".", "byref", "(", "handle", ")", ")", ")", "\n", "if", "handle", ".", "value", ":", "\n", "        ", "return", "Function", "(", "handle", ",", "False", ")", "\n", "\n", "", "if", "allow_missing", ":", "\n", "        ", "return", "None", "\n", "\n", "", "raise", "ValueError", "(", "\"Cannot find global function %s\"", "%", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.list_global_func_names": [[235, 252], ["ctypes.c_uint", "base.check_call", "range", "ctypes.POINTER", "base._LIB.TVMFuncListGlobalNames", "fnames.append", "ctypes.byref", "ctypes.byref", "base.py_str"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "list_global_func_names", "(", ")", ":", "\n", "    ", "\"\"\"Get list of global functions registered.\n\n    Returns\n    -------\n    names : list\n       List of global functions names.\n    \"\"\"", "\n", "plist", "=", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_char_p", ")", "(", ")", "\n", "size", "=", "ctypes", ".", "c_uint", "(", ")", "\n", "\n", "check_call", "(", "_LIB", ".", "TVMFuncListGlobalNames", "(", "ctypes", ".", "byref", "(", "size", ")", ",", "\n", "ctypes", ".", "byref", "(", "plist", ")", ")", ")", "\n", "fnames", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "size", ".", "value", ")", ":", "\n", "        ", "fnames", ".", "append", "(", "py_str", "(", "plist", "[", "i", "]", ")", ")", "\n", "", "return", "fnames", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.extract_ext_funcs": [[254, 277], ["convert_to_tvm_func", "finit", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.convert_to_tvm_func"], ["", "def", "extract_ext_funcs", "(", "finit", ")", ":", "\n", "    ", "\"\"\"\n    Extract the extension PackedFuncs from a C module.\n\n    Parameters\n    ----------\n    finit : ctypes function\n        a ctypes that takes signature of TVMExtensionDeclarer\n\n    Returns\n    -------\n    fdict : dict of str to Function\n        The extracted functions\n    \"\"\"", "\n", "fdict", "=", "{", "}", "\n", "def", "_list", "(", "name", ",", "func", ")", ":", "\n", "        ", "fdict", "[", "name", "]", "=", "func", "\n", "", "myf", "=", "convert_to_tvm_func", "(", "_list", ")", "\n", "ret", "=", "finit", "(", "myf", ".", "handle", ")", "\n", "_", "=", "myf", "\n", "if", "ret", "!=", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"cannot initialize with %s\"", "%", "finit", ")", "\n", "", "return", "fdict", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._get_api": [[279, 283], ["None"], "function", ["None"], ["", "def", "_get_api", "(", "f", ")", ":", "\n", "    ", "flocal", "=", "f", "\n", "flocal", ".", "is_global", "=", "True", "\n", "return", "flocal", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._init_api": [[284, 299], ["namespace.startswith", "function._init_api_prefix", "function._init_api_prefix"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._init_api_prefix", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._init_api_prefix"], ["", "def", "_init_api", "(", "namespace", ",", "target_module_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initialize api for a given module name\n\n    namespace : str\n       The namespace of the source registry\n\n    target_module_name : str\n       The target module name if different from namespace\n    \"\"\"", "\n", "target_module_name", "=", "(", "\n", "target_module_name", "if", "target_module_name", "else", "namespace", ")", "\n", "if", "namespace", ".", "startswith", "(", "\"tvm.\"", ")", ":", "\n", "        ", "_init_api_prefix", "(", "target_module_name", ",", "namespace", "[", "4", ":", "]", ")", "\n", "", "else", ":", "\n", "        ", "_init_api_prefix", "(", "target_module_name", ",", "namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._init_api_prefix": [[301, 324], ["function.list_global_func_names", "function.get_global_func", "function._get_api", "setattr", "name.startswith", "fname.find", "name.startswith", "len"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.list_global_func_names", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function.get_global_func", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.function._get_api"], ["", "", "def", "_init_api_prefix", "(", "module_name", ",", "prefix", ")", ":", "\n", "    ", "module", "=", "sys", ".", "modules", "[", "module_name", "]", "\n", "\n", "for", "name", "in", "list_global_func_names", "(", ")", ":", "\n", "        ", "if", "prefix", "==", "\"api\"", ":", "\n", "            ", "fname", "=", "name", "\n", "if", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                ", "target_module", "=", "sys", ".", "modules", "[", "\"tvm._api_internal\"", "]", "\n", "", "else", ":", "\n", "                ", "target_module", "=", "module", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "name", ".", "startswith", "(", "prefix", ")", ":", "\n", "                ", "continue", "\n", "", "fname", "=", "name", "[", "len", "(", "prefix", ")", "+", "1", ":", "]", "\n", "target_module", "=", "module", "\n", "\n", "", "if", "fname", ".", "find", "(", "\".\"", ")", "!=", "-", "1", ":", "\n", "            ", "continue", "\n", "", "f", "=", "get_global_func", "(", "name", ")", "\n", "ff", "=", "_get_api", "(", "f", ")", "\n", "ff", ".", "__name__", "=", "fname", "\n", "ff", ".", "__doc__", "=", "(", "\"TVM PackedFunc %s. \"", "%", "fname", ")", "\n", "setattr", "(", "target_module", ",", "ff", ".", "__name__", ",", "ff", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMType.__init__": [[65, 105], ["ctypes.Structure.__init__", "isinstance", "str.split", "head.startswith", "str", "int", "head.startswith", "int", "len", "head.startswith", "head.startswith", "head.startswith", "_api_internal._datatype_get_type_code", "ValueError", "head.find", "head.find", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["def", "__init__", "(", "self", ",", "type_str", ")", ":", "\n", "        ", "super", "(", "TVMType", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "type_str", ",", "np", ".", "dtype", ")", ":", "\n", "            ", "type_str", "=", "str", "(", "type_str", ")", "\n", "\n", "", "if", "type_str", "==", "\"bool\"", ":", "\n", "            ", "self", ".", "bits", "=", "1", "\n", "self", ".", "type_code", "=", "1", "\n", "self", ".", "lanes", "=", "1", "\n", "return", "\n", "\n", "", "arr", "=", "type_str", ".", "split", "(", "\"x\"", ")", "\n", "head", "=", "arr", "[", "0", "]", "\n", "self", ".", "lanes", "=", "int", "(", "arr", "[", "1", "]", ")", "if", "len", "(", "arr", ")", ">", "1", "else", "1", "\n", "bits", "=", "32", "\n", "\n", "if", "head", ".", "startswith", "(", "\"int\"", ")", ":", "\n", "            ", "self", ".", "type_code", "=", "0", "\n", "head", "=", "head", "[", "3", ":", "]", "\n", "", "elif", "head", ".", "startswith", "(", "\"uint\"", ")", ":", "\n", "            ", "self", ".", "type_code", "=", "1", "\n", "head", "=", "head", "[", "4", ":", "]", "\n", "", "elif", "head", ".", "startswith", "(", "\"float\"", ")", ":", "\n", "            ", "self", ".", "type_code", "=", "2", "\n", "head", "=", "head", "[", "5", ":", "]", "\n", "", "elif", "head", ".", "startswith", "(", "\"handle\"", ")", ":", "\n", "            ", "self", ".", "type_code", "=", "4", "\n", "bits", "=", "64", "\n", "head", "=", "\"\"", "\n", "", "elif", "head", ".", "startswith", "(", "\"custom\"", ")", ":", "\n", "            ", "low", ",", "high", "=", "head", ".", "find", "(", "'['", ")", ",", "head", ".", "find", "(", "']'", ")", "\n", "if", "not", "low", "or", "not", "high", "or", "low", ">=", "high", ":", "\n", "                ", "raise", "ValueError", "(", "\"Badly formatted custom type string %s\"", "%", "type_str", ")", "\n", "", "type_name", "=", "head", "[", "low", "+", "1", ":", "high", "]", "\n", "self", ".", "type_code", "=", "_api_internal", ".", "_datatype_get_type_code", "(", "type_name", ")", "\n", "head", "=", "head", "[", "high", "+", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Do not know how to handle type %s\"", "%", "type_str", ")", "\n", "", "bits", "=", "int", "(", "head", ")", "if", "head", "else", "bits", "\n", "self", ".", "bits", "=", "bits", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMType.__repr__": [[107, 119], ["_api_internal._datatype_get_type_name"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "bits", "==", "1", "and", "self", ".", "lanes", "==", "1", ":", "\n", "            ", "return", "\"bool\"", "\n", "", "if", "self", ".", "type_code", "in", "TVMType", ".", "CODE2STR", ":", "\n", "            ", "type_name", "=", "TVMType", ".", "CODE2STR", "[", "self", ".", "type_code", "]", "\n", "", "else", ":", "\n", "            ", "type_name", "=", "\"custom[%s]\"", "%", "_api_internal", ".", "_datatype_get_type_name", "(", "self", ".", "type_code", ")", "\n", "", "x", "=", "\"%s%d\"", "%", "(", "type_name", ",", "self", ".", "bits", ")", "\n", "if", "self", ".", "lanes", "!=", "1", ":", "\n", "            ", "x", "+=", "\"x%d\"", "%", "self", ".", "lanes", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMType.__eq__": [[120, 124], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "bits", "==", "other", ".", "bits", "and", "\n", "self", ".", "type_code", "==", "other", ".", "type_code", "and", "\n", "self", ".", "lanes", "==", "other", ".", "lanes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMType.__ne__": [[125, 127], ["runtime_ctypes.TVMType.__eq__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__init__": [[169, 173], ["ctypes.Structure.__init__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["def", "__init__", "(", "self", ",", "device_type", ",", "device_id", ")", ":", "\n", "        ", "super", "(", "TVMContext", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "device_id", "=", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.exist": [[174, 179], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "exist", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether this device exist.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "0", ")", "!=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.max_threads_per_block": [[180, 185], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_threads_per_block", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of threads on each block.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.warp_size": [[186, 191], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "warp_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Number of threads that executes in concurrent.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.max_shared_memory_per_block": [[192, 197], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_shared_memory_per_block", "(", "self", ")", ":", "\n", "        ", "\"\"\"Total amount of shared memory per block in bytes.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.compute_version": [[198, 211], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "compute_version", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get compute verison number in string.\n\n        Currently used to get compute capability of CUDA device.\n\n        Returns\n        -------\n        version : str\n            The version string in `major.minor` format.\n        \"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.device_name": [[212, 217], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "device_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the string name of device.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.max_clock_rate": [[218, 223], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_clock_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the max clock frequency of device.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.multi_processor_count": [[224, 229], ["_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "multi_processor_count", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the number of compute units of device.\"\"\"", "\n", "return", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.max_thread_dimensions": [[230, 241], ["json.loads", "_api_internal._GetDeviceAttr"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_thread_dimensions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the maximum size of each thread axis\n\n        Returns\n        -------\n        dims: List of int\n            The maximum length of threadIdx.x, threadIdx.y, threadIdx.z\n        \"\"\"", "\n", "return", "json", ".", "loads", "(", "_api_internal", ".", "_GetDeviceAttr", "(", "\n", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.sync": [[242, 245], ["base.check_call", "base._LIB.TVMSynchronize"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "sync", "(", "self", ")", ":", "\n", "        ", "\"\"\"Synchronize until jobs finished at the context.\"\"\"", "\n", "check_call", "(", "_LIB", ".", "TVMSynchronize", "(", "self", ".", "device_type", ",", "self", ".", "device_id", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__eq__": [[246, 250], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "isinstance", "(", "other", ",", "TVMContext", ")", "and", "\n", "self", ".", "device_id", "==", "other", ".", "device_id", "and", "\n", "self", ".", "device_type", "==", "other", ".", "device_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__ne__": [[251, 253], ["runtime_ctypes.TVMContext.__eq__"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.runtime_ctypes.TVMContext.__repr__": [[254, 262], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "device_type", ">=", "RPC_SESS_MASK", ":", "\n", "            ", "tbl_id", "=", "self", ".", "device_type", "/", "RPC_SESS_MASK", "-", "1", "\n", "dev_type", "=", "self", ".", "device_type", "%", "RPC_SESS_MASK", "\n", "return", "\"remote[%d]:%s(%d)\"", "%", "(", "\n", "tbl_id", ",", "TVMContext", ".", "MASK2STR", "[", "dev_type", "]", ",", "self", ".", "device_id", ")", "\n", "", "return", "\"%s(%d)\"", "%", "(", "\n", "TVMContext", ".", "MASK2STR", "[", "self", ".", "device_type", "]", ",", "self", ".", "device_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.NodeGeneric.asnode": [[52, 55], ["NotImplementedError"], "methods", ["None"], ["def", "asnode", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convert value to node\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic._set_class_node_base": [[28, 31], ["None"], "function", ["None"], ["def", "_set_class_node_base", "(", "cls", ")", ":", "\n", "    ", "global", "_CLASS_NODE_BASE", "\n", "_CLASS_NODE_BASE", "=", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic._scalar_type_inference": [[33, 48], ["hasattr", "str", "isinstance", "isinstance", "isinstance", "NotImplementedError"], "function", ["None"], ["", "def", "_scalar_type_inference", "(", "value", ")", ":", "\n", "    ", "if", "hasattr", "(", "value", ",", "'dtype'", ")", ":", "\n", "        ", "dtype", "=", "str", "(", "value", ".", "dtype", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "        ", "dtype", "=", "'bool'", "\n", "", "elif", "isinstance", "(", "value", ",", "float", ")", ":", "\n", "# We intentionally convert the float to float32 since it's more common in DL.", "\n", "        ", "dtype", "=", "'float32'", "\n", "", "elif", "isinstance", "(", "value", ",", "int", ")", ":", "\n", "# We intentionally convert the python int to int32 since it's more common in DL.", "\n", "        ", "dtype", "=", "'int32'", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Cannot automatically inference the type.'", "\n", "' value={}'", ".", "format", "(", "value", ")", ")", "\n", "", "return", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.convert_to_node": [[57, 96], ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "ValueError", "node_generic.const", "node_generic.const", "_api_internal._str", "_api_internal._Array", "value.items", "_api_internal._Map", "value.asnode", "node_generic.convert_to_node", "vlist.append", "vlist.append", "type", "ValueError", "node_generic.convert_to_node", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.const", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.const", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.NodeGeneric.asnode", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.convert_to_node", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.convert_to_node"], ["", "", "def", "convert_to_node", "(", "value", ")", ":", "\n", "    ", "\"\"\"Convert a python value to corresponding node type.\n\n    Parameters\n    ----------\n    value : str\n        The value to be inspected.\n\n    Returns\n    -------\n    node : Node\n        The corresponding node value.\n    \"\"\"", "\n", "if", "isinstance", "(", "value", ",", "_CLASS_NODE_BASE", ")", ":", "\n", "        ", "return", "value", "\n", "", "if", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "        ", "return", "const", "(", "value", ",", "'uint1x1'", ")", "\n", "", "if", "isinstance", "(", "value", ",", "Number", ")", ":", "\n", "        ", "return", "const", "(", "value", ")", "\n", "", "if", "isinstance", "(", "value", ",", "string_types", ")", ":", "\n", "        ", "return", "_api_internal", ".", "_str", "(", "value", ")", "\n", "", "if", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "value", "=", "[", "convert_to_node", "(", "x", ")", "for", "x", "in", "value", "]", "\n", "return", "_api_internal", ".", "_Array", "(", "*", "value", ")", "\n", "", "if", "isinstance", "(", "value", ",", "dict", ")", ":", "\n", "        ", "vlist", "=", "[", "]", "\n", "for", "item", "in", "value", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "not", "isinstance", "(", "item", "[", "0", "]", ",", "_CLASS_NODE_BASE", ")", "and", "\n", "not", "isinstance", "(", "item", "[", "0", "]", ",", "string_types", ")", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"key of map must already been a container type\"", ")", "\n", "", "vlist", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "vlist", ".", "append", "(", "convert_to_node", "(", "item", "[", "1", "]", ")", ")", "\n", "", "return", "_api_internal", ".", "_Map", "(", "*", "vlist", ")", "\n", "", "if", "isinstance", "(", "value", ",", "NodeGeneric", ")", ":", "\n", "        ", "return", "value", ".", "asnode", "(", ")", "\n", "", "if", "value", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "raise", "ValueError", "(", "\"don't know how to convert type %s to node\"", "%", "type", "(", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.const": [[98, 117], ["_api_internal._const", "node_generic._scalar_type_inference"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic._scalar_type_inference"], ["", "def", "const", "(", "value", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct a constant value for a given type.\n\n    Parameters\n    ----------\n    value : int or float\n        The input value\n\n    dtype : str or None, optional\n        The data type.\n\n    Returns\n    -------\n    expr : Expr\n        Constant expression corresponds to the value.\n    \"\"\"", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "_scalar_type_inference", "(", "value", ")", "\n", "", "return", "_api_internal", ".", "_const", "(", "value", ",", "dtype", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.node.NodeBase.__del__": [[60, 63], ["base.check_call", "base._LIB.TVMNodeFree"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["\n", "", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "_api_internal", ".", "_raw_ptr", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.node.NodeBase.__getattr__": [[64, 77], ["types.TVMValue", "ctypes.c_int", "ctypes.c_int", "base.check_call", "base._LIB.TVMNodeGetAttr", "AttributeError", "base.c_str", "ctypes.byref", "ctypes.byref", "ctypes.byref", "str", "type"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "same_as", "(", "other", ")", "\n", "\n", "", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "\n", "", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "cls", "=", "type", "(", "self", ")", "\n", "return", "(", "_new_object", ",", "(", "cls", ",", ")", ",", "self", ".", "__getstate__", "(", ")", ")", "\n", "\n", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "handle", "=", "self", ".", "handle", "\n", "if", "handle", "is", "not", "None", ":", "\n", "            ", "return", "{", "'handle'", ":", "_api_internal", ".", "_save_json", "(", "self", ")", "}", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.node.NodeBase.__init_handle_by_constructor__": [[78, 101], ["__init_by_constructor__", "isinstance", "NodeHandle"], "methods", ["None"], ["", "return", "{", "'handle'", ":", "None", "}", "\n", "\n", "", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "# pylint: disable=assigning-non-slot", "\n", "        ", "handle", "=", "state", "[", "'handle'", "]", "\n", "if", "handle", "is", "not", "None", ":", "\n", "            ", "json_str", "=", "handle", "\n", "other", "=", "_api_internal", ".", "_load_json", "(", "json_str", ")", "\n", "self", ".", "handle", "=", "other", ".", "handle", "\n", "other", ".", "handle", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "handle", "=", "None", "\n", "\n", "", "", "def", "same_as", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"check object identity equality\"\"\"", "\n", "if", "not", "isinstance", "(", "other", ",", "NodeBase", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "__hash__", "(", ")", "==", "other", ".", "__hash__", "(", ")", "\n", "\n", "\n", "", "", "def", "register_node", "(", "type_key", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.node._register_node": [[33, 36], ["None"], "function", ["None"], ["        ", "from", ".", "_cy3", ".", "core", "import", "_register_node", ",", "NodeBase", "as", "_NodeBase", "\n", "", "else", ":", "\n", "        ", "from", ".", "_cy2", ".", "core", "import", "_register_node", ",", "NodeBase", "as", "_NodeBase", "\n", "", "", "except", "IMPORT_EXCEPT", ":", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.node._return_node": [[37, 50], ["ctypes.c_int", "base.check_call", "NODE_TYPE.get", "NODE_TYPE.get.__new__", "isinstance", "NodeHandle", "base._LIB.TVMNodeGetTypeIndex", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["# pylint: disable=wrong-import-position", "\n", "    ", "from", ".", "_ctypes", ".", "node", "import", "_register_node", ",", "NodeBase", "as", "_NodeBase", "\n", "\n", "\n", "", "def", "_new_object", "(", "cls", ")", ":", "\n", "    ", "\"\"\"Helper function for pickle\"\"\"", "\n", "return", "cls", ".", "__new__", "(", "cls", ")", "\n", "\n", "\n", "", "class", "NodeBase", "(", "_NodeBase", ")", ":", "\n", "    ", "\"\"\"NodeBase is the base class of all TVM language AST object.\"\"\"", "\n", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "_api_internal", ".", "_format_str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray.NDArrayBase.__init__": [[69, 79], ["None"], "methods", ["None"], ["\n", "return", "TVMContext", "(", "2", ",", "dev_id", ")", "\n", "\n", "", "def", "rocm", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray.NDArrayBase.__del__": [[80, 83], ["base.check_call", "base._LIB.TVMArrayFree"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray.NDArrayBase._tvm_handle": [[84, 87], ["ctypes.cast"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray.NDArrayBase.to_dlpack": [[88, 98], ["ctypes.c_void_p", "base.check_call", "ctypes.pythonapi.PyCapsule_New", "base._LIB.TVMArrayToDLPack", "ctypes.byref"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["return", "TVMContext", "(", "10", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "opencl", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._from_dlpack": [[39, 51], ["ctypes.py_object", "ctypes.pythonapi.PyCapsule_IsValid", "ValueError", "ctypes.pythonapi.PyCapsule_GetPointer", "ctypes.cast", "runtime_ctypes.TVMArrayHandle", "base.check_call", "ctypes.pythonapi.PyCapsule_SetName", "ctypes.pythonapi.PyCapsule_SetDestructor", "ndarray._make_array", "base._LIB.TVMArrayFromDLPack", "TVMPyCapsuleDestructor", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._make_array"], ["\n", "\n", "\n", "", "def", "cpu", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._dlpack_deleter": [[53, 61], ["ctypes.cast", "ctypes.pythonapi.PyCapsule_IsValid", "ctypes.pythonapi.PyCapsule_GetPointer", "ctypes.cast", "base._LIB.TVMDLManagedTensorCallDeleter", "ctypes.pythonapi.PyCapsule_SetDestructor", "TVMPyCapsuleDestructor"], "function", ["None"], ["\n", "return", "TVMContext", "(", "1", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "gpu", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._make_array": [[100, 109], ["ctypes.cast", "fcreate", "ctypes.cast"], "function", ["None"], ["\n", "return", "TVMContext", "(", "4", ",", "dev_id", ")", "\n", "\n", "\n", "", "def", "metal", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._reg_extension": [[112, 119], ["types._wrap_arg_func", "fcreate", "types._return_handle"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._wrap_arg_func", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._return_handle"], ["\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._reg_ndarray": [[122, 125], ["None"], "function", ["None"], ["\n", "", "def", "vpi", "(", "dev_id", "=", "0", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.ndarray._set_class_ndarray": [[128, 131], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._return_handle": [[48, 54], ["isinstance", "ctypes.c_void_p"], "function", ["None"], ["def", "_return_handle", "(", "x", ")", ":", "\n", "    ", "\"\"\"return handle\"\"\"", "\n", "handle", "=", "x", ".", "v_handle", "\n", "if", "not", "isinstance", "(", "handle", ",", "ctypes", ".", "c_void_p", ")", ":", "\n", "        ", "handle", "=", "ctypes", ".", "c_void_p", "(", "handle", ")", "\n", "", "return", "handle", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._return_bytes": [[55, 67], ["bytearray", "isinstance", "ctypes.c_void_p", "ctypes.cast", "ctypes.memmove", "RuntimeError", "ctypes.POINTER"], "function", ["None"], ["", "def", "_return_bytes", "(", "x", ")", ":", "\n", "    ", "\"\"\"return bytes\"\"\"", "\n", "handle", "=", "x", ".", "v_handle", "\n", "if", "not", "isinstance", "(", "handle", ",", "ctypes", ".", "c_void_p", ")", ":", "\n", "        ", "handle", "=", "ctypes", ".", "c_void_p", "(", "handle", ")", "\n", "", "arr", "=", "ctypes", ".", "cast", "(", "handle", ",", "ctypes", ".", "POINTER", "(", "TVMByteArray", ")", ")", "[", "0", "]", "\n", "size", "=", "arr", ".", "size", "\n", "res", "=", "bytearray", "(", "size", ")", "\n", "rptr", "=", "(", "ctypes", ".", "c_byte", "*", "size", ")", ".", "from_buffer", "(", "res", ")", "\n", "if", "not", "ctypes", ".", "memmove", "(", "rptr", ",", "arr", ".", "data", ",", "size", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'memmove failed'", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._return_context": [[68, 75], ["struct.pack", "struct.unpack", "runtime_ctypes.TVMContext"], "function", ["None"], ["", "def", "_return_context", "(", "value", ")", ":", "\n", "    ", "\"\"\"return TVMContext\"\"\"", "\n", "# use bit unpacking from int64 view", "\n", "# We use this to get around ctypes issue on Union of Structure", "\n", "data", "=", "struct", ".", "pack", "(", "\"=q\"", ",", "value", ".", "v_int64", ")", "\n", "arr", "=", "struct", ".", "unpack", "(", "\"=ii\"", ",", "data", ")", "\n", "return", "TVMContext", "(", "arr", "[", "0", "]", ",", "arr", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._wrap_arg_func": [[77, 83], ["ctypes.c_int", "base.check_call", "return_f", "base._LIB.TVMCbArgToReturn", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "_wrap_arg_func", "(", "return_f", ",", "type_code", ")", ":", "\n", "    ", "tcode", "=", "ctypes", ".", "c_int", "(", "type_code", ")", "\n", "def", "_wrap_func", "(", "x", ")", ":", "\n", "        ", "check_call", "(", "_LIB", ".", "TVMCbArgToReturn", "(", "ctypes", ".", "byref", "(", "x", ")", ",", "tcode", ")", ")", "\n", "return", "return_f", "(", "x", ")", "\n", "", "return", "_wrap_func", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._ctx_to_int64": [[84, 88], ["struct.pack", "struct.unpack"], "function", ["None"], ["", "def", "_ctx_to_int64", "(", "ctx", ")", ":", "\n", "    ", "\"\"\"Pack context into int64 in native endian\"\"\"", "\n", "data", "=", "struct", ".", "pack", "(", "\"=ii\"", ",", "ctx", ".", "device_type", ",", "ctx", ".", "device_id", ")", "\n", "return", "struct", ".", "unpack", "(", "\"=q\"", ",", "data", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.vmobj.ObjectBase.__init__": [[51, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "handle", ")", ":", "\n", "        ", "self", ".", "handle", "=", "handle", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.vmobj._register_object": [[30, 33], ["None"], "function", ["None"], ["def", "_register_object", "(", "index", ",", "cls", ")", ":", "\n", "    ", "\"\"\"register object class\"\"\"", "\n", "OBJECT_TYPE", "[", "index", "]", "=", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.vmobj._return_object": [[35, 44], ["ctypes.c_int", "base.check_call", "OBJECT_TYPE.get", "OBJECT_TYPE.get.", "isinstance", "ObjectHandle", "base._LIB.TVMGetObjectTag", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.check_call"], ["", "def", "_return_object", "(", "x", ")", ":", "\n", "    ", "handle", "=", "x", ".", "v_handle", "\n", "if", "not", "isinstance", "(", "handle", ",", "ObjectHandle", ")", ":", "\n", "        ", "handle", "=", "ObjectHandle", "(", "handle", ")", "\n", "", "tag", "=", "ctypes", ".", "c_int", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMGetObjectTag", "(", "handle", ",", "ctypes", ".", "byref", "(", "tag", ")", ")", ")", "\n", "cls", "=", "OBJECT_TYPE", ".", "get", "(", "tag", ".", "value", ",", "ObjectBase", ")", "\n", "obj", "=", "cls", "(", "handle", ")", "\n", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.FunctionBase.__init__": [[178, 191], ["None"], "methods", ["None"], ["\n", "if", "callable", "(", "func_name", ")", ":", "\n", "        ", "f", "=", "func_name", "\n", "func_name", "=", "f", ".", "__name__", "\n", "\n", "", "if", "not", "isinstance", "(", "func_name", ",", "str", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.FunctionBase.__del__": [[192, 196], ["base._LIB.TVMFuncFree", "base.get_last_ffi_error"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error"], ["        ", "raise", "ValueError", "(", "\"expect string function name\"", ")", "\n", "\n", "", "ioverride", "=", "ctypes", ".", "c_int", "(", "override", ")", "\n", "def", "register", "(", "myf", ")", ":", "\n", "        ", "\"\"\"internal register function\"\"\"", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.FunctionBase.__call__": [[197, 214], ["function._make_tvm_args", "types.TVMValue", "ctypes.c_int", "base._LIB.TVMFuncCall", "base.get_last_ffi_error", "ctypes.c_int", "ctypes.byref", "ctypes.byref"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._make_tvm_args", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error"], ["if", "not", "isinstance", "(", "myf", ",", "Function", ")", ":", "\n", "            ", "myf", "=", "convert_to_tvm_func", "(", "myf", ")", "\n", "", "check_call", "(", "_LIB", ".", "TVMFuncRegisterGlobal", "(", "\n", "c_str", "(", "func_name", ")", ",", "myf", ".", "handle", ",", "ioverride", ")", ")", "\n", "return", "myf", "\n", "", "if", "f", ":", "\n", "        ", "return", "register", "(", "f", ")", "\n", "", "return", "register", "\n", "\n", "\n", "", "def", "get_global_func", "(", "name", ",", "allow_missing", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._ctypes_free_resource": [[43, 47], ["ctypes.cast", "ctypes.pythonapi.Py_DecRef"], "function", ["None"], ["    ", "from", ".", "_ctypes", ".", "function", "import", "_set_class_function", ",", "_set_class_module", "\n", "from", ".", "_ctypes", ".", "function", "import", "FunctionBase", "as", "_FunctionBase", "\n", "from", ".", "_ctypes", ".", "function", "import", "convert_to_tvm_func", "\n", "\n", "", "FunctionHandle", "=", "ctypes", ".", "c_void_p", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.convert_to_tvm_func": [[52, 102], ["FunctionHandle", "types.TVMPackedCFunc", "ctypes.py_object", "ctypes.pythonapi.Py_IncRef", "_CLASS_FUNCTION", "base._LIB.TVMFuncCreateFromCFunc", "base.get_last_ffi_error", "isinstance", "local_pyfunc", "isinstance", "function._make_tvm_args", "ctypes.byref", "range", "traceback.format_exc", "base.py2cerror", "base._LIB.TVMAPISetLastError", "ValueError", "isinstance", "TVMRetValueHandle", "base._LIB.TVMCFuncSetReturn", "base.get_last_ffi_error", "base.c_str", "ctypes.c_int"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._make_tvm_args", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.py2cerror", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str"], ["\n", "\n", "\n", "", "class", "ModuleBase", "(", "object", ")", ":", "\n", "    ", "\"\"\"Base class for module\"\"\"", "\n", "__slots__", "=", "[", "\"handle\"", ",", "\"_entry\"", ",", "\"entry_name\"", "]", "\n", "\n", "def", "__init__", "(", "self", ",", "handle", ")", ":", "\n", "        ", "self", ".", "handle", "=", "handle", "\n", "self", ".", "_entry", "=", "None", "\n", "self", ".", "entry_name", "=", "\"__tvm_main__\"", "\n", "\n", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "check_call", "(", "_LIB", ".", "TVMModFree", "(", "self", ".", "handle", ")", ")", "\n", "\n", "", "@", "property", "\n", "def", "entry_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the entry function\n\n        Returns\n        -------\n        f : Function\n            The entry function if exist\n        \"\"\"", "\n", "if", "self", ".", "_entry", ":", "\n", "            ", "return", "self", ".", "_entry", "\n", "", "self", ".", "_entry", "=", "self", ".", "get_function", "(", "self", ".", "entry_name", ")", "\n", "return", "self", ".", "_entry", "\n", "\n", "", "def", "get_function", "(", "self", ",", "name", ",", "query_imports", "=", "False", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._make_tvm_args": [[104, 172], ["len", "enumerate", "isinstance", "isinstance", "ctypes.cast", "isinstance", "ctypes.c_void_p", "isinstance", "isinstance", "isinstance", "base.c_str", "isinstance", "str", "types._ctx_to_int64", "isinstance", "runtime_ctypes.TVMByteArray", "ctypes.cast", "len", "ctypes.c_void_p", "temp_args.append", "isinstance", "ctypes.POINTER", "ctypes.addressof", "base.c_str", "isinstance", "node_generic.convert_to_node", "temp_args.append", "isinstance", "isinstance", "len", "isinstance", "callable", "function.convert_to_tvm_func", "temp_args.append", "isinstance", "TypeError", "type"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.types._ctx_to_int64", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.c_str", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.node_generic.convert_to_node", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.convert_to_tvm_func"], ["\n", "ret_handle", "=", "FunctionHandle", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMModGetFunction", "(", "\n", "self", ".", "handle", ",", "c_str", "(", "name", ")", ",", "\n", "ctypes", ".", "c_int", "(", "query_imports", ")", ",", "\n", "ctypes", ".", "byref", "(", "ret_handle", ")", ")", ")", "\n", "if", "not", "ret_handle", ".", "value", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"Module has no function '%s'\"", "%", "name", ")", "\n", "", "return", "Function", "(", "ret_handle", ",", "False", ")", "\n", "\n", "", "def", "import_module", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Add module to the import list of current one.\n\n        Parameters\n        ----------\n        module : Module\n            The other module.\n        \"\"\"", "\n", "check_call", "(", "_LIB", ".", "TVMModImport", "(", "self", ".", "handle", ",", "module", ".", "handle", ")", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "name", ",", "string_types", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Can only take string as function name\"", ")", "\n", "", "return", "self", ".", "get_function", "(", "name", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "if", "self", ".", "_entry", ":", "\n", "            ", "return", "self", ".", "_entry", "(", "*", "args", ")", "\n", "", "f", "=", "self", ".", "entry_func", "\n", "return", "f", "(", "*", "args", ")", "\n", "\n", "\n", "", "", "def", "register_func", "(", "func_name", ",", "f", "=", "None", ",", "override", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function.__init_handle_by_constructor__": [[216, 231], ["function._make_tvm_args", "types.TVMValue", "ctypes.c_int", "base._LIB.TVMFuncCall", "base.get_last_ffi_error", "ctypes.c_int", "ctypes.byref", "ctypes.byref"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._make_tvm_args", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.base.get_last_ffi_error"], ["\n", "handle", "=", "FunctionHandle", "(", ")", "\n", "check_call", "(", "_LIB", ".", "TVMFuncGetGlobal", "(", "c_str", "(", "name", ")", ",", "ctypes", ".", "byref", "(", "handle", ")", ")", ")", "\n", "if", "handle", ".", "value", ":", "\n", "        ", "return", "Function", "(", "handle", ",", "False", ")", "\n", "\n", "", "if", "allow_missing", ":", "\n", "        ", "return", "None", "\n", "\n", "", "raise", "ValueError", "(", "\"Cannot find global function %s\"", "%", "name", ")", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._return_module": [[233, 239], ["_CLASS_MODULE", "isinstance", "ModuleHandle"], "function", ["None"], ["\n", "\n", "", "def", "list_global_func_names", "(", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._handle_return_func": [[241, 247], ["_CLASS_FUNCTION", "isinstance", "FunctionHandle"], "function", ["None"], ["\n", "plist", "=", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_char_p", ")", "(", ")", "\n", "size", "=", "ctypes", ".", "c_uint", "(", ")", "\n", "\n", "check_call", "(", "_LIB", ".", "TVMFuncListGlobalNames", "(", "ctypes", ".", "byref", "(", "size", ")", ",", "\n", "ctypes", ".", "byref", "(", "plist", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._set_class_module": [[264, 268], ["None"], "function", ["None"], ["\n", "fdict", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._set_class_function": [[269, 272], ["None"], "function", ["None"], ["def", "_list", "(", "name", ",", "func", ")", ":", "\n", "        ", "fdict", "[", "name", "]", "=", "func", "\n", "", "myf", "=", "convert_to_tvm_func", "(", "_list", ")", "\n", "ret", "=", "finit", "(", "myf", ".", "handle", ")", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ctypes.function._set_class_object": [[273, 276], ["None"], "function", ["None"], ["_", "=", "myf", "\n", "if", "ret", "!=", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"cannot initialize with %s\"", "%", "finit", ")", "\n", "", "return", "fdict", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.add_arguments": [[6, 11], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_arguments", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--regional_answer\"", ",", "help", "=", "\"path to regional_answer\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--document_file\"", ",", "help", "=", "\"path to train document file\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--evidence_file\"", ",", "help", "=", "\"path to evidence file\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "help", "=", "\"path to output file\"", ",", "required", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.get_index": [[12, 14], ["i.start", "re.finditer"], "function", ["None"], ["", "def", "get_index", "(", "text", ",", "item", "=", "''", ")", ":", "\n", "    ", "return", "[", "i", ".", "start", "(", ")", "for", "i", "in", "re", ".", "finditer", "(", "item", ",", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.is_overlapping": [[16, 18], ["max", "min"], "function", ["None"], ["", "def", "is_overlapping", "(", "x1", ",", "x2", ",", "y1", ",", "y2", ")", ":", "\n", "    ", "return", "max", "(", "x1", ",", "y1", ")", "<=", "min", "(", "x2", ",", "y2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.remove_overlap": [[19, 38], ["range", "len", "range", "convert_answer_to_text.remove_overlap", "len", "len", "convert_answer_to_text.is_overlapping", "position_no_overlap.append", "position_no_overlap.remove", "position_no_overlap.remove", "min", "max"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.remove_overlap", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.is_overlapping"], ["", "def", "remove_overlap", "(", "positions", ")", ":", "\n", "    ", "position_no_overlap", "=", "positions", "[", ":", "]", "\n", "all_no_overlap", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "position_no_overlap", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "position_no_overlap", ")", ")", ":", "\n", "            ", "if", "i", "!=", "j", "and", "is_overlapping", "(", "position_no_overlap", "[", "i", "]", "[", "0", "]", ",", "position_no_overlap", "[", "i", "]", "[", "1", "]", ",", "position_no_overlap", "[", "j", "]", "[", "0", "]", ",", "position_no_overlap", "[", "j", "]", "[", "1", "]", ",", ")", ":", "\n", "                ", "position_no_overlap", ".", "append", "(", "(", "min", "(", "position_no_overlap", "[", "i", "]", "[", "0", "]", ",", "position_no_overlap", "[", "j", "]", "[", "0", "]", ")", ",", "max", "(", "position_no_overlap", "[", "i", "]", "[", "1", "]", ",", "position_no_overlap", "[", "j", "]", "[", "1", "]", ")", ")", ")", "\n", "remove1", "=", "position_no_overlap", "[", "i", "]", "\n", "remove2", "=", "position_no_overlap", "[", "j", "]", "\n", "position_no_overlap", ".", "remove", "(", "remove1", ")", "\n", "position_no_overlap", ".", "remove", "(", "remove2", ")", "\n", "all_no_overlap", "=", "1", "\n", "break", "\n", "", "", "if", "all_no_overlap", "==", "1", ":", "\n", "            ", "break", "\n", "", "", "if", "all_no_overlap", "==", "0", "or", "len", "(", "positions", ")", "==", "1", ":", "\n", "        ", "return", "positions", "\n", "", "else", ":", "\n", "        ", "return", "remove_overlap", "(", "position_no_overlap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.pend_position": [[39, 45], ["len", "len", "max", "min", "len", "source[].split", "source[].split"], "function", ["None"], ["", "", "def", "pend_position", "(", "start", ",", "end", ",", "source", ")", ":", "\n", "    ", "left", "=", "len", "(", "' '", ".", "join", "(", "source", "[", ":", "start", "]", ".", "split", "(", "' '", ")", "[", "-", "6", ":", "]", ")", ")", "\n", "right", "=", "len", "(", "' '", ".", "join", "(", "source", "[", "end", "+", "1", ":", "]", ".", "split", "(", "' '", ")", "[", ":", "6", "]", ")", ")", "\n", "left_pend", "=", "max", "(", "start", "-", "left", ",", "0", ")", "\n", "right_pend", "=", "min", "(", "end", "+", "right", ",", "len", "(", "source", ")", ")", "\n", "return", "left_pend", ",", "right_pend", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.answer_to_text": [[46, 100], ["source.find", "source.find", "range", "len", "convert_answer_to_text.remove_overlap", "len", "convert_answer_to_text.pend_position", "len", "convert_answer_to_text.is_overlapping", "position.append", "len", "len", "convert_answer_to_text.pend_position", "len", "ans.split", "len", "ans.split"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.remove_overlap", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.pend_position", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.is_overlapping", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.pend_position"], ["", "def", "answer_to_text", "(", "answer", ",", "source", ")", ":", "\n", "    ", "span_text", "=", "[", "]", "\n", "start_position", ",", "end_position", "=", "0", ",", "0", "\n", "for", "ans", "in", "answer", ":", "\n", "        ", "start_position", "=", "source", ".", "find", "(", "ans", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "end_position", "=", "start_position", "+", "len", "(", "ans", ")", "-", "1", "\n", "\n", "if", "len", "(", "ans", ".", "split", "(", "' '", ")", ")", "<", "6", ":", "\n", "                ", "start_position", ",", "end_position", "=", "pend_position", "(", "start_position", ",", "end_position", ",", "source", ")", "\n", "", "break", "\n", "\n", "\n", "", "", "position", "=", "[", "[", "start_position", ",", "end_position", "]", "]", "\n", "for", "ans", "in", "answer", "[", "1", ":", "]", ":", "\n", "        ", "start", "=", "source", ".", "find", "(", "ans", ")", "\n", "if", "start", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "end", "=", "start", "+", "len", "(", "ans", ")", "-", "1", "\n", "\n", "if", "len", "(", "ans", ".", "split", "(", "' '", ")", ")", "<", "6", ":", "\n", "            ", "start", ",", "end", "=", "pend_position", "(", "start", ",", "end", ",", "source", ")", "\n", "\n", "", "match", "=", "0", "\n", "for", "index", "in", "range", "(", "len", "(", "position", ")", ")", ":", "\n", "            ", "if", "is_overlapping", "(", "start", ",", "end", ",", "position", "[", "index", "]", "[", "0", "]", ",", "position", "[", "index", "]", "[", "1", "]", ")", ":", "\n", "                ", "match", "=", "1", "\n", "if", "start", "<", "position", "[", "index", "]", "[", "0", "]", "and", "end", ">", "position", "[", "index", "]", "[", "1", "]", ":", "\n", "                    ", "position", "[", "index", "]", "[", "0", "]", "=", "start", "\n", "position", "[", "index", "]", "[", "1", "]", "=", "end", "\n", "", "elif", "start", "<", "position", "[", "index", "]", "[", "0", "]", "and", "end", "<", "position", "[", "index", "]", "[", "1", "]", ":", "\n", "                    ", "position", "[", "index", "]", "[", "0", "]", "=", "start", "\n", "", "elif", "start", ">", "position", "[", "index", "]", "[", "0", "]", "and", "end", ">", "position", "[", "index", "]", "[", "1", "]", ":", "\n", "                    ", "position", "[", "index", "]", "[", "1", "]", "=", "end", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "break", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "", "", "if", "match", "==", "0", ":", "\n", "            ", "position", ".", "append", "(", "[", "start", ",", "end", "]", ")", "\n", "\n", "", "", "if", "len", "(", "position", ")", "==", "1", ":", "\n", "        ", "position_no_overlap", "=", "position", "\n", "", "else", ":", "\n", "        ", "position_no_overlap", "=", "remove_overlap", "(", "position", ")", "\n", "\n", "", "if", "len", "(", "position_no_overlap", ")", "==", "1", "and", "position_no_overlap", "[", "0", "]", "==", "[", "0", ",", "0", "]", ":", "\n", "        ", "return", "''", "\n", "\n", "", "span_text", "=", "[", "source", "[", "i", ":", "j", "+", "1", "]", "for", "(", "i", ",", "j", ")", "in", "position_no_overlap", "]", "\n", "return", "' . '", ".", "join", "(", "span_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_answer_to_text.pend_text": [[101, 115], ["source.find", "source.find", "split_token", "print", "print", "ValueError", "len", "len", "source[].split", "source[].split"], "function", ["None"], ["", "def", "pend_text", "(", "answer", ",", "source", ")", ":", "\n", "    ", "answer", "=", "' '", ".", "join", "(", "split_token", "(", "answer", ")", ")", "\n", "start", "=", "source", ".", "find", "(", "answer", ")", "\n", "if", "start", "==", "-", "1", ":", "\n", "        ", "print", "(", "answer", ")", "\n", "print", "(", "source", ")", "\n", "raise", "ValueError", "(", "\"answer must in document\"", ")", "\n", "", "end", "=", "start", "+", "len", "(", "answer", ")", "-", "1", "\n", "left_pend", "=", "' '", ".", "join", "(", "source", "[", ":", "start", "]", ".", "split", "(", "' '", ")", "[", "-", "6", ":", "]", ")", "\n", "left_pend_position", "=", "source", ".", "find", "(", "left_pend", ")", "\n", "right_pend", "=", "' '", ".", "join", "(", "source", "[", "end", "+", "1", ":", "]", ".", "split", "(", "' '", ")", "[", ":", "6", "]", ")", "\n", "right_pend_position", "=", "end", "+", "len", "(", "right_pend", ")", "\n", "pend_answer", "=", "source", "[", "left_pend_position", ":", "right_pend_position", "+", "1", "]", "\n", "return", "pend_answer", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub": [[27, 32], ["re.sub", "re.sub"], "function", ["None"], ["def", "re_sub", "(", "pattern", ",", "repl", ",", "text", ",", "flags", "=", "None", ")", ":", "\n", "    ", "if", "flags", "is", "None", ":", "\n", "        ", "return", "re", ".", "sub", "(", "pattern", ",", "repl", ",", "text", ",", "flags", "=", "FLAGS", ")", "\n", "", "else", ":", "\n", "        ", "return", "re", ".", "sub", "(", "pattern", ",", "repl", ",", "text", ",", "flags", "=", "(", "FLAGS", "|", "flags", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.clean_txt": [[34, 52], ["re.sub", "re.sub", "re.sub", "hp_preprocess.re_sub", "hp_preprocess.re_sub", "hp_preprocess.re_sub", "hp_preprocess.re_sub", "hp_preprocess.re_sub", "hp_preprocess.re_sub", "re_sub.strip"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.re_sub"], ["", "", "def", "clean_txt", "(", "text", ")", ":", "\n", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r\"[a-zA-Z]+\\/[a-zA-Z]+\"", ",", "\" \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\\n\"", ",", "\" \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"&#160;\"", ",", "\"\"", ",", "text", ")", "\n", "\n", "# Remove URL", "\n", "text", "=", "re_sub", "(", "r\"(http)\\S+\"", ",", "\"\"", ",", "text", ")", "\n", "text", "=", "re_sub", "(", "r\"(www)\\S+\"", ",", "\"\"", ",", "text", ")", "\n", "text", "=", "re_sub", "(", "r\"(href)\\S+\"", ",", "\"\"", ",", "text", ")", "\n", "# Remove multiple spaces", "\n", "text", "=", "re_sub", "(", "r\"[ \\s\\t\\n]+\"", ",", "\" \"", ",", "text", ")", "\n", "\n", "# remove repetition", "\n", "text", "=", "re_sub", "(", "r\"([!?.]){2,}\"", ",", "r\"\\1\"", ",", "text", ")", "\n", "text", "=", "re_sub", "(", "r\"\\b(\\S*?)(.)\\2{2,}\\b\"", ",", "r\"\\1\\2\"", ",", "text", ")", "\n", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.write_jsonlist": [[54, 57], ["jsonlines.open", "writer.write_all"], "function", ["None"], ["", "def", "write_jsonlist", "(", "list_of_json_objects", ",", "output_filename", ")", ":", "\n", "    ", "with", "jsonlines", ".", "open", "(", "output_filename", ",", "mode", "=", "'w'", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write_all", "(", "list_of_json_objects", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.main": [[59, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "xml.parse().getroot", "print", "xml.parse().getroot", "ET.parse().getroot.findall", "ET.parse().getroot.findall", "tqdm.tqdm", "collections.defaultdict", "collections.defaultdict.items", "len", "len", "zip", "xml.tostring().decode", "hp_preprocess.clean_txt", "int", "open", "simplejson.load().items", "os.path.join", "pathlib.Path().parent.mkdir", "hp_preprocess.write_jsonlist", "xml.parse", "xml.parse", "len", "xml.tostring", "simplejson.load", "splits[].append", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.None.triviaqa.TriviaQA.decode", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.clean_txt", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.hp_preprocess.write_jsonlist", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.tvm.module.load"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--train-file'", ",", "default", "=", "'articles-training-byarticle-20181122.xml'", ")", "\n", "parser", ".", "add_argument", "(", "'--labels-file'", ",", "default", "=", "'ground-truth-training-byarticle-20181122.xml'", ")", "\n", "parser", ".", "add_argument", "(", "'--splits-file'", ",", "default", "=", "'hp-splits.json'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-dir'", ",", "help", "=", "'path to write outfile files'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "print", "(", "'loading articles...'", ")", "\n", "articles_root", "=", "ET", ".", "parse", "(", "args", ".", "train_file", ")", ".", "getroot", "(", ")", "\n", "print", "(", "'loading labels...'", ")", "\n", "labels_root", "=", "ET", ".", "parse", "(", "args", ".", "labels_file", ")", ".", "getroot", "(", ")", "\n", "articles", "=", "articles_root", ".", "findall", "(", "'article'", ")", "\n", "labels", "=", "labels_root", ".", "findall", "(", "'article'", ")", "\n", "assert", "len", "(", "articles", ")", "==", "len", "(", "labels", ")", "\n", "\n", "data", "=", "{", "}", "\n", "for", "article", ",", "label", "in", "tqdm", "(", "zip", "(", "articles", ",", "labels", ")", ",", "total", "=", "len", "(", "labels", ")", ",", "desc", "=", "\"preprocessing\"", ")", ":", "\n", "        ", "text", "=", "ET", ".", "tostring", "(", "article", ",", "method", "=", "'text'", ",", "encoding", "=", "\"utf-8\"", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "text", "=", "clean_txt", "(", "text", ")", "\n", "id_", "=", "int", "(", "label", ".", "attrib", "[", "'id'", "]", ")", "\n", "data", "[", "id_", "]", "=", "{", "'text'", ":", "text", ",", "'label'", ":", "label", ".", "attrib", "[", "'hyperpartisan'", "]", ",", "'id'", ":", "id_", "}", "\n", "\n", "", "splits", "=", "defaultdict", "(", "list", ")", "\n", "with", "open", "(", "args", ".", "splits_file", ")", "as", "f_in", ":", "\n", "        ", "for", "split", ",", "ids", "in", "json", ".", "load", "(", "f_in", ")", ".", "items", "(", ")", ":", "\n", "            ", "for", "id_", "in", "ids", ":", "\n", "                ", "splits", "[", "split", "]", ".", "append", "(", "data", "[", "id_", "]", ")", "\n", "\n", "", "", "", "for", "subset", ",", "data_list", "in", "splits", ".", "items", "(", ")", ":", "\n", "        ", "output_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "subset", "+", "'.jsonl'", ")", "\n", "pathlib", ".", "Path", "(", "output_filename", ")", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "write_jsonlist", "(", "data_list", ",", "output_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_document_to_chunk.add_arguments": [[11, 14], ["parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_arguments", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--document_file\"", ",", "help", "=", "\"path to input file\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--chunk_file\"", ",", "help", "=", "\"path to output file\"", ",", "required", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_document_to_chunk.is_whitespace": [[16, 20], ["ord"], "function", ["None"], ["", "def", "is_whitespace", "(", "c", ")", ":", "\n", "    ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_document_to_chunk.procrss_chunk": [[21, 98], ["print", "min", "os.getpid", "convert_document_to_chunk.is_whitespace", "char_to_word_offset.append", "tokenizer.tokenize", "enumerate", "range", "len", "answer_spans.append", "orig_to_tok_index.append", "len", "min", "tokenizer.convert_tokens_to_string", "copy.deepcopy", "new_example.append", "doc_tokens.append", "len", "tokenizer.encode", "len", "tokenizer.tokenize", "tok_to_orig_index.append", "all_doc_tokens.append", "len", "len", "print", "tokenizer.tokenize", "len", "len"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_document_to_chunk.is_whitespace"], ["", "def", "procrss_chunk", "(", "index", ")", ":", "\n", "    ", "print", "(", "\"%s start processing, qia is %d\"", "%", "(", "i", ",", "os", ".", "getpid", "(", ")", ")", ")", "\n", "new_example", "=", "[", "]", "\n", "for", "example", "in", "train", "[", "index", "*", "batch", ":", "min", "(", "(", "index", "+", "1", ")", "*", "batch", ",", "train_length", ")", "]", ":", "\n", "\n", "        ", "for", "paragraph", "in", "example", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "paragraph_text", "=", "paragraph", "[", "\"context\"", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "question_text", "=", "qa", "[", "\"question\"", "]", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "answer_spans", "=", "[", "]", "\n", "for", "answer", "in", "qa", "[", "\"answers\"", "]", ":", "\n", "                    ", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "answer", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "try", ":", "\n", "                        ", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "token_ids", "=", "tokenizer", ".", "encode", "(", "orig_answer_text", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                        ", "print", "(", "f'Reading example {idx} failed'", ")", "\n", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "", "answer_spans", ".", "append", "(", "{", "'start'", ":", "start_position", ",", "'end'", ":", "end_position", ",", "\n", "'text'", ":", "orig_answer_text", ",", "'token_ids'", ":", "token_ids", "}", ")", "\n", "\n", "# ===== Given an example, convert it into tensors  =============", "\n", "", "query_tokens", "=", "tokenizer", ".", "tokenize", "(", "question_text", ")", "\n", "query_tokens", "=", "query_tokens", "[", ":", "max_question_len", "]", "\n", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "doc_tokens", ")", ":", "\n", "                    ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "f'. {token}'", ")", "[", "1", ":", "]", "if", "i", ">", "0", "else", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                        ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "all_doc_tokens", "=", "all_doc_tokens", "[", ":", "max_doc_len", "]", "\n", "\n", "# The -3 accounts for [CLS], [SEP] and [SEP]", "\n", "max_tokens_per_doc_slice", "=", "max_seq_len", "-", "len", "(", "query_tokens", ")", "-", "3", "\n", "assert", "max_tokens_per_doc_slice", ">", "0", "\n", "\n", "#             stride = max_tokens_per_doc_slice - doc_stride", "\n", "#             if stride == 0:", "\n", "\n", "for", "slice_start", "in", "range", "(", "0", ",", "len", "(", "all_doc_tokens", ")", ",", "4000", ")", ":", "\n", "                    ", "slice_end", "=", "min", "(", "slice_start", "+", "max_tokens_per_doc_slice", ",", "len", "(", "all_doc_tokens", ")", ")", "\n", "doc_slice_tokens", "=", "all_doc_tokens", "[", "slice_start", ":", "slice_end", "]", "\n", "if", "len", "(", "doc_slice_tokens", ")", "+", "len", "(", "query_tokens", ")", "+", "3", "<", "20", ":", "\n", "                        ", "continue", "\n", "", "text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "doc_slice_tokens", ")", "\n", "#print(text)", "\n", "example", "[", "\"paragraphs\"", "]", "[", "0", "]", "[", "\"context\"", "]", "=", "text", "\n", "shadow", "=", "copy", ".", "deepcopy", "(", "example", ")", "\n", "#print(example[\"paragraphs\"][0][\"context\"])", "\n", "#print(example)", "\n", "new_example", ".", "append", "(", "shadow", ")", "\n", "", "", "", "", "return", "new_example", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.CoolDataset.__len__": [[18, 20], ["None"], "methods", ["None"], ["    ", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "1024", "# number of examples", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.CoolDataset.__getitem__": [[21, 26], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "tokne_ids", "=", "torch", ".", "tensor", "(", "[", "5", "]", "*", "seqlen", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "1", "]", "*", "seqlen", ")", "\n", "mask", "[", ":", "global_size", "]", "=", "2", "\n", "return", "tokne_ids", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.MemoryProfiler.__init__": [[30, 43], ["pytorch_lightning.LightningModule.__init__", "longformer.longformer_encoder_decoder.LongformerEncoderDecoderConfig.from_pretrained", "longformer.longformer_encoder_decoder.LongformerEncoderDecoderForConditionalGeneration"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "config", "=", "LongformerEncoderDecoderConfig", ".", "from_pretrained", "(", "'bart-long-4096'", ")", "\n", "# config = LongformerConfig.from_pretrained('roberta-large')", "\n", "config", ".", "max_position_embeddings", "=", "seqlen", "+", "2", "\n", "config", ".", "gradient_checkpointing", "=", "True", "\n", "config", ".", "attention_mode", "=", "'sliding_chunks'", "\n", "# config.attention_mode = 'n2'", "\n", "config", ".", "attention_window", "=", "[", "attention_window", "]", "*", "config", ".", "num_hidden_layers", "\n", "config", ".", "attention_dilation", "=", "[", "1", "]", "*", "config", ".", "num_hidden_layers", "\n", "self", ".", "model", "=", "LongformerEncoderDecoderForConditionalGeneration", "(", "config", ")", "\n", "# self.model = LongformerForMaskedLM(config)", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.MemoryProfiler.forward": [[45, 50], ["print", "mem_profiler.MemoryProfiler.model", "torch.cuda.max_memory_allocated"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "print", "(", "seqlen", ",", "global_size", ",", "attention_window", ",", "torch", ".", "cuda", ".", "max_memory_allocated", "(", "x", ".", "device", ")", "/", "1024", "**", "3", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "# return self.model(x, attention_mask=y, decoder_input_ids=x[:, :attention_window * 2], use_cache=False)", "\n", "return", "self", ".", "model", "(", "x", ",", "attention_mask", "=", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.MemoryProfiler.training_step": [[51, 58], ["mem_profiler.MemoryProfiler.", "y_hat[].sum"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "# import ipdb; ipdb.set_trace()", "\n", "        ", "x", ",", "y", "=", "batch", "\n", "y_hat", "=", "self", "(", "x", ",", "y", ")", "\n", "loss", "=", "y_hat", "[", "0", "]", ".", "sum", "(", ")", "\n", "# import ipdb; ipdb.set_trace()", "\n", "return", "{", "'loss'", ":", "loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.MemoryProfiler.configure_optimizers": [[59, 61], ["torch.optim.Adam", "mem_profiler.MemoryProfiler.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.mem_profiler.MemoryProfiler.train_dataloader": [[62, 64], ["torch.utils.data.DataLoader", "mem_profiler.CoolDataset"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "CoolDataset", "(", ")", ",", "batch_size", "=", "2", ",", "num_workers", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset.__init__": [[41, 53], ["numpy.memmap"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mmap_filename", ",", "chunk_size", ",", "bos_token_id", ",", "eos_token_id", ")", ":", "\n", "# `chunk_size - 2` to reserve space for <s> and </s>", "\n", "        ", "self", ".", "num_instances", "=", "np", ".", "memmap", "(", "mmap_filename", ",", "mode", "=", "'r'", ",", "dtype", "=", "np", ".", "uint16", ")", ".", "shape", "[", "0", "]", "//", "(", "chunk_size", "-", "2", ")", "\n", "# defer loading the token_ids memmap until after the first __getitem__ call.", "\n", "# when spawning new processes for ddp, there is a hard limit in python < 3.8 that", "\n", "# pickle files need to be < 4GB. By waiting until after the first __getitem__ we", "\n", "# don't have to pickle the memmap", "\n", "self", ".", "token_ids", "=", "None", "\n", "self", ".", "_mmap_filename", "=", "mmap_filename", "\n", "self", ".", "_chunk_size", "=", "chunk_size", "\n", "self", ".", "_bos_token_id", "=", "bos_token_id", "\n", "self", ".", "_eos_token_id", "=", "eos_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset.__len__": [[54, 56], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset.__getitem__": [[57, 64], ["numpy.concatenate", "torch.tensor", "numpy.memmap"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "self", ".", "token_ids", "is", "None", ":", "\n", "            ", "self", ".", "token_ids", "=", "np", ".", "memmap", "(", "self", ".", "_mmap_filename", ",", "mode", "=", "'r'", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "", "from_index", "=", "i", "*", "(", "self", ".", "_chunk_size", "-", "2", ")", "\n", "to_index", "=", "(", "i", "+", "1", ")", "*", "(", "self", ".", "_chunk_size", "-", "2", ")", "\n", "data", "=", "np", ".", "concatenate", "(", "(", "[", "self", ".", "_bos_token_id", "]", ",", "self", ".", "token_ids", "[", "from_index", ":", "to_index", "]", ",", "[", "self", ".", "_eos_token_id", "]", ")", ")", "\n", "return", "torch", ".", "tensor", "(", "data", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset._process_file": [[66, 108], ["os.path.isfile", "logging.info", "full_fname.split", "logging.info", "open", "tqdm.tqdm.tqdm", "pretrain.MMapTextDataset._process_file._write_shard"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_process_file", "(", "full_fname", ")", ":", "\n", "        ", "\"Step 1: tokenize an input text file then save token ids into `np.memmap` shards of size `args.shard_size`\"", "\n", "fname", "=", "full_fname", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "log_filename", "=", "f'{args.input_dir}/logs-{args.shard_size}/{fname}.log'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "log_filename", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f'Skipping {full_fname} ...'", ")", "\n", "return", "# log file already exists. Skip current file.", "\n", "\n", "", "logging", ".", "info", "(", "f'Processing {full_fname} ...'", ")", "\n", "with", "open", "(", "full_fname", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "token_list", "=", "[", "]", "\n", "shard_count", "=", "0", "\n", "tokens_count", "=", "0", "\n", "\n", "def", "_write_shard", "(", ")", ":", "\n", "                ", "if", "len", "(", "token_list", ")", "==", "0", ":", "\n", "                    ", "return", "\n", "", "if", "token_list", "[", "-", "1", "]", "!=", "MMapTextDataset", ".", "tokenizer", ".", "sep_token_id", ":", "# handle a rare case", "\n", "                    ", "token_list", ".", "append", "(", "MMapTextDataset", ".", "tokenizer", ".", "sep_token_id", ")", "\n", "", "shared_filename", "=", "f'{args.input_dir}/shards-{args.shard_size}/{fname}-{shard_count}.bin'", "\n", "logging", ".", "info", "(", "f'Writing {len(token_list)} tokens to shared {shared_filename}'", ")", "\n", "fp", "=", "np", ".", "memmap", "(", "shared_filename", ",", "dtype", "=", "np", ".", "uint16", ",", "mode", "=", "'w+'", ",", "shape", "=", "len", "(", "token_list", ")", ")", "\n", "fp", "[", ":", "]", "=", "token_list", "[", ":", "]", "\n", "del", "fp", "# flush and close file", "\n", "", "for", "line", "in", "tqdm", "(", "fin", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "# drop empty lines", "\n", "                    ", "continue", "\n", "", "tokens", "=", "MMapTextDataset", ".", "tokenizer", ".", "encode", "(", "line", ",", "add_special_tokens", "=", "False", ")", "# `__getitem__` adds special tokens", "\n", "token_list", ".", "extend", "(", "tokens", ")", "\n", "if", "len", "(", "token_list", ")", ">", "args", ".", "shard_size", ":", "\n", "                    ", "_write_shard", "(", ")", "\n", "tokens_count", "+=", "len", "(", "token_list", ")", "\n", "token_list", "=", "[", "]", "\n", "shard_count", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "token_list", ".", "append", "(", "MMapTextDataset", ".", "tokenizer", ".", "sep_token_id", ")", "\n", "", "", "_write_shard", "(", ")", "\n", "tokens_count", "+=", "len", "(", "token_list", ")", "\n", "", "with", "open", "(", "log_filename", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f'Generated {tokens_count} tokens in {shard_count + 1} shards'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset._combine_shards": [[109, 125], ["logging.info", "numpy.empty", "tqdm.tqdm.tqdm", "numpy.memmap", "numpy.memmap", "len", "numpy.memmap", "len"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror._ffi.ndarray.empty"], ["", "", "@", "staticmethod", "\n", "def", "_combine_shards", "(", "output_fname", ",", "shards_list", ")", ":", "\n", "        ", "\"Step 2: combining memmap shards into one `train.bin` or `val.bin` file\"", "\n", "total_size", "=", "0", "\n", "for", "filename", "in", "shards_list", ":", "\n", "            ", "total_size", "+=", "np", ".", "memmap", "(", "filename", ",", "mode", "=", "'r'", ",", "dtype", "=", "np", ".", "uint16", ")", ".", "shape", "[", "0", "]", "\n", "", "logging", ".", "info", "(", "f'Writing {total_size} tokens to {output_fname}'", ")", "\n", "all_token_ids", "=", "np", ".", "empty", "(", "total_size", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "last_token_index", "=", "0", "\n", "for", "filename", "in", "tqdm", "(", "shards_list", ")", ":", "\n", "            ", "shared", "=", "np", ".", "memmap", "(", "filename", ",", "mode", "=", "'r'", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "all_token_ids", "[", "last_token_index", ":", "last_token_index", "+", "len", "(", "shared", ")", "]", "=", "shared", "[", ":", "]", "\n", "last_token_index", "+=", "len", "(", "shared", ")", "\n", "", "fp", "=", "np", ".", "memmap", "(", "output_fname", ",", "dtype", "=", "np", ".", "uint16", ",", "mode", "=", "'w+'", ",", "shape", "=", "total_size", ")", "\n", "fp", "[", ":", "]", "=", "all_token_ids", "[", ":", "]", "\n", "del", "fp", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset.raw_text_to_mmap": [[126, 176], ["transformers.AutoTokenizer.from_pretrained", "glob.glob", "glob.glob", "random.shuffle", "int", "pretrain.MMapTextDataset._combine_shards", "pretrain.MMapTextDataset._combine_shards", "len", "os.path.exists", "os.path.exists", "logger.info", "os.mkdir", "os.mkdir", "os.mkdir", "Pool", "list", "pretrain.MMapTextDataset._process_file", "len", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "p.imap", "len"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset._combine_shards", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset._combine_shards", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset._process_file"], ["", "@", "staticmethod", "\n", "def", "raw_text_to_mmap", "(", "args", ")", ":", "\n", "        ", "\"\"\"This is the main preprocessing function. It processes all the text files in `args.input_dir` and\n        outputs two np.memmap files, one for training and one for validation with ratio `args.train_dev_split`.\n        Processing each input file involves tokenizing it, sharding it into shards of size `args.shard_size`,\n        then writing each shard as an np.memmap file. The stream of tokens in the memmap file represents documents\n        separated with `tokenizer.sep_token`. In `__getitem__`, the `tokenizer.bos_token` and `tokenizer.eos_token`\n        are added. The reason for not adding them at preprocessing time is to allow different sequence lengths\n        later on. Notice that this is the \"FULL-SENTENCES\" setting in the RoBERTa paper, Table2.\n        \"\"\"", "\n", "MMapTextDataset", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer", ",", "use_fast", "=", "True", ")", "\n", "assert", "len", "(", "MMapTextDataset", ".", "tokenizer", ")", "<", "65535", "# will use uint16 to store token ids", "\n", "all_files", "=", "glob", ".", "glob", "(", "f'{args.input_dir}/*.txt'", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "f'{args.input_dir}/cache/train.bin'", ")", "and", "os", ".", "path", ".", "exists", "(", "f'{args.input_dir}/cache/val.bin'", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Cache already exists. Remove the cache directory to regenerate\"", ")", "\n", "return", "\n", "", "try", ":", "\n", "            ", "os", ".", "mkdir", "(", "f'{args.input_dir}/cache/'", ")", "\n", "", "except", "FileExistsError", ":", "\n", "            ", "pass", "\n", "", "try", ":", "\n", "            ", "os", ".", "mkdir", "(", "f'{args.input_dir}/shards-{args.shard_size}/'", ")", "\n", "", "except", "FileExistsError", ":", "\n", "            ", "pass", "\n", "", "try", ":", "\n", "            ", "os", ".", "mkdir", "(", "f'{args.input_dir}/logs-{args.shard_size}/'", ")", "# log progrss to be able to resume", "\n", "", "except", "FileExistsError", ":", "\n", "            ", "pass", "\n", "\n", "# STEP1: tokenizing and saving to shards", "\n", "", "if", "args", ".", "num_preprocessing_workers", ">", "1", ":", "\n", "            ", "from", "multiprocessing", ".", "pool", "import", "Pool", "\n", "with", "Pool", "(", "args", ".", "num_preprocessing_workers", ")", "as", "p", ":", "\n", "                ", "list", "(", "tqdm", "(", "p", ".", "imap", "(", "MMapTextDataset", ".", "_process_file", ",", "all_files", ")", ",", "total", "=", "len", "(", "all_files", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "[", "MMapTextDataset", ".", "_process_file", "(", "f", ")", "for", "f", "in", "tqdm", "(", "all_files", ")", "]", "\n", "\n", "# STEP2: shuffling shards and combining them into train.bin and val.bin files", "\n", "", "all_shards", "=", "glob", ".", "glob", "(", "f'{args.input_dir}/shards-{args.shard_size}/*.bin'", ")", "\n", "random", ".", "shuffle", "(", "all_shards", ")", "# shuffling based on shards not individual lines", "\n", "val_shards_count", "=", "int", "(", "args", ".", "train_dev_split", "*", "len", "(", "all_shards", ")", ")", "\n", "val_shards", "=", "all_shards", "[", ":", "val_shards_count", "]", "\n", "train_shards", "=", "all_shards", "[", "val_shards_count", ":", "]", "\n", "# TODO: if MMapTextDataset._combining_shards is very slow for large files, it can be skipped but we nned to", "\n", "# update the dataset to read from multiple shards directly", "\n", "MMapTextDataset", ".", "_combine_shards", "(", "f'{args.input_dir}/cache/val.bin'", ",", "val_shards", ")", "\n", "MMapTextDataset", ".", "_combine_shards", "(", "f'{args.input_dir}/cache/train.bin'", ",", "train_shards", ")", "\n", "\n", "del", "MMapTextDataset", ".", "tokenizer", "\n", "# ========================= end preprocessing code ========================= #", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.__init__": [[181, 202], ["pytorch_lightning.LightningModule.__init__", "transformers.AutoModelForMaskedLM.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "logger.info", "pretrain.MMapTextDataset.raw_text_to_mmap", "transformers.DataCollatorForLanguageModeling"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.MMapTextDataset.raw_text_to_mmap"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "hparams", "\n", "self", ".", "hparams", "=", "self", ".", "args", "\n", "\n", "self", ".", "model", "=", "AutoModelForMaskedLM", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "self", ".", "config", "=", "self", ".", "model", ".", "config", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer", ")", "\n", "self", ".", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "eos_token_id", "=", "tokenizer", ".", "eos_token_id", "\n", "self", ".", "bos_token_id", "=", "tokenizer", ".", "bos_token_id", "\n", "\n", "logger", ".", "info", "(", "f'Creating dataset cache from dir {self.args.input_dir}. This could be slow the first time.'", ")", "\n", "MMapTextDataset", ".", "raw_text_to_mmap", "(", "args", ")", "\n", "\n", "# TODO: add support for other objective functions (whole word masking, BART objectives)", "\n", "self", ".", "data_collator", "=", "DataCollatorForLanguageModeling", "(", "\n", "tokenizer", "=", "tokenizer", ",", "mlm", "=", "True", ",", "mlm_probability", "=", "self", ".", "args", ".", "mlm_prob", "\n", ")", "\n", "self", ".", "start_time", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.to": [[203, 213], ["len", "super().to", "len", "list", "pretrain.Pretrainer.model.tie_weights", "list", "pretrain.Pretrainer.parameters", "pretrain.Pretrainer.parameters"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.to"], ["", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "param_count_before_to", "=", "len", "(", "list", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "super", "(", ")", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "trainer", ".", "use_tpu", ":", "\n", "# need to re-tie the weights after moving to XLA!", "\n", "            ", "self", ".", "model", ".", "tie_weights", "(", ")", "\n", "if", "'roberta'", "in", "self", ".", "args", ".", "model", ":", "\n", "                ", "self", ".", "model", ".", "lm_head", ".", "bias", "=", "self", ".", "model", ".", "lm_head", ".", "decoder", ".", "bias", "\n", "", "", "param_count_after_to", "=", "len", "(", "list", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "assert", "param_count_before_to", "==", "param_count_after_to", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.forward": [[214, 221], ["pretrain.Pretrainer.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "# get the padding mask - 1 for NOT masked, 0 for MASKED/PAD", "\n", "        ", "attention_mask", "=", "(", "input_ids", "!=", "self", ".", "pad_token_id", ")", ".", "int", "(", ")", "\n", "\n", "# output is loss, prediction_scores, hidden_states", "\n", "output", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "labels", "=", "labels", ")", "\n", "return", "output", "[", "0", "]", "# loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.training_step": [[222, 240], ["pretrain.Pretrainer.", "time.time", "input_ids.numel", "torch.exp", "math.log", "time.time", "torch.cuda.memory_allocated", "input_ids.numel"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "loss", "=", "self", "(", "**", "batch", ")", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", "\n", "tensorboard_logs", "=", "{", "\n", "'input_size'", ":", "input_ids", ".", "numel", "(", ")", ",", "\n", "'mlm_loss'", ":", "loss", ",", "\n", "'mlm_bpc'", ":", "loss", "/", "math", ".", "log", "(", "2", ")", ",", "\n", "'mlm_perplexity'", ":", "torch", ".", "exp", "(", "loss", ")", ",", "\n", "'token_per_step'", ":", "input_ids", ".", "numel", "(", ")", "*", "self", ".", "args", ".", "grad_accum", "*", "self", ".", "trainer", ".", "world_size", ",", "\n", "}", "\n", "if", "self", ".", "start_time", "!=", "0", ":", "\n", "            ", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "tensorboard_logs", "[", "'second_per_batch'", "]", "=", "elapsed_time", "\n", "", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "on_gpu", ":", "\n", "            ", "tensorboard_logs", "[", "'memory'", "]", "=", "torch", ".", "cuda", ".", "memory_allocated", "(", "loss", ".", "device", ")", "/", "1024", "**", "3", "\n", "\n", "", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.validation_step": [[241, 249], ["pretrain.Pretrainer.", "pretrain.Pretrainer.detach"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "# TODO: log how long evaluation takes", "\n", "        ", "self", ".", "start_time", "=", "0", "# reset training_step timer", "\n", "loss", "=", "self", "(", "**", "batch", ")", "\n", "tensorboard_logs", "=", "{", "\n", "'val_mlm_loss'", ":", "loss", ".", "detach", "(", ")", ",", "\n", "}", "\n", "return", "{", "'val_loss'", ":", "tensorboard_logs", "[", "\"val_mlm_loss\"", "]", ",", "'log'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.validation_epoch_end": [[250, 262], ["torch.stack().mean", "torch.distributed.all_reduce", "torch.distributed.get_world_size", "torch.stack", "xm.all_reduce", "xm.xrt_world_size"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "'log'", "]", "[", "'val_mlm_loss'", "]", "for", "x", "in", "outputs", "if", "'val_mlm_loss'", "in", "x", "[", "'log'", "]", "]", ")", ".", "mean", "(", ")", "\n", "if", "self", ".", "use_ddp", ":", "\n", "# TODO: PTL is already doing this. Is it still needed here?", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/blob/0.8.5/pytorch_lightning/metrics/converters.py#L251", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "avg_loss", ",", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "avg_loss", "/=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "", "elif", "self", ".", "use_tpu", ":", "\n", "            ", "avg_loss", "=", "xm", ".", "all_reduce", "(", "xm", ".", "REDUCE_SUM", ",", "avg_loss", ")", "/", "xm", ".", "xrt_world_size", "(", ")", "\n", "\n", "", "logs", "=", "{", "'val_mlm_loss'", ":", "avg_loss", "}", "\n", "return", "{", "'log'", ":", "logs", ",", "'progress_bar'", ":", "logs", ",", "\"val_loss\"", ":", "avg_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.configure_optimizers": [[263, 281], ["transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "pretrain.Pretrainer.named_parameters", "pretrain.Pretrainer.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "self", ".", "args", ".", "train_steps", "\n", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer._get_loader": [[282, 312], ["pretrain.MMapTextDataset", "torch.utils.data.DataLoader", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "xm.xrt_world_size", "xm.get_ordinal"], "methods", ["None"], ["", "def", "_get_loader", "(", "self", ",", "fname", ",", "is_train", ")", ":", "\n", "        ", "dataset", "=", "MMapTextDataset", "(", "fname", ",", "chunk_size", "=", "self", ".", "args", ".", "seqlen", ",", "\n", "bos_token_id", "=", "self", ".", "bos_token_id", ",", "eos_token_id", "=", "self", ".", "eos_token_id", ")", "\n", "\n", "# TODO: consider `replace_sampler_ddp=True` and removing the following if statement", "\n", "if", "self", ".", "trainer", ".", "use_ddp", ":", "\n", "            ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "is_train", ")", "\n", "shuffle", "=", "False", "\n", "", "elif", "self", ".", "trainer", ".", "use_tpu", ":", "\n", "            ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "dataset", ",", "\n", "num_replicas", "=", "xm", ".", "xrt_world_size", "(", ")", ",", "\n", "rank", "=", "xm", ".", "get_ordinal", "(", ")", ",", "\n", "shuffle", "=", "is_train", ",", "\n", ")", "\n", "shuffle", "=", "False", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "None", "\n", "shuffle", "=", "is_train", "\n", "\n", "", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ",", "\n", "drop_last", "=", "is_train", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.train_dataloader": [[313, 315], ["pretrain.Pretrainer._get_loader"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer._get_loader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_loader", "(", "f'{self.args.input_dir}/cache/train.bin'", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.val_dataloader": [[316, 318], ["pretrain.Pretrainer._get_loader"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer._get_loader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_loader", "(", "f'{self.args.input_dir}/cache/val.bin'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.grad_norm": [[319, 331], ["torch.zeros", "float", "p.grad.data.pow().sum", "torch.zeros.add_", "pretrain.Pretrainer.parameters", "p.grad.data.pow"], "methods", ["None"], ["", "def", "grad_norm", "(", "self", ",", "norm_type", ")", ":", "\n", "# Override PTL `grad_norm` function to only return `total_grad_norm` instead norms of individual params", "\n", "# TODO: grad_norm reporting needs to take fp16 loss scale into account", "\n", "        ", "parameters", "=", "[", "p", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "device", "=", "parameters", "[", "0", "]", ".", "device", "\n", "total_norm", "=", "torch", ".", "zeros", "(", "[", "]", ",", "device", "=", "device", "if", "parameters", "else", "None", ")", "\n", "norm_type", "=", "float", "(", "norm_type", ")", "\n", "for", "p", "in", "parameters", ":", "\n", "            ", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "pow", "(", "norm_type", ")", ".", "sum", "(", ")", "\n", "total_norm", ".", "add_", "(", "param_norm", ")", "\n", "", "total_norm", "=", "(", "total_norm", "**", "(", "1.0", "/", "norm_type", ")", ")", "\n", "return", "{", "'total_grad_norm'", ":", "total_norm", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.Pretrainer.add_args": [[332, 398], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_args", "(", "parser", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "\n", "# Dataset. Some of these params are only useful when generating the dataset cache", "\n", "parser", ".", "add_argument", "(", "\"--input_dir\"", ",", "type", "=", "str", ",", "default", "=", "'/net/nfs.corp/s2-research/beltagy/longformer/data/'", ")", "\n", "# Used only at the preprocessing phase", "\n", "parser", ".", "add_argument", "(", "\"--train_dev_split\"", ",", "type", "=", "float", ",", "default", "=", "0.05", ")", "\n", "parser", ".", "add_argument", "(", "\"--shard_size\"", ",", "type", "=", "int", ",", "default", "=", "1024", "**", "3", "//", "4", ")", "# 250MB", "\n", "parser", ".", "add_argument", "(", "\"--num_preprocessing_workers\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "# Used only at the training phase", "\n", "parser", ".", "add_argument", "(", "\"--seqlen\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_prob\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ")", "\n", "\n", "# HF model loading", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer\"", ",", "type", "=", "str", ",", "default", "=", "'roberta-base'", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "default", "=", "'roberta-base'", ")", "\n", "\n", "# Checkpointing and logging", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "default", "=", "'/runs/'", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_prefix\"", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "\n", "help", "=", "\"path of output directory is --save_dir/--save_prefix\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "# It is better to use a different output dir.", "\n", "help", "=", "\"Path to a checkpoint to load model weights and training state. It overwrites args\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_model_only\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Path to a checkpoint to load model weights but not training state\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_rate\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--disable_checkpointing\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "\n", "# Training hyperparams", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_steps\"", ",", "type", "=", "int", ",", "default", "=", "3000", ",", "help", "=", "'# training grad. updates'", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'# warmup grad. updates'", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_every\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'# training grad. updates between evaluations'", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_batches\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'# evaluation **batches**'", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "type", "=", "float", ",", "default", "=", "1e-6", ")", "\n", "parser", ".", "add_argument", "(", "\"--grad_clip\"", ",", "type", "=", "float", ",", "default", "=", "0", ")", "# TODO: test this with fp16. Likely not working", "\n", "\n", "# RoBERTa's tokens_per_step = 2^18 = 512(seqlen) x 1(gpu_count) x 32(batch_size) x 16(grad_accum)", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\"--grad_accum\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "# Compute resources", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu_count\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "# `--gpus` is reserved for internal use by PTL", "\n", "help", "=", "\"Number of gpus. This respects `CUDA_VISIBLE_DEVICES`\"", ")", "\n", "\n", "# For multi-node training, use the PyTorch launch script. The script and instructions can be found here:", "\n", "# https://github.com/pytorch/pytorch/blob/master/torch/distributed/launch.py.", "\n", "# To run PTL in a mode compatible with the launch script, two things are needed:", "\n", "#   - pass the argument `--use_env` to `torch.distributed.launch`", "\n", "#   - make sure `--nproc_per_node` matches `--gpu_count` and `--nnodes` matches `--node_count`.", "\n", "# For example, to run on 2 nodes, 3 gpus each, the command line on node rank 1 would be like:", "\n", "#   >>>> python -m torch.distributed.launch  \\", "\n", "#               --use_env  --nnodes 2  --nproc_per_node 3  \\", "\n", "#               --node_rank 1  --master_addr s2-server4  --master_port 12343  \\", "\n", "#               scripts/pretrain.py  \\", "\n", "#               --gpu_count 2  --node_count 2  \\", "\n", "#               --input_dir my_data_dir  --save_prefix test_multinode", "\n", "parser", ".", "add_argument", "(", "\"--node_count\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of nodes. It needs to match --nnodes of torch.distributed.launch\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tpu_core_count\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.pretrain.main": [[400, 456], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "pytorch_lightning.logging.test_tube.TestTubeLogger", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.Trainer", "ptl.Trainer.fit", "torch.cuda.manual_seed_all", "Pretrainer.load_from_checkpoint", "pretrain.Pretrainer", "os.path.join", "pytorch_lightning.callbacks.LearningRateLogger"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", "*", "10", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", "*", "100", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", "*", "1000", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", "*", "10000", ")", "\n", "\n", "", "if", "args", ".", "resume_model_only", "is", "not", "None", ":", "\n", "        ", "pretrainer", "=", "Pretrainer", ".", "load_from_checkpoint", "(", "args", ".", "resume_model_only", ",", "args", ")", "\n", "", "else", ":", "\n", "        ", "pretrainer", "=", "Pretrainer", "(", "args", ")", "\n", "\n", "# logger here is a SummaryWritter for tensorboard", "\n", "# it is used by the trainer, and certain return variables", "\n", "# from the model are automatically logged", "\n", "", "logger", "=", "TestTubeLogger", "(", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "name", "=", "args", ".", "save_prefix", ",", "\n", "version", "=", "0", "# always use version=0", "\n", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "# model saved to filepath/prefix_....", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "args", ".", "save_prefix", ",", "'checkpoint'", ")", ",", "\n", "prefix", "=", "''", ",", "\n", "save_top_k", "=", "1", ",", "\n", "save_last", "=", "True", ",", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "'val_loss'", ",", "\n", "mode", "=", "'min'", ",", "\n", "period", "=", "-", "1", ",", "# to allow multiple checkpoints per epoch", "\n", ")", "\n", "\n", "args", ".", "val_every", "*=", "args", ".", "grad_accum", "# PTL is expecting number of batches_per_gpu", "\n", "trainer", "=", "ptl", ".", "Trainer", "(", "\n", "gpus", "=", "args", ".", "gpu_count", ",", "\n", "num_nodes", "=", "args", ".", "node_count", ",", "\n", "num_tpu_cores", "=", "args", ".", "tpu_core_count", ",", "\n", "distributed_backend", "=", "'ddp'", "if", "(", "args", ".", "gpu_count", ">", "1", "or", "args", ".", "node_count", ">", "1", ")", "else", "None", ",", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "track_grad_norm", "=", "2", ",", "\n", "max_epochs", "=", "10000", ",", "min_epochs", "=", "0", ",", "max_steps", "=", "args", ".", "train_steps", ",", "# run for many epochs, but stop after max_steps", "\n", "val_check_interval", "=", "args", ".", "val_every", ",", "limit_val_batches", "=", "args", ".", "val_batches", ",", "\n", "early_stop_callback", "=", "None", ",", "\n", "row_log_interval", "=", "args", ".", "log_rate", ",", "\n", "progress_bar_refresh_rate", "=", "args", ".", "log_rate", ",", "\n", "logger", "=", "logger", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", "if", "not", "args", ".", "disable_checkpointing", "else", "None", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "grad_accum", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "resume", ",", "\n", "gradient_clip_val", "=", "args", ".", "grad_clip", ",", "\n", "precision", "=", "16", "if", "args", ".", "fp16", "else", "32", ",", "amp_level", "=", "'O2'", ",", "\n", "num_sanity_val_steps", "=", "2", ",", "\n", "callbacks", "=", "[", "LearningRateLogger", "(", ")", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "pretrainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.cross_f1.add_arguments": [[9, 13], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_arguments", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--regional_answer\"", ",", "help", "=", "\"path to regional answer\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--global_answer\"", ",", "help", "=", "\"path to global answer\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "help", "=", "\"path to output file\"", ",", "required", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.cross_f1.normalize_answer": [[15, 27], ["cross_f1.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "  ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "    ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.cross_f1.f1_score": [[28, 39], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "cross_f1.normalize_answer", "cross_f1.normalize_answer"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "  ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.cross_f1.cross_f1_max": [[40, 47], ["range", "len", "list", "list.pop", "cross_f1_max.append", "range", "max", "len", "cross_f1.f1_score"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.f1_score"], ["", "def", "cross_f1_max", "(", "predictions", ")", ":", "\n", "    ", "cross_f1_max", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "        ", "index", "=", "list", "(", "range", "(", "len", "(", "predictions", ")", ")", ")", "\n", "index", ".", "pop", "(", "i", ")", "\n", "cross_f1_max", ".", "append", "(", "max", "(", "[", "f1_score", "(", "predictions", "[", "i", "]", ",", "predictions", "[", "j", "]", ")", "for", "j", "in", "index", "]", ")", ")", "\n", "", "return", "cross_f1_max", "\n", "", "def", "cross_f1_mean", "(", "predictions", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.cross_f1.cross_f1_mean": [[47, 54], ["range", "len", "list", "list.pop", "cross_f1_mean.append", "range", "len", "sum", "len", "cross_f1.f1_score"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.f1_score"], ["", "def", "cross_f1_mean", "(", "predictions", ")", ":", "\n", "    ", "cross_f1_mean", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "        ", "index", "=", "list", "(", "range", "(", "len", "(", "predictions", ")", ")", ")", "\n", "index", ".", "pop", "(", "i", ")", "\n", "cross_f1_mean", ".", "append", "(", "sum", "(", "[", "f1_score", "(", "predictions", "[", "i", "]", ",", "predictions", "[", "j", "]", ")", "for", "j", "in", "index", "]", ")", "/", "len", "(", "index", ")", ")", "\n", "", "return", "cross_f1_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_bart_to_longformerencoderdecoder.create_long_model": [[17, 88], ["transformers.BartForConditionalGeneration.from_pretrained", "transformers.BartTokenizer.from_pretrained", "longformer.longformer_encoder_decoder.LongformerEncoderDecoderConfig.from_pretrained", "BartForConditionalGeneration.from_pretrained.model.encoder.embed_positions.weight.new_empty", "enumerate", "logger.info", "BartForConditionalGeneration.from_pretrained.save_pretrained", "BartTokenizer.from_pretrained.save_pretrained", "longformer.longformer_encoder_decoder.LongformerSelfAttentionForBart", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "function", ["None"], ["def", "create_long_model", "(", "\n", "save_model_to", ",", "\n", "base_model", ",", "\n", "tokenizer_name_or_path", ",", "\n", "attention_window", ",", "\n", "max_pos", "\n", ")", ":", "\n", "    ", "model", "=", "BartForConditionalGeneration", ".", "from_pretrained", "(", "base_model", ")", "\n", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "tokenizer_name_or_path", ",", "model_max_length", "=", "max_pos", ")", "\n", "config", "=", "LongformerEncoderDecoderConfig", ".", "from_pretrained", "(", "base_model", ")", "\n", "model", ".", "config", "=", "config", "\n", "\n", "# in BART attention_probs_dropout_prob is attention_dropout, but LongformerSelfAttention", "\n", "# expects attention_probs_dropout_prob, so set it here", "\n", "config", ".", "attention_probs_dropout_prob", "=", "config", ".", "attention_dropout", "\n", "config", ".", "architectures", "=", "[", "'LongformerEncoderDecoderForConditionalGeneration'", ",", "]", "\n", "\n", "# extend position embeddings", "\n", "tokenizer", ".", "model_max_length", "=", "max_pos", "\n", "tokenizer", ".", "init_kwargs", "[", "'model_max_length'", "]", "=", "max_pos", "\n", "current_max_pos", ",", "embed_size", "=", "model", ".", "model", ".", "encoder", ".", "embed_positions", ".", "weight", ".", "shape", "\n", "assert", "current_max_pos", "==", "config", ".", "max_position_embeddings", "+", "2", "\n", "\n", "config", ".", "max_encoder_position_embeddings", "=", "max_pos", "\n", "config", ".", "max_decoder_position_embeddings", "=", "config", ".", "max_position_embeddings", "\n", "del", "config", ".", "max_position_embeddings", "\n", "max_pos", "+=", "2", "# NOTE: BART has positions 0,1 reserved, so embedding size is max position + 2", "\n", "assert", "max_pos", ">=", "current_max_pos", "\n", "\n", "# allocate a larger position embedding matrix for the encoder", "\n", "new_encoder_pos_embed", "=", "model", ".", "model", ".", "encoder", ".", "embed_positions", ".", "weight", ".", "new_empty", "(", "max_pos", ",", "embed_size", ")", "\n", "# copy position embeddings over and over to initialize the new position embeddings", "\n", "k", "=", "2", "\n", "step", "=", "current_max_pos", "-", "2", "\n", "while", "k", "<", "max_pos", "-", "1", ":", "\n", "        ", "new_encoder_pos_embed", "[", "k", ":", "(", "k", "+", "step", ")", "]", "=", "model", ".", "model", ".", "encoder", ".", "embed_positions", ".", "weight", "[", "2", ":", "]", "\n", "k", "+=", "step", "\n", "", "model", ".", "model", ".", "encoder", ".", "embed_positions", ".", "weight", ".", "data", "=", "new_encoder_pos_embed", "\n", "\n", "# allocate a larger position embedding matrix for the decoder", "\n", "# new_decoder_pos_embed = model.model.decoder.embed_positions.weight.new_empty(max_pos, embed_size)", "\n", "# # copy position embeddings over and over to initialize the new position embeddings", "\n", "# k = 2", "\n", "# step = current_max_pos - 2", "\n", "# while k < max_pos - 1:", "\n", "#     new_decoder_pos_embed[k:(k + step)] = model.model.decoder.embed_positions.weight[2:]", "\n", "#     k += step", "\n", "# model.model.decoder.embed_positions.weight.data = new_decoder_pos_embed", "\n", "\n", "# replace the `modeling_bart.SelfAttention` object with `LongformerSelfAttention`", "\n", "config", ".", "attention_window", "=", "[", "attention_window", "]", "*", "config", ".", "num_hidden_layers", "\n", "config", ".", "attention_dilation", "=", "[", "1", "]", "*", "config", ".", "num_hidden_layers", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "model", ".", "model", ".", "encoder", ".", "layers", ")", ":", "\n", "        ", "longformer_self_attn_for_bart", "=", "LongformerSelfAttentionForBart", "(", "config", ",", "layer_id", "=", "i", ")", "\n", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "query", "=", "layer", ".", "self_attn", ".", "q_proj", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "key", "=", "layer", ".", "self_attn", ".", "k_proj", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "value", "=", "layer", ".", "self_attn", ".", "v_proj", "\n", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "query_global", "=", "copy", ".", "deepcopy", "(", "layer", ".", "self_attn", ".", "q_proj", ")", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "key_global", "=", "copy", ".", "deepcopy", "(", "layer", ".", "self_attn", ".", "k_proj", ")", "\n", "longformer_self_attn_for_bart", ".", "longformer_self_attn", ".", "value_global", "=", "copy", ".", "deepcopy", "(", "layer", ".", "self_attn", ".", "v_proj", ")", "\n", "\n", "longformer_self_attn_for_bart", ".", "output", "=", "layer", ".", "self_attn", ".", "out_proj", "\n", "\n", "layer", ".", "self_attn", "=", "longformer_self_attn_for_bart", "\n", "", "logger", ".", "info", "(", "f'saving model to {save_model_to}'", ")", "\n", "model", ".", "save_pretrained", "(", "save_model_to", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "save_model_to", ")", "\n", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_bart_to_longformerencoderdecoder.main": [[90, 150], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "convert_bart_to_longformerencoderdecoder.create_long_model", "transformers.BartTokenizer.from_pretrained", "longformer.longformer_encoder_decoder.LongformerEncoderDecoderForConditionalGeneration.from_pretrained", "BartTokenizer.from_pretrained.", "transformers.modeling_bart.shift_tokens_right", "logits[].softmax", "logits[].softmax.topk", "print", "os.path.exists", "os.mkdir", "LongformerEncoderDecoderForConditionalGeneration.from_pretrained.", "BartTokenizer.from_pretrained.convert_ids_to_tokens"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.convert_bart_to_longformerencoderdecoder.create_long_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Convert BART to LongBART. Replaces BART encoder's SelfAttnetion with LongformerSelfAttention\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--base_model'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'facebook/bart-large'", ",", "\n", "help", "=", "'The name or path of the base model you want to convert'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tokenizer_name_or_path'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'facebook/bart-large'", ",", "\n", "help", "=", "'The name or path of the tokenizer'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--save_model_to'", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "'The path to save the converted model'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--attention_window'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "512", ",", "\n", "help", "=", "'attention window size for longformer self attention (one sided)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--max_pos'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "4096", "*", "4", ",", "\n", "help", "=", "'maximum encoder positions'", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_model_to", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "save_model_to", ")", "\n", "\n", "", "create_long_model", "(", "\n", "save_model_to", "=", "args", ".", "save_model_to", ",", "\n", "base_model", "=", "args", ".", "base_model", ",", "\n", "tokenizer_name_or_path", "=", "args", ".", "tokenizer_name_or_path", ",", "\n", "attention_window", "=", "args", ".", "attention_window", ",", "\n", "max_pos", "=", "args", ".", "max_pos", "\n", ")", "\n", "\n", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "args", ".", "save_model_to", ")", "\n", "TXT", "=", "\"My friends are <mask> but they eat too many carbs.\"", "\n", "model", "=", "LongformerEncoderDecoderForConditionalGeneration", ".", "from_pretrained", "(", "args", ".", "save_model_to", ")", "\n", "model", ".", "model", ".", "encoder", ".", "config", ".", "gradient_checkpointing", "=", "True", "\n", "model", ".", "model", ".", "decoder", ".", "config", ".", "gradient_checkpointing", "=", "True", "\n", "data", "=", "tokenizer", "(", "[", "TXT", "]", ",", "return_tensors", "=", "'pt'", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "2048", ")", "\n", "input_ids", "=", "data", "[", "'input_ids'", "]", "\n", "attention_mask", "=", "data", "[", "'attention_mask'", "]", "\n", "decoder_input_ids", "=", "shift_tokens_right", "(", "input_ids", "[", ":", ",", ":", "5", "]", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "logits", "=", "model", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "use_cache", "=", "False", ")", "[", "0", "]", "\n", "masked_index", "=", "(", "input_ids", "[", "0", "]", "==", "tokenizer", ".", "mask_token_id", ")", ".", "nonzero", "(", ")", ".", "item", "(", ")", "\n", "probs", "=", "logits", "[", "0", ",", "masked_index", "]", ".", "softmax", "(", "dim", "=", "0", ")", "\n", "values", ",", "predictions", "=", "probs", ".", "topk", "(", "5", ")", "\n", "print", "(", "tokenizer", ".", "convert_ids_to_tokens", "(", "predictions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.SummarizationDataset.__init__": [[47, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hf_dataset", ",", "tokenizer", ",", "max_input_len", ",", "max_output_len", ")", ":", "\n", "        ", "self", ".", "hf_dataset", "=", "hf_dataset", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_input_len", "=", "max_input_len", "\n", "self", ".", "max_output_len", "=", "max_output_len", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.SummarizationDataset.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "hf_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.SummarizationDataset.__getitem__": [[56, 63], ["summarization.SummarizationDataset.tokenizer.encode", "summarization.SummarizationDataset.tokenizer.encode", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "entry", "=", "self", ".", "hf_dataset", "[", "idx", "]", "\n", "input_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "entry", "[", "'article'", "]", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_input_len", ")", "\n", "output_ids", "=", "self", ".", "tokenizer", ".", "encode", "(", "entry", "[", "'abstract'", "]", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_output_len", ")", "\n", "if", "self", ".", "tokenizer", ".", "bos_token_id", "is", "None", ":", "# pegasus", "\n", "            ", "output_ids", "=", "[", "self", ".", "tokenizer", ".", "pad_token_id", "]", "+", "output_ids", "\n", "", "return", "torch", ".", "tensor", "(", "input_ids", ")", ",", "torch", ".", "tensor", "(", "output_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.SummarizationDataset.collate_fn": [[64, 78], ["list", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "[].item", "zip", "[].item"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "# A hack to know if this is bart or pegasus. DDP doesn't like global variables nor class-level memebr variables", "\n", "        ", "if", "batch", "[", "0", "]", "[", "0", "]", "[", "-", "1", "]", ".", "item", "(", ")", "==", "2", ":", "\n", "            ", "pad_token_id", "=", "1", "# AutoTokenizer.from_pretrained('facebook/bart-base').pad_token_id", "\n", "", "elif", "batch", "[", "0", "]", "[", "0", "]", "[", "-", "1", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "            ", "pad_token_id", "=", "0", "# AutoTokenizer.from_pretrained('google/pegasus-large').pad_token_id", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "\n", "", "input_ids", ",", "output_ids", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "input_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "pad_token_id", ")", "\n", "output_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "pad_token_id", ")", "\n", "return", "input_ids", ",", "output_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.__init__": [[82, 102], ["pytorch_lightning.LightningModule.__init__", "transformers.AutoTokenizer.from_pretrained", "longformer.LongformerEncoderDecoderConfig.from_pretrained", "longformer.LongformerEncoderDecoderForConditionalGeneration.from_pretrained", "transformers.AutoConfig.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "params", "\n", "self", ".", "hparams", "=", "params", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "self", ".", "args", ".", "tokenizer", ",", "use_fast", "=", "True", ")", "\n", "\n", "if", "'long'", "in", "self", ".", "args", ".", "model_path", ":", "\n", "            ", "config", "=", "LongformerEncoderDecoderConfig", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "config", ".", "attention_dropout", "=", "self", ".", "args", ".", "attention_dropout", "\n", "config", ".", "gradient_checkpointing", "=", "self", ".", "args", ".", "grad_ckpt", "\n", "config", ".", "attention_mode", "=", "self", ".", "args", ".", "attention_mode", "\n", "config", ".", "attention_window", "=", "[", "self", ".", "args", ".", "attention_window", "]", "*", "config", ".", "encoder_layers", "\n", "self", ".", "model", "=", "LongformerEncoderDecoderForConditionalGeneration", ".", "from_pretrained", "(", "\n", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "self", ".", "args", ".", "model_path", ")", "\n", "config", ".", "attention_dropout", "=", "self", ".", "args", ".", "attention_dropout", "\n", "self", ".", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\n", "self", ".", "args", ".", "model_path", ",", "config", "=", "config", ")", "\n", "", "self", ".", "train_dataloader_object", "=", "self", ".", "val_dataloader_object", "=", "self", ".", "test_dataloader_object", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._prepare_input": [[103, 117], ["torch.ones", "isinstance", "longformer.sliding_chunks.pad_to_window_size"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.longformer.sliding_chunks.pad_to_window_size"], ["", "def", "_prepare_input", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "attention_mask", "=", "torch", ".", "ones", "(", "input_ids", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "attention_mask", "[", "input_ids", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "0", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "LongformerEncoderDecoderForConditionalGeneration", ")", ":", "\n", "            ", "attention_mask", "[", ":", ",", "0", "]", "=", "2", "# global attention on one token for all model params to be used, which is important for gradient checkpointing to work", "\n", "if", "self", ".", "args", ".", "attention_mode", "==", "'sliding_chunks'", ":", "\n", "                ", "half_padding_mod", "=", "self", ".", "model", ".", "config", ".", "attention_window", "[", "0", "]", "\n", "", "elif", "self", ".", "args", ".", "attention_mode", "==", "'sliding_chunks_no_overlap'", ":", "\n", "                ", "half_padding_mod", "=", "self", ".", "model", ".", "config", ".", "attention_window", "[", "0", "]", "/", "2", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "input_ids", ",", "attention_mask", "=", "pad_to_window_size", "(", "# ideally, should be moved inside the LongformerModel", "\n", "input_ids", ",", "attention_mask", ",", "half_padding_mod", ",", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "", "return", "input_ids", ",", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.forward": [[118, 141], ["summarization.Summarizer._prepare_input", "output_ids[].clone", "summarization.Summarizer.model", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.functional.log_softmax", "summarization.label_smoothed_nll_loss", "lm_logits.view", "output_ids[].clone.view"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._prepare_input", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.label_smoothed_nll_loss"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "output_ids", ")", ":", "\n", "        ", "input_ids", ",", "attention_mask", "=", "self", ".", "_prepare_input", "(", "input_ids", ")", "\n", "decoder_input_ids", "=", "output_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "decoder_attention_mask", "=", "(", "decoder_input_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "output_ids", "[", ":", ",", "1", ":", "]", ".", "clone", "(", ")", "\n", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "use_cache", "=", "False", ",", ")", "\n", "lm_logits", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "args", ".", "label_smoothing", "==", "0", ":", "\n", "# Same behavior as modeling_bart.py, besides ignoring pad_token_id", "\n", "            ", "ce_loss_fct", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "assert", "lm_logits", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "model", ".", "config", ".", "vocab_size", "\n", "loss", "=", "ce_loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "lprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "lm_logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "labels", ",", "self", ".", "args", ".", "label_smoothing", ",", "ignore_index", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", ")", "\n", "", "return", "[", "loss", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.training_step": [[142, 151], ["summarization.Summarizer.forward", "loss.new_zeros", "batch[].numel", "batch[].numel", "torch.cuda.is_available", "torch.cuda.memory_allocated"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "output", "=", "self", ".", "forward", "(", "*", "batch", ")", "\n", "loss", "=", "output", "[", "0", "]", "\n", "lr", "=", "loss", ".", "new_zeros", "(", "1", ")", "+", "self", ".", "trainer", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "tensorboard_logs", "=", "{", "'train_loss'", ":", "loss", ",", "'lr'", ":", "lr", ",", "\n", "'input_size'", ":", "batch", "[", "0", "]", ".", "numel", "(", ")", ",", "\n", "'output_size'", ":", "batch", "[", "1", "]", ".", "numel", "(", ")", ",", "\n", "'mem'", ":", "torch", ".", "cuda", ".", "memory_allocated", "(", "loss", ".", "device", ")", "/", "1024", "**", "3", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "0", "}", "\n", "return", "{", "'loss'", ":", "loss", ",", "'log'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.validation_step": [[152, 183], ["summarization.Summarizer.model.parameters", "summarization.Summarizer.forward", "summarization.Summarizer._prepare_input", "summarization.Summarizer.model.generate", "summarization.Summarizer.tokenizer.batch_decode", "summarization.Summarizer.tokenizer.batch_decode", "rouge_score.rouge_scorer.RougeScorer", "zip", "len", "len", "len", "len", "summarization.Summarizer.tolist", "output_ids.tolist", "rouge_score.rouge_scorer.RougeScorer.score", "vloss.new_zeros", "vloss.new_zeros", "vloss.new_zeros", "vloss.new_zeros"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._prepare_input"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "outputs", "=", "self", ".", "forward", "(", "*", "batch", ")", "\n", "vloss", "=", "outputs", "[", "0", "]", "\n", "input_ids", ",", "output_ids", "=", "batch", "\n", "input_ids", ",", "attention_mask", "=", "self", ".", "_prepare_input", "(", "input_ids", ")", "\n", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "True", ",", "max_length", "=", "self", ".", "args", ".", "max_output_len", ",", "\n", "num_beams", "=", "1", ")", "\n", "generated_str", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "generated_ids", ".", "tolist", "(", ")", ",", "skip_special_tokens", "=", "True", ")", "\n", "gold_str", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "output_ids", ".", "tolist", "(", ")", ",", "skip_special_tokens", "=", "True", ")", "\n", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "rouge_types", "=", "[", "'rouge1'", ",", "'rouge2'", ",", "'rougeL'", ",", "'rougeLsum'", "]", ",", "use_stemmer", "=", "False", ")", "\n", "rouge1", "=", "rouge2", "=", "rougel", "=", "rougelsum", "=", "0.0", "\n", "for", "ref", ",", "pred", "in", "zip", "(", "gold_str", ",", "generated_str", ")", ":", "\n", "            ", "score", "=", "scorer", ".", "score", "(", "ref", ",", "pred", ")", "\n", "rouge1", "+=", "score", "[", "'rouge1'", "]", ".", "fmeasure", "\n", "rouge2", "+=", "score", "[", "'rouge2'", "]", ".", "fmeasure", "\n", "rougel", "+=", "score", "[", "'rougeL'", "]", ".", "fmeasure", "\n", "rougelsum", "+=", "score", "[", "'rougeLsum'", "]", ".", "fmeasure", "\n", "", "rouge1", "/=", "len", "(", "generated_str", ")", "\n", "rouge2", "/=", "len", "(", "generated_str", ")", "\n", "rougel", "/=", "len", "(", "generated_str", ")", "\n", "rougelsum", "/=", "len", "(", "generated_str", ")", "\n", "\n", "return", "{", "'vloss'", ":", "vloss", ",", "\n", "'rouge1'", ":", "vloss", ".", "new_zeros", "(", "1", ")", "+", "rouge1", ",", "\n", "'rouge2'", ":", "vloss", ".", "new_zeros", "(", "1", ")", "+", "rouge2", ",", "\n", "'rougeL'", ":", "vloss", ".", "new_zeros", "(", "1", ")", "+", "rougel", ",", "\n", "'rougeLsum'", ":", "vloss", ".", "new_zeros", "(", "1", ")", "+", "rougelsum", ",", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.validation_epoch_end": [[184, 199], ["summarization.Summarizer.model.parameters", "dict", "print", "torch.stack().mean", "metrics.append", "zip", "torch.distributed.all_reduce", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "\n", "", "names", "=", "[", "'vloss'", ",", "'rouge1'", ",", "'rouge2'", ",", "'rougeL'", ",", "'rougeLsum'", "]", "\n", "metrics", "=", "[", "]", "\n", "for", "name", "in", "names", ":", "\n", "            ", "metric", "=", "torch", ".", "stack", "(", "[", "x", "[", "name", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "if", "self", ".", "trainer", ".", "use_ddp", ":", "\n", "                ", "torch", ".", "distributed", ".", "all_reduce", "(", "metric", ",", "op", "=", "torch", ".", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "metric", "/=", "self", ".", "trainer", ".", "world_size", "\n", "", "metrics", ".", "append", "(", "metric", ")", "\n", "", "logs", "=", "dict", "(", "zip", "(", "*", "[", "names", ",", "metrics", "]", ")", ")", "\n", "print", "(", "logs", ")", "\n", "return", "{", "'avg_val_loss'", ":", "logs", "[", "'vloss'", "]", ",", "'log'", ":", "logs", ",", "'progress_bar'", ":", "logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.test_step": [[200, 202], ["summarization.Summarizer.validation_step"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.validation_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "return", "self", ".", "validation_step", "(", "batch", ",", "batch_nb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.test_epoch_end": [[203, 206], ["summarization.Summarizer.validation_epoch_end", "print"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.validation_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "result", "=", "self", ".", "validation_epoch_end", "(", "outputs", ")", "\n", "print", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.configure_optimizers": [[207, 220], ["transformers.optimization.get_linear_schedule_with_warmup", "transformers.optimization.Adafactor", "torch.optim.Adam", "torch.cuda.is_available", "torch.cuda.device_count", "summarization.Summarizer.model.parameters", "summarization.Summarizer.model.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "adafactor", ":", "\n", "            ", "optimizer", "=", "Adafactor", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "\n", "", "if", "self", ".", "args", ".", "debug", ":", "\n", "            ", "return", "optimizer", "# const LR", "\n", "", "num_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "1", "\n", "num_steps", "=", "self", ".", "args", ".", "dataset_size", "*", "self", ".", "args", ".", "epochs", "/", "num_gpus", "/", "self", ".", "args", ".", "grad_accum", "/", "self", ".", "args", ".", "batch_size", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup", ",", "num_training_steps", "=", "num_steps", "\n", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._get_dataloader": [[221, 230], ["summarization.SummarizationDataset", "torch.utils.data.DataLoader", "torch.utils.data.distributed.DistributedSampler"], "methods", ["None"], ["", "def", "_get_dataloader", "(", "self", ",", "current_dataloader", ",", "split_name", ",", "is_train", ")", ":", "\n", "        ", "if", "current_dataloader", "is", "not", "None", ":", "\n", "            ", "return", "current_dataloader", "\n", "", "dataset", "=", "SummarizationDataset", "(", "hf_dataset", "=", "self", ".", "hf_datasets", "[", "split_name", "]", ",", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_input_len", "=", "self", ".", "args", ".", "max_input_len", ",", "max_output_len", "=", "self", ".", "args", ".", "max_output_len", ")", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "is_train", ")", "if", "self", ".", "trainer", ".", "use_ddp", "else", "None", "\n", "return", "DataLoader", "(", "dataset", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "self", ".", "args", ".", "num_workers", ",", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "SummarizationDataset", ".", "collate_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.train_dataloader": [[231, 235], ["summarization.Summarizer._get_dataloader"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._get_dataloader"], ["", "@", "pl", ".", "data_loader", "\n", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_dataloader_object", "=", "self", ".", "_get_dataloader", "(", "self", ".", "train_dataloader_object", ",", "'train'", ",", "is_train", "=", "True", ")", "\n", "return", "self", ".", "train_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.val_dataloader": [[236, 240], ["summarization.Summarizer._get_dataloader"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._get_dataloader"], ["", "@", "pl", ".", "data_loader", "\n", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_dataloader_object", "=", "self", ".", "_get_dataloader", "(", "self", ".", "val_dataloader_object", ",", "'validation'", ",", "is_train", "=", "False", ")", "\n", "return", "self", ".", "val_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.test_dataloader": [[241, 245], ["summarization.Summarizer._get_dataloader"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer._get_dataloader"], ["", "@", "pl", ".", "data_loader", "\n", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_dataloader_object", "=", "self", ".", "_get_dataloader", "(", "self", ".", "test_dataloader_object", ",", "'test'", ",", "is_train", "=", "False", ")", "\n", "return", "self", ".", "test_dataloader_object", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.configure_ddp": [[246, 253], ["pytorch_lightning.overrides.data_parallel.LightningDistributedDataParallel"], "methods", ["None"], ["", "def", "configure_ddp", "(", "self", ",", "model", ",", "device_ids", ")", ":", "\n", "        ", "model", "=", "LightningDistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "device_ids", ",", "\n", "find_unused_parameters", "=", "False", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.Summarizer.add_model_specific_args": [[254, 292], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "default", "=", "'summarization'", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_prefix\"", ",", "type", "=", "str", ",", "default", "=", "'test'", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "\"Batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--grad_accum\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"number of gradient accumulation steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpus\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Number of gpus. 0 for CPU\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "\"Number of warmup steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.00003", ",", "help", "=", "\"Maximum learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_every\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "\"Number of training steps between validations\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_percent_check\"", ",", "default", "=", "1.00", ",", "type", "=", "float", ",", "help", "=", "'Percent of validation data used'", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Number of data loader workers\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "\"Seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Number of epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--disable_checkpointing\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"No logging or checkpointing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_output_len\"", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "\"maximum num of wordpieces/summary. Used for training and testing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_input_len\"", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "\"maximum num of wordpieces/summary. Used for training and testing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Test only, no training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_path\"", ",", "type", "=", "str", ",", "default", "=", "'facebook/bart-base'", ",", "\n", "help", "=", "\"Path to the checkpoint directory or model name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer\"", ",", "type", "=", "str", ",", "default", "=", "'facebook/bart-base'", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_progress_bar\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"no progress bar. Good for printing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp32\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"default is fp16. Use --fp32 to switch to fp32\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"debug run\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_ckpt\"", ",", "type", "=", "str", ",", "help", "=", "\"Path of a checkpoint to resume from\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--from_pretrained\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Path to a checkpoint to load model weights but not training state\"", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_ckpt'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Enable gradient checkpointing to save memory'", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"attention dropout\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention_mode\"", ",", "type", "=", "str", ",", "default", "=", "'sliding_chunks'", ",", "help", "=", "\"Longformer attention mode\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention_window\"", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "\"Attention window\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--adafactor\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use adafactor optimizer\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.label_smoothed_nll_loss": [[23, 44], ["target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.eq", "nll_loss.squeeze.masked_fill_", "smooth_loss.squeeze.masked_fill_", "nll_loss.squeeze.squeeze", "smooth_loss.squeeze.squeeze", "nll_loss.squeeze.numel", "nll_loss.squeeze.sum", "smooth_loss.squeeze.sum", "lprobs.size", "lprobs.dim"], "function", ["None"], ["def", "label_smoothed_nll_loss", "(", "lprobs", ",", "target", ",", "epsilon", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "    ", "\"\"\"From fairseq\"\"\"", "\n", "if", "target", ".", "dim", "(", ")", "==", "lprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "target", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "nll_loss", "=", "-", "lprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ")", "\n", "smooth_loss", "=", "-", "lprobs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "pad_mask", "=", "target", ".", "eq", "(", "ignore_index", ")", "\n", "nll_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "smooth_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "count", "=", "(", "~", "pad_mask", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "count", "=", "nll_loss", ".", "numel", "(", ")", "\n", "\n", "", "nll_loss", "=", "nll_loss", ".", "sum", "(", ")", "/", "count", "\n", "smooth_loss", "=", "smooth_loss", ".", "sum", "(", ")", "/", "count", "\n", "eps_i", "=", "epsilon", "/", "lprobs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.0", "-", "epsilon", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.summarization.main": [[294, 348], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "nlp.load_dataset", "pytorch_lightning.logging.TestTubeLogger", "pytorch_lightning.callbacks.ModelCheckpoint", "print", "pytorch_lightning.Trainer", "pl.Trainer.test", "torch.cuda.manual_seed_all", "Summarizer.load_from_checkpoint", "summarization.Summarizer", "pl.Trainer.fit", "os.path.join", "torch.cuda.is_available"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "args", ".", "from_pretrained", "is", "not", "None", ":", "\n", "        ", "model", "=", "Summarizer", ".", "load_from_checkpoint", "(", "args", ".", "from_pretrained", ",", "args", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "Summarizer", "(", "args", ")", "\n", "\n", "", "model", ".", "hf_datasets", "=", "nlp", ".", "load_dataset", "(", "'scientific_papers'", ",", "'arxiv'", ")", "\n", "\n", "logger", "=", "TestTubeLogger", "(", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "name", "=", "args", ".", "save_prefix", ",", "\n", "version", "=", "0", "# always use version=0", "\n", ")", "\n", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "args", ".", "save_prefix", ",", "\"checkpoints\"", ")", ",", "\n", "save_top_k", "=", "5", ",", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "'avg_val_loss'", ",", "\n", "mode", "=", "'min'", ",", "\n", "period", "=", "-", "1", ",", "\n", "prefix", "=", "''", "\n", ")", "\n", "\n", "print", "(", "args", ")", "\n", "\n", "args", ".", "dataset_size", "=", "203037", "# hardcode dataset size. Needed to compute number of steps for the lr scheduler", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "gpus", "=", "args", ".", "gpus", ",", "distributed_backend", "=", "'ddp'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ",", "\n", "track_grad_norm", "=", "-", "1", ",", "\n", "max_epochs", "=", "args", ".", "epochs", "if", "not", "args", ".", "debug", "else", "100", ",", "\n", "max_steps", "=", "None", "if", "not", "args", ".", "debug", "else", "1", ",", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "grad_accum", ",", "\n", "val_check_interval", "=", "args", ".", "val_every", "if", "not", "args", ".", "debug", "else", "1", ",", "\n", "num_sanity_val_steps", "=", "2", "if", "not", "args", ".", "debug", "else", "0", ",", "\n", "check_val_every_n_epoch", "=", "1", "if", "not", "args", ".", "debug", "else", "1", ",", "\n", "val_percent_check", "=", "args", ".", "val_percent_check", ",", "\n", "test_percent_check", "=", "args", ".", "val_percent_check", ",", "\n", "logger", "=", "logger", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", "if", "not", "args", ".", "disable_checkpointing", "else", "False", ",", "\n", "show_progress_bar", "=", "not", "args", ".", "no_progress_bar", ",", "\n", "use_amp", "=", "not", "args", ".", "fp32", ",", "amp_level", "=", "'O2'", ",", "\n", "resume_from_checkpoint", "=", "args", ".", "resume_ckpt", ",", "\n", ")", "\n", "if", "not", "args", ".", "test", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "", "trainer", ".", "test", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolDataset.__len__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "128", "*", "128", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolDataset.__getitem__": [[12, 14], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "[", "1", ",", "2", ",", "3", ",", "4", "]", "*", "128", "*", "1", ")", ",", "torch", ".", "tensor", "(", "[", "1", ",", "1", ",", "1", ",", "1", "]", "*", "128", "*", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__": [[18, 23], ["pytorch_lightning.LightningModule.__init__", "transformers.AutoModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# self.model = AutoModel.from_pretrained('allenai/longformer-base-4096')", "\n", "self", ".", "model", "=", "AutoModel", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.forward": [[24, 26], ["test_tpu.CoolSystem.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ",", "attention_mask", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.training_step": [[27, 32], ["test_tpu.CoolSystem.", "y_hat[].sum"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "x", ",", "y", "=", "batch", "\n", "y_hat", "=", "self", "(", "x", ",", "y", ")", "\n", "loss", "=", "y_hat", "[", "0", "]", ".", "sum", "(", ")", "\n", "return", "{", "'loss'", ":", "loss", "*", "0.00000001", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.configure_optimizers": [[33, 35], ["torch.optim.Adam", "test_tpu.CoolSystem.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "0.0000000001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.scripts.test_tpu.CoolSystem.train_dataloader": [[36, 39], ["torch.utils.data.DataLoader", "test_tpu.CoolDataset"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "loader", "=", "DataLoader", "(", "CoolDataset", "(", ")", ",", "batch_size", "=", "56", ",", "num_workers", "=", "0", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_key_to_ground_truth": [[7, 12], ["dataset_utils.get_qd_to_answer"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_qd_to_answer"], ["def", "get_key_to_ground_truth", "(", "data", ")", ":", "\n", "    ", "if", "data", "[", "'Domain'", "]", "==", "'Wikipedia'", ":", "\n", "        ", "return", "{", "datum", "[", "'QuestionId'", "]", ":", "datum", "[", "'Answer'", "]", "for", "datum", "in", "data", "[", "'Data'", "]", "}", "\n", "", "else", ":", "\n", "        ", "return", "get_qd_to_answer", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_question_doc_string": [[14, 16], ["None"], "function", ["None"], ["", "", "def", "get_question_doc_string", "(", "qid", ",", "doc_name", ")", ":", "\n", "    ", "return", "'{}--{}'", ".", "format", "(", "qid", ",", "doc_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_qd_to_answer": [[17, 24], ["datum.get", "datum.get", "dataset_utils.get_question_doc_string"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_question_doc_string"], ["", "def", "get_qd_to_answer", "(", "data", ")", ":", "\n", "    ", "key_to_answer", "=", "{", "}", "\n", "for", "datum", "in", "data", "[", "'Data'", "]", ":", "\n", "        ", "for", "page", "in", "datum", ".", "get", "(", "'EntityPages'", ",", "[", "]", ")", "+", "datum", ".", "get", "(", "'SearchResults'", ",", "[", "]", ")", ":", "\n", "            ", "qd_tuple", "=", "get_question_doc_string", "(", "datum", "[", "'QuestionId'", "]", ",", "page", "[", "'Filename'", "]", ")", "\n", "key_to_answer", "[", "qd_tuple", "]", "=", "datum", "[", "'Answer'", "]", "\n", "", "", "return", "key_to_answer", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.read_clean_part": [[26, 35], ["datum.get", "len", "len", "new_page_list.append"], "function", ["None"], ["", "def", "read_clean_part", "(", "datum", ")", ":", "\n", "    ", "for", "key", "in", "[", "'EntityPages'", ",", "'SearchResults'", "]", ":", "\n", "        ", "new_page_list", "=", "[", "]", "\n", "for", "page", "in", "datum", ".", "get", "(", "key", ",", "[", "]", ")", ":", "\n", "            ", "if", "page", "[", "'DocPartOfVerifiedEval'", "]", ":", "\n", "                ", "new_page_list", ".", "append", "(", "page", ")", "\n", "", "", "datum", "[", "key", "]", "=", "new_page_list", "\n", "", "assert", "len", "(", "datum", "[", "'EntityPages'", "]", ")", "+", "len", "(", "datum", "[", "'SearchResults'", "]", ")", ">", "0", "\n", "return", "datum", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.read_triviaqa_data": [[37, 49], ["file_utils.read_json", "clean_data.append", "dataset_utils.read_clean_part"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.read_json", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.read_clean_part"], ["", "def", "read_triviaqa_data", "(", "qajson", ")", ":", "\n", "    ", "data", "=", "file_utils", ".", "read_json", "(", "qajson", ")", "\n", "# read only documents and questions that are a part of clean data set", "\n", "if", "data", "[", "'VerifiedEval'", "]", ":", "\n", "        ", "clean_data", "=", "[", "]", "\n", "for", "datum", "in", "data", "[", "'Data'", "]", ":", "\n", "            ", "if", "datum", "[", "'QuestionPartOfVerifiedEval'", "]", ":", "\n", "                ", "if", "data", "[", "'Domain'", "]", "==", "'Web'", ":", "\n", "                    ", "datum", "=", "read_clean_part", "(", "datum", ")", "\n", "", "clean_data", ".", "append", "(", "datum", ")", "\n", "", "", "data", "[", "'Data'", "]", "=", "clean_data", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.answer_index_in_document": [[51, 62], ["m.start", "answers_in_doc.append", "re.finditer"], "function", ["None"], ["", "def", "answer_index_in_document", "(", "answer", ",", "document", ")", ":", "\n", "    ", "answer_list", "=", "answer", "[", "'NormalizedAliases'", "]", "\n", "answers_in_doc", "=", "[", "]", "\n", "for", "answer_string_in_doc", "in", "answer_list", ":", "\n", "        ", "indices", "=", "[", "m", ".", "start", "(", ")", "for", "m", "in", "re", ".", "finditer", "(", "answer_string_in_doc", ",", "document", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "]", "\n", "for", "index", "in", "indices", ":", "\n", "            ", "answers_in_doc", ".", "append", "(", "{", "\n", "'text'", ":", "answer_string_in_doc", ",", "\n", "'answer_start'", ":", "index", "\n", "}", ")", "\n", "", "", "return", "answers_in_doc", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.write_json_to_file": [[4, 7], ["open", "json.dump"], "function", ["None"], ["def", "write_json_to_file", "(", "json_object", ",", "json_file", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "with", "open", "(", "json_file", ",", "mode", ",", "encoding", "=", "encoding", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "json_object", ",", "outfile", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.get_file_contents": [[9, 13], ["open", "f.read"], "function", ["None"], ["", "", "def", "get_file_contents", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "encoding", "=", "encoding", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "read", "(", ")", "\n", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.read_json": [[15, 18], ["file_utils.get_file_contents", "json.loads"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.get_file_contents"], ["", "def", "read_json", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", ":", "\n", "    ", "contents", "=", "get_file_contents", "(", "filename", ",", "encoding", "=", "encoding", ")", "\n", "return", "json", ".", "loads", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.get_file_contents_as_list": [[20, 25], ["file_utils.get_file_contents", "get_file_contents.split"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.get_file_contents"], ["", "def", "get_file_contents_as_list", "(", "file_path", ",", "encoding", "=", "'utf-8'", ",", "ignore_blanks", "=", "True", ")", ":", "\n", "    ", "contents", "=", "get_file_contents", "(", "file_path", ",", "encoding", "=", "encoding", ")", "\n", "lines", "=", "contents", ".", "split", "(", "'\\n'", ")", "\n", "lines", "=", "[", "line", "for", "line", "in", "lines", "if", "line", "!=", "''", "]", "if", "ignore_blanks", "else", "lines", "\n", "return", "lines", "\n", "", ""]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.get_text": [[10, 13], ["file_utils.get_file_contents", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.get_file_contents"], ["def", "get_text", "(", "qad", ",", "domain", ")", ":", "\n", "    ", "local_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "web_dir", ",", "qad", "[", "'Filename'", "]", ")", "if", "domain", "==", "'SearchResults'", "else", "os", ".", "path", ".", "join", "(", "args", ".", "wikipedia_dir", ",", "qad", "[", "'Filename'", "]", ")", "\n", "return", "file_utils", ".", "get_file_contents", "(", "local_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.select_relevant_portion": [[15, 42], ["text.split", "sent_tokenize.tokenize", "selected.append", "nltk.word_tokenize", "selected.append", "len"], "function", ["None"], ["", "def", "select_relevant_portion", "(", "text", ")", ":", "\n", "    ", "paras", "=", "text", ".", "split", "(", "'\\n'", ")", "\n", "selected", "=", "[", "]", "\n", "done", "=", "False", "\n", "for", "para", "in", "paras", ":", "\n", "# nltk is slow, but we have to use its word tokenizer for the distant supervision matching to work", "\n", "# TODO: try both see which one works better", "\n", "# words = para.split()", "\n", "# extra_words = args.max_num_tokens - len(selected)", "\n", "# selected.extend(words[:extra_words])", "\n", "# if len(selected) >= args.max_num_tokens:", "\n", "#     break", "\n", "        ", "sents", "=", "sent_tokenize", ".", "tokenize", "(", "para", ")", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "words", "=", "nltk", ".", "word_tokenize", "(", "sent", ")", "\n", "for", "word", "in", "words", ":", "\n", "                ", "selected", ".", "append", "(", "word", ")", "\n", "if", "len", "(", "selected", ")", ">=", "args", ".", "max_num_tokens", ":", "\n", "                    ", "done", "=", "True", "\n", "break", "\n", "", "", "if", "done", ":", "\n", "                ", "break", "\n", "", "", "if", "done", ":", "\n", "            ", "break", "\n", "", "selected", ".", "append", "(", "'\\n'", ")", "\n", "", "st", "=", "' '", ".", "join", "(", "selected", ")", ".", "strip", "(", ")", "\n", "return", "st", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.add_triple_data": [[44, 56], ["print"], "function", ["None"], ["", "def", "add_triple_data", "(", "datum", ",", "page", ",", "domain", ")", ":", "\n", "    ", "qad", "=", "{", "'Source'", ":", "domain", "}", "\n", "for", "key", "in", "[", "'QuestionId'", ",", "'Question'", ",", "'Answer'", "]", ":", "\n", "        ", "if", "key", "==", "'Answer'", "and", "key", "not", "in", "datum", ":", "\n", "            ", "qad", "[", "key", "]", "=", "{", "'NormalizedAliases'", ":", "[", "]", "}", "\n", "qid", "=", "datum", "[", "'QuestionId'", "]", "\n", "print", "(", "f'qid: {qid} does not have an answer.'", ")", "\n", "", "else", ":", "\n", "            ", "qad", "[", "key", "]", "=", "datum", "[", "key", "]", "\n", "", "", "for", "key", "in", "page", ":", "\n", "        ", "qad", "[", "key", "]", "=", "page", "[", "key", "]", "\n", "", "return", "qad", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.get_qad_triples": [[58, 66], ["datum.get", "convert_to_squad_format.add_triple_data", "qad_triples.append"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.add_triple_data"], ["", "def", "get_qad_triples", "(", "data", ")", ":", "\n", "    ", "qad_triples", "=", "[", "]", "\n", "for", "datum", "in", "data", "[", "'Data'", "]", ":", "\n", "        ", "for", "key", "in", "[", "'EntityPages'", ",", "'SearchResults'", "]", ":", "\n", "            ", "for", "page", "in", "datum", ".", "get", "(", "key", ",", "[", "]", ")", ":", "\n", "                ", "qad", "=", "add_triple_data", "(", "datum", ",", "page", ",", "key", ")", "\n", "qad_triples", ".", "append", "(", "qad", ")", "\n", "", "", "", "return", "qad_triples", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.convert_to_squad_format": [[68, 109], ["dataset_utils.read_triviaqa_data", "convert_to_squad_format.get_qad_triples", "random.seed", "random.shuffle", "tqdm.tqdm", "file_utils.write_json_to_file", "print", "convert_to_squad_format.get_text", "convert_to_squad_format.select_relevant_portion", "data.append", "dataset_utils.get_question_doc_string", "dataset_utils.answer_index_in_document", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.read_triviaqa_data", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.get_qad_triples", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.file_utils.write_json_to_file", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.get_text", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.select_relevant_portion", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.get_question_doc_string", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.dataset_utils.answer_index_in_document"], ["", "def", "convert_to_squad_format", "(", "qa_json_file", ",", "squad_file", ")", ":", "\n", "    ", "qa_json", "=", "dataset_utils", ".", "read_triviaqa_data", "(", "qa_json_file", ")", "\n", "qad_triples", "=", "get_qad_triples", "(", "qa_json", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "shuffle", "(", "qad_triples", ")", "\n", "\n", "data", "=", "[", "]", "\n", "for", "qad", "in", "tqdm", "(", "qad_triples", ")", ":", "\n", "        ", "qid", "=", "qad", "[", "'QuestionId'", "]", "\n", "\n", "text", "=", "get_text", "(", "qad", ",", "qad", "[", "'Source'", "]", ")", "\n", "selected_text", "=", "select_relevant_portion", "(", "text", ")", "\n", "\n", "question", "=", "qad", "[", "'Question'", "]", "\n", "para", "=", "{", "'context'", ":", "selected_text", ",", "'qas'", ":", "[", "{", "'question'", ":", "question", ",", "'answers'", ":", "[", "]", "}", "]", "}", "\n", "data", ".", "append", "(", "{", "'paragraphs'", ":", "[", "para", "]", "}", ")", "\n", "qa", "=", "para", "[", "'qas'", "]", "[", "0", "]", "\n", "qa", "[", "'id'", "]", "=", "dataset_utils", ".", "get_question_doc_string", "(", "qid", ",", "qad", "[", "'Filename'", "]", ")", "\n", "qa", "[", "'qid'", "]", "=", "qid", "\n", "\n", "answers_in_doc", "=", "dataset_utils", ".", "answer_index_in_document", "(", "qad", "[", "'Answer'", "]", ",", "selected_text", ")", "\n", "qa", "[", "'answers'", "]", "=", "answers_in_doc", "\n", "# We want all answers in the document, not just the first answer", "\n", "# if index == -1:", "\n", "#     if qa_json['Split'] == 'train':", "\n", "#         continue", "\n", "# else:", "\n", "#     qa['answers'].append({'text': ans_string, 'answer_start': index})", "\n", "\n", "# This doesn't fit the squad format, but we need it for evaluation", "\n", "qa", "[", "'aliases'", "]", "=", "qad", "[", "'Answer'", "]", "[", "'NormalizedAliases'", "]", "\n", "\n", "if", "qa_json", "[", "'Split'", "]", "==", "'train'", "and", "len", "(", "data", ")", ">=", "args", ".", "sample_size", "and", "qa_json", "[", "'Domain'", "]", "==", "'Web'", ":", "\n", "            ", "break", "\n", "\n", "", "if", "len", "(", "data", ")", ">=", "args", ".", "sample_size", ":", "\n", "            ", "break", "\n", "\n", "", "", "squad", "=", "{", "'data'", ":", "data", ",", "'version'", ":", "qa_json", "[", "'Version'", "]", "}", "\n", "file_utils", ".", "write_json_to_file", "(", "squad", ",", "squad_file", ")", "\n", "print", "(", "'Added'", ",", "len", "(", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.convert_to_squad_format.get_args": [[111, 124], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--triviaqa_file'", ",", "help", "=", "'Triviaqa file'", ")", "\n", "parser", ".", "add_argument", "(", "'--squad_file'", ",", "help", "=", "'Squad file'", ")", "\n", "parser", ".", "add_argument", "(", "'--wikipedia_dir'", ",", "help", "=", "'Wikipedia doc dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--web_dir'", ",", "help", "=", "'Web doc dir'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "'Random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_num_tokens'", ",", "default", "=", "800", ",", "type", "=", "int", ",", "help", "=", "'Maximum number of tokens from a document'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_size'", ",", "default", "=", "8000000000000", ",", "type", "=", "int", ",", "help", "=", "'Random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "default", "=", "'tokenizers/punkt/english.pickle'", ",", "help", "=", "'Sentence tokenizer'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer": [[15, 35], ["white_space_fix().strip", "re.sub", "set", "text.lower", "text.replace", "text.split", "evaluation_utils.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "handle_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", "+", "\"\"", ".", "join", "(", "[", "u\"\u2018\"", ",", "u\"\u2019\"", ",", "u\"\u00b4\"", ",", "u\"`\"", "]", ")", ")", "\n", "return", "''", ".", "join", "(", "ch", "if", "ch", "not", "in", "exclude", "else", "' '", "for", "ch", "in", "text", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "def", "replace_underscore", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "handle_punc", "(", "lower", "(", "replace_underscore", "(", "s", ")", ")", ")", ")", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.f1_score": [[37, 48], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "evaluation_utils.normalize_answer", "evaluation_utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.exact_match_score": [[50, 52], ["int", "evaluation_utils.normalize_answer", "evaluation_utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "int", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths": [[54, 60], ["max", "scores_for_ground_truths.append", "evaluation_utils.exact_match_score", "evaluation_utils.f1_score"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.exact_match_score", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.is_exact_match": [[62, 68], ["evaluation_utils.get_ground_truths", "evaluation_utils.exact_match_score"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.exact_match_score"], ["", "def", "is_exact_match", "(", "answer_object", ",", "prediction", ")", ":", "\n", "    ", "ground_truths", "=", "get_ground_truths", "(", "answer_object", ")", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "if", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.has_exact_match": [[70, 75], ["None"], "function", ["None"], ["", "def", "has_exact_match", "(", "ground_truths", ",", "candidates", ")", ":", "\n", "    ", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "if", "ground_truth", "in", "candidates", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_ground_truths": [[77, 79], ["evaluation_utils.normalize_answer", "answer.get"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer"], ["", "def", "get_ground_truths", "(", "answer", ")", ":", "\n", "    ", "return", "answer", "[", "'NormalizedAliases'", "]", "+", "[", "normalize_answer", "(", "ans", ")", "for", "ans", "in", "answer", ".", "get", "(", "'HumanAnswers'", ",", "[", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_oracle_score": [[81, 101], ["ground_truth.keys", "evaluation_utils.normalize_answer", "evaluation_utils.get_ground_truths", "evaluation_utils.has_exact_match", "int", "len", "len", "len", "len", "print"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.normalize_answer", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.has_exact_match"], ["", "def", "get_oracle_score", "(", "ground_truth", ",", "predicted_answers", ",", "qid_list", "=", "None", ",", "mute", "=", "False", ")", ":", "\n", "    ", "exact_match", "=", "common", "=", "0", "\n", "if", "qid_list", "is", "None", ":", "\n", "        ", "qid_list", "=", "ground_truth", ".", "keys", "(", ")", "\n", "", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "qid", "not", "in", "predicted_answers", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Irrelavant question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "common", "+=", "1", "\n", "prediction", "=", "normalize_answer", "(", "predicted_answers", "[", "qid", "]", ")", "\n", "ground_truths", "=", "get_ground_truths", "(", "ground_truth", "[", "qid", "]", ")", "\n", "em_for_this_question", "=", "has_exact_match", "(", "ground_truths", ",", "prediction", ")", "\n", "exact_match", "+=", "int", "(", "em_for_this_question", ")", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "len", "(", "qid_list", ")", "\n", "\n", "return", "{", "'oracle_exact_match'", ":", "exact_match", ",", "'common'", ":", "common", ",", "'denominator'", ":", "len", "(", "qid_list", ")", ",", "\n", "'pred_len'", ":", "len", "(", "predicted_answers", ")", ",", "'gold_len'", ":", "len", "(", "ground_truth", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.evaluate_triviaqa": [[103, 135], ["ground_truth.keys", "evaluation_utils.get_ground_truths", "evaluation_utils.metric_max_over_ground_truths", "evaluation_utils.metric_max_over_ground_truths", "len", "len", "len", "len", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.metric_max_over_ground_truths"], ["", "def", "evaluate_triviaqa", "(", "ground_truth", ",", "predicted_answers", ",", "qid_list", "=", "None", ",", "mute", "=", "False", ")", ":", "\n", "    ", "f1", "=", "exact_match", "=", "common", "=", "0", "\n", "if", "qid_list", "is", "None", ":", "\n", "        ", "qid_list", "=", "ground_truth", ".", "keys", "(", ")", "\n", "", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "qid", "not", "in", "predicted_answers", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Missed question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "if", "qid", "not", "in", "ground_truth", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Irrelavant question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "common", "+=", "1", "\n", "prediction", "=", "predicted_answers", "[", "qid", "]", "\n", "ground_truths", "=", "get_ground_truths", "(", "ground_truth", "[", "qid", "]", ")", "\n", "em_for_this_question", "=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "ground_truths", ")", "\n", "if", "em_for_this_question", "==", "0", "and", "not", "mute", ":", "\n", "            ", "print", "(", "\"em=0:\"", ",", "prediction", ",", "ground_truths", ")", "\n", "", "exact_match", "+=", "em_for_this_question", "\n", "f1_for_this_question", "=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "f1", "+=", "f1_for_this_question", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "len", "(", "qid_list", ")", "\n", "f1", "=", "100.0", "*", "f1", "/", "len", "(", "qid_list", ")", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", ",", "'common'", ":", "common", ",", "'denominator'", ":", "len", "(", "qid_list", ")", ",", "\n", "'pred_len'", ":", "len", "(", "predicted_answers", ")", ",", "'gold_len'", ":", "len", "(", "ground_truth", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jd-ai-research-nlp_ror.triviaqa_utils.evaluation_utils.get_args": [[137, 144], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluation for TriviaQA {}'", ".", "format", "(", "expected_version", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_file'", ",", "help", "=", "'Dataset file'", ")", "\n", "parser", ".", "add_argument", "(", "'--prediction_file'", ",", "help", "=", "'Prediction File'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]]}