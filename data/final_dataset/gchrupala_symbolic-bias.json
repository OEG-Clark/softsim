{"home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.main": [[19, 49], ["logging.getLogger().setLevel", "argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "parser.add_subparsers.add_parser", "commands.add_parser.set_defaults", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "parser.add_subparsers.add_parser", "commands.add_parser.set_defaults", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "parser.add_subparsers.add_parser", "commands.add_parser.set_defaults", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "parser.add_subparsers.add_parser", "commands.add_parser.set_defaults", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.func", "logging.getLogger"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "'INFO'", ")", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "commands", "=", "parser", ".", "add_subparsers", "(", ")", "\n", "mfcc_p", "=", "commands", ".", "add_parser", "(", "'mfcc'", ")", "\n", "mfcc_p", ".", "set_defaults", "(", "func", "=", "mfcc", ")", "\n", "mfcc_p", ".", "add_argument", "(", "'--dataset'", ",", "help", "=", "'Dataset to process: flickr8k, places, librispeech or semanticf8k'", ")", "\n", "mfcc_p", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'Path to file where output will be saved'", ",", "default", "=", "'mfcc.npy'", ")", "\n", "\n", "\n", "merge_p", "=", "commands", ".", "add_parser", "(", "'merge'", ")", "\n", "merge_p", ".", "set_defaults", "(", "func", "=", "merge", ")", "\n", "merge_p", ".", "add_argument", "(", "'--prefix'", ",", "help", "=", "'Prefix of the input files'", ")", "\n", "merge_p", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'Path to file where output will be saved'", ",", "default", "=", "'data.h5'", ")", "\n", "\n", "imgfeats_p", "=", "commands", ".", "add_parser", "(", "\"imgfeats\"", ")", "\n", "imgfeats_p", ".", "set_defaults", "(", "func", "=", "run_img_feats", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--dataset'", ",", "choices", "=", "[", "'flickr8k'", ",", "'places'", "]", ",", "help", "=", "'Dataset to process'", ",", "default", "=", "'places'", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--output'", ",", "help", "=", "'Path to file where output will be saved'", ",", "default", "=", "'imgfeats'", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--cnn'", ",", "choices", "=", "[", "\"vgg16\"", ",", "\"vgg19\"", ",", "\"hybrid\"", "]", ",", "help", "=", "'Which CNN to run'", ",", "default", "=", "\"vgg16\"", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--resize'", ",", "type", "=", "int", ",", "help", "=", "'Integer, resize images shorter side to this size'", ",", "default", "=", "None", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "help", "=", "'Integer, crop this sized square from the images'", ",", "default", "=", "224", ")", "\n", "imgfeats_p", ".", "add_argument", "(", "'--tencrop'", ",", "action", "=", "'store_true'", ",", "help", "=", "'If given, average over 10 crop features.'", ")", "\n", "\n", "synth_p", "=", "commands", ".", "add_parser", "(", "\"synth\"", ")", "\n", "synth_p", ".", "set_defaults", "(", "func", "=", "synth", ")", "\n", "synth_p", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'flickr8k'", ",", "help", "=", "'Dataset'", ")", "\n", "synth_p", ".", "add_argument", "(", "'path'", ",", "help", "=", "'Destination directory'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "func", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.synth": [[50, 57], ["[].strip", "open", "open", "f.write", "preprocess.synthesize", "line.split", "preprocess.encode"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.synthesize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.encode"], ["", "def", "synth", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "!=", "\"flickr8k\"", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "sentences", "=", "\"data/flickr8k/Flickr8k.token.txt\"", "\n", "for", "sent", "in", "(", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "sentences", ")", ")", ":", "\n", "        ", "with", "open", "(", "\"{}/{}.wav\"", ".", "format", "(", "args", ".", "path", ",", "encode", "(", "sent", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "synthesize", "(", "sent", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.encode": [[58, 60], ["hashlib.md5().hexdigest", "hashlib.md5", "s.encode"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.encode"], ["", "", "", "def", "encode", "(", "s", ")", ":", "\n", "    ", "return", "hashlib", ".", "md5", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.decodemp3": [[61, 66], ["pydub.AudioSegment.from_mp3", "io.BytesIO", "pydub.AudioSegment.from_mp3.export", "io.BytesIO.getvalue", "io.BytesIO"], "function", ["None"], ["", "def", "decodemp3", "(", "s", ")", ":", "\n", "    ", "seg", "=", "pydub", ".", "AudioSegment", ".", "from_mp3", "(", "io", ".", "BytesIO", "(", "s", ")", ")", "\n", "buf", "=", "io", ".", "BytesIO", "(", ")", "\n", "seg", ".", "export", "(", "buf", ",", "format", "=", "'wav'", ")", "\n", "return", "buf", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.speak": [[67, 71], ["io.BytesIO", "gtts.gTTS().write_to_fp", "io.BytesIO.getvalue", "gtts.gTTS"], "function", ["None"], ["", "def", "speak", "(", "words", ")", ":", "\n", "    ", "f", "=", "io", ".", "BytesIO", "(", ")", "\n", "gtts", ".", "gTTS", "(", "text", "=", "words", ",", "lang", "=", "'en-us'", ")", ".", "write_to_fp", "(", "f", ")", "\n", "return", "f", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.synthesize": [[72, 83], ["logging.info", "preprocess.decodemp3", "preprocess.speak", "RuntimeError", "logging.info", "time.sleep", "preprocess.synthesize"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.decodemp3", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.speak", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.synthesize"], ["", "def", "synthesize", "(", "text", ",", "trial", "=", "1", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Synthesizing {}\"", ".", "format", "(", "text", ")", ")", "\n", "try", ":", "\n", "        ", "return", "decodemp3", "(", "speak", "(", "text", ")", ")", "\n", "", "except", "requests", ".", "exceptions", ".", "HTTPError", ":", "\n", "        ", "if", "trial", ">", "10", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"HTTPError: giving up after 10 trials\"", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"HTTPError on trial {}, waiting for 5 sec\"", ".", "format", "(", "trial", ")", ")", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "return", "synthesize", "(", "text", ",", "trial", "=", "trial", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.merge": [[87, 94], ["vg.util.parse_map", "open", "h5py.File", "zip", "range", "numpy.load", "vg.util.parse_map.keys", "f.create_dataset"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["", "", "", "def", "merge", "(", "args", ")", ":", "\n", "    ", "root", "=", "\"/exp/gchrupal/corpora/placesaudio_distro_part_1\"", "\n", "data", "=", "(", "arr", "for", "i", "in", "range", "(", "230", ")", "for", "arr", "in", "np", ".", "load", "(", "\"{}.{}.npy\"", ".", "format", "(", "args", ".", "prefix", ",", "i", ")", ")", ")", "\n", "M", "=", "parse_map", "(", "open", "(", "root", "+", "\"/\"", "+", "\"metadata/utt2wav\"", ")", ")", "\n", "with", "h5py", ".", "File", "(", "args", ".", "output", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "key", ",", "arr", "in", "zip", "(", "M", ".", "keys", "(", ")", ",", "data", ")", ":", "\n", "            ", "f", ".", "create_dataset", "(", "key", ",", "data", "=", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.mfcc_h5": [[97, 108], ["h5py.File", "vg.util.parse_map", "vg.util.parse_map.items", "open", "preprocess.extract_mfcc", "f.create_dataset"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.mfcc.extract_mfcc"], ["", "", "", "def", "mfcc_h5", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "!=", "'places'", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "with", "h5py", ".", "File", "(", "args", ".", "output", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "root", "=", "\"/exp/gchrupal/corpora/placesaudio_distro_part_1\"", "\n", "M", "=", "parse_map", "(", "open", "(", "root", "+", "\"/\"", "+", "\"metadata/utt2wav\"", ")", ")", "\n", "for", "key", ",", "wav", "in", "M", ".", "items", "(", ")", ":", "\n", "            ", "path", "=", "root", "+", "\"/\"", "+", "wav", "\n", "arr", "=", "extract_mfcc", "(", "path", ")", "\n", "if", "arr", "is", "not", "None", ":", "\n", "                ", "f", ".", "create_dataset", "(", "key", ",", "data", "=", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.mfcc": [[110, 194], ["parse.items", "numpy.save", "vg.util.parse_map", "open", "preprocess.mfcc.parse"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map"], ["", "", "", "", "def", "mfcc", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "'places'", ":", "\n", "        ", "root", "=", "\"/exp/gchrupal/corpora/placesaudio_distro_part_1\"", "\n", "M", "=", "parse_map", "(", "open", "(", "root", "+", "\"/metadata/utt2wav\"", ")", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'flickr8k'", ":", "\n", "        ", "def", "parse", "(", "lines", ")", ":", "\n", "            ", "M", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "wav", ",", "jpg", ",", "no", "=", "line", ".", "split", "(", ")", "\n", "M", "[", "wav", "]", "=", "\"wavs/\"", "+", "wav", "\n", "", "return", "M", "\n", "", "root", "=", "\"/exp/gchrupal/corpora/flickr_audio/\"", "\n", "M", "=", "parse", "(", "open", "(", "root", "+", "\"/wav2capt.txt\"", ")", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'flickr8k_synth'", ":", "\n", "        ", "logging", ".", "info", "(", "\"Synthetic flickr8k dataset\"", ")", "\n", "def", "parse", "(", "lines", ")", ":", "\n", "            ", "M", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "key", ",", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "M", "[", "key", "]", "=", "encode", "(", "text", ")", "+", "\".wav\"", "\n", "", "return", "M", "\n", "", "root", "=", "\"/home/gchrupal/vgs/data/flickr8k/synthetic/\"", "\n", "M", "=", "parse", "(", "open", "(", "\"/home/gchrupal/vgs/data/flickr8k/Flickr8k.token.txt\"", ")", ")", "\n", "", "elif", "args", ".", "dataset", "==", "\"semanticf8k\"", ":", "\n", "        ", "f8k_root", "=", "\"/exp/gchrupal/corpora/flickr_audio/wavs/\"", "\n", "feats", "=", "{", "}", "\n", "with", "open", "(", "\"/roaming/u1257964/semanticf8k/semantic_flickraudio_labels.csv\"", ")", "as", "csvfile", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "','", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "reader", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "cocoid", "=", "row", "[", "0", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "f8k_root", ",", "cocoid", "+", "\".wav\"", ")", "\n", "feats", "[", "path", "]", "=", "extract_mfcc", "(", "path", ")", "\n", "", "", "np", ".", "save", "(", "args", ".", "output", ",", "np", ".", "array", "(", "feats", ")", ")", "\n", "return", "\n", "# Produces .npy file, but also a .csv with meta-data", "\n", "", "elif", "args", ".", "dataset", "==", "\"librispeech\"", ":", "\n", "        ", "root", "=", "\"/roaming/u1257964/LibriSpeech/LibriSpeech/\"", "\n", "paths", "=", "os", ".", "walk", "(", "root", ",", "topdown", "=", "False", ")", "\n", "csv_file", "=", "open", "(", "args", ".", "output", "+", "\".csv\"", ",", "\"w\"", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "csv_writer", ".", "writerow", "(", "[", "\"PATH\"", ",", "\"SPEAKER\"", ",", "\"CHAPTER\"", ",", "\"TRANSCRIPT\"", "]", ")", "\n", "D", "=", "{", "}", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "paths", ")", ":", "\n", "            ", "print", "(", "\"Visiting diretory number {}\"", ".", "format", "(", "i", ")", ")", "\n", "# Only consider deepest directories and avoid root", "\n", "if", "p", "[", "2", "]", "and", "p", "[", "0", "]", "!=", "root", ":", "\n", "# Get the transcript", "\n", "                ", "txt", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "endswith", "(", "\".txt\"", ")", ",", "p", "[", "2", "]", ")", ")", "[", "0", "]", "\n", "trans", "=", "open", "(", "os", ".", "path", ".", "join", "(", "p", "[", "0", "]", ",", "txt", ")", ")", "\n", "# Take SPEAKER, CHAPTER and TRANSCRIPT info from the transcript file", "\n", "for", "line", "in", "trans", ":", "\n", "                    ", "l", "=", "line", ".", "split", "(", ")", "\n", "f", ",", "t", "=", "l", "[", "0", "]", "+", "\".flac\"", ",", "\" \"", ".", "join", "(", "l", "[", "1", ":", "]", ")", "\n", "person", ",", "chapter", ",", "_", "=", "f", ".", "split", "(", "\"-\"", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "p", "[", "0", "]", ",", "f", ")", "\n", "arr", "=", "extract_mfcc", "(", "path", ")", "\n", "if", "arr", "is", "not", "None", ":", "\n", "                        ", "D", "[", "f", "]", "=", "arr", "\n", "csv_writer", ".", "writerow", "(", "[", "path", ",", "person", ",", "chapter", ",", "t", "]", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"NO\"", ")", "\n", "", "", "trans", ".", "close", "(", ")", "\n", "", "if", "i", "%", "100", "==", "0", "and", "i", "!=", "0", ":", "\n", "                ", "print", "(", "\"Saving after {} samples\"", ".", "format", "(", "int", "(", "i", "/", "100", ")", ")", ")", "\n", "np", ".", "save", "(", "args", ".", "output", "+", "\"_\"", "+", "str", "(", "int", "(", "i", "/", "100", ")", ")", ",", "D", ")", "\n", "D", "=", "{", "}", "\n", "", "print", "(", "i", ")", "\n", "", "csv_file", ".", "close", "(", ")", "\n", "return", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "D", "=", "{", "}", "\n", "\n", "for", "key", ",", "wav", "in", "M", ".", "items", "(", ")", ":", "\n", "            ", "path", "=", "root", "+", "\"/\"", "+", "wav", "\n", "if", "args", ".", "dataset", "==", "'flickr8k_synth'", ":", "\n", "                ", "arr", "=", "extract_mfcc", "(", "path", ",", "nfft", "=", "1024", ")", "\n", "", "else", ":", "\n", "                ", "arr", "=", "extract_mfcc", "(", "path", ")", "\n", "", "if", "arr", "is", "not", "None", ":", "\n", "                ", "D", "[", "key", "]", "=", "arr", "\n", "", "", "np", ".", "save", "(", "args", ".", "output", ",", "D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.extract_mfcc": [[197, 213], ["timeout_decorator.timeout", "soundfile.read", "python_speech_features.mfcc", "numpy.asarray", "logging.warning", "logging.warning"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.mfcc"], ["@", "timeout_decorator", ".", "timeout", "(", "5", ")", "\n", "def", "extract_mfcc", "(", "f", ",", "truncate", "=", "20", ",", "nfft", "=", "512", ")", ":", "\n", "#logging.info(\"Extracting features from {}\".format(f))", "\n", "    ", "try", ":", "\n", "        ", "(", "sig", ",", "rate", ")", "=", "sf", ".", "read", "(", "f", ")", "\n", "max_len", "=", "truncate", "*", "rate", "\n", "", "except", ":", "\n", "        ", "logging", ".", "warning", "(", "\"Error reading file {}\"", ".", "format", "(", "f", ")", ")", "\n", "return", "None", "\n", "", "try", ":", "\n", "        ", "mfcc_feat", "=", "psf", ".", "mfcc", "(", "sig", "[", ":", "max_len", "]", ",", "samplerate", "=", "rate", ",", "nfft", "=", "nfft", ")", "\n", "return", "np", ".", "asarray", "(", "mfcc_feat", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "", "except", ":", "\n", "        ", "logging", ".", "warning", "(", "\"Error extracting features from file {}\"", ".", "format", "(", "f", ")", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.get_imgs": [[215, 225], ["ValueError", "open", "line.split"], "function", ["None"], ["", "", "def", "get_imgs", "(", "dataset", ")", ":", "\n", "    ", "if", "dataset", "==", "\"places\"", ":", "\n", "        ", "root", "=", "\"/exp/gchrupal/corpora/placesaudio_distro_part_1\"", "\n", "img_root", "=", "\"/roaming/u1257964/Places205/data/vision/torralba/deeplearning/images256\"", "\n", "names", "=", "[", "img_root", "+", "\"/\"", "+", "line", ".", "split", "(", ")", "[", "1", "]", "for", "line", "in", "open", "(", "root", "+", "\"/\"", "+", "\"metadata/utt2image\"", ")", "]", "\n", "return", "names", "\n", "", "elif", "dataset", "==", "\"flickr8k\"", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown dataset {}\"", ".", "format", "(", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.run_img_feats": [[226, 231], ["preprocess.get_imgs", "img_features", "numpy.save"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.get_imgs", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save"], ["", "", "def", "run_img_feats", "(", "args", ")", ":", "\n", "    ", "from", "extract_img_feats", "import", "img_features", "\n", "paths", "=", "get_imgs", "(", "args", ".", "dataset", ")", "\n", "feats", "=", "img_features", "(", "paths", ",", "args", ".", "cnn", ",", "args", ".", "resize", ",", "args", ".", "crop_size", ",", "args", ".", "tencrop", ")", "\n", "np", ".", "save", "(", "args", ".", "output", ",", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.orthogonal": [[4, 12], ["numpy.random.normal().astype", "numpy.linalg.svd", "q.reshape.reshape", "torch.from_numpy", "numpy.prod", "numpy.random.normal"], "function", ["None"], ["def", "orthogonal", "(", "shape", ",", "scale", "=", "1.1", ")", ":", "\n", "    ", "\"\"\" benanne lasagne ortho init (faster than qr approach)\"\"\"", "\n", "flat_shape", "=", "(", "shape", "[", "0", "]", ",", "np", ".", "prod", "(", "shape", "[", "1", ":", "]", ")", ")", "\n", "a", "=", "np", ".", "random", ".", "normal", "(", "0.0", ",", "1.0", ",", "flat_shape", ")", ".", "astype", "(", "'float32'", ")", "\n", "u", ",", "_", ",", "v", "=", "np", ".", "linalg", ".", "svd", "(", "a", ",", "full_matrices", "=", "False", ")", "\n", "q", "=", "u", "if", "u", ".", "shape", "==", "flat_shape", "else", "v", "# pick the one with the correct shape", "\n", "q", "=", "q", ".", "reshape", "(", "shape", ")", "\n", "return", "torch", ".", "from_numpy", "(", "scale", "*", "q", "[", ":", "shape", "[", "0", "]", ",", ":", "shape", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.glorot_uniform": [[13, 17], ["init.get_fans", "numpy.sqrt", "init.uniform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.get_fans", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.uniform"], ["", "def", "glorot_uniform", "(", "shape", ")", ":", "\n", "    ", "fan_in", ",", "fan_out", "=", "get_fans", "(", "shape", ")", "\n", "s", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "fan_in", "+", "fan_out", ")", ")", "\n", "return", "uniform", "(", "shape", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.xavier": [[18, 23], ["torch.from_numpy", "numpy.sqrt", "numpy.sqrt", "numpy.random.rand().astype", "numpy.random.rand"], "function", ["None"], ["", "def", "xavier", "(", "shape", ")", ":", "\n", "    ", "nin", ",", "nout", "=", "shape", "\n", "r", "=", "np", ".", "sqrt", "(", "6.", ")", "/", "np", ".", "sqrt", "(", "nin", "+", "nout", ")", "\n", "W", "=", "np", ".", "random", ".", "rand", "(", "nin", ",", "nout", ")", ".", "astype", "(", "'float32'", ")", "*", "2", "*", "r", "-", "r", "\n", "return", "torch", ".", "from_numpy", "(", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.get_fans": [[25, 40], ["len", "numpy.prod", "numpy.sqrt", "numpy.sqrt", "len", "len", "numpy.prod", "numpy.prod"], "function", ["None"], ["", "def", "get_fans", "(", "shape", ")", ":", "\n", "    ", "if", "len", "(", "shape", ")", "==", "2", ":", "\n", "        ", "fan_in", "=", "shape", "[", "0", "]", "\n", "fan_out", "=", "shape", "[", "1", "]", "\n", "", "elif", "len", "(", "shape", ")", "==", "4", "or", "len", "(", "shape", ")", "==", "5", ":", "\n", "# assuming convolution kernels (2D or 3D).", "\n", "# TH kernel shape: (depth, input_depth, ...)", "\n", "        ", "receptive_field_size", "=", "np", ".", "prod", "(", "shape", "[", "2", ":", "]", ")", "\n", "fan_in", "=", "shape", "[", "1", "]", "*", "receptive_field_size", "\n", "fan_out", "=", "shape", "[", "0", "]", "*", "receptive_field_size", "\n", "", "else", ":", "\n", "# no specific assumptions", "\n", "        ", "fan_in", "=", "np", ".", "sqrt", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "fan_out", "=", "np", ".", "sqrt", "(", "np", ".", "prod", "(", "shape", ")", ")", "\n", "", "return", "fan_in", ",", "fan_out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.uniform": [[41, 43], ["torch.from_numpy", "numpy.random.uniform().astype", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.uniform"], ["", "def", "uniform", "(", "shape", ",", "scale", "=", "0.05", ")", ":", "\n", "    ", "return", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "scale", ",", "high", "=", "scale", ",", "size", "=", "shape", ")", ".", "astype", "(", "'float32'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.__init__": [[10, 22], ["torch.Module.__init__", "onion.autoassign", "torch.GRU", "torch.GRU", "torch.GRU", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "locals", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GRU", "torch.GRU", "torch.GRU", "stacked_gru.StackedGRU.layers.append"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_layers", ",", "residual", "=", "False", ",", "bidirectional", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_layers", ">", "0", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "bottom", "=", "nn", ".", "GRU", "(", "input_size", ",", "hidden_size", ",", "1", ",", "bidirectional", "=", "bidirectional", ",", "**", "kwargs", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "downscale", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_layers", "-", "1", ")", ":", "\n", "            ", "layer", "=", "nn", ".", "GRU", "(", "hidden_size", ",", "hidden_size", ",", "1", ",", "bidirectional", "=", "self", ".", "bidirectional", ",", "**", "kwargs", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.forward": [[23, 30], ["stacked_gru.StackedGRU.bottom", "stacked_gru.StackedGRU.proj", "range", "stacked_gru.StackedGRU.Residual"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.proj", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.Residual"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "h0", ")", ":", "\n", "        ", "j", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "out", ",", "_", "=", "self", ".", "bottom", "(", "x", ",", "h0", "[", "0", ":", "1", ",", ":", ",", ":", "]", ")", "\n", "out", "=", "self", ".", "proj", "(", "out", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", ":", "\n", "            ", "out", "=", "self", ".", "Residual", "(", "self", ".", "layers", "[", "i", "]", ",", "out", ",", "h0", "[", "i", "+", "1", ":", "i", "+", "2", ",", ":", ",", ":", "]", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.proj": [[31, 36], ["stacked_gru.StackedGRU.downscale"], "methods", ["None"], ["", "def", "proj", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "return", "self", ".", "downscale", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.Residual": [[38, 49], ["f", "stacked_gru.StackedGRU.proj"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.proj"], ["", "", "def", "Residual", "(", "self", ",", "f", ",", "x", ",", "*", "args", ")", ":", "\n", "        ", "fx", ",", "_", "=", "f", "(", "x", ",", "*", "args", ")", "\n", "#print(f)", "\n", "#print(\" x:\", x.size())", "\n", "#print(\"fx:\", fx.size())", "\n", "px", "=", "self", ".", "proj", "(", "fx", ")", "\n", "#print(\"px:\", px.size())", "\n", "if", "self", ".", "residual", ":", "\n", "            ", "return", "x", "+", "px", "\n", "", "else", ":", "\n", "            ", "return", "px", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.forward": [[7, 10], ["x.contiguous().view_as", "x.contiguous"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "contiguous", "(", ")", ".", "view_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward": [[11, 14], ["grad_output.neg"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "return", "grad_output", ".", "neg", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.grad_reverse": [[16, 21], ["GradReverse.apply"], "function", ["None"], ["", "", "def", "grad_reverse", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    GRL must be placed between the feature extractor and the domain classifier\n    \"\"\"", "\n", "return", "GradReverse", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.conv.Convolution1D.__init__": [[8, 15], ["torch.Module.__init__", "onion.autoassign", "onion.autoassign", "torch.Conv1d", "onion.glorot_uniform().squeeze", "onion.glorot_uniform().squeeze", "locals", "onion.glorot_uniform", "onion.glorot_uniform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.glorot_uniform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.glorot_uniform"], ["def", "__init__", "(", "self", ",", "size_in", ",", "length", ",", "size", ",", "stride", "=", "1", ",", "padding", "=", "None", ")", ":", "\n", "        ", "super", "(", "Convolution1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "padding", "=", "padding", "if", "padding", "is", "not", "None", "else", "self", ".", "length", "\n", "self", ".", "Conv", "=", "nn", ".", "Conv1d", "(", "self", ".", "size_in", ",", "self", ".", "size", ",", "self", ".", "length", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "# use Glorot uniform initialization", "\n", "self", ".", "Conv", ".", "weight", ".", "data", "=", "init", ".", "glorot_uniform", "(", "(", "self", ".", "size", ",", "self", ".", "size_in", ",", "self", ".", "length", ",", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "#FIXME what is the correct padding???", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.conv.Convolution1D.forward": [[17, 21], ["conv.Convolution1D.Conv", "conv.Convolution1D.permute", "signal.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "signal", ")", ":", "\n", "# signal's shape is (B, T, C) where B=batch size, T=timesteps, C=channels", "\n", "        ", "out", "=", "self", ".", "Conv", "(", "signal", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "return", "out", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.conv.ConvTranspose1D.__init__": [[26, 33], ["torch.Module.__init__", "onion.autoassign", "onion.autoassign", "torch.ConvTranspose1d", "onion.glorot_uniform().squeeze", "onion.glorot_uniform().squeeze", "locals", "onion.glorot_uniform", "onion.glorot_uniform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.glorot_uniform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.glorot_uniform"], ["def", "__init__", "(", "self", ",", "size_in", ",", "length", ",", "size", ",", "stride", "=", "1", ",", "padding", "=", "None", ")", ":", "\n", "        ", "super", "(", "ConvTranspose1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "padding", "=", "padding", "if", "padding", "is", "not", "None", "else", "self", ".", "length", "\n", "self", ".", "ConvT", "=", "nn", ".", "ConvTranspose1d", "(", "self", ".", "size_in", ",", "self", ".", "size", ",", "self", ".", "length", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "# use Glorot uniform initialization", "\n", "self", ".", "ConvT", ".", "weight", ".", "data", "=", "init", ".", "glorot_uniform", "(", "(", "self", ".", "size", ",", "self", ".", "size_in", ",", "self", ".", "length", ",", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "#FIXME what is the correct padding???", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.conv.ConvTranspose1D.forward": [[35, 39], ["conv.ConvTranspose1D.ConvT", "conv.ConvTranspose1D.permute", "signal.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "signal", ")", ":", "\n", "# signal's shape is (B, T, C) where B=batch size, T=timesteps, C=channels", "\n", "        ", "out", "=", "self", ".", "ConvT", "(", "signal", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "return", "out", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive": [[4, 12], ["torch.diag", "torch.diag", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.diag.view", "C.sum", "torch.diag().sum", "torch.diag().sum", "C.size", "torch.diag", "torch.diag"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["def", "contrastive", "(", "M", ",", "margin", "=", "0.2", ")", ":", "\n", "     ", "\"Returns contrastive margin loss over similarity matrix M.\"", "\n", "E", "=", "-", "M", "\n", "D", "=", "torch", ".", "diag", "(", "E", ")", "\n", "C_c", "=", "torch", ".", "clamp", "(", "margin", "-", "E", "+", "D", ",", "min", "=", "0", ")", "\n", "C_r", "=", "torch", ".", "clamp", "(", "margin", "-", "E", "+", "D", ".", "view", "(", "-", "1", ",", "1", ")", ",", "min", "=", "0", ")", "\n", "C", "=", "C_c", "+", "C_r", "\n", "return", "(", "C", ".", "sum", "(", ")", "-", "torch", ".", "diag", "(", "C", ")", ".", "sum", "(", ")", ")", "/", "C", ".", "size", "(", "0", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.rsa": [[13, 18], ["loss.cosine_matrix", "loss.cosine_matrix", "loss.pearson", "loss.triu", "loss.triu"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.pearson", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "rsa", "(", "A", ",", "B", ")", ":", "\n", "    ", "\"Returns the correlation between the similarity matrices for A and B.\"", "\n", "M_A", "=", "cosine_matrix", "(", "A", ",", "A", ")", "\n", "M_B", "=", "cosine_matrix", "(", "B", ",", "B", ")", "\n", "return", "pearson", "(", "triu", "(", "M_A", ")", ",", "triu", "(", "M_B", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix": [[19, 24], ["torch.matmul", "torch.matmul", "U.norm", "V.norm", "V_norm.t"], "function", ["None"], ["", "def", "cosine_matrix", "(", "U", ",", "V", ")", ":", "\n", "    ", "\"Returns the matrix of cosine similarity between each row of U and each row of V.\"", "\n", "U_norm", "=", "U", "/", "U", ".", "norm", "(", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "V_norm", "=", "V", "/", "V", ".", "norm", "(", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "torch", ".", "matmul", "(", "U_norm", ",", "V_norm", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.pearson": [[26, 34], ["torch.sum", "torch.sum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "pearson", "(", "x", ",", "y", ",", "dim", "=", "1", ",", "eps", "=", "1e-8", ")", ":", "\n", "    ", "\"Returns Pearson's correlation coefficient.\"", "\n", "x1", "=", "x", "-", "torch", ".", "mean", "(", "x", ",", "dim", ")", "\n", "x2", "=", "y", "-", "torch", ".", "mean", "(", "y", ",", "dim", ")", "\n", "w12", "=", "torch", ".", "sum", "(", "x1", "*", "x2", ",", "dim", ")", "\n", "w1", "=", "torch", ".", "norm", "(", "x1", ",", "2", ",", "dim", ")", "\n", "w2", "=", "torch", ".", "norm", "(", "x2", ",", "2", ",", "dim", ")", "\n", "return", "w12", "/", "(", "w1", "*", "w2", ")", ".", "clamp", "(", "min", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.triu": [[35, 39], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.ones_like", "torch.ones_like", "torch.triu", "torch.triu"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "triu", "(", "x", ")", ":", "\n", "    ", "\"Extracts upper triangular part of a matrix, excluding the diagonal.\"", "\n", "ones", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones_like", "(", "x", ".", "data", ")", ")", "\n", "return", "x", "[", "torch", ".", "triu", "(", "ones", ",", "diagonal", "=", "1", ")", "==", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.mlp.MLP.__init__": [[7, 15], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "zip", "mlp.MLP.layers.append", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sizes", ",", "activation", "=", "F", ".", "tanh", ")", ":", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "\n", "for", "size_in", ",", "size_out", "in", "zip", "(", "sizes", "[", ":", "-", "1", "]", ",", "sizes", "[", "1", ":", "]", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "size_in", ",", "size_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.mlp.MLP.forward": [[16, 20], ["range", "mlp.MLP.activation", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "layers", ")", "-", "1", ")", ":", "\n", "            ", "X", "=", "self", ".", "activation", "(", "self", ".", "layers", "[", "i", "]", "(", "X", ")", ")", "\n", "", "return", "self", ".", "layers", "[", "-", "1", "]", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.attention.SelfAttention.__init__": [[8, 13], ["torch.Module.__init__", "onion.autoassign", "onion.make_linear", "onion.make_linear", "locals"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.make_linear", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.make_linear"], ["def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "activation", "=", "F", ".", "tanh", ")", ":", "\n", "        ", "super", "(", "SelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "Regress1", "=", "util", ".", "make_linear", "(", "self", ".", "size_in", ",", "self", ".", "size", ")", "\n", "self", ".", "Regress2", "=", "util", ".", "make_linear", "(", "self", ".", "size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.attention.SelfAttention.forward": [[14, 17], ["attention.softmax_time", "attention.SelfAttention.Regress2", "attention.SelfAttention.activation", "attention.SelfAttention.Regress1", "softmax_time.expand_as"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.attention.softmax_time"], ["", "def", "forward", "(", "self", ",", "h", ")", ":", "\n", "        ", "alpha", "=", "softmax_time", "(", "self", ".", "Regress2", "(", "self", ".", "activation", "(", "self", ".", "Regress1", "(", "h", ")", ")", ")", ")", "\n", "return", "(", "alpha", ".", "expand_as", "(", "h", ")", "*", "h", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.attention.softmax_time": [[19, 22], ["torch.softmax"], "function", ["None"], ["", "", "def", "softmax_time", "(", "x", ")", ":", "\n", "    ", "\"\"\"Input has shape Batch x Time x 1. Return softmax over dimension Time.\"\"\"", "\n", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign": [[6, 11], ["locs.keys"], "function", ["None"], ["def", "autoassign", "(", "locs", ")", ":", "\n", "    ", "\"\"\"Assign locals to self.\"\"\"", "\n", "for", "key", "in", "locs", ".", "keys", "(", ")", ":", "\n", "        ", "if", "key", "!=", "\"self\"", ":", "\n", "            ", "locs", "[", "\"self\"", "]", ".", "__dict__", "[", "key", "]", "=", "locs", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper": [[12, 19], ["itertools.zip_longest", "iter"], "function", ["None"], ["", "", "", "def", "grouper", "(", "iterable", ",", "n", ")", ":", "\n", "        ", "\"Collect data into fixed-length chunks or blocks\"", "\n", "# grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx", "\n", "args", "=", "[", "iter", "(", "iterable", ")", "]", "*", "n", "\n", "chunks", "=", "itertools", ".", "zip_longest", "(", "fillvalue", "=", "None", ",", "*", "args", ")", "\n", "for", "chunk", "in", "chunks", ":", "\n", "            ", "yield", "[", "x", "for", "x", "in", "chunk", "if", "not", "x", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.make_linear": [[20, 26], ["torch.Linear", "onion.orthogonal", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.orthogonal"], ["", "", "def", "make_linear", "(", "size_in", ",", "size_out", ")", ":", "\n", "    ", "\"\"\"Returns linear layer with orthogonal initialization.\"\"\"", "\n", "M", "=", "nn", ".", "Linear", "(", "size_in", ",", "size_out", ")", "\n", "M", ".", "weight", ".", "data", "=", "init", ".", "orthogonal", "(", "(", "size_out", ",", "size_in", ")", ")", "\n", "M", ".", "bias", ".", "data", "=", "torch", ".", "zeros", "(", "size_out", ")", "\n", "return", "M", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Linear.__init__": [[13, 19], ["torch.Module.__init__", "onion.autoassign", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "locals", "rhn.Linear.make_param", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "rhn.Linear.make_param"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Linear.make_param", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Linear.make_param"], ["    ", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "bias_init", "=", "None", ",", "init_scale", "=", "0.04", ")", ":", "\n", "        ", "super", "(", "Linear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "w", "=", "torch", ".", "nn", ".", "Parameter", "(", "self", ".", "make_param", "(", "(", "self", ".", "in_size", ",", "self", ".", "out_size", ")", ",", "'uniform'", ")", ")", "\n", "if", "bias_init", "is", "not", "None", ":", "\n", "            ", "self", ".", "b", "=", "torch", ".", "nn", ".", "Parameter", "(", "self", ".", "make_param", "(", "(", "self", ".", "out_size", ",", ")", ",", "self", ".", "bias_init", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Linear.make_param": [[20, 32], ["isinstance", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.full", "numpy.random.uniform().astype", "AssertionError", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.init.uniform"], ["", "", "def", "make_param", "(", "self", ",", "shape", ",", "init_scheme", ")", ":", "\n", "        ", "\"\"\"Create variables which are used as trainable model parameters.\"\"\"", "\n", "if", "isinstance", "(", "init_scheme", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "init_value", "=", "np", ".", "full", "(", "shape", ",", "init_scheme", ",", "floatX", ")", "\n", "", "elif", "init_scheme", "==", "'uniform'", ":", "\n", "#init_value = self._np_rng.uniform(low=-self.init_scale, high=self.init_scale, size=shape).astype(floatX) # FIXME", "\n", "            ", "init_value", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "self", ".", "init_scale", ",", "high", "=", "self", ".", "init_scale", ",", "size", "=", "shape", ")", ".", "astype", "(", "floatX", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "'unsupported init_scheme'", ")", "\n", "", "p", "=", "torch", ".", "from_numpy", "(", "init_value", ")", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Linear.forward": [[33, 38], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "bias_init", "is", "not", "None", ":", "\n", "            ", "return", "torch", ".", "matmul", "(", "x", ",", "self", ".", "w", ")", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "matmul", "(", "x", ",", "self", ".", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.__init__": [[45, 61], ["torch.Module.__init__", "onion.autoassign", "rhn.Linear", "rhn.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "locals", "rhn.RHN.recurH.append", "rhn.RHN.recurT.append", "rhn.RHN.recurH.append", "rhn.RHN.recurT.append", "rhn.Linear", "rhn.Linear", "rhn.Linear", "rhn.Linear"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "recur_depth", "=", "1", ",", "drop_i", "=", "0.75", ",", "drop_s", "=", "0.25", ",", "\n", "init_T_bias", "=", "-", "2.0", ",", "init_H_bias", "=", "'uniform'", ",", "tied_noise", "=", "True", ",", "init_scale", "=", "0.04", ",", "seed", "=", "1", ")", ":", "\n", "        ", "super", "(", "RHN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "hidden_size", "=", "self", ".", "size", "\n", "self", ".", "LinearH", "=", "Linear", "(", "in_size", "=", "self", ".", "size_in", ",", "out_size", "=", "hidden_size", ",", "bias_init", "=", "self", ".", "init_H_bias", ")", "\n", "self", ".", "LinearT", "=", "Linear", "(", "in_size", "=", "self", ".", "size_in", ",", "out_size", "=", "hidden_size", ",", "bias_init", "=", "self", ".", "init_T_bias", ")", "\n", "self", ".", "recurH", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "recurT", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "recur_depth", ")", ":", "\n", "            ", "if", "l", "==", "0", ":", "\n", "                ", "self", ".", "recurH", ".", "append", "(", "Linear", "(", "in_size", "=", "hidden_size", ",", "out_size", "=", "hidden_size", ")", ")", "\n", "self", ".", "recurT", ".", "append", "(", "Linear", "(", "in_size", "=", "hidden_size", ",", "out_size", "=", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "recurH", ".", "append", "(", "Linear", "(", "in_size", "=", "hidden_size", ",", "out_size", "=", "hidden_size", ",", "bias_init", "=", "self", ".", "init_H_bias", ")", ")", "\n", "self", ".", "recurT", ".", "append", "(", "Linear", "(", "in_size", "=", "hidden_size", ",", "out_size", "=", "hidden_size", ",", "bias_init", "=", "self", ".", "init_T_bias", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.apply_dropout": [[62, 67], ["None"], "methods", ["None"], ["", "", "", "def", "apply_dropout", "(", "self", ",", "x", ",", "noise", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "noise", "*", "x", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.get_dropout_noise": [[68, 75], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "noise.cuda.cuda.cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "def", "get_dropout_noise", "(", "self", ",", "shape", ",", "dropout_p", ")", ":", "\n", "        ", "keep_p", "=", "1", "-", "dropout_p", "\n", "noise", "=", "(", "1.", "/", "keep_p", ")", "*", "torch", ".", "bernoulli", "(", "torch", ".", "zeros", "(", "shape", ")", "+", "keep_p", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "noise", "=", "noise", ".", "cuda", "(", ")", "\n", "", "noise", "=", "torch", ".", "autograd", ".", "Variable", "(", "noise", ")", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.make_noise": [[76, 84], ["inputs.data.new().resize_", "torch.autograd.Variable.bernoulli_", "torch.autograd.Variable.bernoulli_", "torch.autograd.Variable.bernoulli_", "torch.autograd.Variable.mul_", "torch.autograd.Variable.mul_", "torch.autograd.Variable.mul_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "inputs.data.new"], "methods", ["None"], ["", "def", "make_noise", "(", "self", ",", "inputs", ",", "shape", ",", "dropout_p", ")", ":", "\n", "        ", "keep_p", "=", "1", "-", "dropout_p", "\n", "#noise = (1. / keep_p) * torch.bernoulli(torch.zeros(shape) + keep_p)", "\n", "noise", "=", "inputs", ".", "data", ".", "new", "(", ")", ".", "resize_", "(", "shape", ")", "\n", "noise", ".", "bernoulli_", "(", "keep_p", ")", "\n", "noise", ".", "mul_", "(", "1.", "/", "keep_p", ")", "\n", "noise", "=", "torch", ".", "autograd", ".", "Variable", "(", "noise", ")", "\n", "return", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.step": [[85, 108], ["range", "rhn.RHN.apply_dropout", "rhn.RHN.apply_dropout", "tanh", "sigm", "tanh", "sigm"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.apply_dropout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.apply_dropout"], ["", "def", "step", "(", "self", ",", "i_for_H_t", ",", "i_for_T_t", ",", "h_tm1", ",", "noise_s", ")", ":", "\n", "        ", "tanh", ",", "sigm", "=", "F", ".", "tanh", ",", "F", ".", "sigmoid", "\n", "noise_s_for_H", "=", "noise_s", "if", "self", ".", "tied_noise", "else", "noise_s", "[", "0", "]", "\n", "noise_s_for_T", "=", "noise_s", "if", "self", ".", "tied_noise", "else", "noise_s", "[", "1", "]", "\n", "\n", "hidden_size", "=", "self", ".", "size", "\n", "s_lm1", "=", "h_tm1", "\n", "for", "l", "in", "range", "(", "self", ".", "recur_depth", ")", ":", "\n", "            ", "s_lm1_for_H", "=", "self", ".", "apply_dropout", "(", "s_lm1", ",", "noise_s_for_H", ")", "\n", "s_lm1_for_T", "=", "self", ".", "apply_dropout", "(", "s_lm1", ",", "noise_s_for_T", ")", "\n", "if", "l", "==", "0", ":", "\n", "# On the first micro-timestep of each timestep we already have bias", "\n", "# terms summed into i_for_H_t and into i_for_T_t.", "\n", "                ", "H", "=", "tanh", "(", "i_for_H_t", "+", "self", ".", "recurH", "[", "l", "]", "(", "s_lm1_for_H", ")", ")", "\n", "T", "=", "sigm", "(", "i_for_T_t", "+", "self", ".", "recurT", "[", "l", "]", "(", "s_lm1_for_T", ")", ")", "\n", "", "else", ":", "\n", "                ", "H", "=", "tanh", "(", "self", ".", "recurH", "[", "l", "]", "(", "s_lm1_for_H", ")", ")", "\n", "T", "=", "sigm", "(", "self", ".", "recurT", "[", "l", "]", "(", "s_lm1_for_T", ")", ")", "\n", "", "s_l", "=", "(", "H", "-", "s_lm1", ")", "*", "T", "+", "s_lm1", "\n", "s_lm1", "=", "s_l", "\n", "\n", "", "y_t", "=", "s_l", "\n", "return", "y_t", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.forward": [[109, 145], ["seq.permute", "seq.permute.size", "rhn.RHN.get_dropout_noise", "rhn.RHN.apply_dropout", "rhn.RHN.apply_dropout", "rhn.RHN.LinearH", "rhn.RHN.LinearT", "rhn.RHN.get_dropout_noise", "range", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "rhn.RHN.get_dropout_noise", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "h0.expand", "len", "out.append", "rhn.RHN.get_dropout_noise", "rhn.RHN.step", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.get_dropout_noise", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.apply_dropout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.apply_dropout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.get_dropout_noise", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.get_dropout_noise", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHN.get_dropout_noise", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.step"], ["", "def", "forward", "(", "self", ",", "h0", ",", "seq", ",", "repeat_h0", "=", "1", ")", ":", "\n", "#print(seq.size())", "\n", "        ", "inputs", "=", "seq", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "(", "_seq_size", ",", "batch_size", ",", "_", ")", "=", "inputs", ".", "size", "(", ")", "\n", "hidden_size", "=", "self", ".", "size", "\n", "# We first compute the linear transformation of the inputs over all timesteps.", "\n", "# This is done outside of scan() in order to speed up computation.", "\n", "# The result is then fed into scan()'s step function, one timestep at a time.", "\n", "noise_i_for_H", "=", "self", ".", "get_dropout_noise", "(", "(", "batch_size", ",", "self", ".", "size_in", ")", ",", "self", ".", "drop_i", ")", "\n", "noise_i_for_T", "=", "self", ".", "get_dropout_noise", "(", "(", "batch_size", ",", "self", ".", "size_in", ")", ",", "self", ".", "drop_i", ")", "if", "not", "self", ".", "tied_noise", "else", "noise_i_for_H", "\n", "#noise_i_for_H = self.make_noise(inputs, (batch_size, self.size_in), self.drop_i)", "\n", "#noise_i_for_T = self.make_noise(inputs, (batch_size, self.size_in), self.drop_i) if not self.tied_noise else noise_i_for_H", "\n", "\n", "\n", "i_for_H", "=", "self", ".", "apply_dropout", "(", "inputs", ",", "noise_i_for_H", ")", "\n", "i_for_T", "=", "self", ".", "apply_dropout", "(", "inputs", ",", "noise_i_for_T", ")", "\n", "\n", "i_for_H", "=", "self", ".", "LinearH", "(", "i_for_H", ")", "\n", "i_for_T", "=", "self", ".", "LinearT", "(", "i_for_T", ")", "\n", "\n", "\n", "# Dropout noise for recurrent hidden state.", "\n", "noise_s", "=", "self", ".", "get_dropout_noise", "(", "(", "batch_size", ",", "hidden_size", ")", ",", "self", ".", "drop_s", ")", "\n", "if", "not", "self", ".", "tied_noise", ":", "\n", "          ", "noise_s", "=", "torch", ".", "stack", "(", "noise_s", ",", "self", ".", "get_dropout_noise", "(", "(", "batch_size", ",", "hidden_size", ")", ",", "self", ".", "drop_s", ")", ")", "\n", "\n", "", "H0", "=", "h0", ".", "expand", "(", "(", "batch_size", ",", "self", ".", "size", ")", ")", "if", "repeat_h0", "else", "h0", "\n", "#out, _ = theano.scan(self.step,", "\n", "#                     sequences=[i_for_H, i_for_T],", "\n", "#                     outputs_info=[H0],", "\n", "#                     non_sequences = [noise_s])", "\n", "out", "=", "[", "]", "\n", "\n", "for", "t", "in", "range", "(", "len", "(", "i_for_H", ")", ")", ":", "\n", "            ", "out", ".", "append", "(", "self", ".", "step", "(", "i_for_H", "[", "t", "]", ",", "i_for_T", "[", "t", "]", ",", "H0", ",", "noise_s", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "out", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHNH0.__init__": [[148, 154], ["torch.Module.__init__", "onion.autoassign", "rhn.RHN", "locals", "rhn.FixedZeros", "rhn.Zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "fixed", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"An RHN layer with its own initial state.\"\"\"", "\n", "super", "(", "RHNH0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "FixedZeros", "(", "self", ".", "size", ")", "if", "self", ".", "fixed", "else", "Zeros", "(", "self", ".", "size", ")", "\n", "self", ".", "RHN", "=", "RHN", "(", "size_in", ",", "size", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.RHNH0.forward": [[155, 157], ["rhn.RHNH0.RHN", "rhn.RHNH0.h0"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "RHN", "(", "self", ".", "h0", "(", ")", ",", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.WithH0.__init__": [[159, 167], ["torch.Module.__init__", "rhn.FixedZeros", "rhn.Zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "RNN", ",", "fixed", "=", "False", ")", ":", "\n", "        ", "\"\"\"An recurrent layer with its own initial state.\"\"\"", "\n", "super", "(", "WithH0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "RNN", "=", "RNN", "\n", "if", "fixed", ":", "\n", "            ", "self", ".", "h0", "=", "FixedZeros", "(", "self", ".", "RNN", ".", "size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "h0", "=", "Zeros", "(", "self", ".", "RNN", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.WithH0.forward": [[168, 170], ["rhn.WithH0.RNN", "rhn.WithH0.h0"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "RNN", "(", "self", ".", "h0", "(", ")", ",", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Zeros.__init__": [[173, 177], ["torch.Module.__init__", "onion.autoassign", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "Zeros", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "zeros", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Zeros.forward": [[178, 180], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "zeros", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.FixedZeros.__init__": [[183, 189], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rhn.FixedZeros.zeros.cuda"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "FixedZeros", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "zeros", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "size", ")", ",", "requires_grad", "=", "True", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "zeros", "=", "self", ".", "zeros", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.FixedZeros.forward": [[190, 192], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "zeros", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Residual.__init__": [[195, 198], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["def", "__init__", "(", "self", ",", "layer", ")", ":", "\n", "        ", "super", "(", "Residual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "layer", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Residual.forward": [[199, 201], ["rhn.Residual.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "inp", "+", "self", ".", "layer", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Identity.__init__": [[204, 206], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Identity.forward": [[207, 209], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "inp", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Compose.__init__": [[212, 216], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "first", ",", "second", ")", ":", "\n", "        ", "super", "(", "Compose", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "first", "=", "first", "\n", "self", ".", "second", "=", "second", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Compose.forward": [[217, 219], ["rhn.Compose.first", "rhn.Compose.second"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "first", "(", "self", ".", "second", "(", "inp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.Compose.intermediate": [[220, 224], ["rhn.Compose.second", "rhn.Compose.first"], "methods", ["None"], ["", "def", "intermediate", "(", "self", ",", "inp", ")", ":", "\n", "        ", "x", "=", "self", ".", "second", "(", "inp", ")", "\n", "z", "=", "self", ".", "first", "(", "x", ")", "\n", "return", "(", "x", ",", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHN.__init__": [[226, 234], ["torch.Module.__init__", "onion.autoassign", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "rhn.RHN", "functools.reduce", "locals", "rhn.Identity", "rhn.Residual", "f", "rhn.Compose", "rhn.RHNH0", "range"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.stacked_gru.StackedGRU.Residual"], ["    ", "def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "depth", "=", "2", ",", "residual", "=", "False", ",", "fixed", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StackedRHN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "f", "=", "lambda", "x", ":", "Residual", "(", "x", ")", "if", "self", ".", "residual", "else", "x", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "f", "(", "RHNH0", "(", "self", ".", "size", ",", "self", ".", "size", ",", "fixed", "=", "self", ".", "fixed", ",", "**", "self", ".", "kwargs", ")", ")", "for", "_", "in", "range", "(", "1", ",", "self", ".", "depth", ")", "]", ")", "\n", "self", ".", "bottom", "=", "RHN", "(", "self", ".", "size_in", ",", "self", ".", "size", ",", "**", "self", ".", "kwargs", ")", "\n", "self", ".", "stack", "=", "reduce", "(", "lambda", "z", ",", "x", ":", "Compose", "(", "x", ",", "z", ")", ",", "self", ".", "layers", ",", "Identity", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHN.forward": [[235, 237], ["rhn.StackedRHN.stack", "rhn.StackedRHN.bottom"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h0", ",", "inp", ",", "repeat_h0", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "stack", "(", "self", ".", "bottom", "(", "h0", ",", "inp", ",", "repeat_h0", "=", "repeat_h0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHN.intermediate": [[238, 245], ["torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "rhn.StackedRHN.bottom", "layer", "zs.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "intermediate", "(", "self", ",", "h0", ",", "inp", ",", "repeat_h0", "=", "0", ")", ":", "\n", "        ", "zs", "=", "[", "self", ".", "bottom", "(", "h0", ",", "inp", ",", "repeat_h0", "=", "repeat_h0", ")", "]", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "z", "=", "layer", "(", "zs", "[", "-", "1", "]", ")", "\n", "zs", ".", "append", "(", "z", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "zs", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHNH0.__init__": [[249, 253], ["torch.Module.__init__", "onion.autoassign", "rhn.WithH0", "locals", "rhn.StackedRHN"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "depth", "=", "2", ",", "residual", "=", "False", ",", "fixed", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "StackedRHNH0", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "layer", "=", "WithH0", "(", "StackedRHN", "(", "size_in", ",", "size", ",", "depth", "=", "depth", ",", "residual", "=", "residual", ",", "**", "kwargs", ")", ",", "fixed", "=", "fixed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHNH0.forward": [[254, 256], ["rhn.StackedRHNH0.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "layer", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHNH0.intermediate": [[257, 259], ["rhn.StackedRHNH0.layer.intermediate", "rhn.StackedRHNH0.layer.h0"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.rhn.StackedRHNH0.intermediate"], ["", "def", "intermediate", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "layer", ".", "intermediate", "(", "self", ".", "layer", ".", "h0", "(", ")", ",", "inp", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-joint-g.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-joint-f.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-disjoint-e.run.audio": [[53, 55], ["None"], "function", ["None"], ["\n", "\n", "def", "audio", "(", "sent", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-joint-g.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-joint-f.run.audio": [[50, 52], ["None"], "function", ["None"], ["\n", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-disjoint-g.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-disjoint-f.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-disjoint-g.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t.-s2i2-s2t.-t2s.-t2i.--f.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-joint-e.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-joint-f.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t.-s2i2-s2t.-t2s.-t2i.--g.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-disjoint-g.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-joint-e.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-disjoint-f.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-joint-g.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-joint-g.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-joint-e.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-disjoint-e.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-disjoint-f.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-disjoint-e.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t1-t2s1-t2i1-joint-f.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-disjoint-g.run.audio": [[53, 55], ["None"], "function", ["None"], ["\n", "\n", "def", "audio", "(", "sent", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-joint-e.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-disjoint-g.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-joint-f.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t1-t2s1-t2i1-disjoint-f.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-disjoint-f.run.audio": [[53, 55], ["None"], "function", ["None"], ["\n", "\n", "def", "audio", "(", "sent", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i1-disjoint-e.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-joint-e.run.audio": [[50, 52], ["None"], "function", ["None"], ["\n", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t.-s2i2-s2t.-t2s.-t2i.--e.run.audio": [[55, 57], ["None"], "function", ["None"], ["def", "audio", "(", "sent", ")", ":", "\n", "    ", "return", "sent", "[", "'audio'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i1-s2t0-t2s0-t2i1-disjoint-e.run.audio": [[56, 58], ["None"], "function", ["None"], ["    ", "return", "sent", "[", "'audio'", "]", "\n", "\n", "", "net", "=", "D", ".", "Net", "(", "model_config", ")", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.s2-t1-s2i2-s2t0-t2s0-t2i.-joint-g.run.audio": [[50, 52], ["None"], "function", ["None"], ["\n", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.main": [[14, 33], ["print", "pandas.read_json", "print", "print", "pandas.read_json", "print", "print", "print", "print", "analyze.rsa_results", "print", "print", "analyze.phoneme_decoding_results", "print", "json.dumps", "json.dumps", "f[].to_latex", "json.dumps", "json.dumps", "f[].to_latex", "inv_results().to_latex", "phoneme_decoding_results.to_latex", "phoneme_decoding_results.to_latex", "analyze.valid_results", "analyze.test_results", "analyze.inv_results"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.rsa_results", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.phoneme_decoding_results", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.valid_results", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.test_results", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.inv_results"], ["def", "main", "(", "file", "=", "sys", ".", "stdout", ")", ":", "\n", "    ", "print", "(", "\"Table 1 \\label{tab:core-results}\"", ",", "file", "=", "file", ")", "\n", "f", "=", "pd", ".", "read_json", "(", "json", ".", "dumps", "(", "valid_results", "(", ")", ")", ")", "\n", "print", "(", "f", "[", "[", "'cond'", ",", "'tasks'", ",", "'s'", ",", "'t'", ",", "'s2i'", ",", "'s2t'", ",", "'t2s'", ",", "'t2i'", ",", "'recall@10'", ",", "'medr'", "]", "]", ".", "to_latex", "(", ")", ",", "file", "=", "file", ")", "\n", "\n", "print", "(", "\"Table 2 \\label{tab:core-results-test}\"", ",", "file", "=", "file", ")", "\n", "f", "=", "pd", ".", "read_json", "(", "json", ".", "dumps", "(", "test_results", "(", ")", ")", ")", "\n", "print", "(", "f", "[", "[", "'cond'", ",", "'tasks'", ",", "'s'", ",", "'t'", ",", "'s2i'", ",", "'s2t'", ",", "'t2s'", ",", "'t2i'", ",", "'recall@10'", ",", "'medr'", "]", "]", ".", "to_latex", "(", ")", ",", "file", "=", "file", ")", "\n", "\n", "print", "(", "\"Table 3 \\label{tab:speaker-inv}\"", ",", "file", "=", "file", ")", "\n", "print", "(", "inv_results", "(", ")", ".", "to_latex", "(", ")", ",", "file", "=", "file", ")", "\n", "\n", "print", "(", "\"Table 4 \\label{tab:rsa}\"", ",", "file", "=", "file", ")", "\n", "f", "=", "rsa_results", "(", ")", "\n", "print", "(", "f", ".", "to_latex", "(", ")", ",", "file", "=", "file", ")", "\n", "\n", "print", "(", "\"Table 5 \\label{tab:phoneme-decoding}\"", ",", "file", "=", "file", ")", "\n", "f", "=", "phoneme_decoding_results", "(", ")", "\n", "print", "(", "f", ".", "to_latex", "(", ")", ",", "file", "=", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.valid_results": [[36, 46], ["analyze.valid_runs", "run.copy", "numpy.mean", "numpy.mean", "numpy.mean", "out.append"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.valid_runs"], ["", "def", "valid_results", "(", ")", ":", "\n", "    ", "\"\"\"Table 1 (tab:core-results)\"\"\"", "\n", "out", "=", "[", "]", "\n", "for", "run", "in", "valid_runs", "(", ")", ":", "\n", "        ", "result", "=", "run", ".", "copy", "(", ")", "\n", "result", "[", "'recall@10'", "]", "=", "np", ".", "mean", "(", "run", "[", "'recall@10'", "]", ")", "\n", "result", "[", "'speaker_id'", "]", "=", "np", ".", "mean", "(", "run", "[", "'speaker_id'", "]", ")", "\n", "result", "[", "'medr'", "]", "=", "np", ".", "mean", "(", "run", "[", "'medr'", "]", ")", "\n", "out", ".", "append", "(", "result", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.test_results": [[49, 61], ["dict", "dict", "analyze.testscores", "out.append", "analyze.bestrun"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.testscores", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.bestrun"], ["", "def", "test_results", "(", ")", ":", "\n", "    ", "\"\"\"Table 2 (tab:core-results-test)\"\"\"", "\n", "runs", "=", "[", "dict", "(", "cond", "=", "\"\"", ",", "tasks", "=", "1", ",", "s", "=", "2", ",", "t", "=", "'.'", ",", "s2i", "=", "2", ",", "s2t", "=", "'.'", ",", "t2s", "=", "'.'", ",", "t2i", "=", "'.'", ")", ",", "\n", "dict", "(", "cond", "=", "\"joint\"", ",", "tasks", "=", "3", ",", "s", "=", "2", ",", "t", "=", "1", ",", "s2i", "=", "2", ",", "s2t", "=", "0", ",", "t2s", "=", "0", ",", "t2i", "=", "1", ")", "]", "\n", "out", "=", "[", "]", "\n", "for", "run", "in", "runs", ":", "\n", "        ", "spec", "=", "\"{}/s{s}-t{t}-s2i{s2i}-s2t{s2t}-t2s{t2s}-t2i{t2i}\"", ".", "format", "(", "PREFIX", ",", "**", "run", ")", "\n", "suffix", "=", "bestrun", "(", "spec", ",", "suffixes", "=", "'efg'", ",", "cond", "=", "run", "[", "'cond'", "]", ")", "[", "1", "]", "\n", "scores", "=", "testscores", "(", "\"{}/s{s}-t{t}-s2i{s2i}-s2t{s2t}-t2s{t2s}-t2i{t2i}\"", ".", "format", "(", "PREFIX", ",", "**", "run", ")", ",", "\n", "suffix", "=", "suffix", ",", "cond", "=", "run", "[", "'cond'", "]", ")", "\n", "out", ".", "append", "(", "{", "**", "run", ",", "**", "scores", "}", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.inv_results": [[63, 70], ["list", "pandas.concat", "analyze.melt", "pandas.read_json().groupby().mean", "analyze.valid_runs", "pandas.read_json().groupby", "pandas.read_json", "json.dumps", "json.dumps"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.melt", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.valid_runs"], ["", "def", "inv_results", "(", ")", ":", "\n", "    ", "\"\"\"Table 3 (fig:speaker-inv)\"\"\"", "\n", "data", "=", "list", "(", "melt", "(", "valid_runs", "(", ")", ")", ")", "\n", "R", "=", "pd", ".", "read_json", "(", "json", ".", "dumps", "(", "data", ")", ")", ".", "groupby", "(", "[", "'cond'", ",", "'tasks'", ",", "'s'", ",", "'t'", ",", "'s2i'", ",", "'s2t'", ",", "'t2s'", ",", "'t2i'", "]", ")", ".", "mean", "(", ")", "[", "[", "'speaker_id'", "]", "]", "\n", "return", "pd", ".", "concat", "(", "[", "R", ".", "loc", "[", "(", "''", ",", "1", ",", "2", ",", "'.'", ",", "2", ",", "'.'", ",", "'.'", ",", "'.'", ")", ":", "]", ".", "iloc", "[", "0", ":", "1", "]", ",", "\n", "R", ".", "loc", "[", "(", "'joint'", ",", "2", ",", "2", ",", "1", ",", "2", ",", "0", ",", "0", ",", "'.'", ")", ":", "]", ".", "iloc", "[", "0", ":", "1", "]", ",", "\n", "R", ".", "loc", "[", "(", "'joint'", ",", "3", ",", "2", ",", "1", ",", "2", ",", "0", ",", "0", ",", "1", ")", ":", "]", ".", "iloc", "[", "0", ":", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.rsa_results": [[75, 118], ["logging.getLogger().setLevel", "logging.info", "dp_f.getDataProvider", "logging.info", "vg.Scorer", "logging.info", "numpy.array", "cosine_similarity", "logging.info", "analyze.load_best_run", "vg.encode_sentences", "cosine_similarity", "logging.info", "analyze.load_best_run", "vg.encode_sentences", "cosine_similarity", "logging.info", "vg.encode_sentences_SpeechText", "cosine_similarity", "logging.info", "pandas.DataFrame", "dict", "rows.append", "logging.getLogger", "audio.mean", "cols[].append", "vg.RSA"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.getDataProvider", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences_SpeechText", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.RSA"], ["", "def", "rsa_results", "(", ")", ":", "\n", "    ", "\"\"\"Table 4 (tab:rsa)\"\"\"", "\n", "from", "sklearn", ".", "metrics", ".", "pairwise", "import", "cosine_similarity", "\n", "\n", "import", "vg", ".", "flickr8k_provider", "as", "dp_f", "\n", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "'INFO'", ")", "\n", "logging", ".", "info", "(", "\"Loading data\"", ")", "\n", "prov_flickr", "=", "dp_f", ".", "getDataProvider", "(", "'flickr8k'", ",", "root", "=", "'..'", ",", "audio_kind", "=", "'mfcc'", ")", "\n", "logging", ".", "info", "(", "\"Setting up scorer\"", ")", "\n", "scorer", "=", "S", ".", "Scorer", "(", "prov_flickr", ",", "\n", "dict", "(", "split", "=", "'val'", ",", "\n", "tokenize", "=", "lambda", "sent", ":", "sent", "[", "'audio'", "]", ",", "\n", "batch_size", "=", "16", "\n", ")", ")", "\n", "# SIMS", "\n", "logging", ".", "info", "(", "\"Computing MFCC similarity matrix\"", ")", "\n", "mfcc", "=", "np", ".", "array", "(", "[", "audio", ".", "mean", "(", "axis", "=", "0", ")", "for", "audio", "in", "scorer", ".", "sentence_data", "]", ")", "\n", "sim", "=", "{", "}", "\n", "sim", "[", "'mfcc'", "]", "=", "cosine_similarity", "(", "mfcc", ")", "\n", "sim", "[", "'text'", "]", "=", "scorer", ".", "string_sim", "\n", "sim", "[", "'image'", "]", "=", "scorer", ".", "sim_images", "\n", "# PRED 1 s2i", "\n", "logging", ".", "info", "(", "\"Computing M1,s2i similarity matrix\"", ")", "\n", "net", "=", "load_best_run", "(", "'{}/s2-t.-s2i2-s2t.-t2s.-t2i.'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "''", ")", "\n", "pred", "=", "S", ".", "encode_sentences", "(", "net", ",", "scorer", ".", "sentence_data", ",", "batch_size", "=", "scorer", ".", "config", "[", "'batch_size'", "]", ")", "\n", "sim", "[", "'m1,s2i'", "]", "=", "cosine_similarity", "(", "pred", ")", "\n", "# PRED 6 s2i  ", "\n", "logging", ".", "info", "(", "\"Computing M6,s2i similarity matrix\"", ")", "\n", "net", "=", "load_best_run", "(", "'{}/s2-t1-s2i2-s2t0-t2s0-t2i1'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "'joint'", ")", "\n", "pred", "=", "S", ".", "encode_sentences", "(", "net", ",", "scorer", ".", "sentence_data", ",", "batch_size", "=", "scorer", ".", "config", "[", "'batch_size'", "]", ")", "\n", "sim", "[", "'m6,s2i'", "]", "=", "cosine_similarity", "(", "pred", ")", "\n", "# PRED 6 s2t", "\n", "logging", ".", "info", "(", "\"Computing M6,s2t similarity matrix\"", ")", "\n", "pred", "=", "S", ".", "encode_sentences_SpeechText", "(", "net", ",", "scorer", ".", "sentence_data", ",", "batch_size", "=", "scorer", ".", "config", "[", "'batch_size'", "]", ")", "\n", "sim", "[", "'m6,s2t'", "]", "=", "cosine_similarity", "(", "pred", ")", "\n", "logging", ".", "info", "(", "\"Computing RSA scores\"", ")", "\n", "rows", "=", "[", "]", "\n", "cols", "=", "{", "'mfcc'", ":", "[", "]", ",", "'text'", ":", "[", "]", ",", "'image'", ":", "[", "]", "}", "\n", "for", "row", "in", "[", "'m1,s2i'", ",", "'m6,s2i'", ",", "'m6,s2t'", ",", "'image'", "]", ":", "\n", "        ", "rows", ".", "append", "(", "row", ")", "\n", "for", "col", "in", "[", "'mfcc'", ",", "'text'", ",", "'image'", "]", ":", "\n", "            ", "cols", "[", "col", "]", ".", "append", "(", "S", ".", "RSA", "(", "sim", "[", "row", "]", ",", "sim", "[", "col", "]", ")", ")", "\n", "", "", "return", "pd", ".", "DataFrame", "(", "data", "=", "cols", ",", "index", "=", "rows", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.phoneme_decoding_results": [[120, 145], ["dict", "phoneme_decoding_data.keys", "pandas.DataFrame", "numpy.load().item", "StandardScaler", "train_test_split", "StandardScaler.fit_transform", "StandardScaler.transform", "logging.info", "LogisticRegression", "LogisticRegression.fit", "result[].append", "result[].append", "analyze.get_nets", "analyze.phoneme_decoding_data", "numpy.save", "float", "numpy.load", "LogisticRegression.score"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.get_nets", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.phoneme_decoding_data", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.score"], ["", "def", "phoneme_decoding_results", "(", ")", ":", "\n", "    ", "\"\"\"Table 5 (tab:phoneme-decoding)\"\"\"", "\n", "from", "sklearn", ".", "linear_model", "import", "LogisticRegression", ",", "SGDClassifier", "\n", "from", "sklearn", ".", "model_selection", "import", "train_test_split", ",", "GridSearchCV", "\n", "from", "sklearn", ".", "preprocessing", "import", "StandardScaler", "\n", "try", ":", "\n", "        ", "data", "=", "np", ".", "load", "(", "\"phoneme_decoding_data.npy\"", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "nets", "=", "get_nets", "(", ")", "\n", "data", "=", "phoneme_decoding_data", "(", "nets", ")", "\n", "np", ".", "save", "(", "\"phoneme_decoding_data.npy\"", ",", "data", ")", "\n", "", "result", "=", "dict", "(", "representation", "=", "[", "]", ",", "accuracy", "=", "[", "]", ")", "\n", "for", "rep", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "scaler", "=", "StandardScaler", "(", ")", "\n", "X_train", ",", "X_test", ",", "y_train", ",", "y_test", "=", "train_test_split", "(", "data", "[", "rep", "]", "[", "'features'", "]", ",", "data", "[", "rep", "]", "[", "'labels'", "]", ",", "test_size", "=", "1", "/", "2", ",", "random_state", "=", "123", ")", "\n", "X_train", "=", "scaler", ".", "fit_transform", "(", "X_train", ")", "\n", "X_test", "=", "scaler", ".", "transform", "(", "X_test", ")", "\n", "#m = GridSearchCV(LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=200), {'C': [ 10**n for n in range(-1, 1) ]}, cv=3, n_jobs=-1)", "\n", "logging", ".", "info", "(", "\"Fitting Logistic Regression for {}\"", ".", "format", "(", "rep", ")", ")", "\n", "m", "=", "LogisticRegression", "(", "solver", "=", "\"lbfgs\"", ",", "multi_class", "=", "'auto'", ",", "max_iter", "=", "300", ",", "random_state", "=", "123", ",", "C", "=", "1.0", ")", "\n", "m", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "result", "[", "'representation'", "]", ".", "append", "(", "rep", ")", "\n", "result", "[", "'accuracy'", "]", ".", "append", "(", "float", "(", "m", ".", "score", "(", "X_test", ",", "y_test", ")", ")", ")", "\n", "#print(result[rep])", "\n", "", "return", "pd", ".", "DataFrame", "(", "data", "=", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.get_nets": [[146, 182], ["analyze.load_best_run", "analyze.load_best_run", "dict", "analyze.load_best_run", "analyze.load_best_run", "D.Net().cuda", "dict", "dict", "dict", "dict", "dict", "D.Net", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run"], ["", "def", "get_nets", "(", ")", ":", "\n", "    ", "import", "vg", ".", "defn", ".", "three_way2", "as", "D", "\n", "net_base", "=", "load_best_run", "(", "'{}/s2-t.-s2i2-s2t.-t2s.-t2i.'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "''", ")", "\n", "net_mt", "=", "load_best_run", "(", "'{}/s2-t1-s2i2-s2t0-t2s0-t2i1'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "'joint'", ")", "\n", "config", "=", "dict", "(", "TextImage", "=", "dict", "(", "ImageEncoder", "=", "dict", "(", "size", "=", "1024", ",", "size_target", "=", "4096", ")", ",", "\n", "lr", "=", "0.0002", ",", "\n", "margin_size", "=", "0.2", ",", "\n", "max_norm", "=", "2.0", ",", "\n", "TextEncoderTop", "=", "dict", "(", "size", "=", "1024", ",", "size_feature", "=", "1024", ",", "depth", "=", "1", ",", "size_attn", "=", "128", ")", ")", ",", "\n", "SpeechImage", "=", "dict", "(", "ImageEncoder", "=", "dict", "(", "size", "=", "1024", ",", "size_target", "=", "4096", ")", ",", "\n", "lr", "=", "0.0002", ",", "\n", "margin_size", "=", "0.2", ",", "\n", "max_norm", "=", "2.0", ",", "\n", "SpeechEncoderTop", "=", "dict", "(", "size", "=", "1024", ",", "size_input", "=", "1024", ",", "depth", "=", "2", ",", "size_attn", "=", "128", ")", ")", ",", "\n", "SpeechText", "=", "dict", "(", "TextEncoderTop", "=", "dict", "(", "size_feature", "=", "1024", ",", "\n", "size", "=", "1024", ",", "\n", "depth", "=", "0", ",", "\n", "size_attn", "=", "128", ")", ",", "\n", "SpeechEncoderTop", "=", "dict", "(", "size", "=", "1024", ",", "\n", "size_input", "=", "1024", ",", "\n", "depth", "=", "0", ",", "\n", "size_attn", "=", "128", ")", ",", "\n", "lr", "=", "0.0002", ",", "\n", "margin_size", "=", "0.2", ",", "\n", "max_norm", "=", "2.0", ")", ",", "\n", "\n", "SpeechEncoderBottom", "=", "dict", "(", "size", "=", "1024", ",", "depth", "=", "2", ",", "size_vocab", "=", "13", ",", "filter_length", "=", "6", ",", "filter_size", "=", "64", ",", "stride", "=", "2", ")", ",", "\n", "TextEncoderBottom", "=", "dict", "(", "size_feature", "=", "net_mt", ".", "TextEncoderBottom", ".", "size_feature", ",", "\n", "size_embed", "=", "128", ",", "\n", "size", "=", "1024", ",", "\n", "depth", "=", "1", ")", "\n", ")", "\n", "net_base", "=", "load_best_run", "(", "'{}/s2-t.-s2i2-s2t.-t2s.-t2i.'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "''", ")", "\n", "net_mt", "=", "load_best_run", "(", "'{}/s2-t1-s2i2-s2t0-t2s0-t2i1'", ".", "format", "(", "PREFIX", ")", ",", "cond", "=", "'joint'", ")", "\n", "net_init", "=", "D", ".", "Net", "(", "config", ")", ".", "cuda", "(", ")", "\n", "return", "[", "(", "'m6_init'", ",", "net_init", ")", ",", "(", "'m1'", ",", "net_base", ")", ",", "(", "'m6'", ",", "net_mt", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.phoneme_decoding_data": [[183, 220], ["logging.getLogger().setLevel", "logging.info", "open", "logging.info", "dp.getDataProvider", "list", "logging.info", "analyze.fa_data", "json.loads", "json.loads", "dp.getDataProvider.iterSentences", "logging.info", "analyze.get_layer_states", "analyze.fa_data", "logging.getLogger", "numpy.all", "analyze.slices", "x[].mean", "range", "analyze.slices", "word.get", "len", "analyze.index"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.getDataProvider", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.fa_data", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterSentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.get_layer_states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.fa_data", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.slices", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.slices", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index"], ["", "def", "phoneme_decoding_data", "(", "nets", ",", "alignment_path", "=", "\"../data/flickr8k/dataset.val.fa.json\"", ",", "\n", "dataset_path", "=", "\"../data/flickr8k/dataset.json\"", ",", "\n", "max_size", "=", "5000", ",", "\n", "directory", "=", "\".\"", ")", ":", "\n", "    ", "\"\"\"Generate data for training a phoneme decoding model.\"\"\"", "\n", "import", "vg", ".", "flickr8k_provider", "as", "dp", "\n", "\n", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "'INFO'", ")", "\n", "logging", ".", "info", "(", "\"Loading alignments\"", ")", "\n", "data", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "alignment_path", ")", ":", "\n", "        ", "item", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", "[", "item", "[", "'sentid'", "]", "]", "=", "item", "\n", "", "logging", ".", "info", "(", "\"Loading audio features\"", ")", "\n", "prov", "=", "dp", ".", "getDataProvider", "(", "'flickr8k'", ",", "root", "=", "'..'", ",", "audio_kind", "=", "'mfcc'", ")", "\n", "val", "=", "list", "(", "prov", ".", "iterSentences", "(", "split", "=", "'val'", ")", ")", "\n", "data_filter", "=", "[", "(", "data", "[", "sent", "[", "'sentid'", "]", "]", ",", "sent", ")", "for", "sent", "in", "val", "\n", "if", "np", ".", "all", "(", "[", "word", ".", "get", "(", "'start'", ",", "False", ")", "for", "word", "in", "data", "[", "sent", "[", "'sentid'", "]", "]", "[", "'words'", "]", "]", ")", "]", "\n", "data_filter", "=", "data_filter", "[", ":", "max_size", "]", "\n", "data_state", "=", "[", "phoneme", "for", "(", "utt", ",", "sent", ")", "in", "data_filter", "for", "phoneme", "in", "slices", "(", "utt", ",", "sent", "[", "'audio'", "]", ")", "]", "\n", "result", "=", "{", "}", "\n", "logging", ".", "info", "(", "\"Extracting MFCC examples\"", ")", "\n", "result", "[", "'mfcc'", "]", "=", "fa_data", "(", "data_state", ")", "\n", "for", "name", ",", "net", "in", "nets", ":", "\n", "        ", "result", "[", "name", "]", "=", "{", "}", "\n", "L", "=", "1", "\n", "S", "=", "net", ".", "SpeechEncoderBottom", ".", "stride", "\n", "logging", ".", "info", "(", "\"Extracting recurrent layer states\"", ")", "\n", "audio", "=", "[", "sent", "[", "'audio'", "]", "for", "utt", ",", "sent", "in", "data_filter", "]", "\n", "states", "=", "get_layer_states", "(", "net", ",", "audio", ",", "batch_size", "=", "32", ")", "\n", "layer", "=", "0", "\n", "def", "aggregate", "(", "x", ")", ":", "\n", "                ", "return", "x", "[", ":", ",", "layer", ",", ":", "]", ".", "mean", "(", "axis", "=", "0", ")", "\n", "", "data_state", "=", "[", "phoneme", "for", "i", "in", "range", "(", "len", "(", "data_filter", ")", ")", "\n", "for", "phoneme", "in", "slices", "(", "data_filter", "[", "i", "]", "[", "0", "]", ",", "states", "[", "i", "]", ",", "index", "=", "lambda", "x", ":", "index", "(", "x", ",", "stride", "=", "S", ")", ",", "aggregate", "=", "aggregate", ")", "]", "\n", "result", "[", "name", "]", "=", "fa_data", "(", "data_state", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.get_layer_states": [[221, 233], ["analyze.inout", "zip", "numpy.array", "result.append", "list", "util.grouper", "layer_states().cpu().numpy", "numpy.expand_dims", "map", "layer_states().cpu", "analyze.layer_states", "torch.from_numpy().cuda", "torch.from_numpy", "vector_padder"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.layer_states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder"], ["", "def", "get_layer_states", "(", "net", ",", "audios", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "import", "onion", ".", "util", "as", "util", "\n", "from", "vg", ".", "simple_data", "import", "vector_padder", "\n", "\"\"\"Pass audios through the model and for each audio return the state of each timestep and each layer.\"\"\"", "\n", "result", "=", "[", "]", "\n", "lens", "=", "inout", "(", "np", ".", "array", "(", "list", "(", "map", "(", "len", ",", "audios", ")", ")", ")", ")", "\n", "rs", "=", "(", "r", "for", "batch", "in", "util", ".", "grouper", "(", "audios", ",", "batch_size", ")", "\n", "for", "r", "in", "layer_states", "(", "net", ",", "torch", ".", "from_numpy", "(", "vector_padder", "(", "batch", ")", ")", ".", "cuda", "(", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "for", "(", "r", ",", "l", ")", "in", "zip", "(", "rs", ",", "lens", ")", ":", "\n", "        ", "result", ".", "append", "(", "np", ".", "expand_dims", "(", "r", "[", "-", "l", ":", ",", ":", "]", ",", "axis", "=", "1", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.get_state_stack": [[234, 246], ["analyze.inout", "zip", "numpy.array", "result.append", "list", "util.grouper", "state_stack().cpu().numpy", "map", "state_stack().cpu", "analyze.state_stack", "torch.from_numpy().cuda", "torch.from_numpy", "vector_padder"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.state_stack", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder"], ["", "def", "get_state_stack", "(", "net", ",", "audios", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "import", "onion", ".", "util", "as", "util", "\n", "from", "vg", ".", "simple_data", "import", "vector_padder", "\n", "\"\"\"Pass audios through the model and for each audio return the state of each timestep and each layer.\"\"\"", "\n", "result", "=", "[", "]", "\n", "lens", "=", "inout", "(", "np", ".", "array", "(", "list", "(", "map", "(", "len", ",", "audios", ")", ")", ")", ")", "\n", "rs", "=", "(", "r", "for", "batch", "in", "util", ".", "grouper", "(", "audios", ",", "batch_size", ")", "\n", "for", "r", "in", "state_stack", "(", "net", ",", "torch", ".", "from_numpy", "(", "vector_padder", "(", "batch", ")", ")", ".", "cuda", "(", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "for", "(", "r", ",", "l", ")", "in", "zip", "(", "rs", ",", "lens", ")", ":", "\n", "        ", "result", ".", "append", "(", "r", "[", "-", "l", ":", ",", ":", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.inout": [[248, 250], ["numpy.floor().astype", "numpy.floor"], "function", ["None"], ["", "def", "inout", "(", "L", ",", "pad", "=", "6", ",", "ksize", "=", "6", ",", "stride", "=", "2", ")", ":", "# Default Flickr8k model parameters ", "\n", "    ", "return", "np", ".", "floor", "(", "(", "L", "+", "2", "*", "pad", "-", "1", "*", "(", "ksize", "-", "1", ")", "-", "1", ")", "/", "stride", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.index": [[251, 257], ["analyze.inout"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout"], ["", "def", "index", "(", "t", ",", "stride", "=", "2", ",", "size", "=", "6", ")", ":", "\n", "    ", "\"\"\"Return index into the recurrent state of speech model given timestep\n    `t`.\n    See: https://pytorch.org/docs/stable/nn.html#torch.nn.Conv1d\n    \"\"\"", "\n", "return", "inout", "(", "t", "//", "10", ",", "pad", "=", "size", ",", "ksize", "=", "size", ",", "stride", "=", "stride", ")", "# sampling audio every 10ms", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.layer_states": [[259, 264], ["testing", "net.SpeechImage.SpeechEncoderBottom"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "layer_states", "(", "net", ",", "audio", ")", ":", "\n", "    ", "from", "vg", ".", "scorer", "import", "testing", "\n", "with", "testing", "(", "net", ")", ":", "\n", "        ", "states", "=", "net", ".", "SpeechImage", ".", "SpeechEncoderBottom", "(", "audio", ")", "\n", "", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.state_stack": [[265, 272], ["torch.cat().permute", "testing", "net.SpeechImage.SpeechEncoderBottom.states", "net.SpeechImage.SpeechEncoderTop.states", "torch.cat"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states"], ["", "def", "state_stack", "(", "net", ",", "audio", ")", ":", "\n", "    ", "from", "vg", ".", "scorer", "import", "testing", "\n", "with", "testing", "(", "net", ")", ":", "\n", "        ", "states_bot", "=", "net", ".", "SpeechImage", ".", "SpeechEncoderBottom", ".", "states", "(", "audio", ")", "\n", "states_top", "=", "net", ".", "SpeechImage", ".", "SpeechEncoderTop", ".", "states", "(", "states_bot", "[", "-", "1", "]", ")", "\n", "", "states", "=", "torch", ".", "cat", "(", "[", "states_bot", ",", "states_top", "]", ",", "dim", "=", "0", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "#batch x length x layer x feature", "\n", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.fa_data": [[275, 284], ["zip", "numpy.vstack", "numpy.array", "numpy.isnan", "dict", "np.vstack.sum"], "function", ["None"], ["", "def", "fa_data", "(", "data_state", ")", ":", "\n", "    ", "y", ",", "X", "=", "zip", "(", "*", "data_state", ")", "\n", "X", "=", "np", ".", "vstack", "(", "X", ")", "\n", "y", "=", "np", ".", "array", "(", "y", ")", "\n", "# Get rid of NaNs", "\n", "ix", "=", "np", ".", "isnan", "(", "X", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "X", "=", "X", "[", "~", "ix", "]", "\n", "y", "=", "y", "[", "~", "ix", "]", "\n", "return", "dict", "(", "features", "=", "X", ",", "labels", "=", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.slices": [[285, 296], ["analyze.phones", "x.mean", "analyze.index", "analyze.index", "analyze.index", "analyze.index", "analyze.phoneme_decoding_data.aggregate", "analyze.index", "analyze.index"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.phones", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index"], ["", "def", "slices", "(", "utt", ",", "rep", ",", "index", "=", "lambda", "ms", ":", "ms", "//", "10", ",", "aggregate", "=", "lambda", "x", ":", "x", ".", "mean", "(", "axis", "=", "0", ")", ")", ":", "\n", "    ", "\"\"\"Return sequence of slices associated with phoneme labels, given an\n       alignment object `utt`, a representation array `rep`, and\n       indexing function `index`, and an aggregating function\\\n       `aggregate`.\n\n    \"\"\"", "\n", "for", "phoneme", "in", "phones", "(", "utt", ")", ":", "\n", "        ", "phone", ",", "start", ",", "end", "=", "phoneme", "\n", "assert", "index", "(", "start", ")", "<", "index", "(", "end", ")", "+", "1", ",", "\"Something funny: {} {} {} {}\"", ".", "format", "(", "start", ",", "end", ",", "index", "(", "start", ")", ",", "index", "(", "end", ")", ")", "\n", "yield", "(", "phone", ",", "aggregate", "(", "rep", "[", "index", "(", "start", ")", ":", "index", "(", "end", ")", "+", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.phones": [[297, 311], ["phone[].split", "int", "int"], "function", ["None"], ["", "", "def", "phones", "(", "utt", ")", ":", "\n", "    ", "\"\"\"Return sequence of phoneme labels associated with start and end\n     time corresponding to the alignment JSON object `utt`.\n    \n    \"\"\"", "\n", "for", "word", "in", "utt", "[", "'words'", "]", ":", "\n", "        ", "pos", "=", "word", "[", "'start'", "]", "\n", "for", "phone", "in", "word", "[", "'phones'", "]", ":", "\n", "            ", "start", "=", "pos", "\n", "end", "=", "pos", "+", "phone", "[", "'duration'", "]", "\n", "pos", "=", "end", "\n", "label", "=", "phone", "[", "'phone'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "label", "!=", "'oov'", ":", "\n", "                ", "yield", "(", "label", ",", "int", "(", "start", "*", "1000", ")", ",", "int", "(", "end", "*", "1000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.load_best_run": [[314, 320], ["analyze.bestrun", "logging.info", "torch.load"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.bestrun", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["", "", "", "", "def", "load_best_run", "(", "spec", ",", "cond", "=", "'joint'", ")", ":", "\n", "    ", "_", ",", "suffix", ",", "epoch", "=", "bestrun", "(", "spec", ",", "suffixes", "=", "'efg'", ",", "cond", "=", "cond", ")", "\n", "path", "=", "\"{}-{}-{}/model.{}.pkl\"", ".", "format", "(", "spec", ",", "cond", ",", "suffix", ",", "epoch", ")", "\n", "logging", ".", "info", "(", "\"Laoding model from {}\"", ".", "format", "(", "path", ")", ")", "\n", "net", "=", "torch", ".", "load", "(", "path", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.valid_runs": [[322, 347], ["dict", "dict", "dict", "rest.append", "analyze.validscores", "dict", "rest.append", "dict"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.validscores"], ["", "def", "valid_runs", "(", ")", ":", "\n", "    ", "base", "=", "[", "dict", "(", "cond", "=", "\"\"", ",", "tasks", "=", "1", ",", "s", "=", "2", ",", "t", "=", "'.'", ",", "s2i", "=", "2", ",", "s2t", "=", "'.'", ",", "t2s", "=", "'.'", ",", "t2i", "=", "'.'", ")", ",", "\n", "dict", "(", "cond", "=", "\"joint\"", ",", "tasks", "=", "2", ",", "s", "=", "2", ",", "t", "=", "1", ",", "s2i", "=", "2", ",", "s2t", "=", "0", ",", "t2s", "=", "0", ",", "t2i", "=", "'.'", ")", ",", "\n", "dict", "(", "cond", "=", "\"disjoint\"", ",", "tasks", "=", "2", ",", "s", "=", "2", ",", "t", "=", "1", ",", "s2i", "=", "2", ",", "s2t", "=", "0", ",", "t2s", "=", "0", ",", "t2i", "=", "'.'", ")", ",", "\n", "]", "\n", "\n", "S2I", "=", "[", "1", ",", "2", "]", "\n", "ST", "=", "[", "0", ",", "1", "]", "\n", "rest", "=", "[", "]", "\n", "metrics", "=", "(", "'recall@10'", ",", "'medr'", ",", "'speaker_id'", ")", "\n", "for", "cond", "in", "[", "\"joint\"", ",", "\"disjoint\"", "]", ":", "\n", "        ", "for", "s2i", "in", "S2I", ":", "\n", "            ", "for", "st", "in", "ST", ":", "\n", "                 ", "rest", ".", "append", "(", "dict", "(", "cond", "=", "cond", ",", "tasks", "=", "3", ",", "s", "=", "2", ",", "t", "=", "1", ",", "s2i", "=", "s2i", ",", "s2t", "=", "st", ",", "t2s", "=", "st", ",", "t2i", "=", "1", ")", ")", "\n", "\n", "", "", "rest", ".", "append", "(", "dict", "(", "cond", "=", "cond", ",", "tasks", "=", "3", ",", "s", "=", "4", ",", "t", "=", "1", ",", "s2i", "=", "0", ",", "s2t", "=", "0", ",", "t2s", "=", "0", ",", "t2i", "=", "0", ")", ")", "\n", "\n", "", "for", "run", "in", "base", "+", "rest", ":", "\n", "        ", "scores", "=", "validscores", "(", "\"{}/s{s}-t{t}-s2i{s2i}-s2t{s2t}-t2s{t2s}-t2i{t2i}\"", ".", "format", "(", "PREFIX", ",", "**", "run", ")", ",", "\n", "suffixes", "=", "\"efg\"", ",", "\n", "cond", "=", "run", "[", "'cond'", "]", ")", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "           ", "run", "[", "metric", "]", "=", "scores", "[", "metric", "]", "\n", "", "yield", "run", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.melt": [[348, 353], ["range", "len", "len", "len"], "function", ["None"], ["", "", "def", "melt", "(", "runs", ")", ":", "\n", "    ", "for", "run", "in", "runs", ":", "\n", "        ", "assert", "len", "(", "run", "[", "'recall@10'", "]", ")", "==", "len", "(", "run", "[", "'medr'", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "run", "[", "'recall@10'", "]", ")", ")", ":", "\n", "            ", "yield", "{", "**", "run", ",", "'recall@10'", ":", "run", "[", "'recall@10'", "]", "[", "i", "]", ",", "'medr'", ":", "run", "[", "'medr'", "]", "[", "i", "]", ",", "'speaker_id'", ":", "run", "[", "'speaker_id'", "]", "[", "i", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.json2latex": [[357, 366], ["data.keys", "type", "analyze.json2latex.format"], "function", ["None"], ["def", "json2latex", "(", "data", ",", "keys", "=", "KEYS", ")", ":", "\n", "    ", "if", "keys", "is", "None", ":", "\n", "        ", "keys", "=", "data", ".", "keys", "(", ")", "\n", "", "def", "format", "(", "x", ")", ":", "\n", "        ", "if", "type", "(", "x", ")", "in", "[", "float", ",", "np", ".", "float", ",", "np", ".", "float64", "]", ":", "\n", "            ", "return", "\"{:5.3f}\"", ".", "format", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"{}\"", ".", "format", "(", "x", ")", "\n", "", "", "return", "\"\\\\\\\\\\n\"", ".", "join", "(", "\" & \"", ".", "join", "(", "format", "(", "datum", "[", "key", "]", ")", "for", "key", "in", "keys", ")", "for", "datum", "in", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.bestrec": [[367, 372], ["numpy.argmax", "json.loads", "json.loads", "open"], "function", ["None"], ["", "def", "bestrec", "(", "path", ",", "criterion", "=", "'recall@10'", ")", ":", "\n", "#print(path)", "\n", "         ", "R", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "open", "(", "path", ")", "]", "\n", "besti", "=", "np", ".", "argmax", "(", "[", "Ri", "[", "'retrieval'", "]", "[", "criterion", "]", "for", "Ri", "in", "R", "]", ")", "\n", "return", "R", "[", "besti", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.bestrun": [[373, 380], ["zip", "sorted", "range", "open", "json.loads", "json.loads", "rec.append"], "function", ["None"], ["", "def", "bestrun", "(", "spec", ",", "suffixes", ",", "cond", "=", "'joint'", ")", ":", "\n", "    ", "rec", "=", "[", "]", "\n", "for", "suffix", "in", "suffixes", ":", "\n", "        ", "for", "epoch", ",", "line", "in", "zip", "(", "range", "(", "1", ",", "26", ")", ",", "open", "(", "\"{}-{}-{}/result.json\"", ".", "format", "(", "spec", ",", "cond", ",", "suffix", ")", ")", ")", ":", "\n", "            ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "rec", ".", "append", "(", "(", "data", "[", "'retrieval'", "]", "[", "'recall@10'", "]", ",", "suffix", ",", "epoch", ")", ")", "\n", "", "", "return", "sorted", "(", "rec", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.testscores": [[381, 384], ["json.load", "json.load", "open"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["", "def", "testscores", "(", "spec", ",", "suffix", ",", "cond", ")", ":", "\n", "    ", "R", "=", "json", ".", "load", "(", "open", "(", "\"{}-{}-{}/test/result.json\"", ".", "format", "(", "spec", ",", "cond", ",", "suffix", ")", ")", ")", "\n", "return", "{", "'recall@10'", ":", "R", "[", "'retrieval'", "]", "[", "'recall@10'", "]", ",", "'medr'", ":", "R", "[", "'retrieval'", "]", "[", "'medr'", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.validscores": [[386, 398], ["analyze.bestrec", "result[].append", "result[].append", "result[].append"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.bestrec"], ["", "def", "validscores", "(", "spec", ",", "suffixes", ",", "cond", "=", "'joint'", ")", ":", "\n", "    ", "result", "=", "{", "'recall@10'", ":", "[", "]", ",", "'medr'", ":", "[", "]", ",", "'speaker_id'", ":", "[", "]", "}", "\n", "for", "suffix", "in", "suffixes", ":", "\n", "        ", "data", "=", "bestrec", "(", "\"{}-{}-{}/result.json\"", ".", "format", "(", "spec", ",", "cond", ",", "suffix", ")", ")", "\n", "# display key results averaged over runs, with min and max", "\n", "# recall@10", "\n", "# medr", "\n", "# speaker accuracy", "\n", "result", "[", "'recall@10'", "]", ".", "append", "(", "data", "[", "'retrieval'", "]", "[", "'recall@10'", "]", ")", "\n", "result", "[", "'medr'", "]", ".", "append", "(", "data", "[", "'retrieval'", "]", "[", "'medr'", "]", ")", "\n", "result", "[", "'speaker_id'", "]", ".", "append", "(", "data", "[", "'speaker_id'", "]", "[", "'rep'", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.make_json_happy": [[400, 411], ["isinstance", "isinstance", "float", "isinstance", "isinstance", "analyze.make_json_happy", "isinstance", "x.items", "analyze.make_json_happy", "tuple", "analyze.make_json_happy"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.make_json_happy", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.make_json_happy", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.analysis.analyze.make_json_happy"], ["", "def", "make_json_happy", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "np", ".", "float32", ")", "or", "isinstance", "(", "x", ",", "np", ".", "float64", ")", ":", "\n", "        ", "return", "float", "(", "x", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "        ", "return", "{", "key", ":", "make_json_happy", "(", "value", ")", "for", "key", ",", "value", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "return", "[", "make_json_happy", "(", "value", ")", "for", "value", "in", "x", "]", "\n", "", "elif", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "        ", "return", "tuple", "(", "make_json_happy", "(", "value", ")", "for", "value", "in", "x", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.NoScaler.__init__": [[31, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "fit_transform", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.NoScaler.fit_transform": [[33, 35], ["None"], "methods", ["None"], ["", "def", "fit_transform", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "", "def", "transform", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.NoScaler.transform": [[35, 37], ["None"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "", "def", "inverse_transform", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.NoScaler.inverse_transform": [[37, 39], ["None"], "methods", ["None"], ["", "def", "inverse_transform", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.InputScaler.__init__": [[42, 44], ["sklearn.preprocessing.StandardScaler"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "scaler", "=", "StandardScaler", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.InputScaler.fit_transform": [[45, 49], ["numpy.vstack", "simple_data.InputScaler.scaler.fit", "simple_data.InputScaler.scaler.transform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "def", "fit_transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "flat", "=", "numpy", ".", "vstack", "(", "data", ")", "\n", "self", ".", "scaler", ".", "fit", "(", "flat", ")", "\n", "return", "[", "self", ".", "scaler", ".", "transform", "(", "X", ")", "for", "X", "in", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.InputScaler.transform": [[50, 52], ["simple_data.InputScaler.scaler.transform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "[", "self", ".", "scaler", ".", "transform", "(", "X", ")", "for", "X", "in", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.InputScaler.inverse_transform": [[53, 55], ["simple_data.InputScaler.scaler.inverse_transform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.inverse_transform"], ["", "def", "inverse_transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "[", "self", ".", "scaler", ".", "inverse_transform", "(", "X", ")", "for", "X", "in", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.__init__": [[70, 80], ["onion.util.autoassign", "locals"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "mapper", ",", "pad_end", "=", "False", ",", "visual", "=", "True", ",", "erasure", "=", "(", "5", ",", "5", ")", ",", "sigma", "=", "None", ",", "noise_tied", "=", "False", ",", "midpoint", "=", "False", ")", ":", "\n", "        ", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "BEG", "=", "self", ".", "mapper", ".", "BEG_ID", "\n", "self", ".", "END", "=", "self", ".", "mapper", ".", "END_ID", "\n", "try", ":", "\n", "            ", "self", ".", "gap_low", "=", "self", ".", "erasure", "[", "0", "]", "\n", "self", ".", "gap_high", "=", "self", ".", "erasure", "[", "1", "]", "\n", "", "except", ":", "\n", "            ", "self", ".", "gap_low", "=", "self", ".", "erasure", "\n", "self", ".", "gap_high", "=", "self", ".", "erasure", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.pad": [[81, 88], ["max", "simple_data.Batcher.pad.pad_one"], "methods", ["None"], ["", "", "def", "pad", "(", "self", ",", "xss", ")", ":", "# PAD AT BEGINNING", "\n", "        ", "max_len", "=", "max", "(", "(", "len", "(", "xs", ")", "for", "xs", "in", "xss", ")", ")", "\n", "def", "pad_one", "(", "xs", ")", ":", "\n", "            ", "if", "self", ".", "pad_end", ":", "\n", "                ", "return", "xs", "+", "[", "self", ".", "END", "for", "_", "in", "range", "(", "0", ",", "(", "max_len", "-", "len", "(", "xs", ")", ")", ")", "]", "\n", "", "return", "[", "self", ".", "BEG", "for", "_", "in", "range", "(", "0", ",", "(", "max_len", "-", "len", "(", "xs", ")", ")", ")", "]", "+", "xs", "\n", "", "return", "[", "pad_one", "(", "xs", ")", "for", "xs", "in", "xss", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch_inp": [[89, 92], ["simple_data.Batcher.padder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.padder"], ["", "def", "batch_inp", "(", "self", ",", "sents", ")", ":", "\n", "        ", "mb", "=", "self", ".", "padder", "(", "sents", ")", "\n", "return", "mb", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.padder": [[93, 95], ["numpy.array", "simple_data.Batcher.pad"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.pad"], ["", "def", "padder", "(", "self", ",", "sents", ")", ":", "\n", "        ", "return", "numpy", ".", "array", "(", "self", ".", "pad", "(", "[", "[", "self", ".", "BEG", "]", "+", "sent", "+", "[", "self", ".", "END", "]", "for", "sent", "in", "sents", "]", ")", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch": [[97, 173], ["simple_data.Batcher.padder", "simple_data.Batcher.padder", "numpy.array", "len", "numpy.random.randint", "len", "simple_data.vector_padder", "simple_data.midpoint", "simple_data.midpoint", "numpy.array", "numpy.array", "numpy.random.binomial", "numpy.random.normal", "numpy.random.normal", "max", "int", "max", "int", "numpy.random.binomial", "numpy.random.normal", "numpy.random.normal", "numpy.median", "numpy.median"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.padder", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.padder", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.midpoint", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.midpoint"], ["", "def", "batch", "(", "self", ",", "gr", ")", ":", "\n", "        ", "\"\"\"Prepare minibatch.\n        Returns:\n        - input string\n        - visual target vector\n        - output string at t-1\n        - target string\n        \"\"\"", "\n", "L_tok", "=", "[", "len", "(", "x", "[", "'tokens_in'", "]", ")", "for", "x", "in", "gr", "]", "\n", "mb_inp", "=", "self", ".", "padder", "(", "[", "x", "[", "'tokens_in'", "]", "for", "x", "in", "gr", "]", ")", "\n", "mb_target_t", "=", "self", ".", "padder", "(", "[", "x", "[", "'tokens_out'", "]", "for", "x", "in", "gr", "]", ")", "\n", "inp", "=", "mb_inp", "[", ":", ",", "1", ":", "]", "\n", "target_t", "=", "mb_target_t", "[", ":", ",", "1", ":", "]", "\n", "target_prev_t", "=", "mb_target_t", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "target_v", "=", "numpy", ".", "array", "(", "[", "x", "[", "'img'", "]", "for", "x", "in", "gr", "]", ",", "dtype", "=", "'float32'", ")", "\n", "gap", "=", "numpy", ".", "random", ".", "randint", "(", "self", ".", "gap_low", ",", "self", ".", "gap_high", ",", "1", ")", "[", "0", "]", "\n", "\n", "L_aud", "=", "[", "len", "(", "x", "[", "'audio'", "]", ")", "for", "x", "in", "gr", "]", "\n", "audio", "=", "vector_padder", "(", "[", "x", "[", "'audio'", "]", "for", "x", "in", "gr", "]", ")", "if", "gr", "[", "0", "]", "[", "'audio'", "]", "is", "not", "None", "else", "None", "\n", "if", "self", ".", "midpoint", ":", "\n", "            ", "mid", "=", "midpoint", "(", "audio", ".", "shape", "[", "1", "]", ",", "max", "(", "L_aud", ")", "-", "int", "(", "numpy", ".", "median", "(", "L_aud", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "mid", "=", "audio", ".", "shape", "[", "1", "]", "//", "2", "\n", "", "audio_beg", "=", "audio", "[", ":", ",", ":", "mid", "-", "gap", ",", ":", "]", "\n", "audio_end", "=", "audio", "[", ":", ",", "mid", "+", "gap", ":", ",", ":", "]", "\n", "\n", "if", "self", ".", "midpoint", ":", "\n", "            ", "mid", "=", "midpoint", "(", "inp", ".", "shape", "[", "1", "]", ",", "max", "(", "L_tok", ")", "-", "int", "(", "numpy", ".", "median", "(", "L_tok", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "mid", "=", "inp", ".", "shape", "[", "1", "]", "//", "2", "\n", "", "if", "gap", ">=", "mid", ":", "# avoid empty arrays", "\n", "            ", "inp_beg", "=", "inp", "[", ":", ",", ":", "mid", "]", "\n", "inp_end", "=", "inp", "[", ":", ",", "mid", ":", "]", "\n", "", "else", ":", "\n", "            ", "inp_beg", "=", "inp", "[", ":", ",", ":", "mid", "-", "gap", "]", "\n", "inp_end", "=", "inp", "[", ":", ",", "mid", "+", "gap", ":", "]", "\n", "\n", "", "if", "self", ".", "sigma", "is", "not", "None", "and", "not", "self", ".", "noise_tied", ":", "\n", "            ", "if", "numpy", ".", "random", ".", "binomial", "(", "1", ",", "0.5", ")", "==", "1", ":", "\n", "                ", "audio_beg", "+=", "numpy", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "self", ".", "sigma", ",", "size", "=", "audio_beg", ".", "shape", ")", "\n", "", "else", ":", "\n", "                ", "audio_end", "+=", "numpy", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "self", ".", "sigma", ",", "size", "=", "audio_end", ".", "shape", ")", "\n", "# Time tied noise", "\n", "", "", "elif", "self", ".", "sigma", "is", "not", "None", "and", "self", ".", "noise_tied", ":", "\n", "            ", "if", "numpy", ".", "random", ".", "binomial", "(", "1", ",", "0.5", ")", "==", "1", ":", "\n", "                ", "audio_beg", "+=", "numpy", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "self", ".", "sigma", ",", "size", "=", "(", "audio_beg", ".", "shape", "[", "0", "]", ",", "1", ",", "audio_beg", ".", "shape", "[", "2", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "audio_end", "+=", "numpy", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "self", ".", "sigma", ",", "size", "=", "(", "audio_end", ".", "shape", "[", "0", "]", ",", "1", ",", "audio_end", ".", "shape", "[", "2", "]", ")", ")", "\n", "\n", "", "", "one3", "=", "audio", ".", "shape", "[", "1", "]", "//", "3", "\n", "two3", "=", "one3", "*", "2", "\n", "audio_1", "=", "audio", "[", ":", ",", "1", ":", "one3", ",", ":", "]", "\n", "audio_1_prev", "=", "audio", "[", ":", ",", "0", ":", "one3", "-", "1", ",", ":", "]", "\n", "audio_2", "=", "audio", "[", ":", ",", "one3", ":", "two3", ",", ":", "]", "\n", "audio_3", "=", "audio", "[", ":", ",", "two3", "+", "1", ":", ",", ":", "]", "\n", "audio_3_prev", "=", "audio", "[", ":", ",", "two3", ":", "-", "1", ",", ":", "]", "\n", "\n", "assert", "audio_1", ".", "shape", "==", "audio_1_prev", ".", "shape", "\n", "assert", "audio_3", ".", "shape", "==", "audio_3_prev", ".", "shape", "\n", "\n", "return", "{", "'input'", ":", "inp", ",", "\n", "'input_beg'", ":", "inp_beg", ",", "\n", "'input_end'", ":", "inp_end", ",", "\n", "'target_v'", ":", "target_v", "if", "self", ".", "visual", "else", "None", ",", "\n", "'target_prev_t'", ":", "target_prev_t", ",", "\n", "'target_t'", ":", "target_t", ",", "\n", "'audio'", ":", "audio", ",", "\n", "'audio_beg'", ":", "audio_beg", ",", "\n", "'audio_end'", ":", "audio_end", ",", "\n", "'audio_1'", ":", "audio_1", ",", "\n", "'audio_1_prev'", ":", "audio_1_prev", ",", "\n", "'audio_2'", ":", "audio_2", ",", "\n", "'audio_3_prev'", ":", "audio_3_prev", ",", "\n", "'audio_3'", ":", "audio_3", ",", "\n", "'speaker'", ":", "numpy", ".", "array", "(", "[", "x", "[", "'speaker'", "]", "for", "x", "in", "gr", "]", ")", ",", "\n", "'speaker_id'", ":", "numpy", ".", "array", "(", "[", "x", "[", "'speaker_id'", "]", "for", "x", "in", "gr", "]", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.__init__": [[188, 233], ["onion.util.autoassign", "simple_data.IdMapper", "sklearn.preprocessing.LabelEncoder", "simple_data.insideout", "simple_data.insideout", "simple_data.SimpleData.mapper.transform", "simple_data.SimpleData.scaler.fit_transform", "simple_data.SimpleData.speaker_encoder.fit", "simple_data.SimpleData.speaker_encoder.transform", "simple_data.outsidein", "simple_data.SimpleData.mapper.transform", "simple_data.SimpleData.mapper.transform", "simple_data.SimpleData.speaker_encoder.transform", "simple_data.outsidein", "simple_data.Batcher", "locals", "sklearn.preprocessing.StandardScaler", "simple_data.NoScaler", "simple_data.InputScaler", "simple_data.NoScaler", "simple_data.SimpleData.shuffled", "simple_data.SimpleData.shuffled", "list", "simple_data.SimpleData.mapper.transform", "simple_data.SimpleData.mapper.fit_transform", "simple_data.SimpleData.audio_scaler.fit_transform", "simple_data.SimpleData.scaler.transform", "simple_data.SimpleData.audio_scaler.transform", "simple_data.arrange", "simple_data.arrange", "simple_data.SimpleData.mapper.fit_transform", "simple_data.scale_utterance", "simple_data.scale_utterance", "provider.iterImages", "provider.iterImages"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.insideout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.insideout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.outsidein", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.outsidein", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.shuffled", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.shuffled", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.arrange", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.arrange", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.scale_utterance", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.scale_utterance", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterImages", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterImages"], ["def", "__init__", "(", "self", ",", "provider", ",", "tokenize", "=", "words", ",", "min_df", "=", "10", ",", "scale", "=", "True", ",", "scale_input", "=", "False", ",", "scale_utt", "=", "False", ",", "\n", "batch_size", "=", "64", ",", "shuffle", "=", "False", ",", "limit", "=", "None", ",", "curriculum", "=", "False", ",", "by_speaker", "=", "False", ",", "val_vocab", "=", "False", ",", "\n", "visual", "=", "True", ",", "erasure", "=", "5", ",", "midpoint", "=", "False", ",", "sigma", "=", "None", ",", "noise_tied", "=", "False", ",", "speakers", "=", "None", ")", ":", "\n", "        ", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "data", "=", "{", "}", "\n", "self", ".", "mapper", "=", "IdMapper", "(", "min_df", "=", "self", ".", "min_df", ")", "\n", "self", ".", "scaler", "=", "StandardScaler", "(", ")", "if", "scale", "else", "NoScaler", "(", ")", "\n", "self", ".", "audio_scaler", "=", "InputScaler", "(", ")", "if", "scale_input", "else", "NoScaler", "(", ")", "\n", "self", ".", "speaker_encoder", "=", "LabelEncoder", "(", ")", "\n", "parts", "=", "insideout", "(", "self", ".", "shuffled", "(", "arrange", "(", "provider", ".", "iterImages", "(", "split", "=", "'train'", ")", ",", "\n", "tokenize", "=", "self", ".", "tokenize", ",", "\n", "limit", "=", "limit", ",", "\n", "speakers", "=", "speakers", ")", ")", ")", "\n", "parts_val", "=", "insideout", "(", "self", ".", "shuffled", "(", "arrange", "(", "provider", ".", "iterImages", "(", "split", "=", "'val'", ")", ",", "tokenize", "=", "self", ".", "tokenize", ")", ")", ")", "\n", "# TRAINING", "\n", "if", "self", ".", "val_vocab", ":", "\n", "            ", "_", "=", "list", "(", "self", ".", "mapper", ".", "fit_transform", "(", "parts", "[", "'tokens_in'", "]", "+", "parts_val", "[", "'tokens_in'", "]", ")", ")", "\n", "parts", "[", "'tokens_in'", "]", "=", "self", ".", "mapper", ".", "transform", "(", "parts", "[", "'tokens_in'", "]", ")", "# FIXME UGLY HACK", "\n", "", "else", ":", "\n", "            ", "parts", "[", "'tokens_in'", "]", "=", "self", ".", "mapper", ".", "fit_transform", "(", "parts", "[", "'tokens_in'", "]", ")", "\n", "\n", "", "parts", "[", "'tokens_out'", "]", "=", "self", ".", "mapper", ".", "transform", "(", "parts", "[", "'tokens_out'", "]", ")", "\n", "parts", "[", "'img'", "]", "=", "self", ".", "scaler", ".", "fit_transform", "(", "parts", "[", "'img'", "]", ")", "\n", "self", ".", "speaker_encoder", ".", "fit", "(", "parts", "[", "'speaker'", "]", "+", "parts_val", "[", "'speaker'", "]", ")", "\n", "parts", "[", "'speaker_id'", "]", "=", "self", ".", "speaker_encoder", ".", "transform", "(", "parts", "[", "'speaker'", "]", ")", "\n", "if", "scale_input", ":", "\n", "            ", "parts", "[", "'audio'", "]", "=", "self", ".", "audio_scaler", ".", "fit_transform", "(", "parts", "[", "'audio'", "]", ")", "\n", "", "elif", "scale_utt", ":", "\n", "            ", "parts", "[", "'audio'", "]", "=", "scale_utterance", "(", "parts", "[", "'audio'", "]", ")", "\n", "\n", "", "self", ".", "data", "[", "'train'", "]", "=", "outsidein", "(", "parts", ")", "\n", "\n", "# VALIDATION", "\n", "parts_val", "[", "'tokens_in'", "]", "=", "self", ".", "mapper", ".", "transform", "(", "parts_val", "[", "'tokens_in'", "]", ")", "\n", "parts_val", "[", "'tokens_out'", "]", "=", "self", ".", "mapper", ".", "transform", "(", "parts_val", "[", "'tokens_out'", "]", ")", "\n", "if", "self", ".", "visual", ":", "\n", "            ", "parts_val", "[", "'img'", "]", "=", "self", ".", "scaler", ".", "transform", "(", "parts_val", "[", "'img'", "]", ")", "\n", "", "if", "scale_input", ":", "\n", "\n", "            ", "parts_val", "[", "'audio'", "]", "=", "self", ".", "audio_scaler", ".", "transform", "(", "parts_val", "[", "'audio'", "]", ")", "\n", "", "elif", "scale_utt", ":", "\n", "            ", "parts_val", "[", "'audio'", "]", "=", "scale_utterance", "(", "parts_val", "[", "'audio'", "]", ")", "\n", "", "parts_val", "[", "'speaker_id'", "]", "=", "self", ".", "speaker_encoder", ".", "transform", "(", "parts_val", "[", "'speaker'", "]", ")", "\n", "self", ".", "data", "[", "'valid'", "]", "=", "outsidein", "(", "parts_val", ")", "\n", "self", ".", "batcher", "=", "Batcher", "(", "self", ".", "mapper", ",", "pad_end", "=", "False", ",", "visual", "=", "visual", ",", "erasure", "=", "erasure", ",", "sigma", "=", "sigma", ",", "noise_tied", "=", "noise_tied", ",", "midpoint", "=", "midpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.shuffled": [[234, 241], ["copy.copy", "random.shuffle", "list"], "methods", ["None"], ["", "def", "shuffled", "(", "self", ",", "xs", ")", ":", "\n", "        ", "if", "not", "self", ".", "shuffle", ":", "\n", "            ", "return", "xs", "\n", "", "else", ":", "\n", "            ", "zs", "=", "copy", ".", "copy", "(", "list", "(", "xs", ")", ")", "\n", "random", ".", "shuffle", "(", "zs", ")", "\n", "return", "zs", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches": [[243, 259], ["simple_data.randomized", "onion.grouper", "simple_data.by_speaker", "simple_data.randomized", "onion.grouper", "numpy.argsort", "numpy.argsort", "simple_data.SimpleData.batcher.batch", "len", "len"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.randomized", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.by_speaker", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.randomized", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch"], ["", "", "def", "iter_train_batches", "(", "self", ",", "reshuffle", "=", "False", ")", ":", "\n", "# sort data by length", "\n", "        ", "if", "self", ".", "curriculum", ":", "\n", "            ", "data", "=", "[", "self", ".", "data", "[", "'train'", "]", "[", "i", "]", "for", "i", "in", "numpy", ".", "argsort", "(", "[", "len", "(", "x", "[", "'tokens_in'", "]", ")", "for", "x", "in", "self", ".", "data", "[", "'train'", "]", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "self", ".", "data", "[", "'train'", "]", "\n", "", "if", "self", ".", "by_speaker", ":", "\n", "            ", "for", "x", "in", "randomized", "(", "by_speaker", "(", "self", ".", "batcher", ",", "data", ")", ")", ":", "\n", "                ", "yield", "x", "\n", "", "", "else", ":", "\n", "            ", "if", "reshuffle", ":", "\n", "                ", "data", "=", "randomized", "(", "self", ".", "data", "[", "'train'", "]", ")", "\n", "", "for", "bunch", "in", "util", ".", "grouper", "(", "data", ",", "self", ".", "batch_size", "*", "20", ")", ":", "\n", "                ", "bunch_sort", "=", "[", "bunch", "[", "i", "]", "for", "i", "in", "numpy", ".", "argsort", "(", "[", "len", "(", "x", "[", "'tokens_in'", "]", ")", "for", "x", "in", "bunch", "]", ")", "]", "\n", "for", "item", "in", "util", ".", "grouper", "(", "bunch_sort", ",", "self", ".", "batch_size", ")", ":", "\n", "                    ", "yield", "self", ".", "batcher", ".", "batch", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_valid_batches": [[260, 269], ["simple_data.by_speaker", "onion.grouper", "onion.grouper", "numpy.argsort", "simple_data.SimpleData.batcher.batch", "len"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.by_speaker", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch"], ["", "", "", "", "def", "iter_valid_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "by_speaker", ":", "\n", "            ", "for", "x", "in", "by_speaker", "(", "self", ".", "batcher", ",", "self", ".", "data", "[", "'valid'", "]", ")", ":", "\n", "                ", "yield", "x", "\n", "", "", "else", ":", "\n", "            ", "for", "bunch", "in", "util", ".", "grouper", "(", "self", ".", "data", "[", "'valid'", "]", ",", "self", ".", "batch_size", "*", "20", ")", ":", "\n", "                ", "bunch_sort", "=", "[", "bunch", "[", "i", "]", "for", "i", "in", "numpy", ".", "argsort", "(", "[", "len", "(", "x", "[", "'tokens_in'", "]", ")", "for", "x", "in", "bunch", "]", ")", "]", "\n", "for", "item", "in", "util", ".", "grouper", "(", "bunch_sort", ",", "self", ".", "batch_size", ")", ":", "\n", "                    ", "yield", "self", ".", "batcher", ".", "batch", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.dump": [[271, 277], ["pickle.dump", "pickle.dump", "gzip.open", "gzip.open", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.dump", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.dump"], ["", "", "", "", "def", "dump", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "\"\"\"Write scaler and batcher to disc.\"\"\"", "\n", "pickle", ".", "dump", "(", "self", ".", "scaler", ",", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "'scaler.pkl.gz'", ")", ",", "'w'", ")", ",", "\n", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "batcher", ",", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "'batcher.pkl.gz'", ")", ",", "'w'", ")", ",", "\n", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.__init__": [[324, 328], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", "=", "{", "}", "\n", "self", ".", "decoder", "=", "{", "}", "\n", "self", ".", "max", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.to_id": [[329, 339], ["simple_data.IdTable.encoder.get"], "methods", ["None"], ["", "def", "to_id", "(", "self", ",", "s", ",", "default", "=", "None", ")", ":", "\n", "        ", "i", "=", "self", ".", "encoder", ".", "get", "(", "s", ",", "default", ")", "\n", "if", "i", "is", "not", "None", ":", "\n", "            ", "return", "i", "\n", "", "else", ":", "\n", "            ", "i", "=", "self", ".", "max", "\n", "self", ".", "encoder", "[", "s", "]", "=", "i", "\n", "self", ".", "decoder", "[", "i", "]", "=", "s", "\n", "self", ".", "max", "+=", "1", "\n", "return", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.from_id": [[340, 342], ["None"], "methods", ["None"], ["", "", "def", "from_id", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.__init__": [[346, 356], ["simple_data.IdTable", "simple_data.IdMapper.ids.to_id", "simple_data.IdMapper.ids.to_id", "simple_data.IdMapper.ids.to_id"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.to_id", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.to_id", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.to_id"], ["def", "__init__", "(", "self", ",", "min_df", "=", "1", ")", ":", "\n", "        ", "self", ".", "min_df", "=", "min_df", "\n", "self", ".", "freq", "=", "{", "}", "\n", "self", ".", "ids", "=", "IdTable", "(", ")", "\n", "self", ".", "BEG", "=", "'<BEG>'", "\n", "self", ".", "END", "=", "'<END>'", "\n", "self", ".", "UNK", "=", "'<UNK>'", "\n", "self", ".", "BEG_ID", "=", "self", ".", "ids", ".", "to_id", "(", "self", ".", "BEG", ")", "\n", "self", ".", "END_ID", "=", "self", ".", "ids", ".", "to_id", "(", "self", ".", "END", ")", "\n", "self", ".", "UNK_ID", "=", "self", ".", "ids", ".", "to_id", "(", "self", ".", "UNK", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size": [[357, 359], ["len"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit": [[360, 366], ["list", "set", "simple_data.IdMapper.freq.get"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"Prepare model by collecting counts from data.\"\"\"", "\n", "sents", "=", "list", "(", "sents", ")", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "for", "word", "in", "set", "(", "sent", ")", ":", "\n", "                ", "self", ".", "freq", "[", "word", "]", "=", "self", ".", "freq", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform": [[369, 374], ["list", "simple_data.IdMapper.fit", "simple_data.IdMapper._transform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper._transform"], ["", "", "", "def", "fit_transform", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"Map each word in sents to a unique int, adding new words.\"\"\"", "\n", "sents", "=", "list", "(", "sents", ")", "\n", "self", ".", "fit", "(", "sents", ")", "\n", "return", "self", ".", "_transform", "(", "sents", ",", "update", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform": [[375, 378], ["simple_data.IdMapper._transform"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper._transform"], ["", "def", "transform", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"Map each word in sents to a unique int, without adding new words.\"\"\"", "\n", "return", "self", ".", "_transform", "(", "sents", ",", "update", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper._transform": [[379, 389], ["simple_data.IdMapper.freq.get", "ids.append", "ids.append", "simple_data.IdMapper.ids.to_id"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.to_id"], ["", "def", "_transform", "(", "self", ",", "sents", ",", "update", "=", "False", ")", ":", "\n", "        ", "default", "=", "None", "if", "update", "else", "self", ".", "UNK_ID", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "ids", "=", "[", "]", "\n", "for", "word", "in", "sent", ":", "\n", "                ", "if", "self", ".", "freq", ".", "get", "(", "word", ",", "0", ")", "<", "self", ".", "min_df", ":", "\n", "                    ", "ids", ".", "append", "(", "self", ".", "UNK_ID", ")", "\n", "", "else", ":", "\n", "                    ", "ids", ".", "append", "(", "self", ".", "ids", ".", "to_id", "(", "word", ",", "default", "=", "default", ")", ")", "\n", "", "", "yield", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.inverse_transform": [[390, 394], ["simple_data.IdMapper.ids.from_id"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdTable.from_id"], ["", "", "def", "inverse_transform", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"Map each id in sents to the corresponding word.\"\"\"", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "yield", "[", "self", ".", "ids", ".", "from_id", "(", "i", ")", "for", "i", "in", "sent", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.words": [[15, 17], ["None"], "function", ["None"], ["def", "words", "(", "sentence", ")", ":", "\n", "    ", "return", "sentence", "[", "'tokens'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.characters": [[18, 20], ["list"], "function", ["None"], ["", "def", "characters", "(", "sentence", ")", ":", "\n", "    ", "return", "list", "(", "sentence", "[", "'raw'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.compressed": [[21, 23], ["c.lower"], "function", ["None"], ["", "def", "compressed", "(", "sentence", ")", ":", "\n", "    ", "return", "[", "c", ".", "lower", "(", ")", "for", "c", "in", "sentence", "[", "'raw'", "]", "if", "c", "in", "string", ".", "letters", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.phonemes": [[24, 26], ["None"], "function", ["None"], ["", "def", "phonemes", "(", "sentence", ")", ":", "\n", "    ", "return", "[", "pho", "for", "pho", "in", "sentence", "[", "'ipa'", "]", "if", "pho", "!=", "\"*\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.transcription": [[27, 29], ["list"], "function", ["None"], ["", "def", "transcription", "(", "sentence", ")", ":", "\n", "    ", "return", "list", "(", "sentence", "[", "'transcription'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder": [[56, 67], ["max", "numpy.array", "map", "numpy.vstack", "numpy.zeros", "len"], "function", ["None"], ["", "", "def", "vector_padder", "(", "vecs", ")", ":", "\n", "        ", "\"\"\"Pads each vector in vecs with zeros at the beginning. Returns 3D tensor with dimensions:\n           (BATCH_SIZE, SAMPLE_LENGTH, NUMBER_FEATURES).\n        \"\"\"", "\n", "\n", "max_len", "=", "max", "(", "map", "(", "len", ",", "vecs", ")", ")", "\n", "#for vec in vecs:", "\n", "#    assert len(vec.shape) == 2, \"Broken vector {}\".format(vec)", "\n", "\n", "return", "numpy", ".", "array", "(", "[", "numpy", ".", "vstack", "(", "[", "numpy", ".", "zeros", "(", "(", "max_len", "-", "len", "(", "vec", ")", ",", "vec", ".", "shape", "[", "1", "]", ")", ")", ",", "vec", "]", ")", "\n", "for", "vec", "in", "vecs", "]", ",", "dtype", "=", "'float32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.midpoint": [[175, 177], ["None"], "function", ["None"], ["", "", "def", "midpoint", "(", "L_tot", ",", "L_pad", ")", ":", "\n", "    ", "return", "(", "L_tot", "-", "L_pad", ")", "//", "2", "+", "L_pad", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.scale_utterance": [[178, 185], ["datum.mean", "datum.std", "simple_data.scale_utterance.scale"], "function", ["None"], ["", "def", "scale_utterance", "(", "data", ")", ":", "\n", "    ", "def", "scale", "(", "datum", ")", ":", "\n", "# time x feature", "\n", "        ", "mu", "=", "datum", ".", "mean", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "sigma", "=", "datum", ".", "std", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "(", "datum", "-", "mu", ")", "/", "sigma", "\n", "", "return", "[", "scale", "(", "datum", ")", "for", "datum", "in", "data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.by_speaker": [[278, 283], ["itertools.groupby", "sorted", "onion.grouper", "batcher.batch"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch"], ["", "", "def", "by_speaker", "(", "batcher", ",", "data", ",", "batch_size", "=", "32", ")", ":", "\n", "      ", "speaker", "=", "lambda", "x", ":", "x", "[", "'speaker'", "]", "\n", "for", "_", ",", "bunch", "in", "itertools", ".", "groupby", "(", "sorted", "(", "data", ",", "key", "=", "speaker", ")", ",", "speaker", ")", ":", "\n", "          ", "for", "item", "in", "util", ".", "grouper", "(", "bunch", ",", "batch_size", ")", ":", "\n", "             ", "yield", "batcher", ".", "batch", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.randomized": [[284, 286], ["sorted", "random.random"], "function", ["None"], ["", "", "", "def", "randomized", "(", "data", ")", ":", "\n", "    ", "return", "sorted", "(", "data", ",", "key", "=", "lambda", "_", ":", "random", ".", "random", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.arrange": [[287, 300], ["enumerate", "sent.get", "tokenize", "sent.get", "image.get"], "function", ["None"], ["", "def", "arrange", "(", "data", ",", "tokenize", "=", "words", ",", "limit", "=", "None", ",", "speakers", "=", "None", ")", ":", "\n", "    ", "for", "i", ",", "image", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "if", "limit", "is", "not", "None", "and", "i", ">", "limit", ":", "\n", "            ", "break", "\n", "", "for", "sent", "in", "image", "[", "'sentences'", "]", ":", "\n", "            ", "speaker", "=", "sent", ".", "get", "(", "'speaker'", ")", "\n", "if", "speakers", "is", "None", "or", "speaker", "in", "speakers", ":", "\n", "                ", "toks", "=", "tokenize", "(", "sent", ")", "\n", "yield", "{", "'tokens_in'", ":", "toks", ",", "\n", "'tokens_out'", ":", "toks", ",", "\n", "'audio'", ":", "sent", ".", "get", "(", "'audio'", ")", ",", "\n", "'img'", ":", "image", ".", "get", "(", "'feat'", ")", ",", "\n", "'speaker'", ":", "speaker", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.insideout": [[303, 311], ["list", "dict", "d.items", "result[].append", "ds[].keys"], "function", ["None"], ["", "", "", "", "def", "insideout", "(", "ds", ")", ":", "\n", "    ", "\"\"\"Transform a list of dictionaries to a dictionary of lists.\"\"\"", "\n", "ds", "=", "list", "(", "ds", ")", "\n", "result", "=", "dict", "(", "[", "(", "k", ",", "[", "]", ")", "for", "k", "in", "ds", "[", "0", "]", ".", "keys", "(", ")", "]", ")", "\n", "for", "d", "in", "ds", ":", "\n", "        ", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "result", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.outsidein": [[312, 321], ["d.keys", "range", "list", "len", "ds.append", "dict", "list", "d.values"], "function", ["None"], ["", "def", "outsidein", "(", "d", ")", ":", "\n", "    ", "\"\"\"Transform a dictionary of lists to a list of dictionaries.\"\"\"", "\n", "ds", "=", "[", "]", "\n", "keys", "=", "d", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "d", "[", "key", "]", "=", "list", "(", "d", "[", "key", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "list", "(", "d", ".", "values", "(", ")", ")", "[", "0", "]", ")", ")", ":", "\n", "        ", "ds", ".", "append", "(", "dict", "(", "[", "(", "k", ",", "d", "[", "k", "]", "[", "i", "]", ")", "for", "k", "in", "keys", "]", ")", ")", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.Provider.__init__": [[18, 32], ["libri_provider.load_mfcc", "dict", "dict", "set", "logging.info", "sklearn.utils.resample", "len", "len", "dict.items", "list", "csv.reader", "libri_provider.Provider.meta.keys", "row[].split", "open"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.load_mfcc"], ["  ", "def", "__init__", "(", "self", ",", "dataset", ",", "root", "=", "'.'", ",", "audio_kind", "=", "'mfcc'", ",", "truncate", "=", "None", ")", ":", "\n", "    ", "assert", "dataset", "==", "'libri'", "\n", "assert", "audio_kind", "==", "'mfcc'", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "dataset_name", "=", "dataset", "\n", "self", ".", "audio_kind", "=", "audio_kind", "\n", "self", ".", "truncate", "=", "truncate", "\n", "self", ".", "audiopath", "=", "\"{}/data/libri/mfcc/libri_*.npy\"", ".", "format", "(", "self", ".", "root", ")", "\n", "self", ".", "metapath", "=", "\"{}/data/libri/libri.csv\"", ".", "format", "(", "self", ".", "root", ")", "\n", "self", ".", "audio", "=", "load_mfcc", "(", "self", ".", "audiopath", ")", "\n", "meta_all", "=", "dict", "(", "[", "(", "row", "[", "0", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ",", "row", "[", "1", ":", "]", ")", "for", "row", "in", "csv", ".", "reader", "(", "open", "(", "\"{}/data/libri/libri.csv\"", ".", "format", "(", "self", ".", "root", ")", ")", ",", "delimiter", "=", "'\\t'", ")", "]", "[", "1", ":", "]", ")", "\n", "self", ".", "meta", "=", "dict", "(", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "meta_all", ".", "items", "(", ")", "if", "k", "in", "self", ".", "audio", ")", "\n", "self", ".", "val", "=", "set", "(", "resample", "(", "list", "(", "self", ".", "meta", ".", "keys", "(", ")", ")", ",", "replace", "=", "False", ",", "random_state", "=", "123", ")", "[", ":", "1000", "]", ")", "\n", "logging", ".", "info", "(", "\"{} items in libri.csv, {} items in mfcc\"", ".", "format", "(", "len", "(", "meta_all", ")", ",", "len", "(", "self", ".", "audio", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.Provider.iterSentences": [[34, 51], ["sorted", "libri_provider.Provider.meta.keys", "libri_provider.Provider.meta.keys", "dict", "numpy.random.random", "[].split"], "methods", ["None"], ["", "def", "iterSentences", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "assert", "split", "in", "[", "'train'", ",", "'val'", "]", "\n", "if", "shuffle", ":", "\n", "        ", "ID", "=", "sorted", "(", "self", ".", "meta", ".", "keys", "(", ")", ",", "key", "=", "lambda", "_", ":", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "ID", "=", "self", ".", "meta", ".", "keys", "(", ")", "\n", "", "for", "uttid", "in", "ID", ":", "\n", "        ", "if", "(", "split", "==", "'val'", "and", "uttid", "in", "self", ".", "val", ")", "or", "(", "split", "==", "'train'", "and", "uttid", "not", "in", "self", ".", "val", ")", ":", "\n", "\n", "                ", "sent", "=", "dict", "(", "tokens", "=", "self", ".", "meta", "[", "uttid", "]", "[", "2", "]", ".", "split", "(", ")", ",", "\n", "raw", "=", "self", ".", "meta", "[", "uttid", "]", "[", "2", "]", ",", "\n", "audio", "=", "self", ".", "audio", "[", "uttid", "]", "[", ":", "self", ".", "truncate", ",", ":", "]", "if", "self", ".", "truncate", "is", "not", "None", "\n", "else", "self", ".", "audio", "[", "uttid", "]", ",", "\n", "sentid", "=", "uttid", ",", "\n", "chapter", "=", "self", ".", "meta", "[", "uttid", "]", "[", "1", "]", ",", "\n", "speaker", "=", "\"libri_\"", "+", "self", ".", "meta", "[", "uttid", "]", "[", "0", "]", ")", "\n", "yield", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.Provider.iterImages": [[52, 56], ["libri_provider.Provider.iterSentences", "dict"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterSentences"], ["", "", "", "def", "iterImages", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "# For compatibility. There are no images in this dataset", "\n", "    ", "for", "sent", "in", "self", ".", "iterSentences", "(", "split", "=", "split", ",", "shuffle", "=", "shuffle", ")", ":", "\n", "        ", "yield", "dict", "(", "sentences", "=", "[", "sent", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.load_mfcc": [[12, 15], ["functools.reduce", "numpy.load().item", "glob.glob", "numpy.load"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["def", "load_mfcc", "(", "path", ")", ":", "\n", "    ", "L", "=", "(", "np", ".", "load", "(", "f", ")", ".", "item", "(", "0", ")", "for", "f", "in", "glob", ".", "glob", "(", "path", ")", ")", "\n", "return", "reduce", "(", "lambda", "x", ",", "z", ":", "{", "**", "x", ",", "**", "z", "}", ",", "L", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.libri_provider.getDataProvider": [[57, 59], ["libri_provider.Provider"], "function", ["None"], ["", "", "", "def", "getDataProvider", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t", "return", "Provider", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider.__init__": [[13, 44], ["numpy.load().item", "numpy.array", "numpy.array", "dict", "json.load", "set", "list", "list", "list", "open", "enumerate", "numpy.load", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "csv.reader", "csv.reader", "flickr8k_provider.Provider.speakers.add", "open", "open", "logging.warning", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["  ", "def", "__init__", "(", "self", ",", "dataset", ",", "root", "=", "'.'", ",", "audio_kind", "=", "'mfcc'", ",", "truncate", "=", "None", ")", ":", "\n", "    ", "assert", "dataset", "==", "'flickr8k'", "\n", "assert", "audio_kind", "==", "'mfcc'", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "dataset_name", "=", "dataset", "\n", "self", ".", "audio_kind", "=", "audio_kind", "\n", "self", ".", "truncate", "=", "truncate", "\n", "self", ".", "audiofile", "=", "\"{}/data/flickr8k/flickr8k_mfcc.npy\"", ".", "format", "(", "self", ".", "root", ")", "\n", "self", ".", "audio", "=", "np", ".", "load", "(", "self", ".", "audiofile", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", "0", ")", "\n", "self", ".", "img_feat", "=", "scipy", ".", "io", ".", "loadmat", "(", "self", ".", "root", "+", "'/data/flickr8k/vgg_feats.mat'", ")", "[", "'feats'", "]", ".", "T", "\n", "wav2spk", "=", "np", ".", "array", "(", "list", "(", "csv", ".", "reader", "(", "open", "(", "self", ".", "root", "+", "\"/data/flickr8k/wav2spk.txt\"", ")", ",", "delimiter", "=", "' '", ")", ")", ")", "\n", "wav2cap", "=", "np", ".", "array", "(", "list", "(", "csv", ".", "reader", "(", "open", "(", "self", ".", "root", "+", "\"/data/flickr8k/wav2capt.txt\"", ")", ",", "delimiter", "=", "' '", ")", ")", ")", "\n", "cap2wav", "=", "{", "}", "\n", "for", "row", "in", "wav2cap", ":", "\n", "        ", "cap2wav", "[", "row", "[", "1", "]", "+", "row", "[", "2", "]", "]", "=", "row", "[", "0", "]", "\n", "", "W2S", "=", "dict", "(", "list", "(", "wav2spk", ")", ")", "\n", "self", ".", "dataset", "=", "json", ".", "load", "(", "open", "(", "self", ".", "root", "+", "\"/data/flickr8k/dataset.json\"", ",", "'r'", ")", ")", "\n", "self", ".", "speakers", "=", "set", "(", ")", "\n", "\n", "for", "image", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "            ", "image", "[", "'feat'", "]", "=", "self", ".", "img_feat", "[", "image", "[", "'imgid'", "]", "]", "\n", "for", "(", "i", ",", "sentence", ")", "in", "enumerate", "(", "image", "[", "'sentences'", "]", ")", ":", "\n", "                ", "uttid", "=", "cap2wav", "[", "\"{}#{}\"", ".", "format", "(", "image", "[", "'filename'", "]", ",", "i", ")", "]", "\n", "\n", "if", "uttid", "not", "in", "self", ".", "audio", ":", "\n", "                    ", "logging", ".", "warning", "(", "\"No MFCC features, using dummy zeros for {}\"", ".", "format", "(", "uttid", ")", ")", "\n", "sentence", "[", "'audio'", "]", "=", "np", ".", "zeros", "(", "(", "10", ",", "13", ")", ")", "\n", "", "else", ":", "\n", "                    ", "sentence", "[", "'audio'", "]", "=", "self", ".", "audio", "[", "uttid", "]", "if", "self", ".", "truncate", "is", "None", "else", "self", ".", "audio", "[", "uttid", "]", "[", ":", "self", ".", "truncate", ",", ":", "]", "\n", "", "sentence", "[", "'speaker'", "]", "=", "\"flickr8k_\"", "+", "W2S", "[", "uttid", "]", "\n", "self", ".", "speakers", ".", "add", "(", "sentence", "[", "'speaker'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterImages": [[46, 50], ["None"], "methods", ["None"], ["", "", "", "def", "_iterImages", "(", "self", ",", "split", ")", ":", "\n", "        ", "for", "image", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "            ", "if", "image", "[", "'split'", "]", "==", "split", ":", "\n", "                ", "yield", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterSentences": [[51, 55], ["flickr8k_provider.Provider._iterImages"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterImages"], ["", "", "", "def", "_iterSentences", "(", "self", ",", "split", ")", ":", "\n", "        ", "for", "image", "in", "self", ".", "_iterImages", "(", "split", ")", ":", "\n", "            ", "for", "sent", "in", "image", "[", "'sentences'", "]", ":", "\n", "                ", "yield", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider.iterImages": [[56, 61], ["flickr8k_provider.Provider._iterImages", "sorted", "flickr8k_provider.Provider._iterImages", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterImages", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterImages"], ["", "", "", "def", "iterImages", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "if", "not", "shuffle", ":", "\n", "            ", "return", "self", ".", "_iterImages", "(", "split", ")", "\n", "", "else", ":", "\n", "            ", "return", "sorted", "(", "self", ".", "_iterImages", "(", "split", ")", ",", "key", "=", "lambda", "_", ":", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider.iterSentences": [[62, 67], ["flickr8k_provider.Provider._iterSentences", "sorted", "flickr8k_provider.Provider._iterSentences", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterSentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.Provider._iterSentences"], ["", "", "def", "iterSentences", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "if", "not", "shuffle", ":", "\n", "            ", "return", "self", ".", "_iterSentences", "(", "split", ")", "\n", "", "else", ":", "\n", "            ", "return", "sorted", "(", "self", ".", "_iterSentences", "(", "split", ")", ",", "key", "=", "lambda", "_", ":", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.touttid": [[68, 71], ["key.split"], "function", ["None"], ["", "", "", "def", "touttid", "(", "key", ")", ":", "\n", "    ", "a", ",", "b", ",", "c", "=", "key", ".", "split", "(", "'_'", ")", "\n", "return", "\"{}_{}_{}.wav\"", ".", "format", "(", "a", ",", "b", ",", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.flickr8k_provider.getDataProvider": [[72, 74], ["flickr8k_provider.Provider"], "function", ["None"], ["", "def", "getDataProvider", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t", "return", "Provider", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.evaluate.paraphrase_ranking": [[6, 9], ["evaluate.ranking"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.evaluate.ranking"], ["def", "paraphrase_ranking", "(", "vectors", ",", "group", ",", "ns", "=", "(", "1", ",", "5", ",", "10", ")", ",", "metric", "=", "'cosine'", ")", ":", "\n", "    ", "\"\"\"Rank sentences by projection and return evaluation metrics.\"\"\"", "\n", "return", "ranking", "(", "vectors", ",", "vectors", ",", "group", ",", "ns", "=", "ns", ",", "exclude_self", "=", "True", ",", "metric", "=", "metric", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.evaluate.ranking": [[10, 37], ["scipy.spatial.distance.cdist", "enumerate", "numpy.argsort", "result[].append", "numpy.where", "len", "[].append", "[].append", "[].append", "set().intersection", "set", "len", "set"], "function", ["None"], ["", "def", "ranking", "(", "candidates", ",", "vectors", ",", "correct", ",", "ns", "=", "(", "1", ",", "5", ",", "10", ")", ",", "exclude_self", "=", "False", ",", "metric", "=", "'cosine'", ")", ":", "\n", "    ", "\"\"\"Rank `candidates` in order of similarity for each vector and return evaluation metrics.\n\n    `correct[i][j]` indicates whether for vector i the candidate j is correct.\n    \"\"\"", "\n", "distances", "=", "cdist", "(", "vectors", ",", "candidates", ",", "metric", "=", "metric", ")", "\n", "#distances = Cdist(batch_size=2**13)(vectors, candidates)", "\n", "result", "=", "{", "'ranks'", ":", "[", "]", ",", "'precision'", ":", "{", "}", ",", "'recall'", ":", "{", "}", ",", "'overlap'", ":", "{", "}", "}", "\n", "for", "n", "in", "ns", ":", "\n", "        ", "result", "[", "'precision'", "]", "[", "n", "]", "=", "[", "]", "\n", "result", "[", "'recall'", "]", "[", "n", "]", "=", "[", "]", "\n", "result", "[", "'overlap'", "]", "[", "n", "]", "=", "[", "]", "\n", "", "for", "j", ",", "row", "in", "enumerate", "(", "distances", ")", ":", "\n", "        ", "ranked", "=", "numpy", ".", "argsort", "(", "row", ")", "\n", "if", "exclude_self", ":", "\n", "            ", "ranked", "=", "ranked", "[", "ranked", "!=", "j", "]", "\n", "", "id_correct", "=", "numpy", ".", "where", "(", "correct", "[", "j", "]", "[", "ranked", "]", ")", "[", "0", "]", "\n", "rank1", "=", "id_correct", "[", "0", "]", "+", "1", "\n", "topn", "=", "{", "}", "\n", "for", "n", "in", "ns", ":", "\n", "            ", "id_topn", "=", "ranked", "[", ":", "n", "]", "\n", "overlap", "=", "len", "(", "set", "(", "id_topn", ")", ".", "intersection", "(", "set", "(", "ranked", "[", "id_correct", "]", ")", ")", ")", "\n", "result", "[", "'precision'", "]", "[", "n", "]", ".", "append", "(", "overlap", "/", "n", ")", "\n", "result", "[", "'recall'", "]", "[", "n", "]", ".", "append", "(", "overlap", "/", "len", "(", "id_correct", ")", ")", "\n", "result", "[", "'overlap'", "]", "[", "n", "]", ".", "append", "(", "overlap", ")", "\n", "", "result", "[", "'ranks'", "]", ".", "append", "(", "rank1", ")", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.params": [[12, 14], ["None"], "methods", ["None"], ["def", "params", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.weights": [[15, 17], ["param.data.cpu().numpy", "bundle.Bundle.params", "param.data.cpu"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.params"], ["", "def", "weights", "(", "self", ")", ":", "\n", "        ", "return", "[", "param", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "param", "in", "self", ".", "params", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.get_config": [[18, 20], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.get_data": [[21, 23], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedEr", "\n", "", "def", "save", "(", "self", ",", "path", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save": [[23, 33], ["zipfile.ZipFile", "io.BytesIO", "numpy.save", "zipfile.ZipFile.writestr", "zipfile.ZipFile.writestr", "zipfile.ZipFile.writestr", "bundle.Bundle.weights", "io.BytesIO.getvalue", "json.dumps", "pickle.dumps", "bundle.Bundle.get_config", "bundle.Bundle.get_data"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.weights", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.get_config", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.get_data"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "zf", "=", "zipfile", ".", "ZipFile", "(", "path", ",", "'w'", ")", "\n", "buf", "=", "io", ".", "BytesIO", "(", ")", "\n", "numpy", ".", "save", "(", "buf", ",", "self", ".", "weights", "(", ")", ")", "\n", "zf", ".", "writestr", "(", "'weights.npy'", ",", "buf", ".", "getvalue", "(", ")", ",", "\n", "compress_type", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "\n", "zf", ".", "writestr", "(", "'config.json'", ",", "json", ".", "dumps", "(", "self", ".", "get_config", "(", ")", ")", ",", "\n", "compress_type", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "\n", "zf", ".", "writestr", "(", "'data.pkl'", ",", "pickle", ".", "dumps", "(", "self", ".", "get_data", "(", ")", ")", ",", "\n", "compress_type", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.__init__": [[36, 51], ["list", "task", "pickle.dumps", "config.get", "bundle.GenericBundle.data[].mapper.size", "zip", "len", "len", "bundle.GenericBundle.params", "torch.from_numpy", "list", "bundle.GenericBundle.task.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.params"], ["def", "__init__", "(", "self", ",", "data", ",", "config", ",", "task", ",", "weights", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "config", "[", "'task'", "]", "=", "list", "(", "pickle", ".", "dumps", "(", "task", ")", ")", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "batcher", "=", "data", "[", "'batcher'", "]", "\n", "self", ".", "scaler", "=", "data", "[", "'scaler'", "]", "\n", "if", "config", ".", "get", "(", "'size_vocab'", ")", "is", "None", ":", "\n", "            ", "self", ".", "config", "[", "'size_vocab'", "]", "=", "self", ".", "data", "[", "'batcher'", "]", ".", "mapper", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "config", "[", "'size_vocab'", "]", "=", "config", "[", "'size_vocab'", "]", "\n", "", "self", ".", "task", "=", "task", "(", "config", ")", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "list", "(", "self", ".", "task", ".", "parameters", "(", ")", ")", ")", "==", "len", "(", "weights", ")", "\n", "for", "param", ",", "weight", "in", "zip", "(", "self", ".", "params", "(", ")", ",", "weights", ")", ":", "\n", "                ", "param", ".", "data", "=", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "#        self.task.compile()", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.params": [[55, 57], ["bundle.GenericBundle.task.parameters"], "methods", ["None"], ["", "", "", "def", "params", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "task", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.get_config": [[58, 60], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.GenericBundle.get_data": [[61, 63], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.load": [[66, 75], ["bundle.GenericBundle", "zipfile.ZipFile", "io.BytesIO", "numpy.load", "json.loads", "pickle.loads", "pickle.loads", "zf.read", "zf.read().decode", "zf.read", "bytes", "zf.read"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["", "", "def", "load", "(", "path", ")", ":", "\n", "    ", "\"\"\"Load data and reconstruct model.\"\"\"", "\n", "with", "zipfile", ".", "ZipFile", "(", "path", ",", "'r'", ")", "as", "zf", ":", "\n", "        ", "buf", "=", "io", ".", "BytesIO", "(", "zf", ".", "read", "(", "'weights.npy'", ")", ")", "\n", "weights", "=", "numpy", ".", "load", "(", "buf", ",", "encoding", "=", "'bytes'", ")", "\n", "config", "=", "json", ".", "loads", "(", "zf", ".", "read", "(", "'config.json'", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "data", "=", "pickle", ".", "loads", "(", "zf", ".", "read", "(", "'data.pkl'", ")", ")", "\n", "task", "=", "pickle", ".", "loads", "(", "bytes", "(", "config", "[", "'task'", "]", ")", ")", "\n", "", "return", "GenericBundle", "(", "data", ",", "config", ",", "task", ",", "weights", "=", "weights", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.__init__": [[16, 39], ["places_provider.parse_map", "places_provider.parse_map", "places_provider.parse_map", "places_provider.parse_map", "dict", "numpy.load().item", "set", "open", "open", "open", "open", "dict", "set", "set", "numpy.load", "line.split", "open", "places_provider.Provider.utt2spk.values", "line.strip", "line.strip", "zip", "open", "open", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["  ", "def", "__init__", "(", "self", ",", "dataset", ",", "root", "=", "'.'", ",", "audio_kind", "=", "'mfcc'", ",", "truncate", "=", "None", ",", "load_images", "=", "True", ")", ":", "\n", "    ", "assert", "dataset", "==", "'places'", "\n", "assert", "audio_kind", "==", "'mfcc'", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "dataset_name", "=", "dataset", "\n", "self", ".", "audio_kind", "=", "audio_kind", "\n", "self", ".", "truncate", "=", "truncate", "\n", "self", ".", "audiofile", "=", "\"{}/data/places/places_mfcc.npy\"", ".", "format", "(", "self", ".", "root", ")", "\n", "self", ".", "imagefile", "=", "\"{}/data/places/placeimgsfeatsvgg19.npy\"", ".", "format", "(", "self", ".", "root", ")", "\n", "\n", "self", ".", "utt2ASR", "=", "parse_map", "(", "open", "(", "\"{}/data/places/metadata/utt2ASR\"", ".", "format", "(", "self", ".", "root", ")", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "self", ".", "utt2wav", "=", "parse_map", "(", "open", "(", "\"{}/data/places/metadata/utt2wav\"", ".", "format", "(", "self", ".", "root", ")", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "self", ".", "utt2image", "=", "parse_map", "(", "open", "(", "\"{}/data/places/metadata/utt2image\"", ".", "format", "(", "self", ".", "root", ")", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "self", ".", "utt2spk", "=", "parse_map", "(", "open", "(", "\"{}/data/places/metadata/utt2spk\"", ".", "format", "(", "self", ".", "root", ")", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "self", ".", "id", "=", "dict", "(", "train", "=", "set", "(", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "\"{}/data/places/lists/acl_2017_train_uttids\"", ".", "format", "(", "self", ".", "root", ")", ")", ")", ",", "\n", "val", "=", "set", "(", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "\"{}/data/places/lists/acl_2017_val_uttids\"", ".", "format", "(", "self", ".", "root", ")", ")", ")", ")", "\n", "self", ".", "audio", "=", "np", ".", "load", "(", "self", ".", "audiofile", ")", ".", "item", "(", "0", ")", "\n", "self", ".", "imageid", "=", "[", "line", ".", "split", "(", ")", "[", "1", "]", "for", "line", "in", "open", "(", "\"{}/data/places/metadata/utt2image\"", ".", "format", "(", "self", ".", "root", ")", ",", "encoding", "=", "'utf-8'", ")", "]", "\n", "if", "load_images", ":", "\n", "        ", "self", ".", "images", "=", "dict", "(", "(", "imgid", ",", "feat", ")", "for", "imgid", ",", "feat", "in", "zip", "(", "self", ".", "imageid", ",", "np", ".", "load", "(", "self", ".", "imagefile", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "images", "=", "{", "}", "\n", "", "self", ".", "speakers", "=", "set", "(", "\"places_\"", "+", "x", "for", "x", "in", "self", ".", "utt2spk", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterImages": [[40, 45], ["places_provider.Provider.iterSentences", "dict", "places_provider.Provider.images.get"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterSentences"], ["", "def", "iterImages", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "\n", "    ", "for", "sent", "in", "self", ".", "iterSentences", "(", "split", "=", "split", ",", "shuffle", "=", "shuffle", ")", ":", "\n", "        ", "image", "=", "dict", "(", "sentences", "=", "[", "sent", "]", ",", "imgid", "=", "sent", "[", "'imgid'", "]", ",", "feat", "=", "self", ".", "images", ".", "get", "(", "sent", "[", "'imgid'", "]", ")", ")", "\n", "yield", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterSentences": [[46, 60], ["sorted", "dict", "places_provider.Provider.utt2ASR[].split", "numpy.random.random"], "methods", ["None"], ["", "", "def", "iterSentences", "(", "self", ",", "split", "=", "'train'", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "if", "shuffle", ":", "\n", "        ", "ID", "=", "sorted", "(", "self", ".", "id", "[", "split", "]", ",", "key", "=", "lambda", "_", ":", "np", ".", "random", ".", "random", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "ID", "=", "self", ".", "id", "[", "split", "]", "\n", "", "for", "uttid", "in", "ID", ":", "\n", "        ", "sent", "=", "dict", "(", "tokens", "=", "self", ".", "utt2ASR", "[", "uttid", "]", ".", "split", "(", ")", ",", "\n", "raw", "=", "self", ".", "utt2ASR", "[", "uttid", "]", ",", "\n", "imgid", "=", "self", ".", "utt2image", "[", "uttid", "]", ",", "\n", "audio", "=", "self", ".", "audio", "[", "uttid", "]", "[", ":", "self", ".", "truncate", ",", ":", "]", "if", "self", ".", "truncate", "is", "not", "None", "\n", "else", "self", ".", "audio", "[", "uttid", "]", ",", "\n", "sentid", "=", "uttid", ",", "\n", "speaker", "=", "\"places_\"", "+", "self", ".", "utt2spk", "[", "uttid", "]", ")", "\n", "yield", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.parse_map": [[7, 13], ["line.split"], "function", ["None"], ["def", "parse_map", "(", "lines", ")", ":", "\n", "    ", "M", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "fields", "=", "line", ".", "split", "(", ")", "\n", "M", "[", "fields", "[", "0", "]", "]", "=", "' '", ".", "join", "(", "fields", "[", "1", ":", "]", ")", "\n", "", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.getDataProvider": [[63, 65], ["places_provider.Provider"], "function", ["None"], ["", "", "", "def", "getDataProvider", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t", "return", "Provider", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.mfcc.extract_mfcc": [[5, 10], ["soundfile.read", "python_speech_features.mfcc", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.None.preprocess.mfcc"], ["def", "extract_mfcc", "(", "f", ",", "truncate", "=", "20", ",", "nfft", "=", "512", ")", ":", "\n", "    ", "(", "sig", ",", "rate", ")", "=", "sf", ".", "read", "(", "f", ")", "\n", "max_len", "=", "truncate", "*", "rate", "\n", "mfcc_feat", "=", "psf", ".", "mfcc", "(", "sig", "[", ":", "max_len", "]", ",", "samplerate", "=", "rate", ",", "nfft", "=", "nfft", ")", "\n", "return", "np", ".", "asarray", "(", "mfcc_feat", ",", "dtype", "=", "'float32'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.from_audio": [[10, 25], ["vg.activations.from_audio", "zip", "align.align", "align.phoneme_activations", "labels.append", "states.append", "numpy.concatenate", "numpy.concatenate", "zip"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.from_audio", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.align", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.phoneme_activations"], ["def", "from_audio", "(", "modelpath", ",", "audiopaths", ",", "transcripts", ")", ":", "\n", "# Align audio files", "\n", "    ", "alignments", "=", "[", "align", "(", "audiopath", ",", "transcript", ")", "for", "audiopath", ",", "transcript", "in", "zip", "(", "audiopaths", ",", "transcripts", ")", "]", "\n", "# Get activations", "\n", "activations", "=", "vg", ".", "activations", ".", "from_audio", "(", "modelpath", ",", "audiopaths", ")", "\n", "# Return data", "\n", "labels", "=", "[", "]", "\n", "states", "=", "[", "]", "\n", "\n", "for", "activation", ",", "alignment", "in", "zip", "(", "activations", ",", "alignments", ")", ":", "\n", "# extract phoneme labels and activations for current utterance", "\n", "        ", "y", ",", "X", "=", "phoneme_activations", "(", "activation", ",", "alignment", ")", "\n", "labels", ".", "append", "(", "y", ")", "\n", "states", ".", "append", "(", "X", ")", "\n", "", "return", "np", ".", "concatenate", "(", "labels", ")", ",", "np", ".", "concatenate", "(", "states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.phoneme_activations": [[27, 31], ["zip", "numpy.array", "numpy.stack", "list", "align.slices"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.slices"], ["", "def", "phoneme_activations", "(", "activations", ",", "alignment", ")", ":", "\n", "    ", "\"\"\"Return array of phoneme labels and array of corresponding mean-pooled activation states.\"\"\"", "\n", "labels", ",", "states", "=", "zip", "(", "*", "list", "(", "slices", "(", "alignment", ",", "activations", ",", "index", "=", "vg", ".", "activations", ".", "index", ")", ")", ")", "\n", "return", "np", ".", "array", "(", "labels", ")", ",", "np", ".", "stack", "(", "states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.on_progress": [[32, 35], ["p.items", "logging.debug"], "function", ["None"], ["", "def", "on_progress", "(", "p", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "p", ".", "items", "(", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "\"%s: %s\"", "%", "(", "k", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.align": [[37, 44], ["logging.info", "gentle.resampled", "logging.info", "gentle.ForcedAligner", "json.loads", "gentle.ForcedAligner.transcribe().to_json", "gentle.ForcedAligner.transcribe"], "function", ["None"], ["", "", "def", "align", "(", "audiopath", ",", "transcript", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"converting audio to 8K sampled wav\"", ")", "\n", "with", "gentle", ".", "resampled", "(", "audiopath", ")", "as", "wavfile", ":", "\n", "        ", "logging", ".", "info", "(", "\"starting alignment\"", ")", "\n", "aligner", "=", "gentle", ".", "ForcedAligner", "(", "resources", ",", "transcript", ",", "nthreads", "=", "nthreads", ",", "disfluency", "=", "False", ",", "\n", "conservative", "=", "False", ")", "\n", "return", "json", ".", "loads", "(", "aligner", ".", "transcribe", "(", "wavfile", ",", "progress_cb", "=", "on_progress", ",", "logging", "=", "logging", ")", ".", "to_json", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.slices": [[46, 56], ["align.phones", "x.mean", "index", "index", "index", "index", "aggregate", "index", "index"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.phones", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index"], ["", "", "def", "slices", "(", "utt", ",", "rep", ",", "index", "=", "lambda", "ms", ":", "ms", "//", "10", ",", "aggregate", "=", "lambda", "x", ":", "x", ".", "mean", "(", "axis", "=", "0", ")", ")", ":", "\n", "    ", "\"\"\"Return sequence of slices associated with phoneme labels, given an\n       alignment object `utt`, a representation array `rep`, and\n       indexing function `index`, and an aggregating function\\\n       `aggregate`.\n    \"\"\"", "\n", "for", "phoneme", "in", "phones", "(", "utt", ")", ":", "\n", "        ", "phone", ",", "start", ",", "end", "=", "phoneme", "\n", "assert", "index", "(", "start", ")", "<", "index", "(", "end", ")", "+", "1", ",", "\"Something funny: {} {} {} {}\"", ".", "format", "(", "start", ",", "end", ",", "index", "(", "start", ")", ",", "index", "(", "end", ")", ")", "\n", "yield", "(", "phone", ",", "aggregate", "(", "rep", "[", "index", "(", "start", ")", ":", "index", "(", "end", ")", "+", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.align.phones": [[57, 71], ["phone[].split", "int", "int"], "function", ["None"], ["", "", "def", "phones", "(", "utt", ")", ":", "\n", "    ", "\"\"\"Return sequence of phoneme labels associated with start and end\n     time corresponding to the alignment JSON object `utt`.\n    \n    \"\"\"", "\n", "for", "word", "in", "utt", "[", "'words'", "]", ":", "\n", "        ", "pos", "=", "word", "[", "'start'", "]", "\n", "for", "phone", "in", "word", "[", "'phones'", "]", ":", "\n", "            ", "start", "=", "pos", "\n", "end", "=", "pos", "+", "phone", "[", "'duration'", "]", "\n", "pos", "=", "end", "\n", "label", "=", "phone", "[", "'phone'", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "label", "!=", "'oov'", ":", "\n", "                ", "yield", "(", "label", ",", "int", "(", "start", "*", "1000", ")", ",", "int", "(", "end", "*", "1000", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.from_audio": [[5, 12], ["torch.load", "activations.get_state_stack", "vg.extract_mfcc"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.get_state_stack", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.mfcc.extract_mfcc"], ["def", "from_audio", "(", "model_path", ",", "paths", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "\"\"\"Return per-layer activation states for audio files stored in paths, from model stored in model_path. \n    The output is a list of arrays of shape (time, layer, feature).\n    \"\"\"", "\n", "net", "=", "torch", ".", "load", "(", "model_path", ",", "device", ")", "\n", "audio", "=", "[", "C", ".", "extract_mfcc", "(", "path", ")", "for", "path", "in", "paths", "]", "\n", "return", "get_state_stack", "(", "net", ",", "audio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.get_state_stack": [[14, 27], ["activations.inout", "zip", "next", "numpy.array", "result.append", "net.parameters", "list", "util.grouper", "state_stack().cpu().numpy", "map", "state_stack().cpu", "activations.state_stack", "torch.from_numpy().to", "torch.from_numpy", "vector_padder"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.state_stack", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder"], ["", "def", "get_state_stack", "(", "net", ",", "audios", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "import", "onion", ".", "util", "as", "util", "\n", "from", "vg", ".", "simple_data", "import", "vector_padder", "\n", "\"\"\"Pass audios through the model and for each audio return the state of each timestep and each layer.\"\"\"", "\n", "device", "=", "next", "(", "net", ".", "parameters", "(", ")", ")", ".", "device", "\n", "result", "=", "[", "]", "\n", "lens", "=", "inout", "(", "np", ".", "array", "(", "list", "(", "map", "(", "len", ",", "audios", ")", ")", ")", ")", "\n", "rs", "=", "(", "r", "for", "batch", "in", "util", ".", "grouper", "(", "audios", ",", "batch_size", ")", "\n", "for", "r", "in", "state_stack", "(", "net", ",", "torch", ".", "from_numpy", "(", "vector_padder", "(", "batch", ")", ")", ".", "to", "(", "device", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "for", "(", "r", ",", "l", ")", "in", "zip", "(", "rs", ",", "lens", ")", ":", "\n", "        ", "result", ".", "append", "(", "r", "[", "-", "l", ":", ",", ":", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout": [[29, 31], ["numpy.floor().astype", "numpy.floor"], "function", ["None"], ["", "def", "inout", "(", "L", ",", "pad", "=", "6", ",", "ksize", "=", "6", ",", "stride", "=", "2", ")", ":", "# Default Flickr8k model parameters ", "\n", "    ", "return", "np", ".", "floor", "(", "(", "L", "+", "2", "*", "pad", "-", "1", "*", "(", "ksize", "-", "1", ")", "-", "1", ")", "/", "stride", "+", "1", ")", ".", "astype", "(", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.index": [[32, 38], ["activations.inout"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.inout"], ["", "def", "index", "(", "t", ",", "stride", "=", "2", ",", "size", "=", "6", ")", ":", "\n", "    ", "\"\"\"Return index into the recurrent state of speech model given timestep\n    `t`.\n    See: https://pytorch.org/docs/stable/nn.html#torch.nn.Conv1d\n    \"\"\"", "\n", "return", "inout", "(", "t", "//", "10", ",", "pad", "=", "size", ",", "ksize", "=", "size", ",", "stride", "=", "stride", ")", "# sampling audio every 10ms", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.activations.state_stack": [[40, 47], ["torch.cat().permute", "testing", "net.SpeechImage.SpeechEncoderBottom.states", "net.SpeechImage.SpeechEncoderTop.states", "torch.cat"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states"], ["", "def", "state_stack", "(", "net", ",", "audio", ")", ":", "\n", "    ", "from", "vg", ".", "scorer", "import", "testing", "\n", "with", "testing", "(", "net", ")", ":", "\n", "        ", "states_bot", "=", "net", ".", "SpeechImage", ".", "SpeechEncoderBottom", ".", "states", "(", "audio", ")", "\n", "states_top", "=", "net", ".", "SpeechImage", ".", "SpeechEncoderTop", ".", "states", "(", "states_bot", "[", "-", "1", "]", ")", "\n", "", "states", "=", "torch", ".", "cat", "(", "[", "states_bot", ",", "states_top", "]", ",", "dim", "=", "0", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", "#batch x length x layer x feature", "\n", "return", "states", "\n", "", ""]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.__init__": [[91, 123], ["config.get", "config.get", "prov.iterImages", "sklearn.metrics.pairwise.cosine_similarity", "numpy.array", "numpy.array", "len", "numpy.zeros", "range", "collections.Counter", "scorer.Scorer.images.append", "range", "scorer.Scorer.encode_sentences", "scorer.Scorer.rsa_image_data.append", "scorer.Scorer.sentences.append", "scorer.stringsim", "range", "range", "range", "len", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.Provider.iterImages", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.stringsim"], ["    ", "def", "__init__", "(", "self", ",", "prov", ",", "config", ",", "net", "=", "None", ")", ":", "#FIXME this should just take a encoder function, not net", "\n", "        ", "self", ".", "prov", "=", "prov", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "sentences", "=", "[", "]", "\n", "self", ".", "rsa_image_data", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "encode_sentences", "=", "config", ".", "get", "(", "'encode_sentences'", ",", "encode_sentences", ")", "\n", "self", ".", "encode_images", "=", "config", ".", "get", "(", "'encode_images'", ",", "encode_images", ")", "\n", "for", "image", "in", "prov", ".", "iterImages", "(", "split", "=", "config", "[", "'split'", "]", ")", ":", "\n", "           ", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "for", "sent", "in", "image", "[", "'sentences'", "]", ":", "\n", "               ", "self", ".", "rsa_image_data", ".", "append", "(", "image", "[", "'feat'", "]", ")", "\n", "self", ".", "sentences", ".", "append", "(", "sent", ")", "\n", "", "", "self", ".", "sentence_data", "=", "[", "config", "[", "'tokenize'", "]", "(", "s", ")", "for", "s", "in", "self", ".", "sentences", "]", "\n", "self", ".", "sim_images", "=", "cosine_similarity", "(", "self", ".", "rsa_image_data", ")", "\n", "self", ".", "correct_para", "=", "numpy", ".", "array", "(", "[", "[", "self", ".", "sentences", "[", "i", "]", "[", "'imgid'", "]", "==", "self", ".", "sentences", "[", "j", "]", "[", "'imgid'", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "sentences", ")", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sentences", ")", ")", "]", ")", "\n", "self", ".", "correct_img", "=", "numpy", ".", "array", "(", "[", "[", "self", ".", "sentences", "[", "i", "]", "[", "'imgid'", "]", "==", "self", ".", "images", "[", "j", "]", "[", "'imgid'", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "images", ")", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sentences", ")", ")", "]", ")", "\n", "# Precompute string similarity", "\n", "S", "=", "len", "(", "self", ".", "sentences", ")", "\n", "self", ".", "string_sim", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "S", ",", "S", ")", ")", "\n", "for", "i", "in", "range", "(", "S", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "S", ")", ":", "\n", "                ", "self", ".", "string_sim", "[", "i", ",", "j", "]", "=", "stringsim", "(", "self", ".", "sentences", "[", "i", "]", "[", "'raw'", "]", ",", "self", ".", "sentences", "[", "j", "]", "[", "'raw'", "]", ")", "\n", "\n", "", "", "self", ".", "net", "=", "net", "\n", "if", "self", ".", "net", "is", "not", "None", ":", "\n", "            ", "self", ".", "pred", "=", "self", ".", "encode_sentences", "(", "self", ".", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "", "self", ".", "speakers", "=", "Counter", "(", "s", "[", "'speaker'", "]", "for", "s", "in", "self", ".", "sentences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.speaker_id": [[124, 154], ["hasattr", "sklearn.preprocessing.LabelEncoder().fit_transform", "sklearn.model_selection.train_test_split", "dict", "numpy.array", "dict", "numpy.array", "numpy.array", "list", "numpy.array.max", "numpy.array.sum", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.score", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.score", "logging.info", "scores[].append", "scores[].append", "scorer.testing", "scorer.Scorer.encode_sentences", "sklearn.preprocessing.LabelEncoder", "range", "scorer.Scorer.speakers.values", "max", "max", "numpy.zeros", "audio.mean", "scorer.rer"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit_transform", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.score", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.fit", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.score", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.rer"], ["", "def", "speaker_id", "(", "self", ",", "net", "=", "None", ")", ":", "\n", "        ", "if", "net", "is", "None", ":", "\n", "            ", "pred", "=", "self", ".", "pred", "\n", "net", "=", "self", ".", "net", "\n", "", "else", ":", "\n", "            ", "with", "testing", "(", "net", ")", ":", "\n", "                ", "pred", "=", "self", ".", "encode_sentences", "(", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "", "", "X", "=", "pred", "\n", "if", "hasattr", "(", "net", ",", "'mapper'", ")", ":", "\n", "# FIXME do something reasonable here", "\n", "            ", "Z", "=", "numpy", ".", "array", "(", "[", "numpy", ".", "zeros", "(", "(", "1", ")", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "else", ":", "\n", "            ", "Z", "=", "numpy", ".", "array", "(", "[", "audio", ".", "mean", "(", "axis", "=", "0", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "y", "=", "LabelEncoder", "(", ")", ".", "fit_transform", "(", "[", "s", "[", "'speaker'", "]", "for", "s", "in", "self", ".", "sentences", "]", ")", "\n", "C", "=", "[", "10", "**", "p", "for", "p", "in", "range", "(", "2", ",", "3", ")", "]", "\n", "X", ",", "X_test", ",", "Z", ",", "Z_test", ",", "y", ",", "y_test", "=", "train_test_split", "(", "X", ",", "Z", ",", "y", ",", "random_state", "=", "42", ")", "\n", "scores", "=", "dict", "(", "rep", "=", "[", "]", ",", "mfcc", "=", "[", "]", ")", "\n", "counts", "=", "numpy", ".", "array", "(", "list", "(", "self", ".", "speakers", ".", "values", "(", ")", ")", ")", "\n", "maj", "=", "counts", ".", "max", "(", ")", "/", "counts", ".", "sum", "(", ")", "\n", "for", "c", "in", "C", ":", "\n", "            ", "model_rep", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "model_rep", ".", "fit", "(", "X", ",", "y", ")", "\n", "acc_rep", "=", "model_rep", ".", "score", "(", "X_test", ",", "y_test", ")", "\n", "model_mfcc", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "model_mfcc", ".", "fit", "(", "Z", ",", "y", ")", "\n", "acc_mfcc", "=", "model_mfcc", ".", "score", "(", "Z_test", ",", "y_test", ")", "\n", "logging", ".", "info", "(", "\"speaker_id acc {} {} {} {}\"", ".", "format", "(", "c", ",", "acc_rep", ",", "acc_mfcc", ",", "rer", "(", "acc_mfcc", ",", "acc_rep", ")", ")", ")", "\n", "scores", "[", "'rep'", "]", ".", "append", "(", "acc_rep", ")", "\n", "scores", "[", "'mfcc'", "]", ".", "append", "(", "acc_mfcc", ")", "\n", "", "return", "dict", "(", "maj", "=", "maj", ",", "rep", "=", "max", "(", "scores", "[", "'rep'", "]", ")", ",", "mfcc", "=", "max", "(", "scores", "[", "'mfcc'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.rsa_image": [[155, 179], ["sklearn.metrics.pairwise.cosine_similarity", "sklearn.metrics.pairwise.cosine_similarity", "dict", "hasattr", "numpy.array", "numpy.array", "scipy.stats.pearsonr", "scipy.stats.pearsonr", "scipy.stats.pearsonr", "scorer.testing", "scorer.Scorer.encode_sentences", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "float", "float", "float", "numpy.zeros", "audio.mean"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "rsa_image", "(", "self", ",", "net", "=", "None", ",", "within", "=", "False", ")", ":", "\n", "# Full RSA", "\n", "            ", "if", "net", "is", "None", ":", "\n", "                ", "pred", "=", "self", ".", "pred", "\n", "", "else", ":", "\n", "                ", "with", "testing", "(", "net", ")", ":", "\n", "                   ", "pred", "=", "self", ".", "encode_sentences", "(", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "", "", "if", "hasattr", "(", "net", ",", "'mapper'", ")", "and", "net", ".", "mapper", "is", "not", "None", ":", "\n", "# FIXME do something reasonable here", "\n", "#print(\"This is a text net\")", "\n", "                ", "mfcc", "=", "numpy", ".", "array", "(", "[", "numpy", ".", "zeros", "(", "(", "1", ")", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "else", ":", "\n", "#print(\"This is an audio net\")", "\n", "                ", "mfcc", "=", "numpy", ".", "array", "(", "[", "audio", ".", "mean", "(", "axis", "=", "0", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "sim_mfcc", "=", "cosine_similarity", "(", "mfcc", ")", "\n", "sim_pred", "=", "cosine_similarity", "(", "pred", ")", "\n", "\n", "img_rep", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "self", ".", "sim_images", ")", ",", "triu", "(", "sim_pred", ")", ")", "[", "0", "]", "\n", "img_mfcc", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "self", ".", "sim_images", ")", ",", "triu", "(", "sim_mfcc", ")", ")", "[", "0", "]", "\n", "rep_mfcc", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "sim_pred", ")", ",", "triu", "(", "sim_mfcc", ")", ")", "[", "0", "]", "\n", "result", "=", "dict", "(", "img_rep", "=", "float", "(", "img_rep", ")", ",", "img_mfcc", "=", "float", "(", "img_mfcc", ")", ",", "rep_mfcc", "=", "float", "(", "rep_mfcc", ")", ")", "# make json happy", "\n", "if", "within", ":", "\n", "                ", "result", "[", "'within'", "]", "=", "within_rsa", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.rsa_string": [[180, 202], ["sklearn.metrics.pairwise.cosine_similarity", "sklearn.metrics.pairwise.cosine_similarity", "dict", "hasattr", "numpy.array", "numpy.array", "scipy.stats.pearsonr", "scipy.stats.pearsonr", "scipy.stats.pearsonr", "scorer.testing", "scorer.Scorer.encode_sentences", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "scorer.triu", "float", "float", "float", "numpy.zeros", "audio.mean"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "rsa_string", "(", "self", ",", "net", "=", "None", ")", ":", "\n", "# Full RSA", "\n", "            ", "if", "net", "is", "None", ":", "\n", "                ", "pred", "=", "self", ".", "pred", "\n", "", "else", ":", "\n", "                ", "with", "testing", "(", "net", ")", ":", "\n", "                   ", "pred", "=", "self", ".", "encode_sentences", "(", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "", "", "if", "hasattr", "(", "net", ",", "'mapper'", ")", "and", "net", ".", "mapper", "is", "not", "None", ":", "\n", "# FIXME do something reasonable here", "\n", "#print(\"This is a text net\")", "\n", "                ", "mfcc", "=", "numpy", ".", "array", "(", "[", "numpy", ".", "zeros", "(", "(", "1", ")", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "else", ":", "\n", "#print(\"This is an audio net\")", "\n", "                ", "mfcc", "=", "numpy", ".", "array", "(", "[", "audio", ".", "mean", "(", "axis", "=", "0", ")", "for", "audio", "in", "self", ".", "sentence_data", "]", ")", "\n", "", "sim_mfcc", "=", "cosine_similarity", "(", "mfcc", ")", "\n", "sim_pred", "=", "cosine_similarity", "(", "pred", ")", "\n", "\n", "string_rep", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "self", ".", "string_sim", ")", ",", "triu", "(", "sim_pred", ")", ")", "[", "0", "]", "\n", "string_mfcc", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "self", ".", "string_sim", ")", ",", "triu", "(", "sim_mfcc", ")", ")", "[", "0", "]", "\n", "rep_mfcc", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "sim_pred", ")", ",", "triu", "(", "sim_mfcc", ")", ")", "[", "0", "]", "\n", "result", "=", "dict", "(", "string_rep", "=", "float", "(", "string_rep", ")", ",", "string_mfcc", "=", "float", "(", "string_mfcc", ")", ",", "rep_mfcc", "=", "float", "(", "rep_mfcc", ")", ")", "# make json happy", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.retrieval": [[203, 218], ["scorer.Scorer.encode_images", "vg.evaluate.ranking", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.median", "scorer.testing", "scorer.Scorer.encode_sentences"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.evaluate.ranking", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences"], ["", "def", "retrieval", "(", "self", ",", "net", "=", "None", ")", ":", "\n", "            ", "img_fs", "=", "self", ".", "encode_images", "(", "net", ",", "[", "s", "[", "'feat'", "]", "for", "s", "in", "self", ".", "images", "]", ")", "\n", "if", "net", "is", "None", ":", "\n", "                ", "pred", "=", "self", ".", "pred", "\n", "", "else", ":", "\n", "                ", "with", "testing", "(", "net", ")", ":", "\n", "                    ", "pred", "=", "self", ".", "encode_sentences", "(", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "\n", "", "", "result", "=", "{", "}", "\n", "ret", "=", "ranking", "(", "img_fs", ",", "pred", ",", "self", ".", "correct_img", ",", "ns", "=", "(", "1", ",", "5", ",", "10", ")", ",", "exclude_self", "=", "False", ")", "\n", "result", "[", "'recall@1'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "1", "]", ")", "\n", "result", "[", "'recall@5'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "5", "]", ")", "\n", "result", "[", "'recall@10'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "10", "]", ")", "\n", "result", "[", "'medr'", "]", "=", "numpy", ".", "median", "(", "ret", "[", "'ranks'", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.retrieval_para": [[219, 233], ["vg.evaluate.paraphrase_ranking", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.median", "scorer.testing", "scorer.Scorer.encode_sentences"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.evaluate.paraphrase_ranking", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences"], ["", "def", "retrieval_para", "(", "self", ",", "net", "=", "None", ")", ":", "\n", "            ", "if", "net", "is", "None", ":", "\n", "                ", "pred", "=", "self", ".", "pred", "\n", "", "else", ":", "\n", "                ", "with", "testing", "(", "net", ")", ":", "\n", "                   ", "pred", "=", "self", ".", "encode_sentences", "(", "net", ",", "self", ".", "sentence_data", ",", "batch_size", "=", "self", ".", "config", "[", "'batch_size'", "]", ")", "\n", "\n", "", "", "result", "=", "{", "}", "\n", "ret", "=", "paraphrase_ranking", "(", "pred", ",", "self", ".", "correct_para", ",", "ns", "=", "(", "1", ",", "5", ",", "10", ")", ")", "\n", "result", "[", "'recall@1'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "1", "]", ")", "\n", "result", "[", "'recall@5'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "5", "]", ")", "\n", "result", "[", "'recall@10'", "]", "=", "numpy", ".", "mean", "(", "ret", "[", "'recall'", "]", "[", "10", "]", ")", "\n", "result", "[", "'medr'", "]", "=", "numpy", ".", "median", "(", "ret", "[", "'ranks'", "]", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.main": [[25, 41], ["logging.getLogger().setLevel", "argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "parser.add_subparsers.add_parser", "commands.add_parser.set_defaults", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "commands.add_parser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.func", "logging.getLogger"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "'INFO'", ")", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "commands", "=", "parser", ".", "add_subparsers", "(", ")", "\n", "\n", "p", "=", "commands", ".", "add_parser", "(", "'score'", ")", "\n", "p", ".", "set_defaults", "(", "func", "=", "score", ")", "\n", "p", ".", "add_argument", "(", "'model'", ",", "nargs", "=", "'+'", ",", "help", "=", "'Model file(s)'", ")", "\n", "p", ".", "add_argument", "(", "'--text'", ",", "action", "=", "'store_true'", ")", "\n", "p", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'flickr8k'", ")", "\n", "p", ".", "add_argument", "(", "'--split'", ",", "default", "=", "'val'", ")", "\n", "p", ".", "add_argument", "(", "'--root'", ",", "default", "=", "'.'", ")", "\n", "p", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "p", ".", "add_argument", "(", "'--output'", ",", "default", "=", "'result.json'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "func", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.score": [[42, 68], ["logging.info", "dp.getDataProvider", "dict", "scorer.Scorer", "json.dump", "scorer.load", "load.eval().cuda", "scorer.Scorer.rsa_image", "scorer.Scorer.retrieval_para", "dict", "output.append", "open", "scorer.Scorer.speaker_id", "load.eval"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.places_provider.getDataProvider", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.dump", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.rsa_image", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.retrieval_para", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.speaker_id"], ["", "def", "score", "(", "args", ")", ":", "\n", "\n", "    ", "if", "args", ".", "dataset", "==", "'coco'", ":", "\n", "        ", "import", "vg", ".", "vendrov_provider", "as", "dp", "\n", "", "elif", "args", ".", "dataset", "==", "'places'", ":", "\n", "        ", "import", "vg", ".", "places_provider", "as", "dp", "\n", "", "elif", "args", ".", "dataset", "==", "'flickr8k'", ":", "\n", "        ", "import", "vg", ".", "flickr8k_provider", "as", "dp", "\n", "", "logging", ".", "info", "(", "'Loading data'", ")", "\n", "prov", "=", "dp", ".", "getDataProvider", "(", "args", ".", "dataset", ",", "root", "=", "args", ".", "root", ",", "audio_kind", "=", "'mfcc'", ")", "\n", "tokenize", "=", "characters", "if", "args", ".", "text", "else", "lambda", "x", ":", "x", "[", "'audio'", "]", "\n", "config", "=", "dict", "(", "split", "=", "args", ".", "split", ",", "tokenize", "=", "tokenize", ",", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "if", "args", ".", "text", ":", "\n", "        ", "config", "[", "'encode_sentences'", "]", "=", "encode_texts", "\n", "", "scorer", "=", "Scorer", "(", "prov", ",", "config", ")", "\n", "output", "=", "[", "]", "\n", "for", "path", "in", "args", ".", "model", ":", "\n", "        ", "task", "=", "load", "(", "path", ")", "\n", "task", ".", "eval", "(", ")", ".", "cuda", "(", ")", "\n", "rsa", "=", "scorer", ".", "rsa_image", "(", "task", ")", "\n", "para", "=", "scorer", ".", "retrieval_para", "(", "task", ")", "\n", "result", "=", "dict", "(", "path", "=", "path", ",", "rsa", "=", "rsa", ",", "para", "=", "para", ")", "\n", "if", "not", "args", ".", "text", ":", "\n", "            ", "result", "[", "'speaker_id'", "]", "=", "scorer", ".", "speaker_id", "(", "task", ")", "\n", "", "output", ".", "append", "(", "result", ")", "\n", "", "json", ".", "dump", "(", "output", ",", "open", "(", "args", ".", "output", ",", "'w'", ")", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load": [[69, 76], ["vg.load", "torch.load"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.load"], ["", "def", "load", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "model", "=", "bundle", ".", "load", "(", "path", ")", "\n", "return", "model", ".", "task", "\n", "", "except", ":", "\n", "        ", "task", "=", "torch", ".", "load", "(", "path", ")", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing": [[77, 83], ["torch.no_grad", "net.eval", "net.train"], "function", ["None"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "testing", "(", "net", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "net", ".", "eval", "(", ")", "\n", "yield", "net", "\n", "net", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.stringsim": [[85, 88], ["Levenshtein.distance", "max", "len", "len"], "function", ["None"], ["", "", "def", "stringsim", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Levenshtein edit distance normalized by length of longer string.\"\"\"", "\n", "return", "1", "-", "L", ".", "distance", "(", "a", ",", "b", ")", "/", "max", "(", "len", "(", "a", ")", ",", "len", "(", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.rer": [[234, 236], ["None"], "function", ["None"], ["", "", "def", "rer", "(", "hi", ",", "lo", ")", ":", "\n", "    ", "return", "(", "(", "1", "-", "lo", ")", "-", "(", "1", "-", "hi", ")", ")", "/", "(", "1", "-", "lo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu": [[237, 241], ["numpy.ones_like", "numpy.triu"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "triu", "(", "x", ")", ":", "\n", "    ", "\"Extracts upper triangular part of a matrix, excluding the diagonal.\"", "\n", "ones", "=", "numpy", ".", "ones_like", "(", "x", ")", "\n", "return", "x", "[", "numpy", ".", "triu", "(", "ones", ",", "k", "=", "1", ")", "==", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.RSA": [[242, 244], ["round", "scipy.stats.pearsonr", "scorer.triu", "scorer.triu"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.triu"], ["", "def", "RSA", "(", "M", ",", "N", ")", ":", "\n", "    ", "return", "round", "(", "scipy", ".", "stats", ".", "pearsonr", "(", "triu", "(", "M", ")", ",", "triu", "(", "N", ")", ")", "[", "0", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences": [[245, 250], ["numpy.vstack", "task.predict().data.cpu().numpy", "onion.grouper", "task.predict().data.cpu", "task.predict", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.from_numpy", "vg.simple_data.vector_padder"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.vector_padder"], ["", "def", "encode_sentences", "(", "task", ",", "audios", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "vector_padder", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "audios", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_texts": [[251, 256], ["numpy.vstack", "task.predict().data.cpu().numpy", "onion.grouper", "task.predict().data.cpu", "task.predict", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.from_numpy", "task.batcher.batch_inp().astype", "task.batcher.batch_inp", "task.mapper.transform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch_inp", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "def", "encode_texts", "(", "task", ",", "texts", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "task", ".", "batcher", ".", "batch_inp", "(", "task", ".", "mapper", ".", "transform", "(", "batch", ")", ")", ".", "astype", "(", "'int64'", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "texts", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_images": [[257, 264], ["numpy.vstack", "task.encode_images().data.cpu().numpy", "onion.grouper", "task.encode_images().data.cpu", "task.encode_images", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.from_numpy", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images"], ["", "def", "encode_images", "(", "task", ",", "imgs", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "\"\"\"Project imgs to the joint space using model.\n    \"\"\"", "\n", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "encode_images", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "numpy", ".", "vstack", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "imgs", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.encode_sentences_SpeechText": [[265, 272], ["numpy.vstack", "task.SpeechText.SpeechEncoderTop", "task.SpeechText.SpeechEncoderBottom", "predict().data.cpu().numpy", "onion.grouper", "predict().data.cpu", "scorer.encode_sentences_SpeechText.predict"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict"], ["", "def", "encode_sentences_SpeechText", "(", "task", ",", "audios", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "def", "predict", "(", "x", ")", ":", "\n", "        ", "return", "task", ".", "SpeechText", ".", "SpeechEncoderTop", "(", "task", ".", "SpeechText", ".", "SpeechEncoderBottom", "(", "x", ")", ")", "\n", "", "return", "numpy", ".", "vstack", "(", "[", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "vector_padder", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "audios", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoder.__init__": [[13, 21], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "onion.attention.SelfAttention", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "size_embed", "=", "64", ",", "depth", "=", "1", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "TextEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Embed", "=", "nn", ".", "Embedding", "(", "self", ".", "size_feature", ",", "self", ".", "size_embed", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_embed", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoder.forward": [[22, 26], ["encoders.TextEncoder.h0.expand().cuda", "encoders.TextEncoder.RNN", "encoders.l2normalize", "encoders.TextEncoder.Dropout", "encoders.TextEncoder.Attn", "encoders.TextEncoder.h0.expand", "encoders.TextEncoder.Embed", "text.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "text", ")", ":", "\n", "        ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "text", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "self", ".", "Embed", "(", "text", ")", ")", ",", "h0", ")", "\n", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoderBottom.__init__": [[30, 37], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "size_embed", "=", "64", ",", "depth", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "TextEncoderBottom", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Embed", "=", "nn", ".", "Embedding", "(", "self", ".", "size_feature", ",", "self", ".", "size_embed", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_embed", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoderBottom.forward": [[39, 43], ["encoders.TextEncoderBottom.h0.expand().cuda", "encoders.TextEncoderBottom.RNN", "encoders.TextEncoderBottom.Dropout", "encoders.TextEncoderBottom.h0.expand", "encoders.TextEncoderBottom.Embed", "text.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "text", ")", ":", "\n", "        ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "text", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "self", ".", "Embed", "(", "text", ")", ")", ",", "h0", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoderTop.__init__": [[47, 55], ["torch.Module.__init__", "onion.autoassign", "onion.attention.SelfAttention", "locals", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "depth", "=", "1", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "TextEncoderTop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_feature", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.TextEncoderTop.forward": [[56, 63], ["encoders.l2normalize", "encoders.TextEncoderTop.h0.expand().cuda", "encoders.TextEncoderTop.RNN", "encoders.TextEncoderTop.Attn", "encoders.TextEncoderTop.Dropout", "encoders.TextEncoderTop.h0.expand", "x.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "_last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ",", "h0", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoder.__init__": [[67, 75], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "onion.conv.Convolution1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "onion.attention.SelfAttention", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_vocab", ",", "size", ",", "depth", "=", "1", ",", "filter_length", "=", "6", ",", "filter_size", "=", "64", ",", "stride", "=", "2", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Conv", "=", "conv", ".", "Convolution1D", "(", "self", ".", "size_vocab", ",", "self", ".", "filter_length", ",", "self", ".", "filter_size", ",", "stride", "=", "self", ".", "stride", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "filter_size", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoder.forward": [[76, 80], ["encoders.SpeechEncoder.h0.expand().cuda", "encoders.SpeechEncoder.RNN", "encoders.l2normalize", "encoders.SpeechEncoder.Dropout", "encoders.SpeechEncoder.Attn", "encoders.SpeechEncoder.h0.expand", "encoders.SpeechEncoder.Conv", "input.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "input", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "self", ".", "Conv", "(", "input", ")", ")", ",", "h0", ")", "\n", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.GRUStack.__init__": [[84, 88], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.GRU", "torch.GRU", "torch.GRU", "range"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["def", "__init__", "(", "self", ",", "size_in", ",", "size", ",", "depth", ")", ":", "\n", "        ", "super", "(", "GRUStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bottom", "=", "nn", ".", "GRU", "(", "size_in", ",", "size", ",", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "GRU", "(", "size", ",", "size", ",", "1", ",", "batch_first", "=", "True", ")", "for", "i", "in", "range", "(", "depth", "-", "1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.GRUStack.forward": [[89, 100], ["encoders.GRUStack.bottom", "hidden.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "rnn", "hidden.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "hidden", "=", "[", "]", "\n", "#        print(\"rnn x\", x.size())", "\n", "output", ",", "_", "=", "self", ".", "bottom", "(", "x", ")", "\n", "#        print(\"rnn bottom\", output.size())", "\n", "hidden", ".", "append", "(", "output", ")", "\n", "for", "rnn", "in", "self", ".", "layers", ":", "\n", "            ", "output", ",", "_", "=", "rnn", "(", "hidden", "[", "-", "1", "]", ")", "\n", "#            print(\"rnn middle\", output.size())", "\n", "hidden", ".", "append", "(", "output", ")", "\n", "", "return", "torch", ".", "stack", "(", "hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottom.__init__": [[102, 110], ["torch.Module.__init__", "onion.autoassign", "onion.conv.Convolution1D", "locals", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_vocab", ",", "size", ",", "depth", "=", "1", ",", "filter_length", "=", "6", ",", "filter_size", "=", "64", ",", "stride", "=", "2", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderBottom", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "Conv", "=", "conv", ".", "Convolution1D", "(", "self", ".", "size_vocab", ",", "self", ".", "filter_length", ",", "self", ".", "filter_size", ",", "stride", "=", "self", ".", "stride", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "filter_size", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottom.forward": [[111, 118], ["encoders.SpeechEncoderBottom.h0.expand().cuda", "encoders.SpeechEncoderBottom.RNN", "encoders.SpeechEncoderBottom.Conv", "encoders.SpeechEncoderBottom.Dropout", "encoders.SpeechEncoderBottom.h0.expand", "encoders.SpeechEncoderBottom.Conv", "x.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "self", ".", "Conv", "(", "x", ")", ")", ",", "h0", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "Conv", "(", "x", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomStack.__init__": [[120, 127], ["torch.Module.__init__", "onion.autoassign", "onion.conv.Convolution1D", "locals", "torch.Dropout", "torch.Dropout", "torch.Dropout", "encoders.GRUStack"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_vocab", ",", "size", ",", "depth", "=", "1", ",", "filter_length", "=", "6", ",", "filter_size", "=", "64", ",", "stride", "=", "2", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderBottomStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "Conv", "=", "conv", ".", "Convolution1D", "(", "self", ".", "size_vocab", ",", "self", ".", "filter_length", ",", "self", ".", "filter_size", ",", "stride", "=", "self", ".", "stride", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "GRUStack", "(", "self", ".", "filter_size", ",", "self", ".", "size", ",", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomStack.forward": [[128, 130], ["encoders.SpeechEncoderBottomStack.states"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "states", "(", "x", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomStack.states": [[131, 145], ["encoders.SpeechEncoderBottomStack.RNN", "encoders.SpeechEncoderBottomStack.Conv", "encoders.SpeechEncoderBottomStack.Dropout", "encoders.SpeechEncoderBottomStack.Conv"], "methods", ["None"], ["", "def", "states", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "#            print(\"x\", x.size())", "\n", "#            x = self.Conv(x)", "\n", "#            print(\"conv\", x.size())", "\n", "#            x = self.Dropout(x)", "\n", "#            print(\"dropout\", x.size())", "\n", "#            x = self.RNN(x)", "\n", "#            print(\"rnn.forward\", x.size())", "\n", "#            out = x", "\n", "            ", "out", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "self", ".", "Conv", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "Conv", "(", "x", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomNoConv.__init__": [[148, 155], ["torch.Module.__init__", "onion.autoassign", "locals", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_vocab", ",", "size", ",", "depth", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderBottomNoConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_vocab", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomNoConv.forward": [[156, 163], ["encoders.SpeechEncoderBottomNoConv.h0.expand().cuda", "encoders.SpeechEncoderBottomNoConv.RNN", "encoders.SpeechEncoderBottomNoConv.Dropout", "encoders.SpeechEncoderBottomNoConv.h0.expand", "x.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ",", "h0", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomBidi.__init__": [[165, 172], ["torch.Module.__init__", "onion.autoassign", "locals", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_vocab", ",", "size", ",", "depth", "=", "1", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderBottomBidi", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_vocab", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "Down", "=", "nn", ".", "Linear", "(", "self", ".", "size", "*", "2", ",", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderBottomBidi.forward": [[173, 180], ["encoders.SpeechEncoderBottomBidi.RNN", "encoders.SpeechEncoderBottomBidi.Down", "encoders.SpeechEncoderBottomBidi.Dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ")", "\n", "out", "=", "self", ".", "Down", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTop.__init__": [[182, 190], ["torch.Module.__init__", "onion.autoassign", "onion.attention.SelfAttention", "locals", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_input", ",", "size", ",", "depth", "=", "1", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderTop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_input", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTop.forward": [[192, 199], ["encoders.l2normalize", "encoders.SpeechEncoderTop.h0.expand().cuda", "encoders.SpeechEncoderTop.RNN", "encoders.SpeechEncoderTop.Attn", "encoders.SpeechEncoderTop.Dropout", "encoders.SpeechEncoderTop.h0.expand", "x.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "_last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ",", "h0", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTop.states": [[200, 207], ["encoders.SpeechEncoderTop.h0.expand().cuda", "encoders.SpeechEncoderTop.RNN", "encoders.l2normalize", "encoders.SpeechEncoderTop.Dropout", "encoders.SpeechEncoderTop.Attn", "encoders.SpeechEncoderTop.h0.expand", "x.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "states", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "h0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "x", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "_last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ",", "h0", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", ",", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopStack.__init__": [[209, 216], ["torch.Module.__init__", "onion.autoassign", "onion.attention.SelfAttention", "locals", "torch.Dropout", "torch.Dropout", "torch.Dropout", "encoders.GRUStack"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_input", ",", "size", ",", "depth", "=", "1", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderTopStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "GRUStack", "(", "self", ".", "size_input", ",", "self", ".", "size", ",", "self", ".", "depth", ")", "\n", "", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopStack.states": [[217, 223], ["encoders.SpeechEncoderTopStack.RNN", "encoders.SpeechEncoderTopStack.Dropout"], "methods", ["None"], ["", "def", "states", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "out", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopStack.forward": [[224, 227], ["encoders.SpeechEncoderTopStack.states", "encoders.l2normalize", "encoders.SpeechEncoderTopStack.Attn"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "states", "(", "x", ")", "\n", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", "[", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.__init__": [[230, 238], ["torch.Module.__init__", "onion.autoassign", "onion.attention.SelfAttention", "locals", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_input", ",", "size", ",", "depth", "=", "1", ",", "size_attn", "=", "512", ",", "dropout_p", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "SpeechEncoderTopBidi", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "self", ".", "Dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_p", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_input", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "Down", "=", "nn", ".", "Linear", "(", "self", ".", "size", "*", "2", ",", "self", ".", "size", ")", "\n", "", "self", ".", "Attn", "=", "attention", ".", "SelfAttention", "(", "self", ".", "size", ",", "size", "=", "self", ".", "size_attn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.forward": [[240, 247], ["encoders.l2normalize", "encoders.SpeechEncoderTopBidi.RNN", "encoders.SpeechEncoderTopBidi.Down", "encoders.SpeechEncoderTopBidi.Attn", "encoders.SpeechEncoderTopBidi.Dropout"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "out", ",", "_last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ")", "\n", "out", "=", "self", ".", "Down", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states": [[248, 255], ["encoders.SpeechEncoderTopBidi.RNN", "encoders.SpeechEncoderTopBidi.Down", "encoders.l2normalize", "encoders.SpeechEncoderTopBidi.Dropout", "encoders.SpeechEncoderTopBidi.Attn"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize"], ["", "def", "states", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "depth", ">", "0", ":", "\n", "            ", "out", ",", "_last", "=", "self", ".", "RNN", "(", "self", ".", "Dropout", "(", "x", ")", ")", "\n", "out", "=", "self", ".", "Down", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "\n", "", "return", "out", ",", "l2normalize", "(", "self", ".", "Attn", "(", "out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.ImageEncoder.__init__": [[258, 261], ["torch.Module.__init__", "onion.make_linear"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.make_linear"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "size_target", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Encoder", "=", "util", ".", "make_linear", "(", "size_target", ",", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.ImageEncoder.forward": [[262, 264], ["encoders.l2normalize", "encoders.ImageEncoder.Encoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize"], ["", "def", "forward", "(", "self", ",", "img", ")", ":", "\n", "        ", "return", "l2normalize", "(", "self", ".", "Encoder", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.l2normalize": [[7, 9], ["torch.normalize"], "function", ["None"], ["def", "l2normalize", "(", "x", ")", ":", "\n", "    ", "return", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.BilinearAttention.__init__": [[11, 15], ["torch.Module.__init__", "onion.autoassign", "torch.Linear", "torch.Linear", "torch.Linear", "locals"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size_in", ")", ":", "\n", "        ", "super", "(", "BilinearAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "self", ".", "size_in", ",", "self", ".", "size_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.BilinearAttention.forward": [[16, 22], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.permute().bmm", "g.bmm", "decoders.BilinearAttention.W().permute", "torch.softmax.permute", "decoders.BilinearAttention.W"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g", ",", "h", ")", ":", "\n", "        ", "alpha", "=", "F", ".", "softmax", "(", "g", ".", "bmm", "(", "self", ".", "W", "(", "h", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "# FIXME is dim=1 correct?", "\n", "# Alignment based on bi-linear scores between g (source) and h (target)", "\n", "context", "=", "alpha", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "bmm", "(", "g", ")", "\n", "# print(context.size(), h.size())", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.SimpleDecoder.__init__": [[25, 31], ["torch.Module.__init__", "onion.autoassign", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.GRU", "torch.GRU", "torch.GRU", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "size_embed", "=", "64", ",", "depth", "=", "1", ")", ":", "\n", "        ", "super", "(", "SimpleDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "Embed", "=", "nn", ".", "Embedding", "(", "self", ".", "size_feature", ",", "self", ".", "size_embed", ")", "# Why not share embeddings with encoder?", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_embed", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.SimpleDecoder.forward": [[33, 37], ["rep.expand", "decoders.SimpleDecoder.RNN", "rep.size", "rep.size", "decoders.SimpleDecoder.Embed"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "prev", ",", "rep", ")", ":", "\n", "        ", "R", "=", "rep", ".", "expand", "(", "self", ".", "depth", ",", "rep", ".", "size", "(", "0", ")", ",", "rep", ".", "size", "(", "1", ")", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "self", ".", "Embed", "(", "prev", ")", ",", "R", ")", "\n", "return", "out", ",", "last", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.DecoderWithAttn.__init__": [[45, 51], ["torch.Module.__init__", "onion.autoassign", "decoders.SimpleDecoder", "decoders.BilinearAttention", "torch.Linear", "torch.Linear", "torch.Linear", "locals"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "size_target_vocab", ",", "size_embed", "=", "64", ",", "depth", "=", "1", ")", ":", "\n", "        ", "super", "(", "DecoderWithAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "Decoder", "=", "SimpleDecoder", "(", "self", ".", "size_target_vocab", ",", "self", ".", "size", ",", "size_embed", "=", "self", ".", "size_embed", ",", "depth", "=", "self", ".", "depth", ")", "\n", "self", ".", "BAttn", "=", "BilinearAttention", "(", "self", ".", "size", ")", "\n", "self", ".", "Proj", "=", "nn", ".", "Linear", "(", "self", ".", "size", "*", "2", ",", "self", ".", "size_target_vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.DecoderWithAttn.forward": [[52, 65], ["decoders.DecoderWithAttn.Decoder", "decoders.DecoderWithAttn.BAttn", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoders.DecoderWithAttn.Proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "states", ",", "rep", ",", "prev", ")", ":", "\n", "# Encoder returns the hidden state per time step, states, and a global representation, rep", "\n", "# Decoder decodes conditioned on rep, and on the symbol decoded at previous time step, prev", "\n", "        ", "h", ",", "_last", "=", "self", ".", "Decoder", "(", "prev", ",", "rep", ")", "\n", "# Bilinear attention generates a weighted sum of the source hidden states (context) for each time ", "\n", "# step of the target", "\n", "context", "=", "self", ".", "BAttn", "(", "states", ",", "h", ")", "\n", "# The context is concatenated with target hidden states", "\n", "h_context", "=", "torch", ".", "cat", "(", "(", "context", ",", "h", ")", ",", "dim", "=", "2", ")", "\n", "# The target symbols are generated conditioned on the concatenation of target states and context", "\n", "pred", "=", "self", ".", "Proj", "(", "h_context", ")", "\n", "#print(pred.size())", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.CondDecoder.__init__": [[70, 76], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "depth", "=", "1", ")", ":", "\n", "        ", "super", "(", "CondDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size_feature", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "Proj", "=", "nn", ".", "Linear", "(", "self", ".", "size", ",", "self", ".", "size_feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.CondDecoder.forward": [[77, 82], ["rep.expand.expand.expand", "decoders.CondDecoder.RNN", "decoders.CondDecoder.Proj", "rep.expand.expand.size", "rep.expand.expand.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "rep", ",", "prev", ")", ":", "\n", "        ", "rep", "=", "rep", ".", "expand", "(", "self", ".", "depth", ",", "rep", ".", "size", "(", "0", ")", ",", "rep", ".", "size", "(", "1", ")", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "prev", ",", "rep", ")", "\n", "pred", "=", "self", ".", "Proj", "(", "out", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.UncondDecoder.__init__": [[85, 91], ["torch.Module.__init__", "onion.autoassign", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "locals", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.autoassign"], ["    ", "def", "__init__", "(", "self", ",", "size_feature", ",", "size", ",", "depth", "=", "1", ")", ":", "\n", "        ", "super", "(", "UncondDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "util", ".", "autoassign", "(", "locals", "(", ")", ")", "\n", "self", ".", "h0", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "self", ".", "depth", ",", "1", ",", "self", ".", "size", ")", ")", "\n", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "self", ".", "size", ",", "self", ".", "size", ",", "self", ".", "depth", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "Proj", "=", "nn", ".", "Linear", "(", "self", ".", "size", ",", "self", ".", "size_feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.UncondDecoder.forward": [[92, 98], ["rep.unsqueeze().expand().cuda", "decoders.UncondDecoder.h0.expand().cuda", "decoders.UncondDecoder.RNN", "decoders.UncondDecoder.Proj", "rep.unsqueeze().expand", "decoders.UncondDecoder.h0.expand", "target.size", "target.size", "rep.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "forward", "(", "self", ",", "rep", ",", "target", ")", ":", "\n", "        ", "R", "=", "rep", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "target", ".", "size", "(", "1", ")", ",", "-", "1", ")", ".", "cuda", "(", ")", "\n", "H0", "=", "self", ".", "h0", ".", "expand", "(", "self", ".", "depth", ",", "target", ".", "size", "(", "0", ")", ",", "self", ".", "size", ")", ".", "cuda", "(", ")", "\n", "out", ",", "last", "=", "self", ".", "RNN", "(", "R", ",", "H0", ")", "\n", "pred", "=", "self", ".", "Proj", "(", "out", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.decoders.beam_search": [[101, 114], ["net.SpeechTranscriber.SpeechEncoderTop.states", "net.SpeechTranscriber.SpeechEncoderBottom"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states"], ["", "", "def", "beam_search", "(", "net", ",", "audio", ",", "beg", "=", "0", ",", "end", "=", "1", ")", ":", "\n", "# Encode speech signal", "\n", "    ", "states", ",", "rep", "=", "net", ".", "SpeechTranscriber", ".", "SpeechEncoderTop", ".", "states", "(", "net", ".", "SpeechTranscriber", ".", "SpeechEncoderBottom", "(", "audio", ")", ")", "\n", "# feed states and rep, plus BEG token to decoder", "\n", "# get top N choices for next letter", "\n", "# for each N:", "\n", "# feed states and rep, plus guess to decoder", "\n", "# get top N choices for next letter", "\n", "# extend beam ", "\n", "# prune prefixes", "\n", "# go to next position", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechText.__init__": [[30, 38], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTopStack", "vg.defn.encoders.TextEncoderTop", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_stack.SpeechText.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTopStack", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechText.cost": [[39, 45], ["three_way_stack.SpeechText.SpeechEncoderTop", "three_way_stack.SpeechText.TextEncoderTop", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_stack.SpeechText.SpeechEncoderBottom", "three_way_stack.SpeechText.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "text", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "text_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechText.args": [[46, 48], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechText.test_cost": [[49, 51], ["three_way_stack.SpeechText.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechImage.__init__": [[55, 62], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTopStack", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_stack.SpeechImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTopStack", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechImage.cost": [[63, 69], ["three_way_stack.SpeechImage.SpeechEncoderTop", "three_way_stack.SpeechImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_stack.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "image", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechImage.args": [[70, 72], ["None"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.SpeechImage.test_cost": [[73, 76], ["three_way_stack.SpeechImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "result", "=", "self", ".", "cost", "(", "*", "args", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.__init__": [[79, 86], ["torch.Module.__init__", "vg.defn.encoders.TextEncoderTop", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_stack.TextImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "TextImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.cost": [[87, 93], ["three_way_stack.TextImage.TextEncoderTop", "three_way_stack.TextImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_stack.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "text", ",", "image", ")", ":", "\n", "        ", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "text_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.args": [[94, 96], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.test_cost": [[97, 100], ["vg.scorer.testing", "three_way_stack.TextImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.encode_images": [[101, 105], ["vg.scorer.testing", "three_way_stack.TextImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.TextImage.predict": [[106, 110], ["vg.scorer.testing", "three_way_stack.TextImage.TextEncoderTop", "three_way_stack.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "text", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.Net.__init__": [[113, 123], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderBottomStack", "three_way_stack.SpeechImage", "config.get", "vg.defn.encoders.TextEncoderBottom", "config.get", "three_way_stack.SpeechText", "config.get", "three_way_stack.TextImage"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SpeechEncoderBottom", "=", "SpeechEncoderBottomStack", "(", "**", "config", "[", "'SpeechEncoderBottom'", "]", ")", "\n", "self", ".", "TextEncoderBottom", "=", "TextEncoderBottom", "(", "**", "config", "[", "'TextEncoderBottom'", "]", ")", "if", "config", ".", "get", "(", "'TextEncoderBottom'", ")", "else", "None", "\n", "self", ".", "SpeechText", "=", "SpeechText", "(", "self", ".", "SpeechEncoderBottom", ",", "self", ".", "TextEncoderBottom", ",", "config", "[", "'SpeechText'", "]", ")", "if", "config", ".", "get", "(", "'SpeechText'", ")", "else", "None", "\n", "self", ".", "SpeechImage", "=", "SpeechImage", "(", "self", ".", "SpeechEncoderBottom", ",", "config", "[", "'SpeechImage'", "]", ")", "\n", "self", ".", "TextImage", "=", "TextImage", "(", "self", ".", "TextEncoderBottom", ",", "config", "[", "'TextImage'", "]", ")", "if", "config", ".", "get", "(", "'TextImage'", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.Net.encode_images": [[124, 128], ["vg.scorer.testing", "three_way_stack.Net.SpeechImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.Net.predict": [[129, 133], ["vg.scorer.testing", "three_way_stack.Net.SpeechImage.SpeechEncoderTop", "three_way_stack.Net.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "audio", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechImage", ".", "SpeechEncoderBottom", "(", "audio", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.step": [[20, 27], ["task.train_cost", "task.optimizer.zero_grad", "task.train_cost.backward", "torch.utils.clip_grad_norm_", "task.parameters"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward"], ["def", "step", "(", "task", ",", "*", "args", ")", ":", "\n", "\n", "    ", "loss", "=", "task", ".", "train_cost", "(", "*", "args", ")", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.encode_texts": [[135, 140], ["numpy.vstack", "numpy.vstack", "task.TextImage.predict().data.cpu().numpy", "onion.grouper", "task.TextImage.predict().data.cpu", "task.TextImage.predict", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "task.batcher.batch_inp().astype", "task.batcher.batch_inp", "task.mapper.transform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch_inp", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "", "def", "encode_texts", "(", "task", ",", "texts", ",", "batch_size", "=", "128", ")", ":", "\n", "        ", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "task", ".", "batcher", ".", "batch_inp", "(", "task", ".", "mapper", ".", "transform", "(", "batch", ")", ")", ".", "astype", "(", "'int64'", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "texts", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.encode_images_TextImage": [[141, 148], ["numpy.vstack", "numpy.vstack", "task.TextImage.encode_images().data.cpu().numpy", "onion.grouper", "task.TextImage.encode_images().data.cpu", "task.TextImage.encode_images", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.vstack", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images"], ["", "def", "encode_images_TextImage", "(", "task", ",", "imgs", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "\"\"\"Project imgs to the joint space using model.\n    \"\"\"", "\n", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "encode_images", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "numpy", ".", "vstack", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "imgs", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.valid_loss": [[149, 157], ["vg.scorer.testing", "data[].iter_valid_batches", "task.args", "result.append", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "task.test_cost().data.cpu().numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "task.test_cost().data.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "task.test_cost"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_valid_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.test_cost"], ["", "def", "valid_loss", "(", "net", ",", "name", ",", "task", ",", "data", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "with", "testing", "(", "net", ")", ":", "#net.eval()", "\n", "            ", "for", "item", "in", "data", "[", "name", "]", ".", "iter_valid_batches", "(", ")", ":", "\n", "                ", "args", "=", "task", ".", "args", "(", "item", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "result", ".", "append", "(", "task", ".", "test_cost", "(", "*", "args", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_stack.experiment": [[158, 210], ["net.cuda", "net.train", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "task.optimizer.zero_grad", "open", "range", "dict", "enumerate", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "zip", "dict", "vg.scorer.testing", "dict", "out.write", "out.write", "out.flush", "collections.Counter", "collections.Counter", "collections.Counter", "data[].iter_train_batches", "data[].iter_train_batches", "data[].iter_train_batches", "task.args", "task.cost", "task.optimizer.zero_grad", "valid_loss.backward", "torch.utils.clip_grad_norm_", "task.optimizer.step", "collections.Counter", "print", "sys.stdout.flush", "json.dumps", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "task.parameters", "three_way_stack.valid_loss", "print", "scorer.rsa_image", "scorer.retrieval", "scorer.speaker_id", "len", "valid_loss.data.item", "set", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "str", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "str", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.step", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.valid_loss", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.rsa_image", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.retrieval", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.speaker_id"], ["", "def", "experiment", "(", "net", ",", "data", ",", "run_config", ")", ":", "\n", "\n", "    ", "net", ".", "cuda", "(", ")", "\n", "net", ".", "train", "(", ")", "\n", "scorer", "=", "run_config", "[", "'Scorer'", "]", "\n", "last_epoch", "=", "0", "\n", "\n", "for", "_", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "        ", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "with", "open", "(", "\"result.json\"", ",", "\"w\"", ")", "as", "out", ":", "\n", "      ", "for", "epoch", "in", "range", "(", "last_epoch", "+", "1", ",", "run_config", "[", "'epochs'", "]", "+", "1", ")", ":", "\n", "        ", "costs", "=", "dict", "(", "SpeechText", "=", "Counter", "(", ")", ",", "SpeechImage", "=", "Counter", "(", ")", ",", "TextImage", "=", "Counter", "(", ")", ")", "\n", "\n", "for", "_j", ",", "items", "in", "enumerate", "(", "zip", "(", "data", "[", "'SpeechImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'SpeechText'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'TextImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ")", ")", ":", "\n", "            ", "j", "=", "_j", "+", "1", "\n", "item", "=", "dict", "(", "SpeechImage", "=", "items", "[", "0", "]", ",", "SpeechText", "=", "items", "[", "1", "]", ",", "TextImage", "=", "items", "[", "2", "]", ")", "\n", "for", "name", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "                ", "spk", "=", "item", "[", "name", "]", "[", "'speaker'", "]", "[", "0", "]", "if", "len", "(", "set", "(", "item", "[", "name", "]", "[", "'speaker'", "]", ")", ")", "==", "1", "else", "'MIXED'", "\n", "args", "=", "task", ".", "args", "(", "item", "[", "name", "]", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "\n", "loss", "=", "task", ".", "cost", "(", "*", "args", ")", "\n", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "task", ".", "optimizer", ".", "step", "(", ")", "\n", "costs", "[", "name", "]", "+=", "Counter", "(", "{", "'cost'", ":", "loss", ".", "data", ".", "item", "(", ")", ",", "'N'", ":", "1", "}", ")", "\n", "print", "(", "epoch", ",", "j", ",", "j", "*", "data", "[", "name", "]", ".", "batch_size", ",", "name", ",", "spk", ",", "\"train\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "costs", "[", "name", "]", "[", "'cost'", "]", "/", "costs", "[", "name", "]", "[", "'N'", "]", ")", "]", ")", ")", "\n", "\n", "if", "j", "%", "run_config", "[", "'validate_period'", "]", "==", "0", ":", "\n", "                    ", "loss", "=", "valid_loss", "(", "net", ",", "name", ",", "task", ",", "data", ")", "\n", "print", "(", "epoch", ",", "j", ",", "0", ",", "name", ",", "\"VALID\"", ",", "\"valid\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "numpy", ".", "mean", "(", "loss", ")", ")", "]", ")", ")", "\n", "\n", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "torch", ".", "save", "(", "net", ",", "\"model.{}.pkl\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "with", "testing", "(", "net", ")", ":", "\n", "            ", "result", "=", "dict", "(", "epoch", "=", "epoch", ",", "\n", "rsa", "=", "scorer", ".", "rsa_image", "(", "net", ")", ",", "\n", "retrieval", "=", "scorer", ".", "retrieval", "(", "net", ")", ",", "\n", "speaker_id", "=", "scorer", ".", "speaker_id", "(", "net", ")", ")", "\n", "out", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "out", ".", "write", "(", "\"\\n\"", ")", "\n", "out", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "", "torch", ".", "save", "(", "net", ",", "\"model.pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechText.__init__": [[31, 39], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTop", "vg.defn.encoders.TextEncoderTop", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_dec.SpeechText.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTop", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechText.cost": [[40, 46], ["three_way_dec.SpeechText.SpeechEncoderTop", "three_way_dec.SpeechText.TextEncoderTop", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_dec.SpeechText.SpeechEncoderBottom", "three_way_dec.SpeechText.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "text", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "text_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechText.args": [[47, 49], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechText.test_cost": [[50, 53], ["vg.scorer.testing", "three_way_dec.SpeechText.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechImage.__init__": [[57, 64], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTop", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_dec.SpeechImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTop", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechImage.cost": [[65, 71], ["three_way_dec.SpeechImage.SpeechEncoderTop", "three_way_dec.SpeechImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_dec.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "image", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechImage.args": [[72, 74], ["None"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechImage.test_cost": [[75, 78], ["vg.scorer.testing", "three_way_dec.SpeechImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.__init__": [[81, 88], ["torch.Module.__init__", "vg.defn.encoders.TextEncoderTop", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_dec.TextImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "TextImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.cost": [[89, 95], ["three_way_dec.TextImage.TextEncoderTop", "three_way_dec.TextImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way_dec.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "text", ",", "image", ")", ":", "\n", "        ", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "text_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.args": [[96, 98], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.test_cost": [[99, 102], ["vg.scorer.testing", "three_way_dec.TextImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.encode_images": [[103, 107], ["vg.scorer.testing", "three_way_dec.TextImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.TextImage.predict": [[108, 112], ["vg.scorer.testing", "three_way_dec.TextImage.TextEncoderTop", "three_way_dec.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "text", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechTranscriber.__init__": [[115, 122], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTop", "vg.defn.decoders.DecoderWithAttn", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way_dec.SpeechTranscriber.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechTranscriber", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTop", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "TextDecoder", "=", "DecoderWithAttn", "(", "**", "config", "[", "'TextDecoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechTranscriber.cost": [[123, 129], ["three_way_dec.SpeechTranscriber.SpeechEncoderTop.states", "three_way_dec.SpeechTranscriber.TextDecoder", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "three_way_dec.SpeechTranscriber.SpeechEncoderBottom", "three_way_dec.SpeechTranscriber.view", "target.view", "three_way_dec.SpeechTranscriber.size", "three_way_dec.SpeechTranscriber.size", "target.size", "target.size"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.encoders.SpeechEncoderTopBidi.states", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.size"], ["", "def", "cost", "(", "self", ",", "speech", ",", "target", ",", "target_prev", ")", ":", "\n", "        ", "states", ",", "rep", "=", "self", ".", "SpeechEncoderTop", ".", "states", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "target_logits", "=", "self", ".", "TextDecoder", "(", "states", ",", "rep", ",", "target_prev", ")", "\n", "cost", "=", "F", ".", "cross_entropy", "(", "target_logits", ".", "view", "(", "target_logits", ".", "size", "(", "0", ")", "*", "target_logits", ".", "size", "(", "1", ")", ",", "-", "1", ")", ",", "\n", "target", ".", "view", "(", "target", ".", "size", "(", "0", ")", "*", "target", ".", "size", "(", "1", ")", ")", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechTranscriber.args": [[130, 132], ["item[].astype", "item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'target_t'", "]", ".", "astype", "(", "'int64'", ")", ",", "item", "[", "'target_prev_t'", "]", ".", "astype", "(", "'int64'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.SpeechTranscriber.test_cost": [[133, 136], ["vg.scorer.testing", "three_way_dec.SpeechTranscriber.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.Net.__init__": [[139, 152], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderBottom", "config.get", "vg.defn.encoders.TextEncoderBottom", "config.get", "three_way_dec.SpeechText", "config.get", "three_way_dec.SpeechImage", "config.get", "three_way_dec.TextImage", "config.get", "three_way_dec.SpeechTranscriber"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SpeechEncoderBottom", "=", "SpeechEncoderBottom", "(", "**", "config", "[", "'SpeechEncoderBottom'", "]", ")", "\n", "self", ".", "TextEncoderBottom", "=", "TextEncoderBottom", "(", "**", "config", "[", "'TextEncoderBottom'", "]", ")", "if", "config", ".", "get", "(", "'TextEncoderBottom'", ")", "else", "None", "\n", "self", ".", "SpeechText", "=", "SpeechText", "(", "self", ".", "SpeechEncoderBottom", ",", "self", ".", "TextEncoderBottom", ",", "config", "[", "'SpeechText'", "]", ")", "if", "config", ".", "get", "(", "'SpeechText'", ")", "else", "None", "\n", "self", ".", "SpeechImage", "=", "SpeechImage", "(", "self", ".", "SpeechEncoderBottom", ",", "config", "[", "'SpeechImage'", "]", ")", "if", "config", ".", "get", "(", "'SpeechText'", ")", "else", "None", "\n", "self", ".", "TextImage", "=", "TextImage", "(", "self", ".", "TextEncoderBottom", ",", "config", "[", "'TextImage'", "]", ")", "if", "config", ".", "get", "(", "'TextImage'", ")", "else", "None", "\n", "self", ".", "SpeechTranscriber", "=", "SpeechTranscriber", "(", "self", ".", "SpeechEncoderBottom", ",", "config", "[", "'SpeechTranscriber'", "]", ")", "if", "config", ".", "get", "(", "'SpeechTranscriber'", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.Net.encode_images": [[153, 157], ["vg.scorer.testing", "three_way_dec.Net.SpeechImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.Net.predict": [[158, 162], ["vg.scorer.testing", "three_way_dec.Net.SpeechImage.SpeechEncoderTop", "three_way_dec.Net.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "audio", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechImage", ".", "SpeechEncoderBottom", "(", "audio", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.step": [[21, 28], ["task.train_cost", "task.optimizer.zero_grad", "task.train_cost.backward", "torch.utils.clip_grad_norm", "task.parameters"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward"], ["def", "step", "(", "task", ",", "*", "args", ")", ":", "\n", "\n", "    ", "loss", "=", "task", ".", "train_cost", "(", "*", "args", ")", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "_", "=", "nn", ".", "utils", ".", "clip_grad_norm", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.encode_texts": [[164, 169], ["numpy.vstack", "numpy.vstack", "task.TextImage.predict().data.cpu().numpy", "onion.grouper", "task.TextImage.predict().data.cpu", "task.TextImage.predict", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "task.batcher.batch_inp().astype", "task.batcher.batch_inp", "task.mapper.transform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch_inp", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "", "def", "encode_texts", "(", "task", ",", "texts", ",", "batch_size", "=", "128", ")", ":", "\n", "        ", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "task", ".", "batcher", ".", "batch_inp", "(", "task", ".", "mapper", ".", "transform", "(", "batch", ")", ")", ".", "astype", "(", "'int64'", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "texts", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.encode_images_TextImage": [[170, 177], ["numpy.vstack", "numpy.vstack", "task.TextImage.encode_images().data.cpu().numpy", "onion.grouper", "task.TextImage.encode_images().data.cpu", "task.TextImage.encode_images", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.vstack", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images"], ["", "def", "encode_images_TextImage", "(", "task", ",", "imgs", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "\"\"\"Project imgs to the joint space using model.\n    \"\"\"", "\n", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "encode_images", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "numpy", ".", "vstack", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "imgs", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way_dec.experiment": [[178, 241], ["net.cuda", "net.train", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "data[].iter_valid_batches", "task.optimizer.zero_grad", "open", "range", "task.args", "dict.append", "dict", "enumerate", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "zip", "dict", "vg.scorer.testing", "run_config.get", "x.data.cpu().numpy", "collections.Counter", "collections.Counter", "collections.Counter", "collections.Counter", "data[].iter_train_batches", "data[].iter_train_batches", "data[].iter_train_batches", "data[].iter_train_batches", "task.args", "task.cost", "task.optimizer.zero_grad", "valid_loss.backward", "torch.utils.clip_grad_norm", "task.optimizer.step", "collections.Counter", "print", "sys.stdout.flush", "dict", "out.write", "out.write", "out.flush", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "task.test_cost", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "task.parameters", "three_way_dec.experiment.valid_loss"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_valid_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.step", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.test_cost", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.valid_loss"], ["", "def", "experiment", "(", "net", ",", "data", ",", "run_config", ")", ":", "\n", "    ", "def", "valid_loss", "(", "name", ",", "task", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "item", "in", "data", "[", "name", "]", ".", "iter_valid_batches", "(", ")", ":", "\n", "            ", "args", "=", "task", ".", "args", "(", "item", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ",", "volatile", "=", "True", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "result", ".", "append", "(", "[", "x", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "x", "in", "task", ".", "test_cost", "(", "*", "args", ")", "]", ")", "\n", "", "return", "result", "\n", "\n", "", "net", ".", "cuda", "(", ")", "\n", "net", ".", "train", "(", ")", "\n", "scorer", "=", "run_config", "[", "'Scorer'", "]", "\n", "last_epoch", "=", "0", "\n", "\n", "for", "_", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "        ", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "with", "open", "(", "\"result.json\"", ",", "\"w\"", ")", "as", "out", ":", "\n", "      ", "for", "epoch", "in", "range", "(", "last_epoch", "+", "1", ",", "run_config", "[", "'epochs'", "]", "+", "1", ")", ":", "\n", "        ", "costs", "=", "dict", "(", "SpeechText", "=", "Counter", "(", ")", ",", "SpeechImage", "=", "Counter", "(", ")", ",", "TextImage", "=", "Counter", "(", ")", ",", "SpeechTranscriber", "=", "Counter", "(", ")", ")", "\n", "\n", "for", "_j", ",", "items", "in", "enumerate", "(", "zip", "(", "data", "[", "'SpeechImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'SpeechText'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'TextImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'SpeechTranscriber'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ")", ")", ":", "\n", "            ", "j", "=", "_j", "+", "1", "\n", "item", "=", "dict", "(", "SpeechImage", "=", "items", "[", "0", "]", ",", "SpeechText", "=", "items", "[", "1", "]", ",", "TextImage", "=", "items", "[", "2", "]", ",", "SpeechTranscriber", "=", "items", "[", "3", "]", ")", "\n", "for", "name", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "                ", "spk", "=", "item", "[", "name", "]", "[", "'speaker'", "]", "[", "0", "]", "if", "len", "(", "set", "(", "item", "[", "name", "]", "[", "'speaker'", "]", ")", ")", "==", "1", "else", "'MIXED'", "\n", "args", "=", "task", ".", "args", "(", "item", "[", "name", "]", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "\n", "\n", "loss", "=", "task", ".", "cost", "(", "*", "args", ")", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "_", "=", "nn", ".", "utils", ".", "clip_grad_norm", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "task", ".", "optimizer", ".", "step", "(", ")", "\n", "costs", "[", "name", "]", "+=", "Counter", "(", "{", "'cost'", ":", "loss", ".", "data", "[", "0", "]", ",", "'N'", ":", "1", "}", ")", "\n", "print", "(", "epoch", ",", "j", ",", "j", "*", "data", "[", "name", "]", ".", "batch_size", ",", "name", ",", "spk", ",", "\"train\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "costs", "[", "name", "]", "[", "'cost'", "]", "/", "costs", "[", "name", "]", "[", "'N'", "]", ")", "]", ")", ")", "\n", "\n", "if", "j", "%", "run_config", "[", "'validate_period'", "]", "==", "0", ":", "\n", "                    ", "loss", "=", "valid_loss", "(", "name", ",", "task", ")", "\n", "print", "(", "epoch", ",", "j", ",", "0", ",", "name", ",", "\"VALID\"", ",", "\"valid\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "numpy", ".", "mean", "(", "loss", ")", ")", "]", ")", ")", "\n", "\n", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "torch", ".", "save", "(", "net", ",", "\"model.{}.pkl\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "with", "testing", "(", "net", ")", ":", "\n", "            ", "if", "run_config", ".", "get", "(", "'skip_scoring'", ")", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "result", "=", "dict", "(", "epoch", "=", "epoch", ",", "\n", "rsa", "=", "scorer", ".", "rsa_image", "(", "net", ")", ",", "\n", "retrieval", "=", "scorer", ".", "retrieval", "(", "net", ")", ",", "\n", "speaker_id", "=", "scorer", ".", "speaker_id", "(", "net", ")", ")", "\n", "out", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "out", ".", "write", "(", "\"\\n\"", ")", "\n", "out", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "", "", "torch", ".", "save", "(", "net", ",", "\"model.pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechText.__init__": [[30, 38], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTop", "vg.defn.encoders.TextEncoderTop", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way2.SpeechText.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTop", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechText.cost": [[39, 45], ["three_way2.SpeechText.SpeechEncoderTop", "three_way2.SpeechText.TextEncoderTop", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way2.SpeechText.SpeechEncoderBottom", "three_way2.SpeechText.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "text", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "text_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechText.args": [[46, 48], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechText.test_cost": [[49, 51], ["three_way2.SpeechText.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechImage.__init__": [[55, 62], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderTop", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way2.SpeechImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "speech_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "SpeechImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "SpeechEncoderBottom", "=", "speech_encoder", "\n", "self", ".", "SpeechEncoderTop", "=", "SpeechEncoderTop", "(", "**", "config", "[", "'SpeechEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechImage.cost": [[63, 69], ["three_way2.SpeechImage.SpeechEncoderTop", "three_way2.SpeechImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way2.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "speech", ",", "image", ")", ":", "\n", "        ", "speech_enc", "=", "self", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechEncoderBottom", "(", "speech", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "speech_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechImage.args": [[70, 72], ["None"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'audio'", "]", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.SpeechImage.test_cost": [[73, 76], ["three_way2.SpeechImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "result", "=", "self", ".", "cost", "(", "*", "args", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.__init__": [[79, 86], ["torch.Module.__init__", "vg.defn.encoders.TextEncoderTop", "vg.defn.encoders.ImageEncoder", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "three_way2.TextImage.parameters"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "text_encoder", ",", "config", ")", ":", "\n", "        ", "super", "(", "TextImage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "TextEncoderBottom", "=", "text_encoder", "\n", "self", ".", "TextEncoderTop", "=", "TextEncoderTop", "(", "**", "config", "[", "'TextEncoderTop'", "]", ")", "\n", "self", ".", "ImageEncoder", "=", "ImageEncoder", "(", "**", "config", "[", "'ImageEncoder'", "]", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "config", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost": [[87, 93], ["three_way2.TextImage.TextEncoderTop", "three_way2.TextImage.ImageEncoder", "onion.cosine_matrix", "onion.cosine_matrix", "onion.contrastive", "onion.contrastive", "three_way2.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.cosine_matrix", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.loss.contrastive"], ["", "def", "cost", "(", "self", ",", "text", ",", "image", ")", ":", "\n", "        ", "text_enc", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "image_enc", "=", "self", ".", "ImageEncoder", "(", "image", ")", "\n", "scores", "=", "loss", ".", "cosine_matrix", "(", "text_enc", ",", "image_enc", ")", "\n", "cost", "=", "loss", ".", "contrastive", "(", "scores", ",", "margin", "=", "self", ".", "config", "[", "'margin_size'", "]", ")", "\n", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args": [[94, 96], ["item[].astype"], "methods", ["None"], ["", "def", "args", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "item", "[", "'input'", "]", ".", "astype", "(", "'int64'", ")", ",", "item", "[", "'target_v'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.test_cost": [[97, 100], ["vg.scorer.testing", "three_way2.TextImage.cost"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost"], ["", "def", "test_cost", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "return", "self", ".", "cost", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.encode_images": [[101, 105], ["vg.scorer.testing", "three_way2.TextImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.predict": [[106, 110], ["vg.scorer.testing", "three_way2.TextImage.TextEncoderTop", "three_way2.TextImage.TextEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "text", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "TextEncoderTop", "(", "self", ".", "TextEncoderBottom", "(", "text", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__": [[113, 123], ["torch.Module.__init__", "vg.defn.encoders.SpeechEncoderBottom", "three_way2.SpeechImage", "config.get", "vg.defn.encoders.TextEncoderBottom", "config.get", "three_way2.SpeechText", "config.get", "three_way2.TextImage"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SpeechEncoderBottom", "=", "SpeechEncoderBottom", "(", "**", "config", "[", "'SpeechEncoderBottom'", "]", ")", "\n", "self", ".", "TextEncoderBottom", "=", "TextEncoderBottom", "(", "**", "config", "[", "'TextEncoderBottom'", "]", ")", "if", "config", ".", "get", "(", "'TextEncoderBottom'", ")", "else", "None", "\n", "self", ".", "SpeechText", "=", "SpeechText", "(", "self", ".", "SpeechEncoderBottom", ",", "self", ".", "TextEncoderBottom", ",", "config", "[", "'SpeechText'", "]", ")", "if", "config", ".", "get", "(", "'SpeechText'", ")", "else", "None", "\n", "self", ".", "SpeechImage", "=", "SpeechImage", "(", "self", ".", "SpeechEncoderBottom", ",", "config", "[", "'SpeechImage'", "]", ")", "\n", "self", ".", "TextImage", "=", "TextImage", "(", "self", ".", "TextEncoderBottom", ",", "config", "[", "'TextImage'", "]", ")", "if", "config", ".", "get", "(", "'TextImage'", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images": [[124, 128], ["vg.scorer.testing", "three_way2.Net.SpeechImage.ImageEncoder"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "encode_images", "(", "self", ",", "images", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "ImageEncoder", "(", "images", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict": [[129, 133], ["vg.scorer.testing", "three_way2.Net.SpeechImage.SpeechEncoderTop", "three_way2.Net.SpeechImage.SpeechEncoderBottom"], "methods", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing"], ["", "def", "predict", "(", "self", ",", "audio", ")", ":", "\n", "        ", "with", "testing", "(", "self", ")", ":", "\n", "            ", "rep", "=", "self", ".", "SpeechImage", ".", "SpeechEncoderTop", "(", "self", ".", "SpeechImage", ".", "SpeechEncoderBottom", "(", "audio", ")", ")", "\n", "", "return", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.step": [[20, 27], ["task.train_cost", "task.optimizer.zero_grad", "task.train_cost.backward", "torch.utils.clip_grad_norm_", "task.parameters"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward"], ["def", "step", "(", "task", ",", "*", "args", ")", ":", "\n", "\n", "    ", "loss", "=", "task", ".", "train_cost", "(", "*", "args", ")", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.encode_texts": [[135, 140], ["numpy.vstack", "numpy.vstack", "task.TextImage.predict().data.cpu().numpy", "onion.grouper", "task.TextImage.predict().data.cpu", "task.TextImage.predict", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "task.batcher.batch_inp().astype", "task.batcher.batch_inp", "task.mapper.transform"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.predict", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.Batcher.batch_inp", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.IdMapper.transform"], ["", "", "def", "encode_texts", "(", "task", ",", "texts", ",", "batch_size", "=", "128", ")", ":", "\n", "        ", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "predict", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "task", ".", "batcher", ".", "batch_inp", "(", "task", ".", "mapper", ".", "transform", "(", "batch", ")", ")", ".", "astype", "(", "'int64'", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "texts", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.encode_images_TextImage": [[141, 148], ["numpy.vstack", "numpy.vstack", "task.TextImage.encode_images().data.cpu().numpy", "onion.grouper", "task.TextImage.encode_images().data.cpu", "task.TextImage.encode_images", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.vstack", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.util.grouper", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.Net.encode_images"], ["", "def", "encode_images_TextImage", "(", "task", ",", "imgs", ",", "batch_size", "=", "128", ")", ":", "\n", "    ", "\"\"\"Project imgs to the joint space using model.\n    \"\"\"", "\n", "return", "numpy", ".", "vstack", "(", "[", "task", ".", "TextImage", ".", "encode_images", "(", "\n", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "\n", "numpy", ".", "vstack", "(", "batch", ")", ")", ")", ".", "cuda", "(", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "batch", "in", "util", ".", "grouper", "(", "imgs", ",", "batch_size", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.valid_loss": [[149, 157], ["vg.scorer.testing", "data[].iter_valid_batches", "task.args", "result.append", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "task.test_cost().data.cpu().numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "task.test_cost().data.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "task.test_cost"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_valid_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.test_cost"], ["", "def", "valid_loss", "(", "net", ",", "name", ",", "task", ",", "data", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "with", "testing", "(", "net", ")", ":", "#net.eval()", "\n", "            ", "for", "item", "in", "data", "[", "name", "]", ".", "iter_valid_batches", "(", ")", ":", "\n", "                ", "args", "=", "task", ".", "args", "(", "item", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "result", ".", "append", "(", "task", ".", "test_cost", "(", "*", "args", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.experiment": [[158, 210], ["net.cuda", "net.train", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "task.optimizer.zero_grad", "open", "range", "dict", "enumerate", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "zip", "dict", "vg.scorer.testing", "dict", "out.write", "out.write", "out.flush", "collections.Counter", "collections.Counter", "collections.Counter", "data[].iter_train_batches", "data[].iter_train_batches", "data[].iter_train_batches", "task.args", "task.cost", "task.optimizer.zero_grad", "valid_loss.backward", "torch.utils.clip_grad_norm_", "task.optimizer.step", "collections.Counter", "print", "sys.stdout.flush", "json.dumps", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "task.parameters", "three_way2.valid_loss", "print", "scorer.rsa_image", "scorer.retrieval", "scorer.speaker_id", "len", "valid_loss.data.item", "set", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "str", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "str", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.bundle.Bundle.save", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.testing", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.simple_data.SimpleData.iter_train_batches", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.args", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.TextImage.cost", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.onion.grad_reverse.GradReverse.backward", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.step", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.defn.three_way2.valid_loss", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.rsa_image", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.retrieval", "home.repos.pwc.inspect_result.gchrupala_symbolic-bias.vg.scorer.Scorer.speaker_id"], ["", "def", "experiment", "(", "net", ",", "data", ",", "run_config", ")", ":", "\n", "\n", "    ", "net", ".", "cuda", "(", ")", "\n", "net", ".", "train", "(", ")", "\n", "scorer", "=", "run_config", "[", "'Scorer'", "]", "\n", "last_epoch", "=", "0", "\n", "\n", "for", "_", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "        ", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "with", "open", "(", "\"result.json\"", ",", "\"w\"", ")", "as", "out", ":", "\n", "      ", "for", "epoch", "in", "range", "(", "last_epoch", "+", "1", ",", "run_config", "[", "'epochs'", "]", "+", "1", ")", ":", "\n", "        ", "costs", "=", "dict", "(", "SpeechText", "=", "Counter", "(", ")", ",", "SpeechImage", "=", "Counter", "(", ")", ",", "TextImage", "=", "Counter", "(", ")", ")", "\n", "\n", "for", "_j", ",", "items", "in", "enumerate", "(", "zip", "(", "data", "[", "'SpeechImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'SpeechText'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ",", "\n", "data", "[", "'TextImage'", "]", ".", "iter_train_batches", "(", "reshuffle", "=", "True", ")", ")", ")", ":", "\n", "            ", "j", "=", "_j", "+", "1", "\n", "item", "=", "dict", "(", "SpeechImage", "=", "items", "[", "0", "]", ",", "SpeechText", "=", "items", "[", "1", "]", ",", "TextImage", "=", "items", "[", "2", "]", ")", "\n", "for", "name", ",", "task", "in", "run_config", "[", "'tasks'", "]", ":", "\n", "                ", "spk", "=", "item", "[", "name", "]", "[", "'speaker'", "]", "[", "0", "]", "if", "len", "(", "set", "(", "item", "[", "name", "]", "[", "'speaker'", "]", ")", ")", "==", "1", "else", "'MIXED'", "\n", "args", "=", "task", ".", "args", "(", "item", "[", "name", "]", ")", "\n", "args", "=", "[", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "cuda", "(", ")", "for", "x", "in", "args", "]", "\n", "\n", "loss", "=", "task", ".", "cost", "(", "*", "args", ")", "\n", "\n", "task", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "task", ".", "parameters", "(", ")", ",", "task", ".", "config", "[", "'max_norm'", "]", ")", "\n", "task", ".", "optimizer", ".", "step", "(", ")", "\n", "costs", "[", "name", "]", "+=", "Counter", "(", "{", "'cost'", ":", "loss", ".", "data", ".", "item", "(", ")", ",", "'N'", ":", "1", "}", ")", "\n", "print", "(", "epoch", ",", "j", ",", "j", "*", "data", "[", "name", "]", ".", "batch_size", ",", "name", ",", "spk", ",", "\"train\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "costs", "[", "name", "]", "[", "'cost'", "]", "/", "costs", "[", "name", "]", "[", "'N'", "]", ")", "]", ")", ")", "\n", "\n", "if", "j", "%", "run_config", "[", "'validate_period'", "]", "==", "0", ":", "\n", "                    ", "loss", "=", "valid_loss", "(", "net", ",", "name", ",", "task", ",", "data", ")", "\n", "print", "(", "epoch", ",", "j", ",", "0", ",", "name", ",", "\"VALID\"", ",", "\"valid\"", ",", "\"\"", ".", "join", "(", "[", "str", "(", "numpy", ".", "mean", "(", "loss", ")", ")", "]", ")", ")", "\n", "\n", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "torch", ".", "save", "(", "net", ",", "\"model.{}.pkl\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "with", "testing", "(", "net", ")", ":", "\n", "            ", "result", "=", "dict", "(", "epoch", "=", "epoch", ",", "\n", "rsa", "=", "scorer", ".", "rsa_image", "(", "net", ")", ",", "\n", "retrieval", "=", "scorer", ".", "retrieval", "(", "net", ")", ",", "\n", "speaker_id", "=", "scorer", ".", "speaker_id", "(", "net", ")", ")", "\n", "out", ".", "write", "(", "json", ".", "dumps", "(", "result", ")", ")", "\n", "out", ".", "write", "(", "\"\\n\"", ")", "\n", "out", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "", "torch", ".", "save", "(", "net", ",", "\"model.pkl\"", ")", "\n", "\n"]]}