{"home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_pretrain.main": [[58, 221], ["pytorch_lightning.seed_everything", "solo.args.setup.parse_args_pretrain", "solo.utils.misc.make_contiguous", "pytorch_lightning.Trainer.from_argparse_args", "PretrainDALIDataModule", "solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.pretrain_dataloader.prepare_datasets", "solo.utils.pretrain_dataloader.prepare_dataloader", "solo.utils.auto_resumer.AutoResumer", "solo.utils.auto_resumer.AutoResumer.find_checkpoint", "solo.utils.checkpointer.Checkpointer", "callbacks.append", "AutoUMAP", "callbacks.append", "pytorch_lightning.loggers.WandbLogger", "pytorch_lightning.loggers.WandbLogger.watch", "pytorch_lightning.loggers.WandbLogger.log_hyperparams", "pytorch_lightning.callbacks.LearningRateMonitor", "callbacks.append", "WorkaroundFitLoop", "Trainer.from_argparse_args.fit", "Trainer.from_argparse_args.fit", "solo.methods.METHODS.keys", "solo.utils.classification_dataloader.prepare_data", "print", "pprint.pprint", "print", "solo.utils.pretrain_dataloader.prepare_transform", "os.path.join", "os.path.join", "os.path.join", "pytorch_lightning.strategies.ddp.DDPStrategy"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.make_contiguous", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_dataloader", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.find_checkpoint", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_data", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform"], ["def", "main", "(", ")", ":", "\n", "    ", "seed_everything", "(", "5", ")", "\n", "\n", "args", "=", "parse_args_pretrain", "(", ")", "\n", "\n", "assert", "args", ".", "method", "in", "METHODS", ",", "f\"Choose from {METHODS.keys()}\"", "\n", "\n", "if", "args", ".", "num_large_crops", "!=", "2", ":", "\n", "        ", "assert", "args", ".", "method", "==", "\"wmse\"", "\n", "\n", "", "model", "=", "METHODS", "[", "args", ".", "method", "]", "(", "**", "args", ".", "__dict__", ")", "\n", "make_contiguous", "(", "model", ")", "\n", "\n", "# validation dataloader for when it is available", "\n", "if", "args", ".", "dataset", "==", "\"custom\"", "and", "(", "args", ".", "no_labels", "or", "args", ".", "val_dir", "is", "None", ")", ":", "\n", "        ", "val_loader", "=", "None", "\n", "", "elif", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", "and", "args", ".", "val_dir", "is", "None", ":", "\n", "        ", "val_loader", "=", "None", "\n", "", "else", ":", "\n", "        ", "_", ",", "val_loader", "=", "prepare_data_classification", "(", "\n", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", "\n", "\n", "# pretrain dataloader", "\n", "", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "_dali_avaliable", ",", "\"Dali is not avaiable, please install it first with [dali].\"", "\n", "\n", "dali_datamodule", "=", "PretrainDALIDataModule", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "unique_augs", "=", "args", ".", "unique_augs", ",", "\n", "transform_kwargs", "=", "args", ".", "transform_kwargs", ",", "\n", "num_crops_per_aug", "=", "args", ".", "num_crops_per_aug", ",", "\n", "num_large_crops", "=", "args", ".", "num_large_crops", ",", "\n", "num_small_crops", "=", "args", ".", "num_small_crops", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "no_labels", "=", "args", ".", "no_labels", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", "dali_device", "=", "args", ".", "dali_device", ",", "\n", "encode_indexes_into_labels", "=", "args", ".", "encode_indexes_into_labels", ",", "\n", ")", "\n", "dali_datamodule", ".", "val_dataloader", "=", "lambda", ":", "val_loader", "\n", "", "else", ":", "\n", "        ", "transform_kwargs", "=", "(", "\n", "args", ".", "transform_kwargs", "if", "args", ".", "unique_augs", ">", "1", "else", "[", "args", ".", "transform_kwargs", "]", "\n", ")", "\n", "transform", "=", "prepare_n_crop_transform", "(", "\n", "[", "prepare_transform", "(", "args", ".", "dataset", ",", "**", "kwargs", ")", "for", "kwargs", "in", "transform_kwargs", "]", ",", "\n", "num_crops_per_aug", "=", "args", ".", "num_crops_per_aug", ",", "\n", ")", "\n", "\n", "if", "args", ".", "debug_augmentations", ":", "\n", "            ", "print", "(", "\"Transforms:\"", ")", "\n", "pprint", "(", "transform", ")", "\n", "\n", "", "train_dataset", "=", "prepare_datasets", "(", "\n", "args", ".", "dataset", ",", "\n", "transform", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "no_labels", "=", "args", ".", "no_labels", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", ")", "\n", "train_loader", "=", "prepare_dataloader", "(", "\n", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", "\n", ")", "\n", "\n", "# 1.7 will deprecate resume_from_checkpoint, but for the moment", "\n", "# the argument is the same, but we need to pass it as ckpt_path to trainer.fit", "\n", "", "ckpt_path", ",", "wandb_run_id", "=", "None", ",", "None", "\n", "if", "args", ".", "auto_resume", "and", "args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "        ", "auto_resumer", "=", "AutoResumer", "(", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "args", ".", "method", ")", ",", "\n", "max_hours", "=", "args", ".", "auto_resumer_max_hours", ",", "\n", ")", "\n", "resume_from_checkpoint", ",", "wandb_run_id", "=", "auto_resumer", ".", "find_checkpoint", "(", "args", ")", "\n", "if", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"Resuming from previous checkpoint that matches specifications:\"", ",", "\n", "f\"'{resume_from_checkpoint}'\"", ",", "\n", ")", "\n", "ckpt_path", "=", "resume_from_checkpoint", "\n", "", "", "elif", "args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "        ", "ckpt_path", "=", "args", ".", "resume_from_checkpoint", "\n", "del", "args", ".", "resume_from_checkpoint", "\n", "\n", "", "callbacks", "=", "[", "]", "\n", "\n", "if", "args", ".", "save_checkpoint", ":", "\n", "# save checkpoint on last epoch only", "\n", "        ", "ckpt", "=", "Checkpointer", "(", "\n", "args", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "args", ".", "method", ")", ",", "\n", "frequency", "=", "args", ".", "checkpoint_frequency", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "ckpt", ")", "\n", "\n", "", "if", "args", ".", "auto_umap", ":", "\n", "        ", "assert", "(", "\n", "_umap_available", "\n", ")", ",", "\"UMAP is not currently avaiable, please install it first with [umap].\"", "\n", "auto_umap", "=", "AutoUMAP", "(", "\n", "args", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "auto_umap_dir", ",", "args", ".", "method", ")", ",", "\n", "frequency", "=", "args", ".", "auto_umap_frequency", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "auto_umap", ")", "\n", "\n", "# wandb logging", "\n", "", "if", "args", ".", "wandb", ":", "\n", "        ", "wandb_logger", "=", "WandbLogger", "(", "\n", "name", "=", "args", ".", "name", ",", "\n", "project", "=", "args", ".", "project", ",", "\n", "entity", "=", "args", ".", "entity", ",", "\n", "offline", "=", "args", ".", "offline", ",", "\n", "resume", "=", "\"allow\"", "if", "wandb_run_id", "else", "None", ",", "\n", "id", "=", "wandb_run_id", ",", "\n", ")", "\n", "wandb_logger", ".", "watch", "(", "model", ",", "log", "=", "\"gradients\"", ",", "log_freq", "=", "100", ")", "\n", "wandb_logger", ".", "log_hyperparams", "(", "args", ")", "\n", "\n", "# lr logging", "\n", "lr_monitor", "=", "LearningRateMonitor", "(", "logging_interval", "=", "\"step\"", ")", "\n", "callbacks", ".", "append", "(", "lr_monitor", ")", "\n", "\n", "", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "logger", "=", "wandb_logger", "if", "args", ".", "wandb", "else", "None", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "enable_checkpointing", "=", "False", ",", "\n", "strategy", "=", "DDPStrategy", "(", "find_unused_parameters", "=", "False", ")", "\n", "if", "args", ".", "strategy", "==", "\"ddp\"", "\n", "else", "args", ".", "strategy", ",", "\n", ")", "\n", "\n", "# fix for incompatibility with nvidia-dali and pytorch lightning", "\n", "# with dali 1.15 (this will be fixed on 1.16)", "\n", "# https://github.com/Lightning-AI/lightning/issues/12956", "\n", "try", ":", "\n", "        ", "from", "pytorch_lightning", ".", "loops", "import", "FitLoop", "\n", "\n", "class", "WorkaroundFitLoop", "(", "FitLoop", ")", ":", "\n", "            ", "@", "property", "\n", "def", "prefetch_batches", "(", "self", ")", "->", "int", ":", "\n", "                ", "return", "1", "\n", "\n", "", "", "trainer", ".", "fit_loop", "=", "WorkaroundFitLoop", "(", "\n", "trainer", ".", "fit_loop", ".", "min_epochs", ",", "trainer", ".", "fit_loop", ".", "max_epochs", "\n", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "if", "args", ".", "dali", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "ckpt_path", "=", "ckpt_path", ",", "datamodule", "=", "dali_datamodule", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "train_loader", ",", "val_loader", ",", "ckpt_path", "=", "ckpt_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_umap.main": [[30, 68], ["solo.args.setup.parse_args_umap", "pathlib.Path", "model.to.cuda", "solo.utils.classification_dataloader.prepare_data", "solo.utils.auto_umap.OfflineUMAP", "model.to.to", "solo.utils.auto_umap.OfflineUMAP.plot", "solo.utils.auto_umap.OfflineUMAP.plot", "open", "json.load", "METHODS[].load_from_checkpoint", "os.listdir", "ckpt.endswith"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_umap", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_data", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.OfflineUMAP.plot", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.OfflineUMAP.plot"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args_umap", "(", ")", "\n", "\n", "# build paths", "\n", "ckpt_dir", "=", "Path", "(", "args", ".", "pretrained_checkpoint_dir", ")", "\n", "args_path", "=", "ckpt_dir", "/", "\"args.json\"", "\n", "ckpt_path", "=", "[", "ckpt_dir", "/", "ckpt", "for", "ckpt", "in", "os", ".", "listdir", "(", "ckpt_dir", ")", "if", "ckpt", ".", "endswith", "(", "\".ckpt\"", ")", "]", "[", "0", "]", "\n", "\n", "# load arguments", "\n", "with", "open", "(", "args_path", ")", "as", "f", ":", "\n", "        ", "method_args", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# build the model", "\n", "", "model", "=", "(", "\n", "METHODS", "[", "method_args", "[", "\"method\"", "]", "]", "\n", ".", "load_from_checkpoint", "(", "ckpt_path", ",", "strict", "=", "False", ",", "**", "method_args", ")", "\n", ".", "backbone", "\n", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "# prepare data", "\n", "train_loader", ",", "val_loader", "=", "prepare_data", "(", "\n", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", "\n", "\n", "umap", "=", "OfflineUMAP", "(", ")", "\n", "\n", "# move model to the gpu", "\n", "device", "=", "\"cuda:0\"", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "umap", ".", "plot", "(", "device", ",", "model", ",", "train_loader", ",", "\"im100_train_umap.pdf\"", ")", "\n", "umap", ".", "plot", "(", "device", ",", "model", ",", "val_loader", ",", "\"im100_val_umap.pdf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.setup.parse_requirements": [[31, 35], ["open", "p.strip().split", "f.readlines", "p.strip"], "function", ["None"], ["def", "parse_requirements", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "        ", "requirements", "=", "[", "p", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", "for", "p", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "return", "requirements", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_linear.main": [[58, 221], ["solo.args.setup.parse_args_linear", "kwargs.pop", "backbone_model", "solo.args.setup.parse_args_linear.backbone.startswith", "list", "backbone_model.load_state_dict", "print", "solo.methods.linear.LinearModel", "solo.utils.misc.make_contiguous", "solo.utils.classification_dataloader.prepare_data", "pytorch_lightning.Trainer.from_argparse_args", "torch.Identity", "solo.args.setup.parse_args_linear.pretrained_feature_extractor.endswith", "solo.args.setup.parse_args_linear.pretrained_feature_extractor.endswith", "solo.args.setup.parse_args_linear.pretrained_feature_extractor.endswith", "torch.load", "torch.load", "state.keys", "ClassificationDALIDataModule", "solo.utils.auto_resumer.AutoResumer", "solo.utils.auto_resumer.AutoResumer.find_checkpoint", "solo.utils.checkpointer.Checkpointer", "callbacks.append", "pytorch_lightning.loggers.WandbLogger", "pytorch_lightning.loggers.WandbLogger.watch", "pytorch_lightning.loggers.WandbLogger.log_hyperparams", "pytorch_lightning.callbacks.LearningRateMonitor", "callbacks.append", "WorkaroundFitLoop", "Trainer.from_argparse_args.fit", "Trainer.from_argparse_args.fit", "torch.Conv2d", "torch.Identity", "warnings.warn", "print", "os.path.join", "os.path.join", "pytorch_lightning.strategies.ddp.DDPStrategy", "k.replace", "k.replace"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_linear", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.make_contiguous", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_data", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.find_checkpoint"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args_linear", "(", ")", "\n", "\n", "assert", "args", ".", "backbone", "in", "BaseMethod", ".", "_BACKBONES", "\n", "backbone_model", "=", "{", "\n", "\"resnet18\"", ":", "resnet18", ",", "\n", "\"resnet50\"", ":", "resnet50", ",", "\n", "\"vit_tiny\"", ":", "vit_tiny", ",", "\n", "\"vit_small\"", ":", "vit_small", ",", "\n", "\"vit_base\"", ":", "vit_base", ",", "\n", "\"vit_large\"", ":", "vit_large", ",", "\n", "\"swin_tiny\"", ":", "swin_tiny", ",", "\n", "\"swin_small\"", ":", "swin_small", ",", "\n", "\"swin_base\"", ":", "swin_base", ",", "\n", "\"swin_large\"", ":", "swin_large", ",", "\n", "}", "[", "args", ".", "backbone", "]", "\n", "\n", "# initialize backbone", "\n", "kwargs", "=", "args", ".", "backbone_args", "\n", "cifar", "=", "kwargs", ".", "pop", "(", "\"cifar\"", ",", "False", ")", "\n", "# swin specific", "\n", "if", "\"swin\"", "in", "args", ".", "backbone", "and", "cifar", ":", "\n", "        ", "kwargs", "[", "\"window_size\"", "]", "=", "4", "\n", "\n", "", "backbone", "=", "backbone_model", "(", "**", "kwargs", ")", "\n", "if", "args", ".", "backbone", ".", "startswith", "(", "\"resnet\"", ")", ":", "\n", "# remove fc layer", "\n", "        ", "backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "cifar", ":", "\n", "            ", "backbone", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", "\n", "backbone", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "", "", "assert", "(", "\n", "args", ".", "pretrained_feature_extractor", ".", "endswith", "(", "\".ckpt\"", ")", "\n", "or", "args", ".", "pretrained_feature_extractor", ".", "endswith", "(", "\".pth\"", ")", "\n", "or", "args", ".", "pretrained_feature_extractor", ".", "endswith", "(", "\".pt\"", ")", "\n", ")", "\n", "ckpt_path", "=", "args", ".", "pretrained_feature_extractor", "\n", "\n", "state", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "\"cpu\"", ")", "[", "\"state_dict\"", "]", "\n", "for", "k", "in", "list", "(", "state", ".", "keys", "(", ")", ")", ":", "\n", "        ", "if", "\"encoder\"", "in", "k", ":", "\n", "            ", "state", "[", "k", ".", "replace", "(", "\"encoder\"", ",", "\"backbone\"", ")", "]", "=", "state", "[", "k", "]", "\n", "warnings", ".", "warn", "(", "\n", "\"You are using an older checkpoint. Use a new one as some issues might arrise.\"", "\n", ")", "\n", "", "if", "\"backbone\"", "in", "k", ":", "\n", "            ", "state", "[", "k", ".", "replace", "(", "\"backbone.\"", ",", "\"\"", ")", "]", "=", "state", "[", "k", "]", "\n", "", "del", "state", "[", "k", "]", "\n", "", "backbone", ".", "load_state_dict", "(", "state", ",", "strict", "=", "False", ")", "\n", "\n", "print", "(", "f\"loaded {ckpt_path}\"", ")", "\n", "\n", "del", "args", ".", "backbone", "\n", "model", "=", "LinearModel", "(", "backbone", ",", "**", "args", ".", "__dict__", ")", "\n", "make_contiguous", "(", "model", ")", "\n", "\n", "train_loader", ",", "val_loader", "=", "prepare_data", "(", "\n", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", ")", "\n", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "(", "\n", "_dali_avaliable", "\n", ")", ",", "\"Dali is not currently avaiable, please install it first with [dali].\"", "\n", "\n", "dali_datamodule", "=", "ClassificationDALIDataModule", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", "dali_device", "=", "args", ".", "dali_device", ",", "\n", ")", "\n", "\n", "# use normal torchvision dataloader for validation to save memory", "\n", "dali_datamodule", ".", "val_dataloader", "=", "lambda", ":", "val_loader", "\n", "\n", "# 1.7 will deprecate resume_from_checkpoint, but for the moment", "\n", "# the argument is the same, but we need to pass it as ckpt_path to trainer.fit", "\n", "", "ckpt_path", ",", "wandb_run_id", "=", "None", ",", "None", "\n", "if", "args", ".", "auto_resume", "and", "args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "        ", "auto_resumer", "=", "AutoResumer", "(", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "\"linear\"", ")", ",", "\n", "max_hours", "=", "args", ".", "auto_resumer_max_hours", ",", "\n", ")", "\n", "resume_from_checkpoint", ",", "wandb_run_id", "=", "auto_resumer", ".", "find_checkpoint", "(", "args", ")", "\n", "if", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"Resuming from previous checkpoint that matches specifications:\"", ",", "\n", "f\"'{resume_from_checkpoint}'\"", ",", "\n", ")", "\n", "ckpt_path", "=", "resume_from_checkpoint", "\n", "", "", "elif", "args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "        ", "ckpt_path", "=", "args", ".", "resume_from_checkpoint", "\n", "del", "args", ".", "resume_from_checkpoint", "\n", "\n", "", "callbacks", "=", "[", "]", "\n", "\n", "if", "args", ".", "save_checkpoint", ":", "\n", "# save checkpoint on last epoch only", "\n", "        ", "ckpt", "=", "Checkpointer", "(", "\n", "args", ",", "\n", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "\"linear\"", ")", ",", "\n", "frequency", "=", "args", ".", "checkpoint_frequency", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "ckpt", ")", "\n", "\n", "# wandb logging", "\n", "", "if", "args", ".", "wandb", ":", "\n", "        ", "wandb_logger", "=", "WandbLogger", "(", "\n", "name", "=", "args", ".", "name", ",", "\n", "project", "=", "args", ".", "project", ",", "\n", "entity", "=", "args", ".", "entity", ",", "\n", "offline", "=", "args", ".", "offline", ",", "\n", "resume", "=", "\"allow\"", "if", "wandb_run_id", "else", "None", ",", "\n", "id", "=", "wandb_run_id", ",", "\n", ")", "\n", "wandb_logger", ".", "watch", "(", "model", ",", "log", "=", "\"gradients\"", ",", "log_freq", "=", "100", ")", "\n", "wandb_logger", ".", "log_hyperparams", "(", "args", ")", "\n", "\n", "# lr logging", "\n", "lr_monitor", "=", "LearningRateMonitor", "(", "logging_interval", "=", "\"step\"", ")", "\n", "callbacks", ".", "append", "(", "lr_monitor", ")", "\n", "\n", "", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "logger", "=", "wandb_logger", "if", "args", ".", "wandb", "else", "None", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "enable_checkpointing", "=", "False", ",", "\n", "strategy", "=", "DDPStrategy", "(", "find_unused_parameters", "=", "False", ")", "\n", "if", "args", ".", "strategy", "==", "\"ddp\"", "\n", "else", "args", ".", "strategy", ",", "\n", ")", "\n", "\n", "# fix for incompatibility with nvidia-dali and pytorch lightning", "\n", "# with dali 1.15 (this will be fixed on 1.16)", "\n", "# https://github.com/Lightning-AI/lightning/issues/12956", "\n", "try", ":", "\n", "        ", "from", "pytorch_lightning", ".", "loops", "import", "FitLoop", "\n", "\n", "class", "WorkaroundFitLoop", "(", "FitLoop", ")", ":", "\n", "            ", "@", "property", "\n", "def", "prefetch_batches", "(", "self", ")", "->", "int", ":", "\n", "                ", "return", "1", "\n", "\n", "", "", "trainer", ".", "fit_loop", "=", "WorkaroundFitLoop", "(", "\n", "trainer", ".", "fit_loop", ".", "min_epochs", ",", "trainer", ".", "fit_loop", ".", "max_epochs", "\n", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "if", "args", ".", "dali", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "ckpt_path", "=", "ckpt_path", ",", "datamodule", "=", "dali_datamodule", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ",", "train_loader", ",", "val_loader", ",", "ckpt_path", "=", "ckpt_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.extract_features": [[40, 66], ["torch.no_grad", "torch.no_grad", "model.eval", "tqdm.tqdm", "model.train", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "im.cuda.cuda", "lab.cuda.cuda", "model", "torch.cat.append", "torch.cat.append", "torch.cat.append", "outs[].detach"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "extract_features", "(", "loader", ":", "DataLoader", ",", "model", ":", "nn", ".", "Module", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Extract features from a data loader using a model.\n\n    Args:\n        loader (DataLoader): dataloader for a dataset.\n        model (nn.Module): torch module used to extract features.\n\n    Returns:\n        Tuple(torch.Tensor): tuple containing the backbone features, projector features and labels.\n    \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "backbone_features", ",", "proj_features", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "im", ",", "lab", "in", "tqdm", "(", "loader", ")", ":", "\n", "        ", "im", "=", "im", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "lab", "=", "lab", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "outs", "=", "model", "(", "im", ")", "\n", "backbone_features", ".", "append", "(", "outs", "[", "\"feats\"", "]", ".", "detach", "(", ")", ")", "\n", "proj_features", ".", "append", "(", "outs", "[", "\"z\"", "]", ")", "\n", "labels", ".", "append", "(", "lab", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "backbone_features", "=", "torch", ".", "cat", "(", "backbone_features", ")", "\n", "proj_features", "=", "torch", ".", "cat", "(", "proj_features", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ")", "\n", "return", "backbone_features", ",", "proj_features", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.run_knn": [[68, 116], ["torch.no_grad", "torch.no_grad", "solo.utils.knn.WeightedKNNClassifier", "solo.utils.knn.WeightedKNNClassifier.", "solo.utils.knn.WeightedKNNClassifier.compute"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.compute"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "run_knn", "(", "\n", "train_features", ":", "torch", ".", "Tensor", ",", "\n", "train_targets", ":", "torch", ".", "Tensor", ",", "\n", "test_features", ":", "torch", ".", "Tensor", ",", "\n", "test_targets", ":", "torch", ".", "Tensor", ",", "\n", "k", ":", "int", ",", "\n", "T", ":", "float", ",", "\n", "distance_fx", ":", "str", ",", "\n", ")", "->", "Tuple", "[", "float", "]", ":", "\n", "    ", "\"\"\"Runs offline knn on a train and a test dataset.\n\n    Args:\n        train_features (torch.Tensor, optional): train features.\n        train_targets (torch.Tensor, optional): train targets.\n        test_features (torch.Tensor, optional): test features.\n        test_targets (torch.Tensor, optional): test targets.\n        k (int): number of neighbors.\n        T (float): temperature for the exponential. Only used with cosine\n            distance.\n        distance_fx (str): distance function.\n\n    Returns:\n        Tuple[float]: tuple containing the the knn acc@1 and acc@5 for the model.\n    \"\"\"", "\n", "\n", "# build knn", "\n", "knn", "=", "WeightedKNNClassifier", "(", "\n", "k", "=", "k", ",", "\n", "T", "=", "T", ",", "\n", "distance_fx", "=", "distance_fx", ",", "\n", ")", "\n", "\n", "# add features", "\n", "knn", "(", "\n", "train_features", "=", "train_features", ",", "\n", "train_targets", "=", "train_targets", ",", "\n", "test_features", "=", "test_features", ",", "\n", "test_targets", "=", "test_targets", ",", "\n", ")", "\n", "\n", "# compute", "\n", "acc1", ",", "acc5", "=", "knn", ".", "compute", "(", ")", "\n", "\n", "# free up memory", "\n", "del", "knn", "\n", "\n", "return", "acc1", ",", "acc5", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.main": [[118, 181], ["solo.args.setup.parse_args_knn", "pathlib.Path", "METHODS[].load_from_checkpoint", "METHODS[].load_from_checkpoint.cuda", "solo.utils.classification_dataloader.prepare_transforms", "solo.utils.classification_dataloader.prepare_datasets", "solo.utils.classification_dataloader.prepare_dataloaders", "main_knn.extract_features", "main_knn.extract_features", "open", "json.load", "print", "os.listdir", "ckpt.endswith", "feat_type.upper", "print", "print", "main_knn.run_knn", "print"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_knn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.extract_features", "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.extract_features", "home.repos.pwc.inspect_result.vturrisi_solo-learn.None.main_knn.run_knn"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args_knn", "(", ")", "\n", "\n", "# build paths", "\n", "ckpt_dir", "=", "Path", "(", "args", ".", "pretrained_checkpoint_dir", ")", "\n", "args_path", "=", "ckpt_dir", "/", "\"args.json\"", "\n", "ckpt_path", "=", "[", "ckpt_dir", "/", "ckpt", "for", "ckpt", "in", "os", ".", "listdir", "(", "ckpt_dir", ")", "if", "ckpt", ".", "endswith", "(", "\".ckpt\"", ")", "]", "[", "0", "]", "\n", "\n", "# load arguments", "\n", "with", "open", "(", "args_path", ")", "as", "f", ":", "\n", "        ", "method_args", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# build the model", "\n", "", "model", "=", "METHODS", "[", "method_args", "[", "\"method\"", "]", "]", ".", "load_from_checkpoint", "(", "\n", "ckpt_path", ",", "strict", "=", "False", ",", "**", "method_args", "\n", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "# prepare data", "\n", "_", ",", "T", "=", "prepare_transforms", "(", "args", ".", "dataset", ")", "\n", "train_dataset", ",", "val_dataset", "=", "prepare_datasets", "(", "\n", "args", ".", "dataset", ",", "\n", "T_train", "=", "T", ",", "\n", "T_val", "=", "T", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "download", "=", "True", ",", "\n", ")", "\n", "train_loader", ",", "val_loader", "=", "prepare_dataloaders", "(", "\n", "train_dataset", ",", "\n", "val_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", ")", "\n", "\n", "# extract train features", "\n", "train_features_bb", ",", "train_features_proj", ",", "train_targets", "=", "extract_features", "(", "train_loader", ",", "model", ")", "\n", "train_features", "=", "{", "\"backbone\"", ":", "train_features_bb", ",", "\"projector\"", ":", "train_features_proj", "}", "\n", "\n", "# extract test features", "\n", "test_features_bb", ",", "test_features_proj", ",", "test_targets", "=", "extract_features", "(", "val_loader", ",", "model", ")", "\n", "test_features", "=", "{", "\"backbone\"", ":", "test_features_bb", ",", "\"projector\"", ":", "test_features_proj", "}", "\n", "\n", "# run k-nn for all possible combinations of parameters", "\n", "for", "feat_type", "in", "args", ".", "feature_type", ":", "\n", "        ", "print", "(", "f\"\\n### {feat_type.upper()} ###\"", ")", "\n", "for", "k", "in", "args", ".", "k", ":", "\n", "            ", "for", "distance_fx", "in", "args", ".", "distance_function", ":", "\n", "                ", "temperatures", "=", "args", ".", "temperature", "if", "distance_fx", "==", "\"cosine\"", "else", "[", "None", "]", "\n", "for", "T", "in", "temperatures", ":", "\n", "                    ", "print", "(", "\"---\"", ")", "\n", "print", "(", "f\"Running k-NN with params: distance_fx={distance_fx}, k={k}, T={T}...\"", ")", "\n", "acc1", ",", "acc5", "=", "run_knn", "(", "\n", "train_features", "=", "train_features", "[", "feat_type", "]", ",", "\n", "train_targets", "=", "train_targets", ",", "\n", "test_features", "=", "test_features", "[", "feat_type", "]", ",", "\n", "test_targets", "=", "test_targets", ",", "\n", "k", "=", "k", ",", "\n", "T", "=", "T", ",", "\n", "distance_fx", "=", "distance_fx", ",", "\n", ")", "\n", "print", "(", "f\"Result: acc@1={acc1}, acc@5={acc5}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.lars.LARS.__init__": [[70, 105], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "required", ",", "\n", "momentum", "=", "0", ",", "\n", "dampening", "=", "0", ",", "\n", "weight_decay", "=", "0", ",", "\n", "nesterov", "=", "False", ",", "\n", "eta", "=", "1e-3", ",", "\n", "eps", "=", "1e-8", ",", "\n", "clip_lars_lr", "=", "False", ",", "\n", "exclude_bias_n_norm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid learning rate: {lr}\"", ")", "\n", "", "if", "momentum", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid momentum value: {momentum}\"", ")", "\n", "", "if", "weight_decay", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid weight_decay value: {weight_decay}\"", ")", "\n", "\n", "", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "\n", "momentum", "=", "momentum", ",", "\n", "dampening", "=", "dampening", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "nesterov", "=", "nesterov", ",", "\n", "eta", "=", "eta", ",", "\n", "eps", "=", "eps", ",", "\n", "clip_lars_lr", "=", "clip_lars_lr", ",", "\n", "exclude_bias_n_norm", "=", "exclude_bias_n_norm", ",", "\n", ")", "\n", "if", "nesterov", "and", "(", "momentum", "<=", "0", "or", "dampening", "!=", "0", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Nesterov momentum requires a momentum and zero dampening\"", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.lars.LARS.__setstate__": [[106, 111], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.lars.LARS.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "\"nesterov\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.lars.LARS.step": [[112, 168], ["torch.no_grad", "torch.enable_grad", "closure", "torch.norm", "torch.norm", "p.add_", "d_p.add.add.add", "torch.clone().detach", "torch.clone().detach.mul_().add_", "d_p.add.add.add", "min", "torch.clone", "torch.clone().detach.mul_"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Args:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "loss", "=", "closure", "(", ")", "\n", "\n", "# exclude scaling for params with 0 weight decay", "\n", "", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "weight_decay", "=", "group", "[", "\"weight_decay\"", "]", "\n", "momentum", "=", "group", "[", "\"momentum\"", "]", "\n", "dampening", "=", "group", "[", "\"dampening\"", "]", "\n", "nesterov", "=", "group", "[", "\"nesterov\"", "]", "\n", "\n", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "d_p", "=", "p", ".", "grad", "\n", "p_norm", "=", "torch", ".", "norm", "(", "p", ".", "data", ")", "\n", "g_norm", "=", "torch", ".", "norm", "(", "p", ".", "grad", ".", "data", ")", "\n", "\n", "# lars scaling + weight decay part", "\n", "if", "p", ".", "ndim", "!=", "1", "or", "not", "group", "[", "\"exclude_bias_n_norm\"", "]", ":", "\n", "                    ", "if", "p_norm", "!=", "0", "and", "g_norm", "!=", "0", ":", "\n", "                        ", "lars_lr", "=", "p_norm", "/", "(", "g_norm", "+", "p_norm", "*", "weight_decay", "+", "group", "[", "\"eps\"", "]", ")", "\n", "lars_lr", "*=", "group", "[", "\"eta\"", "]", "\n", "\n", "# clip lr", "\n", "if", "group", "[", "\"clip_lars_lr\"", "]", ":", "\n", "                            ", "lars_lr", "=", "min", "(", "lars_lr", "/", "group", "[", "\"lr\"", "]", ",", "1", ")", "\n", "\n", "", "d_p", "=", "d_p", ".", "add", "(", "p", ",", "alpha", "=", "weight_decay", ")", "\n", "d_p", "*=", "lars_lr", "\n", "\n", "# sgd part", "\n", "", "", "if", "momentum", "!=", "0", ":", "\n", "                    ", "param_state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "\"momentum_buffer\"", "not", "in", "param_state", ":", "\n", "                        ", "buf", "=", "param_state", "[", "\"momentum_buffer\"", "]", "=", "torch", ".", "clone", "(", "d_p", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                        ", "buf", "=", "param_state", "[", "\"momentum_buffer\"", "]", "\n", "buf", ".", "mul_", "(", "momentum", ")", ".", "add_", "(", "d_p", ",", "alpha", "=", "1", "-", "dampening", ")", "\n", "", "if", "nesterov", ":", "\n", "                        ", "d_p", "=", "d_p", ".", "add", "(", "buf", ",", "alpha", "=", "momentum", ")", "\n", "", "else", ":", "\n", "                        ", "d_p", "=", "buf", "\n", "\n", "", "", "p", ".", "add_", "(", "d_p", ",", "alpha", "=", "-", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.__init__": [[27, 43], ["pathlib.Path", "datetime.datetime.timedelta"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "checkpoint_dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "Path", "(", "\"trained_models\"", ")", ",", "\n", "max_hours", ":", "int", "=", "36", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Autoresumer object that automatically tries to find a checkpoint\n        that is as old as max_time.\n\n        Args:\n            checkpoint_dir (Union[str, Path], optional): base directory to store checkpoints.\n                Defaults to \"trained_models\".\n            max_hours (int): maximum elapsed hours to consider checkpoint as valid.\n        \"\"\"", "\n", "\n", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "self", ".", "max_hours", "=", "timedelta", "(", "hours", "=", "max_hours", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.add_autoresumer_args": [[44, 55], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_autoresumer_args", "(", "parent_parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"Adds user-required arguments to a parser.\n\n        Args:\n            parent_parser (ArgumentParser): parser to add new args to.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"autoresumer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_resumer_max_hours\"", ",", "default", "=", "36", ",", "type", "=", "int", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.find_checkpoint": [[56, 98], ["datetime.datetime.datetime.now", "os.walk", "pathlib.Path", "sorted", "datetime.datetime.datetime.fromtimestamp", "argparse.Namespace", "all", "os.path.getctime", "Checkpoint", "sorted.append", "getattr", "json.load", "open", "getattr", "getattr", "f.endswith"], "methods", ["None"], ["", "def", "find_checkpoint", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "\"\"\"Finds a valid checkpoint that matches the arguments\n\n        Args:\n            args (Namespace): namespace object containing all settings of the model.\n        \"\"\"", "\n", "\n", "current_time", "=", "datetime", ".", "now", "(", ")", "\n", "\n", "candidates", "=", "[", "]", "\n", "for", "rootdir", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "            ", "rootdir", "=", "Path", "(", "rootdir", ")", "\n", "if", "files", ":", "\n", "# skip checkpoints that are empty", "\n", "                ", "try", ":", "\n", "                    ", "checkpoint_file", "=", "[", "rootdir", "/", "f", "for", "f", "in", "files", "if", "f", ".", "endswith", "(", "\".ckpt\"", ")", "]", "[", "0", "]", "\n", "", "except", ":", "\n", "                    ", "continue", "\n", "\n", "", "creation_time", "=", "datetime", ".", "fromtimestamp", "(", "os", ".", "path", ".", "getctime", "(", "checkpoint_file", ")", ")", "\n", "if", "current_time", "-", "creation_time", "<", "self", ".", "max_hours", ":", "\n", "                    ", "ck", "=", "Checkpoint", "(", "\n", "creation_time", "=", "creation_time", ",", "\n", "args", "=", "rootdir", "/", "\"args.json\"", ",", "\n", "checkpoint", "=", "checkpoint_file", ",", "\n", ")", "\n", "candidates", ".", "append", "(", "ck", ")", "\n", "\n", "", "", "", "if", "candidates", ":", "\n", "# sort by most recent", "\n", "            ", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "ck", ":", "ck", ".", "creation_time", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "candidate", "in", "candidates", ":", "\n", "                ", "candidate_args", "=", "Namespace", "(", "**", "json", ".", "load", "(", "open", "(", "candidate", ".", "args", ")", ")", ")", "\n", "if", "all", "(", "\n", "getattr", "(", "candidate_args", ",", "param", ",", "None", ")", "==", "getattr", "(", "args", ",", "param", ",", "None", ")", "\n", "for", "param", "in", "AutoResumer", ".", "SHOULD_MATCH", "\n", ")", ":", "\n", "                    ", "wandb_run_id", "=", "getattr", "(", "candidate_args", ",", "\"wandb_run_id\"", ",", "None", ")", "\n", "return", "candidate", ".", "checkpoint", ",", "wandb_run_id", "\n", "\n", "", "", "", "return", "None", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.accuracy_at_k": [[25, 53], ["torch.no_grad", "max", "targets.size", "outputs.topk", "pred.t.t", "pred.t.eq", "targets.view().expand_as", "correct[].contiguous().view().float().sum", "res.append", "correct[].contiguous().view().float().sum.mul_", "targets.view", "correct[].contiguous().view().float", "correct[].contiguous().view", "correct[].contiguous"], "function", ["None"], ["def", "accuracy_at_k", "(", "\n", "outputs", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ",", "top_k", ":", "Sequence", "[", "int", "]", "=", "(", "1", ",", "5", ")", "\n", ")", "->", "Sequence", "[", "int", "]", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k.\n\n    Args:\n        outputs (torch.Tensor): output of a classifier (logits or probabilities).\n        targets (torch.Tensor): ground truth labels.\n        top_k (Sequence[int], optional): sequence of top k values to compute the accuracy over.\n            Defaults to (1, 5).\n\n    Returns:\n        Sequence[int]:  accuracies at the desired k.\n    \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "top_k", ")", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "outputs", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "top_k", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean": [[55, 74], ["value.squeeze"], "function", ["None"], ["", "", "def", "weighted_mean", "(", "outputs", ":", "List", "[", "Dict", "]", ",", "key", ":", "str", ",", "batch_size_key", ":", "str", ")", "->", "float", ":", "\n", "    ", "\"\"\"Computes the mean of the values of a key weighted by the batch size.\n\n    Args:\n        outputs (List[Dict]): list of dicts containing the outputs of a validation step.\n        key (str): key of the metric of interest.\n        batch_size_key (str): key of batch size values.\n\n    Returns:\n        float: weighted mean of the values of a key\n    \"\"\"", "\n", "\n", "value", "=", "0", "\n", "n", "=", "0", "\n", "for", "out", "in", "outputs", ":", "\n", "        ", "value", "+=", "out", "[", "batch_size_key", "]", "*", "out", "[", "key", "]", "\n", "n", "+=", "out", "[", "batch_size_key", "]", "\n", "", "value", "=", "value", "/", "n", "\n", "return", "value", ".", "squeeze", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.sinkhorn_knopp.SinkhornKnopp.__init__": [[27, 44], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_iters", ":", "int", "=", "3", ",", "epsilon", ":", "float", "=", "0.05", ",", "world_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "\"\"\"Approximates optimal transport using the Sinkhorn-Knopp algorithm.\n\n        A simple iterative method to approach the double stochastic matrix is to alternately rescale\n        rows and columns of the matrix to sum to 1.\n\n        Args:\n            num_iters (int, optional):  number of times to perform row and column normalization.\n                Defaults to 3.\n            epsilon (float, optional): weight for the entropy regularization term. Defaults to 0.05.\n            world_size (int, optional): number of nodes for distributed training. Defaults to 1.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_iters", "=", "num_iters", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "world_size", "=", "world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.sinkhorn_knopp.SinkhornKnopp.forward": [[45, 85], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.exp().t", "torch.exp().t", "torch.exp().t", "torch.exp().t", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "range", "torch.exp().t.t", "torch.exp().t.t", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "self", ",", "Q", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Produces assignments using Sinkhorn-Knopp algorithm.\n\n        Applies the entropy regularization, normalizes the Q matrix and then normalizes rows and\n        columns in an alternating fashion for num_iter times. Before returning it normalizes again\n        the columns in order for the output to be an assignment of samples to prototypes.\n\n        Args:\n            Q (torch.Tensor): cosine similarities between the features of the\n                samples and the prototypes.\n\n        Returns:\n            torch.Tensor: assignment of samples to prototypes according to optimal transport.\n        \"\"\"", "\n", "\n", "Q", "=", "torch", ".", "exp", "(", "Q", "/", "self", ".", "epsilon", ")", ".", "t", "(", ")", "\n", "B", "=", "Q", ".", "shape", "[", "1", "]", "*", "self", ".", "world_size", "\n", "K", "=", "Q", ".", "shape", "[", "0", "]", "# num prototypes", "\n", "\n", "# make the matrix sums to 1", "\n", "sum_Q", "=", "torch", ".", "sum", "(", "Q", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "sum_Q", ")", "\n", "", "Q", "/=", "sum_Q", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "num_iters", ")", ":", "\n", "# normalize each row: total weight per prototype must be 1/K", "\n", "            ", "sum_of_rows", "=", "torch", ".", "sum", "(", "Q", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "dist", ".", "all_reduce", "(", "sum_of_rows", ")", "\n", "", "Q", "/=", "sum_of_rows", "\n", "Q", "/=", "K", "\n", "\n", "# normalize each column: total weight per sample must be 1/B", "\n", "Q", "/=", "torch", ".", "sum", "(", "Q", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "Q", "/=", "B", "\n", "\n", "", "Q", "*=", "B", "# the colomns must sum to 1 so that Q is an assignment", "\n", "return", "Q", ".", "t", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PatchEmbed.__init__": [[184, 195], ["torch.Module.__init__", "timm.models.layers.helpers.to_2tuple", "timm.models.layers.helpers.to_2tuple", "timm.models.layers.helpers.to_2tuple", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "patch_size", "=", "16", ",", "stride", "=", "16", ",", "padding", "=", "0", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "768", ",", "norm_layer", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "padding", "=", "to_2tuple", "(", "padding", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Conv2d", "(", "\n", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", "\n", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "if", "norm_layer", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PatchEmbed.forward": [[196, 200], ["backbones.PatchEmbed.proj", "backbones.PatchEmbed.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.LayerNormChannel.__init__": [[208, 213], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "self", ",", "num_channels", ",", "eps", "=", "1e-05", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_channels", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_channels", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.LayerNormChannel.forward": [[214, 220], ["x.mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "backbones.LayerNormChannel.bias.unsqueeze().unsqueeze", "backbones.LayerNormChannel.weight.unsqueeze().unsqueeze", "backbones.LayerNormChannel.bias.unsqueeze", "backbones.LayerNormChannel.weight.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", "=", "x", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "(", "x", "-", "u", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "torch", ".", "sqrt", "(", "s", "+", "self", ".", "eps", ")", "\n", "x", "=", "self", ".", "weight", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "x", "+", "self", ".", "bias", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.GroupNorm.__init__": [[228, 230], ["torch.GroupNorm.__init__"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "self", ",", "num_channels", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "1", ",", "num_channels", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.Pooling.__init__": [[238, 242], ["torch.Module.__init__", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "self", ",", "pool_size", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "\n", "pool_size", ",", "stride", "=", "1", ",", "padding", "=", "pool_size", "//", "2", ",", "count_include_pad", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.Pooling.forward": [[244, 246], ["backbones.Pooling.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "pool", "(", "x", ")", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.Mlp.__init__": [[254, 265], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "act_layer", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "backbones.Mlp.apply"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.0", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Conv2d", "(", "in_features", ",", "hidden_features", ",", "1", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv2d", "(", "hidden_features", ",", "out_features", ",", "1", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.Mlp._init_weights": [[266, 271], ["isinstance", "timm.models.layers.trunc_normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.trunc_normal_"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.Mlp.forward": [[272, 279], ["backbones.Mlp.fc1", "backbones.Mlp.act", "backbones.Mlp.drop", "backbones.Mlp.fc2", "backbones.Mlp.drop"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormerBlock.__init__": [[296, 328], ["torch.Module.__init__", "norm_layer", "backbones.Pooling", "norm_layer", "int", "backbones.Mlp", "timm.models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "pool_size", "=", "3", ",", "\n", "mlp_ratio", "=", "4.0", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "norm_layer", "=", "GroupNorm", ",", "\n", "drop", "=", "0.0", ",", "\n", "drop_path", "=", "0.0", ",", "\n", "use_layer_scale", "=", "True", ",", "\n", "layer_scale_init_value", "=", "1e-5", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "token_mixer", "=", "Pooling", "(", "pool_size", "=", "pool_size", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "\n", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", "\n", ")", "\n", "\n", "# The following two techniques are useful to train deep PoolFormers.", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.0", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "use_layer_scale", "=", "use_layer_scale", "\n", "if", "use_layer_scale", ":", "\n", "            ", "self", ".", "layer_scale_1", "=", "nn", ".", "Parameter", "(", "\n", "layer_scale_init_value", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", "\n", ")", "\n", "self", ".", "layer_scale_2", "=", "nn", ".", "Parameter", "(", "\n", "layer_scale_init_value", "*", "torch", ".", "ones", "(", "(", "dim", ")", ")", ",", "requires_grad", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormerBlock.forward": [[330, 342], ["backbones.PoolFormerBlock.drop_path", "backbones.PoolFormerBlock.drop_path", "backbones.PoolFormerBlock.drop_path", "backbones.PoolFormerBlock.drop_path", "backbones.PoolFormerBlock.token_mixer", "backbones.PoolFormerBlock.mlp", "backbones.PoolFormerBlock.layer_scale_1.unsqueeze().unsqueeze", "backbones.PoolFormerBlock.token_mixer", "backbones.PoolFormerBlock.layer_scale_2.unsqueeze().unsqueeze", "backbones.PoolFormerBlock.mlp", "backbones.PoolFormerBlock.norm1", "backbones.PoolFormerBlock.norm2", "backbones.PoolFormerBlock.norm1", "backbones.PoolFormerBlock.norm2", "backbones.PoolFormerBlock.layer_scale_1.unsqueeze", "backbones.PoolFormerBlock.layer_scale_2.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "use_layer_scale", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "\n", "self", ".", "layer_scale_1", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "self", ".", "token_mixer", "(", "self", ".", "norm1", "(", "x", ")", ")", "\n", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "\n", "self", ".", "layer_scale_2", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "token_mixer", "(", "self", ".", "norm1", "(", "x", ")", ")", ")", "\n", "x", "=", "x", "+", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.__init__": [[400, 500], ["torch.Module.__init__", "backbones.PatchEmbed", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "backbones.PoolFormer.apply", "copy.deepcopy", "len", "backbones.basic_blocks", "network.append", "enumerate", "norm_layer", "backbones.PoolFormer.init_weights", "network.append", "backbones.PoolFormer.add_module", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "len", "backbones.PatchEmbed", "os.environ.get", "torch.Identity", "torch.Identity", "torch.Identity", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.basic_blocks"], ["def", "__init__", "(", "\n", "self", ",", "\n", "layers", ",", "\n", "embed_dims", "=", "None", ",", "\n", "mlp_ratios", "=", "None", ",", "\n", "downsamples", "=", "None", ",", "\n", "pool_size", "=", "3", ",", "\n", "norm_layer", "=", "GroupNorm", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "num_classes", "=", "1000", ",", "\n", "in_patch_size", "=", "7", ",", "\n", "in_stride", "=", "4", ",", "\n", "in_pad", "=", "2", ",", "\n", "down_patch_size", "=", "3", ",", "\n", "down_stride", "=", "2", ",", "\n", "down_pad", "=", "1", ",", "\n", "drop_rate", "=", "0.0", ",", "\n", "drop_path_rate", "=", "0.0", ",", "\n", "use_layer_scale", "=", "True", ",", "\n", "layer_scale_init_value", "=", "1e-5", ",", "\n", "fork_feat", "=", "False", ",", "\n", "init_cfg", "=", "None", ",", "\n", "pretrained", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "not", "fork_feat", ":", "\n", "            ", "self", ".", "num_classes", "=", "num_classes", "\n", "", "self", ".", "fork_feat", "=", "fork_feat", "\n", "\n", "self", ".", "num_features", "=", "embed_dims", "[", "-", "1", "]", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "patch_size", "=", "in_patch_size", ",", "\n", "stride", "=", "in_stride", ",", "\n", "padding", "=", "in_pad", ",", "\n", "in_chans", "=", "3", ",", "\n", "embed_dim", "=", "embed_dims", "[", "0", "]", ",", "\n", ")", "\n", "\n", "# set the main block in network", "\n", "network", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "layers", ")", ")", ":", "\n", "            ", "stage", "=", "basic_blocks", "(", "\n", "embed_dims", "[", "i", "]", ",", "\n", "i", ",", "\n", "layers", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "mlp_ratio", "=", "mlp_ratios", "[", "i", "]", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", ",", "\n", "use_layer_scale", "=", "use_layer_scale", ",", "\n", "layer_scale_init_value", "=", "layer_scale_init_value", ",", "\n", ")", "\n", "network", ".", "append", "(", "stage", ")", "\n", "if", "i", ">=", "len", "(", "layers", ")", "-", "1", ":", "\n", "                ", "break", "\n", "", "if", "downsamples", "[", "i", "]", "or", "embed_dims", "[", "i", "]", "!=", "embed_dims", "[", "i", "+", "1", "]", ":", "\n", "# downsampling between two stages", "\n", "                ", "network", ".", "append", "(", "\n", "PatchEmbed", "(", "\n", "patch_size", "=", "down_patch_size", ",", "\n", "stride", "=", "down_stride", ",", "\n", "padding", "=", "down_pad", ",", "\n", "in_chans", "=", "embed_dims", "[", "i", "]", ",", "\n", "embed_dim", "=", "embed_dims", "[", "i", "+", "1", "]", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "network", "=", "nn", ".", "ModuleList", "(", "network", ")", "\n", "\n", "if", "self", ".", "fork_feat", ":", "\n", "# add a norm layer for each output", "\n", "            ", "self", ".", "out_indices", "=", "[", "0", ",", "2", ",", "4", ",", "6", "]", "\n", "for", "i_emb", ",", "i_layer", "in", "enumerate", "(", "self", ".", "out_indices", ")", ":", "\n", "                ", "if", "i_emb", "==", "0", "and", "os", ".", "environ", ".", "get", "(", "\"FORK_LAST3\"", ",", "None", ")", ":", "\n", "# TODO: more elegant way", "\n", "                    ", "\"\"\"For RetinaNet, `start_level=1`. The first norm layer will not used.\n                    cmd: `FORK_LAST3=1 python -m torch.distributed.launch ...`\n                    \"\"\"", "\n", "layer", "=", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "                    ", "layer", "=", "norm_layer", "(", "embed_dims", "[", "i_emb", "]", ")", "\n", "", "layer_name", "=", "f\"norm{i_layer}\"", "\n", "self", ".", "add_module", "(", "layer_name", ",", "layer", ")", "\n", "", "", "else", ":", "\n", "# Classifier head", "\n", "            ", "self", ".", "norm", "=", "norm_layer", "(", "embed_dims", "[", "-", "1", "]", ")", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "embed_dims", "[", "-", "1", "]", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "cls_init_weights", ")", "\n", "\n", "self", ".", "init_cfg", "=", "copy", ".", "deepcopy", "(", "init_cfg", ")", "\n", "# load pre-trained model", "\n", "if", "self", ".", "fork_feat", "and", "(", "self", ".", "init_cfg", "is", "not", "None", "or", "pretrained", "is", "not", "None", ")", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.cls_init_weights": [[502, 507], ["isinstance", "timm.models.layers.trunc_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.trunc_normal_"], ["", "", "def", "cls_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.get_classifier": [[508, 510], ["None"], "methods", ["None"], ["", "", "", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.reset_classifier": [[511, 514], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["None"], ["", "def", "reset_classifier", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "head", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "num_classes", ")", "if", "num_classes", ">", "0", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.forward_embeddings": [[515, 518], ["backbones.PoolFormer.patch_embed"], "methods", ["None"], ["", "def", "forward_embeddings", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.forward_tokens": [[519, 532], ["enumerate", "block", "getattr", "getattr.", "outs.append"], "methods", ["None"], ["", "def", "forward_tokens", "(", "self", ",", "x", ")", ":", "\n", "        ", "outs", "=", "[", "]", "\n", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "network", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "self", ".", "fork_feat", "and", "idx", "in", "self", ".", "out_indices", ":", "\n", "                ", "norm_layer", "=", "getattr", "(", "self", ",", "f\"norm{idx}\"", ")", "\n", "x_out", "=", "norm_layer", "(", "x", ")", "\n", "outs", ".", "append", "(", "x_out", ")", "\n", "", "", "if", "self", ".", "fork_feat", ":", "\n", "# output the features of four stages for dense prediction", "\n", "            ", "return", "outs", "\n", "# output only the features of last layer for image classification", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.forward": [[533, 545], ["backbones.PoolFormer.forward_embeddings", "backbones.PoolFormer.forward_tokens", "backbones.PoolFormer.norm", "backbones.PoolFormer.head", "backbones.PoolFormer.mean"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.forward_embeddings", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.PoolFormer.forward_tokens"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# input embedding", "\n", "        ", "x", "=", "self", ".", "forward_embeddings", "(", "x", ")", "\n", "# through backbone", "\n", "x", "=", "self", ".", "forward_tokens", "(", "x", ")", "\n", "if", "self", ".", "fork_feat", ":", "\n", "# otuput features of four stages for dense prediction", "\n", "            ", "return", "x", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "cls_out", "=", "self", ".", "head", "(", "x", ".", "mean", "(", "[", "-", "2", ",", "-", "1", "]", ")", ")", "\n", "# for image classification", "\n", "return", "cls_out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetBasicBlock.__init__": [[688, 710], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_planes", ",", "out_planes", ",", "stride", ",", "drop_rate", "=", "0.0", ",", "activate_before_residual", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "WideResnetBasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ",", "momentum", "=", "0.001", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.1", ",", "inplace", "=", "False", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "True", "\n", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ",", "momentum", "=", "0.001", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.1", ",", "inplace", "=", "False", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "out_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", "\n", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "self", ".", "equalInOut", "=", "in_planes", "==", "out_planes", "\n", "self", ".", "convShortcut", "=", "(", "\n", "(", "not", "self", ".", "equalInOut", ")", "\n", "and", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "or", "None", "\n", ")", "\n", "self", ".", "activate_before_residual", "=", "activate_before_residual", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetBasicBlock.forward": [[711, 721], ["backbones.WideResnetBasicBlock.relu2", "backbones.WideResnetBasicBlock.conv2", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "backbones.WideResnetBasicBlock.relu1", "backbones.WideResnetBasicBlock.relu1", "backbones.WideResnetBasicBlock.bn2", "torch.dropout", "torch.dropout", "torch.dropout", "backbones.WideResnetBasicBlock.bn1", "backbones.WideResnetBasicBlock.bn1", "backbones.WideResnetBasicBlock.conv1", "backbones.WideResnetBasicBlock.convShortcut"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "equalInOut", "and", "self", ".", "activate_before_residual", ":", "\n", "            ", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv1", "(", "out", "if", "self", ".", "equalInOut", "else", "x", ")", ")", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "return", "torch", ".", "add", "(", "x", "if", "self", ".", "equalInOut", "else", "self", ".", "convShortcut", "(", "x", ")", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetNetworkBlock.__init__": [[724, 737], ["torch.Module.__init__", "backbones.WideResnetNetworkBlock._make_layer"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetNetworkBlock._make_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "nb_layers", ",", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "block", ",", "\n", "stride", ",", "\n", "drop_rate", "=", "0.0", ",", "\n", "activate_before_residual", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "WideResnetNetworkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "drop_rate", ",", "activate_before_residual", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetNetworkBlock._make_layer": [[739, 754], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "\n", "self", ",", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "drop_rate", ",", "activate_before_residual", "\n", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_layers", ")", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "i", "==", "0", "and", "in_planes", "or", "out_planes", ",", "\n", "out_planes", ",", "\n", "i", "==", "0", "and", "stride", "or", "1", ",", "\n", "drop_rate", ",", "\n", "activate_before_residual", ",", "\n", ")", "\n", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResnetNetworkBlock.forward": [[755, 757], ["backbones.WideResnetNetworkBlock.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResNet.__init__": [[760, 797], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "backbones.WideResnetNetworkBlock", "backbones.WideResnetNetworkBlock", "backbones.WideResnetNetworkBlock", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "backbones.WideResNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "first_stride", "=", "1", ",", "depth", "=", "28", ",", "widen_factor", "=", "2", ",", "drop_rate", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "channels", "=", "[", "16", ",", "16", "*", "widen_factor", ",", "32", "*", "widen_factor", ",", "64", "*", "widen_factor", "]", "\n", "self", ".", "num_features", "=", "channels", "[", "-", "1", "]", "\n", "assert", "(", "depth", "-", "4", ")", "%", "6", "==", "0", "\n", "n", "=", "(", "depth", "-", "4", ")", "/", "6", "\n", "block", "=", "WideResnetBasicBlock", "\n", "# 1st conv before any network block", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "channels", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "# 1st block", "\n", "self", ".", "block1", "=", "WideResnetNetworkBlock", "(", "\n", "n", ",", "\n", "channels", "[", "0", "]", ",", "\n", "channels", "[", "1", "]", ",", "\n", "block", ",", "\n", "first_stride", ",", "\n", "drop_rate", ",", "\n", "activate_before_residual", "=", "True", ",", "\n", ")", "\n", "# 2nd block", "\n", "self", ".", "block2", "=", "WideResnetNetworkBlock", "(", "n", ",", "channels", "[", "1", "]", ",", "channels", "[", "2", "]", ",", "block", ",", "2", ",", "drop_rate", ")", "\n", "# 3rd block", "\n", "self", ".", "block3", "=", "WideResnetNetworkBlock", "(", "n", ",", "channels", "[", "2", "]", ",", "channels", "[", "3", "]", ",", "block", ",", "2", ",", "drop_rate", ")", "\n", "# global average pooling", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "channels", "[", "3", "]", ",", "momentum", "=", "0.001", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "relu", "=", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.1", ",", "inplace", "=", "False", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"leaky_relu\"", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.WideResNet.forward": [[798, 807], ["backbones.WideResNet.conv1", "backbones.WideResNet.block1", "backbones.WideResNet.block2", "backbones.WideResNet.block3", "backbones.WideResNet.relu", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d.view", "backbones.WideResNet.bn1"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "block1", "(", "out", ")", "\n", "out", "=", "self", ".", "block2", "(", "out", ")", "\n", "out", "=", "self", ".", "block3", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "out", "=", "F", ".", "adaptive_avg_pool2d", "(", "out", ",", "1", ")", "\n", "x", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "num_features", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_tiny": [[39, 51], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["@", "register_model", "\n", "def", "swin_tiny", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\"swin_tiny_patch4_window7_224\"", ",", "**", "model_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_small": [[53, 66], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_small", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_small_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_base": [[69, 82], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_base", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "128", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "4", ",", "8", ",", "16", ",", "32", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_base_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_large": [[85, 98], ["dict", "timm.models.swin_transformer._create_swin_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "swin_large", "(", "window_size", "=", "7", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "window_size", ",", "\n", "embed_dim", "=", "192", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "18", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "6", ",", "12", ",", "24", ",", "48", ")", ",", "\n", "num_classes", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "_create_swin_transformer", "(", "\n", "\"swin_large_patch4_window7_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_tiny": [[101, 109], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_tiny", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"ViT-Tiny (Vit-Ti/16)\"\"\"", "\n", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "192", ",", "depth", "=", "12", ",", "num_heads", "=", "3", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_tiny_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_small": [[111, 118], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_small", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "384", ",", "depth", "=", "12", ",", "num_heads", "=", "6", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_small_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_base": [[120, 127], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_base", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "768", ",", "depth", "=", "12", ",", "num_heads", "=", "12", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_base_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_large": [[129, 136], ["dict", "timm.models.vision_transformer._create_vision_transformer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "vit_large", "(", "patch_size", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_kwargs", "=", "dict", "(", "\n", "patch_size", "=", "patch_size", ",", "embed_dim", "=", "1024", ",", "depth", "=", "24", ",", "num_heads", "=", "16", ",", "num_classes", "=", "0", ",", "**", "kwargs", "\n", ")", "\n", "model", "=", "_create_vision_transformer", "(", "\"vit_large_patch16_224\"", ",", "pretrained", "=", "False", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones._cfg": [[156, 168], ["None"], "function", ["None"], ["", "def", "_cfg", "(", "url", "=", "\"\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "\n", "\"url\"", ":", "url", ",", "\n", "\"num_classes\"", ":", "0", ",", "\n", "\"input_size\"", ":", "(", "3", ",", "224", ",", "224", ")", ",", "\n", "\"pool_size\"", ":", "None", ",", "\n", "\"crop_pct\"", ":", "0.95", ",", "\n", "\"interpolation\"", ":", "\"bicubic\"", ",", "\n", "\"mean\"", ":", "IMAGENET_DEFAULT_MEAN", ",", "\n", "\"std\"", ":", "IMAGENET_DEFAULT_STD", ",", "\n", "\"classifier\"", ":", "\"head\"", ",", "\n", "**", "kwargs", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.basic_blocks": [[344, 380], ["range", "torch.Sequential", "nn.Sequential.append", "backbones.PoolFormerBlock", "sum", "sum"], "function", ["None"], ["", "", "def", "basic_blocks", "(", "\n", "dim", ",", "\n", "index", ",", "\n", "layers", ",", "\n", "pool_size", "=", "3", ",", "\n", "mlp_ratio", "=", "4.0", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "\n", "norm_layer", "=", "GroupNorm", ",", "\n", "drop_rate", "=", "0.0", ",", "\n", "drop_path_rate", "=", "0.0", ",", "\n", "use_layer_scale", "=", "True", ",", "\n", "layer_scale_init_value", "=", "1e-5", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    generate PoolFormer blocks for a stage\n    return: PoolFormer blocks\n    \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "for", "block_idx", "in", "range", "(", "layers", "[", "index", "]", ")", ":", "\n", "        ", "block_dpr", "=", "drop_path_rate", "*", "(", "block_idx", "+", "sum", "(", "layers", "[", ":", "index", "]", ")", ")", "/", "(", "sum", "(", "layers", ")", "-", "1", ")", "\n", "blocks", ".", "append", "(", "\n", "PoolFormerBlock", "(", "\n", "dim", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "drop_path", "=", "block_dpr", ",", "\n", "use_layer_scale", "=", "use_layer_scale", ",", "\n", "layer_scale_init_value", "=", "layer_scale_init_value", ",", "\n", ")", "\n", ")", "\n", "", "blocks", "=", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s12": [[547, 570], ["backbones.PoolFormer"], "function", ["None"], ["", "", "@", "register_model", "\n", "def", "poolformer_s12", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    PoolFormer-S12 model, Params: 12M\n    --layers: [x,x,x,x], numbers of layers for the four stages\n    --embed_dims, --mlp_ratios:\n        embedding dims and mlp ratios for the four stages\n    --downsamples: flags to apply downsampling or not in four blocks\n    \"\"\"", "\n", "layers", "=", "[", "2", ",", "2", ",", "6", ",", "2", "]", "\n", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "model", "=", "PoolFormer", "(", "\n", "layers", ",", "\n", "num_classes", "=", "0", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "\"poolformer_s\"", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s24": [[572, 591], ["backbones.PoolFormer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "poolformer_s24", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    PoolFormer-S24 model, Params: 21M\n    \"\"\"", "\n", "layers", "=", "[", "4", ",", "4", ",", "12", ",", "4", "]", "\n", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "model", "=", "PoolFormer", "(", "\n", "layers", ",", "\n", "num_classes", "=", "0", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "\"poolformer_s\"", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s36": [[593, 613], ["backbones.PoolFormer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "poolformer_s36", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    PoolFormer-S36 model, Params: 31M\n    \"\"\"", "\n", "layers", "=", "[", "6", ",", "6", ",", "18", ",", "6", "]", "\n", "embed_dims", "=", "[", "64", ",", "128", ",", "320", ",", "512", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "model", "=", "PoolFormer", "(", "\n", "layers", ",", "\n", "num_classes", "=", "0", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "layer_scale_init_value", "=", "1e-6", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "\"poolformer_s\"", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_m36": [[615, 635], ["backbones.PoolFormer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "poolformer_m36", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    PoolFormer-M36 model, Params: 56M\n    \"\"\"", "\n", "layers", "=", "[", "6", ",", "6", ",", "18", ",", "6", "]", "\n", "embed_dims", "=", "[", "96", ",", "192", ",", "384", ",", "768", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "model", "=", "PoolFormer", "(", "\n", "layers", ",", "\n", "num_classes", "=", "0", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "layer_scale_init_value", "=", "1e-6", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "\"poolformer_m\"", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_m48": [[637, 657], ["backbones.PoolFormer"], "function", ["None"], ["", "@", "register_model", "\n", "def", "poolformer_m48", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    PoolFormer-M48 model, Params: 73M\n    \"\"\"", "\n", "layers", "=", "[", "8", ",", "8", ",", "24", ",", "8", "]", "\n", "embed_dims", "=", "[", "96", ",", "192", ",", "384", ",", "768", "]", "\n", "mlp_ratios", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", "\n", "downsamples", "=", "[", "True", ",", "True", ",", "True", ",", "True", "]", "\n", "model", "=", "PoolFormer", "(", "\n", "layers", ",", "\n", "num_classes", "=", "0", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "mlp_ratios", "=", "mlp_ratios", ",", "\n", "downsamples", "=", "downsamples", ",", "\n", "layer_scale_init_value", "=", "1e-6", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "model", ".", "default_cfg", "=", "default_cfgs", "[", "\"poolformer_m\"", "]", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_tiny": [[659, 664], ["dict", "timm.models.convnext._create_convnext"], "function", ["None"], ["", "@", "register_model", "\n", "def", "convnext_tiny", "(", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "(", "3", ",", "3", ",", "9", ",", "3", ")", ",", "dims", "=", "(", "96", ",", "192", ",", "384", ",", "768", ")", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "\"convnext_tiny\"", ",", "pretrained", "=", "False", ",", "num_classes", "=", "0", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_small": [[666, 671], ["dict", "timm.models.convnext._create_convnext"], "function", ["None"], ["", "@", "register_model", "\n", "def", "convnext_small", "(", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "96", ",", "192", ",", "384", ",", "768", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "\"convnext_small\"", ",", "pretrained", "=", "False", ",", "num_classes", "=", "0", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_base": [[673, 678], ["dict", "timm.models.convnext._create_convnext"], "function", ["None"], ["", "@", "register_model", "\n", "def", "convnext_base", "(", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "\"convnext_base\"", ",", "pretrained", "=", "False", ",", "num_classes", "=", "0", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_large": [[680, 685], ["dict", "timm.models.convnext._create_convnext"], "function", ["None"], ["", "@", "register_model", "\n", "def", "convnext_large", "(", "**", "kwargs", ")", ":", "\n", "    ", "model_args", "=", "dict", "(", "depths", "=", "[", "3", ",", "3", ",", "27", ",", "3", "]", ",", "dims", "=", "[", "192", ",", "384", ",", "768", ",", "1536", "]", ",", "**", "kwargs", ")", "\n", "model", "=", "_create_convnext", "(", "\"convnext_large\"", ",", "pretrained", "=", "False", ",", "num_classes", "=", "0", ",", "**", "model_args", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.wide_resnet28w2": [[809, 813], ["backbones.WideResNet"], "function", ["None"], ["", "", "@", "register_model", "\n", "def", "wide_resnet28w2", "(", "**", "kwargs", ")", ":", "\n", "    ", "encoder", "=", "WideResNet", "(", "depth", "=", "28", ",", "widen_factor", "=", "2", ",", "**", "kwargs", ")", "\n", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.wide_resnet28w8": [[815, 819], ["backbones.WideResNet"], "function", ["None"], ["", "@", "register_model", "\n", "def", "wide_resnet28w8", "(", "**", "kwargs", ")", ":", "\n", "    ", "encoder", "=", "WideResNet", "(", "depth", "=", "28", ",", "widen_factor", "=", "8", ",", "**", "kwargs", ")", "\n", "return", "encoder", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__init__": [[53, 57], ["pathlib.Path", "os.listdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "Path", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "images", "=", "os", ".", "listdir", "(", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__getitem__": [[58, 64], ["PIL.Image.open().convert", "pretrain_dataloader.CustomDatasetWithoutLabels.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "root", "/", "self", ".", "images", "[", "index", "]", "\n", "x", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "", "return", "x", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.GaussianBlur.__init__": [[70, 82], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sigma", ":", "Sequence", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"Gaussian blur as a callable object.\n\n        Args:\n            sigma (Sequence[float]): range to sample the radius of the gaussian blur filter.\n                Defaults to [0.1, 2.0].\n        \"\"\"", "\n", "\n", "if", "sigma", "is", "None", ":", "\n", "            ", "sigma", "=", "[", "0.1", ",", "2.0", "]", "\n", "\n", "", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.GaussianBlur.__call__": [[83, 96], ["random.uniform", "img.filter.filter.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ":", "Image", ")", "->", "Image", ":", "\n", "        ", "\"\"\"Applies gaussian blur to an input image.\n\n        Args:\n            img (Image): an image in the PIL.Image format.\n\n        Returns:\n            Image: blurred image.\n        \"\"\"", "\n", "\n", "sigma", "=", "random", ".", "uniform", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", "\n", "img", "=", "img", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "sigma", ")", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.Solarization.__call__": [[101, 112], ["PIL.ImageOps.solarize"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ":", "Image", ")", "->", "Image", ":", "\n", "        ", "\"\"\"Applies solarization to an input image.\n\n        Args:\n            img (Image): an image in the PIL.Image format.\n\n        Returns:\n            Image: solarized image.\n        \"\"\"", "\n", "\n", "return", "ImageOps", ".", "solarize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.Equalization.__call__": [[115, 117], ["PIL.ImageOps.equalize"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "img", ":", "Image", ")", "->", "Image", ":", "\n", "        ", "return", "ImageOps", ".", "equalize", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.NCropAugmentation.__init__": [[120, 130], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transform", ":", "Callable", ",", "num_crops", ":", "int", ")", ":", "\n", "        ", "\"\"\"Creates a pipeline that apply a transformation pipeline multiple times.\n\n        Args:\n            transform (Callable): transformation pipeline.\n            num_crops (int): number of crops to create from the transformation pipeline.\n        \"\"\"", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "num_crops", "=", "num_crops", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.NCropAugmentation.__call__": [[131, 142], ["pretrain_dataloader.NCropAugmentation.transform", "range"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Applies transforms n times to generate n crops.\n\n        Args:\n            x (Image): an image in the PIL.Image format.\n\n        Returns:\n            List[torch.Tensor]: an image in the tensor format.\n        \"\"\"", "\n", "\n", "return", "[", "self", ".", "transform", "(", "x", ")", "for", "_", "in", "range", "(", "self", ".", "num_crops", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.NCropAugmentation.__repr__": [[143, 145], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"{self.num_crops} x [{self.transform}]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.FullTransformPipeline.__init__": [[148, 150], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transforms", ":", "Callable", ")", "->", "None", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.FullTransformPipeline.__call__": [[151, 165], ["out.extend", "transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Applies transforms n times to generate n crops.\n\n        Args:\n            x (Image): an image in the PIL.Image format.\n\n        Returns:\n            List[torch.Tensor]: an image in the tensor format.\n        \"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "out", ".", "extend", "(", "transform", "(", "x", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.FullTransformPipeline.__repr__": [[166, 168], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "\"\\n\"", ".", "join", "(", "[", "str", "(", "transform", ")", "for", "transform", "in", "self", ".", "transforms", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.BaseTransform.__call__": [[173, 175], ["pretrain_dataloader.BaseTransform.transform"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "x", ":", "Image", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "transform", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.BaseTransform.__repr__": [[176, 178], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "self", ".", "transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CifarTransform.__init__": [[181, 250], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization", "pretrain_dataloader.Equalization"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "cifar", ":", "str", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "equalization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "32", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies Cifar10/Cifar100 transformations.\n\n        Args:\n            cifar (str): type of cifar, either cifar10 or cifar100.\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            color_jitter_prob (float, optional): probability of applying color jitter.\n                Defaults to 0.8.\n            gray_scale_prob (float, optional): probability of converting to gray scale.\n                Defaults to 0.2.\n            horizontal_flip_prob (float, optional): probability of flipping horizontally.\n                Defaults to 0.5.\n            gaussian_prob (float, optional): probability of applying gaussian blur.\n                Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization.\n                Defaults to 0.0.\n            equalization_prob (float, optional): probability of applying equalization.\n                Defaults to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the crop. Defaults to 32.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "cifar", "==", "\"cifar10\"", ":", "\n", "            ", "mean", "=", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", "\n", "std", "=", "(", "0.2470", ",", "0.2435", ",", "0.2616", ")", "\n", "", "else", ":", "\n", "            ", "mean", "=", "(", "0.5071", ",", "0.4865", ",", "0.4409", ")", "\n", "std", "=", "(", "0.2673", ",", "0.2564", ",", "0.2762", ")", "\n", "\n", "", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "(", "crop_size", ",", "crop_size", ")", ",", "\n", "scale", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "color_jitter_prob", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "gray_scale_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Equalization", "(", ")", "]", ",", "p", "=", "equalization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "horizontal_flip_prob", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.STLTransform.__init__": [[255, 314], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization", "pretrain_dataloader.Equalization"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "equalization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "96", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies STL10 transformations.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            color_jitter_prob (float, optional): probability of applying color jitter.\n                Defaults to 0.8.\n            gray_scale_prob (float, optional): probability of converting to gray scale.\n                Defaults to 0.2.\n            horizontal_flip_prob (float, optional): probability of flipping horizontally.\n                Defaults to 0.5.\n            gaussian_prob (float, optional): probability of applying gaussian blur.\n                Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization.\n                Defaults to 0.0.\n            equalization_prob (float, optional): probability of applying equalization.\n                Defaults to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the crop. Defaults to 96.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "(", "crop_size", ",", "crop_size", ")", ",", "\n", "scale", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "color_jitter_prob", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "gray_scale_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Equalization", "(", ")", "]", ",", "p", "=", "equalization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "horizontal_flip_prob", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.ImagenetTransform.__init__": [[319, 377], ["torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization", "pretrain_dataloader.Equalization"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "equalization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "224", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies Imagenet transformations.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            color_jitter_prob (float, optional): probability of applying color jitter.\n                Defaults to 0.8.\n            gray_scale_prob (float, optional): probability of converting to gray scale.\n                Defaults to 0.2.\n            horizontal_flip_prob (float, optional): probability of flipping horizontally.\n                Defaults to 0.5.\n            gaussian_prob (float, optional): probability of applying gaussian blur.\n                Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization.\n                Defaults to 0.0.\n            equalization_prob (float, optional): probability of applying equalization.\n                Defaults to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the crop. Defaults to 224.\n        \"\"\"", "\n", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "crop_size", ",", "\n", "scale", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "color_jitter_prob", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "gray_scale_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Equalization", "(", ")", "]", ",", "p", "=", "equalization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "horizontal_flip_prob", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CustomTransform.__init__": [[382, 448], ["super().__init__", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ColorJitter", "pretrain_dataloader.GaussianBlur", "pretrain_dataloader.Solarization", "pretrain_dataloader.Equalization"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "equalization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "224", ",", "\n", "mean", ":", "Sequence", "[", "float", "]", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", ":", "Sequence", "[", "float", "]", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that applies Custom transformations.\n        If you want to do exoteric augmentations, you can just re-write this class.\n\n        Args:\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            color_jitter_prob (float, optional): probability of applying color jitter.\n                Defaults to 0.8.\n            gray_scale_prob (float, optional): probability of converting to gray scale.\n                Defaults to 0.2.\n            horizontal_flip_prob (float, optional): probability of flipping horizontally.\n                Defaults to 0.5.\n            gaussian_prob (float, optional): probability of applying gaussian blur.\n                Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization.\n                Defaults to 0.0.\n            equalization_prob (float, optional): probability of applying equalization.\n                Defaults to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the crop. Defaults to 224.\n            mean (Sequence[float], optional): mean values for normalization.\n                Defaults to (0.485, 0.456, 0.406).\n            std (Sequence[float], optional): std values for normalization.\n                Defaults to (0.228, 0.224, 0.225).\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "\n", "crop_size", ",", "\n", "scale", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interpolation", "=", "transforms", ".", "InterpolationMode", ".", "BICUBIC", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "brightness", ",", "contrast", ",", "saturation", ",", "hue", ")", "]", ",", "\n", "p", "=", "color_jitter_prob", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "gray_scale_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", ")", "]", ",", "p", "=", "gaussian_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Solarization", "(", ")", "]", ",", "p", "=", "solarization_prob", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "Equalization", "(", ")", "]", ",", "p", "=", "equalization_prob", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "horizontal_flip_prob", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index": [[34, 50], ["super().__getitem__", "torchvision.datasets.STL10", "torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.CustomDatasetWithoutLabels.__getitem__"], ["def", "dataset_with_index", "(", "DatasetClass", ":", "Type", "[", "Dataset", "]", ")", "->", "Type", "[", "Dataset", "]", ":", "\n", "    ", "\"\"\"Factory for datasets that also returns the data index.\n\n    Args:\n        DatasetClass (Type[Dataset]): Dataset class to be wrapped.\n\n    Returns:\n        Type[Dataset]: dataset with index.\n    \"\"\"", "\n", "\n", "class", "DatasetWithIndex", "(", "DatasetClass", ")", ":", "\n", "        ", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "            ", "data", "=", "super", "(", ")", ".", "__getitem__", "(", "index", ")", "\n", "return", "(", "index", ",", "*", "data", ")", "\n", "\n", "", "", "return", "DatasetWithIndex", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform": [[452, 472], ["pretrain_dataloader.CifarTransform", "pretrain_dataloader.STLTransform", "pretrain_dataloader.ImagenetTransform", "pretrain_dataloader.CustomTransform", "ValueError"], "function", ["None"], ["", "", "def", "prepare_transform", "(", "dataset", ":", "str", ",", "**", "kwargs", ")", "->", "Any", ":", "\n", "    ", "\"\"\"Prepares transforms for a specific dataset. Optionally uses multi crop.\n\n    Args:\n        dataset (str): name of the dataset.\n\n    Returns:\n        Any: a transformation for a specific dataset.\n    \"\"\"", "\n", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "return", "CifarTransform", "(", "cifar", "=", "dataset", ",", "**", "kwargs", ")", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "return", "STLTransform", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", "]", ":", "\n", "        ", "return", "ImagenetTransform", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "        ", "return", "CustomTransform", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{dataset} is not currently supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform": [[474, 493], ["zip", "pretrain_dataloader.FullTransformPipeline", "len", "len", "T.append", "pretrain_dataloader.NCropAugmentation"], "function", ["None"], ["", "", "def", "prepare_n_crop_transform", "(", "\n", "transforms", ":", "List", "[", "Callable", "]", ",", "num_crops_per_aug", ":", "List", "[", "int", "]", "\n", ")", "->", "NCropAugmentation", ":", "\n", "    ", "\"\"\"Turns a single crop transformation to an N crops transformation.\n\n    Args:\n        transforms (List[Callable]): list of transformations.\n        num_crops_per_aug (List[int]): number of crops per pipeline.\n\n    Returns:\n        NCropAugmentation: an N crop transformation.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "transforms", ")", "==", "len", "(", "num_crops_per_aug", ")", "\n", "\n", "T", "=", "[", "]", "\n", "for", "transform", ",", "num_crops", "in", "zip", "(", "transforms", ",", "num_crops_per_aug", ")", ":", "\n", "        ", "T", ".", "append", "(", "NCropAugmentation", "(", "transform", ",", "num_crops", ")", ")", "\n", "", "return", "FullTransformPipeline", "(", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_datasets": [[495, 574], ["pathlib.Path", "pathlib.Path", "pathlib.Path", "train_test_split", "os.path.dirname", "vars", "pretrain_dataloader.dataset_with_index", "tuple", "os.path.dirname", "dataset.upper", "pretrain_dataloader.dataset_with_index", "zip", "os.path.realpath", "pretrain_dataloader.dataset_with_index", "pretrain_dataloader.dataset_with_index"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index"], ["", "def", "prepare_datasets", "(", "\n", "dataset", ":", "str", ",", "\n", "transform", ":", "Callable", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "no_labels", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "False", ",", "\n", "download", ":", "bool", "=", "True", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", ")", "->", "Dataset", ":", "\n", "    ", "\"\"\"Prepares the desired dataset.\n\n    Args:\n        dataset (str): the name of the dataset.\n        transform (Callable): a transformation.\n        data_dir (Optional[Union[str, Path]], optional): the directory to load data from.\n            Defaults to None.\n        train_dir (Optional[Union[str, Path]], optional): training data directory\n            to be appended to data_dir. Defaults to None.\n        no_labels (Optional[bool], optional): if the custom dataset has no labels.\n        data_fraction (Optional[float]): percentage of data to use. Use all data when set to -1.0.\n            Defaults to -1.0.\n    Returns:\n        Dataset: the desired dataset with transformations.\n    \"\"\"", "\n", "\n", "if", "data_dir", "is", "None", ":", "\n", "        ", "sandbox_folder", "=", "Path", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", ")", "\n", "data_dir", "=", "sandbox_folder", "/", "\"datasets\"", "\n", "\n", "", "if", "train_dir", "is", "None", ":", "\n", "        ", "train_dir", "=", "Path", "(", "f\"{dataset}/train\"", ")", "\n", "", "else", ":", "\n", "        ", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "\n", "", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "DatasetClass", "=", "vars", "(", "torchvision", ".", "datasets", ")", "[", "dataset", ".", "upper", "(", ")", "]", "\n", "train_dataset", "=", "dataset_with_index", "(", "DatasetClass", ")", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "train_dataset", "=", "dataset_with_index", "(", "STL10", ")", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "split", "=", "\"train+unlabeled\"", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "transform", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", "]", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "train_dataset", "=", "dataset_with_index", "(", "ImageFolder", ")", "(", "train_dir", ",", "transform", ")", "\n", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "\n", "if", "no_labels", ":", "\n", "            ", "dataset_class", "=", "CustomDatasetWithoutLabels", "\n", "", "else", ":", "\n", "            ", "dataset_class", "=", "ImageFolder", "\n", "\n", "", "train_dataset", "=", "dataset_with_index", "(", "dataset_class", ")", "(", "train_dir", ",", "transform", ")", "\n", "\n", "", "if", "data_fraction", ">", "0", ":", "\n", "        ", "assert", "data_fraction", "<", "1", ",", "\"Only use data_fraction for values smaller than 1.\"", "\n", "data", "=", "train_dataset", ".", "samples", "\n", "files", "=", "[", "f", "for", "f", ",", "_", "in", "data", "]", "\n", "labels", "=", "[", "l", "for", "_", ",", "l", "in", "data", "]", "\n", "\n", "from", "sklearn", ".", "model_selection", "import", "train_test_split", "\n", "\n", "files", ",", "_", ",", "labels", ",", "_", "=", "train_test_split", "(", "\n", "files", ",", "labels", ",", "train_size", "=", "data_fraction", ",", "stratify", "=", "labels", ",", "random_state", "=", "42", "\n", ")", "\n", "train_dataset", ".", "samples", "=", "[", "tuple", "(", "p", ")", "for", "p", "in", "zip", "(", "files", ",", "labels", ")", "]", "\n", "\n", "", "return", "train_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_dataloader": [[576, 597], ["torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "prepare_dataloader", "(", "\n", "train_dataset", ":", "Dataset", ",", "batch_size", ":", "int", "=", "64", ",", "num_workers", ":", "int", "=", "4", "\n", ")", "->", "DataLoader", ":", "\n", "    ", "\"\"\"Prepares the training dataloader for pretraining.\n    Args:\n        train_dataset (Dataset): the name of the dataset.\n        batch_size (int, optional): batch size. Defaults to 64.\n        num_workers (int, optional): number of workers. Defaults to 4.\n    Returns:\n        DataLoader: the training dataloader with the desired dataset.\n    \"\"\"", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "return", "train_loader", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.FilterInfNNan.__init__": [[91, 105], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Layer that filters out inf and nans from any tensor.\n        This is usefull when there are instability issues,\n        which cause a small number of values to go bad.\n\n        Args:\n            tensor (List): tensor to remove nans and infs from.\n\n        Returns:\n            torch.Tensor: filtered view of the tensor without nans or infs.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.FilterInfNNan.forward": [[106, 110], ["misc.FilterInfNNan.module", "misc.filter_inf_n_nan"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "out", "=", "self", ".", "module", "(", "x", ")", "\n", "out", "=", "filter_inf_n_nan", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.FilterInfNNan.__getattr__": [[111, 118], ["super().__getattr__", "getattr", "AttributeError"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.FilterInfNNan.__getattr__"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "if", "name", "==", "\"module\"", ":", "\n", "                ", "raise", "AttributeError", "(", ")", "\n", "", "return", "getattr", "(", "self", ".", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.GatherLayer.forward": [[181, 189], ["tuple", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "output", "=", "[", "torch", ".", "zeros_like", "(", "x", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "output", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "[", "x", "]", "\n", "", "return", "tuple", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.GatherLayer.backward": [[190, 199], ["torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "misc.get_rank"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grads", ")", ":", "\n", "        ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "all_gradients", "=", "torch", ".", "stack", "(", "grads", ")", "\n", "dist", ".", "all_reduce", "(", "all_gradients", ")", "\n", "grad_out", "=", "all_gradients", "[", "get_rank", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "grad_out", "=", "grads", "[", "0", "]", "\n", "", "return", "grad_out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._1d_filter": [[30, 32], ["tensor.isfinite"], "function", ["None"], ["def", "_1d_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "tensor", ".", "isfinite", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._2d_filter": [[34, 36], ["tensor.isfinite().all", "tensor.isfinite"], "function", ["None"], ["", "def", "_2d_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "return", "tensor", ".", "isfinite", "(", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._single_input_filter": [[38, 50], ["filter_func", "len", "tensor.size", "len", "RuntimeError", "tensor.size"], "function", ["None"], ["", "def", "_single_input_filter", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "        ", "filter_func", "=", "_1d_filter", "\n", "", "elif", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "filter_func", "=", "_2d_filter", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Only 1d and 2d tensors are supported.\"", ")", "\n", "\n", "", "selected", "=", "filter_func", "(", "tensor", ")", "\n", "tensor", "=", "tensor", "[", "selected", "]", "\n", "\n", "return", "tensor", ",", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._multi_input_filter": [[52, 66], ["filter_func", "len", "torch.logical_and", "torch.logical_and", "torch.logical_and", "tensors[].size", "len", "RuntimeError", "filter_func", "tensors[].size"], "function", ["None"], ["", "def", "_multi_input_filter", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", "]", ":", "\n", "    ", "if", "len", "(", "tensors", "[", "0", "]", ".", "size", "(", ")", ")", "==", "1", ":", "\n", "        ", "filter_func", "=", "_1d_filter", "\n", "", "elif", "len", "(", "tensors", "[", "0", "]", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "filter_func", "=", "_2d_filter", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Only 1d and 2d tensors are supported.\"", ")", "\n", "\n", "", "selected", "=", "filter_func", "(", "tensors", "[", "0", "]", ")", "\n", "for", "tensor", "in", "tensors", "[", "1", ":", "]", ":", "\n", "        ", "selected", "=", "torch", ".", "logical_and", "(", "selected", ",", "filter_func", "(", "tensor", ")", ")", "\n", "", "tensors", "=", "[", "tensor", "[", "selected", "]", "for", "tensor", "in", "tensors", "]", "\n", "\n", "return", "tensors", ",", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan": [[68, 88], ["isinstance", "misc._single_input_filter", "misc._multi_input_filter"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._single_input_filter", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._multi_input_filter"], ["", "def", "filter_inf_n_nan", "(", "tensors", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "return_indexes", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Filters out inf and nans from any tensor.\n    This is usefull when there are instability issues,\n    which cause a small number of values to go bad.\n\n    Args:\n        tensor (List): tensor to remove nans and infs from.\n\n    Returns:\n        torch.Tensor: filtered view of the tensor without nans or infs.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensors", ",", "selected", "=", "_single_input_filter", "(", "tensors", ")", "\n", "", "else", ":", "\n", "        ", "tensors", ",", "selected", "=", "_multi_input_filter", "(", "tensors", ")", "\n", "\n", "", "if", "return_indexes", ":", "\n", "        ", "return", "tensors", ",", "selected", "\n", "", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._no_grad_trunc_normal_": [[120, 159], ["warnings.warn", "torch.no_grad", "torch.no_grad", "torch.no_grad", "misc._no_grad_trunc_normal_.norm_cdf"], "function", ["None"], ["", "", "", "def", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Copy & paste from PyTorch official master until it's in a few official releases - RW\n    Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    \"\"\"", "\n", "\n", "def", "norm_cdf", "(", "x", ")", ":", "\n", "        ", "\"\"\"Computes standard normal cumulative distribution function\"\"\"", "\n", "\n", "return", "(", "1.0", "+", "math", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "/", "2.0", "\n", "\n", "", "if", "(", "mean", "<", "a", "-", "2", "*", "std", ")", "or", "(", "mean", ">", "b", "+", "2", "*", "std", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"", "\n", "\"The distribution of values may be incorrect.\"", ",", "\n", "stacklevel", "=", "2", ",", "\n", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Values are generated by using a truncated uniform distribution and", "\n", "# then using the inverse CDF for the normal distribution.", "\n", "# Get upper and lower cdf values", "\n", "        ", "l", "=", "norm_cdf", "(", "(", "a", "-", "mean", ")", "/", "std", ")", "\n", "u", "=", "norm_cdf", "(", "(", "b", "-", "mean", ")", "/", "std", ")", "\n", "\n", "# Uniformly fill tensor with values from [l, u], then translate to", "\n", "# [2l-1, 2u-1].", "\n", "tensor", ".", "uniform_", "(", "2", "*", "l", "-", "1", ",", "2", "*", "u", "-", "1", ")", "\n", "\n", "# Use inverse cdf transform for normal distribution to get truncated", "\n", "# standard normal", "\n", "tensor", ".", "erfinv_", "(", ")", "\n", "\n", "# Transform to proper mean, std", "\n", "tensor", ".", "mul_", "(", "std", "*", "math", ".", "sqrt", "(", "2.0", ")", ")", "\n", "tensor", ".", "add_", "(", "mean", ")", "\n", "\n", "# Clamp to ensure it's in the proper range", "\n", "tensor", ".", "clamp_", "(", "min", "=", "a", ",", "max", "=", "b", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.trunc_normal_": [[161, 167], ["misc._no_grad_trunc_normal_"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc._no_grad_trunc_normal_"], ["", "", "def", "trunc_normal_", "(", "tensor", ",", "mean", "=", "0.0", ",", "std", "=", "1.0", ",", "a", "=", "-", "2.0", ",", "b", "=", "2.0", ")", ":", "\n", "    ", "\"\"\"Copy & paste from PyTorch official master until it's in a few official releases - RW\n    Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n    \"\"\"", "\n", "\n", "return", "_no_grad_trunc_normal_", "(", "tensor", ",", "mean", ",", "std", ",", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank": [[169, 173], ["torch.is_available", "torch.is_initialized", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "dist", ".", "get_rank", "(", ")", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather": [[201, 204], ["torch.cat", "torch.cat", "torch.cat", "GatherLayer.apply"], "function", ["None"], ["", "", "def", "gather", "(", "X", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"Gathers tensors from all processes, supporting backward propagation.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "GatherLayer", ".", "apply", "(", "X", ")", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.compute_dataset_size": [[206, 251], ["DATASET_SIZES.get().get", "int", "len", "sum", "DATASET_SIZES.get", "os.listdir", "dataset.lower", "len", "os.listdir", "os.listdir", "os.path.join"], "function", ["None"], ["", "def", "compute_dataset_size", "(", "\n", "dataset", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "train", ":", "Optional", "[", "str", "]", "=", "True", ",", "\n", "folder", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "no_labels", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "data_fraction", ":", "Optional", "[", "float", "]", "=", "-", "1", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Utility function to get the dataset size. If using cifar or stl,\n    provide dataset and the train flag.\n    E.g., compute_dataset_size(dataset='cifar10', train=True/False).\n    When using an ImageFolder dataset, just provide the path to the folder and\n    specify if it has labels or not with the no_labels flag.\n\n    Args:\n        folder (Optional[str], optional): path to the ImageFolder. Defaults to None.\n        dataset (Optional[str], optional): dataset size for predefined datasets\n            [cifar10, cifar100, stl10]. Defaults to None.\n        train (Optional[str], optional): either train dataset or validation. Defaults to True.\n        no_labels (Optional[bool], optional): if the dataset has no labels. Defaults to False.\n        data_fraction (Optional[float], optional): amount of data to use. Defaults to -1.\n\n    Returns:\n        _type_: _description_\n    \"\"\"", "\n", "DATASET_SIZES", "=", "{", "\n", "\"cifar10\"", ":", "{", "\"train\"", ":", "50_000", ",", "\"val\"", ":", "10_000", "}", ",", "\n", "\"cifar100\"", ":", "{", "\"train\"", ":", "50_000", ",", "\"val\"", ":", "10_000", "}", ",", "\n", "\"stl10\"", ":", "{", "\"train\"", ":", "105_000", ",", "\"val\"", ":", "8_000", "}", ",", "\n", "}", "\n", "size", "=", "None", "\n", "\n", "if", "dataset", "is", "not", "None", ":", "\n", "        ", "size", "=", "DATASET_SIZES", ".", "get", "(", "dataset", ".", "lower", "(", ")", ",", "{", "}", ")", ".", "get", "(", "\"train\"", "if", "train", "else", "\"val\"", ",", "None", ")", "\n", "\n", "", "if", "size", "is", "None", ":", "\n", "        ", "if", "no_labels", ":", "\n", "            ", "size", "=", "len", "(", "os", ".", "listdir", "(", "folder", ")", ")", "\n", "", "else", ":", "\n", "            ", "size", "=", "sum", "(", "\n", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "class_", ")", ")", ")", "for", "class_", "in", "os", ".", "listdir", "(", "folder", ")", "\n", ")", "\n", "\n", "", "", "if", "data_fraction", "!=", "-", "1", ":", "\n", "        ", "size", "=", "int", "(", "size", "*", "data_fraction", ")", "\n", "", "return", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.make_contiguous": [[253, 261], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "module.parameters", "param.set_", "param.contiguous"], "function", ["None"], ["", "def", "make_contiguous", "(", "module", ")", ":", "\n", "    ", "\"\"\"Make the model contigous in order to comply with horovod.\n    https://github.com/lucidrains/DALLE-pytorch/issues/330\n    \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "param", "in", "module", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "set_", "(", "param", ".", "contiguous", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.Mux.__init__": [[38, 47], ["nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", ")", ":", "\n", "        ", "\"\"\"Implements mutex operation for dali in order to support probabilitic augmentations.\n\n        Args:\n            prob (float): probability value\n        \"\"\"", "\n", "\n", "self", ".", "to_bool", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "DALIDataType", ".", "BOOL", ")", "\n", "self", ".", "rng", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.Mux.__call__": [[48, 52], ["dali_dataloader.Mux.to_bool", "dali_dataloader.Mux.rng"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "true_case", ",", "false_case", ")", ":", "\n", "        ", "condition", "=", "self", ".", "to_bool", "(", "self", ".", "rng", "(", ")", ")", "\n", "neg_condition", "=", "condition", "^", "True", "\n", "return", "condition", "*", "true_case", "+", "neg_condition", "*", "false_case", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomGrayScaleConversion.__init__": [[55, 67], ["dali_dataloader.Mux", "nvidia.ColorSpaceConversion", "nvidia.ColorSpaceConversion", "nvidia.ColorSpaceConversion"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", "=", "0.2", ",", "device", ":", "str", "=", "\"gpu\"", ")", ":", "\n", "        ", "\"\"\"Converts image to greyscale with probability.\n\n        Args:\n            prob (float, optional): probability of conversion. Defaults to 0.2.\n            device (str, optional): device on which the operation will be performed.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "self", ".", "grayscale", "=", "ops", ".", "ColorSpaceConversion", "(", "\n", "device", "=", "device", ",", "image_type", "=", "types", ".", "RGB", ",", "output_type", "=", "types", ".", "GRAY", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomGrayScaleConversion.__call__": [[69, 73], ["dali_dataloader.RandomGrayScaleConversion.grayscale", "nvidia.cat", "nvidia.cat", "nvidia.cat", "dali_dataloader.RandomGrayScaleConversion.mux"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "grayscale", "(", "images", ")", "\n", "out", "=", "fn", ".", "cat", "(", "out", ",", "out", ",", "out", ",", "axis", "=", "2", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomColorJitter.__init__": [[76, 128], ["dali_dataloader.Mux", "nvidia.ColorTwist", "nvidia.ColorTwist", "nvidia.ColorTwist", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform", "max", "max", "max"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "prob", ":", "float", "=", "0.8", ",", "\n", "device", ":", "str", "=", "\"gpu\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies random color jittering with probability.\n\n        Args:\n            brightness (float): brightness value for samplying uniformly\n                in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): contrast value for samplying uniformly\n                in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): saturation value for samplying uniformly\n                in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): hue value for samplying uniformly in [-hue, hue].\n            prob (float, optional): probability of applying jitter. Defaults to 0.8.\n            device (str, optional): device on which the operation will be performed.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "assert", "0", "<=", "hue", "<=", "0.5", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "\n", "self", ".", "color", "=", "ops", ".", "ColorTwist", "(", "device", "=", "device", ")", "\n", "\n", "# look at torchvision docs to see how colorjitter samples stuff", "\n", "# for bright, cont and sat, it samples from [1-v, 1+v]", "\n", "# for hue, it samples from [-hue, hue]", "\n", "\n", "self", ".", "brightness", "=", "1", "\n", "self", ".", "contrast", "=", "1", "\n", "self", ".", "saturation", "=", "1", "\n", "self", ".", "hue", "=", "0", "\n", "\n", "if", "brightness", ":", "\n", "            ", "self", ".", "brightness", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "brightness", ")", ",", "1", "+", "brightness", "]", ")", "\n", "\n", "", "if", "contrast", ":", "\n", "            ", "self", ".", "contrast", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "contrast", ")", ",", "1", "+", "contrast", "]", ")", "\n", "\n", "", "if", "saturation", ":", "\n", "            ", "self", ".", "saturation", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "max", "(", "0", ",", "1", "-", "saturation", ")", ",", "1", "+", "saturation", "]", ")", "\n", "\n", "", "if", "hue", ":", "\n", "# dali uses hue in degrees for some reason...", "\n", "            ", "hue", "=", "360", "*", "hue", "\n", "self", ".", "hue", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "-", "hue", ",", "hue", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomColorJitter.__call__": [[129, 138], ["dali_dataloader.RandomColorJitter.color", "dali_dataloader.RandomColorJitter.mux", "callable", "dali_dataloader.RandomColorJitter.brightness", "callable", "dali_dataloader.RandomColorJitter.contrast", "callable", "dali_dataloader.RandomColorJitter.saturation", "callable", "dali_dataloader.RandomColorJitter.hue"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "color", "(", "\n", "images", ",", "\n", "brightness", "=", "self", ".", "brightness", "(", ")", "if", "callable", "(", "self", ".", "brightness", ")", "else", "self", ".", "brightness", ",", "\n", "contrast", "=", "self", ".", "contrast", "(", ")", "if", "callable", "(", "self", ".", "contrast", ")", "else", "self", ".", "contrast", ",", "\n", "saturation", "=", "self", ".", "saturation", "(", ")", "if", "callable", "(", "self", ".", "saturation", ")", "else", "self", ".", "saturation", ",", "\n", "hue", "=", "self", ".", "hue", "(", ")", "if", "callable", "(", "self", ".", "hue", ")", "else", "self", ".", "hue", ",", "\n", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomGaussianBlur.__init__": [[141, 155], ["dali_dataloader.Mux", "nvidia.GaussianBlur", "nvidia.GaussianBlur", "nvidia.GaussianBlur", "nvidia.random.Uniform", "nvidia.random.Uniform", "nvidia.random.Uniform"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", ":", "float", "=", "0.5", ",", "window_size", ":", "int", "=", "23", ",", "device", ":", "str", "=", "\"gpu\"", ")", ":", "\n", "        ", "\"\"\"Applies random gaussian blur with probability.\n\n        Args:\n            prob (float, optional): probability of applying random gaussian blur. Defaults to 0.5.\n            window_size (int, optional): window size for gaussian blur. Defaults to 23.\n            device (str, optional): device on which the operation will be performe.\n                Defaults to \"gpu\".\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "# gaussian blur", "\n", "self", ".", "gaussian_blur", "=", "ops", ".", "GaussianBlur", "(", "device", "=", "device", ",", "window_size", "=", "(", "window_size", ",", "window_size", ")", ")", "\n", "self", ".", "sigma", "=", "ops", ".", "random", ".", "Uniform", "(", "range", "=", "[", "0", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomGaussianBlur.__call__": [[156, 160], ["dali_dataloader.RandomGaussianBlur.gaussian_blur", "dali_dataloader.RandomGaussianBlur.mux", "dali_dataloader.RandomGaussianBlur.sigma"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "sigma", "=", "self", ".", "sigma", "(", ")", "*", "1.9", "+", "0.1", "\n", "out", "=", "self", ".", "gaussian_blur", "(", "images", ",", "sigma", "=", "sigma", ")", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomSolarize.__init__": [[163, 174], ["dali_dataloader.Mux"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "threshold", ":", "int", "=", "128", ",", "prob", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Applies random solarization with probability.\n\n        Args:\n            threshold (int, optional): threshold for inversion. Defaults to 128.\n            prob (float, optional): probability of solarization. Defaults to 0.0.\n        \"\"\"", "\n", "\n", "self", ".", "mux", "=", "Mux", "(", "prob", "=", "prob", ")", "\n", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.RandomSolarize.__call__": [[175, 180], ["dali_dataloader.RandomSolarize.mux"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "inverted_img", "=", "255", "-", "images", "\n", "mask", "=", "images", ">=", "self", ".", "threshold", "\n", "out", "=", "mask", "*", "inverted_img", "+", "(", "True", "^", "mask", ")", "*", "images", "\n", "return", "self", ".", "mux", "(", "true_case", "=", "out", ",", "false_case", "=", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.NormalPipelineBuilder.__init__": [[183, 298], ["super().__init__", "sorted", "map", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "zip", "train_test_split", "nvidia.Resize", "nvidia.Resize", "nvidia.Resize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "pathlib.Path", "enumerate", "sorted", "os.scandir", "entry.is_dir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_path", ":", "str", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "str", ",", "\n", "validation", ":", "bool", "=", "False", ",", "\n", "device_id", ":", "int", "=", "0", ",", "\n", "shard_id", ":", "int", "=", "0", ",", "\n", "num_shards", ":", "int", "=", "1", ",", "\n", "num_threads", ":", "int", "=", "4", ",", "\n", "seed", ":", "int", "=", "12", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initializes the pipeline for validation or linear eval training.\n\n        If validation is set to True then images will only be resized to 256px and center cropped\n        to 224px, otherwise random resized crop, horizontal flip are applied. In both cases images\n        are normalized.\n\n        Args:\n            data_path (str): directory that contains the data.\n            batch_size (int): batch size.\n            device (str): device on which the operation will be performed.\n            validation (bool): whether it is validation or training. Defaults to False. Defaults to\n                False.\n            device_id (int): id of the device used to initialize the seed and for parent class.\n                Defaults to 0.\n            shard_id (int): id of the shard (chuck of samples). Defaults to 0.\n            num_shards (int): total number of shards. Defaults to 1.\n            num_threads (int): number of threads to run in parallel. Defaults to 4.\n            seed (int): seed for random number generation. Defaults to 12.\n            data_fraction (float): percentage of data to use. Use all data when set to -1.0.\n                Defaults to -1.0.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_threads", "=", "num_threads", "\n", "self", ".", "device_id", "=", "device_id", "\n", "self", ".", "seed", "=", "seed", "+", "device_id", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "validation", "=", "validation", "\n", "\n", "# manually load files and labels", "\n", "labels", "=", "sorted", "(", "Path", "(", "entry", ".", "name", ")", "for", "entry", "in", "os", ".", "scandir", "(", "data_path", ")", "if", "entry", ".", "is_dir", "(", ")", ")", "\n", "data", "=", "[", "\n", "(", "data_path", "/", "label", "/", "file", ",", "label_idx", ")", "\n", "for", "label_idx", ",", "label", "in", "enumerate", "(", "labels", ")", "\n", "for", "file", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", "/", "label", ")", ")", "\n", "]", "\n", "files", ",", "labels", "=", "map", "(", "list", ",", "zip", "(", "*", "data", ")", ")", "\n", "\n", "# sample data if needed", "\n", "if", "data_fraction", ">", "0", ":", "\n", "            ", "assert", "data_fraction", "<", "1", ",", "\"data_fraction must be smaller than 1.\"", "\n", "\n", "from", "sklearn", ".", "model_selection", "import", "train_test_split", "\n", "\n", "files", ",", "_", ",", "labels", ",", "_", "=", "train_test_split", "(", "\n", "files", ",", "labels", ",", "train_size", "=", "data_fraction", ",", "stratify", "=", "labels", ",", "random_state", "=", "42", "\n", ")", "\n", "\n", "", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "labels", "=", "labels", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "not", "self", ".", "validation", ",", "\n", ")", "\n", "decoder_device", "=", "\"mixed\"", "if", "self", ".", "device", "==", "\"gpu\"", "else", "\"cpu\"", "\n", "device_memory_padding", "=", "211025920", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "host_memory_padding", "=", "140544512", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "self", ".", "decode", "=", "ops", ".", "decoders", ".", "Image", "(", "\n", "device", "=", "decoder_device", ",", "\n", "output_type", "=", "types", ".", "RGB", ",", "\n", "device_memory_padding", "=", "device_memory_padding", ",", "\n", "host_memory_padding", "=", "host_memory_padding", ",", "\n", ")", "\n", "\n", "# crop operations", "\n", "if", "self", ".", "validation", ":", "\n", "            ", "self", ".", "resize", "=", "ops", ".", "Resize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "resize_shorter", "=", "256", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "# center crop and normalize", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "crop", "=", "(", "224", ",", "224", ")", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "resize", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "size", "=", "224", ",", "\n", "random_area", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "self", ".", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "\n", "", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "0.5", ")", "\n", "self", ".", "to_int64", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "INT64", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.NormalPipelineBuilder.pipeline": [[299, 323], ["dali_dataloader.NormalPipelineBuilder.reader", "dali_dataloader.NormalPipelineBuilder.decode", "dali_dataloader.NormalPipelineBuilder.resize", "dali_dataloader.NormalPipelineBuilder.to_int64", "dali_dataloader.NormalPipelineBuilder.cmn", "dali_dataloader.NormalPipelineBuilder.cmn", "labels.gpu.gpu.gpu", "dali_dataloader.NormalPipelineBuilder.coin05"], "methods", ["None"], ["", "@", "pipeline_def", "\n", "def", "pipeline", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the computational pipeline for dali operations.\"\"\"", "\n", "\n", "# read images from memory", "\n", "inputs", ",", "labels", "=", "self", ".", "reader", "(", "name", "=", "\"Reader\"", ")", "\n", "images", "=", "self", ".", "decode", "(", "inputs", ")", "\n", "\n", "# crop into large and small images", "\n", "images", "=", "self", ".", "resize", "(", "images", ")", "\n", "\n", "if", "self", ".", "validation", ":", "\n", "# crop and normalize", "\n", "            ", "images", "=", "self", ".", "cmn", "(", "images", ")", "\n", "", "else", ":", "\n", "# normalize and maybe apply horizontal flip with 0.5 chance", "\n", "            ", "images", "=", "self", ".", "cmn", "(", "images", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "device", "==", "\"gpu\"", ":", "\n", "            ", "labels", "=", "labels", ".", "gpu", "(", ")", "\n", "# PyTorch expects labels as INT64", "\n", "", "labels", "=", "self", ".", "to_int64", "(", "labels", ")", "\n", "\n", "return", "(", "images", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ImagenetTransform.__init__": [[335, 413], ["nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "dali_dataloader.RandomColorJitter", "dali_dataloader.RandomGrayScaleConversion", "dali_dataloader.RandomGaussianBlur", "dali_dataloader.RandomSolarize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "device", ":", "str", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "224", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies Imagenet transformations to a batch of images.\n\n        Args:\n            device (str): device on which the operations will be performed.\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            color_jitter_prob (float, optional): probability of applying color jitter.\n                Defaults to 0.8.\n            gray_scale_prob (float, optional): probability of converting to gray scale.\n                Defaults to 0.2.\n            horizontal_flip_prob (float, optional): probability of flipping horizontally.\n                Defaults to 0.5.\n            gaussian_prob (float, optional): probability of applying gaussian blur.\n                Defaults to 0.0.\n            solarization_prob (float, optional): probability of applying solarization.\n                Defaults to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the crop. Defaults to 224.\n        \"\"\"", "\n", "\n", "# random crop", "\n", "self", ".", "random_crop", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "device", ",", "\n", "size", "=", "crop_size", ",", "\n", "random_area", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "\n", "# color jitter", "\n", "self", ".", "random_color_jitter", "=", "RandomColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "prob", "=", "color_jitter_prob", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "# grayscale conversion", "\n", "self", ".", "random_grayscale", "=", "RandomGrayScaleConversion", "(", "prob", "=", "gray_scale_prob", ",", "device", "=", "device", ")", "\n", "\n", "# gaussian blur", "\n", "self", ".", "random_gaussian_blur", "=", "RandomGaussianBlur", "(", "prob", "=", "gaussian_prob", ",", "device", "=", "device", ")", "\n", "\n", "# solarization", "\n", "self", ".", "random_solarization", "=", "RandomSolarize", "(", "prob", "=", "solarization_prob", ")", "\n", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "0.485", "*", "255", ",", "0.456", "*", "255", ",", "0.406", "*", "255", "]", ",", "\n", "std", "=", "[", "0.228", "*", "255", ",", "0.224", "*", "255", ",", "0.225", "*", "255", "]", ",", "\n", ")", "\n", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "horizontal_flip_prob", ")", "\n", "\n", "self", ".", "str", "=", "(", "\n", "\"ImagenetTransform(\"", "\n", "f\"random_crop({min_scale}, {max_scale}), \"", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ImagenetTransform.__str__": [[421, 423], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "self", ".", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ImagenetTransform.__call__": [[424, 432], ["dali_dataloader.ImagenetTransform.random_crop", "dali_dataloader.ImagenetTransform.random_color_jitter", "dali_dataloader.ImagenetTransform.random_grayscale", "dali_dataloader.ImagenetTransform.random_gaussian_blur", "dali_dataloader.ImagenetTransform.random_solarization", "dali_dataloader.ImagenetTransform.cmn", "dali_dataloader.ImagenetTransform.coin05"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "random_crop", "(", "images", ")", "\n", "out", "=", "self", ".", "random_color_jitter", "(", "out", ")", "\n", "out", "=", "self", ".", "random_grayscale", "(", "out", ")", "\n", "out", "=", "self", ".", "random_gaussian_blur", "(", "out", ")", "\n", "out", "=", "self", ".", "random_solarization", "(", "out", ")", "\n", "out", "=", "self", ".", "cmn", "(", "out", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.CustomTransform.__init__": [[435, 514], ["nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "nvidia.RandomResizedCrop", "dali_dataloader.RandomColorJitter", "dali_dataloader.RandomGrayScaleConversion", "dali_dataloader.RandomGaussianBlur", "dali_dataloader.RandomSolarize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.CropMirrorNormalize", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip", "nvidia.random.CoinFlip"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "device", ":", "str", ",", "\n", "brightness", ":", "float", ",", "\n", "contrast", ":", "float", ",", "\n", "saturation", ":", "float", ",", "\n", "hue", ":", "float", ",", "\n", "color_jitter_prob", ":", "float", "=", "0.8", ",", "\n", "gray_scale_prob", ":", "float", "=", "0.2", ",", "\n", "horizontal_flip_prob", ":", "float", "=", "0.5", ",", "\n", "gaussian_prob", ":", "float", "=", "0.5", ",", "\n", "solarization_prob", ":", "float", "=", "0.0", ",", "\n", "min_scale", ":", "float", "=", "0.08", ",", "\n", "max_scale", ":", "float", "=", "1.0", ",", "\n", "crop_size", ":", "int", "=", "224", ",", "\n", "mean", ":", "Sequence", "[", "float", "]", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "\n", "std", ":", "Sequence", "[", "float", "]", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Applies Custom transformations.\n        If you want to do exoteric augmentations, you can just re-write this class.\n\n        Args:\n            device (str): device on which the operations will be performed.\n            brightness (float): sampled uniformly in [max(0, 1 - brightness), 1 + brightness].\n            contrast (float): sampled uniformly in [max(0, 1 - contrast), 1 + contrast].\n            saturation (float): sampled uniformly in [max(0, 1 - saturation), 1 + saturation].\n            hue (float): sampled uniformly in [-hue, hue].\n            gaussian_prob (float, optional): probability of applying gaussian blur. Defaults to 0.5.\n            solarization_prob (float, optional): probability of applying solarization. Defaults\n                to 0.0.\n            min_scale (float, optional): minimum scale of the crops. Defaults to 0.08.\n            max_scale (float, optional): maximum scale of the crops. Defaults to 1.0.\n            crop_size (int, optional): size of the side of the image after transformation. Defaults\n                to 224.\n            mean (Sequence[float], optional): mean values for normalization.\n                Defaults to (0.485, 0.456, 0.406).\n            std (Sequence[float], optional): std values for normalization.\n                Defaults to (0.228, 0.224, 0.225).\n        \"\"\"", "\n", "\n", "# random crop", "\n", "self", ".", "random_crop", "=", "ops", ".", "RandomResizedCrop", "(", "\n", "device", "=", "device", ",", "\n", "size", "=", "crop_size", ",", "\n", "random_area", "=", "(", "min_scale", ",", "max_scale", ")", ",", "\n", "interp_type", "=", "types", ".", "INTERP_CUBIC", ",", "\n", ")", "\n", "\n", "# color jitter", "\n", "self", ".", "random_color_jitter", "=", "RandomColorJitter", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "prob", "=", "color_jitter_prob", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "# grayscale conversion", "\n", "self", ".", "random_grayscale", "=", "RandomGrayScaleConversion", "(", "prob", "=", "gray_scale_prob", ",", "device", "=", "device", ")", "\n", "\n", "# gaussian blur", "\n", "self", ".", "random_gaussian_blur", "=", "RandomGaussianBlur", "(", "prob", "=", "gaussian_prob", ",", "device", "=", "device", ")", "\n", "\n", "# solarization", "\n", "self", ".", "random_solarization", "=", "RandomSolarize", "(", "prob", "=", "solarization_prob", ")", "\n", "\n", "# normalize and horizontal flip", "\n", "self", ".", "cmn", "=", "ops", ".", "CropMirrorNormalize", "(", "\n", "device", "=", "device", ",", "\n", "dtype", "=", "types", ".", "FLOAT", ",", "\n", "output_layout", "=", "types", ".", "NCHW", ",", "\n", "mean", "=", "[", "v", "*", "255", "for", "v", "in", "mean", "]", ",", "\n", "std", "=", "[", "v", "*", "255", "for", "v", "in", "std", "]", ",", "\n", ")", "\n", "self", ".", "coin05", "=", "ops", ".", "random", ".", "CoinFlip", "(", "probability", "=", "horizontal_flip_prob", ")", "\n", "\n", "self", ".", "str", "=", "(", "\n", "\"CustomTransform(\"", "\n", "f\"random_crop({min_scale}, {max_scale}), \"", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.CustomTransform.__call__": [[522, 530], ["dali_dataloader.CustomTransform.random_crop", "dali_dataloader.CustomTransform.random_color_jitter", "dali_dataloader.CustomTransform.random_grayscale", "dali_dataloader.CustomTransform.random_gaussian_blur", "dali_dataloader.CustomTransform.random_solarization", "dali_dataloader.CustomTransform.cmn", "dali_dataloader.CustomTransform.coin05"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "images", ")", ":", "\n", "        ", "out", "=", "self", ".", "random_crop", "(", "images", ")", "\n", "out", "=", "self", ".", "random_color_jitter", "(", "out", ")", "\n", "out", "=", "self", ".", "random_grayscale", "(", "out", ")", "\n", "out", "=", "self", ".", "random_gaussian_blur", "(", "out", ")", "\n", "out", "=", "self", ".", "random_solarization", "(", "out", ")", "\n", "out", "=", "self", ".", "cmn", "(", "out", ",", "mirror", "=", "self", ".", "coin05", "(", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.CustomTransform.__repr__": [[531, 533], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "str", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.__init__": [[536, 660], ["super().__init__", "pathlib.Path", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.decoders.Image", "nvidia.Cast", "nvidia.Cast", "nvidia.Cast", "zip", "solo.utils.pretrain_dataloader.FullTransformPipeline", "sorted", "map", "train_test_split", "nvidia.readers.File", "nvidia.readers.File", "nvidia.readers.File", "enumerate", "zip", "T.append", "len", "zip", "encoded_labels.append", "dali_dataloader.PretrainPipelineBuilder.conversion_map.append", "solo.utils.pretrain_dataloader.NCropAugmentation", "sorted", "pathlib.Path", "enumerate", "sorted", "len", "os.listdir", "os.scandir", "entry.is_dir", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "str", ",", "\n", "transforms", ":", "List", "[", "Callable", "]", ",", "\n", "num_crops_per_aug", ":", "List", "[", "int", "]", ",", "\n", "random_shuffle", ":", "bool", "=", "True", ",", "\n", "device_id", ":", "int", "=", "0", ",", "\n", "shard_id", ":", "int", "=", "0", ",", "\n", "num_shards", ":", "int", "=", "1", ",", "\n", "num_threads", ":", "int", "=", "4", ",", "\n", "seed", ":", "int", "=", "12", ",", "\n", "no_labels", ":", "bool", "=", "False", ",", "\n", "encode_indexes_into_labels", ":", "bool", "=", "False", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Builder for a pretrain pipeline with Nvidia DALI.\n\n        Args:\n            data_path (str): directory that contains the data.\n            batch_size (int): batch size.\n            device (str): device on which the operation will be performed.\n            transforms (List[Callable]): list of transformations.\n            num_crops_per_aug (List[int]): number of crops per pipeline.\n            random_shuffle (bool, optional): whether to randomly shuffle the samples.\n                Defaults to True.\n            device_id (int, optional): id of the device used to initialize the seed and\n                for parent class. Defaults to 0.\n            shard_id (int, optional): id of the shard (chuck of samples). Defaults to 0.\n            num_shards (int, optional): total number of shards. Defaults to 1.\n            num_threads (int, optional): number of threads to run in parallel. Defaults to 4.\n            seed (int, optional): seed for random number generation. Defaults to 12.\n            no_labels (bool, optional): if the data has no labels. Defaults to False.\n            encode_indexes_into_labels (bool, optional): uses sample indexes as labels\n                and then gets the labels from a lookup table. This may use more CPU memory,\n                so just use when needed. Defaults to False.\n            data_fraction (float): percentage of data to use. Use all data when set to -1.\n                Defaults to -1.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_threads", "=", "num_threads", "\n", "self", ".", "device_id", "=", "device_id", "\n", "self", ".", "seed", "=", "seed", "+", "device_id", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "data_path", "=", "Path", "(", "data_path", ")", "\n", "\n", "# manually load files and labels", "\n", "if", "no_labels", ":", "\n", "            ", "files", "=", "[", "data_path", "/", "f", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", ")", ")", "]", "\n", "labels", "=", "[", "-", "1", "]", "*", "len", "(", "files", ")", "\n", "", "else", ":", "\n", "            ", "labels", "=", "sorted", "(", "Path", "(", "entry", ".", "name", ")", "for", "entry", "in", "os", ".", "scandir", "(", "data_path", ")", "if", "entry", ".", "is_dir", "(", ")", ")", "\n", "data", "=", "[", "\n", "(", "data_path", "/", "label", "/", "file", ",", "label_idx", ")", "\n", "for", "label_idx", ",", "label", "in", "enumerate", "(", "labels", ")", "\n", "for", "file", "in", "sorted", "(", "os", ".", "listdir", "(", "data_path", "/", "label", ")", ")", "\n", "]", "\n", "files", ",", "labels", "=", "map", "(", "list", ",", "zip", "(", "*", "data", ")", ")", "\n", "\n", "", "if", "data_fraction", ">", "0", ":", "\n", "            ", "assert", "data_fraction", "<", "1", ",", "\"Only use data_fraction for values smaller than 1.\"", "\n", "\n", "if", "no_labels", ":", "\n", "                ", "labels", "=", "[", "-", "1", "]", "*", "len", "(", "files", ")", "\n", "", "else", ":", "\n", "                ", "labels", "=", "[", "l", "for", "_", ",", "l", "in", "data", "]", "\n", "\n", "", "from", "sklearn", ".", "model_selection", "import", "train_test_split", "\n", "\n", "files", ",", "_", ",", "labels", ",", "_", "=", "train_test_split", "(", "\n", "files", ",", "labels", ",", "train_size", "=", "data_fraction", ",", "stratify", "=", "labels", ",", "random_state", "=", "42", "\n", ")", "\n", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "labels", "=", "labels", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "\n", "", "if", "encode_indexes_into_labels", ":", "\n", "            ", "encoded_labels", "=", "[", "]", "\n", "\n", "self", ".", "conversion_map", "=", "[", "]", "\n", "for", "file_idx", ",", "label_idx", "in", "enumerate", "(", "labels", ")", ":", "\n", "                ", "encoded_labels", ".", "append", "(", "file_idx", ")", "\n", "self", ".", "conversion_map", ".", "append", "(", "label_idx", ")", "\n", "\n", "# to assert that everything is fine", "\n", "", "for", "file_idx", ",", "label_idx", "in", "zip", "(", "encoded_labels", ",", "labels", ")", ":", "\n", "                ", "assert", "self", ".", "conversion_map", "[", "file_idx", "]", "==", "label_idx", "\n", "\n", "# use the encoded labels which will be decoded later", "\n", "", "labels", "=", "encoded_labels", "\n", "\n", "", "self", ".", "reader", "=", "ops", ".", "readers", ".", "File", "(", "\n", "files", "=", "files", ",", "\n", "labels", "=", "labels", ",", "\n", "shard_id", "=", "shard_id", ",", "\n", "num_shards", "=", "num_shards", ",", "\n", "shuffle_after_epoch", "=", "random_shuffle", ",", "\n", ")", "\n", "\n", "decoder_device", "=", "\"mixed\"", "if", "self", ".", "device", "==", "\"gpu\"", "else", "\"cpu\"", "\n", "device_memory_padding", "=", "211025920", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "host_memory_padding", "=", "140544512", "if", "decoder_device", "==", "\"mixed\"", "else", "0", "\n", "self", ".", "decode", "=", "ops", ".", "decoders", ".", "Image", "(", "\n", "device", "=", "decoder_device", ",", "\n", "output_type", "=", "types", ".", "RGB", ",", "\n", "device_memory_padding", "=", "device_memory_padding", ",", "\n", "host_memory_padding", "=", "host_memory_padding", ",", "\n", ")", "\n", "self", ".", "to_int64", "=", "ops", ".", "Cast", "(", "dtype", "=", "types", ".", "INT64", ",", "device", "=", "device", ")", "\n", "\n", "T", "=", "[", "]", "\n", "for", "transform", ",", "num_crops", "in", "zip", "(", "transforms", ",", "num_crops_per_aug", ")", ":", "\n", "            ", "T", ".", "append", "(", "NCropAugmentation", "(", "transform", ",", "num_crops", ")", ")", "\n", "", "self", ".", "transforms", "=", "FullTransformPipeline", "(", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline": [[661, 678], ["dali_dataloader.PretrainPipelineBuilder.reader", "dali_dataloader.PretrainPipelineBuilder.decode", "dali_dataloader.PretrainPipelineBuilder.transforms", "dali_dataloader.PretrainPipelineBuilder.to_int64", "labels.gpu.gpu.gpu"], "methods", ["None"], ["", "@", "pipeline_def", "\n", "def", "pipeline", "(", "self", ")", ":", "\n", "        ", "\"\"\"Defines the computational pipeline for dali operations.\"\"\"", "\n", "\n", "# read images from memory", "\n", "inputs", ",", "labels", "=", "self", ".", "reader", "(", "name", "=", "\"Reader\"", ")", "\n", "\n", "images", "=", "self", ".", "decode", "(", "inputs", ")", "\n", "\n", "crops", "=", "self", ".", "transforms", "(", "images", ")", "\n", "\n", "if", "self", ".", "device", "==", "\"gpu\"", ":", "\n", "            ", "labels", "=", "labels", ".", "gpu", "(", ")", "\n", "# PyTorch expects labels as INT64", "\n", "", "labels", "=", "self", ".", "to_int64", "(", "labels", ")", "\n", "\n", "return", "(", "*", "crops", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.__repr__": [[679, 681], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "self", ".", "transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.BaseWrapper.__len__": [[686, 702], ["math.ceil", "math.ceil"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "size", "=", "(", "\n", "self", ".", "_size_no_pad", "//", "self", ".", "_shards_num", "\n", "if", "self", ".", "_last_batch_policy", "==", "LastBatchPolicy", ".", "DROP", "\n", "else", "self", ".", "size", "\n", ")", "\n", "if", "self", ".", "_reader_name", ":", "\n", "            ", "if", "self", ".", "_last_batch_policy", "!=", "LastBatchPolicy", ".", "DROP", ":", "\n", "                ", "return", "math", ".", "ceil", "(", "size", "/", "self", ".", "batch_size", ")", "\n", "\n", "", "return", "size", "//", "self", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "_last_batch_policy", "!=", "LastBatchPolicy", ".", "DROP", ":", "\n", "                ", "return", "math", ".", "ceil", "(", "size", "/", "(", "self", ".", "_devices", "*", "self", ".", "batch_size", ")", ")", "\n", "\n", "", "return", "size", "//", "(", "self", ".", "_devices", "*", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainWrapper.__init__": [[705, 735], ["nvidia.dali.plugin.pytorch.DALIGenericIterator.__init__", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model_batch_size", ":", "int", ",", "\n", "model_rank", ":", "int", ",", "\n", "model_device", ":", "str", ",", "\n", "conversion_map", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Adds indices to a batch fetched from the parent.\n\n        Args:\n            model_batch_size (int): batch size.\n            model_rank (int): rank of the current process.\n            model_device (str): id of the current device.\n            conversion_map  (List[int], optional): list of integers that map each index\n                to a class label. If nothing is passed, no label mapping needs to be done.\n                Defaults to None.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "model_batch_size", "=", "model_batch_size", "\n", "self", ".", "model_rank", "=", "model_rank", "\n", "self", ".", "model_device", "=", "model_device", "\n", "self", ".", "conversion_map", "=", "conversion_map", "\n", "if", "self", ".", "conversion_map", "is", "not", "None", ":", "\n", "            ", "self", ".", "conversion_map", "=", "torch", ".", "tensor", "(", "\n", "self", ".", "conversion_map", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "model_device", "\n", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "self", ".", "conversion_map", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "self", ".", "conversion_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainWrapper.__next__": [[736, 762], ["super().__next__", "dali_dataloader.PretrainWrapper.conversion_map().flatten().long().detach().clone", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long().detach().clone", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long().detach().clone", "x.detach().clone", "dali_dataloader.PretrainWrapper.conversion_map().flatten().long().detach", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long().detach", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long().detach", "x.detach", "dali_dataloader.PretrainWrapper.conversion_map().flatten().long", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten().long", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze().long", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dali_dataloader.PretrainWrapper.conversion_map().flatten", "indexes.flatten().long().detach().clone.flatten().long().detach().clone.flatten", "targets.squeeze().long().detach().clone.squeeze().long().detach().clone.squeeze", "dali_dataloader.PretrainWrapper.conversion_map"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.Wrapper.__next__"], ["", "", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "super", "(", ")", ".", "__next__", "(", ")", "[", "0", "]", "\n", "# PyTorch Lightning does double buffering", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/issues/1316,", "\n", "# and as DALI owns the tensors it returns the content of it is trashed so the copy needs,", "\n", "# to be made before returning.", "\n", "\n", "if", "self", ".", "conversion_map", "is", "not", "None", ":", "\n", "            ", "*", "all_X", ",", "indexes", "=", "[", "batch", "[", "v", "]", "for", "v", "in", "self", ".", "output_map", "]", "\n", "targets", "=", "self", ".", "conversion_map", "(", "indexes", ")", ".", "flatten", "(", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "indexes", "=", "indexes", ".", "flatten", "(", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "*", "all_X", ",", "targets", "=", "[", "batch", "[", "v", "]", "for", "v", "in", "self", ".", "output_map", "]", "\n", "targets", "=", "targets", ".", "squeeze", "(", "-", "1", ")", ".", "long", "(", ")", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "# creates dummy indexes", "\n", "indexes", "=", "(", "\n", "(", "\n", "torch", ".", "arange", "(", "self", ".", "model_batch_size", ",", "device", "=", "self", ".", "model_device", ")", "\n", "+", "(", "self", ".", "model_rank", "*", "self", ".", "model_batch_size", ")", "\n", ")", "\n", ".", "detach", "(", ")", "\n", ".", "clone", "(", ")", "\n", ")", "\n", "\n", "", "all_X", "=", "[", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", "for", "x", "in", "all_X", "]", "\n", "return", "[", "indexes", ",", "all_X", ",", "targets", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.Wrapper.__next__": [[765, 776], ["super().__next__", "target.detach().clone.detach().clone.squeeze().long", "x.detach().clone.detach().clone.detach().clone", "target.detach().clone.detach().clone.detach().clone", "target.detach().clone.detach().clone.squeeze", "x.detach().clone.detach().clone.detach", "target.detach().clone.detach().clone.detach"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.Wrapper.__next__"], ["    ", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "super", "(", ")", ".", "__next__", "(", ")", "\n", "x", ",", "target", "=", "batch", "[", "0", "]", "[", "\"x\"", "]", ",", "batch", "[", "0", "]", "[", "\"label\"", "]", "\n", "target", "=", "target", ".", "squeeze", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "# PyTorch Lightning does double buffering", "\n", "# https://github.com/PyTorchLightning/pytorch-lightning/issues/1316,", "\n", "# and as DALI owns the tensors it returns the content of it is trashed so the copy needs,", "\n", "# to be made before returning.", "\n", "x", "=", "x", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "target", "=", "target", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "return", "x", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainDALIDataModule.__init__": [[779, 878], ["pytorch_lightning.LightningDataModule.__init__", "pathlib.Path", "pathlib.Path", "all", "ValueError", "transform_pipeline", "transform_pipeline"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "str", ",", "\n", "data_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "train_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "unique_augs", ":", "int", ",", "\n", "transform_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "num_crops_per_aug", ":", "List", "[", "int", "]", ",", "\n", "num_large_crops", ":", "int", ",", "\n", "num_small_crops", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "no_labels", "=", "False", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", "dali_device", ":", "str", "=", "\"gpu\"", ",", "\n", "encode_indexes_into_labels", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "\"\"\"DataModule for pretrain data using Nvidia DALI.\n\n        Args:\n            dataset (str): dataset name.\n            data_dir (Union[str, Path]): path where to download/locate the dataset.\n            train_dir (Union[str, Path]): subpath where the training data is located.\n            unique_augs (int): number of unique augmentation pielines\n            transform_kwargs (Dict[str, Any]): kwargs for the transformations.\n            num_crops_per_aug (List[int]): number of crops per pipeline.\n            num_large_crops (int): total number of large crops.\n            num_small_crops (int): total number of small crops.\n            batch_size (int): batch size..\n            num_workers (int, optional): number of parallel workers. Defaults to 4.\n            data_fraction (Optional[float]): percentage of data to use.\n                Use all data when set to -1.0. Defaults to -1.0.\n            dali_device (str, optional): device used by the dali pipeline.\n                Either 'gpu' or 'cpu'. Defaults to 'gpu'.\n            encode_indexes_into_labels (bool, optional). Encodes instance indexes\n                together with labels. Allows user to access the true instance index.\n                Defaults to False.\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "# paths", "\n", "self", ".", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "self", ".", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "\n", "# augmentation-related", "\n", "self", ".", "unique_augs", "=", "unique_augs", "\n", "self", ".", "transform_kwargs", "=", "transform_kwargs", "\n", "self", ".", "num_crops_per_aug", "=", "num_crops_per_aug", "\n", "self", ".", "num_large_crops", "=", "num_large_crops", "\n", "self", ".", "num_small_crops", "=", "num_small_crops", "\n", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "no_labels", "=", "no_labels", "\n", "self", ".", "data_fraction", "=", "data_fraction", "\n", "\n", "self", ".", "dali_device", "=", "dali_device", "\n", "assert", "dali_device", "in", "[", "\"gpu\"", ",", "\"cpu\"", "]", "\n", "# hack to encode image indexes into the labels", "\n", "self", ".", "encode_indexes_into_labels", "=", "encode_indexes_into_labels", "\n", "\n", "# handle custom data by creating the needed pipeline", "\n", "if", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", ":", "\n", "            ", "transform_pipeline", "=", "ImagenetTransform", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "            ", "transform_pipeline", "=", "CustomTransform", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset", ",", "\"is not supported, used [imagenet, imagenet100 or custom]\"", ")", "\n", "\n", "", "if", "unique_augs", ">", "1", ":", "\n", "            ", "assert", "all", "(", "\n", "[", "(", "kwargs", "[", "\"equalization_prob\"", "]", "==", "0.0", ")", "for", "kwargs", "in", "transform_kwargs", "]", "\n", ")", ",", "\"Equalization is not yet supported in Dali\"", "\n", "for", "kwargs", "in", "transform_kwargs", ":", "\n", "                ", "del", "kwargs", "[", "\"equalization_prob\"", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "assert", "(", "\n", "transform_kwargs", "[", "\"equalization_prob\"", "]", "==", "0.0", "\n", ")", ",", "\"Equalization is not yet supported in Dali\"", "\n", "del", "transform_kwargs", "[", "\"equalization_prob\"", "]", "\n", "\n", "", "if", "unique_augs", ">", "1", ":", "\n", "            ", "self", ".", "transforms", "=", "[", "\n", "transform_pipeline", "(", "\n", "device", "=", "dali_device", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "for", "kwargs", "in", "transform_kwargs", "\n", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transforms", "=", "[", "transform_pipeline", "(", "device", "=", "dali_device", ",", "**", "transform_kwargs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainDALIDataModule.add_dali_args": [[879, 887], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_dali_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"dali\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dali_device\"", ",", "type", "=", "str", ",", "default", "=", "\"gpu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--encode_indexes_into_labels\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainDALIDataModule.setup": [[888, 899], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "# extra info about training", "\n", "        ", "self", ".", "device_id", "=", "self", ".", "trainer", ".", "local_rank", "\n", "self", ".", "shard_id", "=", "self", ".", "trainer", ".", "global_rank", "\n", "self", ".", "num_shards", "=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "# get current device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "dali_device", "==", "\"gpu\"", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "f\"cuda:{torch.cuda.current_device()}\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainDALIDataModule.train_dataloader": [[900, 948], ["dali_dataloader.PretrainPipelineBuilder", "dali_dataloader.PretrainPipelineBuilder.pipeline", "dali_dataloader.PretrainPipelineBuilder.pipeline", "dali_dataloader.PretrainWrapper", "dali_dataloader.PretrainPipelineBuilder.pipeline", "range", "range"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "train_pipeline_builder", "=", "PretrainPipelineBuilder", "(", "\n", "self", ".", "data_dir", "/", "self", ".", "train_dir", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "transforms", "=", "self", ".", "transforms", ",", "\n", "num_crops_per_aug", "=", "self", ".", "num_crops_per_aug", ",", "\n", "device", "=", "self", ".", "dali_device", ",", "\n", "device_id", "=", "self", ".", "device_id", ",", "\n", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "num_shards", ",", "\n", "num_threads", "=", "self", ".", "num_workers", ",", "\n", "no_labels", "=", "self", ".", "no_labels", ",", "\n", "encode_indexes_into_labels", "=", "self", ".", "encode_indexes_into_labels", ",", "\n", "data_fraction", "=", "self", ".", "data_fraction", ",", "\n", ")", "\n", "train_pipeline", "=", "train_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "train_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "train_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "train_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "train_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "train_pipeline", ".", "build", "(", ")", "\n", "\n", "output_map", "=", "(", "\n", "[", "f\"large{i}\"", "for", "i", "in", "range", "(", "self", ".", "num_large_crops", ")", "]", "\n", "+", "[", "f\"small{i}\"", "for", "i", "in", "range", "(", "self", ".", "num_small_crops", ")", "]", "\n", "+", "[", "\"label\"", "]", "\n", ")", "\n", "\n", "policy", "=", "LastBatchPolicy", ".", "DROP", "\n", "conversion_map", "=", "(", "\n", "train_pipeline_builder", ".", "conversion_map", "if", "self", ".", "encode_indexes_into_labels", "else", "None", "\n", ")", "\n", "train_loader", "=", "PretrainWrapper", "(", "\n", "model_batch_size", "=", "self", ".", "batch_size", ",", "\n", "model_rank", "=", "self", ".", "device_id", ",", "\n", "model_device", "=", "self", ".", "device", ",", "\n", "conversion_map", "=", "conversion_map", ",", "\n", "pipelines", "=", "train_pipeline", ",", "\n", "output_map", "=", "output_map", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "policy", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "dali_epoch_size", "=", "train_pipeline", ".", "epoch_size", "(", "\"Reader\"", ")", "\n", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.__init__": [[951, 1002], ["pytorch_lightning.LightningDataModule.__init__", "pathlib.Path", "pathlib.Path", "pathlib.Path", "ValueError"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "str", ",", "\n", "data_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "train_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "val_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", "dali_device", ":", "str", "=", "\"gpu\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"DataModule for classification data using Nvidia DALI.\n\n        Args:\n            dataset (str): dataset name.\n            data_dir (Union[str, Path]): path where to download/locate the dataset.\n            train_dir (Union[str, Path]): subpath where the training data is located.\n            val_dir (Union[str, Path]): subpath where the validation data is located.\n            batch_size (int): batch size..\n            num_workers (int, optional): number of parallel workers. Defaults to 4.\n            data_fraction (float, optional): percentage of data to use.\n                Use all data when set to -1.0. Defaults to -1.0.\n            dali_device (str, optional): device used by the dali pipeline.\n                Either 'gpu' or 'cpu'. Defaults to 'gpu'.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "# paths", "\n", "self", ".", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "self", ".", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "self", ".", "val_dir", "=", "Path", "(", "val_dir", ")", "\n", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "data_fraction", "=", "data_fraction", "\n", "\n", "self", ".", "dali_device", "=", "dali_device", "\n", "assert", "dali_device", "in", "[", "\"gpu\"", ",", "\"cpu\"", "]", "\n", "\n", "# handle custom data by creating the needed pipeline", "\n", "if", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", "]", ":", "\n", "            ", "self", ".", "pipeline_class", "=", "NormalPipelineBuilder", "\n", "", "elif", "dataset", "==", "\"custom\"", ":", "\n", "            ", "self", ".", "pipeline_class", "=", "CustomNormalPipelineBuilder", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "dataset", ",", "\"is not supported, used [imagenet, imagenet100 or custom]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.add_dali_args": [[1003, 1010], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_dali_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"dali\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dali_device\"", ",", "type", "=", "str", ",", "default", "=", "\"gpu\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.setup": [[1011, 1022], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "# extra info about training", "\n", "        ", "self", ".", "device_id", "=", "self", ".", "trainer", ".", "local_rank", "\n", "self", ".", "shard_id", "=", "self", ".", "trainer", ".", "global_rank", "\n", "self", ".", "num_shards", "=", "self", ".", "trainer", ".", "world_size", "\n", "\n", "# get current device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "dali_device", "==", "\"gpu\"", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "f\"cuda:{torch.cuda.current_device()}\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.train_dataloader": [[1023, 1054], ["dali_dataloader.ClassificationDALIDataModule.pipeline_class", "dali_dataloader.ClassificationDALIDataModule.pipeline", "dali_dataloader.ClassificationDALIDataModule.pipeline.build", "dali_dataloader.Wrapper", "dali_dataloader.ClassificationDALIDataModule.pipeline.epoch_size"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "train_pipeline_builder", "=", "self", ".", "pipeline_class", "(", "\n", "self", ".", "data_dir", "/", "self", ".", "train_dir", ",", "\n", "validation", "=", "False", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "device", "=", "self", ".", "dali_device", ",", "\n", "device_id", "=", "self", ".", "device_id", ",", "\n", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "num_shards", ",", "\n", "num_threads", "=", "self", ".", "num_workers", ",", "\n", "data_fraction", "=", "self", ".", "data_fraction", ",", "\n", ")", "\n", "train_pipeline", "=", "train_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "train_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "train_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "train_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "train_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "train_pipeline", ".", "build", "(", ")", "\n", "\n", "train_loader", "=", "Wrapper", "(", "\n", "train_pipeline", ",", "\n", "output_map", "=", "[", "\"x\"", ",", "\"label\"", "]", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "LastBatchPolicy", ".", "DROP", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "dali_epoch_size", "=", "train_pipeline", ".", "epoch_size", "(", "\"Reader\"", ")", "\n", "\n", "return", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.val_dataloader": [[1055, 1082], ["dali_dataloader.ClassificationDALIDataModule.pipeline_class", "dali_dataloader.ClassificationDALIDataModule.pipeline", "dali_dataloader.ClassificationDALIDataModule.pipeline.build", "dali_dataloader.Wrapper"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline"], ["", "def", "val_dataloader", "(", "self", ")", "->", "DALIGenericIterator", ":", "\n", "        ", "val_pipeline_builder", "=", "self", ".", "pipeline_class", "(", "\n", "self", ".", "data_dir", "/", "self", ".", "val_dir", ",", "\n", "validation", "=", "True", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "device", "=", "self", ".", "dali_device", ",", "\n", "device_id", "=", "self", ".", "device_id", ",", "\n", "shard_id", "=", "self", ".", "shard_id", ",", "\n", "num_shards", "=", "self", ".", "num_shards", ",", "\n", "num_threads", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "val_pipeline", "=", "val_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "val_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "val_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "val_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "val_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "val_pipeline", ".", "build", "(", ")", "\n", "\n", "val_loader", "=", "Wrapper", "(", "\n", "val_pipeline", ",", "\n", "output_map", "=", "[", "\"x\"", ",", "\"label\"", "]", ",", "\n", "reader_name", "=", "\"Reader\"", ",", "\n", "last_batch_policy", "=", "LastBatchPolicy", ".", "PARTIAL", ",", "\n", "auto_reset", "=", "True", ",", "\n", ")", "\n", "return", "val_loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.__init__": [[53, 81], ["pathlib.Path", "pytorch_lightning.callbacks.Callback.__init__", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "args", ":", "Namespace", ",", "\n", "logdir", ":", "Union", "[", "str", ",", "Path", "]", "=", "Path", "(", "\"auto_umap\"", ")", ",", "\n", "frequency", ":", "int", "=", "1", ",", "\n", "keep_previous", ":", "bool", "=", "False", ",", "\n", "color_palette", ":", "str", "=", "\"hls\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"UMAP callback that automatically runs UMAP on the validation dataset and uploads the\n        figure to wandb.\n\n        Args:\n            args (Namespace): namespace object containing at least an attribute name.\n            logdir (Union[str, Path], optional): base directory to store checkpoints.\n                Defaults to Path(\"auto_umap\").\n            frequency (int, optional): number of epochs between each UMAP. Defaults to 1.\n            color_palette (str, optional): color scheme for the classes. Defaults to \"hls\".\n            keep_previous (bool, optional): whether to keep previous plots or not.\n                Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "logdir", "=", "Path", "(", "logdir", ")", "\n", "self", ".", "frequency", "=", "frequency", "\n", "self", ".", "color_palette", "=", "color_palette", "\n", "self", ".", "keep_previous", "=", "keep_previous", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.add_auto_umap_args": [[82, 94], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_auto_umap_args", "(", "parent_parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"Adds user-required arguments to a parser.\n\n        Args:\n            parent_parser (ArgumentParser): parser to add new args to.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"auto_umap\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_umap_dir\"", ",", "default", "=", "Path", "(", "\"auto_umap\"", ")", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--auto_umap_frequency\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.initial_setup": [[95, 123], ["auto_umap.AutoUMAP.logdir.exists", "str", "os.makedirs", "set", "auto_umap.random_string", "os.listdir", "auto_umap.random_string"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.random_string", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.random_string"], ["", "def", "initial_setup", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Creates the directories and does the initial setup needed.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "logger", "is", "None", ":", "\n", "            ", "if", "self", ".", "logdir", ".", "exists", "(", ")", ":", "\n", "                ", "existing_versions", "=", "set", "(", "os", ".", "listdir", "(", "self", ".", "logdir", ")", ")", "\n", "", "else", ":", "\n", "                ", "existing_versions", "=", "[", "]", "\n", "", "version", "=", "\"offline-\"", "+", "random_string", "(", ")", "\n", "while", "version", "in", "existing_versions", ":", "\n", "                ", "version", "=", "\"offline-\"", "+", "random_string", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "version", "=", "str", "(", "trainer", ".", "logger", ".", "version", ")", "\n", "", "if", "version", "is", "not", "None", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "/", "version", "\n", "self", ".", "umap_placeholder", "=", "f\"{self.args.name}-{version}\"", "+", "\"-ep={}.pdf\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "\n", "self", ".", "umap_placeholder", "=", "f\"{self.args.name}\"", "+", "\"-ep={}.pdf\"", "\n", "", "self", ".", "last_ckpt", ":", "Optional", "[", "str", "]", "=", "None", "\n", "\n", "# create logging dirs", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.on_train_start": [[124, 132], ["auto_umap.AutoUMAP.initial_setup"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.initial_setup"], ["", "", "def", "on_train_start", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Performs initial setup on training start.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "self", ".", "initial_setup", "(", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.plot": [[133, 207], ["module.eval", "module.train", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "len", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "Y.numpy.numpy.numpy", "umap.UMAP().fit_transform", "pandas.DataFrame", "matplotlib.pyplot.figure", "seaborn.scatterplot", "seaborn.scatterplot.set", "seaborn.scatterplot.tick_params", "matplotlib.pyplot.legend", "matplotlib.pyplot.tight_layout", "isinstance", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "x.to.to.to", "misc.gather.to", "misc.gather", "misc.gather", "umap.UMAP().fit_transform.append", "Y.numpy.numpy.append", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "wandb.log", "module", "misc.gather.cpu", "misc.gather.cpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "umap.UMAP", "seaborn.color_palette", "math.ceil", "auto_umap.AutoUMAP.umap_placeholder.format", "wandb.Image"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "def", "plot", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "\"\"\"Produces a UMAP visualization by forwarding all data of the\n        first validation dataloader through the module.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n            module (pl.LightningModule): current module object.\n        \"\"\"", "\n", "\n", "device", "=", "module", ".", "device", "\n", "data", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "\n", "# set module to eval model and collect all feature representations", "\n", "module", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "x", ",", "y", "in", "trainer", ".", "val_dataloaders", "[", "0", "]", ":", "\n", "                ", "x", "=", "x", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "y", "=", "y", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "feats", "=", "module", "(", "x", ")", "[", "\"feats\"", "]", "\n", "\n", "feats", "=", "gather", "(", "feats", ")", "\n", "y", "=", "gather", "(", "y", ")", "\n", "\n", "data", ".", "append", "(", "feats", ".", "cpu", "(", ")", ")", "\n", "Y", ".", "append", "(", "y", ".", "cpu", "(", ")", ")", "\n", "", "", "module", ".", "train", "(", ")", "\n", "\n", "if", "trainer", ".", "is_global_zero", "and", "len", "(", "data", ")", ":", "\n", "            ", "data", "=", "torch", ".", "cat", "(", "data", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "Y", "=", "torch", ".", "cat", "(", "Y", ",", "dim", "=", "0", ")", "\n", "num_classes", "=", "len", "(", "torch", ".", "unique", "(", "Y", ")", ")", "\n", "Y", "=", "Y", ".", "numpy", "(", ")", "\n", "\n", "data", "=", "umap", ".", "UMAP", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "data", ")", "\n", "\n", "# passing to dataframe", "\n", "df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "df", "[", "\"feat_1\"", "]", "=", "data", "[", ":", ",", "0", "]", "\n", "df", "[", "\"feat_2\"", "]", "=", "data", "[", ":", ",", "1", "]", "\n", "df", "[", "\"Y\"", "]", "=", "Y", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "9", ",", "9", ")", ")", "\n", "ax", "=", "sns", ".", "scatterplot", "(", "\n", "x", "=", "\"feat_1\"", ",", "\n", "y", "=", "\"feat_2\"", ",", "\n", "hue", "=", "\"Y\"", ",", "\n", "palette", "=", "sns", ".", "color_palette", "(", "self", ".", "color_palette", ",", "num_classes", ")", ",", "\n", "data", "=", "df", ",", "\n", "legend", "=", "\"full\"", ",", "\n", "alpha", "=", "0.3", ",", "\n", ")", "\n", "ax", ".", "set", "(", "xlabel", "=", "\"\"", ",", "ylabel", "=", "\"\"", ",", "xticklabels", "=", "[", "]", ",", "yticklabels", "=", "[", "]", ")", "\n", "ax", ".", "tick_params", "(", "left", "=", "False", ",", "right", "=", "False", ",", "bottom", "=", "False", ",", "top", "=", "False", ")", "\n", "\n", "# manually improve quality of imagenet umaps", "\n", "if", "num_classes", ">", "100", ":", "\n", "                ", "anchor", "=", "(", "0.5", ",", "1.8", ")", "\n", "", "else", ":", "\n", "                ", "anchor", "=", "(", "0.5", ",", "1.35", ")", "\n", "\n", "", "plt", ".", "legend", "(", "loc", "=", "\"upper center\"", ",", "bbox_to_anchor", "=", "anchor", ",", "ncol", "=", "math", ".", "ceil", "(", "num_classes", "/", "10", ")", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "if", "isinstance", "(", "trainer", ".", "logger", ",", "pl", ".", "loggers", ".", "WandbLogger", ")", ":", "\n", "                ", "wandb", ".", "log", "(", "\n", "{", "\"validation_umap\"", ":", "wandb", ".", "Image", "(", "ax", ")", "}", ",", "\n", "commit", "=", "False", ",", "\n", ")", "\n", "\n", "# save plot locally as well", "\n", "", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "plt", ".", "savefig", "(", "self", ".", "path", "/", "self", ".", "umap_placeholder", ".", "format", "(", "epoch", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.on_validation_end": [[208, 219], ["auto_umap.AutoUMAP.plot"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.OfflineUMAP.plot"], ["", "", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "\"\"\"Tries to generate an up-to-date UMAP visualization of the features\n        at the end of each validation epoch.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "if", "epoch", "%", "self", ".", "frequency", "==", "0", "and", "not", "trainer", ".", "sanity_checking", ":", "\n", "            ", "self", ".", "plot", "(", "trainer", ",", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.OfflineUMAP.__init__": [[222, 230], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "color_palette", ":", "str", "=", "\"hls\"", ")", ":", "\n", "        ", "\"\"\"Offline UMAP helper.\n\n        Args:\n            color_palette (str, optional): color scheme for the classes. Defaults to \"hls\".\n        \"\"\"", "\n", "\n", "self", ".", "color_palette", "=", "color_palette", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.OfflineUMAP.plot": [[231, 302], ["model.eval", "model.train", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "Y.numpy.numpy.numpy", "print", "umap.UMAP().fit_transform", "pandas.DataFrame", "matplotlib.pyplot.figure", "seaborn.scatterplot", "seaborn.scatterplot.set", "seaborn.scatterplot.tick_params", "matplotlib.pyplot.legend", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm.tqdm", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "x.to.to.to", "y.to.to.to", "model", "umap.UMAP().fit_transform.append", "Y.numpy.numpy.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "umap.UMAP", "seaborn.color_palette", "math.ceil", "model.cpu", "y.to.to.cpu"], "methods", ["None"], ["", "def", "plot", "(", "\n", "self", ",", "\n", "device", ":", "str", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "dataloader", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", ",", "\n", "plot_path", ":", "str", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Produces a UMAP visualization by forwarding all data of the\n        first validation dataloader through the model.\n        **Note: the model should produce features for the forward() function.\n\n        Args:\n            device (str): gpu/cpu device.\n            model (nn.Module): current model.\n            dataloader (torch.utils.data.Dataloader): current dataloader containing data.\n            plot_path (str): path to save the figure.\n        \"\"\"", "\n", "\n", "data", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "\n", "# set module to eval model and collect all feature representations", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "x", ",", "y", "in", "tqdm", "(", "dataloader", ",", "desc", "=", "\"Collecting features\"", ")", ":", "\n", "                ", "x", "=", "x", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "y", "=", "y", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "feats", "=", "model", "(", "x", ")", "\n", "data", ".", "append", "(", "feats", ".", "cpu", "(", ")", ")", "\n", "Y", ".", "append", "(", "y", ".", "cpu", "(", ")", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "\n", "data", "=", "torch", ".", "cat", "(", "data", ",", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "Y", "=", "torch", ".", "cat", "(", "Y", ",", "dim", "=", "0", ")", "\n", "num_classes", "=", "len", "(", "torch", ".", "unique", "(", "Y", ")", ")", "\n", "Y", "=", "Y", ".", "numpy", "(", ")", "\n", "\n", "print", "(", "\"Creating UMAP\"", ")", "\n", "data", "=", "umap", ".", "UMAP", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "data", ")", "\n", "\n", "# passing to dataframe", "\n", "df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "df", "[", "\"feat_1\"", "]", "=", "data", "[", ":", ",", "0", "]", "\n", "df", "[", "\"feat_2\"", "]", "=", "data", "[", ":", ",", "1", "]", "\n", "df", "[", "\"Y\"", "]", "=", "Y", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "9", ",", "9", ")", ")", "\n", "ax", "=", "sns", ".", "scatterplot", "(", "\n", "x", "=", "\"feat_1\"", ",", "\n", "y", "=", "\"feat_2\"", ",", "\n", "hue", "=", "\"Y\"", ",", "\n", "palette", "=", "sns", ".", "color_palette", "(", "self", ".", "color_palette", ",", "num_classes", ")", ",", "\n", "data", "=", "df", ",", "\n", "legend", "=", "\"full\"", ",", "\n", "alpha", "=", "0.3", ",", "\n", ")", "\n", "ax", ".", "set", "(", "xlabel", "=", "\"\"", ",", "ylabel", "=", "\"\"", ",", "xticklabels", "=", "[", "]", ",", "yticklabels", "=", "[", "]", ")", "\n", "ax", ".", "tick_params", "(", "left", "=", "False", ",", "right", "=", "False", ",", "bottom", "=", "False", ",", "top", "=", "False", ")", "\n", "\n", "# manually improve quality of imagenet umaps", "\n", "if", "num_classes", ">", "100", ":", "\n", "            ", "anchor", "=", "(", "0.5", ",", "1.8", ")", "\n", "", "else", ":", "\n", "            ", "anchor", "=", "(", "0.5", ",", "1.35", ")", "\n", "\n", "", "plt", ".", "legend", "(", "loc", "=", "\"upper center\"", ",", "bbox_to_anchor", "=", "anchor", ",", "ncol", "=", "math", ".", "ceil", "(", "num_classes", "/", "10", ")", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "# save plot locally as well", "\n", "plt", ".", "savefig", "(", "plot_path", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.random_string": [[43, 50], ["random.Random", "list", "random.Random.shuffle", "time.time", "random.Random.choice", "random.Random.choice", "range", "range"], "function", ["None"], ["def", "random_string", "(", "letter_count", "=", "4", ",", "digit_count", "=", "4", ")", ":", "\n", "    ", "tmp_random", "=", "random", ".", "Random", "(", "time", ".", "time", "(", ")", ")", "\n", "rand_str", "=", "\"\"", ".", "join", "(", "(", "tmp_random", ".", "choice", "(", "string", ".", "ascii_lowercase", ")", "for", "x", "in", "range", "(", "letter_count", ")", ")", ")", "\n", "rand_str", "+=", "\"\"", ".", "join", "(", "(", "tmp_random", ".", "choice", "(", "string", ".", "digits", ")", "for", "x", "in", "range", "(", "digit_count", ")", ")", ")", "\n", "rand_str", "=", "list", "(", "rand_str", ")", "\n", "tmp_random", ".", "shuffle", "(", "rand_str", ")", "\n", "return", "\"\"", ".", "join", "(", "rand_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.__init__": [[28, 65], ["int", "torchmetrics.metric.Metric.__init__", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state", "knn.WeightedKNNClassifier.add_state"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "k", ":", "int", "=", "20", ",", "\n", "T", ":", "float", "=", "0.07", ",", "\n", "max_distance_matrix_size", ":", "int", "=", "int", "(", "5e6", ")", ",", "\n", "distance_fx", ":", "str", "=", "\"cosine\"", ",", "\n", "epsilon", ":", "float", "=", "0.00001", ",", "\n", "dist_sync_on_step", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implements the weighted k-NN classifier used for evaluation.\n\n        Args:\n            k (int, optional): number of neighbors. Defaults to 20.\n            T (float, optional): temperature for the exponential. Only used with cosine\n                distance. Defaults to 0.07.\n            max_distance_matrix_size (int, optional): maximum number of elements in the\n                distance matrix. Defaults to 5e6.\n            distance_fx (str, optional): Distance function. Accepted arguments: \"cosine\" or\n                \"euclidean\". Defaults to \"cosine\".\n            epsilon (float, optional): Small value for numerical stability. Only used with\n                euclidean distance. Defaults to 0.00001.\n            dist_sync_on_step (bool, optional): whether to sync distributed values at every\n                step. Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dist_sync_on_step", "=", "dist_sync_on_step", ",", "compute_on_step", "=", "False", ")", "\n", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "max_distance_matrix_size", "=", "max_distance_matrix_size", "\n", "self", ".", "distance_fx", "=", "distance_fx", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n", "self", ".", "add_state", "(", "\"train_features\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"train_targets\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"test_features\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "self", ".", "add_state", "(", "\"test_targets\"", ",", "default", "=", "[", "]", ",", "persistent", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.update": [[66, 94], ["knn.WeightedKNNClassifier.train_features.append", "knn.WeightedKNNClassifier.train_targets.append", "knn.WeightedKNNClassifier.test_features.append", "knn.WeightedKNNClassifier.test_targets.append", "train_features.size", "train_targets.size", "train_features.detach", "train_targets.detach", "test_features.size", "test_targets.size", "test_features.detach", "test_targets.detach"], "methods", ["None"], ["", "def", "update", "(", "\n", "self", ",", "\n", "train_features", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "train_targets", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "test_features", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "test_targets", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Updates the memory banks. If train (test) features are passed as input, the\n        corresponding train (test) targets must be passed as well.\n\n        Args:\n            train_features (torch.Tensor, optional): a batch of train features. Defaults to None.\n            train_targets (torch.Tensor, optional): a batch of train targets. Defaults to None.\n            test_features (torch.Tensor, optional): a batch of test features. Defaults to None.\n            test_targets (torch.Tensor, optional): a batch of test targets. Defaults to None.\n        \"\"\"", "\n", "assert", "(", "train_features", "is", "None", ")", "==", "(", "train_targets", "is", "None", ")", "\n", "assert", "(", "test_features", "is", "None", ")", "==", "(", "test_targets", "is", "None", ")", "\n", "\n", "if", "train_features", "is", "not", "None", ":", "\n", "            ", "assert", "train_features", ".", "size", "(", "0", ")", "==", "train_targets", ".", "size", "(", "0", ")", "\n", "self", ".", "train_features", ".", "append", "(", "train_features", ".", "detach", "(", ")", ")", "\n", "self", ".", "train_targets", ".", "append", "(", "train_targets", ".", "detach", "(", ")", ")", "\n", "\n", "", "if", "test_features", "is", "not", "None", ":", "\n", "            ", "assert", "test_features", ".", "size", "(", "0", ")", "==", "test_targets", ".", "size", "(", "0", ")", "\n", "self", ".", "test_features", ".", "append", "(", "test_features", ".", "detach", "(", ")", ")", "\n", "self", ".", "test_targets", ".", "append", "(", "test_targets", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.compute": [[95, 174], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.unique().numel", "torch.unique().numel", "torch.unique().numel", "torch.unique().numel", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "min", "min", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "knn.WeightedKNNClassifier.reset", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "max", "targets.size", "similarities.clone().div_().exp_.clone().div_().exp_.topk", "torch.cat.view().expand", "torch.cat.view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.zeros().to.resize_().zero_", "torch.zeros().to.resize_().zero_", "torch.zeros().to.scatter_", "torch.zeros().to.scatter_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.sort", "torch.sum.sort", "predictions.eq", "targets.size", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.gather.view", "torch.gather.view", "similarities.clone().div_().exp_.clone().div_().exp_.clone().div_().exp_", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "targets.data.view", "predictions.eq.narrow().sum().item", "predictions.eq.narrow().sum().item", "min", "torch.normalize.t", "torch.cat.view", "torch.cat.view", "torch.zeros().to.resize_", "torch.zeros().to.resize_", "torch.zeros().to.view", "torch.zeros().to.view", "similarities.clone().div_().exp_.clone().div_().exp_.view", "min", "similarities.clone().div_().exp_.clone().div_().exp_.clone().div_", "predictions.eq.narrow().sum", "predictions.eq.narrow().sum", "torch.cdist", "torch.cdist", "torch.cdist", "torch.cdist", "similarities.clone().div_().exp_.clone().div_().exp_.clone", "predictions.eq.narrow", "predictions.eq.narrow", "min", "predictions.eq.size"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute", "(", "self", ")", "->", "Tuple", "[", "float", "]", ":", "\n", "        ", "\"\"\"Computes weighted k-NN accuracy @1 and @5. If cosine distance is selected,\n        the weight is computed using the exponential of the temperature scaled cosine\n        distance of the samples. If euclidean distance is selected, the weight corresponds\n        to the inverse of the euclidean distance.\n\n        Returns:\n            Tuple[float]: k-NN accuracy @1 and @5.\n        \"\"\"", "\n", "\n", "train_features", "=", "torch", ".", "cat", "(", "self", ".", "train_features", ")", "\n", "train_targets", "=", "torch", ".", "cat", "(", "self", ".", "train_targets", ")", "\n", "test_features", "=", "torch", ".", "cat", "(", "self", ".", "test_features", ")", "\n", "test_targets", "=", "torch", ".", "cat", "(", "self", ".", "test_targets", ")", "\n", "\n", "if", "self", ".", "distance_fx", "==", "\"cosine\"", ":", "\n", "            ", "train_features", "=", "F", ".", "normalize", "(", "train_features", ")", "\n", "test_features", "=", "F", ".", "normalize", "(", "test_features", ")", "\n", "\n", "", "num_classes", "=", "torch", ".", "unique", "(", "test_targets", ")", ".", "numel", "(", ")", "\n", "num_train_images", "=", "train_targets", ".", "size", "(", "0", ")", "\n", "num_test_images", "=", "test_targets", ".", "size", "(", "0", ")", "\n", "num_train_images", "=", "train_targets", ".", "size", "(", "0", ")", "\n", "chunk_size", "=", "min", "(", "\n", "max", "(", "1", ",", "self", ".", "max_distance_matrix_size", "//", "num_train_images", ")", ",", "\n", "num_test_images", ",", "\n", ")", "\n", "k", "=", "min", "(", "self", ".", "k", ",", "num_train_images", ")", "\n", "\n", "top1", ",", "top5", ",", "total", "=", "0.0", ",", "0.0", ",", "0", "\n", "retrieval_one_hot", "=", "torch", ".", "zeros", "(", "k", ",", "num_classes", ")", ".", "to", "(", "train_features", ".", "device", ")", "\n", "for", "idx", "in", "range", "(", "0", ",", "num_test_images", ",", "chunk_size", ")", ":", "\n", "# get the features for test images", "\n", "            ", "features", "=", "test_features", "[", "idx", ":", "min", "(", "(", "idx", "+", "chunk_size", ")", ",", "num_test_images", ")", ",", ":", "]", "\n", "targets", "=", "test_targets", "[", "idx", ":", "min", "(", "(", "idx", "+", "chunk_size", ")", ",", "num_test_images", ")", "]", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "# calculate the dot product and compute top-k neighbors", "\n", "if", "self", ".", "distance_fx", "==", "\"cosine\"", ":", "\n", "                ", "similarities", "=", "torch", ".", "mm", "(", "features", ",", "train_features", ".", "t", "(", ")", ")", "\n", "", "elif", "self", ".", "distance_fx", "==", "\"euclidean\"", ":", "\n", "                ", "similarities", "=", "1", "/", "(", "torch", ".", "cdist", "(", "features", ",", "train_features", ")", "+", "self", ".", "epsilon", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "similarities", ",", "indices", "=", "similarities", ".", "topk", "(", "k", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "candidates", "=", "train_targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", "retrieved_neighbors", "=", "torch", ".", "gather", "(", "candidates", ",", "1", ",", "indices", ")", "\n", "\n", "retrieval_one_hot", ".", "resize_", "(", "batch_size", "*", "k", ",", "num_classes", ")", ".", "zero_", "(", ")", "\n", "retrieval_one_hot", ".", "scatter_", "(", "1", ",", "retrieved_neighbors", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "\n", "if", "self", ".", "distance_fx", "==", "\"cosine\"", ":", "\n", "                ", "similarities", "=", "similarities", ".", "clone", "(", ")", ".", "div_", "(", "self", ".", "T", ")", ".", "exp_", "(", ")", "\n", "\n", "", "probs", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "mul", "(", "\n", "retrieval_one_hot", ".", "view", "(", "batch_size", ",", "-", "1", ",", "num_classes", ")", ",", "\n", "similarities", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", ",", "\n", ")", ",", "\n", "1", ",", "\n", ")", "\n", "_", ",", "predictions", "=", "probs", ".", "sort", "(", "1", ",", "True", ")", "\n", "\n", "# find the predictions that match the target", "\n", "correct", "=", "predictions", ".", "eq", "(", "targets", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "top1", "=", "top1", "+", "correct", ".", "narrow", "(", "1", ",", "0", ",", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "top5", "=", "(", "\n", "top5", "+", "correct", ".", "narrow", "(", "1", ",", "0", ",", "min", "(", "5", ",", "k", ",", "correct", ".", "size", "(", "-", "1", ")", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "# top5 does not make sense if k < 5", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "", "top1", "=", "top1", "*", "100.0", "/", "total", "\n", "top5", "=", "top5", "*", "100.0", "/", "total", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "return", "top1", ",", "top5", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.__init__": [[30, 59], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "world_size", ":", "int", ",", "\n", "rank", ":", "int", ",", "\n", "num_large_crops", ":", "int", ",", "\n", "dataset_size", ":", "int", ",", "\n", "proj_features_dim", ":", "int", ",", "\n", "num_prototypes", ":", "int", ",", "\n", "kmeans_iters", ":", "int", "=", "10", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Class that performs K-Means on the hypersphere.\n\n        Args:\n            world_size (int): world size.\n            rank (int): rank of the current process.\n            num_large_crops (int): number of crops.\n            dataset_size (int): total size of the dataset (number of samples).\n            proj_features_dim (int): number of dimensions of the projected features.\n            num_prototypes (int): number of prototypes.\n            kmeans_iters (int, optional): number of iterations for the k-means clustering.\n                Defaults to 10.\n        \"\"\"", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "num_large_crops", "=", "num_large_crops", "\n", "self", ".", "dataset_size", "=", "dataset_size", "\n", "self", ".", "proj_features_dim", "=", "proj_features_dim", "\n", "self", ".", "num_prototypes", "=", "num_prototypes", "\n", "self", ".", "kmeans_iters", "=", "kmeans_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.get_indices_sparse": [[60, 65], ["numpy.arange", "scipy.sparse.csr_matrix", "numpy.unravel_index", "data.ravel", "int", "data.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_indices_sparse", "(", "data", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "cols", "=", "np", ".", "arange", "(", "data", ".", "size", ")", "\n", "M", "=", "csr_matrix", "(", "(", "cols", ",", "(", "data", ".", "ravel", "(", ")", ",", "cols", ")", ")", ",", "shape", "=", "(", "int", "(", "data", ".", "max", "(", ")", ")", "+", "1", ",", "data", ".", "size", ")", ")", "\n", "return", "[", "np", ".", "unravel_index", "(", "row", ".", "data", ",", "data", ".", "shape", ")", "for", "row", "in", "M", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.cluster_memory": [[66, 171], ["torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "torch.empty().to", "range", "centroids_list.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.broadcast", "torch.broadcast", "torch.broadcast", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm.max", "torch.mm.max", "torch.mm.max", "kmeans.KMeans.get_indices_sparse", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to().int", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.normalize", "torch.normalize", "torch.normalize", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "list", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.all_gather.wait", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "list", "torch.all_gather", "torch.all_gather", "torch.all_gather", "torch.all_gather.wait", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len", "torch.normalize.t", "local_assignments.cpu().numpy", "len", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "counts[].unsqueeze", "local_assignments.size", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "local_memory_index.size", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "torch.cat().cpu.unbind", "len", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "local_assignments.cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.get_indices_sparse"], ["", "def", "cluster_memory", "(", "\n", "self", ",", "\n", "local_memory_index", ":", "torch", ".", "Tensor", ",", "\n", "local_memory_embeddings", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Sequence", "[", "Any", "]", ":", "\n", "        ", "\"\"\"Performs K-Means clustering on the hypersphere and returns centroids and\n        assignments for each sample.\n\n        Args:\n            local_memory_index (torch.Tensor): memory bank cointaining indices of the\n                samples.\n            local_memory_embeddings (torch.Tensor): memory bank cointaining embeddings\n                of the samples.\n\n        Returns:\n            Sequence[Any]: assignments and centroids.\n        \"\"\"", "\n", "j", "=", "0", "\n", "device", "=", "local_memory_embeddings", ".", "device", "\n", "assignments", "=", "-", "torch", ".", "ones", "(", "len", "(", "self", ".", "num_prototypes", ")", ",", "self", ".", "dataset_size", ")", ".", "long", "(", ")", "\n", "centroids_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_K", ",", "K", "in", "enumerate", "(", "self", ".", "num_prototypes", ")", ":", "\n", "# run distributed k-means", "\n", "\n", "# init centroids with elements from memory bank of rank 0", "\n", "                ", "centroids", "=", "torch", ".", "empty", "(", "K", ",", "self", ".", "proj_features_dim", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "if", "self", ".", "rank", "==", "0", ":", "\n", "                    ", "random_idx", "=", "torch", ".", "randperm", "(", "len", "(", "local_memory_embeddings", "[", "j", "]", ")", ")", "[", ":", "K", "]", "\n", "assert", "len", "(", "random_idx", ")", ">=", "K", ",", "\"please reduce the number of centroids\"", "\n", "centroids", "=", "local_memory_embeddings", "[", "j", "]", "[", "random_idx", "]", "\n", "", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                    ", "dist", ".", "broadcast", "(", "centroids", ",", "0", ")", "\n", "\n", "", "for", "n_iter", "in", "range", "(", "self", ".", "kmeans_iters", "+", "1", ")", ":", "\n", "\n", "# E step", "\n", "                    ", "dot_products", "=", "torch", ".", "mm", "(", "local_memory_embeddings", "[", "j", "]", ",", "centroids", ".", "t", "(", ")", ")", "\n", "_", ",", "local_assignments", "=", "dot_products", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "# finish", "\n", "if", "n_iter", "==", "self", ".", "kmeans_iters", ":", "\n", "                        ", "break", "\n", "\n", "# M step", "\n", "", "where_helper", "=", "self", ".", "get_indices_sparse", "(", "local_assignments", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "counts", "=", "torch", ".", "zeros", "(", "K", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "int", "(", ")", "\n", "emb_sums", "=", "torch", ".", "zeros", "(", "K", ",", "self", ".", "proj_features_dim", ")", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "for", "k", "in", "range", "(", "len", "(", "where_helper", ")", ")", ":", "\n", "                        ", "if", "len", "(", "where_helper", "[", "k", "]", "[", "0", "]", ")", ">", "0", ":", "\n", "                            ", "emb_sums", "[", "k", "]", "=", "torch", ".", "sum", "(", "\n", "local_memory_embeddings", "[", "j", "]", "[", "where_helper", "[", "k", "]", "[", "0", "]", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "counts", "[", "k", "]", "=", "len", "(", "where_helper", "[", "k", "]", "[", "0", "]", ")", "\n", "", "", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                        ", "dist", ".", "all_reduce", "(", "counts", ")", "\n", "dist", ".", "all_reduce", "(", "emb_sums", ")", "\n", "", "mask", "=", "counts", ">", "0", "\n", "centroids", "[", "mask", "]", "=", "emb_sums", "[", "mask", "]", "/", "counts", "[", "mask", "]", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# normalize centroids", "\n", "centroids", "=", "F", ".", "normalize", "(", "centroids", ",", "dim", "=", "1", ",", "p", "=", "2", ")", "\n", "\n", "", "centroids_list", ".", "append", "(", "centroids", ")", "\n", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "# gather the assignments", "\n", "                    ", "assignments_all", "=", "torch", ".", "empty", "(", "\n", "self", ".", "world_size", ",", "\n", "local_assignments", ".", "size", "(", "0", ")", ",", "\n", "dtype", "=", "local_assignments", ".", "dtype", ",", "\n", "device", "=", "local_assignments", ".", "device", ",", "\n", ")", "\n", "assignments_all", "=", "list", "(", "assignments_all", ".", "unbind", "(", "0", ")", ")", "\n", "\n", "dist_process", "=", "dist", ".", "all_gather", "(", "\n", "assignments_all", ",", "local_assignments", ",", "async_op", "=", "True", "\n", ")", "\n", "dist_process", ".", "wait", "(", ")", "\n", "assignments_all", "=", "torch", ".", "cat", "(", "assignments_all", ")", ".", "cpu", "(", ")", "\n", "\n", "# gather the indexes", "\n", "indexes_all", "=", "torch", ".", "empty", "(", "\n", "self", ".", "world_size", ",", "\n", "local_memory_index", ".", "size", "(", "0", ")", ",", "\n", "dtype", "=", "local_memory_index", ".", "dtype", ",", "\n", "device", "=", "local_memory_index", ".", "device", ",", "\n", ")", "\n", "indexes_all", "=", "list", "(", "indexes_all", ".", "unbind", "(", "0", ")", ")", "\n", "dist_process", "=", "dist", ".", "all_gather", "(", "indexes_all", ",", "local_memory_index", ",", "async_op", "=", "True", ")", "\n", "dist_process", ".", "wait", "(", ")", "\n", "indexes_all", "=", "torch", ".", "cat", "(", "indexes_all", ")", ".", "cpu", "(", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "assignments_all", "=", "local_assignments", "\n", "indexes_all", "=", "local_memory_index", "\n", "\n", "# log assignments", "\n", "", "assignments", "[", "i_K", "]", "[", "indexes_all", "]", "=", "assignments_all", "\n", "\n", "# next memory bank to use", "\n", "j", "=", "(", "j", "+", "1", ")", "%", "self", ".", "num_large_crops", "\n", "\n", "", "", "return", "assignments", ",", "centroids_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.__init__": [[43, 67], ["pathlib.Path", "pytorch_lightning.callbacks.Callback.__init__", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "args", ":", "Namespace", ",", "\n", "logdir", ":", "Union", "[", "str", ",", "Path", "]", "=", "Path", "(", "\"trained_models\"", ")", ",", "\n", "frequency", ":", "int", "=", "1", ",", "\n", "keep_previous_checkpoints", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Custom checkpointer callback that stores checkpoints in an easier to access way.\n\n        Args:\n            args (Namespace): namespace object containing at least an attribute name.\n            logdir (Union[str, Path], optional): base directory to store checkpoints.\n                Defaults to \"trained_models\".\n            frequency (int, optional): number of epochs between each checkpoint. Defaults to 1.\n            keep_previous_checkpoints (bool, optional): whether to keep previous checkpoints or not.\n                Defaults to False.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "logdir", "=", "Path", "(", "logdir", ")", "\n", "self", ".", "frequency", "=", "frequency", "\n", "self", ".", "keep_previous_checkpoints", "=", "keep_previous_checkpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.add_checkpointer_args": [[68, 80], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_checkpointer_args", "(", "parent_parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"Adds user-required arguments to a parser.\n\n        Args:\n            parent_parser (ArgumentParser): parser to add new args to.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"checkpointer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_dir\"", ",", "default", "=", "Path", "(", "\"trained_models\"", ")", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_frequency\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.initial_setup": [[81, 110], ["checkpointer.Checkpointer.logdir.exists", "str", "os.makedirs", "set", "checkpointer.random_string", "os.listdir", "checkpointer.random_string"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.random_string", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.random_string"], ["", "def", "initial_setup", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Creates the directories and does the initial setup needed.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "logger", "is", "None", ":", "\n", "            ", "if", "self", ".", "logdir", ".", "exists", "(", ")", ":", "\n", "                ", "existing_versions", "=", "set", "(", "os", ".", "listdir", "(", "self", ".", "logdir", ")", ")", "\n", "", "else", ":", "\n", "                ", "existing_versions", "=", "[", "]", "\n", "", "version", "=", "\"offline-\"", "+", "random_string", "(", ")", "\n", "while", "version", "in", "existing_versions", ":", "\n", "                ", "version", "=", "\"offline-\"", "+", "random_string", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "version", "=", "str", "(", "trainer", ".", "logger", ".", "version", ")", "\n", "self", ".", "wandb_run_id", "=", "version", "\n", "", "if", "version", "is", "not", "None", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "/", "version", "\n", "self", ".", "ckpt_placeholder", "=", "f\"{self.args.name}-{version}\"", "+", "\"-ep={}.ckpt\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "self", ".", "logdir", "\n", "self", ".", "ckpt_placeholder", "=", "f\"{self.args.name}\"", "+", "\"-ep={}.ckpt\"", "\n", "", "self", ".", "last_ckpt", ":", "Optional", "[", "str", "]", "=", "None", "\n", "\n", "# create logging dirs", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.save_args": [[111, 123], ["vars", "getattr", "json.dump", "open"], "methods", ["None"], ["", "", "def", "save_args", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Stores arguments into a json file.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "is_global_zero", ":", "\n", "            ", "args", "=", "vars", "(", "self", ".", "args", ")", "\n", "args", "[", "\"wandb_run_id\"", "]", "=", "getattr", "(", "self", ",", "\"wandb_run_id\"", ",", "None", ")", "\n", "json_path", "=", "self", ".", "path", "/", "\"args.json\"", "\n", "json", ".", "dump", "(", "args", ",", "open", "(", "json_path", ",", "\"w\"", ")", ",", "default", "=", "lambda", "o", ":", "\"<not serializable>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.save": [[124, 139], ["trainer.save_checkpoint", "checkpointer.Checkpointer.ckpt_placeholder.format", "os.remove"], "methods", ["None"], ["", "", "def", "save", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ")", ":", "\n", "        ", "\"\"\"Saves current checkpoint.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "if", "trainer", ".", "is_global_zero", "and", "not", "trainer", ".", "sanity_checking", ":", "\n", "            ", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "ckpt", "=", "self", ".", "path", "/", "self", ".", "ckpt_placeholder", ".", "format", "(", "epoch", ")", "\n", "trainer", ".", "save_checkpoint", "(", "ckpt", ")", "\n", "\n", "if", "self", ".", "last_ckpt", "and", "self", ".", "last_ckpt", "!=", "ckpt", "and", "not", "self", ".", "keep_previous_checkpoints", ":", "\n", "                ", "os", ".", "remove", "(", "self", ".", "last_ckpt", ")", "\n", "", "self", ".", "last_ckpt", "=", "ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.on_train_start": [[140, 149], ["checkpointer.Checkpointer.initial_setup", "checkpointer.Checkpointer.save_args"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.initial_setup", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.save_args"], ["", "", "def", "on_train_start", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Executes initial setup and saves arguments.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "self", ".", "initial_setup", "(", "trainer", ")", "\n", "self", ".", "save_args", "(", "trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.on_train_epoch_end": [[150, 160], ["checkpointer.Checkpointer.save"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.save"], ["", "def", "on_train_epoch_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "_", ")", ":", "\n", "        ", "\"\"\"Tries to save current checkpoint at the end of each train epoch.\n\n        Args:\n            trainer (pl.Trainer): pytorch lightning trainer object.\n        \"\"\"", "\n", "\n", "epoch", "=", "trainer", ".", "current_epoch", "# type: ignore", "\n", "if", "epoch", "%", "self", ".", "frequency", "==", "0", ":", "\n", "            ", "self", ".", "save", "(", "trainer", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.random_string": [[33, 40], ["random.Random", "list", "random.Random.shuffle", "time.time", "random.Random.choice", "random.Random.choice", "range", "range"], "function", ["None"], ["def", "random_string", "(", "letter_count", "=", "4", ",", "digit_count", "=", "4", ")", ":", "\n", "    ", "tmp_random", "=", "random", ".", "Random", "(", "time", ".", "time", "(", ")", ")", "\n", "rand_str", "=", "\"\"", ".", "join", "(", "(", "tmp_random", ".", "choice", "(", "string", ".", "ascii_lowercase", ")", "for", "x", "in", "range", "(", "letter_count", ")", ")", ")", "\n", "rand_str", "+=", "\"\"", ".", "join", "(", "(", "tmp_random", ".", "choice", "(", "string", ".", "digits", ")", "for", "x", "in", "range", "(", "digit_count", ")", ")", ")", "\n", "rand_str", "=", "list", "(", "rand_str", ")", "\n", "tmp_random", ".", "shuffle", "(", "rand_str", ")", "\n", "return", "\"\"", ".", "join", "(", "rand_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.build_custom_pipeline": [[31, 56], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "build_custom_pipeline", "(", ")", ":", "\n", "    ", "\"\"\"Builds augmentation pipelines for custom data.\n    If you want to do exoteric augmentations, you can just re-write this function.\n    Needs to return a dict with the same structure.\n    \"\"\"", "\n", "\n", "pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "224", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "# resize shorter", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "# take center crop", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "return", "pipeline", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms": [[58, 140], ["classification_dataloader.build_custom_pipeline", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.build_custom_pipeline"], ["", "def", "prepare_transforms", "(", "dataset", ":", "str", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Module", "]", ":", "\n", "    ", "\"\"\"Prepares pre-defined train and test transformation pipelines for some datasets.\n\n    Args:\n        dataset (str): dataset name.\n\n    Returns:\n        Tuple[nn.Module, nn.Module]: training and validation transformation pipelines.\n    \"\"\"", "\n", "\n", "cifar_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "32", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "stl_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "96", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "(", "96", ",", "96", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4823", ",", "0.4466", ")", ",", "(", "0.247", ",", "0.243", ",", "0.261", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "imagenet_pipeline", "=", "{", "\n", "\"T_train\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "224", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "\"T_val\"", ":", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "# resize shorter", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "# take center crop", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.228", ",", "0.224", ",", "0.225", ")", ")", ",", "\n", "]", "\n", ")", ",", "\n", "}", "\n", "\n", "custom_pipeline", "=", "build_custom_pipeline", "(", ")", "\n", "\n", "pipelines", "=", "{", "\n", "\"cifar10\"", ":", "cifar_pipeline", ",", "\n", "\"cifar100\"", ":", "cifar_pipeline", ",", "\n", "\"stl10\"", ":", "stl_pipeline", ",", "\n", "\"imagenet100\"", ":", "imagenet_pipeline", ",", "\n", "\"imagenet\"", ":", "imagenet_pipeline", ",", "\n", "\"custom\"", ":", "custom_pipeline", ",", "\n", "}", "\n", "\n", "assert", "dataset", "in", "pipelines", "\n", "\n", "pipeline", "=", "pipelines", "[", "dataset", "]", "\n", "T_train", "=", "pipeline", "[", "\"T_train\"", "]", "\n", "T_val", "=", "pipeline", "[", "\"T_val\"", "]", "\n", "\n", "return", "T_train", ",", "T_val", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets": [[142, 237], ["pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "DatasetClass", "DatasetClass", "train_test_split", "os.path.dirname", "vars", "torchvision.datasets.STL10", "torchvision.datasets.STL10", "tuple", "os.path.dirname", "dataset.upper", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "zip", "os.path.realpath"], "function", ["None"], ["", "def", "prepare_datasets", "(", "\n", "dataset", ":", "str", ",", "\n", "T_train", ":", "Callable", ",", "\n", "T_val", ":", "Callable", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "val_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "download", ":", "bool", "=", "True", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", ")", "->", "Tuple", "[", "Dataset", ",", "Dataset", "]", ":", "\n", "    ", "\"\"\"Prepares train and val datasets.\n\n    Args:\n        dataset (str): dataset name.\n        T_train (Callable): pipeline of transformations for training dataset.\n        T_val (Callable): pipeline of transformations for validation dataset.\n        data_dir Optional[Union[str, Path]]: path where to download/locate the dataset.\n        train_dir Optional[Union[str, Path]]: subpath where the training data is located.\n        val_dir Optional[Union[str, Path]]: subpath where the validation data is located.\n        data_fraction (Optional[float]): percentage of data to use. Use all data when set to -1.0.\n            Defaults to -1.0.\n\n    Returns:\n        Tuple[Dataset, Dataset]: training dataset and validation dataset.\n    \"\"\"", "\n", "\n", "if", "data_dir", "is", "None", ":", "\n", "        ", "sandbox_dir", "=", "Path", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", ")", "\n", "data_dir", "=", "sandbox_dir", "/", "\"datasets\"", "\n", "", "else", ":", "\n", "        ", "data_dir", "=", "Path", "(", "data_dir", ")", "\n", "\n", "", "if", "train_dir", "is", "None", ":", "\n", "        ", "train_dir", "=", "Path", "(", "f\"{dataset}/train\"", ")", "\n", "", "else", ":", "\n", "        ", "train_dir", "=", "Path", "(", "train_dir", ")", "\n", "\n", "", "if", "val_dir", "is", "None", ":", "\n", "        ", "val_dir", "=", "Path", "(", "f\"{dataset}/val\"", ")", "\n", "", "else", ":", "\n", "        ", "val_dir", "=", "Path", "(", "val_dir", ")", "\n", "\n", "", "assert", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"stl10\"", ",", "\"imagenet\"", ",", "\"imagenet100\"", ",", "\"custom\"", "]", "\n", "\n", "if", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", ":", "\n", "        ", "DatasetClass", "=", "vars", "(", "torchvision", ".", "datasets", ")", "[", "dataset", ".", "upper", "(", ")", "]", "\n", "train_dataset", "=", "DatasetClass", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "T_train", ",", "\n", ")", "\n", "\n", "val_dataset", "=", "DatasetClass", "(", "\n", "data_dir", "/", "val_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "T_val", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "==", "\"stl10\"", ":", "\n", "        ", "train_dataset", "=", "STL10", "(", "\n", "data_dir", "/", "train_dir", ",", "\n", "split", "=", "\"train\"", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "T_train", ",", "\n", ")", "\n", "val_dataset", "=", "STL10", "(", "\n", "data_dir", "/", "val_dir", ",", "\n", "split", "=", "\"test\"", ",", "\n", "download", "=", "download", ",", "\n", "transform", "=", "T_val", ",", "\n", ")", "\n", "\n", "", "elif", "dataset", "in", "[", "\"imagenet\"", ",", "\"imagenet100\"", ",", "\"custom\"", "]", ":", "\n", "        ", "train_dir", "=", "data_dir", "/", "train_dir", "\n", "val_dir", "=", "data_dir", "/", "val_dir", "\n", "\n", "train_dataset", "=", "ImageFolder", "(", "train_dir", ",", "T_train", ")", "\n", "val_dataset", "=", "ImageFolder", "(", "val_dir", ",", "T_val", ")", "\n", "\n", "", "if", "data_fraction", ">", "0", ":", "\n", "        ", "assert", "data_fraction", "<", "1", ",", "\"Only use data_fraction for values smaller than 1.\"", "\n", "data", "=", "train_dataset", ".", "samples", "\n", "files", "=", "[", "f", "for", "f", ",", "_", "in", "data", "]", "\n", "labels", "=", "[", "l", "for", "_", ",", "l", "in", "data", "]", "\n", "\n", "from", "sklearn", ".", "model_selection", "import", "train_test_split", "\n", "\n", "files", ",", "_", ",", "labels", ",", "_", "=", "train_test_split", "(", "\n", "files", ",", "labels", ",", "train_size", "=", "data_fraction", ",", "stratify", "=", "labels", ",", "random_state", "=", "42", "\n", ")", "\n", "train_dataset", ".", "samples", "=", "[", "tuple", "(", "p", ")", "for", "p", "in", "zip", "(", "files", ",", "labels", ")", "]", "\n", "\n", "", "return", "train_dataset", ",", "val_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_dataloaders": [[239, 269], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "\n", "train_dataset", ":", "Dataset", ",", "val_dataset", ":", "Dataset", ",", "batch_size", ":", "int", "=", "64", ",", "num_workers", ":", "int", "=", "4", "\n", ")", "->", "Tuple", "[", "DataLoader", ",", "DataLoader", "]", ":", "\n", "    ", "\"\"\"Wraps a train and a validation dataset with a DataLoader.\n\n    Args:\n        train_dataset (Dataset): object containing training data.\n        val_dataset (Dataset): object containing validation data.\n        batch_size (int): batch size.\n        num_workers (int): number of parallel workers.\n    Returns:\n        Tuple[DataLoader, DataLoader]: training dataloader and validation dataloader.\n    \"\"\"", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_data": [[271, 318], ["classification_dataloader.prepare_transforms", "classification_dataloader.prepare_datasets", "classification_dataloader.prepare_dataloaders"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_dataloaders"], ["", "def", "prepare_data", "(", "\n", "dataset", ":", "str", ",", "\n", "data_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "train_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "val_dir", ":", "Optional", "[", "Union", "[", "str", ",", "Path", "]", "]", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "download", ":", "bool", "=", "True", ",", "\n", "data_fraction", ":", "float", "=", "-", "1.0", ",", "\n", ")", "->", "Tuple", "[", "DataLoader", ",", "DataLoader", "]", ":", "\n", "    ", "\"\"\"Prepares transformations, creates dataset objects and wraps them in dataloaders.\n\n    Args:\n        dataset (str): dataset name.\n        data_dir (Optional[Union[str, Path]], optional): path where to download/locate the dataset.\n            Defaults to None.\n        train_dir (Optional[Union[str, Path]], optional): subpath where the\n            training data is located. Defaults to None.\n        val_dir (Optional[Union[str, Path]], optional): subpath where the\n            validation data is located. Defaults to None.\n        batch_size (int, optional): batch size. Defaults to 64.\n        num_workers (int, optional): number of parallel workers. Defaults to 4.\n        data_fraction (Optional[float]): percentage of data to use. Use all data when set to -1.0.\n            Defaults to -1.0.\n\n    Returns:\n        Tuple[DataLoader, DataLoader]: prepared training and validation dataloader.\n    \"\"\"", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "dataset", ")", "\n", "train_dataset", ",", "val_dataset", "=", "prepare_datasets", "(", "\n", "dataset", ",", "\n", "T_train", ",", "\n", "T_val", ",", "\n", "data_dir", "=", "data_dir", ",", "\n", "train_dir", "=", "train_dir", ",", "\n", "val_dir", "=", "val_dir", ",", "\n", "download", "=", "download", ",", "\n", "data_fraction", "=", "data_fraction", ",", "\n", ")", "\n", "train_loader", ",", "val_loader", "=", "prepare_dataloaders", "(", "\n", "train_dataset", ",", "\n", "val_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.__init__": [[44, 62], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_tau", ":", "float", "=", "0.996", ",", "final_tau", ":", "float", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Updates momentum parameters using exponential moving average.\n\n        Args:\n            base_tau (float, optional): base value of the weight decrease coefficient\n                (should be in [0,1]). Defaults to 0.996.\n            final_tau (float, optional): final value of the weight decrease coefficient\n                (should be in [0,1]). Defaults to 1.0.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "0", "<=", "base_tau", "<=", "1", "\n", "assert", "0", "<=", "final_tau", "<=", "1", "and", "base_tau", "<=", "final_tau", "\n", "\n", "self", ".", "base_tau", "=", "base_tau", "\n", "self", ".", "cur_tau", "=", "base_tau", "\n", "self", ".", "final_tau", "=", "final_tau", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update": [[63, 75], ["torch.no_grad", "zip", "online_net.parameters", "momentum_net.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update", "(", "self", ",", "online_net", ":", "nn", ".", "Module", ",", "momentum_net", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "\"\"\"Performs the momentum update for each param group.\n\n        Args:\n            online_net (nn.Module): online network (e.g. online backbone, online projection, etc...).\n            momentum_net (nn.Module): momentum network (e.g. momentum backbone,\n                momentum projection, etc...).\n        \"\"\"", "\n", "\n", "for", "op", ",", "mp", "in", "zip", "(", "online_net", ".", "parameters", "(", ")", ",", "momentum_net", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "mp", ".", "data", "=", "self", ".", "cur_tau", "*", "mp", ".", "data", "+", "(", "1", "-", "self", ".", "cur_tau", ")", "*", "op", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update_tau": [[76, 87], ["math.cos"], "methods", ["None"], ["", "", "def", "update_tau", "(", "self", ",", "cur_step", ":", "int", ",", "max_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"Computes the next value for the weighting decrease coefficient tau using cosine annealing.\n\n        Args:\n            cur_step (int): number of gradient steps so far.\n            max_steps (int): overall number of gradient steps in the whole training.\n        \"\"\"", "\n", "\n", "self", ".", "cur_tau", "=", "(", "\n", "self", ".", "final_tau", "\n", "-", "(", "self", ".", "final_tau", "-", "self", ".", "base_tau", ")", "*", "(", "math", ".", "cos", "(", "math", ".", "pi", "*", "cur_step", "/", "max_steps", ")", "+", "1", ")", "/", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params": [[26, 41], ["torch.no_grad", "online_net.parameters", "momentum_net.parameters", "zip", "pm.data.copy_"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "initialize_momentum_params", "(", "online_net", ":", "nn", ".", "Module", ",", "momentum_net", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Copies the parameters of the online network to the momentum network.\n\n    Args:\n        online_net (nn.Module): online network (e.g. online backbone, online projection, etc...).\n        momentum_net (nn.Module): momentum network (e.g. momentum backbone,\n            momentum projection, etc...).\n    \"\"\"", "\n", "\n", "params_online", "=", "online_net", ".", "parameters", "(", ")", "\n", "params_momentum", "=", "momentum_net", ".", "parameters", "(", ")", "\n", "for", "po", ",", "pm", "in", "zip", "(", "params_online", ",", "params_momentum", ")", ":", "\n", "        ", "pm", ".", "data", ".", "copy_", "(", "po", ".", "data", ")", "\n", "pm", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.Whitening2d.__init__": [[30, 42], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_dim", ":", "int", ",", "eps", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Layer that computes hard whitening for W-MSE using the Cholesky decomposition.\n\n        Args:\n            output_dim (int): number of dimension of projected features.\n            eps (float, optional): eps for numerical stability in Cholesky decomposition. Defaults\n                to 0.0.\n        \"\"\"", "\n", "\n", "super", "(", "Whitening2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.Whitening2d.forward": [[43, 73], ["torch.cuda.amp.custom_fwd", "torch.cuda.amp.custom_fwd", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view().mean().view", "xn.permute().contiguous().view", "torch.eye().type", "torch.eye().type", "torch.eye().type", "torch.eye().type", "inv_sqrt.contiguous().view.contiguous().view.contiguous().view", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d.squeeze().squeeze", "torch.nn.functional.conv2d.squeeze().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "f_cov.type", "torch.triangular_solve", "torch.triangular_solve", "torch.triangular_solve", "torch.triangular_solve", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view().mean", "xn.permute().contiguous", "xn.permute().contiguous().view.permute", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.linalg.cholesky", "torch.linalg.cholesky", "torch.linalg.cholesky", "torch.linalg.cholesky", "inv_sqrt.contiguous().view.contiguous().view.contiguous", "torch.nn.functional.conv2d.squeeze", "torch.nn.functional.conv2d.squeeze", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean().view", "xn.permute", "x.unsqueeze().unsqueeze.unsqueeze().unsqueeze.mean"], "methods", ["None"], ["", "@", "custom_fwd", "(", "cast_inputs", "=", "torch", ".", "float32", ")", "\n", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs whitening using the Cholesky decomposition.\n\n        Args:\n            x (torch.Tensor): a batch or slice of projected features.\n\n        Returns:\n            torch.Tensor: a batch or slice of whitened features.\n        \"\"\"", "\n", "\n", "x", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "m", "=", "x", ".", "mean", "(", "0", ")", ".", "view", "(", "self", ".", "output_dim", ",", "-", "1", ")", ".", "mean", "(", "-", "1", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "xn", "=", "x", "-", "m", "\n", "\n", "T", "=", "xn", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "output_dim", ",", "-", "1", ")", "\n", "f_cov", "=", "torch", ".", "mm", "(", "T", ",", "T", ".", "permute", "(", "1", ",", "0", ")", ")", "/", "(", "T", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "\n", "eye", "=", "torch", ".", "eye", "(", "self", ".", "output_dim", ")", ".", "type", "(", "f_cov", ".", "type", "(", ")", ")", "\n", "\n", "f_cov_shrinked", "=", "(", "1", "-", "self", ".", "eps", ")", "*", "f_cov", "+", "self", ".", "eps", "*", "eye", "\n", "\n", "inv_sqrt", "=", "torch", ".", "triangular_solve", "(", "eye", ",", "torch", ".", "linalg", ".", "cholesky", "(", "f_cov_shrinked", ")", ",", "upper", "=", "False", ")", "[", "\n", "0", "\n", "]", "\n", "inv_sqrt", "=", "inv_sqrt", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "output_dim", ",", "self", ".", "output_dim", ",", "1", ",", "1", ")", "\n", "\n", "decorrelated", "=", "conv2d", "(", "xn", ",", "inv_sqrt", ")", "\n", "\n", "return", "decorrelated", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.forward": [[76, 127], ["X.transpose().contiguous().view", "X.transpose().contiguous().view.size", "P[].mul_.matmul", "P[].mul_.matmul.view().transpose().contiguous", "ctx.save_for_backward", "X.size", "X.transpose().contiguous().view.mean", "saved.append", "torch.eye().to().expand", "torch.eye().to().expand", "torch.eye().to().expand", "torch.eye().to().expand", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "saved.append", "saved.append", "range", "saved.extend", "P[].mul_", "running_mean.copy_", "running_wmat.copy_", "X.transpose().contiguous", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "rTr.sqrt", "P[].mul_.matmul.view().transpose", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "xc.transpose", "X.transpose", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "P[].mul_.matmul.view", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "X.size", "X.size", "X.size"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "*", "args", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "X", ",", "running_mean", ",", "running_wmat", ",", "nc", ",", "ctx", ".", "T", ",", "eps", ",", "momentum", ",", "training", "=", "args", "\n", "\n", "# change NxCxHxW to (G x D) x(NxHxW), i.e., g*d*m", "\n", "ctx", ".", "g", "=", "X", ".", "size", "(", "1", ")", "//", "nc", "\n", "x", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ctx", ".", "g", ",", "nc", ",", "-", "1", ")", "\n", "_", ",", "d", ",", "m", "=", "x", ".", "size", "(", ")", "\n", "saved", "=", "[", "]", "\n", "if", "training", ":", "\n", "# calculate centered activation by subtracted mini-batch mean", "\n", "            ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "xc", "=", "x", "-", "mean", "\n", "saved", ".", "append", "(", "xc", ")", "\n", "# calculate covariance matrix", "\n", "P", "=", "[", "None", "]", "*", "(", "ctx", ".", "T", "+", "1", ")", "\n", "P", "[", "0", "]", "=", "torch", ".", "eye", "(", "d", ")", ".", "to", "(", "X", ")", ".", "expand", "(", "ctx", ".", "g", ",", "d", ",", "d", ")", "\n", "Sigma", "=", "torch", ".", "baddbmm", "(", "\n", "beta", "=", "eps", ",", "\n", "input", "=", "P", "[", "0", "]", ",", "\n", "alpha", "=", "1.0", "/", "m", ",", "\n", "batch1", "=", "xc", ",", "\n", "batch2", "=", "xc", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", ")", "\n", "# reciprocal of trace of Sigma: shape [g, 1, 1]", "\n", "rTr", "=", "(", "Sigma", "*", "P", "[", "0", "]", ")", ".", "sum", "(", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", ")", ".", "reciprocal_", "(", ")", "\n", "saved", ".", "append", "(", "rTr", ")", "\n", "Sigma_N", "=", "Sigma", "*", "rTr", "\n", "saved", ".", "append", "(", "Sigma_N", ")", "\n", "for", "k", "in", "range", "(", "ctx", ".", "T", ")", ":", "\n", "                ", "P", "[", "k", "+", "1", "]", "=", "torch", ".", "baddbmm", "(", "\n", "beta", "=", "1.5", ",", "\n", "input", "=", "P", "[", "k", "]", ",", "\n", "alpha", "=", "-", "0.5", ",", "\n", "batch1", "=", "torch", ".", "matrix_power", "(", "P", "[", "k", "]", ",", "3", ")", ",", "\n", "batch2", "=", "Sigma_N", ",", "\n", ")", "\n", "", "saved", ".", "extend", "(", "P", ")", "\n", "wm", "=", "P", "[", "ctx", ".", "T", "]", ".", "mul_", "(", "\n", "rTr", ".", "sqrt", "(", ")", "\n", ")", "# whiten matrix: the matrix inverse of Sigma, i.e., Sigma^{-1/2}", "\n", "\n", "running_mean", ".", "copy_", "(", "momentum", "*", "mean", "+", "(", "1.0", "-", "momentum", ")", "*", "running_mean", ")", "\n", "running_wmat", ".", "copy_", "(", "momentum", "*", "wm", "+", "(", "1.0", "-", "momentum", ")", "*", "running_wmat", ")", "\n", "", "else", ":", "\n", "            ", "xc", "=", "x", "-", "running_mean", "\n", "wm", "=", "running_wmat", "\n", "", "xn", "=", "wm", ".", "matmul", "(", "xc", ")", "\n", "Xn", "=", "xn", ".", "view", "(", "X", ".", "size", "(", "1", ")", ",", "X", ".", "size", "(", "0", ")", ",", "*", "X", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "ctx", ".", "save_for_backward", "(", "*", "saved", ")", "\n", "return", "Xn", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward": [[128, 164], ["saved[].transpose", "xc.size", "grad.transpose().contiguous().view_as", "grad.transpose().contiguous().view_as.matmul", "range", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm", "torch.baddbmm.view().transpose().contiguous", "torch.baddbmm.view().transpose().contiguous", "len", "xc.transpose", "rTr.sqrt", "P[].transpose_", "P[].matmul", "P[].matmul.matmul().matmul", "g_P.matmul", "g_P.baddbmm_", "g_P.baddbmm_", "g_P.baddbmm_", "wm.matmul", "grad.transpose().contiguous", "torch.baddbmm.view().transpose", "torch.baddbmm.view().transpose", "P[].matmul.matmul", "P[].matmul", "g_sn.transpose", "grad.transpose().contiguous().view_as.mean", "grad.transpose", "torch.baddbmm.view", "torch.baddbmm.view", "grad.transpose().contiguous().view_as.matmul.transpose().matmul", "grad.size", "grad.size", "saved[].transpose.matmul", "grad.transpose().contiguous().view_as.matmul.transpose", "grad.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_outputs", ")", ":", "\n", "        ", "(", "grad", ",", ")", "=", "grad_outputs", "\n", "saved", "=", "ctx", ".", "saved_tensors", "\n", "if", "len", "(", "saved", ")", "==", "0", ":", "\n", "            ", "return", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "", "xc", "=", "saved", "[", "0", "]", "# centered input", "\n", "rTr", "=", "saved", "[", "1", "]", "# trace of Sigma", "\n", "sn", "=", "saved", "[", "2", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "# normalized Sigma", "\n", "P", "=", "saved", "[", "3", ":", "]", "# middle result matrix,", "\n", "g", ",", "d", ",", "m", "=", "xc", ".", "size", "(", ")", "\n", "\n", "g_", "=", "grad", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view_as", "(", "xc", ")", "\n", "g_wm", "=", "g_", ".", "matmul", "(", "xc", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "g_P", "=", "g_wm", "*", "rTr", ".", "sqrt", "(", ")", "\n", "wm", "=", "P", "[", "ctx", ".", "T", "]", "\n", "g_sn", "=", "0", "\n", "for", "k", "in", "range", "(", "ctx", ".", "T", ",", "1", ",", "-", "1", ")", ":", "\n", "            ", "P", "[", "k", "-", "1", "]", ".", "transpose_", "(", "-", "2", ",", "-", "1", ")", "\n", "P2", "=", "P", "[", "k", "-", "1", "]", ".", "matmul", "(", "P", "[", "k", "-", "1", "]", ")", "\n", "g_sn", "+=", "P2", ".", "matmul", "(", "P", "[", "k", "-", "1", "]", ")", ".", "matmul", "(", "g_P", ")", "\n", "g_tmp", "=", "g_P", ".", "matmul", "(", "sn", ")", "\n", "g_P", ".", "baddbmm_", "(", "beta", "=", "1.5", ",", "alpha", "=", "-", "0.5", ",", "batch1", "=", "g_tmp", ",", "batch2", "=", "P2", ")", "\n", "g_P", ".", "baddbmm_", "(", "beta", "=", "1", ",", "alpha", "=", "-", "0.5", ",", "batch1", "=", "P2", ",", "batch2", "=", "g_tmp", ")", "\n", "g_P", ".", "baddbmm_", "(", "beta", "=", "1", ",", "alpha", "=", "-", "0.5", ",", "batch1", "=", "P", "[", "k", "-", "1", "]", ".", "matmul", "(", "g_tmp", ")", ",", "batch2", "=", "P", "[", "k", "-", "1", "]", ")", "\n", "", "g_sn", "+=", "g_P", "\n", "g_tr", "=", "(", "(", "-", "sn", ".", "matmul", "(", "g_sn", ")", "+", "g_wm", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ".", "matmul", "(", "wm", ")", ")", "*", "P", "[", "0", "]", ")", ".", "sum", "(", "\n", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", "\n", ")", "*", "P", "[", "0", "]", "\n", "g_sigma", "=", "(", "g_sn", "+", "g_sn", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "+", "2.0", "*", "g_tr", ")", "*", "(", "-", "0.5", "/", "m", "*", "rTr", ")", "\n", "g_x", "=", "torch", ".", "baddbmm", "(", "wm", ".", "matmul", "(", "g_", "-", "g_", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", ")", ",", "g_sigma", ",", "xc", ")", "\n", "grad_input", "=", "(", "\n", "g_x", ".", "view", "(", "grad", ".", "size", "(", "1", ")", ",", "grad", ".", "size", "(", "0", ")", ",", "*", "grad", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", ")", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.IterNorm.__init__": [[167, 214], ["super().__init__", "whitening.IterNorm.register_buffer", "whitening.IterNorm.register_buffer", "whitening.IterNorm.reset_parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "whitening.IterNorm.register_parameter", "whitening.IterNorm.register_parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.eye().expand().clone", "torch.eye().expand().clone", "torch.eye().expand().clone", "torch.eye().expand().clone", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.eye().expand", "torch.eye().expand", "torch.eye().expand", "torch.eye().expand", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.IterNorm.reset_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_features", ":", "int", ",", "\n", "num_groups", ":", "int", "=", "64", ",", "\n", "num_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "T", ":", "int", "=", "5", ",", "\n", "dim", ":", "int", "=", "2", ",", "\n", "eps", ":", "float", "=", "1.0e-5", ",", "\n", "momentum", ":", "float", "=", "0.1", ",", "\n", "affine", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", "IterNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# assert dim == 4, 'IterNorm does not support 2D'", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "dim", "=", "dim", "\n", "if", "num_channels", "is", "None", ":", "\n", "            ", "num_channels", "=", "(", "num_features", "-", "1", ")", "//", "num_groups", "+", "1", "\n", "", "num_groups", "=", "num_features", "//", "num_channels", "\n", "while", "num_features", "%", "num_channels", "!=", "0", ":", "\n", "            ", "num_channels", "//=", "2", "\n", "num_groups", "=", "num_features", "//", "num_channels", "\n", "", "assert", "(", "\n", "num_groups", ">", "0", "and", "num_features", "%", "num_groups", "==", "0", "\n", ")", ",", "f\"num features={num_features}, num groups={num_groups}\"", "\n", "self", ".", "num_groups", "=", "num_groups", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "shape", "=", "[", "1", "]", "*", "dim", "\n", "shape", "[", "1", "]", "=", "self", ".", "num_features", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "shape", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "shape", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "\"weight\"", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "\"bias\"", ",", "None", ")", "\n", "\n", "", "self", ".", "register_buffer", "(", "\"running_mean\"", ",", "torch", ".", "zeros", "(", "num_groups", ",", "num_channels", ",", "1", ")", ")", "\n", "# running whiten matrix", "\n", "self", ".", "register_buffer", "(", "\n", "\"running_wm\"", ",", "\n", "torch", ".", "eye", "(", "num_channels", ")", ".", "expand", "(", "num_groups", ",", "num_channels", ",", "num_channels", ")", ".", "clone", "(", ")", ",", "\n", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.IterNorm.reset_parameters": [[215, 219], ["torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "affine", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.IterNorm.forward": [[220, 237], ["torch.cuda.amp.custom_fwd", "torch.cuda.amp.custom_fwd", "iterative_normalization_py.apply"], "methods", ["None"], ["", "", "@", "custom_fwd", "(", "cast_inputs", "=", "torch", ".", "float32", ")", "\n", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "X_hat", "=", "iterative_normalization_py", ".", "apply", "(", "\n", "X", ",", "\n", "self", ".", "running_mean", ",", "\n", "self", ".", "running_wm", ",", "\n", "self", ".", "num_channels", ",", "\n", "self", ".", "T", ",", "\n", "self", ".", "eps", ",", "\n", "self", ".", "momentum", ",", "\n", "self", ".", "training", ",", "\n", ")", "\n", "# affine", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "return", "X_hat", "*", "self", ".", "weight", "+", "self", ".", "bias", "\n", "\n", "", "return", "X_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.IterNorm.extra_repr": [[238, 241], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f\"{self.num_features}, num_channels={self.num_channels}, T={self.T}, eps={self.eps}, \"", "\n", "\"momentum={momentum}, affine={affine}\"", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_auto_umap.test_auto_umap": [[30, 73], ["methods.utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.Namespace", "solo.utils.auto_umap.AutoUMAP", "pytorch_lightning.Trainer.from_argparse_args", "methods.utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "umap_path.exists", "shutil.rmtree", "solo.utils.auto_umap.AutoUMAP.umap_placeholder.format"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders"], ["def", "test_auto_umap", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"name\"", ":", "\"barlow_twins\"", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"proj_output_dim\"", ":", "2048", ",", "\n", "\"lamb\"", ":", "5e-3", ",", "\n", "\"scale_loss\"", ":", "0.001", ",", "\n", "}", "\n", "\n", "# normal training", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "\n", "# UMAP", "\n", "auto_umap", "=", "AutoUMAP", "(", "args", ")", "\n", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", "callbacks", "=", "[", "auto_umap", "]", ",", "\n", ")", "\n", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# check if checkpointer dumped the umap", "\n", "umap_path", "=", "auto_umap", ".", "path", "/", "auto_umap", ".", "umap_placeholder", ".", "format", "(", "trainer", ".", "current_epoch", "-", "1", ")", "\n", "assert", "umap_path", ".", "exists", "(", ")", "\n", "\n", "# clean stuff", "\n", "shutil", ".", "rmtree", "(", "auto_umap", ".", "logdir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_gather.test_gather_layer": [[24, 32], ["torch.randn", "solo.utils.misc.gather", "isinstance", "torch.mm().sum", "torch.mm().sum.backward", "torch.mm"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_gather_layer", "(", ")", ":", "\n", "    ", "X", "=", "torch", ".", "randn", "(", "10", ",", "30", ",", "requires_grad", "=", "True", ")", "\n", "X_gathered", "=", "gather", "(", "X", ")", "\n", "assert", "isinstance", "(", "X", ",", "torch", ".", "Tensor", ")", "\n", "\n", "dummy_loss", "=", "torch", ".", "mm", "(", "X_gathered", ",", "X_gathered", ".", "T", ")", ".", "sum", "(", ")", "\n", "dummy_loss", ".", "backward", "(", ")", "\n", "assert", "X", ".", "grad", "is", "not", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_filter.test_filter": [[27, 52], ["torch.randn", "torch.randn", "solo.utils.misc.filter_inf_n_nan", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "DummyNanLayer", "solo.utils.misc.FilterInfNNan", "filtered.size", "selected.sum", "solo.utils.misc.filter_inf_n_nan().size", "solo.utils.misc.FilterInfNNan.size", "t.size", "solo.utils.misc.filter_inf_n_nan", "t.size", "solo.utils.misc.filter_inf_n_nan", "solo.utils.misc.filter_inf_n_nan", "solo.utils.misc.FilterInfNNan."], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.filter_inf_n_nan"], ["def", "test_filter", "(", ")", ":", "\n", "    ", "tensor", "=", "torch", ".", "randn", "(", "100", ")", "\n", "tensor", "[", "10", "]", "=", "math", ".", "nan", "\n", "filtered", ",", "selected", "=", "filter_inf_n_nan", "(", "tensor", ",", "return_indexes", "=", "True", ")", "\n", "assert", "filtered", ".", "size", "(", "0", ")", "==", "99", "\n", "assert", "selected", ".", "sum", "(", ")", "==", "99", "\n", "\n", "tensor2", "=", "torch", ".", "randn", "(", "100", ")", "\n", "assert", "[", "t", ".", "size", "(", "0", ")", "==", "99", "for", "t", "in", "filter_inf_n_nan", "(", "[", "tensor", ",", "tensor2", "]", ")", "]", "\n", "\n", "tensor", "=", "torch", ".", "randn", "(", "100", ",", "30", ")", "\n", "tensor", "[", "10", ",", "0", "]", "=", "math", ".", "inf", "\n", "assert", "filter_inf_n_nan", "(", "tensor", ")", ".", "size", "(", "0", ")", "==", "99", "\n", "\n", "tensor2", "=", "torch", ".", "randn", "(", "100", ",", "30", ")", "\n", "assert", "[", "t", ".", "size", "(", "0", ")", "==", "99", "for", "t", "in", "filter_inf_n_nan", "(", "[", "tensor", ",", "tensor2", "]", ")", "]", "\n", "\n", "class", "DummyNanLayer", "(", "nn", ".", "Module", ")", ":", "\n", "        ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "            ", "x", "[", "10", "]", "=", "-", "math", ".", "inf", "\n", "return", "x", "\n", "\n", "", "", "dummy_nan_layer", "=", "DummyNanLayer", "(", ")", "\n", "filter_layer", "=", "FilterInfNNan", "(", "dummy_nan_layer", ")", "\n", "assert", "filter_layer", "(", "tensor", ")", ".", "size", "(", "0", ")", "==", "99", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_classification_dataloader.test_transforms": [[29, 51], ["PIL.Image.fromarray().convert", "solo.utils.classification_dataloader.prepare_transforms", "solo.utils.classification_dataloader.prepare_transforms", "PIL.Image.fromarray().convert", "solo.utils.classification_dataloader.prepare_transforms", "solo.utils.classification_dataloader.prepare_transforms", "numpy.random.rand", "T_train().size", "T_val().size", "T_train().size", "T_val().size", "numpy.random.rand", "T_train().size", "T_val().size", "T_train().size", "T_val().size", "PIL.Image.fromarray", "PIL.Image.fromarray", "Image.fromarray().convert.astype", "T_train", "T_val", "T_train", "T_val", "Image.fromarray().convert.astype", "T_train", "T_val", "T_train", "T_val"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms"], ["def", "test_transforms", "(", ")", ":", "\n", "    ", "im", "=", "np", ".", "random", ".", "rand", "(", "32", ",", "32", ",", "3", ")", "*", "255", "\n", "im", "=", "Image", ".", "fromarray", "(", "im", ".", "astype", "(", "\"uint8\"", ")", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "\"cifar10\"", ")", "\n", "assert", "T_train", "(", "im", ")", ".", "size", "(", "1", ")", "==", "32", "\n", "assert", "T_val", "(", "im", ")", ".", "size", "(", "1", ")", "==", "32", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "\"cifar100\"", ")", "\n", "assert", "T_train", "(", "im", ")", ".", "size", "(", "1", ")", "==", "32", "\n", "assert", "T_val", "(", "im", ")", ".", "size", "(", "1", ")", "==", "32", "\n", "\n", "im", "=", "np", ".", "random", ".", "rand", "(", "500", ",", "300", ",", "3", ")", "*", "255", "\n", "im", "=", "Image", ".", "fromarray", "(", "im", ".", "astype", "(", "\"uint8\"", ")", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "\"stl10\"", ")", "\n", "assert", "T_train", "(", "im", ")", ".", "size", "(", "1", ")", "==", "96", "\n", "assert", "T_val", "(", "im", ")", ".", "size", "(", "1", ")", "==", "96", "\n", "\n", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "\"imagenet100\"", ")", "\n", "assert", "T_train", "(", "im", ")", ".", "size", "(", "1", ")", "==", "224", "\n", "assert", "T_val", "(", "im", ")", ".", "size", "(", "1", ")", "==", "224", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_classification_dataloader.test_datasets": [[53, 60], ["solo.utils.classification_dataloader.prepare_transforms", "solo.utils.classification_dataloader.prepare_datasets", "isinstance", "isinstance", "len", "len"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_transforms", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets"], ["", "def", "test_datasets", "(", ")", ":", "\n", "    ", "T_train", ",", "T_val", "=", "prepare_transforms", "(", "\"cifar10\"", ")", "\n", "train_dataset", ",", "val_dataset", "=", "prepare_datasets", "(", "\"cifar10\"", ",", "T_train", ",", "T_val", ")", "\n", "assert", "isinstance", "(", "train_dataset", ",", "CIFAR10", ")", "\n", "assert", "isinstance", "(", "val_dataset", ",", "CIFAR10", ")", "\n", "assert", "len", "(", "train_dataset", "[", "0", "]", ")", "==", "2", "\n", "assert", "len", "(", "val_dataset", "[", "0", "]", ")", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_classification_dataloader.test_data": [[62, 74], ["math.ceil", "solo.utils.classification_dataloader.prepare_data", "isinstance", "isinstance", "len", "len"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_data"], ["", "def", "test_data", "(", ")", ":", "\n", "    ", "bs", "=", "64", "\n", "num_samples_train", "=", "50000", "\n", "num_samples_val", "=", "10000", "\n", "num_batches_train", "=", "num_samples_train", "//", "bs", "\n", "num_batches_val", "=", "math", ".", "ceil", "(", "num_samples_val", "/", "bs", ")", "\n", "\n", "train_loader", ",", "val_loader", "=", "prepare_data", "(", "\"cifar10\"", ",", "batch_size", "=", "bs", ",", "num_workers", "=", "0", ")", "\n", "assert", "isinstance", "(", "train_loader", ",", "DataLoader", ")", "\n", "assert", "isinstance", "(", "val_loader", ",", "DataLoader", ")", "\n", "assert", "num_batches_train", "==", "len", "(", "train_loader", ")", "\n", "assert", "num_batches_val", "==", "len", "(", "val_loader", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_auto_resumer.test_checkpointer": [[32, 89], ["methods.utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.Namespace", "solo.utils.checkpointer.Checkpointer", "pytorch_lightning.Trainer.from_argparse_args", "methods.utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "args_path.exists", "json.load", "solo.utils.auto_resumer.AutoResumer", "argparse.ArgumentParser", "solo.utils.auto_resumer.AutoResumer.add_autoresumer_args", "shutil.rmtree", "open", "vars", "solo.utils.auto_resumer.AutoResumer.find_checkpoint", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.add_autoresumer_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.find_checkpoint"], ["def", "test_checkpointer", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"name\"", ":", "\"barlow_twins\"", ",", "\n", "\"method\"", ":", "\"barlow_twins\"", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"proj_output_dim\"", ":", "2048", ",", "\n", "\"lamb\"", ":", "5e-3", ",", "\n", "\"scale_loss\"", ":", "0.025", ",", "\n", "}", "\n", "\n", "# normal training", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", ",", "\"project\"", ":", "\"test\"", ",", "\"entity\"", ":", "\"test\"", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "\n", "# checkpointer", "\n", "ckpt_callback", "=", "Checkpointer", "(", "args", ")", "\n", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", "callbacks", "=", "[", "ckpt_callback", "]", ",", "\n", ")", "\n", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# check if checkpointer dumped the args", "\n", "args_path", "=", "ckpt_callback", ".", "path", "/", "\"args.json\"", "\n", "assert", "args_path", ".", "exists", "(", ")", "\n", "\n", "# check if the args are correct", "\n", "loaded_args", "=", "json", ".", "load", "(", "open", "(", "args_path", ")", ")", "\n", "assert", "loaded_args", "==", "vars", "(", "args", ")", "\n", "\n", "auto_resumer", "=", "AutoResumer", "(", "ckpt_callback", ".", "logdir", ",", "max_hours", "=", "1", ")", "\n", "assert", "auto_resumer", ".", "find_checkpoint", "(", "args", ")", "is", "not", "None", "\n", "\n", "# check arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "auto_resumer", ".", "add_autoresumer_args", "(", "parser", ")", "\n", "args", "=", "[", "vars", "(", "action", ")", "[", "\"dest\"", "]", "for", "action", "in", "vars", "(", "parser", ")", "[", "\"_actions\"", "]", "]", "\n", "assert", "\"auto_resumer_max_hours\"", "in", "args", "\n", "\n", "# clean stuff", "\n", "shutil", ".", "rmtree", "(", "ckpt_callback", ".", "logdir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_checkpointer.test_checkpointer": [[32, 104], ["methods.utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.Namespace", "solo.utils.checkpointer.Checkpointer", "pytorch_lightning.Trainer.from_argparse_args", "methods.utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "args_path.exists", "json.load", "ckpt_path.exists", "torch.load", "list", "all", "argparse.ArgumentParser", "solo.utils.checkpointer.Checkpointer.add_checkpointer_args", "shutil.rmtree", "open", "vars", "solo.utils.checkpointer.Checkpointer.ckpt_placeholder.format", "torch.load.keys", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.add_checkpointer_args"], ["def", "test_checkpointer", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"name\"", ":", "\"barlow_twins\"", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"proj_output_dim\"", ":", "2048", ",", "\n", "\"lamb\"", ":", "5e-3", ",", "\n", "\"scale_loss\"", ":", "0.025", ",", "\n", "}", "\n", "\n", "# normal training", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "\n", "# checkpointer", "\n", "ckpt_callback", "=", "Checkpointer", "(", "args", ")", "\n", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", "callbacks", "=", "[", "ckpt_callback", "]", ",", "\n", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# check if checkpointer dumped the args", "\n", "args_path", "=", "ckpt_callback", ".", "path", "/", "\"args.json\"", "\n", "assert", "args_path", ".", "exists", "(", ")", "\n", "\n", "# check if the args are correct", "\n", "loaded_args", "=", "json", ".", "load", "(", "open", "(", "args_path", ")", ")", "\n", "assert", "loaded_args", "==", "vars", "(", "args", ")", "\n", "\n", "# check if checkpointer dumped the checkpoint", "\n", "ckpt_path", "=", "ckpt_callback", ".", "path", "/", "ckpt_callback", ".", "ckpt_placeholder", ".", "format", "(", "\n", "trainer", ".", "current_epoch", "-", "1", "\n", ")", "\n", "assert", "ckpt_path", ".", "exists", "(", ")", "\n", "\n", "# check if the checkpoint contains the correct keys", "\n", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ")", "\n", "expected_keys", "=", "[", "\n", "\"epoch\"", ",", "\n", "\"global_step\"", ",", "\n", "\"pytorch-lightning_version\"", ",", "\n", "\"state_dict\"", ",", "\n", "\"callbacks\"", ",", "\n", "\"optimizer_states\"", ",", "\n", "\"lr_schedulers\"", ",", "\n", "]", "\n", "ckpt_keys", "=", "list", "(", "ckpt", ".", "keys", "(", ")", ")", "\n", "assert", "all", "(", "k", "in", "ckpt_keys", "for", "k", "in", "expected_keys", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "ckpt_callback", ".", "add_checkpointer_args", "(", "parser", ")", "\n", "args", "=", "[", "vars", "(", "action", ")", "[", "\"dest\"", "]", "for", "action", "in", "vars", "(", "parser", ")", "[", "\"_actions\"", "]", "]", "\n", "assert", "\"checkpoint_dir\"", "in", "args", "\n", "assert", "\"checkpoint_frequency\"", "in", "args", "\n", "\n", "# clean stuff", "\n", "shutil", ".", "rmtree", "(", "ckpt_callback", ".", "logdir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_backbones.test_backbones": [[42, 105], ["torch.randn", "solo.utils.backbones.swin_tiny", "isinstance", "torch.randn", "solo.utils.backbones.swin_small", "isinstance", "solo.utils.backbones.swin_base", "isinstance", "solo.utils.backbones.swin_large", "isinstance", "torch.randn", "solo.utils.backbones.vit_tiny", "isinstance", "torch.randn", "solo.utils.backbones.vit_small", "isinstance", "solo.utils.backbones.vit_base", "isinstance", "solo.utils.backbones.vit_large", "isinstance", "torch.randn", "solo.utils.backbones.poolformer_s12", "isinstance", "torch.randn", "solo.utils.backbones.poolformer_s24", "isinstance", "solo.utils.backbones.poolformer_s36", "isinstance", "solo.utils.backbones.poolformer_m36", "isinstance", "solo.utils.backbones.poolformer_m48", "isinstance", "torch.randn", "solo.utils.backbones.convnext_tiny", "isinstance", "torch.randn", "solo.utils.backbones.convnext_small", "isinstance", "solo.utils.backbones.convnext_base", "isinstance", "solo.utils.backbones.convnext_large", "isinstance", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large.", "solo.utils.backbones.convnext_large."], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_tiny", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_small", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_base", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.swin_large", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_tiny", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_small", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_base", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.vit_large", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s12", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s24", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_s36", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_m36", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.poolformer_m48", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_tiny", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_small", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_base", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.backbones.convnext_large"], ["def", "test_backbones", "(", ")", ":", "\n", "# swin models", "\n", "    ", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "32", ",", "32", ")", "\n", "model", "=", "swin_tiny", "(", "window_size", "=", "4", ",", "img_size", "=", "32", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "224", ",", "224", ")", "\n", "model", "=", "swin_small", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "swin_base", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "swin_large", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "# vit models", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "32", ",", "32", ")", "\n", "model", "=", "vit_tiny", "(", "patch_size", "=", "8", ",", "img_size", "=", "32", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "224", ",", "224", ")", "\n", "model", "=", "vit_small", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "vit_base", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "vit_large", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "# PoolFormer", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "32", ",", "32", ")", "\n", "model", "=", "poolformer_s12", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "224", ",", "224", ")", "\n", "model", "=", "poolformer_s24", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "poolformer_s36", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "poolformer_m36", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "poolformer_m48", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "# ConvNeXt", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "32", ",", "32", ")", "\n", "model", "=", "convnext_tiny", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "dummy_data", "=", "torch", ".", "randn", "(", "6", ",", "3", ",", "224", ",", "224", ")", "\n", "model", "=", "convnext_small", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "convnext_base", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "\n", "model", "=", "convnext_large", "(", ")", "\n", "assert", "isinstance", "(", "model", "(", "dummy_data", ")", ",", "torch", ".", "Tensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_knn.test_knn": [[25, 62], ["solo.utils.knn.WeightedKNNClassifier", "solo.utils.knn.WeightedKNNClassifier.update", "solo.utils.knn.WeightedKNNClassifier.compute", "solo.utils.knn.WeightedKNNClassifier", "solo.utils.knn.WeightedKNNClassifier.update", "solo.utils.knn.WeightedKNNClassifier.compute", "torch.normalize", "torch.arange().repeat", "torch.arange().repeat", "torch.normalize", "torch.arange().repeat", "torch.arange().repeat", "torch.randn", "torch.randn", "torch.arange().repeat", "torch.arange().repeat", "torch.randn", "torch.randn", "torch.arange().repeat", "torch.arange().repeat", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.compute", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.compute"], ["def", "test_knn", "(", ")", ":", "\n", "    ", "num_samples_train", "=", "100", "\n", "num_samples_test", "=", "20", "\n", "max_distance_matrix_size", "=", "num_samples_train", "*", "num_samples_test", "//", "10", "\n", "num_classes", "=", "10", "\n", "neighbors", "=", "5", "\n", "features_dim", "=", "16", "\n", "\n", "# test distances", "\n", "knn", "=", "WeightedKNNClassifier", "(", "\n", "k", "=", "neighbors", ",", "distance_fx", "=", "\"cosine\"", ",", "max_distance_matrix_size", "=", "max_distance_matrix_size", "\n", ")", "\n", "knn", ".", "update", "(", "\n", "train_features", "=", "F", ".", "normalize", "(", "torch", ".", "randn", "(", "num_samples_train", ",", "features_dim", ")", ")", ",", "\n", "train_targets", "=", "torch", ".", "arange", "(", "end", "=", "num_classes", ")", ".", "repeat", "(", "num_samples_train", "//", "num_classes", ")", ",", "\n", "test_features", "=", "F", ".", "normalize", "(", "torch", ".", "randn", "(", "num_samples_test", ",", "features_dim", ")", ")", ",", "\n", "test_targets", "=", "torch", ".", "arange", "(", "end", "=", "num_classes", ")", ".", "repeat", "(", "num_samples_test", "//", "num_classes", ")", ",", "\n", ")", "\n", "acc1", ",", "acc5", "=", "knn", ".", "compute", "(", ")", "\n", "assert", "acc1", ">=", "0", "and", "acc1", "<=", "100", "\n", "assert", "acc5", ">=", "0", "and", "acc5", "<=", "100", "\n", "assert", "acc5", ">=", "acc1", "\n", "\n", "# test distances", "\n", "knn", "=", "WeightedKNNClassifier", "(", "\n", "k", "=", "neighbors", ",", "distance_fx", "=", "\"euclidean\"", ",", "max_distance_matrix_size", "=", "max_distance_matrix_size", "\n", ")", "\n", "knn", ".", "update", "(", "\n", "train_features", "=", "torch", ".", "randn", "(", "num_samples_train", ",", "features_dim", ")", ",", "\n", "train_targets", "=", "torch", ".", "arange", "(", "end", "=", "num_classes", ")", ".", "repeat", "(", "num_samples_train", "//", "num_classes", ")", ",", "\n", "test_features", "=", "torch", ".", "randn", "(", "num_samples_test", ",", "features_dim", ")", ",", "\n", "test_targets", "=", "torch", ".", "arange", "(", "end", "=", "num_classes", ")", ".", "repeat", "(", "num_samples_test", "//", "num_classes", ")", ",", "\n", ")", "\n", "acc1", ",", "acc5", "=", "knn", ".", "compute", "(", ")", "\n", "assert", "acc1", ">=", "0", "and", "acc1", "<=", "100", "\n", "assert", "acc5", ">=", "0", "and", "acc5", "<=", "100", "\n", "assert", "acc5", ">=", "acc1", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_metrics.test_accuracy_at_k": [[24, 32], ["torch.randn", "torch.randint", "solo.utils.metrics.accuracy_at_k", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.accuracy_at_k"], ["def", "test_accuracy_at_k", "(", ")", ":", "\n", "    ", "b", ",", "c", "=", "32", ",", "100", "\n", "output", "=", "torch", ".", "randn", "(", "b", ",", "c", ")", "\n", "target", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "c", ",", "size", "=", "(", "b", ",", ")", ")", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "output", ",", "target", ")", "\n", "\n", "assert", "isinstance", "(", "acc1", ",", "torch", ".", "Tensor", ")", "\n", "assert", "isinstance", "(", "acc5", ",", "torch", ".", "Tensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_pretrain_dataloader.test_transforms": [[32, 80], ["dict", "PIL.Image.fromarray().convert", "solo.utils.pretrain_dataloader.prepare_transform", "solo.utils.pretrain_dataloader.prepare_transform", "solo.utils.pretrain_dataloader.prepare_transform", "dict", "solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.", "zip", "numpy.random.rand", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.size", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.size", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.size", "len", "solo.utils.pretrain_dataloader.prepare_transform", "PIL.Image.fromarray", "crop.size", "Image.fromarray().convert.astype", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.", "solo.utils.pretrain_dataloader.prepare_n_crop_transform"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform"], ["def", "test_transforms", "(", ")", ":", "\n", "    ", "kwargs", "=", "dict", "(", "\n", "brightness", "=", "0.5", ",", "\n", "contrast", "=", "0.5", ",", "\n", "saturation", "=", "0.4", ",", "\n", "hue", "=", "0.2", ",", "\n", "gaussian_prob", "=", "0.5", ",", "\n", "solarization_prob", "=", "0.4", ",", "\n", "min_scale", "=", "0.08", ",", "\n", "max_scale", "=", "1.0", ",", "\n", ")", "\n", "\n", "im", "=", "np", ".", "random", ".", "rand", "(", "100", ",", "100", ",", "3", ")", "*", "255", "\n", "im", "=", "Image", ".", "fromarray", "(", "im", ".", "astype", "(", "\"uint8\"", ")", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "T", "=", "prepare_transform", "(", "\"cifar10\"", ",", "crop_size", "=", "32", ",", "**", "kwargs", ")", "\n", "assert", "T", "(", "im", ")", ".", "size", "(", "1", ")", "==", "32", "\n", "\n", "T", "=", "prepare_transform", "(", "\"stl10\"", ",", "crop_size", "=", "96", ",", "**", "kwargs", ")", "\n", "assert", "T", "(", "im", ")", ".", "size", "(", "1", ")", "==", "96", "\n", "\n", "T", "=", "prepare_transform", "(", "\"imagenet100\"", ",", "**", "kwargs", ")", "\n", "assert", "T", "(", "im", ")", ".", "size", "(", "1", ")", "==", "224", "\n", "\n", "num_large_crops", "=", "10", "\n", "assert", "(", "\n", "len", "(", "prepare_n_crop_transform", "(", "[", "T", "]", ",", "num_crops_per_aug", "=", "[", "num_large_crops", "]", ")", "(", "im", ")", ")", "\n", "==", "num_large_crops", "\n", ")", "\n", "\n", "kwargs_small", "=", "dict", "(", "\n", "brightness", "=", "0.5", ",", "\n", "contrast", "=", "0.5", ",", "\n", "saturation", "=", "0.4", ",", "\n", "hue", "=", "0.2", ",", "\n", "gaussian_prob", "=", "0.5", ",", "\n", "solarization_prob", "=", "0.4", ",", "\n", "crop_size", "=", "96", ",", "\n", "min_scale", "=", "0.08", ",", "\n", "max_scale", "=", "1.0", ",", "\n", ")", "\n", "\n", "T", "=", "[", "prepare_transform", "(", "\"imagenet100\"", ",", "**", "kw", ")", "for", "kw", "in", "[", "kwargs", ",", "kwargs_small", "]", "]", "\n", "T", "=", "prepare_n_crop_transform", "(", "T", ",", "num_crops_per_aug", "=", "[", "2", ",", "6", "]", ")", "\n", "crops", "=", "T", "(", "im", ")", "\n", "sizes", "=", "[", "224", "]", "*", "2", "+", "[", "96", "]", "*", "6", "\n", "for", "crop", ",", "size", "in", "zip", "(", "crops", ",", "sizes", ")", ":", "\n", "        ", "assert", "crop", ".", "size", "(", "1", ")", "==", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_pretrain_dataloader.test_data": [[82, 107], ["dict", "solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.pretrain_dataloader.prepare_datasets", "isinstance", "len", "solo.utils.pretrain_dataloader.prepare_dataloader", "isinstance", "solo.utils.pretrain_dataloader.prepare_transform", "len", "len"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.classification_dataloader.prepare_datasets", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_dataloader", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform"], ["", "", "def", "test_data", "(", ")", ":", "\n", "    ", "kwargs", "=", "dict", "(", "\n", "brightness", "=", "0.5", ",", "\n", "contrast", "=", "0.5", ",", "\n", "saturation", "=", "0.4", ",", "\n", "hue", "=", "0.2", ",", "\n", "gaussian_prob", "=", "0.5", ",", "\n", "solarization_prob", "=", "0.4", ",", "\n", ")", "\n", "\n", "T", "=", "[", "prepare_transform", "(", "\"cifar10\"", ",", "**", "kwargs", ")", "]", "\n", "T", "=", "prepare_n_crop_transform", "(", "T", ",", "num_crops_per_aug", "=", "[", "2", "]", ")", "\n", "train_dataset", "=", "prepare_datasets", "(", "\"cifar10\"", ",", "T", ",", "data_dir", "=", "None", ")", "\n", "\n", "assert", "isinstance", "(", "train_dataset", ",", "CIFAR10", ")", "\n", "assert", "len", "(", "train_dataset", "[", "0", "]", ")", "==", "3", "\n", "\n", "bs", "=", "64", "\n", "num_samples_train", "=", "len", "(", "train_dataset", ")", "\n", "num_batches_train", "=", "num_samples_train", "//", "bs", "\n", "\n", "train_loader", "=", "prepare_dataloader", "(", "train_dataset", ",", "batch_size", "=", "bs", ",", "num_workers", "=", "0", ")", "\n", "\n", "assert", "isinstance", "(", "train_loader", ",", "DataLoader", ")", "\n", "assert", "num_batches_train", "==", "len", "(", "train_loader", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.test_kmeans.test_kmeans": [[5, 14], ["solo.utils.kmeans.KMeans", "torch.arange", "torch.randn", "solo.utils.kmeans.KMeans.cluster_memory", "assignments.size", "len", "centroids_list[].size", "assignments.unique"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.cluster_memory"], ["def", "test_kmeans", "(", ")", ":", "\n", "    ", "k", "=", "[", "30", "]", "\n", "kmeans", "=", "KMeans", "(", "1", ",", "0", ",", "1", ",", "500", ",", "128", ",", "k", ")", "\n", "local_memory_index", "=", "torch", ".", "arange", "(", "0", ",", "500", ")", "\n", "local_memory_embeddings", "=", "torch", ".", "randn", "(", "(", "1", ",", "500", ",", "128", ")", ")", "\n", "assignments", ",", "centroids_list", "=", "kmeans", ".", "cluster_memory", "(", "local_memory_index", ",", "local_memory_embeddings", ")", "\n", "assert", "assignments", ".", "size", "(", ")", "==", "(", "1", ",", "500", ")", "\n", "assert", "len", "(", "assignments", ".", "unique", "(", ")", ")", "==", "30", "\n", "assert", "centroids_list", "[", "0", "]", ".", "size", "(", ")", "==", "(", "30", ",", "128", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simclr.simclr_loss_func": [[25, 60], ["torch.normalize", "solo.utils.misc.gather", "torch.exp", "torch.exp", "solo.utils.misc.gather", "indexes.unsqueeze.unsqueeze", "gathered_indexes.unsqueeze.unsqueeze", "pos_mask[].fill_diagonal_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "indexes.unsqueeze.t", "indexes.unsqueeze.t", "torch.mean", "torch.mean", "torch.einsum", "torch.einsum", "torch.log", "torch.log", "F.normalize.size", "solo.utils.misc.get_rank"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank"], ["def", "simclr_loss_func", "(", "\n", "z", ":", "torch", ".", "Tensor", ",", "indexes", ":", "torch", ".", "Tensor", ",", "temperature", ":", "float", "=", "0.1", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes SimCLR's loss given batch of projected features z\n    from different views, a positive boolean mask of all positives and\n    a negative boolean mask of all negatives.\n\n    Args:\n        z (torch.Tensor): (N*views) x D Tensor containing projected features from the views.\n        indexes (torch.Tensor): unique identifiers for each crop (unsupervised)\n            or targets of each crop (supervised).\n\n    Return:\n        torch.Tensor: SimCLR loss.\n    \"\"\"", "\n", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "gathered_z", "=", "gather", "(", "z", ")", "\n", "\n", "sim", "=", "torch", ".", "exp", "(", "torch", ".", "einsum", "(", "\"if, jf -> ij\"", ",", "z", ",", "gathered_z", ")", "/", "temperature", ")", "\n", "\n", "gathered_indexes", "=", "gather", "(", "indexes", ")", "\n", "\n", "indexes", "=", "indexes", ".", "unsqueeze", "(", "0", ")", "\n", "gathered_indexes", "=", "gathered_indexes", ".", "unsqueeze", "(", "0", ")", "\n", "# positives", "\n", "pos_mask", "=", "indexes", ".", "t", "(", ")", "==", "gathered_indexes", "\n", "pos_mask", "[", ":", ",", "z", ".", "size", "(", "0", ")", "*", "get_rank", "(", ")", ":", "]", ".", "fill_diagonal_", "(", "0", ")", "\n", "# negatives", "\n", "neg_mask", "=", "indexes", ".", "t", "(", ")", "!=", "gathered_indexes", "\n", "\n", "pos", "=", "torch", ".", "sum", "(", "sim", "*", "pos_mask", ",", "1", ")", "\n", "neg", "=", "torch", ".", "sum", "(", "sim", "*", "neg_mask", ",", "1", ")", "\n", "loss", "=", "-", "(", "torch", ".", "mean", "(", "torch", ".", "log", "(", "pos", "/", "(", "pos", "+", "neg", ")", ")", ")", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func": [[24, 44], ["torch.normalize", "torch.normalize", "torch.cosine_similarity().mean", "torch.cosine_similarity", "F.normalize.detach", "F.normalize.detach"], "function", ["None"], ["def", "simsiam_loss_func", "(", "p", ":", "torch", ".", "Tensor", ",", "z", ":", "torch", ".", "Tensor", ",", "simplified", ":", "bool", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes SimSiam's loss given batch of predicted features p from view 1 and\n    a batch of projected features z from view 2.\n\n    Args:\n        p (torch.Tensor): Tensor containing predicted features from view 1.\n        z (torch.Tensor): Tensor containing projected features from view 2.\n        simplified (bool): faster computation, but with same result.\n\n    Returns:\n        torch.Tensor: SimSiam loss.\n    \"\"\"", "\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "-", "F", ".", "cosine_similarity", "(", "p", ",", "z", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "-", "(", "p", "*", "z", ".", "detach", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov2plus.mocov2plus_loss_func": [[24, 47], ["torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum", "torch.einsum", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.cross_entropy", "query.size", "torch.einsum", "torch.einsum"], "function", ["None"], ["def", "mocov2plus_loss_func", "(", "\n", "query", ":", "torch", ".", "Tensor", ",", "key", ":", "torch", ".", "Tensor", ",", "queue", ":", "torch", ".", "Tensor", ",", "temperature", "=", "0.1", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes MoCo's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n    queue of past elements.\n\n    Args:\n        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n        key (torch.Tensor): NxD Tensor containing the keys from view 2.\n        queue (torch.Tensor): a queue of negative samples for the contrastive loss.\n        temperature (float, optional): temperature of the softmax in the contrastive\n            loss. Defaults to 0.1.\n\n    Returns:\n        torch.Tensor: MoCo loss.\n    \"\"\"", "\n", "\n", "pos", "=", "torch", ".", "einsum", "(", "\"nc,nc->n\"", ",", "[", "query", ",", "key", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "neg", "=", "torch", ".", "einsum", "(", "\"nc,ck->nk\"", ",", "[", "query", ",", "queue", "]", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "pos", ",", "neg", "]", ",", "dim", "=", "1", ")", "\n", "logits", "/=", "temperature", "\n", "targets", "=", "torch", ".", "zeros", "(", "query", ".", "size", "(", "0", ")", ",", "device", "=", "query", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.dino.DINOLoss.__init__": [[28, 66], ["torch.Module.__init__", "dino.DINOLoss.register_buffer", "numpy.concatenate", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.linspace", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "num_prototypes", ":", "int", ",", "\n", "warmup_teacher_temp", ":", "float", ",", "\n", "teacher_temp", ":", "float", ",", "\n", "warmup_teacher_temp_epochs", ":", "float", ",", "\n", "num_epochs", ":", "int", ",", "\n", "student_temp", ":", "float", "=", "0.1", ",", "\n", "num_large_crops", ":", "int", "=", "2", ",", "\n", "center_momentum", ":", "float", "=", "0.9", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Auxiliary module to compute DINO's loss.\n\n        Args:\n            num_prototypes (int): number of prototypes.\n            warmup_teacher_temp (float): base temperature for the temperature schedule\n                of the teacher.\n            teacher_temp (float): final temperature for the teacher.\n            warmup_teacher_temp_epochs (float): number of epochs for the cosine annealing schedule.\n            num_epochs (int): total number of epochs.\n            student_temp (float, optional): temperature for the student. Defaults to 0.1.\n            num_large_crops (int, optional): number of crops/views. Defaults to 2.\n            center_momentum (float, optional): momentum for the EMA update of the center of\n                mass of the teacher. Defaults to 0.9.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "student_temp", "=", "student_temp", "\n", "self", ".", "center_momentum", "=", "center_momentum", "\n", "self", ".", "num_large_crops", "=", "num_large_crops", "\n", "self", ".", "register_buffer", "(", "\"center\"", ",", "torch", ".", "zeros", "(", "1", ",", "num_prototypes", ")", ")", "\n", "# we apply a warm up for the teacher temperature because", "\n", "# a too high temperature makes the training unstable at the beginning", "\n", "self", ".", "teacher_temp_schedule", "=", "np", ".", "concatenate", "(", "\n", "(", "\n", "np", ".", "linspace", "(", "warmup_teacher_temp", ",", "teacher_temp", ",", "warmup_teacher_temp_epochs", ")", ",", "\n", "np", ".", "ones", "(", "num_epochs", "-", "warmup_teacher_temp_epochs", ")", "*", "teacher_temp", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.dino.DINOLoss.forward": [[69, 102], ["student_out.chunk.chunk.chunk", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "teacher_out.detach().chunk.detach().chunk.detach().chunk", "enumerate", "dino.DINOLoss.update_center", "enumerate", "teacher_out.detach().chunk.detach().chunk.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.dino.DINOLoss.update_center"], ["", "def", "forward", "(", "self", ",", "student_output", ":", "torch", ".", "Tensor", ",", "teacher_output", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes DINO's loss given a batch of logits of the student and a batch of logits of the\n        teacher.\n\n        Args:\n            student_output (torch.Tensor): NxP Tensor containing student logits for all views.\n            teacher_output (torch.Tensor): NxP Tensor containing teacher logits for all views.\n\n        Returns:\n            torch.Tensor: DINO loss.\n        \"\"\"", "\n", "\n", "student_out", "=", "student_output", "/", "self", ".", "student_temp", "\n", "student_out", "=", "student_out", ".", "chunk", "(", "self", ".", "num_large_crops", ")", "\n", "\n", "# teacher centering and sharpening", "\n", "temp", "=", "self", ".", "teacher_temp_schedule", "[", "self", ".", "epoch", "]", "\n", "teacher_out", "=", "F", ".", "softmax", "(", "(", "teacher_output", "-", "self", ".", "center", ")", "/", "temp", ",", "dim", "=", "-", "1", ")", "\n", "teacher_out", "=", "teacher_out", ".", "detach", "(", ")", ".", "chunk", "(", "2", ")", "\n", "\n", "total_loss", "=", "0", "\n", "n_loss_terms", "=", "0", "\n", "for", "iq", ",", "q", "in", "enumerate", "(", "teacher_out", ")", ":", "\n", "            ", "for", "iv", ",", "v", "in", "enumerate", "(", "student_out", ")", ":", "\n", "                ", "if", "iv", "==", "iq", ":", "\n", "# we skip cases where student and teacher operate on the same view", "\n", "                    ", "continue", "\n", "", "loss", "=", "torch", ".", "sum", "(", "-", "q", "*", "F", ".", "log_softmax", "(", "v", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "total_loss", "+=", "loss", ".", "mean", "(", ")", "\n", "n_loss_terms", "+=", "1", "\n", "", "", "total_loss", "/=", "n_loss_terms", "\n", "self", ".", "update_center", "(", "teacher_output", ")", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.dino.DINOLoss.update_center": [[103, 119], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "len", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_center", "(", "self", ",", "teacher_output", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Updates the center for DINO's loss using exponential moving average.\n\n        Args:\n            teacher_output (torch.Tensor): NxP Tensor containing teacher logits of all views.\n        \"\"\"", "\n", "\n", "batch_center", "=", "torch", ".", "sum", "(", "teacher_output", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "batch_center", ")", "\n", "batch_center", "=", "batch_center", "/", "dist", ".", "get_world_size", "(", ")", "\n", "", "batch_center", "=", "batch_center", "/", "len", "(", "teacher_output", ")", "\n", "\n", "# ema update", "\n", "self", ".", "center", "=", "self", ".", "center", "*", "self", ".", "center_momentum", "+", "batch_center", "*", "(", "1", "-", "self", ".", "center_momentum", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vibcreg.covariance_loss": [[26, 48], ["torch.normalize", "torch.normalize", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm.fill_diagonal_", "torch.mm.fill_diagonal_", "z1.mean", "z2.mean"], "function", ["None"], ["def", "covariance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes normalized covariance loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n\n    Returns:\n        torch.Tensor: covariance regularization loss.\n    \"\"\"", "\n", "\n", "norm_z1", "=", "z1", "-", "z1", ".", "mean", "(", "dim", "=", "0", ")", "\n", "norm_z2", "=", "z2", "-", "z2", ".", "mean", "(", "dim", "=", "0", ")", "\n", "norm_z1", "=", "F", ".", "normalize", "(", "norm_z1", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "# (batch * feature); l2-norm", "\n", "norm_z2", "=", "F", ".", "normalize", "(", "norm_z2", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "\n", "fxf_cov_z1", "=", "torch", ".", "mm", "(", "norm_z1", ".", "T", ",", "norm_z1", ")", "# (feature * feature)", "\n", "fxf_cov_z2", "=", "torch", ".", "mm", "(", "norm_z2", ".", "T", ",", "norm_z2", ")", "\n", "fxf_cov_z1", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "fxf_cov_z2", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "cov_loss", "=", "(", "fxf_cov_z1", "**", "2", ")", ".", "mean", "(", ")", "+", "(", "fxf_cov_z2", "**", "2", ")", ".", "mean", "(", ")", "\n", "return", "cov_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vibcreg.vibcreg_loss_func": [[50, 81], ["solo.losses.vicreg.invariance_loss", "solo.losses.vicreg.variance_loss", "vibcreg.covariance_loss", "solo.utils.misc.gather", "solo.utils.misc.gather"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.invariance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.variance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.covariance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "def", "vibcreg_loss_func", "(", "\n", "z1", ":", "torch", ".", "Tensor", ",", "\n", "z2", ":", "torch", ".", "Tensor", ",", "\n", "sim_loss_weight", ":", "float", "=", "25.0", ",", "\n", "var_loss_weight", ":", "float", "=", "25.0", ",", "\n", "cov_loss_weight", ":", "float", "=", "200.0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes VIbCReg's loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n        sim_loss_weight (float): invariance loss weight.\n        var_loss_weight (float): variance loss weight.\n        cov_loss_weight (float): covariance loss weight.\n\n    Returns:\n        torch.Tensor: VIbCReg loss.\n    \"\"\"", "\n", "\n", "sim_loss", "=", "invariance_loss", "(", "z1", ",", "z2", ")", "\n", "# vicreg's official coded gathers the tensors here, so it's likely to benefit vibcreg", "\n", "# https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py", "\n", "z1", ",", "z2", "=", "gather", "(", "z1", ")", ",", "gather", "(", "z2", ")", "\n", "\n", "var_loss", "=", "variance_loss", "(", "z1", ",", "z2", ")", "\n", "cov_loss", "=", "covariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "loss", "=", "sim_loss_weight", "*", "sim_loss", "+", "var_loss_weight", "*", "var_loss", "+", "cov_loss_weight", "*", "cov_loss", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.concat_all_gather_no_grad": [[25, 41], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.is_available", "torch.is_initialized", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like", "torch.ones_like", "torch.ones_like", "range", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "concat_all_gather_no_grad", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: torch.distributed.all_gather has no gradient.\n    \"\"\"", "\n", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "tensors_gather", "=", "[", "\n", "torch", ".", "ones_like", "(", "tensor", ")", "for", "_", "in", "range", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", ")", "\n", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "tensors_gather", ",", "tensor", ",", "async_op", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "tensors_gather", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.mocov3_loss_func": [[43, 71], ["F.normalize.size", "torch.normalize", "torch.normalize", "mocov3.concat_all_gather_no_grad", "torch.get_rank", "torch.einsum", "torch.einsum", "torch.einsum", "torch.arange", "torch.arange", "torch.arange", "torch.cross_entropy", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.concat_all_gather_no_grad", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank"], ["", "def", "mocov3_loss_func", "(", "query", ":", "torch", ".", "Tensor", ",", "key", ":", "torch", ".", "Tensor", ",", "temperature", "=", "0.2", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes MoCo V3's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n    queue of past elements.\n\n    Args:\n        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n        key (torch.Tensor): NxD Tensor containing the keys from view 2.\n        temperature (float, optional): temperature of the softmax in the contrastive\n            loss. Defaults to 0.2.\n\n    Returns:\n        torch.Tensor: MoCo loss.\n    \"\"\"", "\n", "\n", "n", "=", "query", ".", "size", "(", "0", ")", "\n", "device", "=", "query", ".", "device", "\n", "rank", "=", "dist", ".", "get_rank", "(", ")", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", "else", "0", "\n", "\n", "query", "=", "F", ".", "normalize", "(", "query", ",", "dim", "=", "1", ")", "\n", "key", "=", "F", ".", "normalize", "(", "key", ",", "dim", "=", "1", ")", "\n", "\n", "# gather all targets without gradients", "\n", "key", "=", "concat_all_gather_no_grad", "(", "key", ")", "\n", "\n", "logits", "=", "torch", ".", "einsum", "(", "\"nc,mc->nm\"", ",", "[", "query", ",", "key", "]", ")", "/", "temperature", "\n", "labels", "=", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "+", "n", "*", "rank", "\n", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "labels", ")", "*", "(", "2", "*", "temperature", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.nnclr.nnclr_loss_func": [[25, 52], ["torch.normalize", "torch.normalize", "solo.utils.misc.gather", "solo.utils.misc.get_rank", "F.normalize.size", "torch.arange", "torch.arange", "torch.cross_entropy"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.get_rank"], ["def", "nnclr_loss_func", "(", "nn", ":", "torch", ".", "Tensor", ",", "p", ":", "torch", ".", "Tensor", ",", "temperature", ":", "float", "=", "0.1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes NNCLR's loss given batch of nearest-neighbors nn from view 1 and\n    predicted features p from view 2.\n\n    Args:\n        nn (torch.Tensor): NxD Tensor containing nearest neighbors' features from view 1.\n        p (torch.Tensor): NxD Tensor containing predicted features from view 2\n        temperature (float, optional): temperature of the softmax in the contrastive loss. Defaults\n            to 0.1.\n\n    Returns:\n        torch.Tensor: NNCLR loss.\n    \"\"\"", "\n", "\n", "nn", "=", "F", ".", "normalize", "(", "nn", ",", "dim", "=", "-", "1", ")", "\n", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "# to be consistent with simclr, we now gather p", "\n", "# this might result in suboptimal results given previous parameters.", "\n", "p", "=", "gather", "(", "p", ")", "\n", "\n", "logits", "=", "nn", "@", "p", ".", "T", "/", "temperature", "\n", "\n", "rank", "=", "get_rank", "(", ")", "\n", "n", "=", "nn", ".", "size", "(", "0", ")", "\n", "labels", "=", "torch", ".", "arange", "(", "n", "*", "rank", ",", "n", "*", "(", "rank", "+", "1", ")", ",", "device", "=", "p", ".", "device", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.barlow.barlow_loss_func": [[25, 61], ["bn.size", "torch.nn.BatchNorm1d().to", "torch.nn.BatchNorm1d().to", "torch.nn.BatchNorm1d().to.", "torch.nn.BatchNorm1d().to.", "torch.eye", "torch.eye", "torch.einsum", "torch.einsum", "torch.is_available", "torch.is_initialized", "torch.all_reduce", "torch.get_world_size", "cdif.sum", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.eye.bool"], "function", ["None"], ["def", "barlow_loss_func", "(", "\n", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ",", "lamb", ":", "float", "=", "5e-3", ",", "scale_loss", ":", "float", "=", "0.025", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes Barlow Twins' loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n        lamb (float, optional): off-diagonal scaling factor for the cross-covariance matrix.\n            Defaults to 5e-3.\n        scale_loss (float, optional): final scaling factor of the loss. Defaults to 0.025.\n\n    Returns:\n        torch.Tensor: Barlow Twins' loss.\n    \"\"\"", "\n", "\n", "N", ",", "D", "=", "z1", ".", "size", "(", ")", "\n", "\n", "# to match the original code", "\n", "bn", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "D", ",", "affine", "=", "False", ")", ".", "to", "(", "z1", ".", "device", ")", "\n", "z1", "=", "bn", "(", "z1", ")", "\n", "z2", "=", "bn", "(", "z2", ")", "\n", "\n", "corr", "=", "torch", ".", "einsum", "(", "\"bi, bj -> ij\"", ",", "z1", ",", "z2", ")", "/", "N", "\n", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "dist", ".", "all_reduce", "(", "corr", ")", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "corr", "/=", "world_size", "\n", "\n", "", "diag", "=", "torch", ".", "eye", "(", "D", ",", "device", "=", "corr", ".", "device", ")", "\n", "cdif", "=", "(", "corr", "-", "diag", ")", ".", "pow", "(", "2", ")", "\n", "cdif", "[", "~", "diag", ".", "bool", "(", ")", "]", "*=", "lamb", "\n", "loss", "=", "scale_loss", "*", "cdif", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.invariance_loss": [[25, 38], ["torch.mse_loss"], "function", ["None"], ["def", "invariance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes mse loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n\n    Returns:\n        torch.Tensor: invariance loss (mean squared error).\n    \"\"\"", "\n", "\n", "return", "F", ".", "mse_loss", "(", "z1", ",", "z2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.variance_loss": [[40, 57], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "z1.var", "z2.var", "torch.relu", "torch.relu"], "function", ["None"], ["", "def", "variance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes variance loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n\n    Returns:\n        torch.Tensor: variance regularization loss.\n    \"\"\"", "\n", "\n", "eps", "=", "1e-4", "\n", "std_z1", "=", "torch", ".", "sqrt", "(", "z1", ".", "var", "(", "dim", "=", "0", ")", "+", "eps", ")", "\n", "std_z2", "=", "torch", ".", "sqrt", "(", "z2", ".", "var", "(", "dim", "=", "0", ")", "+", "eps", ")", "\n", "std_loss", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_z1", ")", ")", "+", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_z2", ")", ")", "\n", "return", "std_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.covariance_loss": [[59, 81], ["z1.size", "torch.eye", "torch.eye", "z1.mean", "z2.mean", "cov_z1[].pow_().sum", "cov_z2[].pow_().sum", "cov_z1[].pow_", "cov_z2[].pow_", "torch.eye.bool", "torch.eye.bool"], "function", ["None"], ["", "def", "covariance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes covariance loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n\n    Returns:\n        torch.Tensor: covariance regularization loss.\n    \"\"\"", "\n", "\n", "N", ",", "D", "=", "z1", ".", "size", "(", ")", "\n", "\n", "z1", "=", "z1", "-", "z1", ".", "mean", "(", "dim", "=", "0", ")", "\n", "z2", "=", "z2", "-", "z2", ".", "mean", "(", "dim", "=", "0", ")", "\n", "cov_z1", "=", "(", "z1", ".", "T", "@", "z1", ")", "/", "(", "N", "-", "1", ")", "\n", "cov_z2", "=", "(", "z2", ".", "T", "@", "z2", ")", "/", "(", "N", "-", "1", ")", "\n", "\n", "diag", "=", "torch", ".", "eye", "(", "D", ",", "device", "=", "z1", ".", "device", ")", "\n", "cov_loss", "=", "cov_z1", "[", "~", "diag", ".", "bool", "(", ")", "]", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "/", "D", "+", "cov_z2", "[", "~", "diag", ".", "bool", "(", ")", "]", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "/", "D", "\n", "return", "cov_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.vicreg_loss_func": [[83, 115], ["vicreg.invariance_loss", "vicreg.variance_loss", "vicreg.covariance_loss", "solo.utils.misc.gather", "solo.utils.misc.gather"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.invariance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.variance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.covariance_loss", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "def", "vicreg_loss_func", "(", "\n", "z1", ":", "torch", ".", "Tensor", ",", "\n", "z2", ":", "torch", ".", "Tensor", ",", "\n", "sim_loss_weight", ":", "float", "=", "25.0", ",", "\n", "var_loss_weight", ":", "float", "=", "25.0", ",", "\n", "cov_loss_weight", ":", "float", "=", "1.0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes VICReg's loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n        sim_loss_weight (float): invariance loss weight.\n        var_loss_weight (float): variance loss weight.\n        cov_loss_weight (float): covariance loss weight.\n\n    Returns:\n        torch.Tensor: VICReg loss.\n    \"\"\"", "\n", "\n", "sim_loss", "=", "invariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "# vicreg's official code gathers the tensors here", "\n", "# https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py", "\n", "z1", ",", "z2", "=", "gather", "(", "z1", ")", ",", "gather", "(", "z2", ")", "\n", "\n", "var_loss", "=", "variance_loss", "(", "z1", ",", "z2", ")", "\n", "cov_loss", "=", "covariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "loss", "=", "sim_loss_weight", "*", "sim_loss", "+", "var_loss_weight", "*", "var_loss", "+", "cov_loss_weight", "*", "cov_loss", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func": [[24, 43], ["torch.normalize", "torch.normalize", "torch.cosine_similarity().mean", "torch.cosine_similarity", "F.normalize.detach"], "function", ["None"], ["def", "wmse_loss_func", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ",", "simplified", ":", "bool", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes W-MSE's loss given two batches of whitened features z1 and z2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing whitened features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing whitened features from view 2.\n        simplified (bool): faster computation, but with same result.\n\n    Returns:\n        torch.Tensor: W-MSE loss.\n    \"\"\"", "\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "2", "-", "2", "*", "F", ".", "cosine_similarity", "(", "z1", ",", "z2", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "z1", "=", "F", ".", "normalize", "(", "z1", ",", "dim", "=", "-", "1", ")", "\n", "z2", "=", "F", ".", "normalize", "(", "z2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "2", "-", "2", "*", "(", "z1", "*", "z2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.swav.swav_loss_func": [[26, 49], ["enumerate", "numpy.delete", "sum", "len", "numpy.arange", "losses.append", "len", "torch.mean", "torch.sum", "torch.log_softmax"], "function", ["None"], ["def", "swav_loss_func", "(", "\n", "preds", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "assignments", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "temperature", ":", "float", "=", "0.1", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes SwAV's loss given list of batch predictions from multiple views\n    and a list of cluster assignments from the same multiple views.\n\n    Args:\n        preds (torch.Tensor): list of NxC Tensors containing nearest neighbors' features from\n            view 1.\n        assignments (torch.Tensor): list of NxC Tensor containing predicted features from view 2.\n        temperature (torch.Tensor): softmax temperature for the loss. Defaults to 0.1.\n\n    Returns:\n        torch.Tensor: SwAV loss.\n    \"\"\"", "\n", "\n", "losses", "=", "[", "]", "\n", "for", "v1", ",", "a", "in", "enumerate", "(", "assignments", ")", ":", "\n", "        ", "for", "v2", "in", "np", ".", "delete", "(", "np", ".", "arange", "(", "len", "(", "preds", ")", ")", ",", "v1", ")", ":", "\n", "            ", "p", "=", "preds", "[", "v2", "]", "/", "temperature", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "a", "*", "torch", ".", "log_softmax", "(", "p", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ")", "\n", "losses", ".", "append", "(", "loss", ")", "\n", "", "", "return", "sum", "(", "losses", ")", "/", "len", "(", "losses", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func": [[24, 43], ["torch.normalize", "torch.normalize", "torch.cosine_similarity().mean", "torch.cosine_similarity", "F.normalize.detach", "F.normalize.detach"], "function", ["None"], ["def", "byol_loss_func", "(", "p", ":", "torch", ".", "Tensor", ",", "z", ":", "torch", ".", "Tensor", ",", "simplified", ":", "bool", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes BYOL's loss given batch of predicted features p and projected momentum features z.\n\n    Args:\n        p (torch.Tensor): NxD Tensor containing predicted features from view 1\n        z (torch.Tensor): NxD Tensor containing projected momentum features from view 2\n        simplified (bool): faster computation, but with same result. Defaults to True.\n\n    Returns:\n        torch.Tensor: BYOL's loss.\n    \"\"\"", "\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "2", "-", "2", "*", "F", ".", "cosine_similarity", "(", "p", ",", "z", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "2", "-", "2", "*", "(", "p", "*", "z", ".", "detach", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.ressl.ressl_loss_func": [[24, 57], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.softmax", "torch.log_softmax", "torch.einsum.detach"], "function", ["None"], ["def", "ressl_loss_func", "(", "\n", "q", ":", "torch", ".", "Tensor", ",", "\n", "k", ":", "torch", ".", "Tensor", ",", "\n", "queue", ":", "torch", ".", "Tensor", ",", "\n", "temperature_q", ":", "float", "=", "0.1", ",", "\n", "temperature_k", ":", "float", "=", "0.04", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes ReSSL's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n    queue of past elements.\n\n    Args:\n        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n        key (torch.Tensor): NxD Tensor containing the queries from view 2.\n        queue (torch.Tensor): a queue of negative samples for the contrastive loss.\n        temperature_q (float, optional): [description]. temperature of the softmax for the query.\n            Defaults to 0.1.\n        temperature_k (float, optional): [description]. temperature of the softmax for the key.\n            Defaults to 0.04.\n\n    Returns:\n        torch.Tensor: ReSSL loss.\n    \"\"\"", "\n", "\n", "logits_q", "=", "torch", ".", "einsum", "(", "\"nc,kc->nk\"", ",", "[", "q", ",", "queue", "]", ")", "\n", "logits_k", "=", "torch", ".", "einsum", "(", "\"nc,kc->nk\"", ",", "[", "k", ",", "queue", "]", ")", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "\n", "F", ".", "softmax", "(", "logits_k", ".", "detach", "(", ")", "/", "temperature_k", ",", "dim", "=", "1", ")", "\n", "*", "F", ".", "log_softmax", "(", "logits_q", "/", "temperature_q", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "\n", ")", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.deepclusterv2.deepclusterv2_loss_func": [[24, 46], ["range", "outputs.size", "assignments[].repeat().to", "torch.cross_entropy", "outputs.size", "outputs[].view", "outputs.size", "assignments[].repeat", "outputs.size"], "function", ["None"], ["def", "deepclusterv2_loss_func", "(", "\n", "outputs", ":", "torch", ".", "Tensor", ",", "assignments", ":", "torch", ".", "Tensor", ",", "temperature", ":", "float", "=", "0.1", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes DeepClusterV2's loss given a tensor containing logits from multiple views\n    and a tensor containing cluster assignments from the same multiple views.\n\n    Args:\n        outputs (torch.Tensor): tensor of size PxVxNxC where P is the number of prototype\n            layers and V is the number of views.\n        assignments (torch.Tensor): tensor of size PxVxNxC containing the assignments\n            generated using k-means.\n        temperature (float, optional): softmax temperature for the loss. Defaults to 0.1.\n\n    Returns:\n        torch.Tensor: DeepClusterV2 loss.\n    \"\"\"", "\n", "loss", "=", "0", "\n", "for", "h", "in", "range", "(", "outputs", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "scores", "=", "outputs", "[", "h", "]", ".", "view", "(", "-", "1", ",", "outputs", ".", "size", "(", "-", "1", ")", ")", "/", "temperature", "\n", "targets", "=", "assignments", "[", "h", "]", ".", "repeat", "(", "outputs", ".", "size", "(", "1", ")", ")", ".", "to", "(", "outputs", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "scores", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "", "return", "loss", "/", "outputs", ".", "size", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_swav.get_assignments": [[26, 35], ["preds[].size", "solo.utils.sinkhorn_knopp.SinkhornKnopp", "assignments.append", "solo.utils.sinkhorn_knopp.SinkhornKnopp."], "function", ["None"], ["def", "get_assignments", "(", "preds", ")", ":", "\n", "    ", "bs", "=", "preds", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "assignments", "=", "[", "]", "\n", "sk", "=", "SinkhornKnopp", "(", "10", ",", "0.05", ",", "1", ")", "\n", "\n", "for", "p", "in", "preds", ":", "\n", "# compute assignments with sinkhorn-knopp", "\n", "        ", "assignments", ".", "append", "(", "sk", "(", "p", ")", "[", ":", "bs", "]", ")", "\n", "", "return", "assignments", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_swav.test_swav_loss": [[37, 59], ["torch.utils.weight_norm", "torch.zeros().uniform_().requires_grad_", "torch.zeros().uniform_().requires_grad_", "nn.utils.weight_norm.", "test_swav.get_assignments", "solo.losses.swav_loss_func", "solo.losses.swav_loss_func.item", "range", "torch.nn.Linear", "torch.nn.Linear", "nn.utils.weight_norm.", "test_swav.get_assignments", "solo.losses.swav_loss_func", "solo.losses.swav_loss_func.backward", "torch.zeros().uniform_().requires_grad_.data.add_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.get_assignments", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.swav.swav_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.get_assignments", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.swav.swav_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["", "def", "test_swav_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "256", ",", "128", "\n", "prototypes", "=", "nn", ".", "utils", ".", "weight_norm", "(", "torch", ".", "nn", ".", "Linear", "(", "f", ",", "f", ",", "bias", "=", "False", ")", ")", "\n", "\n", "z", "=", "torch", ".", "zeros", "(", "2", ",", "b", ",", "f", ")", ".", "uniform_", "(", "-", "2", ",", "2", ")", ".", "requires_grad_", "(", ")", "\n", "preds", "=", "prototypes", "(", "z", ")", "\n", "assignments", "=", "get_assignments", "(", "preds", ")", "\n", "\n", "loss", "=", "swav_loss_func", "(", "preds", ",", "assignments", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "preds", "=", "prototypes", "(", "z", ")", "\n", "assignments", "=", "get_assignments", "(", "preds", ")", "\n", "loss", "=", "swav_loss_func", "(", "preds", ",", "assignments", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "z", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z", ".", "grad", ")", "\n", "z", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_nnclr.test_nnclr_loss": [[24, 41], ["torch.randn", "torch.randn().requires_grad_", "solo.losses.nnclr_loss_func", "solo.losses.nnclr_loss_func.item", "range", "solo.losses.nnclr_loss_func", "solo.losses.nnclr_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.nnclr.nnclr_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.nnclr.nnclr_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_nnclr_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "nn", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "p", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "loss", "=", "nnclr_loss_func", "(", "nn", ",", "p", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "nnclr_loss_func", "(", "nn", ",", "p", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_wmse.test_simsiam_loss": [[24, 43], ["torch.randn().requires_grad_", "torch.randn", "solo.losses.wmse_loss_func", "solo.losses.wmse_loss_func.item", "range", "solo.losses.wmse_loss_func", "solo.losses.wmse_loss_func.backward", "torch.randn().requires_grad_.data.add_", "abs", "torch.randn", "solo.losses.wmse_loss_func", "solo.losses.wmse_loss_func"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func"], ["def", "test_simsiam_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "p", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "\n", "loss", "=", "wmse_loss_func", "(", "p", ",", "z", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "wmse_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "wmse_loss_func", "(", "p", ",", "z", ")", "-", "wmse_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_mocov3.test_mocov3_loss": [[24, 42], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "solo.losses.mocov3_loss_func", "solo.losses.mocov3_loss_func.item", "range", "solo.losses.mocov3_loss_func", "solo.losses.mocov3_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.mocov3_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.mocov3_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_mocov3_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "query", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "key", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "loss", "=", "mocov3_loss_func", "(", "query", ",", "key", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "mocov3_loss_func", "(", "query", ",", "key", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "key", ".", "data", ".", "add_", "(", "-", "0.5", "*", "key", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "key", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_barlow.test_barlow_loss": [[24, 42], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "solo.losses.barlow_loss_func", "solo.losses.barlow_loss_func.item", "range", "solo.losses.barlow_loss_func", "solo.losses.barlow_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.barlow.barlow_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.barlow.barlow_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_barlow_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "z1", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z2", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "loss", "=", "barlow_loss_func", "(", "z1", ",", "z2", ",", "lamb", "=", "5e-3", ",", "scale_loss", "=", "0.025", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "barlow_loss_func", "(", "z1", ",", "z2", ",", "lamb", "=", "5e-3", ",", "scale_loss", "=", "0.025", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_simsiam.test_simsiam_loss": [[24, 43], ["torch.randn().requires_grad_", "torch.randn", "solo.losses.simsiam_loss_func", "solo.losses.simsiam_loss_func.item", "range", "solo.losses.simsiam_loss_func", "solo.losses.simsiam_loss_func.backward", "torch.randn().requires_grad_.data.add_", "abs", "torch.randn", "solo.losses.simsiam_loss_func", "solo.losses.simsiam_loss_func"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func"], ["def", "test_simsiam_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "p", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "\n", "loss", "=", "simsiam_loss_func", "(", "p", ",", "z", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "simsiam_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "simsiam_loss_func", "(", "p", ",", "z", ")", "-", "simsiam_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_ressl.test_moco_loss": [[24, 42], ["torch.randn().requires_grad_", "torch.randn", "torch.randn", "solo.losses.ressl_loss_func", "solo.losses.ressl_loss_func.item", "range", "solo.losses.ressl_loss_func", "solo.losses.ressl_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.ressl.ressl_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.ressl.ressl_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_moco_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", ",", "q", "=", "32", ",", "128", ",", "15000", "\n", "query", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "key", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "queue", "=", "torch", ".", "randn", "(", "q", ",", "f", ")", "\n", "\n", "loss", "=", "ressl_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature_q", "=", "0.1", ",", "temperature_k", "=", "0.04", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "ressl_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature_q", "=", "0.1", ",", "temperature_k", "=", "0.04", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_simclr.test_simclr_loss": [[24, 46], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "torch.cat", "torch.arange().repeat", "solo.losses.simclr_loss_func", "solo.losses.simclr_loss_func.item", "range", "torch.cat", "solo.losses.simclr_loss_func", "solo.losses.simclr_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn", "torch.arange"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simclr.simclr_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simclr.simclr_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_simclr_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "z1", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z2", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z", "=", "torch", ".", "cat", "(", "(", "z1", ",", "z2", ")", ")", "\n", "indexes", "=", "torch", ".", "arange", "(", "b", ")", ".", "repeat", "(", "2", ")", "\n", "\n", "loss", "=", "simclr_loss_func", "(", "z", ",", "indexes", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "z", "=", "torch", ".", "cat", "(", "(", "z1", ",", "z2", ")", ")", "\n", "loss", "=", "simclr_loss_func", "(", "z", ",", "indexes", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_dino.test_dino_loss": [[24, 52], ["torch.randn().requires_grad_", "torch.randn", "solo.losses.DINOLoss", "solo.losses.DINOLoss.", "dino_loss.item", "range", "solo.losses.DINOLoss.", "dino_loss.backward", "torch.randn().requires_grad_.data.add_", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_dino_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", ",", "num_epochs", "=", "32", ",", "128", ",", "20", "\n", "p", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "p_momentum", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "\n", "dino_loss", "=", "DINOLoss", "(", "\n", "num_prototypes", "=", "f", ",", "\n", "warmup_teacher_temp", "=", "0.4", ",", "\n", "teacher_temp", "=", "0.7", ",", "\n", "warmup_teacher_temp_epochs", "=", "10", ",", "\n", "student_temp", "=", "0.1", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", ")", "\n", "\n", "loss", "=", "dino_loss", "(", "p", ",", "p_momentum", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "i", "in", "range", "(", "20", ")", ":", "\n", "        ", "dino_loss", ".", "epoch", "=", "i", "\n", "\n", "loss", "=", "dino_loss", "(", "p", ",", "p_momentum", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_byol.test_byol_loss": [[24, 43], ["torch.randn().requires_grad_", "torch.randn", "solo.losses.byol_loss_func", "solo.losses.byol_loss_func.item", "range", "solo.losses.byol_loss_func", "solo.losses.byol_loss_func.backward", "torch.randn().requires_grad_.data.add_", "abs", "torch.randn", "solo.losses.byol_loss_func", "solo.losses.byol_loss_func"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func"], ["def", "test_byol_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "p", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", "\n", "\n", "loss", "=", "byol_loss_func", "(", "p", ",", "z", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "byol_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "byol_loss_func", "(", "p", ",", "z", ")", "-", "byol_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_mocov2plus.test_mocov2plus_loss": [[24, 43], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "torch.randn", "solo.losses.mocov2plus_loss_func", "solo.losses.mocov2plus_loss_func.item", "range", "solo.losses.mocov2plus_loss_func", "solo.losses.mocov2plus_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov2plus.mocov2plus_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov2plus.mocov2plus_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_mocov2plus_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", ",", "q", "=", "32", ",", "128", ",", "15000", "\n", "query", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "key", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "queue", "=", "torch", ".", "randn", "(", "f", ",", "q", ")", "\n", "\n", "loss", "=", "mocov2plus_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "mocov2plus_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "key", ".", "data", ".", "add_", "(", "-", "0.5", "*", "key", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "key", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_vibcreg.test_vibcreg_loss_func": [[24, 46], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "solo.losses.vibcreg_loss_func", "solo.losses.vibcreg_loss_func.item", "range", "solo.losses.vibcreg_loss_func", "solo.losses.vibcreg_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vibcreg.vibcreg_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vibcreg.vibcreg_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_vibcreg_loss_func", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "z1", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z2", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "loss", "=", "vibcreg_loss_func", "(", "\n", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "200.0", "\n", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "vibcreg_loss_func", "(", "\n", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "200.0", "\n", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.test_vicreg.test_vicreg_loss": [[24, 44], ["torch.randn().requires_grad_", "torch.randn().requires_grad_", "solo.losses.vicreg_loss_func", "solo.losses.vicreg_loss_func.item", "range", "solo.losses.vicreg_loss_func", "solo.losses.vicreg_loss_func.backward", "torch.randn().requires_grad_.data.add_", "torch.randn().requires_grad_.data.add_", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.vicreg_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.vicreg_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.whitening.iterative_normalization_py.backward"], ["def", "test_vicreg_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "32", ",", "128", "\n", "z1", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "z2", "=", "torch", ".", "randn", "(", "b", ",", "f", ")", ".", "requires_grad_", "(", ")", "\n", "\n", "loss", "=", "vicreg_loss_func", "(", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "1.0", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "vicreg_loss_func", "(", "\n", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "1.0", "\n", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_pretrain": [[49, 105], ["argparse.ArgumentParser", "solo.args.dataset.dataset_args", "solo.args.dataset.augmentations_args", "solo.args.dataset.custom_dataset_args", "pytorch_lightning.Trainer.add_argparse_args", "PretrainDALIDataModule.add_dali_args.add_argument", "PretrainDALIDataModule.add_dali_args.parse_known_args", "METHODS[].add_model_specific_args", "PretrainDALIDataModule.add_dali_args.add_argument", "PretrainDALIDataModule.add_dali_args.add_argument", "PretrainDALIDataModule.add_dali_args.add_argument", "PretrainDALIDataModule.add_dali_args.parse_known_args", "PretrainDALIDataModule.add_dali_args.parse_args", "solo.args.utils.additional_setup_pretrain", "solo.utils.checkpointer.Checkpointer.add_checkpointer_args", "AutoUMAP.add_auto_umap_args", "solo.utils.auto_resumer.AutoResumer.add_autoresumer_args", "PretrainDALIDataModule.add_dali_args"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.augmentations_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.custom_dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.add_checkpointer_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_umap.AutoUMAP.add_auto_umap_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.add_autoresumer_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.add_dali_args"], ["\"einops\"", ",", "\n", "\"pytorch-lightning==1.6.4\"", ",", "\n", "\"torchmetrics==0.6.0\"", ",", "\n", "\"lightning-bolts>=0.5.0\"", ",", "\n", "\"tqdm\"", ",", "\n", "\"wandb\"", ",", "\n", "\"scipy\"", ",", "\n", "\"timm\"", ",", "\n", "\"scikit-learn\"", ",", "\n", "]", ",", "\n", "extras_require", "=", "EXTRA_REQUIREMENTS", ",", "\n", "dependency_links", "=", "[", "\"https://developer.download.nvidia.com/compute/redist\"", "]", ",", "\n", "classifiers", "=", "[", "\n", "\"Programming Language :: Python :: 3.8\"", ",", "\n", "\"License :: OSI Approved :: MIT License\"", ",", "\n", "\"Operating System :: OS Independent\"", ",", "\n", "]", ",", "\n", "include_package_data", "=", "True", ",", "\n", "zip_safe", "=", "False", ",", "\n", ")", "\n", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_linear": [[107, 153], ["argparse.ArgumentParser", "ClassificationDALIDataModule.add_dali_args.add_argument", "solo.args.dataset.dataset_args", "solo.args.dataset.linear_augmentations_args", "solo.args.dataset.custom_dataset_args", "pytorch_lightning.Trainer.add_argparse_args", "METHODS[].add_model_specific_args", "ClassificationDALIDataModule.add_dali_args.add_argument", "ClassificationDALIDataModule.add_dali_args.add_argument", "ClassificationDALIDataModule.add_dali_args.parse_known_args", "ClassificationDALIDataModule.add_dali_args.parse_args", "solo.args.utils.additional_setup_linear", "solo.utils.checkpointer.Checkpointer.add_checkpointer_args", "solo.utils.auto_resumer.AutoResumer.add_autoresumer_args", "ClassificationDALIDataModule.add_dali_args"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.linear_augmentations_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.custom_dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_linear", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.add_checkpointer_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.auto_resumer.AutoResumer.add_autoresumer_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.ClassificationDALIDataModule.add_dali_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_knn": [[155, 181], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "solo.args.dataset.dataset_args", "solo.args.dataset.custom_dataset_args", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.custom_dataset_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.setup.parse_args_umap": [[183, 205], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "solo.args.dataset.dataset_args", "solo.args.dataset.custom_dataset_args", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.custom_dataset_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args": [[24, 52], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "dataset_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"Adds dataset-related arguments to a parser.\n\n    Args:\n        parser (ArgumentParser): parser to add dataset args to.\n    \"\"\"", "\n", "\n", "SUPPORTED_DATASETS", "=", "[", "\n", "\"cifar10\"", ",", "\n", "\"cifar100\"", ",", "\n", "\"stl10\"", ",", "\n", "\"imagenet\"", ",", "\n", "\"imagenet100\"", ",", "\n", "\"custom\"", ",", "\n", "]", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "SUPPORTED_DATASETS", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "\n", "# dataset path", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_dir\"", ",", "type", "=", "Path", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_dir\"", ",", "type", "=", "Path", ",", "default", "=", "None", ")", "\n", "\n", "# percentage of data used from training, leave -1.0 to use all data available", "\n", "parser", ".", "add_argument", "(", "\"--data_fraction\"", ",", "default", "=", "-", "1.0", ",", "type", "=", "float", ")", "\n", "\n", "# dali (imagenet-100/imagenet/custom only)", "\n", "parser", ".", "add_argument", "(", "\"--dali\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.augmentations_args": [[54, 85], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "augmentations_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"Adds augmentation-related arguments to a parser.\n\n    Args:\n        parser (ArgumentParser): parser to add augmentation args to.\n    \"\"\"", "\n", "\n", "# cropping", "\n", "parser", ".", "add_argument", "(", "\"--num_crops_per_aug\"", ",", "type", "=", "int", ",", "default", "=", "[", "2", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# color jitter", "\n", "parser", ".", "add_argument", "(", "\"--brightness\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--contrast\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--saturation\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hue\"", ",", "type", "=", "float", ",", "required", "=", "True", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--color_jitter_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.8", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# other augmentation probabilities", "\n", "parser", ".", "add_argument", "(", "\"--gray_scale_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.2", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--horizontal_flip_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.5", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gaussian_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.5", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--solarization_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.0", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--equalization_prob\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.0", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# cropping", "\n", "parser", ".", "add_argument", "(", "\"--crop_size\"", ",", "type", "=", "int", ",", "default", "=", "[", "224", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_scale\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.08", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_scale\"", ",", "type", "=", "float", ",", "default", "=", "[", "1.0", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n", "# debug", "\n", "parser", ".", "add_argument", "(", "\"--debug_augmentations\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.linear_augmentations_args": [[87, 89], ["parser.add_argument"], "function", ["None"], ["", "def", "linear_augmentations_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--crop_size\"", ",", "type", "=", "int", ",", "default", "=", "[", "224", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.custom_dataset_args": [[91, 104], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "custom_dataset_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "    ", "\"\"\"Adds custom data-related arguments to a parser.\n\n    Args:\n        parser (ArgumentParser): parser to add augmentation args to.\n    \"\"\"", "\n", "\n", "# custom dataset only", "\n", "parser", ".", "add_argument", "(", "\"--no_labels\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# for custom dataset", "\n", "parser", ".", "add_argument", "(", "\"--mean\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--std\"", ",", "type", "=", "float", ",", "default", "=", "[", "0.228", ",", "0.224", ",", "0.225", "]", ",", "nargs", "=", "\"+\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain": [[34, 260], ["max", "isinstance", "max", "len", "getattr", "len", "zip", "dict", "isinstance", "contextlib.suppress", "contextlib.suppress", "contextlib.suppress", "contextlib.suppress", "contextlib.suppress", "isinstance", "warnings.warn", "len", "len", "setattr", "dict", "zip", "int", "len", "getattr", "args.devices.split", "os.scandir"], "function", ["None"], ["def", "additional_setup_pretrain", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"Provides final setup for pretraining to non-user given parameters by changing args.\n\n    Parsers arguments to extract the number of classes of a dataset, create\n    transformations kwargs, correctly parse gpus, identify if a cifar dataset\n    is being used and adjust the lr.\n\n    Args:\n        args (Namespace): object that needs to contain, at least:\n        - dataset: dataset name.\n        - brightness, contrast, saturation, hue, min_scale: required augmentations\n            settings.\n        - dali: flag to use dali.\n        - optimizer: optimizer name being used.\n        - gpus: list of gpus to use.\n        - lr: learning rate.\n\n        [optional]\n        - gaussian_prob, solarization_prob: optional augmentations settings.\n    \"\"\"", "\n", "\n", "if", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", ":", "\n", "        ", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "# hack to maintain the current pipeline", "\n", "# even if the custom dataset doesn't have any labels", "\n", "        ", "dir_path", "=", "args", ".", "data_dir", "/", "args", ".", "train_dir", "\n", "args", ".", "num_classes", "=", "max", "(", "\n", "1", ",", "\n", "len", "(", "[", "entry", ".", "name", "for", "entry", "in", "os", ".", "scandir", "(", "dir_path", ")", "if", "entry", ".", "is_dir", "]", ")", ",", "\n", ")", "\n", "\n", "", "unique_augs", "=", "max", "(", "\n", "len", "(", "p", ")", "\n", "for", "p", "in", "[", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "color_jitter_prob", ",", "\n", "args", ".", "gray_scale_prob", ",", "\n", "args", ".", "horizontal_flip_prob", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "equalization_prob", ",", "\n", "args", ".", "crop_size", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "max_scale", ",", "\n", "]", "\n", ")", "\n", "assert", "len", "(", "args", ".", "num_crops_per_aug", ")", "==", "unique_augs", "\n", "\n", "# assert that either all unique augmentation pipelines have a unique", "\n", "# parameter or that a single parameter is replicated to all pipelines", "\n", "for", "p", "in", "[", "\n", "\"brightness\"", ",", "\n", "\"contrast\"", ",", "\n", "\"saturation\"", ",", "\n", "\"hue\"", ",", "\n", "\"color_jitter_prob\"", ",", "\n", "\"gray_scale_prob\"", ",", "\n", "\"horizontal_flip_prob\"", ",", "\n", "\"gaussian_prob\"", ",", "\n", "\"solarization_prob\"", ",", "\n", "\"equalization_prob\"", ",", "\n", "\"crop_size\"", ",", "\n", "\"min_scale\"", ",", "\n", "\"max_scale\"", ",", "\n", "]", ":", "\n", "        ", "values", "=", "getattr", "(", "args", ",", "p", ")", "\n", "n", "=", "len", "(", "values", ")", "\n", "assert", "n", "==", "unique_augs", "or", "n", "==", "1", "\n", "\n", "if", "n", "==", "1", ":", "\n", "            ", "setattr", "(", "args", ",", "p", ",", "getattr", "(", "args", ",", "p", ")", "*", "unique_augs", ")", "\n", "\n", "", "", "args", ".", "unique_augs", "=", "unique_augs", "\n", "\n", "if", "unique_augs", ">", "1", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "[", "\n", "dict", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "color_jitter_prob", "=", "color_jitter_prob", ",", "\n", "gray_scale_prob", "=", "gray_scale_prob", ",", "\n", "horizontal_flip_prob", "=", "horizontal_flip_prob", ",", "\n", "gaussian_prob", "=", "gaussian_prob", ",", "\n", "solarization_prob", "=", "solarization_prob", ",", "\n", "equalization_prob", "=", "equalization_prob", ",", "\n", "crop_size", "=", "crop_size", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", ")", "\n", "for", "(", "\n", "brightness", ",", "\n", "contrast", ",", "\n", "saturation", ",", "\n", "hue", ",", "\n", "color_jitter_prob", ",", "\n", "gray_scale_prob", ",", "\n", "horizontal_flip_prob", ",", "\n", "gaussian_prob", ",", "\n", "solarization_prob", ",", "\n", "equalization_prob", ",", "\n", "crop_size", ",", "\n", "min_scale", ",", "\n", "max_scale", ",", "\n", ")", "in", "zip", "(", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "color_jitter_prob", ",", "\n", "args", ".", "gray_scale_prob", ",", "\n", "args", ".", "horizontal_flip_prob", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "equalization_prob", ",", "\n", "args", ".", "crop_size", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "max_scale", ",", "\n", ")", "\n", "]", "\n", "\n", "# find number of big/small crops", "\n", "big_size", "=", "args", ".", "crop_size", "[", "0", "]", "\n", "num_large_crops", "=", "num_small_crops", "=", "0", "\n", "for", "size", ",", "n_crops", "in", "zip", "(", "args", ".", "crop_size", ",", "args", ".", "num_crops_per_aug", ")", ":", "\n", "            ", "if", "big_size", "==", "size", ":", "\n", "                ", "num_large_crops", "+=", "n_crops", "\n", "", "else", ":", "\n", "                ", "num_small_crops", "+=", "n_crops", "\n", "", "", "args", ".", "num_large_crops", "=", "num_large_crops", "\n", "args", ".", "num_small_crops", "=", "num_small_crops", "\n", "", "else", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "dict", "(", "\n", "brightness", "=", "args", ".", "brightness", "[", "0", "]", ",", "\n", "contrast", "=", "args", ".", "contrast", "[", "0", "]", ",", "\n", "saturation", "=", "args", ".", "saturation", "[", "0", "]", ",", "\n", "hue", "=", "args", ".", "hue", "[", "0", "]", ",", "\n", "color_jitter_prob", "=", "args", ".", "color_jitter_prob", "[", "0", "]", ",", "\n", "gray_scale_prob", "=", "args", ".", "gray_scale_prob", "[", "0", "]", ",", "\n", "horizontal_flip_prob", "=", "args", ".", "horizontal_flip_prob", "[", "0", "]", ",", "\n", "gaussian_prob", "=", "args", ".", "gaussian_prob", "[", "0", "]", ",", "\n", "solarization_prob", "=", "args", ".", "solarization_prob", "[", "0", "]", ",", "\n", "equalization_prob", "=", "args", ".", "equalization_prob", "[", "0", "]", ",", "\n", "crop_size", "=", "args", ".", "crop_size", "[", "0", "]", ",", "\n", "min_scale", "=", "args", ".", "min_scale", "[", "0", "]", ",", "\n", "max_scale", "=", "args", ".", "max_scale", "[", "0", "]", ",", "\n", ")", "\n", "\n", "# find number of big/small crops", "\n", "args", ".", "num_large_crops", "=", "args", ".", "num_crops_per_aug", "[", "0", "]", "\n", "args", ".", "num_small_crops", "=", "0", "\n", "\n", "# add support for custom mean and std", "\n", "", "if", "args", ".", "dataset", "==", "\"custom\"", ":", "\n", "        ", "if", "isinstance", "(", "args", ".", "transform_kwargs", ",", "dict", ")", ":", "\n", "            ", "args", ".", "transform_kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "args", ".", "transform_kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "", "else", ":", "\n", "            ", "for", "kwargs", "in", "args", ".", "transform_kwargs", ":", "\n", "                ", "kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "\n", "# create backbone-specific arguments", "\n", "", "", "", "args", ".", "backbone_args", "=", "{", "\"cifar\"", ":", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", "}", "\n", "if", "\"resnet\"", "in", "args", ".", "backbone", "and", "\"wide\"", "not", "in", "args", ".", "backbone", ":", "\n", "        ", "args", ".", "backbone_args", "[", "\"zero_init_residual\"", "]", "=", "args", ".", "zero_init_residual", "\n", "", "elif", "\"convnext\"", "not", "in", "args", ".", "backbone", ":", "\n", "# dataset related for all transformers", "\n", "        ", "crop_size", "=", "args", ".", "crop_size", "[", "0", "]", "\n", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "crop_size", "\n", "if", "\"vit\"", "in", "args", ".", "backbone", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"patch_size\"", "]", "=", "args", ".", "patch_size", "\n", "\n", "", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "zero_init_residual", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "patch_size", "\n", "\n", "", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", ",", "\"custom\"", "]", "\n", "\n", "", "args", ".", "extra_optimizer_args", "=", "{", "}", "\n", "if", "args", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "", "if", "args", ".", "optimizer", "==", "\"lars\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "args", ".", "extra_optimizer_args", "[", "\"eta\"", "]", "=", "args", ".", "eta_lars", "\n", "args", ".", "extra_optimizer_args", "[", "\"clip_lars_lr\"", "]", "=", "args", ".", "grad_clip_lars", "\n", "args", ".", "extra_optimizer_args", "[", "\"exclude_bias_n_norm\"", "]", "=", "args", ".", "exclude_bias_n_norm", "\n", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "eta_lars", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "grad_clip_lars", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "exclude_bias_n_norm", "\n", "\n", "", "if", "isinstance", "(", "args", ".", "devices", ",", "int", ")", ":", "\n", "        ", "args", ".", "devices", "=", "[", "args", ".", "devices", "]", "\n", "", "elif", "isinstance", "(", "args", ".", "devices", ",", "str", ")", ":", "\n", "        ", "args", ".", "devices", "=", "[", "int", "(", "device", ")", "for", "device", "in", "args", ".", "devices", ".", "split", "(", "\",\"", ")", "if", "device", "]", "\n", "\n", "# adjust lr according to batch size", "\n", "", "if", "args", ".", "strategy", "==", "\"horovod\"", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"When using horovod, be aware of how the processes are divided. \"", "\n", "\"The learning rate will only be scaled considering the number of \"", "\n", "\"devices in each process. \"", "\n", "\"If each gpu corresponds to each process, you should pass --num_nodes_horovod \"", "\n", "\"N_GPUS to properly scale the lr. \"", "\n", "\"You can also manually scale your lr if you are not sure, by checking your logs.\"", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "num_nodes", "=", "args", ".", "num_nodes_horovod", "or", "args", ".", "num_nodes", "or", "1", "\n", "", "except", "AttributeError", ":", "\n", "        ", "num_nodes", "=", "1", "\n", "\n", "", "scale_factor", "=", "args", ".", "batch_size", "*", "len", "(", "args", ".", "devices", ")", "*", "num_nodes", "/", "256", "\n", "args", ".", "lr", "=", "args", ".", "lr", "*", "scale_factor", "\n", "args", ".", "classifier_lr", "=", "args", ".", "classifier_lr", "*", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_linear": [[262, 335], ["isinstance", "max", "contextlib.suppress", "contextlib.suppress", "isinstance", "warnings.warn", "len", "int", "len", "args.devices.split", "os.scandir"], "function", ["None"], ["", "def", "additional_setup_linear", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"Provides final setup for linear evaluation to non-user given parameters by changing args.\n\n    Parsers arguments to extract the number of classes of a dataset, correctly parse gpus, identify\n    if a cifar dataset is being used and adjust the lr.\n\n    Args:\n        args: Namespace object that needs to contain, at least:\n        - dataset: dataset name.\n        - optimizer: optimizer name being used.\n        - gpus: list of gpus to use.\n        - lr: learning rate.\n    \"\"\"", "\n", "\n", "if", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", ":", "\n", "        ", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "# hack to maintain the current pipeline", "\n", "# even if the custom dataset doesn't have any labels", "\n", "        ", "dir_path", "=", "args", ".", "data_dir", "/", "args", ".", "train_dir", "\n", "args", ".", "num_classes", "=", "max", "(", "\n", "1", ",", "\n", "len", "(", "[", "entry", ".", "name", "for", "entry", "in", "os", ".", "scandir", "(", "dir_path", ")", "if", "entry", ".", "is_dir", "]", ")", ",", "\n", ")", "\n", "\n", "# create backbone-specific arguments", "\n", "", "args", ".", "backbone_args", "=", "{", "\"cifar\"", ":", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", "}", "\n", "if", "\"resnet\"", "not", "in", "args", ".", "backbone", "and", "\"convnext\"", "not", "in", "args", ".", "backbone", ":", "\n", "# dataset related for all transformers", "\n", "        ", "crop_size", "=", "args", ".", "crop_size", "[", "0", "]", "\n", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "crop_size", "\n", "if", "\"vit\"", "in", "args", ".", "backbone", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"patch_size\"", "]", "=", "args", ".", "patch_size", "\n", "\n", "", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "patch_size", "\n", "\n", "", "if", "args", ".", "dali", ":", "\n", "        ", "assert", "args", ".", "dataset", "in", "[", "\"imagenet100\"", ",", "\"imagenet\"", ",", "\"custom\"", "]", "\n", "\n", "", "args", ".", "extra_optimizer_args", "=", "{", "}", "\n", "if", "args", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "", "if", "args", ".", "optimizer", "==", "\"lars\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "args", ".", "extra_optimizer_args", "[", "\"exclude_bias_n_norm\"", "]", "=", "args", ".", "exclude_bias_n_norm", "\n", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "exclude_bias_n_norm", "\n", "\n", "", "if", "isinstance", "(", "args", ".", "devices", ",", "int", ")", ":", "\n", "        ", "args", ".", "devices", "=", "[", "args", ".", "devices", "]", "\n", "", "elif", "isinstance", "(", "args", ".", "devices", ",", "str", ")", ":", "\n", "        ", "args", ".", "devices", "=", "[", "int", "(", "device", ")", "for", "device", "in", "args", ".", "devices", ".", "split", "(", "\",\"", ")", "if", "device", "]", "\n", "\n", "# adjust lr according to batch size", "\n", "", "if", "args", ".", "strategy", "==", "\"horovod\"", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"When using horovod, be aware of how the processes are divided. \"", "\n", "\"The learning rate will only be scaled considering the number of \"", "\n", "\"devices in each process. \"", "\n", "\"If each gpu corresponds to each process, you should pass --num_nodes_horovod \"", "\n", "\"N_GPUS to properly scale the lr. \"", "\n", "\"You can also manually scale your lr if you are not sure, by checking your logs.\"", "\n", ")", "\n", "\n", "", "try", ":", "\n", "        ", "num_nodes", "=", "args", ".", "num_nodes_horovod", "or", "args", ".", "num_nodes", "or", "1", "\n", "", "except", "AttributeError", ":", "\n", "        ", "num_nodes", "=", "1", "\n", "\n", "", "scale_factor", "=", "args", ".", "batch_size", "*", "len", "(", "args", ".", "devices", ")", "*", "num_nodes", "/", "256", "\n", "args", ".", "lr", "=", "args", ".", "lr", "*", "scale_factor", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_datasets.test_argparse_dataset": [[24, 34], ["argparse.ArgumentParser", "solo.args.dataset.dataset_args", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.dataset_args"], ["def", "test_argparse_dataset", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "dataset_args", "(", "parser", ")", "\n", "actions", "=", "[", "vars", "(", "action", ")", "[", "\"dest\"", "]", "for", "action", "in", "vars", "(", "parser", ")", "[", "\"_actions\"", "]", "]", "\n", "\n", "assert", "\"dataset\"", "in", "actions", "\n", "assert", "\"data_dir\"", "in", "actions", "\n", "assert", "\"train_dir\"", "in", "actions", "\n", "assert", "\"val_dir\"", "in", "actions", "\n", "assert", "\"dali\"", "in", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_datasets.test_argparse_augmentations": [[36, 53], ["argparse.ArgumentParser", "solo.args.dataset.augmentations_args", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.dataset.augmentations_args"], ["", "def", "test_argparse_augmentations", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "augmentations_args", "(", "parser", ")", "\n", "actions", "=", "[", "vars", "(", "action", ")", "[", "\"dest\"", "]", "for", "action", "in", "vars", "(", "parser", ")", "[", "\"_actions\"", "]", "]", "\n", "\n", "assert", "\"num_crops_per_aug\"", "in", "actions", "\n", "\n", "assert", "\"brightness\"", "in", "actions", "\n", "assert", "\"contrast\"", "in", "actions", "\n", "assert", "\"saturation\"", "in", "actions", "\n", "assert", "\"hue\"", "in", "actions", "\n", "assert", "\"color_jitter_prob\"", "in", "actions", "\n", "assert", "\"gray_scale_prob\"", "in", "actions", "\n", "assert", "\"horizontal_flip_prob\"", "in", "actions", "\n", "assert", "\"gaussian_prob\"", "in", "actions", "\n", "assert", "\"solarization_prob\"", "in", "actions", "\n", "assert", "\"min_scale\"", "in", "actions", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_setup.test_setup_pretrain": [[30, 123], ["textwrap.dedent", "open", "f.write", "subprocess.check_output", "os.remove", "print"], "function", ["None"], ["def", "test_setup_pretrain", "(", ")", ":", "\n", "    ", "dummy_script", "=", "\"\"\"\n        from solo.args.setup import parse_args_pretrain\n\n        args = parse_args_pretrain()\n    \"\"\"", "\n", "dummy_script", "=", "textwrap", ".", "dedent", "(", "dummy_script", ")", "\n", "\n", "dummy_args", "=", "[", "\n", "\"--dataset\"", ",", "\n", "\"cifar10\"", ",", "\n", "\"--backbone\"", ",", "\n", "\"resnet18\"", ",", "\n", "\"--data_dir\"", ",", "\n", "\"./datasets\"", ",", "\n", "\"--max_epochs\"", ",", "\n", "\"1000\"", ",", "\n", "\"--devices\"", ",", "\n", "\"0\"", ",", "\n", "\"--precision\"", ",", "\n", "\"16\"", ",", "\n", "\"--optimizer\"", ",", "\n", "\"lars\"", ",", "\n", "\"--exclude_bias_n_norm\"", ",", "\n", "\"--scheduler\"", ",", "\n", "\"warmup_cosine\"", ",", "\n", "\"--lr\"", ",", "\n", "\"1.0\"", ",", "\n", "\"--classifier_lr\"", ",", "\n", "\"0.1\"", ",", "\n", "\"--weight_decay\"", ",", "\n", "\"1e-5\"", ",", "\n", "\"--batch_size\"", ",", "\n", "\"256\"", ",", "\n", "\"--num_workers\"", ",", "\n", "\"5\"", ",", "\n", "\"--brightness\"", ",", "\n", "\"0.4\"", ",", "\n", "\"--contrast\"", ",", "\n", "\"0.4\"", ",", "\n", "\"--saturation\"", ",", "\n", "\"0.2\"", ",", "\n", "\"--hue\"", ",", "\n", "\"0.1\"", ",", "\n", "\"--gaussian_prob\"", ",", "\n", "\"0.0\"", ",", "\n", "\"--solarization_prob\"", ",", "\n", "\"0.2\"", ",", "\n", "\"--equalization_prob\"", ",", "\n", "\"0.2\"", ",", "\n", "\"--name\"", ",", "\n", "\"test\"", ",", "\n", "\"--project\"", ",", "\n", "\"solo-learn\"", ",", "\n", "\"--entity\"", ",", "\n", "\"unitn-mhug\"", ",", "\n", "\"--wandb\"", ",", "\n", "\"--save_checkpoint\"", ",", "\n", "\"--method\"", ",", "\n", "\"byol\"", ",", "\n", "\"--proj_output_dim\"", ",", "\n", "\"256\"", ",", "\n", "\"--proj_hidden_dim\"", ",", "\n", "\"4096\"", ",", "\n", "\"--pred_hidden_dim\"", ",", "\n", "\"4096\"", ",", "\n", "\"--base_tau_momentum\"", ",", "\n", "\"0.99\"", ",", "\n", "\"--final_tau_momentum\"", ",", "\n", "\"1.0\"", ",", "\n", "\"--momentum_classifier\"", ",", "\n", "\"--wandb\"", ",", "\n", "\"--save_checkpoint\"", ",", "\n", "\"--auto_umap\"", ",", "\n", "]", "\n", "# Write string to a file", "\n", "with", "open", "(", "\"dummy_script.py\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "dummy_script", ")", "\n", "\n", "# Run the python file as a separate process", "\n", "", "try", ":", "\n", "        ", "script", "=", "[", "\"python3\"", ",", "\"dummy_script.py\"", "]", "+", "dummy_args", "\n", "subprocess", ".", "check_output", "(", "script", ")", "\n", "worked", "=", "True", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "\n", "        ", "print", "(", "\"error code\"", ",", "e", ".", "returncode", ",", "e", ".", "output", ")", "\n", "worked", "=", "False", "\n", "", "assert", "worked", "\n", "\n", "try", ":", "\n", "        ", "os", ".", "remove", "(", "\"dummy_script.py\"", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_setup.test_setup_linear": [[125, 197], ["textwrap.dedent", "open", "f.write", "subprocess.check_output", "os.remove", "print"], "function", ["None"], ["", "", "def", "test_setup_linear", "(", ")", ":", "\n", "    ", "dummy_script", "=", "\"\"\"\n        from solo.args.setup import parse_args_linear\n\n        args = parse_args_linear()\n    \"\"\"", "\n", "dummy_script", "=", "textwrap", ".", "dedent", "(", "dummy_script", ")", "\n", "\n", "dummy_args", "=", "[", "\n", "\"--dataset\"", ",", "\n", "\"imagenet100\"", ",", "\n", "\"--backbone\"", ",", "\n", "\"resnet18\"", ",", "\n", "\"--data_dir\"", ",", "\n", "\"/datasets\"", ",", "\n", "\"--train_dir\"", ",", "\n", "\"imagenet-100/train\"", ",", "\n", "\"--val_dir\"", ",", "\n", "\"imagenet-100/val\"", ",", "\n", "\"--max_epochs\"", ",", "\n", "\"100\"", ",", "\n", "\"--devices\"", ",", "\n", "\"0\"", ",", "\n", "\"--accelerator\"", ",", "\n", "\"gpu\"", ",", "\n", "\"--strategy\"", ",", "\n", "\"ddp\"", ",", "\n", "\"--sync_batchnorm\"", ",", "\n", "\"--precision\"", ",", "\n", "\"16\"", ",", "\n", "\"--optimizer\"", ",", "\n", "\"sgd\"", ",", "\n", "\"--scheduler\"", ",", "\n", "\"step\"", ",", "\n", "\"--lr\"", ",", "\n", "\"3.0\"", ",", "\n", "\"--lr_decay_steps\"", ",", "\n", "\"60\"", ",", "\n", "\"--weight_decay\"", ",", "\n", "\"0\"", ",", "\n", "\"--batch_size\"", ",", "\n", "\"128\"", ",", "\n", "\"--num_workers\"", ",", "\n", "\"10\"", ",", "\n", "\"--dali\"", ",", "\n", "\"--name\"", ",", "\n", "\"test\"", ",", "\n", "\"--pretrained_feature_extractor\"", ",", "\n", "\"PATH\"", ",", "\n", "\"--project\"", ",", "\n", "\"solo-learn\"", ",", "\n", "\"--wandb\"", ",", "\n", "\"--save_checkpoint\"", ",", "\n", "]", "\n", "# Write string to a file", "\n", "with", "open", "(", "\"dummy_script.py\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "dummy_script", ")", "\n", "\n", "# Run the python file as a separate process", "\n", "", "try", ":", "\n", "        ", "script", "=", "[", "\"python3\"", ",", "\"dummy_script.py\"", "]", "+", "dummy_args", "\n", "subprocess", ".", "check_output", "(", "script", ")", "\n", "worked", "=", "True", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "\n", "        ", "print", "(", "\"error code\"", ",", "e", ".", "returncode", ",", "e", ".", "output", ")", "\n", "worked", "=", "False", "\n", "", "assert", "worked", "\n", "\n", "try", ":", "\n", "        ", "os", ".", "remove", "(", "\"dummy_script.py\"", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_setup.test_additional_setup_pretrain": [[199, 395], ["argparse.Namespace", "solo.args.utils.additional_setup_pretrain", "isinstance", "argparse.Namespace", "solo.args.utils.additional_setup_pretrain", "isinstance", "argparse.Namespace", "solo.args.utils.additional_setup_pretrain", "isinstance", "argparse.Namespace", "solo.args.utils.additional_setup_pretrain", "isinstance", "tests.dali.utils.DummyDataset", "argparse.Namespace", "solo.args.utils.additional_setup_pretrain", "isinstance", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_pretrain"], ["", "", "def", "test_additional_setup_pretrain", "(", ")", ":", "\n", "    ", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"multicrop\"", ":", "False", ",", "\n", "\"brightness\"", ":", "[", "0.4", "]", ",", "\n", "\"contrast\"", ":", "[", "0.4", "]", ",", "\n", "\"saturation\"", ":", "[", "0.2", "]", ",", "\n", "\"hue\"", ":", "[", "0.1", "]", ",", "\n", "\"color_jitter_prob\"", ":", "[", "0.8", "]", ",", "\n", "\"gray_scale_prob\"", ":", "[", "0.2", "]", ",", "\n", "\"horizontal_flip_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"gaussian_prob\"", ":", "[", "1.0", ",", "0.1", "]", ",", "\n", "\"solarization_prob\"", ":", "[", "0.2", ",", "0.1", "]", ",", "\n", "\"equalization_prob\"", ":", "[", "0.2", ",", "0.1", "]", ",", "\n", "\"min_scale\"", ":", "[", "0.08", "]", ",", "\n", "\"max_scale\"", ":", "[", "1.0", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", "]", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "1", ",", "1", "]", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,1\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"classifier_lr\"", ":", "0.2", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "assert", "\"transform_kwargs\"", "in", "args", "\n", "\n", "# symmetric and no multicrop", "\n", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"brightness\"", ":", "[", "0.4", "]", ",", "\n", "\"contrast\"", ":", "[", "0.4", "]", ",", "\n", "\"saturation\"", ":", "[", "0.2", "]", ",", "\n", "\"hue\"", ":", "[", "0.1", "]", ",", "\n", "\"color_jitter_prob\"", ":", "[", "0.8", "]", ",", "\n", "\"gray_scale_prob\"", ":", "[", "0.2", "]", ",", "\n", "\"horizontal_flip_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"gaussian_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"solarization_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"equalization_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"min_scale\"", ":", "[", "0.08", "]", ",", "\n", "\"max_scale\"", ":", "[", "1.0", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", "]", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "2", "]", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,1\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"classifier_lr\"", ":", "0.2", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "assert", "\"transform_kwargs\"", "in", "args", "\n", "\n", "# multicrop", "\n", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"brightness\"", ":", "[", "0.4", "]", ",", "\n", "\"contrast\"", ":", "[", "0.4", "]", ",", "\n", "\"saturation\"", ":", "[", "0.2", "]", ",", "\n", "\"hue\"", ":", "[", "0.1", "]", ",", "\n", "\"color_jitter_prob\"", ":", "[", "0.8", "]", ",", "\n", "\"gray_scale_prob\"", ":", "[", "0.2", "]", ",", "\n", "\"horizontal_flip_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"gaussian_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"solarization_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"equalization_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"min_scale\"", ":", "[", "0.08", "]", ",", "\n", "\"max_scale\"", ":", "[", "1.0", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", ",", "96", "]", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "2", ",", "4", "]", ",", "\n", "\"dali\"", ":", "False", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,1\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"classifier_lr\"", ":", "0.2", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "assert", "\"transform_kwargs\"", "in", "args", "\n", "\n", "# check for different gpu syntax", "\n", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"brightness\"", ":", "[", "0.4", "]", ",", "\n", "\"contrast\"", ":", "[", "0.4", "]", ",", "\n", "\"saturation\"", ":", "[", "0.2", "]", ",", "\n", "\"hue\"", ":", "[", "0.1", "]", ",", "\n", "\"color_jitter_prob\"", ":", "[", "0.8", "]", ",", "\n", "\"gray_scale_prob\"", ":", "[", "0.2", "]", ",", "\n", "\"horizontal_flip_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"gaussian_prob\"", ":", "[", "0.5", ",", "0.2", "]", ",", "\n", "\"solarization_prob\"", ":", "[", "0.5", ",", "0.3", "]", ",", "\n", "\"equalization_prob\"", ":", "[", "0.5", ",", "0.3", "]", ",", "\n", "\"min_scale\"", ":", "[", "0.08", "]", ",", "\n", "\"max_scale\"", ":", "[", "1.0", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", "]", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "1", ",", "1", "]", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"classifier_lr\"", ":", "0.2", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "assert", "\"transform_kwargs\"", "in", "args", "\n", "\n", "# check for different backbone / custom dataset", "\n", "with", "DummyDataset", "(", "\"dummy_train\"", ",", "\"dummy_val\"", ",", "10", ",", "4", ")", ":", "\n", "        ", "args", "=", "{", "\n", "\"backbone\"", ":", "\"vit_small\"", ",", "\n", "\"dataset\"", ":", "\"custom\"", ",", "\n", "\"data_dir\"", ":", "Path", "(", "\".\"", ")", ",", "\n", "\"train_dir\"", ":", "\"dummy_train\"", ",", "\n", "\"val_dir\"", ":", "\"dummy_val\"", ",", "\n", "\"mean\"", ":", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "\"std\"", ":", "[", "0.228", ",", "0.224", ",", "0.225", "]", ",", "\n", "\"brightness\"", ":", "[", "0.4", "]", ",", "\n", "\"contrast\"", ":", "[", "0.4", "]", ",", "\n", "\"saturation\"", ":", "[", "0.2", "]", ",", "\n", "\"hue\"", ":", "[", "0.1", "]", ",", "\n", "\"color_jitter_prob\"", ":", "[", "0.8", "]", ",", "\n", "\"gray_scale_prob\"", ":", "[", "0.2", "]", ",", "\n", "\"horizontal_flip_prob\"", ":", "[", "0.5", "]", ",", "\n", "\"gaussian_prob\"", ":", "[", "0.5", ",", "0.2", "]", ",", "\n", "\"solarization_prob\"", ":", "[", "0.5", ",", "0.3", "]", ",", "\n", "\"equalization_prob\"", ":", "[", "0.5", ",", "0.3", "]", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "1", ",", "1", "]", ",", "\n", "\"min_scale\"", ":", "[", "0.08", "]", ",", "\n", "\"max_scale\"", ":", "[", "1.0", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", "]", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"classifier_lr\"", ":", "0.2", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"patch_size\"", ":", "16", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_pretrain", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "assert", "\"transform_kwargs\"", "in", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.test_setup.test_additional_setup_linear": [[397, 471], ["argparse.Namespace", "solo.args.utils.additional_setup_linear", "isinstance", "argparse.Namespace", "solo.args.utils.additional_setup_linear", "isinstance", "tests.dali.utils.DummyDataset", "argparse.Namespace", "solo.args.utils.additional_setup_linear", "isinstance", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_linear", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_linear", "home.repos.pwc.inspect_result.vturrisi_solo-learn.args.utils.additional_setup_linear"], ["", "", "def", "test_additional_setup_linear", "(", ")", ":", "\n", "    ", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,1\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_linear", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "\n", "# check for different gpu syntax", "\n", "args", "=", "{", "\n", "\"backbone\"", ":", "\"resnet18\"", ",", "\n", "\"dataset\"", ":", "\"imagenet100\"", ",", "\n", "\"dali\"", ":", "True", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_linear", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "\n", "# check for different backbone / custom dataset", "\n", "with", "DummyDataset", "(", "\"dummy_train\"", ",", "\"dummy_val\"", ",", "10", ",", "4", ")", ":", "\n", "        ", "args", "=", "{", "\n", "\"backbone\"", ":", "\"vit_small\"", ",", "\n", "\"dataset\"", ":", "\"custom\"", ",", "\n", "\"data_dir\"", ":", "Path", "(", "\".\"", ")", ",", "\n", "\"train_dir\"", ":", "\"dummy_train\"", ",", "\n", "\"val_dir\"", ":", "\"dummy_val\"", ",", "\n", "\"mean\"", ":", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "\"std\"", ":", "[", "0.228", ",", "0.224", ",", "0.225", "]", ",", "\n", "\"crop_size\"", ":", "[", "224", "]", ",", "\n", "\"dali\"", ":", "False", ",", "\n", "\"num_crops_per_aug\"", ":", "[", "2", "]", ",", "\n", "\"optimizer\"", ":", "\"sgd\"", ",", "\n", "\"devices\"", ":", "\"0,\"", ",", "\n", "\"lr\"", ":", "0.1", ",", "\n", "\"batch_size\"", ":", "128", ",", "\n", "\"zero_init_residual\"", ":", "False", ",", "\n", "\"patch_size\"", ":", "16", ",", "\n", "\"strategy\"", ":", "None", ",", "\n", "\"num_nodes\"", ":", "1", ",", "\n", "\"num_nodes_horovod\"", ":", "None", ",", "\n", "}", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n", "additional_setup_linear", "(", "args", ")", "\n", "\n", "assert", "args", ".", "backbone_args", "[", "\"cifar\"", "]", "is", "False", "\n", "assert", "\"momentum\"", "in", "args", ".", "extra_optimizer_args", "\n", "assert", "isinstance", "(", "args", ".", "devices", ",", "list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.__init__": [[108, 274], ["pytorch_lightning.LightningModule.__init__", "base.BaseMethod.backbone_args.copy", "base.BaseMethod.pop", "base.BaseMethod.base_model", "base.BaseMethod.backbone_name.startswith", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "solo.utils.knn.WeightedKNNClassifier", "warnings.warn", "base.BaseMethod.to", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "backbone", ":", "str", ",", "\n", "num_classes", ":", "int", ",", "\n", "backbone_args", ":", "dict", ",", "\n", "max_epochs", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "\n", "optimizer", ":", "str", ",", "\n", "lr", ":", "float", ",", "\n", "weight_decay", ":", "float", ",", "\n", "classifier_lr", ":", "float", ",", "\n", "accumulate_grad_batches", ":", "Union", "[", "int", ",", "None", "]", ",", "\n", "extra_optimizer_args", ":", "Dict", ",", "\n", "scheduler", ":", "str", ",", "\n", "num_large_crops", ":", "int", ",", "\n", "num_small_crops", ":", "int", ",", "\n", "min_lr", ":", "float", "=", "0.0", ",", "\n", "warmup_start_lr", ":", "float", "=", "0.00003", ",", "\n", "warmup_epochs", ":", "float", "=", "10", ",", "\n", "scheduler_interval", ":", "str", "=", "\"step\"", ",", "\n", "lr_decay_steps", ":", "Sequence", "=", "None", ",", "\n", "knn_eval", ":", "bool", "=", "False", ",", "\n", "knn_k", ":", "int", "=", "20", ",", "\n", "no_channel_last", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Base model that implements all basic operations for all self-supervised methods.\n        It adds shared arguments, extract basic learnable parameters, creates optimizers\n        and schedulers, implements basic training_step for any number of crops,\n        trains the online classifier and implements validation_step.\n\n        Args:\n            backbone (str): architecture of the base backbone.\n            num_classes (int): number of classes.\n            backbone_params (dict): dict containing extra backbone args, namely:\n                #! optional, if it's not present, it is considered as False\n                cifar (bool): flag indicating if cifar is being used.\n                #! only for resnet\n                zero_init_residual (bool): change the initialization of the resnet backbone.\n                #! only for vit\n                patch_size (int): size of the patches for ViT.\n            max_epochs (int): number of training epochs.\n            batch_size (int): number of samples in the batch.\n            optimizer (str): name of the optimizer.\n            lr (float): learning rate.\n            weight_decay (float): weight decay for optimizer.\n            classifier_lr (float): learning rate for the online linear classifier.\n            accumulate_grad_batches (Union[int, None]): number of batches for gradient accumulation.\n            extra_optimizer_args (Dict): extra named arguments for the optimizer.\n            scheduler (str): name of the scheduler.\n            num_large_crops (int): number of big crops.\n            num_small_crops (int): number of small crops .\n            min_lr (float): minimum learning rate for warmup scheduler. Defaults to 0.0.\n            warmup_start_lr (float): initial learning rate for warmup scheduler.\n                Defaults to 0.00003.\n            warmup_epochs (float): number of warmup epochs. Defaults to 10.\n            scheduler_interval (str): interval to update the lr scheduler. Defaults to 'step'.\n            lr_decay_steps (Sequence, optional): steps to decay the learning rate if scheduler is\n                step. Defaults to None.\n            knn_eval (bool): enables online knn evaluation while training.\n            knn_k (int): the number of neighbors to use for knn.\n            no_channel_last (bool). Disables channel last conversion operation which\n                speeds up training considerably. Defaults to False.\n                https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html#converting-existing-models\n\n        .. note::\n            When using distributed data parallel, the batch size and the number of workers are\n            specified on a per process basis. Therefore, the total batch size (number of workers)\n            is calculated as the product of the number of GPUs with the batch size (number of\n            workers).\n\n        .. note::\n            The learning rate (base, min and warmup) is automatically scaled linearly based on the\n            batch size and gradient accumulation.\n\n        .. note::\n            For CIFAR10/100, the first convolutional and maxpooling layers of the ResNet backbone\n            are slightly adjusted to handle lower resolution images (32x32 instead of 224x224).\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# resnet backbone related", "\n", "self", ".", "backbone_args", "=", "backbone_args", "\n", "\n", "# training related", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "max_epochs", "=", "max_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "self", ".", "classifier_lr", "=", "classifier_lr", "\n", "self", ".", "accumulate_grad_batches", "=", "accumulate_grad_batches", "\n", "self", ".", "extra_optimizer_args", "=", "extra_optimizer_args", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "lr_decay_steps", "=", "lr_decay_steps", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "self", ".", "warmup_start_lr", "=", "warmup_start_lr", "\n", "self", ".", "warmup_epochs", "=", "warmup_epochs", "\n", "assert", "scheduler_interval", "in", "[", "\"step\"", ",", "\"epoch\"", "]", "\n", "self", ".", "scheduler_interval", "=", "scheduler_interval", "\n", "self", ".", "num_large_crops", "=", "num_large_crops", "\n", "self", ".", "num_small_crops", "=", "num_small_crops", "\n", "self", ".", "knn_eval", "=", "knn_eval", "\n", "self", ".", "knn_k", "=", "knn_k", "\n", "self", ".", "no_channel_last", "=", "no_channel_last", "\n", "\n", "self", ".", "_num_training_steps", "=", "None", "\n", "\n", "# multicrop", "\n", "self", ".", "num_crops", "=", "self", ".", "num_large_crops", "+", "self", ".", "num_small_crops", "\n", "\n", "# all the other parameters", "\n", "self", ".", "extra_args", "=", "kwargs", "\n", "\n", "# turn on multicrop if there are small crops", "\n", "self", ".", "multicrop", "=", "self", ".", "num_small_crops", "!=", "0", "\n", "\n", "# if accumulating gradient then scale lr", "\n", "if", "self", ".", "accumulate_grad_batches", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "classifier_lr", "=", "self", ".", "classifier_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "min_lr", "=", "self", ".", "min_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "self", ".", "warmup_start_lr", "=", "self", ".", "warmup_start_lr", "*", "self", ".", "accumulate_grad_batches", "\n", "\n", "", "assert", "backbone", "in", "BaseMethod", ".", "_BACKBONES", "\n", "self", ".", "base_model", "=", "self", ".", "_BACKBONES", "[", "backbone", "]", "\n", "\n", "self", ".", "backbone_name", "=", "backbone", "\n", "\n", "# initialize backbone", "\n", "kwargs", "=", "self", ".", "backbone_args", ".", "copy", "(", ")", "\n", "cifar", "=", "kwargs", ".", "pop", "(", "\"cifar\"", ",", "False", ")", "\n", "# swin specific", "\n", "if", "\"swin\"", "in", "self", ".", "backbone_name", "and", "cifar", ":", "\n", "            ", "kwargs", "[", "\"window_size\"", "]", "=", "4", "\n", "\n", "", "self", ".", "backbone", "=", "self", ".", "base_model", "(", "**", "kwargs", ")", "\n", "if", "self", ".", "backbone_name", ".", "startswith", "(", "\"resnet\"", ")", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "backbone", ".", "inplanes", "\n", "# remove fc layer", "\n", "self", ".", "backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "cifar", ":", "\n", "                ", "self", ".", "backbone", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "backbone", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "backbone", ".", "num_features", "\n", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "num_classes", ")", "\n", "\n", "if", "self", ".", "knn_eval", ":", "\n", "            ", "self", ".", "knn", "=", "WeightedKNNClassifier", "(", "k", "=", "self", ".", "knn_k", ",", "distance_fx", "=", "\"euclidean\"", ")", "\n", "\n", "", "if", "scheduler_interval", "==", "\"step\"", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\"Using scheduler_interval={scheduler_interval} might generate \"", "\n", "\"issues when resuming a checkpoint.\"", "\n", ")", "\n", "\n", "# can provide up to ~20% speed up", "\n", "", "if", "not", "no_channel_last", ":", "\n", "            ", "self", "=", "self", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.add_model_specific_args": [[275, 346], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "BaseMethod._OPTIMIZERS.keys"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "\"\"\"Adds shared basic arguments that are shared for all methods.\n\n        Args:\n            parent_parser (ArgumentParser): argument parser that is used to create a\n                argument group.\n\n        Returns:\n            ArgumentParser: same as the argument, used to avoid errors.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"base\"", ")", "\n", "\n", "# backbone args", "\n", "BACKBONES", "=", "BaseMethod", ".", "_BACKBONES", "\n", "\n", "parser", ".", "add_argument", "(", "\"--backbone\"", ",", "choices", "=", "BACKBONES", ",", "type", "=", "str", ")", "\n", "# extra args for resnet", "\n", "parser", ".", "add_argument", "(", "\"--zero_init_residual\"", ",", "action", "=", "\"store_true\"", ")", "\n", "# extra args for ViT", "\n", "parser", ".", "add_argument", "(", "\"--patch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "# general train", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier_lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "\n", "# wandb", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--project\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--entity\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--wandb\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--offline\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--optimizer\"", ",", "choices", "=", "BaseMethod", ".", "_OPTIMIZERS", ".", "keys", "(", ")", ",", "type", "=", "str", ",", "required", "=", "True", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--grad_clip_lars\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eta_lars\"", ",", "default", "=", "1e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--exclude_bias_n_norm\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--scheduler\"", ",", "choices", "=", "BaseMethod", ".", "_SCHEDULERS", ",", "type", "=", "str", ",", "default", "=", "\"reduce\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_decay_steps\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_lr\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_start_lr\"", ",", "default", "=", "0.00003", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--scheduler_interval\"", ",", "choices", "=", "[", "\"step\"", ",", "\"epoch\"", "]", ",", "default", "=", "\"step\"", ",", "type", "=", "str", "\n", ")", "\n", "\n", "# online knn eval", "\n", "parser", ".", "add_argument", "(", "\"--knn_eval\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--knn_k\"", ",", "default", "=", "20", ",", "type", "=", "int", ")", "\n", "\n", "# disables channel last optimization", "\n", "parser", ".", "add_argument", "(", "\"--no_channel_last\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# When using horovod, be aware of how the processes are divided.", "\n", "# The learning rate will only be scaled considering the number of", "\n", "# devices in each process.", "\n", "# If each gpu corresponds to each process, you should pass --num_nodes_horovod", "\n", "# N_GPUS to properly scale the lr.", "\n", "# You can also manually scale your lr if you are not sure, by checking your logs.", "\n", "parser", ".", "add_argument", "(", "\"--num_nodes_horovod\"", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.num_training_steps": [[347, 386], ["base.BaseMethod.extra_args.get", "base.BaseMethod.extra_args.get", "base.BaseMethod.extra_args.get", "solo.utils.misc.compute_dataset_size", "base.BaseMethod.extra_args.get", "base.BaseMethod.extra_args.get", "base.BaseMethod.extra_args.get", "os.path.join", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.compute_dataset_size"], ["", "@", "property", "\n", "def", "num_training_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Compute the number of training steps for each epoch.\"\"\"", "\n", "\n", "if", "self", ".", "_num_training_steps", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "dataset", "=", "self", ".", "extra_args", ".", "get", "(", "\"dataset\"", ",", "None", ")", "\n", "if", "dataset", "not", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"stl10\"", "]", ":", "\n", "                    ", "data_dir", "=", "self", ".", "extra_args", ".", "get", "(", "\"data_dir\"", ",", "\".\"", ")", "\n", "train_dir", "=", "self", ".", "extra_args", ".", "get", "(", "\"train_dir\"", ",", "\"train\"", ")", "\n", "folder", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "train_dir", ")", "\n", "", "else", ":", "\n", "                    ", "folder", "=", "None", "\n", "", "no_labels", "=", "self", ".", "extra_args", ".", "get", "(", "\"no_labels\"", ",", "False", ")", "\n", "data_fraction", "=", "self", ".", "extra_args", ".", "get", "(", "\"data_fraction\"", ",", "-", "1.0", ")", "\n", "\n", "dataset_size", "=", "compute_dataset_size", "(", "\n", "dataset", "=", "dataset", ",", "\n", "folder", "=", "folder", ",", "\n", "train", "=", "True", ",", "\n", "no_labels", "=", "no_labels", ",", "\n", "data_fraction", "=", "data_fraction", ",", "\n", ")", "\n", "", "except", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Please pass 'dataset' or 'data_dir '\"", "\n", "\"and 'train_dir' as parameters to the model.\"", "\n", ")", "\n", "\n", "", "dataset_size", "=", "self", ".", "trainer", ".", "limit_train_batches", "*", "dataset_size", "\n", "\n", "num_devices", "=", "self", ".", "trainer", ".", "num_devices", "\n", "num_nodes", "=", "self", ".", "extra_args", ".", "get", "(", "\"num_nodes_horovod\"", ",", "0", ")", "or", "self", ".", "trainer", ".", "num_nodes", "or", "1", "\n", "effective_batch_size", "=", "(", "\n", "self", ".", "batch_size", "*", "self", ".", "trainer", ".", "accumulate_grad_batches", "*", "num_devices", "*", "num_nodes", "\n", ")", "\n", "self", ".", "_num_training_steps", "=", "dataset_size", "//", "effective_batch_size", "\n", "\n", "", "return", "self", ".", "_num_training_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.learnable_params": [[387, 403], ["base.BaseMethod.backbone.parameters", "base.BaseMethod.classifier.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Defines learnable parameters for the base class.\n\n        Returns:\n            List[Dict[str, Any]]:\n                list of dicts containing learnable parameters and possible settings.\n        \"\"\"", "\n", "\n", "return", "[", "\n", "{", "\"name\"", ":", "\"backbone\"", ",", "\"params\"", ":", "self", ".", "backbone", ".", "parameters", "(", ")", "}", ",", "\n", "{", "\n", "\"name\"", ":", "\"classifier\"", ",", "\n", "\"params\"", ":", "self", ".", "classifier", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "classifier_lr", ",", "\n", "\"weight_decay\"", ":", "0", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.configure_optimizers": [[406, 464], ["optimizer.", "functools.partial", "isinstance", "enumerate", "m.pop", "pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "ValueError", "isinstance", "len"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", ",", "List", "]", ":", "\n", "        ", "\"\"\"Collects learnable parameters and configures the optimizer and learning rate scheduler.\n\n        Returns:\n            Tuple[List, List]: two lists containing the optimizer and the scheduler.\n        \"\"\"", "\n", "\n", "# collect learnable parameters", "\n", "idxs_no_scheduler", "=", "[", "\n", "i", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "learnable_params", ")", "if", "m", ".", "pop", "(", "\"static_lr\"", ",", "False", ")", "\n", "]", "\n", "\n", "assert", "self", ".", "optimizer", "in", "self", ".", "_OPTIMIZERS", "\n", "optimizer", "=", "self", ".", "_OPTIMIZERS", "[", "self", ".", "optimizer", "]", "\n", "\n", "# create optimizer", "\n", "optimizer", "=", "optimizer", "(", "\n", "self", ".", "learnable_params", ",", "\n", "lr", "=", "self", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", "**", "self", ".", "extra_optimizer_args", ",", "\n", ")", "\n", "\n", "if", "self", ".", "scheduler", "==", "\"none\"", ":", "\n", "            ", "return", "optimizer", "\n", "\n", "", "if", "self", ".", "scheduler", "==", "\"warmup_cosine\"", ":", "\n", "            ", "scheduler", "=", "{", "\n", "\"scheduler\"", ":", "LinearWarmupCosineAnnealingLR", "(", "\n", "optimizer", ",", "\n", "warmup_epochs", "=", "self", ".", "warmup_epochs", "*", "self", ".", "num_training_steps", ",", "\n", "max_epochs", "=", "self", ".", "max_epochs", "*", "self", ".", "num_training_steps", ",", "\n", "warmup_start_lr", "=", "self", ".", "warmup_start_lr", "if", "self", ".", "warmup_epochs", ">", "0", "else", "self", ".", "lr", ",", "\n", "eta_min", "=", "self", ".", "min_lr", ",", "\n", ")", ",", "\n", "\"interval\"", ":", "self", ".", "scheduler_interval", ",", "\n", "\"frequency\"", ":", "1", ",", "\n", "}", "\n", "", "elif", "self", ".", "scheduler", "==", "\"step\"", ":", "\n", "            ", "scheduler", "=", "MultiStepLR", "(", "optimizer", ",", "self", ".", "lr_decay_steps", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.scheduler} not in (warmup_cosine, cosine, step)\"", ")", "\n", "\n", "", "if", "idxs_no_scheduler", ":", "\n", "            ", "partial_fn", "=", "partial", "(", "\n", "static_lr", ",", "\n", "get_lr", "=", "scheduler", "[", "\"scheduler\"", "]", ".", "get_lr", "\n", "if", "isinstance", "(", "scheduler", ",", "dict", ")", "\n", "else", "scheduler", ".", "get_lr", ",", "\n", "param_group_indexes", "=", "idxs_no_scheduler", ",", "\n", "lrs_to_replace", "=", "[", "self", ".", "lr", "]", "*", "len", "(", "idxs_no_scheduler", ")", ",", "\n", ")", "\n", "if", "isinstance", "(", "scheduler", ",", "dict", ")", ":", "\n", "                ", "scheduler", "[", "\"scheduler\"", "]", ".", "get_lr", "=", "partial_fn", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "get_lr", "=", "partial_fn", "\n", "\n", "", "", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.optimizer_zero_grad": [[465, 478], ["optimizer.zero_grad", "optimizer.zero_grad"], "methods", ["None"], ["", "def", "optimizer_zero_grad", "(", "self", ",", "epoch", ",", "batch_idx", ",", "optimizer", ",", "optimizer_idx", ")", ":", "\n", "        ", "\"\"\"\n        This improves performance marginally. It should be fine\n        since we are not affected by any of the downsides descrited in\n        https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad\n\n        Implemented as in here\n        https://pytorch-lightning.readthedocs.io/en/1.5.10/guides/speed.html#set-grads-to-none\n        \"\"\"", "\n", "try", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", "set_to_none", "=", "True", ")", "\n", "", "except", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.forward": [[479, 495], ["base.BaseMethod.backbone", "base.BaseMethod.classifier", "X.to.to.to", "base.BaseMethod.detach"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "X", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Basic forward method. Children methods should call this function,\n        modify the ouputs (without deleting anything) and return it.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict: dict of logits and features.\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "no_channel_last", ":", "\n", "            ", "X", "=", "X", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "", "feats", "=", "self", ".", "backbone", "(", "X", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "feats", ".", "detach", "(", ")", ")", "\n", "return", "{", "\"logits\"", ":", "logits", ",", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.multicrop_forward": [[496, 513], ["base.BaseMethod.backbone", "X.to.to.to"], "methods", ["None"], ["", "def", "multicrop_forward", "(", "self", ",", "X", ":", "torch", ".", "tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Basic multicrop forward method that performs the forward pass\n        for the multicrop views. Children classes can override this method to\n        add new outputs but should still call this function. Make sure\n        that this method and its overrides always return a dict.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict: dict of features.\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "no_channel_last", ":", "\n", "            ", "X", "=", "X", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "", "feats", "=", "self", ".", "backbone", "(", "X", ")", "\n", "return", "{", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod._base_shared_step": [[514, 536], ["base.BaseMethod.", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "min", "solo.utils.metrics.accuracy_at_k", "base.BaseMethod.update", "logits.size"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.accuracy_at_k", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "_base_shared_step", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Forwards a batch of images X and computes the classification loss, the logits, the\n        features, acc@1 and acc@5.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n            targets (torch.Tensor): batch of labels for X.\n\n        Returns:\n            Dict: dict containing the classification loss, logits, features, acc@1 and acc@5.\n        \"\"\"", "\n", "\n", "out", "=", "self", "(", "X", ")", "\n", "logits", "=", "out", "[", "\"logits\"", "]", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "# handle when the number of classes is smaller than 5", "\n", "top_k_max", "=", "min", "(", "5", ",", "logits", ".", "size", "(", "1", ")", ")", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "logits", ",", "targets", ",", "top_k", "=", "(", "1", ",", "top_k_max", ")", ")", "\n", "\n", "out", ".", "update", "(", "{", "\"loss\"", ":", "loss", ",", "\"acc1\"", ":", "acc1", ",", "\"acc5\"", ":", "acc5", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.training_step": [[537, 587], ["base.BaseMethod.log_dict", "isinstance", "len", "base.BaseMethod._base_shared_step", "multicrop_outs[].keys", "sum", "sum", "sum", "targets.repeat.repeat.repeat", "base.BaseMethod.knn", "outs[].keys", "base.BaseMethod.multicrop_forward", "outs.get", "[].detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod._base_shared_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "List", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Training step for pytorch lightning. It does all the shared operations, such as\n        forwarding the crops, computing logits and computing statistics.\n\n        Args:\n            batch (List[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            Dict[str, Any]: dict with the classification loss, features and logits.\n        \"\"\"", "\n", "\n", "_", ",", "X", ",", "targets", "=", "batch", "\n", "\n", "X", "=", "[", "X", "]", "if", "isinstance", "(", "X", ",", "torch", ".", "Tensor", ")", "else", "X", "\n", "\n", "# check that we received the desired number of crops", "\n", "assert", "len", "(", "X", ")", "==", "self", ".", "num_crops", "\n", "\n", "outs", "=", "[", "self", ".", "_base_shared_step", "(", "x", ",", "targets", ")", "for", "x", "in", "X", "[", ":", "self", ".", "num_large_crops", "]", "]", "\n", "outs", "=", "{", "k", ":", "[", "out", "[", "k", "]", "for", "out", "in", "outs", "]", "for", "k", "in", "outs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "if", "self", ".", "multicrop", ":", "\n", "            ", "multicrop_outs", "=", "[", "self", ".", "multicrop_forward", "(", "x", ")", "for", "x", "in", "X", "[", "self", ".", "num_large_crops", ":", "]", "]", "\n", "for", "k", "in", "multicrop_outs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                ", "outs", "[", "k", "]", "=", "outs", ".", "get", "(", "k", ",", "[", "]", ")", "+", "[", "out", "[", "k", "]", "for", "out", "in", "multicrop_outs", "]", "\n", "\n", "# loss and stats", "\n", "", "", "outs", "[", "\"loss\"", "]", "=", "sum", "(", "outs", "[", "\"loss\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", "outs", "[", "\"acc1\"", "]", "=", "sum", "(", "outs", "[", "\"acc1\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", "outs", "[", "\"acc5\"", "]", "=", "sum", "(", "outs", "[", "\"acc5\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", "\n", "metrics", "=", "{", "\n", "\"train_class_loss\"", ":", "outs", "[", "\"loss\"", "]", ",", "\n", "\"train_acc1\"", ":", "outs", "[", "\"acc1\"", "]", ",", "\n", "\"train_acc5\"", ":", "outs", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "if", "self", ".", "knn_eval", ":", "\n", "            ", "targets", "=", "targets", ".", "repeat", "(", "self", ".", "num_large_crops", ")", "\n", "mask", "=", "targets", "!=", "-", "1", "\n", "self", ".", "knn", "(", "\n", "train_features", "=", "torch", ".", "cat", "(", "outs", "[", "\"feats\"", "]", "[", ":", "self", ".", "num_large_crops", "]", ")", "[", "mask", "]", ".", "detach", "(", ")", ",", "\n", "train_targets", "=", "targets", "[", "mask", "]", ",", "\n", ")", "\n", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.validation_step": [[588, 618], ["targets.size", "base.BaseMethod._base_shared_step", "base.BaseMethod.knn", "base.BaseMethod.pop().detach", "targets.detach", "base.BaseMethod.pop"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod._base_shared_step"], ["", "def", "validation_step", "(", "\n", "self", ",", "batch", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", ",", "dataloader_idx", ":", "int", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Validation step for pytorch lightning. It does all the shared operations, such as\n        forwarding a batch of images, computing logits and computing metrics.\n\n        Args:\n            batch (List[torch.Tensor]):a batch of data in the format of [img_indexes, X, Y].\n            batch_idx (int): index of the batch.\n\n        Returns:\n            Dict[str, Any]: dict with the batch_size (used for averaging), the classification loss\n                and accuracies.\n        \"\"\"", "\n", "\n", "X", ",", "targets", "=", "batch", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "out", "=", "self", ".", "_base_shared_step", "(", "X", ",", "targets", ")", "\n", "\n", "if", "self", ".", "knn_eval", "and", "not", "self", ".", "trainer", ".", "sanity_checking", ":", "\n", "            ", "self", ".", "knn", "(", "test_features", "=", "out", ".", "pop", "(", "\"feats\"", ")", ".", "detach", "(", ")", ",", "test_targets", "=", "targets", ".", "detach", "(", ")", ")", "\n", "\n", "", "metrics", "=", "{", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"val_loss\"", ":", "out", "[", "\"loss\"", "]", ",", "\n", "\"val_acc1\"", ":", "out", "[", "\"acc1\"", "]", ",", "\n", "\"val_acc5\"", ":", "out", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMethod.validation_epoch_end": [[619, 639], ["solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "base.BaseMethod.log_dict", "base.BaseMethod.knn.compute", "log.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.knn.WeightedKNNClassifier.compute", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", ":", "\n", "        ", "\"\"\"Averages the losses and accuracies of all the validation batches.\n        This is needed because the last batch can be smaller than the others,\n        slightly skewing the metrics.\n\n        Args:\n            outs (List[Dict[str, Any]]): list of outputs of the validation step.\n        \"\"\"", "\n", "\n", "val_loss", "=", "weighted_mean", "(", "outs", ",", "\"val_loss\"", ",", "\"batch_size\"", ")", "\n", "val_acc1", "=", "weighted_mean", "(", "outs", ",", "\"val_acc1\"", ",", "\"batch_size\"", ")", "\n", "val_acc5", "=", "weighted_mean", "(", "outs", ",", "\"val_acc5\"", ",", "\"batch_size\"", ")", "\n", "\n", "log", "=", "{", "\"val_loss\"", ":", "val_loss", ",", "\"val_acc1\"", ":", "val_acc1", ",", "\"val_acc5\"", ":", "val_acc5", "}", "\n", "\n", "if", "self", ".", "knn_eval", "and", "not", "self", ".", "trainer", ".", "sanity_checking", ":", "\n", "            ", "val_knn_acc1", ",", "val_knn_acc5", "=", "self", ".", "knn", ".", "compute", "(", ")", "\n", "log", ".", "update", "(", "{", "\"val_knn_acc1\"", ":", "val_knn_acc1", ",", "\"val_knn_acc5\"", ":", "val_knn_acc5", "}", ")", "\n", "\n", "", "self", ".", "log_dict", "(", "log", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.__init__": [[642, 695], ["base.BaseMethod.__init__", "base.BaseMomentumMethod.backbone_args.copy", "base.BaseMomentumMethod.pop", "base.BaseMomentumMethod.base_model", "base.BaseMomentumMethod.backbone_name.startswith", "solo.utils.momentum.initialize_momentum_params", "solo.utils.momentum.MomentumUpdater", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "base_tau_momentum", ":", "float", ",", "\n", "final_tau_momentum", ":", "float", ",", "\n", "momentum_classifier", ":", "bool", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Base momentum model that implements all basic operations for all self-supervised methods\n        that use a momentum backbone. It adds shared momentum arguments, adds basic learnable\n        parameters, implements basic training and validation steps for the momentum backbone and\n        classifier. Also implements momentum update using exponential moving average and cosine\n        annealing of the weighting decrease coefficient.\n\n        Args:\n            base_tau_momentum (float): base value of the weighting decrease coefficient (should be\n                in [0,1]).\n            final_tau_momentum (float): final value of the weighting decrease coefficient (should be\n                in [0,1]).\n            momentum_classifier (bool): whether or not to train a classifier on top of the momentum\n                backbone.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "# momentum backbone", "\n", "kwargs", "=", "self", ".", "backbone_args", ".", "copy", "(", ")", "\n", "cifar", "=", "kwargs", ".", "pop", "(", "\"cifar\"", ",", "False", ")", "\n", "# swin specific", "\n", "if", "\"swin\"", "in", "self", ".", "backbone_name", "and", "cifar", ":", "\n", "            ", "kwargs", "[", "\"window_size\"", "]", "=", "4", "\n", "\n", "", "self", ".", "momentum_backbone", "=", "self", ".", "base_model", "(", "**", "kwargs", ")", "\n", "if", "self", ".", "backbone_name", ".", "startswith", "(", "\"resnet\"", ")", ":", "\n", "# remove fc layer", "\n", "            ", "self", ".", "momentum_backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "if", "cifar", ":", "\n", "                ", "self", ".", "momentum_backbone", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "momentum_backbone", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "features_dim", "=", "self", ".", "momentum_backbone", ".", "num_features", "\n", "\n", "", "initialize_momentum_params", "(", "self", ".", "backbone", ",", "self", ".", "momentum_backbone", ")", "\n", "\n", "# momentum classifier", "\n", "if", "momentum_classifier", ":", "\n", "            ", "self", ".", "momentum_classifier", ":", "Any", "=", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "self", ".", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "momentum_classifier", "=", "None", "\n", "\n", "# momentum updater", "\n", "", "self", ".", "momentum_updater", "=", "MomentumUpdater", "(", "base_tau_momentum", ",", "final_tau_momentum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.learnable_params": [[696, 716], ["momentum_learnable_parameters.append", "base.BaseMomentumMethod.momentum_classifier.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds momentum classifier parameters to the parameters of the base class.\n\n        Returns:\n            List[Dict[str, Any]]:\n                list of dicts containing learnable parameters and possible settings.\n        \"\"\"", "\n", "\n", "momentum_learnable_parameters", "=", "[", "]", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "momentum_learnable_parameters", ".", "append", "(", "\n", "{", "\n", "\"name\"", ":", "\"momentum_classifier\"", ",", "\n", "\"params\"", ":", "self", ".", "momentum_classifier", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "self", ".", "classifier_lr", ",", "\n", "\"weight_decay\"", ":", "0", ",", "\n", "}", "\n", ")", "\n", "", "return", "super", "(", ")", ".", "learnable_params", "+", "momentum_learnable_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.momentum_pairs": [[717, 726], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Defines base momentum pairs that will be updated using exponential moving average.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs (two element tuples).\n        \"\"\"", "\n", "\n", "return", "[", "(", "self", ".", "backbone", ",", "self", ".", "momentum_backbone", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.add_model_specific_args": [[727, 750], ["base.BaseMethod.add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "\"\"\"Adds basic momentum arguments that are shared for all methods.\n\n        Args:\n            parent_parser (ArgumentParser): argument parser that is used to create a\n                argument group.\n\n        Returns:\n            ArgumentParser: same as the argument, used to avoid errors.\n        \"\"\"", "\n", "\n", "parent_parser", "=", "super", "(", "BaseMomentumMethod", ",", "BaseMomentumMethod", ")", ".", "add_model_specific_args", "(", "\n", "parent_parser", "\n", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"base\"", ")", "\n", "\n", "# momentum settings", "\n", "parser", ".", "add_argument", "(", "\"--base_tau_momentum\"", ",", "default", "=", "0.99", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_tau_momentum\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--momentum_classifier\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.on_train_start": [[751, 754], ["None"], "methods", ["None"], ["", "def", "on_train_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the step counter at the beginning of training.\"\"\"", "\n", "self", ".", "last_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.momentum_forward": [[755, 771], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "base.BaseMomentumMethod.momentum_backbone", "X.to.to.to"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "momentum_forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Momentum forward method. Children methods should call this function,\n        modify the ouputs (without deleting anything) and return it.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict: dict of logits and features.\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "no_channel_last", ":", "\n", "            ", "X", "=", "X", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "", "feats", "=", "self", ".", "momentum_backbone", "(", "X", ")", "\n", "return", "{", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod._shared_step_momentum": [[772, 797], ["base.BaseMomentumMethod.momentum_forward", "base.BaseMomentumMethod.momentum_classifier", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "solo.utils.metrics.accuracy_at_k", "base.BaseMomentumMethod.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.accuracy_at_k", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "_shared_step_momentum", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Forwards a batch of images X in the momentum backbone and optionally computes the\n        classification loss, the logits, the features, acc@1 and acc@5 for of momentum classifier.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n            targets (torch.Tensor): batch of labels for X.\n\n        Returns:\n            Dict[str, Any]:\n                a dict containing the classification loss, logits, features, acc@1 and\n                acc@5 of the momentum backbone / classifier.\n        \"\"\"", "\n", "\n", "out", "=", "self", ".", "momentum_forward", "(", "X", ")", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "feats", "=", "out", "[", "\"feats\"", "]", "\n", "logits", "=", "self", ".", "momentum_classifier", "(", "feats", ")", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "logits", ",", "targets", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "out", ".", "update", "(", "{", "\"logits\"", ":", "logits", ",", "\"loss\"", ":", "loss", ",", "\"acc1\"", ":", "acc1", ",", "\"acc5\"", ":", "acc5", "}", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.training_step": [[798, 849], ["base.BaseMethod.training_step", "super().training_step.update", "isinstance", "base.BaseMomentumMethod._shared_step_momentum", "base.BaseMomentumMethod.log_dict", "momentum_outs[].keys", "sum", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod._shared_step_momentum"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "List", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Training step for pytorch lightning. It performs all the shared operations for the\n        momentum backbone and classifier, such as forwarding the crops in the momentum backbone\n        and classifier, and computing statistics.\n        Args:\n            batch (List[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            Dict[str, Any]: a dict with the features of the momentum backbone and the classification\n                loss and logits of the momentum classifier.\n        \"\"\"", "\n", "\n", "outs", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "_", ",", "X", ",", "targets", "=", "batch", "\n", "X", "=", "[", "X", "]", "if", "isinstance", "(", "X", ",", "torch", ".", "Tensor", ")", "else", "X", "\n", "\n", "# remove small crops", "\n", "X", "=", "X", "[", ":", "self", ".", "num_large_crops", "]", "\n", "\n", "momentum_outs", "=", "[", "self", ".", "_shared_step_momentum", "(", "x", ",", "targets", ")", "for", "x", "in", "X", "]", "\n", "momentum_outs", "=", "{", "\n", "\"momentum_\"", "+", "k", ":", "[", "out", "[", "k", "]", "for", "out", "in", "momentum_outs", "]", "for", "k", "in", "momentum_outs", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "# momentum loss and stats", "\n", "            ", "momentum_outs", "[", "\"momentum_loss\"", "]", "=", "(", "\n", "sum", "(", "momentum_outs", "[", "\"momentum_loss\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", ")", "\n", "momentum_outs", "[", "\"momentum_acc1\"", "]", "=", "(", "\n", "sum", "(", "momentum_outs", "[", "\"momentum_acc1\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", ")", "\n", "momentum_outs", "[", "\"momentum_acc5\"", "]", "=", "(", "\n", "sum", "(", "momentum_outs", "[", "\"momentum_acc5\"", "]", ")", "/", "self", ".", "num_large_crops", "\n", ")", "\n", "\n", "metrics", "=", "{", "\n", "\"train_momentum_class_loss\"", ":", "momentum_outs", "[", "\"momentum_loss\"", "]", ",", "\n", "\"train_momentum_acc1\"", ":", "momentum_outs", "[", "\"momentum_acc1\"", "]", ",", "\n", "\"train_momentum_acc5\"", ":", "momentum_outs", "[", "\"momentum_acc5\"", "]", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "# adds the momentum classifier loss together with the general loss", "\n", "outs", "[", "\"loss\"", "]", "+=", "momentum_outs", "[", "\"momentum_loss\"", "]", "\n", "\n", "", "outs", ".", "update", "(", "momentum_outs", ")", "\n", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.on_train_batch_end": [[850, 876], ["base.BaseMomentumMethod.log", "base.BaseMomentumMethod.momentum_updater.update_tau", "base.BaseMomentumMethod.momentum_updater.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update_tau", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "on_train_batch_end", "(", "self", ",", "outputs", ":", "Dict", "[", "str", ",", "Any", "]", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"Performs the momentum update of momentum pairs using exponential moving average at the\n        end of the current training step if an optimizer step was performed.\n\n        Args:\n            outputs (Dict[str, Any]): the outputs of the training step.\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size self.num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n        \"\"\"", "\n", "\n", "if", "self", ".", "trainer", ".", "global_step", ">", "self", ".", "last_step", ":", "\n", "# update momentum backbone and projector", "\n", "            ", "momentum_pairs", "=", "self", ".", "momentum_pairs", "\n", "for", "mp", "in", "momentum_pairs", ":", "\n", "                ", "self", ".", "momentum_updater", ".", "update", "(", "*", "mp", ")", "\n", "# log tau momentum", "\n", "", "self", ".", "log", "(", "\"tau\"", ",", "self", ".", "momentum_updater", ".", "cur_tau", ")", "\n", "# update tau", "\n", "cur_step", "=", "self", ".", "trainer", ".", "global_step", "\n", "if", "self", ".", "trainer", ".", "accumulate_grad_batches", ":", "\n", "                ", "cur_step", "=", "cur_step", "*", "self", ".", "trainer", ".", "accumulate_grad_batches", "\n", "", "self", ".", "momentum_updater", ".", "update_tau", "(", "\n", "cur_step", "=", "cur_step", ",", "max_steps", "=", "self", ".", "max_epochs", "*", "self", ".", "num_training_steps", "\n", ")", "\n", "", "self", ".", "last_step", "=", "self", ".", "trainer", ".", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.validation_step": [[877, 909], ["base.BaseMethod.validation_step", "targets.size", "base.BaseMomentumMethod._shared_step_momentum"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.validation_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod._shared_step_momentum"], ["", "def", "validation_step", "(", "\n", "self", ",", "batch", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", ",", "dataloader_idx", ":", "int", "=", "None", "\n", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "Any", "]", ",", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Validation step for pytorch lightning. It performs all the shared operations for the\n        momentum backbone and classifier, such as forwarding a batch of images in the momentum\n        backbone and classifier and computing statistics.\n        Args:\n            batch (List[torch.Tensor]): a batch of data in the format of [X, Y].\n            batch_idx (int): index of the batch.\n        Returns:\n            Tuple(Dict[str, Any], Dict[str, Any]): tuple of dicts containing the batch_size (used\n                for averaging), the classification loss and accuracies for both the online and the\n                momentum classifiers.\n        \"\"\"", "\n", "\n", "parent_metrics", "=", "super", "(", ")", ".", "validation_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "X", ",", "targets", "=", "batch", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "out", "=", "self", ".", "_shared_step_momentum", "(", "X", ",", "targets", ")", "\n", "\n", "metrics", "=", "None", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "metrics", "=", "{", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"momentum_val_loss\"", ":", "out", "[", "\"loss\"", "]", ",", "\n", "\"momentum_val_acc1\"", ":", "out", "[", "\"acc1\"", "]", ",", "\n", "\"momentum_val_acc5\"", ":", "out", "[", "\"acc5\"", "]", ",", "\n", "}", "\n", "\n", "", "return", "parent_metrics", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.BaseMomentumMethod.validation_epoch_end": [[910, 935], ["base.BaseMethod.validation_epoch_end", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "base.BaseMomentumMethod.log_dict"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.validation_epoch_end", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ":", "Tuple", "[", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "]", ")", ":", "\n", "        ", "\"\"\"Averages the losses and accuracies of the momentum backbone / classifier for all the\n        validation batches. This is needed because the last batch can be smaller than the others,\n        slightly skewing the metrics.\n        Args:\n            outs (Tuple[List[Dict[str, Any]]]):): list of outputs of the validation step for self\n                and the parent.\n        \"\"\"", "\n", "\n", "parent_outs", "=", "[", "out", "[", "0", "]", "for", "out", "in", "outs", "]", "\n", "super", "(", ")", ".", "validation_epoch_end", "(", "parent_outs", ")", "\n", "\n", "if", "self", ".", "momentum_classifier", "is", "not", "None", ":", "\n", "            ", "momentum_outs", "=", "[", "out", "[", "1", "]", "for", "out", "in", "outs", "]", "\n", "\n", "val_loss", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_loss\"", ",", "\"batch_size\"", ")", "\n", "val_acc1", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_acc1\"", ",", "\"batch_size\"", ")", "\n", "val_acc5", "=", "weighted_mean", "(", "momentum_outs", ",", "\"momentum_val_acc5\"", ",", "\"batch_size\"", ")", "\n", "\n", "log", "=", "{", "\n", "\"momentum_val_loss\"", ":", "val_loss", ",", "\n", "\"momentum_val_acc1\"", ":", "val_acc1", ",", "\n", "\"momentum_val_acc5\"", ":", "val_acc5", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "log", ",", "sync_dist", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.base.static_lr": [[61, 68], ["get_lr", "zip"], "function", ["None"], ["def", "static_lr", "(", "\n", "get_lr", ":", "Callable", ",", "param_group_indexes", ":", "Sequence", "[", "int", "]", ",", "lrs_to_replace", ":", "Sequence", "[", "float", "]", "\n", ")", ":", "\n", "    ", "lrs", "=", "get_lr", "(", ")", "\n", "for", "idx", ",", "lr", "in", "zip", "(", "param_group_indexes", ",", "lrs_to_replace", ")", ":", "\n", "        ", "lrs", "[", "idx", "]", "=", "lr", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.__init__": [[30, 48], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "gathered_z", "=", "gather", "(", "z", ")", "\n", "\n", "sim", "=", "torch", ".", "exp", "(", "torch", ".", "einsum", "(", "\"if, jf -> ij\"", ",", "z", ",", "gathered_z", ")", "/", "temperature", ")", "\n", "\n", "gathered_indexes", "=", "gather", "(", "indexes", ")", "\n", "\n", "indexes", "=", "indexes", ".", "unsqueeze", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.add_model_specific_args": [[50, 63], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["# positives", "\n", "pos_mask", "=", "indexes", ".", "t", "(", ")", "==", "gathered_indexes", "\n", "pos_mask", "[", ":", ",", "z", ".", "size", "(", "0", ")", "*", "get_rank", "(", ")", ":", "]", ".", "fill_diagonal_", "(", "0", ")", "\n", "# negatives", "\n", "neg_mask", "=", "indexes", ".", "t", "(", ")", "!=", "gathered_indexes", "\n", "\n", "pos", "=", "torch", ".", "sum", "(", "sim", "*", "pos_mask", ",", "1", ")", "\n", "neg", "=", "torch", ".", "sum", "(", "sim", "*", "neg_mask", ",", "1", ")", "\n", "loss", "=", "-", "(", "torch", ".", "mean", "(", "torch", ".", "log", "(", "pos", "/", "(", "pos", "+", "neg", ")", ")", ")", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.learnable_params": [[64, 74], ["simclr.SimCLR.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.forward": [[75, 91], ["super().forward", "simclr.SimCLR.projector", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.multicrop_forward": [[92, 107], ["super().multicrop_forward", "simclr.SimCLR.projector", "super().multicrop_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simclr.SimCLR.training_step": [[108, 139], ["super().training_step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "indexes.repeat.repeat.repeat", "solo.losses.simclr.simclr_loss_func", "simclr.SimCLR.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simclr.simclr_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simsiam.SimSiam.__init__": [[31, 67], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "-", "F", ".", "cosine_similarity", "(", "p", ",", "z", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "-", "(", "p", "*", "z", ".", "detach", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simsiam.SimSiam.add_model_specific_args": [[69, 81], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simsiam.SimSiam.learnable_params": [[82, 95], ["simsiam.SimSiam.projector.parameters", "simsiam.SimSiam.predictor.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simsiam.SimSiam.forward": [[96, 113], ["super().forward", "simsiam.SimSiam.projector", "simsiam.SimSiam.predictor", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.simsiam.SimSiam.training_step": [[114, 146], ["super().training_step", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "simsiam.SimSiam.log_dict", "solo.losses.simsiam.simsiam_loss_func", "solo.losses.simsiam.simsiam_loss_func", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.__init__": [[34, 81], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nnsiam.NNSiam.register_buffer", "nnsiam.NNSiam.register_buffer", "torch.normalize", "torch.normalize", "torch.normalize", "nnsiam.NNSiam.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "pred_hidden_dim", ":", "int", ",", "\n", "queue_size", ":", "int", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implements NNSiam (https://arxiv.org/abs/2104.14548).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            pred_hidden_dim (int): number of neurons of the hidden layers of the predictor.\n            queue_size (int): number of samples to keep in the queue.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "queue_size", "=", "queue_size", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_output_dim", ",", "affine", "=", "False", ")", ",", "\n", ")", "\n", "self", ".", "projector", "[", "6", "]", ".", "bias", ".", "requires_grad", "=", "False", "# hack: not use bias as it is followed by BN", "\n", "\n", "# predictor", "\n", "self", ".", "predictor", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "proj_output_dim", ",", "pred_hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "pred_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "pred_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# queue", "\n", "self", ".", "register_buffer", "(", "\"queue\"", ",", "torch", ".", "randn", "(", "self", ".", "queue_size", ",", "proj_output_dim", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_y\"", ",", "-", "torch", ".", "ones", "(", "self", ".", "queue_size", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "self", ".", "queue", "=", "F", ".", "normalize", "(", "self", ".", "queue", ",", "dim", "=", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_ptr\"", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.add_model_specific_args": [[82, 98], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "NNSiam", ",", "NNSiam", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"nnsiam\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# predictor", "\n", "parser", ".", "add_argument", "(", "\"--pred_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "\n", "# queue settings", "\n", "parser", ".", "add_argument", "(", "\"--queue_size\"", ",", "default", "=", "65536", ",", "type", "=", "int", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.learnable_params": [[99, 112], ["nnsiam.NNSiam.projector.parameters", "nnsiam.NNSiam.predictor.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector and predictor parameters to the parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", ":", "List", "[", "dict", "]", "=", "[", "\n", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", ",", "\n", "{", "\"params\"", ":", "self", ".", "predictor", ".", "parameters", "(", ")", ",", "\"static_lr\"", ":", "True", "}", ",", "\n", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.dequeue_and_enqueue": [[113, 136], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "solo.utils.misc.gather", "solo.utils.misc.gather", "int"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "dequeue_and_enqueue", "(", "self", ",", "z", ":", "torch", ".", "Tensor", ",", "y", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Adds new samples and removes old samples from the queue in a fifo manner. Also stores\n        the labels of the samples.\n\n        Args:\n            z (torch.Tensor): batch of projected features.\n            y (torch.Tensor): labels of the samples in the batch.\n        \"\"\"", "\n", "\n", "z", "=", "gather", "(", "z", ")", "\n", "y", "=", "gather", "(", "y", ")", "\n", "\n", "batch_size", "=", "z", ".", "shape", "[", "0", "]", "\n", "\n", "ptr", "=", "int", "(", "self", ".", "queue_ptr", ")", "# type: ignore", "\n", "assert", "self", ".", "queue_size", "%", "batch_size", "==", "0", "\n", "\n", "self", ".", "queue", "[", "ptr", ":", "ptr", "+", "batch_size", ",", ":", "]", "=", "z", "\n", "self", ".", "queue_y", "[", "ptr", ":", "ptr", "+", "batch_size", "]", "=", "y", "# type: ignore", "\n", "ptr", "=", "(", "ptr", "+", "batch_size", ")", "%", "self", ".", "queue_size", "\n", "\n", "self", ".", "queue_ptr", "[", "0", "]", "=", "ptr", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.find_nn": [[137, 152], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "find_nn", "(", "self", ",", "z", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Finds the nearest neighbor of a sample.\n\n        Args:\n            z (torch.Tensor): a batch of projected features.\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]:\n                indices and projected features of the nearest neighbors.\n        \"\"\"", "\n", "\n", "idx", "=", "(", "z", "@", "self", ".", "queue", ".", "T", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "1", "]", "\n", "nn", "=", "self", ".", "queue", "[", "idx", "]", "\n", "return", "idx", ",", "nn", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.forward": [[153, 171], ["super().forward", "nnsiam.NNSiam.projector", "nnsiam.NNSiam.predictor", "torch.normalize", "torch.normalize", "torch.normalize", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the backbone, the projector and the predictor.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]:\n                a dict containing the outputs of the parent\n                and the projected and predicted features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ")", "\n", "z", "=", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", "\n", "p", "=", "self", ".", "predictor", "(", "z", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "out", ".", "update", "(", "{", "\"z\"", ":", "z", ",", "\"p\"", ":", "p", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnsiam.NNSiam.training_step": [[172, 218], ["super().training_step", "nnsiam.NNSiam.find_nn", "nnsiam.NNSiam.find_nn", "targets.size", "nnsiam.NNSiam.dequeue_and_enqueue", "z1.std().mean", "z2.std().mean", "nnsiam.NNSiam.log_dict", "solo.losses.simsiam.simsiam_loss_func", "solo.losses.simsiam.simsiam_loss_func", "z1.std", "z2.std"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.dequeue_and_enqueue", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simsiam.simsiam_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Training step for NNSiam reusing BaseMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size num_crops containing batches of images\n            batch_idx (int): index of the batch\n\n        Returns:\n            torch.Tensor: total loss composed of NNSiam loss and classification loss\n        \"\"\"", "\n", "\n", "targets", "=", "batch", "[", "-", "1", "]", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "z1", ",", "z2", "=", "out", "[", "\"z\"", "]", "\n", "p1", ",", "p2", "=", "out", "[", "\"p\"", "]", "\n", "\n", "# find nn", "\n", "idx1", ",", "nn1", "=", "self", ".", "find_nn", "(", "z1", ")", "\n", "_", ",", "nn2", "=", "self", ".", "find_nn", "(", "z2", ")", "\n", "\n", "# ------- negative cosine similarity loss -------", "\n", "neg_cos_sim", "=", "simsiam_loss_func", "(", "p1", ",", "nn2", ")", "/", "2", "+", "simsiam_loss_func", "(", "p2", ",", "nn1", ")", "/", "2", "\n", "\n", "# compute nn accuracy", "\n", "b", "=", "targets", ".", "size", "(", "0", ")", "\n", "nn_acc", "=", "(", "targets", "==", "self", ".", "queue_y", "[", "idx1", "]", ")", ".", "sum", "(", ")", "/", "b", "\n", "\n", "# dequeue and enqueue", "\n", "self", ".", "dequeue_and_enqueue", "(", "z1", ",", "targets", ")", "\n", "\n", "# calculate std of features", "\n", "z1_std", "=", "z1", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z2_std", "=", "z2", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z_std", "=", "(", "z1_std", "+", "z2_std", ")", "/", "2", "\n", "\n", "metrics", "=", "{", "\n", "\"train_neg_cos_sim\"", ":", "neg_cos_sim", ",", "\n", "\"train_z_std\"", ":", "z_std", ",", "\n", "\"train_nn_acc\"", ":", "nn_acc", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "neg_cos_sim", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.__init__": [[35, 76], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "mocov2plus.MoCoV2Plus.register_buffer", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "mocov2plus.MoCoV2Plus.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["\n", "\n", "pos", "=", "torch", ".", "einsum", "(", "\"nc,nc->n\"", ",", "[", "query", ",", "key", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "neg", "=", "torch", ".", "einsum", "(", "\"nc,ck->nk\"", ",", "[", "query", ",", "queue", "]", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "pos", ",", "neg", "]", ",", "dim", "=", "1", ")", "\n", "logits", "/=", "temperature", "\n", "targets", "=", "torch", ".", "zeros", "(", "query", ".", "size", "(", "0", ")", ",", "device", "=", "query", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "targets", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.add_model_specific_args": [[77, 93], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.learnable_params": [[94, 104], ["mocov2plus.MoCoV2Plus.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.momentum_pairs": [[105, 115], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus._dequeue_and_enqueue": [[116, 133], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "int", "keys.permute.permute.permute"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.forward": [[134, 148], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "super().forward.update", "mocov2plus.MoCoV2Plus.projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.momentum_forward": [[149, 164], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "torch.normalize", "torch.normalize", "torch.normalize", "super().momentum_forward.update", "mocov2plus.MoCoV2Plus.momentum_projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus.training_step": [[165, 200], ["super().training_step", "mocov2plus.MoCoV2Plus.queue.clone().detach", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "mocov2plus.MoCoV2Plus._dequeue_and_enqueue", "mocov2plus.MoCoV2Plus.log", "mocov2plus.MoCoV2Plus.queue.clone", "solo.losses.mocov2plus.mocov2plus_loss_func", "solo.losses.mocov2plus.mocov2plus_loss_func", "solo.utils.misc.gather", "solo.utils.misc.gather"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov2plus.MoCoV2Plus._dequeue_and_enqueue", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov2plus.mocov2plus_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov2plus.mocov2plus_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINOHead.__init__": [[37, 86], ["torch.Module.__init__", "max", "dino.DINOHead.apply", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "dino.DINOHead.last_layer.weight_g.data.fill_", "torch.Linear", "torch.Linear", "torch.Linear", "layers.append", "range", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "layers.append", "torch.GELU", "torch.GELU", "torch.GELU", "layers.append", "layers.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "layers.append", "torch.GELU", "torch.GELU", "torch.GELU", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["center_momentum", ":", "float", "=", "0.9", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Auxiliary module to compute DINO's loss.\n\n        Args:\n            num_prototypes (int): number of prototypes.\n            warmup_teacher_temp (float): base temperature for the temperature schedule\n                of the teacher.\n            teacher_temp (float): final temperature for the teacher.\n            warmup_teacher_temp_epochs (float): number of epochs for the cosine annealing schedule.\n            num_epochs (int): total number of epochs.\n            student_temp (float, optional): temperature for the student. Defaults to 0.1.\n            num_large_crops (int, optional): number of crops/views. Defaults to 2.\n            center_momentum (float, optional): momentum for the EMA update of the center of\n                mass of the teacher. Defaults to 0.9.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "student_temp", "=", "student_temp", "\n", "self", ".", "center_momentum", "=", "center_momentum", "\n", "self", ".", "num_large_crops", "=", "num_large_crops", "\n", "self", ".", "register_buffer", "(", "\"center\"", ",", "torch", ".", "zeros", "(", "1", ",", "num_prototypes", ")", ")", "\n", "# we apply a warm up for the teacher temperature because", "\n", "# a too high temperature makes the training unstable at the beginning", "\n", "self", ".", "teacher_temp_schedule", "=", "np", ".", "concatenate", "(", "\n", "(", "\n", "np", ".", "linspace", "(", "warmup_teacher_temp", ",", "teacher_temp", ",", "warmup_teacher_temp_epochs", ")", ",", "\n", "np", ".", "ones", "(", "num_epochs", "-", "warmup_teacher_temp_epochs", ")", "*", "teacher_temp", ",", "\n", ")", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "student_output", ":", "torch", ".", "Tensor", ",", "teacher_output", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes DINO's loss given a batch of logits of the student and a batch of logits of the\n        teacher.\n\n        Args:\n            student_output (torch.Tensor): NxP Tensor containing student logits for all views.\n            teacher_output (torch.Tensor): NxP Tensor containing teacher logits for all views.\n\n        Returns:\n            torch.Tensor: DINO loss.\n        \"\"\"", "\n", "\n", "student_out", "=", "student_output", "/", "self", ".", "student_temp", "\n", "student_out", "=", "student_out", ".", "chunk", "(", "self", ".", "num_large_crops", ")", "\n", "\n", "# teacher centering and sharpening", "\n", "temp", "=", "self", ".", "teacher_temp_schedule", "[", "self", ".", "epoch", "]", "\n", "teacher_out", "=", "F", ".", "softmax", "(", "(", "teacher_output", "-", "self", ".", "center", ")", "/", "temp", ",", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINOHead._init_weights": [[87, 98], ["isinstance", "solo.utils.misc.trunc_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.trunc_normal_"], ["teacher_out", "=", "teacher_out", ".", "detach", "(", ")", ".", "chunk", "(", "2", ")", "\n", "\n", "total_loss", "=", "0", "\n", "n_loss_terms", "=", "0", "\n", "for", "iq", ",", "q", "in", "enumerate", "(", "teacher_out", ")", ":", "\n", "            ", "for", "iv", ",", "v", "in", "enumerate", "(", "student_out", ")", ":", "\n", "                ", "if", "iv", "==", "iq", ":", "\n", "# we skip cases where student and teacher operate on the same view", "\n", "                    ", "continue", "\n", "", "loss", "=", "torch", ".", "sum", "(", "-", "q", "*", "F", ".", "log_softmax", "(", "v", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "total_loss", "+=", "loss", ".", "mean", "(", ")", "\n", "n_loss_terms", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINOHead.forward": [[99, 113], ["dino.DINOHead.mlp", "torch.normalize", "torch.normalize", "torch.normalize", "dino.DINOHead.last_layer"], "methods", ["None"], ["", "", "total_loss", "/=", "n_loss_terms", "\n", "self", ".", "update_center", "(", "teacher_output", ")", "\n", "return", "total_loss", "\n", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_center", "(", "self", ",", "teacher_output", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Updates the center for DINO's loss using exponential moving average.\n\n        Args:\n            teacher_output (torch.Tensor): NxP Tensor containing teacher logits of all views.\n        \"\"\"", "\n", "\n", "batch_center", "=", "torch", ".", "sum", "(", "teacher_output", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "            ", "dist", ".", "all_reduce", "(", "batch_center", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.__init__": [[116, 182], ["solo.methods.base.BaseMomentumMethod.__init__", "dino.DINOHead", "dino.DINOHead", "solo.utils.momentum.initialize_momentum_params", "solo.losses.dino.DINOLoss"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["\n", "# ema update", "\n", "self", ".", "center", "=", "self", ".", "center", "*", "self", ".", "center_momentum", "+", "batch_center", "*", "(", "1", "-", "self", ".", "center_momentum", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.add_model_specific_args": [[184, 207], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.learnable_params": [[208, 218], ["dino.DINO.head.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.momentum_pairs": [[219, 229], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.dino_clip_gradients": [[230, 243], ["dino.DINO.backbone.parameters", "p.grad.data.norm", "p.grad.data.mul_"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.on_train_epoch_start": [[244, 247], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.forward": [[248, 262], ["super().forward", "dino.DINO.head", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.momentum_forward": [[263, 278], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "dino.DINO.momentum_head", "super().momentum_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.training_step": [[279, 302], ["super().training_step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dino.DINO.dino_loss_func", "dino.DINO.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.on_after_backward": [[303, 313], ["dino.DINO.dino_clip_gradients", "dino.DINO.head.last_layer.parameters"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.dino.DINO.dino_clip_gradients"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vibcreg.VIbCReg.__init__": [[31, 68], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.GELU", "torch.GELU", "torch.Linear", "torch.Linear", "solo.utils.whitening.IterNorm", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "norm_z1", "=", "z1", "-", "z1", ".", "mean", "(", "dim", "=", "0", ")", "\n", "norm_z2", "=", "z2", "-", "z2", ".", "mean", "(", "dim", "=", "0", ")", "\n", "norm_z1", "=", "F", ".", "normalize", "(", "norm_z1", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "# (batch * feature); l2-norm", "\n", "norm_z2", "=", "F", ".", "normalize", "(", "norm_z2", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "\n", "fxf_cov_z1", "=", "torch", ".", "mm", "(", "norm_z1", ".", "T", ",", "norm_z1", ")", "# (feature * feature)", "\n", "fxf_cov_z2", "=", "torch", ".", "mm", "(", "norm_z2", ".", "T", ",", "norm_z2", ")", "\n", "fxf_cov_z1", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "fxf_cov_z2", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "cov_loss", "=", "(", "fxf_cov_z1", "**", "2", ")", ".", "mean", "(", ")", "+", "(", "fxf_cov_z2", "**", "2", ")", ".", "mean", "(", ")", "\n", "return", "cov_loss", "\n", "\n", "\n", "", "def", "vibcreg_loss_func", "(", "\n", "z1", ":", "torch", ".", "Tensor", ",", "\n", "z2", ":", "torch", ".", "Tensor", ",", "\n", "sim_loss_weight", ":", "float", "=", "25.0", ",", "\n", "var_loss_weight", ":", "float", "=", "25.0", ",", "\n", "cov_loss_weight", ":", "float", "=", "200.0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    "]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vibcreg.VIbCReg.add_model_specific_args": [[70, 85], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["\n", "sim_loss", "=", "invariance_loss", "(", "z1", ",", "z2", ")", "\n", "# vicreg's official coded gathers the tensors here, so it's likely to benefit vibcreg", "\n", "# https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py", "\n", "z1", ",", "z2", "=", "gather", "(", "z1", ")", ",", "gather", "(", "z2", ")", "\n", "\n", "var_loss", "=", "variance_loss", "(", "z1", ",", "z2", ")", "\n", "cov_loss", "=", "covariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "loss", "=", "sim_loss_weight", "*", "sim_loss", "+", "var_loss_weight", "*", "var_loss", "+", "cov_loss_weight", "*", "cov_loss", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vibcreg.VIbCReg.learnable_params": [[86, 96], ["vibcreg.VIbCReg.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vibcreg.VIbCReg.forward": [[97, 111], ["super().forward", "vibcreg.VIbCReg.projector", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vibcreg.VIbCReg.training_step": [[112, 140], ["super().training_step", "solo.losses.vibcreg.vibcreg_loss_func", "vibcreg.VIbCReg.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vibcreg.vibcreg_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.__init__": [[30, 48], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "proj_output_dim", ":", "int", ",", "proj_hidden_dim", ":", "int", ",", "temperature", ":", "float", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Implements SupCon (https://arxiv.org/abs/2004.11362).\n\n        Args:\n            proj_output_dim (int): number of dimensions of the projected features.\n            proj_hidden_dim (int): number of neurons in the hidden layers of the projector.\n            temperature (float): temperature for the softmax in the contrastive loss.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.add_model_specific_args": [[50, 63], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "SupCon", ",", "SupCon", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"supcon\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.learnable_params": [[64, 74], ["supcon.SupCon.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters to the parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.forward": [[75, 90], ["super().forward", "supcon.SupCon.projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass of the backbone and the projector.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]:\n                a dict containing the outputs of the parent\n                and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ")", "\n", "z", "=", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", "\n", "return", "{", "**", "out", ",", "\"z\"", ":", "z", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.multicrop_forward": [[91, 106], ["super().multicrop_forward", "supcon.SupCon.projector", "super().multicrop_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "multicrop_forward", "(", "self", ",", "X", ":", "torch", ".", "tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the forward pass for the multicrop views.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict[]: a dict containing the outputs of the parent\n                and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "multicrop_forward", "(", "X", ")", "\n", "z", "=", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", "\n", "out", ".", "update", "(", "{", "\"z\"", ":", "z", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.supcon.SupCon.training_step": [[107, 138], ["super().training_step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "targets.repeat.repeat.repeat", "solo.losses.simclr.simclr_loss_func", "supcon.SupCon.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.simclr.simclr_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Training step for SupCon reusing BaseMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of SupCon loss and classification loss.\n        \"\"\"", "\n", "\n", "targets", "=", "batch", "[", "-", "1", "]", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "z", "=", "torch", ".", "cat", "(", "out", "[", "\"z\"", "]", ")", "\n", "\n", "# ------- contrastive loss -------", "\n", "n_augs", "=", "self", ".", "num_large_crops", "+", "self", ".", "num_small_crops", "\n", "targets", "=", "targets", ".", "repeat", "(", "n_augs", ")", "\n", "\n", "nce_loss", "=", "simclr_loss_func", "(", "\n", "z", ",", "\n", "indexes", "=", "targets", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "self", ".", "log", "(", "\"train_nce_loss\"", ",", "nce_loss", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "nce_loss", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.__init__": [[31, 77], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["\n", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "tensors_gather", "=", "[", "\n", "torch", ".", "ones_like", "(", "tensor", ")", "for", "_", "in", "range", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", ")", "\n", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "tensors_gather", ",", "tensor", ",", "async_op", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "tensors_gather", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "", "return", "tensor", "\n", "\n", "\n", "", "def", "mocov3_loss_func", "(", "query", ":", "torch", ".", "Tensor", ",", "key", ":", "torch", ".", "Tensor", ",", "temperature", "=", "0.2", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes MoCo V3's loss given a batch of queries from view 1, a batch of keys from view 2 and a\n    queue of past elements.\n\n    Args:\n        query (torch.Tensor): NxD Tensor containing the queries from view 1.\n        key (torch.Tensor): NxD Tensor containing the keys from view 2.\n        temperature (float, optional): temperature of the softmax in the contrastive\n            loss. Defaults to 0.2.\n\n    Returns:\n        torch.Tensor: MoCo loss.\n    \"\"\"", "\n", "\n", "n", "=", "query", ".", "size", "(", "0", ")", "\n", "device", "=", "query", ".", "device", "\n", "rank", "=", "dist", ".", "get_rank", "(", ")", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", "else", "0", "\n", "\n", "query", "=", "F", ".", "normalize", "(", "query", ",", "dim", "=", "1", ")", "\n", "key", "=", "F", ".", "normalize", "(", "key", ",", "dim", "=", "1", ")", "\n", "\n", "# gather all targets without gradients", "\n", "key", "=", "concat_all_gather_no_grad", "(", "key", ")", "\n", "\n", "logits", "=", "torch", ".", "einsum", "(", "\"nc,mc->nm\"", ",", "[", "query", ",", "key", "]", ")", "/", "temperature", "\n", "labels", "=", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "+", "n", "*", "rank", "\n", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "labels", ")", "*", "(", "2", "*", "temperature", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.add_model_specific_args": [[79, 95], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.learnable_params": [[96, 109], ["mocov3.MoCoV3.projector.parameters", "mocov3.MoCoV3.predictor.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.momentum_pairs": [[110, 120], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.forward": [[121, 135], ["super().forward", "mocov3.MoCoV3.predictor", "super().forward.update", "mocov3.MoCoV3.projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.momentum_forward": [[136, 152], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "mocov3.MoCoV3.momentum_projector", "super().momentum_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.mocov3.MoCoV3.training_step": [[153, 178], ["super().training_step", "mocov3.MoCoV3.log_dict", "solo.losses.mocov3.mocov3_loss_func", "solo.losses.mocov3.mocov3_loss_func"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.mocov3_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.mocov3.mocov3_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.__init__": [[34, 82], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nnclr.NNCLR.register_buffer", "nnclr.NNCLR.register_buffer", "torch.normalize", "torch.normalize", "torch.normalize", "nnclr.NNCLR.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "nn", "=", "F", ".", "normalize", "(", "nn", ",", "dim", "=", "-", "1", ")", "\n", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "# to be consistent with simclr, we now gather p", "\n", "# this might result in suboptimal results given previous parameters.", "\n", "p", "=", "gather", "(", "p", ")", "\n", "\n", "logits", "=", "nn", "@", "p", ".", "T", "/", "temperature", "\n", "\n", "rank", "=", "get_rank", "(", ")", "\n", "n", "=", "nn", ".", "size", "(", "0", ")", "\n", "labels", "=", "torch", ".", "arange", "(", "n", "*", "rank", ",", "n", "*", "(", "rank", "+", "1", ")", ",", "device", "=", "p", ".", "device", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.add_model_specific_args": [[83, 101], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.learnable_params": [[102, 115], ["nnclr.NNCLR.projector.parameters", "nnclr.NNCLR.predictor.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.dequeue_and_enqueue": [[116, 139], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "solo.utils.misc.gather", "solo.utils.misc.gather", "int"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.find_nn": [[140, 155], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.forward": [[156, 174], ["super().forward", "nnclr.NNCLR.projector", "nnclr.NNCLR.predictor", "torch.normalize", "torch.normalize", "torch.normalize", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnclr.NNCLR.training_step": [[175, 218], ["super().training_step", "nnclr.NNCLR.find_nn", "nnclr.NNCLR.find_nn", "targets.size", "nnclr.NNCLR.dequeue_and_enqueue", "nnclr.NNCLR.log_dict", "solo.losses.nnclr.nnclr_loss_func", "solo.losses.nnclr.nnclr_loss_func"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.dequeue_and_enqueue", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.nnclr.nnclr_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.nnclr.nnclr_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.barlow_twins.BarlowTwins.__init__": [[30, 56], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "proj_hidden_dim", ":", "int", ",", "proj_output_dim", ":", "int", ",", "lamb", ":", "float", ",", "scale_loss", ":", "float", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Implements Barlow Twins (https://arxiv.org/abs/2103.03230)\n\n        Args:\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            proj_output_dim (int): number of dimensions of projected features.\n            lamb (float): off-diagonal scaling factor for the cross-covariance matrix.\n            scale_loss (float): scaling factor of the loss.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "lamb", "=", "lamb", "\n", "self", ".", "scale_loss", "=", "scale_loss", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.barlow_twins.BarlowTwins.add_model_specific_args": [[58, 71], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "BarlowTwins", ",", "BarlowTwins", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"barlow_twins\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# parameters", "\n", "parser", ".", "add_argument", "(", "\"--lamb\"", ",", "type", "=", "float", ",", "default", "=", "0.0051", ")", "\n", "parser", ".", "add_argument", "(", "\"--scale_loss\"", ",", "type", "=", "float", ",", "default", "=", "0.024", ")", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.barlow_twins.BarlowTwins.learnable_params": [[72, 82], ["barlow_twins.BarlowTwins.projector.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector parameters to parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.barlow_twins.BarlowTwins.forward": [[83, 97], ["super().forward", "barlow_twins.BarlowTwins.projector", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"Performs the forward pass of the backbone and the projector.\n\n        Args:\n            X (torch.Tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the projected features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ")", "\n", "z", "=", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", "\n", "out", ".", "update", "(", "{", "\"z\"", ":", "z", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.barlow_twins.BarlowTwins.training_step": [[98, 120], ["super().training_step", "solo.losses.barlow.barlow_loss_func", "barlow_twins.BarlowTwins.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.barlow.barlow_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Training step for Barlow Twins reusing BaseMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of Barlow loss and classification loss.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "z1", ",", "z2", "=", "out", "[", "\"z\"", "]", "\n", "\n", "# ------- barlow twins loss -------", "\n", "barlow_loss", "=", "barlow_loss_func", "(", "z1", ",", "z2", ",", "lamb", "=", "self", ".", "lamb", ",", "scale_loss", "=", "self", ".", "scale_loss", ")", "\n", "\n", "self", ".", "log", "(", "\"train_barlow_loss\"", ",", "barlow_loss", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "barlow_loss", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vicreg.VICReg.__init__": [[30, 64], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "return", "F", ".", "mse_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "\n", "", "def", "variance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Computes variance loss given batch of projected features z1 from view 1 and\n    projected features z2 from view 2.\n\n    Args:\n        z1 (torch.Tensor): NxD Tensor containing projected features from view 1.\n        z2 (torch.Tensor): NxD Tensor containing projected features from view 2.\n\n    Returns:\n        torch.Tensor: variance regularization loss.\n    \"\"\"", "\n", "\n", "eps", "=", "1e-4", "\n", "std_z1", "=", "torch", ".", "sqrt", "(", "z1", ".", "var", "(", "dim", "=", "0", ")", "+", "eps", ")", "\n", "std_z2", "=", "torch", ".", "sqrt", "(", "z2", ".", "var", "(", "dim", "=", "0", ")", "+", "eps", ")", "\n", "std_loss", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_z1", ")", ")", "+", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_z2", ")", ")", "\n", "return", "std_loss", "\n", "\n", "\n", "", "def", "covariance_loss", "(", "z1", ":", "torch", ".", "Tensor", ",", "z2", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    "]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vicreg.VICReg.add_model_specific_args": [[66, 80], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["\n", "\n", "N", ",", "D", "=", "z1", ".", "size", "(", ")", "\n", "\n", "z1", "=", "z1", "-", "z1", ".", "mean", "(", "dim", "=", "0", ")", "\n", "z2", "=", "z2", "-", "z2", ".", "mean", "(", "dim", "=", "0", ")", "\n", "cov_z1", "=", "(", "z1", ".", "T", "@", "z1", ")", "/", "(", "N", "-", "1", ")", "\n", "cov_z2", "=", "(", "z2", ".", "T", "@", "z2", ")", "/", "(", "N", "-", "1", ")", "\n", "\n", "diag", "=", "torch", ".", "eye", "(", "D", ",", "device", "=", "z1", ".", "device", ")", "\n", "cov_loss", "=", "cov_z1", "[", "~", "diag", ".", "bool", "(", ")", "]", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "/", "D", "+", "cov_z2", "[", "~", "diag", ".", "bool", "(", ")", "]", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "/", "D", "\n", "return", "cov_loss", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vicreg.VICReg.learnable_params": [[81, 91], ["vicreg.VICReg.projector.parameters"], "methods", ["None"], ["\n", "\n", "", "def", "vicreg_loss_func", "(", "\n", "z1", ":", "torch", ".", "Tensor", ",", "\n", "z2", ":", "torch", ".", "Tensor", ",", "\n", "sim_loss_weight", ":", "float", "=", "25.0", ",", "\n", "var_loss_weight", ":", "float", "=", "25.0", ",", "\n", "cov_loss_weight", ":", "float", "=", "1.0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    "]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vicreg.VICReg.forward": [[92, 106], ["super().forward", "vicreg.VICReg.projector", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["\n", "\n", "sim_loss", "=", "invariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "# vicreg's official code gathers the tensors here", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.vicreg.VICReg.training_step": [[107, 135], ["super().training_step", "solo.losses.vicreg.vicreg_loss_func", "vicreg.VICReg.log"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.vicreg.vicreg_loss_func"], ["# https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py", "\n", "z1", ",", "z2", "=", "gather", "(", "z1", ")", ",", "gather", "(", "z2", ")", "\n", "\n", "var_loss", "=", "variance_loss", "(", "z1", ",", "z2", ")", "\n", "cov_loss", "=", "covariance_loss", "(", "z1", ",", "z2", ")", "\n", "\n", "loss", "=", "sim_loss_weight", "*", "sim_loss", "+", "var_loss_weight", "*", "var_loss", "+", "cov_loss_weight", "*", "cov_loss", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.wmse.WMSE.__init__": [[30, 65], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "solo.utils.whitening.Whitening2d", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "2", "-", "2", "*", "F", ".", "cosine_similarity", "(", "z1", ",", "z2", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "z1", "=", "F", ".", "normalize", "(", "z1", ",", "dim", "=", "-", "1", ")", "\n", "z2", "=", "F", ".", "normalize", "(", "z2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "2", "-", "2", "*", "(", "z1", "*", "z2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.wmse.WMSE.add_model_specific_args": [[66, 81], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.wmse.WMSE.learnable_params": [[82, 92], ["wmse.WMSE.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.wmse.WMSE.forward": [[93, 107], ["super().forward", "wmse.WMSE.projector", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.wmse.WMSE.training_step": [[108, 144], ["super().training_step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "wmse.WMSE.log", "torch.empty_like", "torch.empty_like", "torch.empty_like", "torch.empty_like", "torch.randperm().view", "torch.randperm().view", "torch.randperm().view", "torch.randperm().view", "range", "range", "range", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "wmse.WMSE.whitening().type_as", "solo.losses.wmse.wmse_loss_func", "wmse.WMSE.whitening"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.wmse.wmse_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.__init__": [[32, 83], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.utils.weight_norm", "torch.utils.weight_norm", "torch.utils.weight_norm", "swav.SwAV.prototypes.weight_g.data.fill_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "\n", "losses", "=", "[", "]", "\n", "for", "v1", ",", "a", "in", "enumerate", "(", "assignments", ")", ":", "\n", "        ", "for", "v2", "in", "np", ".", "delete", "(", "np", ".", "arange", "(", "len", "(", "preds", ")", ")", ",", "v1", ")", ":", "\n", "            ", "p", "=", "preds", "[", "v2", "]", "/", "temperature", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "a", "*", "torch", ".", "log_softmax", "(", "p", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ")", "\n", "losses", ".", "append", "(", "loss", ")", "\n", "", "", "return", "sum", "(", "losses", ")", "/", "len", "(", "losses", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.add_model_specific_args": [[84, 104], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.learnable_params": [[105, 118], ["swav.SwAV.projector.parameters", "swav.SwAV.prototypes.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.on_train_start": [[119, 133], ["solo.utils.sinkhorn_knopp.SinkhornKnopp", "swav.SwAV.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.forward": [[136, 154], ["super().forward", "swav.SwAV.projector", "torch.normalize", "torch.normalize", "torch.normalize", "swav.SwAV.prototypes", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.multicrop_forward": [[155, 173], ["super().multicrop_forward", "swav.SwAV.projector", "torch.normalize", "torch.normalize", "torch.normalize", "swav.SwAV.prototypes", "super().multicrop_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.get_assignments": [[174, 195], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "preds[].size", "enumerate", "assignments.append", "swav.SwAV.prototypes", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "swav.SwAV.sk"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.training_step": [[196, 225], ["super().training_step", "swav.SwAV.get_assignments", "solo.losses.swav.swav_loss_func", "swav.SwAV.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "swav.SwAV.queue[].clone", "torch.stack.detach", "torch.stack.detach", "torch.stack.detach", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size", "torch.stack.size"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.get_assignments", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.swav.swav_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.swav.SwAV.on_after_backward": [[226, 231], ["swav.SwAV.prototypes.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.__init__": [[51, 124], ["pytorch_lightning.LightningModule.__init__", "hasattr", "torch.Linear", "torch.Linear", "torch.Linear", "linear.LinearModel.backbone.parameters", "linear.LinearModel.to"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "backbone", ":", "nn", ".", "Module", ",", "\n", "num_classes", ":", "int", ",", "\n", "max_epochs", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "\n", "optimizer", ":", "str", ",", "\n", "lr", ":", "float", ",", "\n", "weight_decay", ":", "float", ",", "\n", "extra_optimizer_args", ":", "dict", ",", "\n", "scheduler", ":", "str", ",", "\n", "min_lr", ":", "float", ",", "\n", "warmup_start_lr", ":", "float", ",", "\n", "warmup_epochs", ":", "float", ",", "\n", "lr_decay_steps", ":", "Optional", "[", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "no_channel_last", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implements linear evaluation.\n\n        Args:\n            backbone (nn.Module): backbone architecture for feature extraction.\n            num_classes (int): number of classes in the dataset.\n            max_epochs (int): total number of epochs.\n            batch_size (int): batch size.\n            optimizer (str): optimizer to use.\n            weight_decay (float): weight decay.\n            extra_optimizer_args (dict): extra optimizer arguments.\n            scheduler (str): learning rate scheduler.\n            min_lr (float): minimum learning rate for warmup scheduler.\n            warmup_start_lr (float): initial learning rate for warmup scheduler.\n            warmup_epochs (float): number of warmup epochs.\n            lr_decay_steps (Optional[Sequence[int]], optional): list of epochs where the learning\n                rate will be decreased. Defaults to None.\n            no_channel_last (bool). Disables channel last conversion operation which\n                speeds up training considerably. Defaults to False.\n                https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html#converting-existing-models\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "backbone", "=", "backbone", "\n", "if", "hasattr", "(", "self", ".", "backbone", ",", "\"inplanes\"", ")", ":", "\n", "            ", "features_dim", "=", "self", ".", "backbone", ".", "inplanes", "\n", "", "else", ":", "\n", "            ", "features_dim", "=", "self", ".", "backbone", ".", "num_features", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "features_dim", ",", "num_classes", ")", "# type: ignore", "\n", "\n", "# training related", "\n", "self", ".", "max_epochs", "=", "max_epochs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "self", ".", "extra_optimizer_args", "=", "extra_optimizer_args", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "self", ".", "warmup_start_lr", "=", "warmup_start_lr", "\n", "self", ".", "warmup_epochs", "=", "warmup_epochs", "\n", "self", ".", "lr_decay_steps", "=", "lr_decay_steps", "\n", "self", ".", "no_channel_last", "=", "no_channel_last", "\n", "\n", "self", ".", "_num_training_steps", "=", "None", "\n", "\n", "# all the other parameters", "\n", "self", ".", "extra_args", "=", "kwargs", "\n", "\n", "for", "param", "in", "self", ".", "backbone", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "# can provide up to ~20% speed up", "\n", "", "if", "not", "no_channel_last", ":", "\n", "            ", "self", "=", "self", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.add_model_specific_args": [[125, 175], ["parent_parser.add_argument_group", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "parent_parser.add_argument_group.add_argument", "LinearModel._OPTIMIZERS.keys"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "        ", "\"\"\"Adds basic linear arguments.\n\n        Args:\n            parent_parser (ArgumentParser): argument parser that is used to create a\n                argument group.\n\n        Returns:\n            ArgumentParser: same as the argument, used to avoid errors.\n        \"\"\"", "\n", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"linear\"", ")", "\n", "\n", "# backbone args", "\n", "parser", ".", "add_argument", "(", "\"--backbone\"", ",", "choices", "=", "BaseMethod", ".", "_BACKBONES", ",", "type", "=", "str", ")", "\n", "# for ViT", "\n", "parser", ".", "add_argument", "(", "\"--patch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "# general train", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier_lr\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "0.0001", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "\n", "# wandb", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--project\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--entity\"", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--wandb\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--offline\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--optimizer\"", ",", "choices", "=", "LinearModel", ".", "_OPTIMIZERS", ".", "keys", "(", ")", ",", "type", "=", "str", ",", "required", "=", "True", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--exclude_bias_n_norm\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--scheduler\"", ",", "choices", "=", "LinearModel", ".", "_SCHEDULERS", ",", "type", "=", "str", ",", "default", "=", "\"reduce\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_decay_steps\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_lr\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_start_lr\"", ",", "default", "=", "0.003", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "\n", "# disables channel last optimization", "\n", "parser", ".", "add_argument", "(", "\"--no_channel_last\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.num_training_steps": [[176, 215], ["linear.LinearModel.extra_args.get", "linear.LinearModel.extra_args.get", "linear.LinearModel.extra_args.get", "solo.utils.misc.compute_dataset_size", "linear.LinearModel.extra_args.get", "linear.LinearModel.extra_args.get", "linear.LinearModel.extra_args.get", "os.path.join", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.compute_dataset_size"], ["", "@", "property", "\n", "def", "num_training_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Compute the number of training steps for each epoch.\"\"\"", "\n", "\n", "if", "self", ".", "_num_training_steps", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "dataset", "=", "self", ".", "extra_args", ".", "get", "(", "\"dataset\"", ",", "None", ")", "\n", "if", "dataset", "not", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"stl10\"", "]", ":", "\n", "                    ", "data_dir", "=", "self", ".", "extra_args", ".", "get", "(", "\"data_dir\"", ",", "\".\"", ")", "\n", "train_dir", "=", "self", ".", "extra_args", ".", "get", "(", "\"train_dir\"", ",", "\"train\"", ")", "\n", "folder", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "train_dir", ")", "\n", "", "else", ":", "\n", "                    ", "folder", "=", "None", "\n", "", "no_labels", "=", "self", ".", "extra_args", ".", "get", "(", "\"no_labels\"", ",", "False", ")", "\n", "data_fraction", "=", "self", ".", "extra_args", ".", "get", "(", "\"data_fraction\"", ",", "-", "1.0", ")", "\n", "\n", "dataset_size", "=", "compute_dataset_size", "(", "\n", "dataset", "=", "dataset", ",", "\n", "folder", "=", "folder", ",", "\n", "train", "=", "True", ",", "\n", "no_labels", "=", "no_labels", ",", "\n", "data_fraction", "=", "data_fraction", ",", "\n", ")", "\n", "", "except", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Please pass 'dataset' or 'data_dir '\"", "\n", "\"and 'train_dir' as parameters to the model.\"", "\n", ")", "\n", "\n", "", "dataset_size", "=", "self", ".", "trainer", ".", "limit_train_batches", "*", "dataset_size", "\n", "\n", "num_devices", "=", "self", ".", "trainer", ".", "num_devices", "\n", "num_nodes", "=", "self", ".", "extra_args", ".", "get", "(", "\"num_nodes_horovod\"", ",", "0", ")", "or", "self", ".", "trainer", ".", "num_nodes", "or", "1", "\n", "effective_batch_size", "=", "(", "\n", "self", ".", "batch_size", "*", "self", ".", "trainer", ".", "accumulate_grad_batches", "*", "num_devices", "*", "num_nodes", "\n", ")", "\n", "self", ".", "_num_training_steps", "=", "dataset_size", "//", "effective_batch_size", "\n", "\n", "", "return", "self", ".", "_num_training_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.forward": [[216, 233], ["linear.LinearModel.classifier", "X.to.to.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "linear.LinearModel.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "tensor", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs forward pass of the frozen backbone and the linear layer for evaluation.\n\n        Args:\n            X (torch.tensor): a batch of images in the tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing features and logits.\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "no_channel_last", ":", "\n", "            ", "X", "=", "X", ".", "to", "(", "memory_format", "=", "torch", ".", "channels_last", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "feats", "=", "self", ".", "backbone", "(", "X", ")", "\n", "", "logits", "=", "self", ".", "classifier", "(", "feats", ")", "\n", "return", "{", "\"logits\"", ":", "logits", ",", "\"feats\"", ":", "feats", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers": [[234, 284], ["optimizer.", "linear.LinearModel.classifier.parameters", "pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "ValueError"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", ",", "List", "]", ":", "\n", "        ", "\"\"\"Configures the optimizer for the linear layer.\n\n        Raises:\n            ValueError: if the optimizer is not in (sgd, adam).\n            ValueError: if the scheduler is not in not in (warmup_cosine, cosine, reduce, step,\n                exponential).\n\n        Returns:\n            Tuple[List, List]: two lists containing the optimizer and the scheduler.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "optimizer", "in", "self", ".", "_OPTIMIZERS", "\n", "optimizer", "=", "self", ".", "_OPTIMIZERS", "[", "self", ".", "optimizer", "]", "\n", "\n", "optimizer", "=", "optimizer", "(", "\n", "self", ".", "classifier", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", "**", "self", ".", "extra_optimizer_args", ",", "\n", ")", "\n", "\n", "# select scheduler", "\n", "if", "self", ".", "scheduler", "==", "\"none\"", ":", "\n", "            ", "return", "optimizer", "\n", "\n", "", "if", "self", ".", "scheduler", "==", "\"warmup_cosine\"", ":", "\n", "            ", "scheduler", "=", "{", "\n", "\"scheduler\"", ":", "LinearWarmupCosineAnnealingLR", "(", "\n", "optimizer", ",", "\n", "warmup_epochs", "=", "self", ".", "warmup_epochs", "*", "self", ".", "num_training_steps", ",", "\n", "max_epochs", "=", "self", ".", "max_epochs", "*", "self", ".", "num_training_steps", ",", "\n", "warmup_start_lr", "=", "self", ".", "warmup_start_lr", "if", "self", ".", "warmup_epochs", ">", "0", "else", "self", ".", "lr", ",", "\n", "eta_min", "=", "self", ".", "min_lr", ",", "\n", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "\"frequency\"", ":", "1", ",", "\n", "}", "\n", "", "elif", "self", ".", "scheduler", "==", "\"reduce\"", ":", "\n", "            ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ")", "\n", "", "elif", "self", ".", "scheduler", "==", "\"step\"", ":", "\n", "            ", "scheduler", "=", "MultiStepLR", "(", "optimizer", ",", "self", ".", "lr_decay_steps", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "self", ".", "scheduler", "==", "\"exponential\"", ":", "\n", "            ", "scheduler", "=", "ExponentialLR", "(", "optimizer", ",", "self", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{self.scheduler} not in (warmup_cosine, cosine, reduce, step, exponential)\"", "\n", ")", "\n", "\n", "", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.shared_step": [[285, 308], ["X.size", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "solo.utils.metrics.accuracy_at_k", "linear.LinearModel."], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.accuracy_at_k"], ["", "def", "shared_step", "(", "\n", "self", ",", "batch", ":", "Tuple", ",", "batch_idx", ":", "int", "\n", ")", "->", "Tuple", "[", "int", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Performs operations that are shared between the training nd validation steps.\n\n        Args:\n            batch (Tuple): a batch of images in the tensor format.\n            batch_idx (int): the index of the batch.\n\n        Returns:\n            Tuple[int, torch.Tensor, torch.Tensor, torch.Tensor]:\n                batch size, loss, accuracy @1 and accuracy @5.\n        \"\"\"", "\n", "\n", "X", ",", "target", "=", "batch", "\n", "batch_size", "=", "X", ".", "size", "(", "0", ")", "\n", "\n", "out", "=", "self", "(", "X", ")", "[", "\"logits\"", "]", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "out", ",", "target", ")", "\n", "\n", "acc1", ",", "acc5", "=", "accuracy_at_k", "(", "out", ",", "target", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "return", "batch_size", ",", "loss", ",", "acc1", ",", "acc5", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.training_step": [[309, 328], ["linear.LinearModel.backbone.eval", "linear.LinearModel.shared_step", "linear.LinearModel.log_dict"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.shared_step"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "torch", ".", "Tensor", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Performs the training step for the linear eval.\n\n        Args:\n            batch (torch.Tensor): a batch of images in the tensor format.\n            batch_idx (int): the index of the batch.\n\n        Returns:\n            torch.Tensor: cross-entropy loss between the predictions and the ground truth.\n        \"\"\"", "\n", "\n", "# set backbone to eval mode", "\n", "self", ".", "backbone", ".", "eval", "(", ")", "\n", "\n", "_", ",", "loss", ",", "acc1", ",", "acc5", "=", "self", ".", "shared_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "log", "=", "{", "\"train_loss\"", ":", "loss", ",", "\"train_acc1\"", ":", "acc1", ",", "\"train_acc5\"", ":", "acc5", "}", "\n", "self", ".", "log_dict", "(", "log", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.validation_step": [[329, 351], ["linear.LinearModel.shared_step"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.shared_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "torch", ".", "Tensor", ",", "batch_idx", ":", "int", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs the validation step for the linear eval.\n\n        Args:\n            batch (torch.Tensor): a batch of images in the tensor format.\n            batch_idx (int): the index of the batch.\n\n        Returns:\n            Dict[str, Any]:\n                dict with the batch_size (used for averaging),\n                the classification loss and accuracies.\n        \"\"\"", "\n", "\n", "batch_size", ",", "loss", ",", "acc1", ",", "acc5", "=", "self", ".", "shared_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n", "results", "=", "{", "\n", "\"batch_size\"", ":", "batch_size", ",", "\n", "\"val_loss\"", ":", "loss", ",", "\n", "\"val_acc1\"", ":", "acc1", ",", "\n", "\"val_acc5\"", ":", "acc5", ",", "\n", "}", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.validation_epoch_end": [[352, 367], ["solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "solo.utils.metrics.weighted_mean", "linear.LinearModel.log_dict"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.metrics.weighted_mean"], ["", "def", "validation_epoch_end", "(", "self", ",", "outs", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", ":", "\n", "        ", "\"\"\"Averages the losses and accuracies of all the validation batches.\n        This is needed because the last batch can be smaller than the others,\n        slightly skewing the metrics.\n\n        Args:\n            outs (List[Dict[str, Any]]): list of outputs of the validation step.\n        \"\"\"", "\n", "\n", "val_loss", "=", "weighted_mean", "(", "outs", ",", "\"val_loss\"", ",", "\"batch_size\"", ")", "\n", "val_acc1", "=", "weighted_mean", "(", "outs", ",", "\"val_acc1\"", ",", "\"batch_size\"", ")", "\n", "val_acc5", "=", "weighted_mean", "(", "outs", ",", "\"val_acc5\"", ",", "\"batch_size\"", ")", "\n", "\n", "log", "=", "{", "\"val_loss\"", ":", "val_loss", ",", "\"val_acc1\"", ":", "val_acc1", ",", "\"val_acc5\"", ":", "val_acc5", "}", "\n", "self", ".", "log_dict", "(", "log", ",", "sync_dist", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.__init__": [[33, 73], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["\n", "\n", "if", "simplified", ":", "\n", "        ", "return", "2", "-", "2", "*", "F", ".", "cosine_similarity", "(", "p", ",", "z", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "\n", "", "p", "=", "F", ".", "normalize", "(", "p", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "F", ".", "normalize", "(", "z", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "2", "-", "2", "*", "(", "p", "*", "z", ".", "detach", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.add_model_specific_args": [[75, 88], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.learnable_params": [[89, 102], ["byol.BYOL.projector.parameters", "byol.BYOL.predictor.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.momentum_pairs": [[103, 113], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.forward": [[114, 129], ["super().forward", "byol.BYOL.projector", "byol.BYOL.predictor", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward": [[130, 146], ["super().multicrop_forward", "byol.BYOL.projector", "byol.BYOL.predictor", "super().multicrop_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.momentum_forward": [[147, 163], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "byol.BYOL.momentum_projector", "super().momentum_forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.training_step": [[164, 199], ["super().training_step", "range", "byol.BYOL.log_dict", "numpy.delete", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "range", "solo.losses.byol.byol_loss_func", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize", "torch.normalize", "torch.normalize", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.__init__": [[33, 77], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "ressl.ReSSL.register_buffer", "torch.normalize", "torch.normalize", "torch.normalize", "ressl.ReSSL.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["\n", "\n", "logits_q", "=", "torch", ".", "einsum", "(", "\"nc,kc->nk\"", ",", "[", "q", ",", "queue", "]", ")", "\n", "logits_k", "=", "torch", ".", "einsum", "(", "\"nc,kc->nk\"", ",", "[", "k", ",", "queue", "]", ")", "\n", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "\n", "F", ".", "softmax", "(", "logits_k", ".", "detach", "(", ")", "/", "temperature_k", ",", "dim", "=", "1", ")", "\n", "*", "F", ".", "log_softmax", "(", "logits_q", "/", "temperature_q", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "\n", ")", ".", "mean", "(", ")", "\n", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.add_model_specific_args": [[78, 95], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.learnable_params": [[96, 108], ["ressl.ReSSL.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.momentum_pairs": [[109, 119], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.dequeue_and_enqueue": [[120, 139], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "solo.utils.misc.gather", "int"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.forward": [[140, 154], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "super().forward.update", "ressl.ReSSL.projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.momentum_forward": [[155, 170], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "torch.normalize", "torch.normalize", "torch.normalize", "super().momentum_forward.update", "ressl.ReSSL.momentum_projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.ressl.ReSSL.training_step": [[171, 198], ["super().training_step", "ressl.ReSSL.queue.clone().detach", "solo.losses.ressl.ressl_loss_func", "ressl.ReSSL.log", "ressl.ReSSL.dequeue_and_enqueue", "ressl.ReSSL.queue.clone"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.ressl.ressl_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.dequeue_and_enqueue"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.__init__": [[35, 92], ["solo.methods.base.BaseMomentumMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "solo.utils.momentum.initialize_momentum_params", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nnbyol.NNBYOL.register_buffer", "nnbyol.NNBYOL.register_buffer", "torch.normalize", "torch.normalize", "torch.normalize", "nnbyol.NNBYOL.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.initialize_momentum_params"], ["def", "__init__", "(", "\n", "self", ",", "\n", "proj_output_dim", ":", "int", ",", "\n", "proj_hidden_dim", ":", "int", ",", "\n", "pred_hidden_dim", ":", "int", ",", "\n", "queue_size", ":", "int", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Implements NNBYOL (https://arxiv.org/abs/2104.14548).\n\n        Args:\n            proj_output_dim (int): number of dimensions of projected features.\n            proj_hidden_dim (int): number of neurons of the hidden layers of the projector.\n            pred_hidden_dim (int): number of neurons of the hidden layers of the predictor.\n            queue_size (int): number of samples to keep in the queue.\n\n        .. note::\n            NNBYOL is similar to NNSiam but the queue from which the neighbors are retrieved is\n            updated using the features of the momentum backbone. See NNCLR's paper for more details:\n            https://arxiv.org/abs/2104.14548\n\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "queue_size", "=", "queue_size", "\n", "\n", "# projector", "\n", "self", ".", "projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# momentum projector", "\n", "self", ".", "momentum_projector", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "features_dim", ",", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "proj_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "proj_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "initialize_momentum_params", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "\n", "\n", "# predictor", "\n", "self", ".", "predictor", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "proj_output_dim", ",", "pred_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "pred_hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "pred_hidden_dim", ",", "proj_output_dim", ")", ",", "\n", ")", "\n", "\n", "# queue", "\n", "self", ".", "register_buffer", "(", "\"queue\"", ",", "torch", ".", "randn", "(", "self", ".", "queue_size", ",", "proj_output_dim", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_y\"", ",", "-", "torch", ".", "ones", "(", "self", ".", "queue_size", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "self", ".", "queue", "=", "F", ".", "normalize", "(", "self", ".", "queue", ",", "dim", "=", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"queue_ptr\"", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.add_model_specific_args": [[93, 109], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ":", "argparse", ".", "ArgumentParser", ")", "->", "argparse", ".", "ArgumentParser", ":", "\n", "        ", "parent_parser", "=", "super", "(", "NNBYOL", ",", "NNBYOL", ")", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "parent_parser", ".", "add_argument_group", "(", "\"byol\"", ")", "\n", "\n", "# projector", "\n", "parser", ".", "add_argument", "(", "\"--proj_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "# predictor", "\n", "parser", ".", "add_argument", "(", "\"--pred_hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "\n", "# queue settings", "\n", "parser", ".", "add_argument", "(", "\"--queue_size\"", ",", "default", "=", "65536", ",", "type", "=", "int", ")", "\n", "\n", "return", "parent_parser", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.learnable_params": [[110, 123], ["nnbyol.NNBYOL.projector.parameters", "nnbyol.NNBYOL.predictor.parameters"], "methods", ["None"], ["", "@", "property", "\n", "def", "learnable_params", "(", "self", ")", "->", "List", "[", "dict", "]", ":", "\n", "        ", "\"\"\"Adds projector and predictor parameters to the parent's learnable parameters.\n\n        Returns:\n            List[dict]: list of learnable parameters.\n        \"\"\"", "\n", "\n", "extra_learnable_params", "=", "[", "\n", "{", "\"params\"", ":", "self", ".", "projector", ".", "parameters", "(", ")", "}", ",", "\n", "{", "\"params\"", ":", "self", ".", "predictor", ".", "parameters", "(", ")", "}", ",", "\n", "]", "\n", "return", "super", "(", ")", ".", "learnable_params", "+", "extra_learnable_params", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_pairs": [[124, 134], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "momentum_pairs", "(", "self", ")", "->", "List", "[", "Tuple", "[", "Any", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Adds (projector, momentum_projector) to the parent's momentum pairs.\n\n        Returns:\n            List[Tuple[Any, Any]]: list of momentum pairs.\n        \"\"\"", "\n", "\n", "extra_momentum_pairs", "=", "[", "(", "self", ".", "projector", ",", "self", ".", "momentum_projector", ")", "]", "\n", "return", "super", "(", ")", ".", "momentum_pairs", "+", "extra_momentum_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.dequeue_and_enqueue": [[135, 158], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "solo.utils.misc.gather", "solo.utils.misc.gather", "int"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.misc.gather"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "dequeue_and_enqueue", "(", "self", ",", "z", ":", "torch", ".", "Tensor", ",", "y", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Adds new samples and removes old samples from the queue in a fifo manner. Also stores\n        the labels of the samples.\n\n        Args:\n            z (torch.Tensor): batch of projected features.\n            y (torch.Tensor): labels of the samples in the batch.\n        \"\"\"", "\n", "\n", "z", "=", "gather", "(", "z", ")", "\n", "y", "=", "gather", "(", "y", ")", "\n", "\n", "batch_size", "=", "z", ".", "shape", "[", "0", "]", "\n", "\n", "ptr", "=", "int", "(", "self", ".", "queue_ptr", ")", "# type: ignore", "\n", "assert", "self", ".", "queue_size", "%", "batch_size", "==", "0", "\n", "\n", "self", ".", "queue", "[", "ptr", ":", "ptr", "+", "batch_size", ",", ":", "]", "=", "z", "\n", "self", ".", "queue_y", "[", "ptr", ":", "ptr", "+", "batch_size", "]", "=", "y", "# type: ignore", "\n", "ptr", "=", "(", "ptr", "+", "batch_size", ")", "%", "self", ".", "queue_size", "\n", "\n", "self", ".", "queue_ptr", "[", "0", "]", "=", "ptr", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn": [[159, 174], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "find_nn", "(", "self", ",", "z", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Finds the nearest neighbor of a sample.\n\n        Args:\n            z (torch.Tensor): a batch of projected features.\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]:\n                indices and projected features of the nearest neighbors.\n        \"\"\"", "\n", "\n", "idx", "=", "(", "z", "@", "self", ".", "queue", ".", "T", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "1", "]", "\n", "nn", "=", "self", ".", "queue", "[", "idx", "]", "\n", "return", "idx", ",", "nn", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.forward": [[175, 192], ["super().forward", "nnbyol.NNBYOL.projector", "nnbyol.NNBYOL.predictor", "super().forward.update"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Performs forward pass of the online backbone, projector and predictor.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict[str, Any]:\n                a dict containing the outputs of the parent, the projected features and the\n                predicted features.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "X", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "z", "=", "self", ".", "projector", "(", "out", "[", "\"feats\"", "]", ")", "\n", "p", "=", "self", ".", "predictor", "(", "z", ")", "\n", "out", ".", "update", "(", "{", "\"z\"", ":", "z", ",", "\"p\"", ":", "p", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward": [[193, 208], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "super().momentum_forward", "torch.normalize", "torch.normalize", "torch.normalize", "super().momentum_forward.update", "nnbyol.NNBYOL.momentum_projector"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "momentum_forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"Performs the forward pass of the momentum backbone and projector.\n\n        Args:\n            X (torch.Tensor): batch of images in tensor format.\n\n        Returns:\n            Dict[str, Any]: a dict containing the outputs of the parent and the key.\n        \"\"\"", "\n", "\n", "out", "=", "super", "(", ")", ".", "momentum_forward", "(", "X", ")", "\n", "z", "=", "F", ".", "normalize", "(", "self", ".", "momentum_projector", "(", "out", "[", "\"feats\"", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "out", ".", "update", "(", "{", "\"z\"", ":", "z", "}", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.training_step": [[209, 256], ["super().training_step", "nnbyol.NNBYOL.find_nn", "nnbyol.NNBYOL.find_nn", "targets.size", "nnbyol.NNBYOL.dequeue_and_enqueue", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "torch.normalize().std().mean", "nnbyol.NNBYOL.log_dict", "solo.losses.byol.byol_loss_func", "solo.losses.byol.byol_loss_func", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize().std", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.find_nn", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.dequeue_and_enqueue", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.byol.byol_loss_func"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "Sequence", "[", "Any", "]", ",", "batch_idx", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Training step for NNBYOL reusing BaseMethod training step.\n\n        Args:\n            batch (Sequence[Any]): a batch of data in the format of [img_indexes, [X], Y], where\n                [X] is a list of size num_crops containing batches of images.\n            batch_idx (int): index of the batch.\n\n        Returns:\n            torch.Tensor: total loss composed of NNBYOL and classification loss.\n        \"\"\"", "\n", "\n", "targets", "=", "batch", "[", "-", "1", "]", "\n", "\n", "out", "=", "super", "(", ")", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "class_loss", "=", "out", "[", "\"loss\"", "]", "\n", "z1", ",", "z2", "=", "out", "[", "\"z\"", "]", "\n", "p1", ",", "p2", "=", "out", "[", "\"p\"", "]", "\n", "z1_momentum", ",", "z2_momentum", "=", "out", "[", "\"momentum_z\"", "]", "\n", "\n", "# find nn", "\n", "idx1", ",", "nn1_momentum", "=", "self", ".", "find_nn", "(", "z1_momentum", ")", "\n", "_", ",", "nn2_momentum", "=", "self", ".", "find_nn", "(", "z2_momentum", ")", "\n", "\n", "# ------- negative cosine similarity loss -------", "\n", "neg_cos_sim", "=", "byol_loss_func", "(", "p1", ",", "nn2_momentum", ")", "+", "byol_loss_func", "(", "p2", ",", "nn1_momentum", ")", "\n", "\n", "# compute nn accuracy", "\n", "b", "=", "targets", ".", "size", "(", "0", ")", "\n", "nn_acc", "=", "(", "targets", "==", "self", ".", "queue_y", "[", "idx1", "]", ")", ".", "sum", "(", ")", "/", "b", "\n", "\n", "# dequeue and enqueue", "\n", "self", ".", "dequeue_and_enqueue", "(", "z1_momentum", ",", "targets", ")", "\n", "\n", "# calculate std of features", "\n", "z1_std", "=", "F", ".", "normalize", "(", "z1", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z2_std", "=", "F", ".", "normalize", "(", "z2", ",", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "0", ")", ".", "mean", "(", ")", "\n", "z_std", "=", "(", "z1_std", "+", "z2_std", ")", "/", "2", "\n", "\n", "metrics", "=", "{", "\n", "\"train_neg_cos_sim\"", ":", "neg_cos_sim", ",", "\n", "\"train_z_std\"", ":", "z_std", ",", "\n", "\"train_nn_acc\"", ":", "nn_acc", ",", "\n", "}", "\n", "self", ".", "log_dict", "(", "metrics", ",", "on_epoch", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n", "return", "neg_cos_sim", "+", "class_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.__init__": [[32, 75], ["solo.methods.base.BaseMethod.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "proto.parameters", "proto.weight.copy_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.normalize", "torch.normalize", "torch.normalize", "proto.weight.data.clone"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__"], ["\n", "loss", "=", "0", "\n", "for", "h", "in", "range", "(", "outputs", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "scores", "=", "outputs", "[", "h", "]", ".", "view", "(", "-", "1", ",", "outputs", ".", "size", "(", "-", "1", ")", ")", "/", "temperature", "\n", "targets", "=", "assignments", "[", "h", "]", ".", "repeat", "(", "outputs", ".", "size", "(", "1", ")", ")", ".", "to", "(", "outputs", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "scores", ",", "targets", ",", "ignore_index", "=", "-", "1", ")", "\n", "", "return", "loss", "/", "outputs", ".", "size", "(", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args": [[76, 91], ["super().add_model_specific_args", "super().add_model_specific_args.add_argument_group", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument", "super().add_model_specific_args.add_argument_group.add_argument"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.learnable_params": [[92, 102], ["deepclusterv2.DeepClusterV2.projector.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.on_train_start": [[103, 134], ["solo.utils.kmeans.KMeans", "deepclusterv2.DeepClusterV2.register_buffer", "deepclusterv2.DeepClusterV2.register_buffer", "getattr", "len", "len", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.normalize().to", "torch.normalize().to", "torch.normalize().to", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.normalize", "torch.normalize", "torch.normalize", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.on_train_epoch_start": [[136, 149], ["deepclusterv2.DeepClusterV2.kmeans.cluster_memory", "zip", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "torch.ones().long", "proto.weight.copy_", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.kmeans.KMeans.cluster_memory"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.update_memory_banks": [[150, 163], ["enumerate", "z_c.detach"], "methods", ["None"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward": [[164, 181], ["super().forward", "torch.normalize", "torch.normalize", "torch.normalize", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "super().forward.update", "deepclusterv2.DeepClusterV2.projector", "torch.stack.", "torch.stack.", "torch.stack."], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.momentum.MomentumUpdater.update"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step": [[182, 212], ["super().training_step", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "solo.losses.deepclusterv2.deepclusterv2_loss_func", "deepclusterv2.DeepClusterV2.update_memory_banks", "deepclusterv2.DeepClusterV2.log", "p1.unsqueeze", "p2.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.training_step", "home.repos.pwc.inspect_result.vturrisi_solo-learn.losses.deepclusterv2.deepclusterv2_loss_func", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.update_memory_banks"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_nnsiam.test_nnsiam": [[30, 106], ["utils.gen_base_kwargs", "solo.methods.NNSiam", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.NNSiam.", "utils.gen_base_kwargs", "solo.methods.NNSiam", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.NNSiam", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.NNSiam.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["def", "test_nnsiam", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"proj_output_dim\"", ":", "256", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"pred_hidden_dim\"", ":", "2048", ",", "\n", "\"queue_size\"", ":", "8192", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNSiam", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "# test parameters", "\n", "assert", "model", ".", "learnable_params", "is", "not", "None", "\n", "\n", "# test forward", "\n", "batch", ",", "_", "=", "gen_batch", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", ")", "\n", "out", "=", "model", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"z\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"p\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"p\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"p\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "# imagenet", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNSiam", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# cifar", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNSiam", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"cifar10\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_swav.test_swav": [[30, 111], ["utils.gen_base_kwargs", "solo.methods.SwAV", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.SwAV.", "utils.gen_base_kwargs", "solo.methods.SwAV", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SwAV", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.SwAV.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["\n", "for", "p", "in", "preds", ":", "\n", "# compute assignments with sinkhorn-knopp", "\n", "        ", "assignments", ".", "append", "(", "sk", "(", "p", ")", "[", ":", "bs", "]", ")", "\n", "", "return", "assignments", "\n", "\n", "\n", "", "def", "test_swav_loss", "(", ")", ":", "\n", "    ", "b", ",", "f", "=", "256", ",", "128", "\n", "prototypes", "=", "nn", ".", "utils", ".", "weight_norm", "(", "torch", ".", "nn", ".", "Linear", "(", "f", ",", "f", ",", "bias", "=", "False", ")", ")", "\n", "\n", "z", "=", "torch", ".", "zeros", "(", "2", ",", "b", ",", "f", ")", ".", "uniform_", "(", "-", "2", ",", "2", ")", ".", "requires_grad_", "(", ")", "\n", "preds", "=", "prototypes", "(", "z", ")", "\n", "assignments", "=", "get_assignments", "(", "preds", ")", "\n", "\n", "loss", "=", "swav_loss_func", "(", "preds", ",", "assignments", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "preds", "=", "prototypes", "(", "z", ")", "\n", "assignments", "=", "get_assignments", "(", "preds", ")", "\n", "loss", "=", "swav_loss_func", "(", "preds", ",", "assignments", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "z", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z", ".", "grad", ")", "\n", "z", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_deepclusterv2.test_deepclusterv2": [[30, 113], ["utils.gen_base_kwargs", "solo.methods.DeepClusterV2", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.DeepClusterV2.", "utils.gen_base_kwargs", "solo.methods.DeepClusterV2", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.DeepClusterV2", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.DeepClusterV2.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size", "len"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["def", "test_deepclusterv2", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"proj_output_dim\"", ":", "128", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"num_prototypes\"", ":", "[", "10", ",", "10", ",", "10", "]", ",", "\n", "\"kmeans_iters\"", ":", "3", ",", "\n", "\"temperature\"", ":", "0.1", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "DeepClusterV2", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "# test parameters", "\n", "assert", "model", ".", "learnable_params", "is", "not", "None", "\n", "\n", "# test forward", "\n", "batch", ",", "_", "=", "gen_batch", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", ")", "\n", "out", "=", "model", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"z\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "assert", "(", "\n", "\"p\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"p\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"p\"", "]", ".", "size", "(", ")", "\n", "==", "(", "\n", "len", "(", "method_kwargs", "[", "\"num_prototypes\"", "]", ")", ",", "\n", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", "method_kwargs", "[", "\"num_prototypes\"", "]", "[", "0", "]", ",", "\n", ")", "\n", ")", "\n", "\n", "# imagenet", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "DeepClusterV2", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# cifar", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "DeepClusterV2", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"cifar10\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_nnbyol.test_nnbyol": [[30, 120], ["utils.gen_base_kwargs", "solo.methods.NNBYOL", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.NNBYOL.", "solo.methods.NNBYOL.momentum_forward", "utils.gen_base_kwargs", "solo.methods.NNBYOL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.NNBYOL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.NNBYOL.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["def", "test_nnbyol", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"proj_output_dim\"", ":", "256", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"pred_hidden_dim\"", ":", "2048", ",", "\n", "\"queue_size\"", ":", "8192", ",", "\n", "\"momentum_classifier\"", ":", "True", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "momentum", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNBYOL", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "# test parameters", "\n", "assert", "model", ".", "learnable_params", "is", "not", "None", "\n", "\n", "# test forward", "\n", "batch", ",", "_", "=", "gen_batch", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", ")", "\n", "out", "=", "model", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"z\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"p\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"p\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"p\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "momentum_out", "=", "model", ".", "momentum_forward", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "momentum_out", "\n", "and", "isinstance", "(", "momentum_out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "momentum_out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "momentum_out", "\n", "and", "isinstance", "(", "momentum_out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "momentum_out", "[", "\"z\"", "]", ".", "size", "(", ")", "\n", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "# imagenet", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "momentum", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNBYOL", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# cifar", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "momentum", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "NNBYOL", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"cifar10\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_nnclr.test_nnclr": [[30, 107], ["utils.gen_base_kwargs", "solo.methods.NNCLR", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.NNCLR.", "utils.gen_base_kwargs", "solo.methods.NNCLR", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.NNCLR", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.NNCLR.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "nnclr_loss_func", "(", "nn", ",", "p", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_wmse.test_wmse": [[30, 109], ["utils.gen_base_kwargs", "solo.methods.WMSE", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.WMSE.", "solo.methods.WMSE.add_model_specific_args", "isinstance", "isinstance", "isinstance", "utils.gen_base_kwargs", "solo.methods.WMSE", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.WMSE", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "wmse_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "wmse_loss_func", "(", "p", ",", "z", ")", "-", "wmse_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_barlow_twins.test_barlow": [[30, 101], ["utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.BarlowTwins.", "utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.BarlowTwins", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.BarlowTwins.add_model_specific_args", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["def", "test_barlow", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"proj_output_dim\"", ":", "2048", ",", "\n", "\"lamb\"", ":", "5e-3", ",", "\n", "\"scale_loss\"", ":", "0.025", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "# test parameters", "\n", "assert", "model", ".", "learnable_params", "is", "not", "None", "\n", "\n", "# test forward", "\n", "batch", ",", "_", "=", "gen_batch", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", ")", "\n", "out", "=", "model", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"z\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "# imagenet", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# cifar", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"cifar10\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_mocov3.test_mocov3": [[30, 116], ["utils.gen_base_kwargs", "solo.methods.MoCoV3", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.MoCoV3.", "solo.methods.MoCoV3.momentum_forward", "utils.gen_base_kwargs", "solo.methods.MoCoV3", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.MoCoV3", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.MoCoV3.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "mocov3_loss_func", "(", "query", ",", "key", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "key", ".", "data", ".", "add_", "(", "-", "0.5", "*", "key", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "key", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_simsiam.test_simsiam": [[30, 105], ["utils.gen_base_kwargs", "solo.methods.SimSiam", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.SimSiam.", "utils.gen_base_kwargs", "solo.methods.SimSiam", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SimSiam", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.SimSiam.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "simsiam_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "simsiam_loss_func", "(", "p", ",", "z", ")", "-", "simsiam_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_ressl.test_ressl": [[30, 117], ["utils.gen_base_kwargs", "solo.methods.ReSSL", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.ReSSL.", "solo.methods.ReSSL.momentum_forward", "utils.gen_base_kwargs", "solo.methods.ReSSL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.ReSSL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.ReSSL.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["loss", "=", "ressl_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature_q", "=", "0.1", ",", "temperature_k", "=", "0.04", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "ressl_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature_q", "=", "0.1", ",", "temperature_k", "=", "0.04", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_simclr.test_simclr": [[30, 131], ["utils.gen_base_kwargs", "solo.methods.SimCLR", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.SimCLR.", "solo.methods.SimCLR.multicrop_forward", "utils.gen_base_kwargs", "solo.methods.SimCLR", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SimCLR", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SimCLR", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.SimCLR.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "multicrop_out[].size", "multicrop_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["\n", "loss", "=", "simclr_loss_func", "(", "z", ",", "indexes", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "z", "=", "torch", ".", "cat", "(", "(", "z1", ",", "z2", ")", ")", "\n", "loss", "=", "simclr_loss_func", "(", "z", ",", "indexes", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_base.test_base": [[27, 65], ["utils.gen_base_kwargs", "solo.methods.base.BaseMethod", "solo.methods.base.BaseMethod.configure_optimizers", "isinstance", "isinstance", "solo.methods.base.BaseMethod.configure_optimizers", "isinstance", "solo.methods.base.BaseMethod.configure_optimizers", "isinstance", "pytest.raises", "solo.methods.base.BaseMethod.configure_optimizers", "pytest.raises", "solo.methods.base.BaseMethod.configure_optimizers", "solo.methods.base.BaseMethod.configure_optimizers"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers"], ["def", "test_base", "(", ")", ":", "\n", "    ", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ")", "\n", "kwargs", "=", "{", "\n", "**", "BASE_KWARGS", ",", "\n", "**", "DATA_KWARGS", ",", "\n", "}", "\n", "model", "=", "BaseMethod", "(", "**", "kwargs", ")", "\n", "\n", "# test optimizers/scheduler", "\n", "model", ".", "optimizer", "=", "\"random\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "model", ".", "configure_optimizers", "(", ")", "\n", "\n", "", "model", ".", "optimizer", "=", "\"lars\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "optimizer", "=", "model", ".", "configure_optimizers", "(", ")", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"step\"", "\n", "scheduler", "=", "model", ".", "configure_optimizers", "(", ")", "[", "1", "]", "[", "0", "]", "\n", "assert", "isinstance", "(", "scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"random\"", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "model", ".", "configure_optimizers", "(", ")", "\n", "\n", "", "model", ".", "optimizer", "=", "\"adam\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "model", ".", "extra_optimizer_args", "=", "{", "}", "\n", "optimizer", "=", "model", ".", "configure_optimizers", "(", ")", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", "\n", "\n", "model", ".", "optimizer", "=", "\"adamw\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "model", ".", "extra_optimizer_args", "=", "{", "}", "\n", "optimizer", "=", "model", ".", "configure_optimizers", "(", ")", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_dino.test_dino": [[30, 122], ["utils.gen_base_kwargs", "solo.methods.DINO", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.DINO.", "solo.methods.DINO.momentum_forward", "utils.gen_base_kwargs", "solo.methods.DINO", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.DINO", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.DINO.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["num_prototypes", "=", "f", ",", "\n", "warmup_teacher_temp", "=", "0.4", ",", "\n", "teacher_temp", "=", "0.7", ",", "\n", "warmup_teacher_temp_epochs", "=", "10", ",", "\n", "student_temp", "=", "0.1", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", ")", "\n", "\n", "loss", "=", "dino_loss", "(", "p", ",", "p_momentum", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "i", "in", "range", "(", "20", ")", ":", "\n", "        ", "dino_loss", ".", "epoch", "=", "i", "\n", "\n", "loss", "=", "dino_loss", "(", "p", ",", "p_momentum", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_linear.test_linear": [[37, 111], ["utils.gen_base_kwargs", "torchvision.models.resnet18", "torch.Identity", "kwargs.pop", "solo.methods.linear.LinearModel", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_classification_batch", "solo.methods.linear.LinearModel.", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_classification_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.linear.LinearModel.configure_optimizers", "isinstance", "isinstance", "isinstance", "isinstance", "solo.methods.linear.LinearModel.configure_optimizers", "isinstance", "solo.methods.linear.LinearModel.add_model_specific_args", "isinstance", "isinstance", "pytest.raises", "solo.methods.linear.LinearModel.configure_optimizers", "pytest.raises", "solo.methods.linear.LinearModel.configure_optimizers", "out[].size", "out[].size", "solo.methods.linear.LinearModel.configure_optimizers", "solo.methods.linear.LinearModel.configure_optimizers", "solo.methods.linear.LinearModel.configure_optimizers"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_classification_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_classification_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.linear.LinearModel.configure_optimizers"], ["def", "test_linear", "(", ")", ":", "\n", "    ", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "momentum", "=", "True", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", "}", "\n", "backbone", "=", "resnet18", "(", ")", "\n", "backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "kwargs", ".", "pop", "(", "\"backbone\"", ")", "\n", "model", "=", "LinearModel", "(", "backbone", ",", "**", "kwargs", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "batch", ",", "_", "=", "gen_classification_batch", "(", "\n", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", "\n", ")", "\n", "out", "=", "model", "(", "batch", "[", "0", "]", ")", "\n", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "backbone", ".", "inplanes", ")", "\n", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_classification_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# test optimizers/scheduler", "\n", "model", ".", "optimizer", "=", "\"random\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "model", ".", "configure_optimizers", "(", ")", "\n", "\n", "", "model", ".", "optimizer", "=", "\"sgd\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "optimizer", "=", "model", ".", "configure_optimizers", "(", ")", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"reduce\"", "\n", "scheduler", "=", "model", ".", "configure_optimizers", "(", ")", "[", "1", "]", "[", "0", "]", "\n", "assert", "isinstance", "(", "scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"step\"", "\n", "scheduler", "=", "model", ".", "configure_optimizers", "(", ")", "[", "1", "]", "[", "0", "]", "\n", "assert", "isinstance", "(", "scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"exponential\"", "\n", "scheduler", "=", "model", ".", "configure_optimizers", "(", ")", "[", "1", "]", "[", "0", "]", "\n", "assert", "isinstance", "(", "scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "ExponentialLR", ")", "\n", "\n", "model", ".", "scheduler", "=", "\"random\"", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "model", ".", "configure_optimizers", "(", ")", "\n", "\n", "", "model", ".", "optimizer", "=", "\"adam\"", "\n", "model", ".", "scheduler", "=", "\"none\"", "\n", "model", ".", "extra_optimizer_args", "=", "{", "}", "\n", "optimizer", "=", "model", ".", "configure_optimizers", "(", ")", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "Optimizer", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_supcon.test_supcon": [[30, 131], ["utils.gen_base_kwargs", "solo.methods.SupCon", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.SupCon.", "solo.methods.SupCon.multicrop_forward", "utils.gen_base_kwargs", "solo.methods.SupCon", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SupCon", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.SupCon", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.SupCon.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "multicrop_out[].size", "multicrop_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["def", "test_supcon", "(", ")", ":", "\n", "    ", "method_kwargs", "=", "{", "\n", "\"proj_output_dim\"", ":", "256", ",", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"temperature\"", ":", "0.2", ",", "\n", "\"supervised\"", ":", "False", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "SupCon", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "# test arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "\n", "assert", "model", ".", "add_model_specific_args", "(", "parser", ")", "is", "not", "None", "\n", "\n", "# test parameters", "\n", "assert", "model", ".", "learnable_params", "is", "not", "None", "\n", "\n", "# test forward", "\n", "batch", ",", "_", "=", "gen_batch", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\"imagenet100\"", ")", "\n", "out", "=", "model", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"logits\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"logits\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"logits\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "BASE_KWARGS", "[", "\"num_classes\"", "]", ")", "\n", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "out", "\n", "and", "isinstance", "(", "out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "out", "[", "\"z\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "multicrop_out", "=", "model", ".", "multicrop_forward", "(", "batch", "[", "1", "]", "[", "0", "]", ")", "\n", "assert", "(", "\n", "\"feats\"", "in", "multicrop_out", "\n", "and", "isinstance", "(", "multicrop_out", "[", "\"feats\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "multicrop_out", "[", "\"feats\"", "]", ".", "size", "(", ")", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "model", ".", "features_dim", ")", "\n", ")", "\n", "assert", "(", "\n", "\"z\"", "in", "multicrop_out", "\n", "and", "isinstance", "(", "multicrop_out", "[", "\"z\"", "]", ",", "torch", ".", "Tensor", ")", "\n", "and", "multicrop_out", "[", "\"z\"", "]", ".", "size", "(", ")", "\n", "==", "(", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "method_kwargs", "[", "\"proj_output_dim\"", "]", ")", "\n", ")", "\n", "\n", "# imagenet", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "SupCon", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# cifar", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "True", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "SupCon", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"cifar10\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "0", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "False", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "\n", "# multicrop", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "num_small_crops", "=", "6", ",", "batch_size", "=", "2", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", ",", "**", "method_kwargs", "}", "\n", "model", "=", "SupCon", "(", "**", "kwargs", ",", "disable_knn_eval", "=", "True", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "fast_dev_run", "=", "True", ")", "\n", "train_dl", ",", "val_dl", "=", "prepare_dummy_dataloaders", "(", "\n", "\"imagenet100\"", ",", "\n", "num_large_crops", "=", "BASE_KWARGS", "[", "\"num_large_crops\"", "]", ",", "\n", "num_small_crops", "=", "6", ",", "\n", "num_classes", "=", "BASE_KWARGS", "[", "\"num_classes\"", "]", ",", "\n", "multicrop", "=", "True", ",", "\n", "batch_size", "=", "BASE_KWARGS", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dl", ",", "val_dl", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_byol.test_byol": [[30, 132], ["utils.gen_base_kwargs", "solo.methods.BYOL", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.BYOL.", "solo.methods.BYOL.momentum_forward", "solo.methods.BYOL.multicrop_forward", "utils.gen_base_kwargs", "solo.methods.BYOL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.BYOL", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.BYOL.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size", "multicrop_out[].size", "multicrop_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.byol.BYOL.multicrop_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "byol_loss_func", "(", "p", ",", "z", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "p", ".", "data", ".", "add_", "(", "-", "0.5", "*", "p", ".", "grad", ")", "\n", "\n", "p", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "\n", "assert", "abs", "(", "byol_loss_func", "(", "p", ",", "z", ")", "-", "byol_loss_func", "(", "p", ",", "z", ",", "simplified", "=", "False", ")", ")", "<", "1e-6", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_mocov2plus.test_mocov2plus": [[30, 116], ["utils.gen_base_kwargs", "solo.methods.MoCoV2Plus", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.MoCoV2Plus.", "solo.methods.MoCoV2Plus.momentum_forward", "utils.gen_base_kwargs", "solo.methods.MoCoV2Plus", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.MoCoV2Plus", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.MoCoV2Plus.add_model_specific_args", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size", "momentum_out[].size", "momentum_out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.nnbyol.NNBYOL.momentum_forward", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["loss", "=", "mocov2plus_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature", "=", "0.1", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "mocov2plus_loss_func", "(", "query", ",", "key", ",", "queue", ",", "temperature", "=", "0.1", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "query", ".", "data", ".", "add_", "(", "-", "0.5", "*", "query", ".", "grad", ")", "\n", "key", ".", "data", ".", "add_", "(", "-", "0.5", "*", "key", ".", "grad", ")", "\n", "\n", "query", ".", "grad", "=", "key", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_vibcreg.test_vibcreg": [[30, 103], ["utils.gen_base_kwargs", "solo.methods.VIbCReg", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.VIbCReg.", "utils.gen_base_kwargs", "solo.methods.VIbCReg", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.VIbCReg", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.VIbCReg.add_model_specific_args", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "200.0", "\n", ")", "\n", "initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "vibcreg_loss_func", "(", "\n", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "200.0", "\n", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs": [[43, 86], ["None"], "function", ["None"], ["\n", "\n", "if", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", ":", "\n", "        ", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n", "", "else", ":", "\n", "# hack to maintain the current pipeline", "\n", "# even if the custom dataset doesn't have any labels", "\n", "        ", "dir_path", "=", "args", ".", "data_dir", "/", "args", ".", "train_dir", "\n", "args", ".", "num_classes", "=", "max", "(", "\n", "1", ",", "\n", "len", "(", "[", "entry", ".", "name", "for", "entry", "in", "os", ".", "scandir", "(", "dir_path", ")", "if", "entry", ".", "is_dir", "]", ")", ",", "\n", ")", "\n", "\n", "", "unique_augs", "=", "max", "(", "\n", "len", "(", "p", ")", "\n", "for", "p", "in", "[", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "color_jitter_prob", ",", "\n", "args", ".", "gray_scale_prob", ",", "\n", "args", ".", "horizontal_flip_prob", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "equalization_prob", ",", "\n", "args", ".", "crop_size", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "max_scale", ",", "\n", "]", "\n", ")", "\n", "assert", "len", "(", "args", ".", "num_crops_per_aug", ")", "==", "unique_augs", "\n", "\n", "# assert that either all unique augmentation pipelines have a unique", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch": [[88, 110], ["PIL.Image.fromarray().convert", "solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.pretrain_dataloader.prepare_n_crop_transform.", "x1.unsqueeze().repeat().requires_grad_.unsqueeze().repeat().requires_grad_", "x2.unsqueeze().repeat().requires_grad_.unsqueeze().repeat().requires_grad_", "torch.arange", "torch.randint", "numpy.random.rand", "solo.utils.pretrain_dataloader.prepare_transform", "PIL.Image.fromarray", "x1.unsqueeze().repeat().requires_grad_.unsqueeze().repeat", "x2.unsqueeze().repeat().requires_grad_.unsqueeze().repeat", "Image.fromarray().convert.astype", "x1.unsqueeze().repeat().requires_grad_.unsqueeze", "x2.unsqueeze().repeat().requires_grad_.unsqueeze"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform"], ["for", "p", "in", "[", "\n", "\"brightness\"", ",", "\n", "\"contrast\"", ",", "\n", "\"saturation\"", ",", "\n", "\"hue\"", ",", "\n", "\"color_jitter_prob\"", ",", "\n", "\"gray_scale_prob\"", ",", "\n", "\"horizontal_flip_prob\"", ",", "\n", "\"gaussian_prob\"", ",", "\n", "\"solarization_prob\"", ",", "\n", "\"equalization_prob\"", ",", "\n", "\"crop_size\"", ",", "\n", "\"min_scale\"", ",", "\n", "\"max_scale\"", ",", "\n", "]", ":", "\n", "        ", "values", "=", "getattr", "(", "args", ",", "p", ")", "\n", "n", "=", "len", "(", "values", ")", "\n", "assert", "n", "==", "unique_augs", "or", "n", "==", "1", "\n", "\n", "if", "n", "==", "1", ":", "\n", "            ", "setattr", "(", "args", ",", "p", ",", "getattr", "(", "args", ",", "p", ")", "*", "unique_augs", ")", "\n", "\n", "", "", "args", ".", "unique_augs", "=", "unique_augs", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_classification_batch": [[112, 136], ["PIL.Image.fromarray().convert", "torchvision.transforms.Compose", "transforms.Compose.", "x.unsqueeze().repeat().requires_grad_.unsqueeze().repeat().requires_grad_", "torch.randint", "numpy.random.rand", "PIL.Image.fromarray", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "x.unsqueeze().repeat().requires_grad_.unsqueeze().repeat", "Image.fromarray().convert.astype", "x.unsqueeze().repeat().requires_grad_.unsqueeze"], "function", ["None"], ["if", "unique_augs", ">", "1", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "[", "\n", "dict", "(", "\n", "brightness", "=", "brightness", ",", "\n", "contrast", "=", "contrast", ",", "\n", "saturation", "=", "saturation", ",", "\n", "hue", "=", "hue", ",", "\n", "color_jitter_prob", "=", "color_jitter_prob", ",", "\n", "gray_scale_prob", "=", "gray_scale_prob", ",", "\n", "horizontal_flip_prob", "=", "horizontal_flip_prob", ",", "\n", "gaussian_prob", "=", "gaussian_prob", ",", "\n", "solarization_prob", "=", "solarization_prob", ",", "\n", "equalization_prob", "=", "equalization_prob", ",", "\n", "crop_size", "=", "crop_size", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", ")", "\n", "for", "(", "\n", "brightness", ",", "\n", "contrast", ",", "\n", "saturation", ",", "\n", "hue", ",", "\n", "color_jitter_prob", ",", "\n", "gray_scale_prob", ",", "\n", "horizontal_flip_prob", ",", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders": [[138, 217], ["solo.utils.pretrain_dataloader.prepare_n_crop_transform", "solo.utils.pretrain_dataloader.prepare_dataloader", "torchvision.transforms.Compose", "torchvision.datasets.FakeData", "torch.utils.data.DataLoader", "dict", "solo.utils.pretrain_dataloader.dataset_with_index", "dict", "solo.utils.pretrain_dataloader.prepare_transform", "solo.utils.pretrain_dataloader.prepare_transform", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "zip"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_n_crop_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_dataloader", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.dataset_with_index", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.pretrain_dataloader.prepare_transform"], ["solarization_prob", ",", "\n", "equalization_prob", ",", "\n", "crop_size", ",", "\n", "min_scale", ",", "\n", "max_scale", ",", "\n", ")", "in", "zip", "(", "\n", "args", ".", "brightness", ",", "\n", "args", ".", "contrast", ",", "\n", "args", ".", "saturation", ",", "\n", "args", ".", "hue", ",", "\n", "args", ".", "color_jitter_prob", ",", "\n", "args", ".", "gray_scale_prob", ",", "\n", "args", ".", "horizontal_flip_prob", ",", "\n", "args", ".", "gaussian_prob", ",", "\n", "args", ".", "solarization_prob", ",", "\n", "args", ".", "equalization_prob", ",", "\n", "args", ".", "crop_size", ",", "\n", "args", ".", "min_scale", ",", "\n", "args", ".", "max_scale", ",", "\n", ")", "\n", "]", "\n", "\n", "# find number of big/small crops", "\n", "big_size", "=", "args", ".", "crop_size", "[", "0", "]", "\n", "num_large_crops", "=", "num_small_crops", "=", "0", "\n", "for", "size", ",", "n_crops", "in", "zip", "(", "args", ".", "crop_size", ",", "args", ".", "num_crops_per_aug", ")", ":", "\n", "            ", "if", "big_size", "==", "size", ":", "\n", "                ", "num_large_crops", "+=", "n_crops", "\n", "", "else", ":", "\n", "                ", "num_small_crops", "+=", "n_crops", "\n", "", "", "args", ".", "num_large_crops", "=", "num_large_crops", "\n", "args", ".", "num_small_crops", "=", "num_small_crops", "\n", "", "else", ":", "\n", "        ", "args", ".", "transform_kwargs", "=", "dict", "(", "\n", "brightness", "=", "args", ".", "brightness", "[", "0", "]", ",", "\n", "contrast", "=", "args", ".", "contrast", "[", "0", "]", ",", "\n", "saturation", "=", "args", ".", "saturation", "[", "0", "]", ",", "\n", "hue", "=", "args", ".", "hue", "[", "0", "]", ",", "\n", "color_jitter_prob", "=", "args", ".", "color_jitter_prob", "[", "0", "]", ",", "\n", "gray_scale_prob", "=", "args", ".", "gray_scale_prob", "[", "0", "]", ",", "\n", "horizontal_flip_prob", "=", "args", ".", "horizontal_flip_prob", "[", "0", "]", ",", "\n", "gaussian_prob", "=", "args", ".", "gaussian_prob", "[", "0", "]", ",", "\n", "solarization_prob", "=", "args", ".", "solarization_prob", "[", "0", "]", ",", "\n", "equalization_prob", "=", "args", ".", "equalization_prob", "[", "0", "]", ",", "\n", "crop_size", "=", "args", ".", "crop_size", "[", "0", "]", ",", "\n", "min_scale", "=", "args", ".", "min_scale", "[", "0", "]", ",", "\n", "max_scale", "=", "args", ".", "max_scale", "[", "0", "]", ",", "\n", ")", "\n", "\n", "# find number of big/small crops", "\n", "args", ".", "num_large_crops", "=", "args", ".", "num_crops_per_aug", "[", "0", "]", "\n", "args", ".", "num_small_crops", "=", "0", "\n", "\n", "# add support for custom mean and std", "\n", "", "if", "args", ".", "dataset", "==", "\"custom\"", ":", "\n", "        ", "if", "isinstance", "(", "args", ".", "transform_kwargs", ",", "dict", ")", ":", "\n", "            ", "args", ".", "transform_kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "args", ".", "transform_kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "", "else", ":", "\n", "            ", "for", "kwargs", "in", "args", ".", "transform_kwargs", ":", "\n", "                ", "kwargs", "[", "\"mean\"", "]", "=", "args", ".", "mean", "\n", "kwargs", "[", "\"std\"", "]", "=", "args", ".", "std", "\n", "\n", "# create backbone-specific arguments", "\n", "", "", "", "args", ".", "backbone_args", "=", "{", "\"cifar\"", ":", "args", ".", "dataset", "in", "[", "\"cifar10\"", ",", "\"cifar100\"", "]", "}", "\n", "if", "\"resnet\"", "in", "args", ".", "backbone", "and", "\"wide\"", "not", "in", "args", ".", "backbone", ":", "\n", "        ", "args", ".", "backbone_args", "[", "\"zero_init_residual\"", "]", "=", "args", ".", "zero_init_residual", "\n", "", "elif", "\"convnext\"", "not", "in", "args", ".", "backbone", ":", "\n", "# dataset related for all transformers", "\n", "        ", "crop_size", "=", "args", ".", "crop_size", "[", "0", "]", "\n", "args", ".", "backbone_args", "[", "\"img_size\"", "]", "=", "crop_size", "\n", "if", "\"vit\"", "in", "args", ".", "backbone", ":", "\n", "            ", "args", ".", "backbone_args", "[", "\"patch_size\"", "]", "=", "args", ".", "patch_size", "\n", "\n", "", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "zero_init_residual", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "patch_size", "\n", "\n", "", "if", "args", ".", "dali", ":", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_classification_dummy_dataloaders": [[219, 231], ["torchvision.transforms.Compose", "torchvision.datasets.FakeData", "torch.utils.data.DataLoader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["\n", "", "args", ".", "extra_optimizer_args", "=", "{", "}", "\n", "if", "args", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "", "if", "args", ".", "optimizer", "==", "\"lars\"", ":", "\n", "        ", "args", ".", "extra_optimizer_args", "[", "\"momentum\"", "]", "=", "0.9", "\n", "args", ".", "extra_optimizer_args", "[", "\"eta\"", "]", "=", "args", ".", "eta_lars", "\n", "args", ".", "extra_optimizer_args", "[", "\"clip_lars_lr\"", "]", "=", "args", ".", "grad_clip_lars", "\n", "args", ".", "extra_optimizer_args", "[", "\"exclude_bias_n_norm\"", "]", "=", "args", ".", "exclude_bias_n_norm", "\n", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n", "        ", "del", "args", ".", "eta_lars", "\n", "", "with", "suppress", "(", "AttributeError", ")", ":", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.test_vicreg.test_vicreg": [[30, 102], ["utils.gen_base_kwargs", "solo.methods.VICReg", "argparse.ArgumentParser", "pytorch_lightning.Trainer.add_argparse_args", "utils.gen_batch", "solo.methods.VICReg.", "utils.gen_base_kwargs", "solo.methods.VICReg", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "utils.gen_base_kwargs", "solo.methods.VICReg", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "utils.prepare_dummy_dataloaders", "Trainer.from_argparse_args.fit", "solo.methods.VICReg.add_model_specific_args", "isinstance", "isinstance", "isinstance", "out[].size", "out[].size", "out[].size"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_batch", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.prepare_dummy_dataloaders", "home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.deepclusterv2.DeepClusterV2.add_model_specific_args"], ["initial_loss", "=", "loss", ".", "item", "(", ")", "\n", "assert", "loss", "!=", "0", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "loss", "=", "vicreg_loss_func", "(", "\n", "z1", ",", "z2", ",", "sim_loss_weight", "=", "25.0", ",", "var_loss_weight", "=", "25.0", ",", "cov_loss_weight", "=", "1.0", "\n", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "z1", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z1", ".", "grad", ")", "\n", "z2", ".", "data", ".", "add_", "(", "-", "0.5", "*", "z2", ".", "grad", ")", "\n", "\n", "z1", ".", "grad", "=", "z2", ".", "grad", "=", "None", "\n", "\n", "", "assert", "loss", "<", "initial_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.source.conf.package_list_from_file": [[52, 64], ["open", "fp.readlines", "pkg.rstrip", "ln.index", "mocked_packages.append", "list", "pkg.rstrip", "min"], "function", ["None"], ["def", "package_list_from_file", "(", "file", ")", ":", "\n", "    ", "\"\"\"List up package name (not containing version and extras) from a package list file\"\"\"", "\n", "mocked_packages", "=", "[", "]", "\n", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "for", "ln", "in", "fp", ".", "readlines", "(", ")", ":", "\n", "# Example: `tqdm>=4.41.0` => `tqdm`", "\n", "# `[` is for package with extras", "\n", "            ", "found", "=", "[", "ln", ".", "index", "(", "ch", ")", "for", "ch", "in", "list", "(", "\",=<>#[\"", ")", "if", "ch", "in", "ln", "]", "\n", "pkg", "=", "ln", "[", ":", "min", "(", "found", ")", "]", "if", "found", "else", "ln", "\n", "if", "pkg", ".", "rstrip", "(", ")", ":", "\n", "                ", "mocked_packages", ".", "append", "(", "pkg", ".", "rstrip", "(", ")", ")", "\n", "", "", "", "return", "mocked_packages", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.Res5ROIHeadsExtraNorm._build_res5_block": [[21, 27], ["super()._build_res5_block", "detectron2.layers.get_norm", "seq.add_module"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.Res5ROIHeadsExtraNorm._build_res5_block"], ["def", "_build_res5_block", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "seq", ",", "out_channels", "=", "super", "(", ")", ".", "_build_res5_block", "(", "cfg", ")", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", "\n", "seq", ".", "add_module", "(", "\"norm\"", ",", "norm", ")", "\n", "return", "seq", ",", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.Trainer.build_evaluator": [[30, 39], ["os.path.join", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.PascalVOCDetectionEvaluator"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "if", "\"coco\"", "in", "dataset_name", ":", "\n", "            ", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "", "else", ":", "\n", "            ", "assert", "\"voc\"", "in", "dataset_name", "\n", "return", "PascalVOCDetectionEvaluator", "(", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.setup": [[41, 48], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["None"], ["", "", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "default_setup", "(", "cfg", ",", "args", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.main": [[50, 64], ["train_object_detection.setup", "train_object_detection.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.object_detection.train_object_detection.setup"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "model", ")", "\n", "return", "res", "\n", "\n", "", "trainer", "=", "Trainer", "(", "cfg", ")", "\n", "trainer", ".", "resume_or_load", "(", "resume", "=", "args", ".", "resume", ")", "\n", "return", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.test_dali_dataloader.test_dali_dataloader": [[39, 118], ["utils.DummyDataset", "zip", "solo.utils.dali_dataloader.PretrainPipelineBuilder", "solo.utils.dali_dataloader.NormalPipelineBuilder.pipeline", "train_pipeline_builder.pipeline.build", "solo.utils.dali_dataloader.NormalPipelineBuilder", "solo.utils.dali_dataloader.NormalPipelineBuilder.pipeline", "train_pipeline_builder.pipeline.build", "solo.utils.dali_dataloader.NormalPipelineBuilder", "solo.utils.dali_dataloader.NormalPipelineBuilder.pipeline", "val_pipeline_builder.pipeline.build", "solo.utils.dali_dataloader.ImagenetTransform", "transforms.append"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline", "home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.dali_dataloader.PretrainPipelineBuilder.pipeline"], ["def", "test_dali_dataloader", "(", ")", ":", "\n", "# creates a dummy dataset that autodeletes after usage", "\n", "    ", "with", "DummyDataset", "(", "\"dummy_train\"", ",", "\"dummy_val\"", ",", "10", ",", "4", ")", ":", "\n", "        ", "size_crops", "=", "[", "224", ",", "96", "]", "\n", "min_scales", "=", "[", "0.14", ",", "0.05", "]", "\n", "max_scale_crops", "=", "[", "1.0", ",", "0.14", "]", "\n", "\n", "transforms", "=", "[", "]", "\n", "for", "size", ",", "min_scale", ",", "max_scale", "in", "zip", "(", "size_crops", ",", "min_scales", ",", "max_scale_crops", ")", ":", "\n", "            ", "transform", "=", "ImagenetTransform", "(", "\n", "device", "=", "\"cpu\"", ",", "\n", "brightness", "=", "0.4", ",", "\n", "contrast", "=", "0.4", ",", "\n", "saturation", "=", "0.2", ",", "\n", "hue", "=", "0.1", ",", "\n", "gaussian_prob", "=", "0.5", ",", "\n", "solarization_prob", "=", "0.1", ",", "\n", "crop_size", "=", "size", ",", "\n", "min_scale", "=", "min_scale", ",", "\n", "max_scale", "=", "max_scale", ",", "\n", ")", "\n", "transforms", ".", "append", "(", "transform", ")", "\n", "\n", "# multicrop pipeline", "\n", "", "train_pipeline_builder", "=", "PretrainPipelineBuilder", "(", "\n", "\"dummy_train\"", ",", "\n", "batch_size", "=", "4", ",", "\n", "transforms", "=", "transforms", ",", "\n", "num_crops_per_aug", "=", "[", "2", ",", "4", "]", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", "device_id", "=", "0", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_shards", "=", "1", ",", "\n", "num_threads", "=", "1", ",", "\n", ")", "\n", "train_pipeline", "=", "train_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "train_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "train_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "train_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "train_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "train_pipeline", ".", "build", "(", ")", "\n", "\n", "# normal pipeline", "\n", "train_pipeline_builder", "=", "NormalPipelineBuilder", "(", "\n", "\"dummy_train\"", ",", "\n", "validation", "=", "False", ",", "\n", "batch_size", "=", "4", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", "device_id", "=", "0", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_shards", "=", "1", ",", "\n", "num_threads", "=", "1", ",", "\n", ")", "\n", "train_pipeline", "=", "train_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "train_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "train_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "train_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "train_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "train_pipeline", ".", "build", "(", ")", "\n", "\n", "val_pipeline_builder", "=", "NormalPipelineBuilder", "(", "\n", "\"dummy_val\"", ",", "\n", "validation", "=", "True", ",", "\n", "batch_size", "=", "4", ",", "\n", "device", "=", "\"cpu\"", ",", "\n", "device_id", "=", "0", ",", "\n", "shard_id", "=", "0", ",", "\n", "num_shards", "=", "1", ",", "\n", "num_threads", "=", "1", ",", "\n", ")", "\n", "val_pipeline", "=", "val_pipeline_builder", ".", "pipeline", "(", "\n", "batch_size", "=", "val_pipeline_builder", ".", "batch_size", ",", "\n", "num_threads", "=", "val_pipeline_builder", ".", "num_threads", ",", "\n", "device_id", "=", "val_pipeline_builder", ".", "device_id", ",", "\n", "seed", "=", "val_pipeline_builder", ".", "seed", ",", "\n", ")", "\n", "val_pipeline", ".", "build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.test_dali_dataloader.test_dali_pretrain": [[120, 179], ["utils.DummyDataset", "methods.utils.gen_base_kwargs", "dict", "solo.methods.BarlowTwins", "argparse.Namespace", "pytorch_lightning.Trainer.from_argparse_args", "solo.utils.dali_dataloader.PretrainDALIDataModule", "Trainer.from_argparse_args.fit", "methods.utils.DATA_KWARGS.items"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs"], ["", "", "def", "test_dali_pretrain", "(", ")", ":", "\n", "    ", "for", "encode_indexes_into_labels", "in", "[", "True", ",", "False", "]", ":", "\n", "# creates a dummy dataset that autodeletes after usage", "\n", "        ", "with", "DummyDataset", "(", "\"dummy_train\"", ",", "\"dummy_val\"", ",", "128", ",", "4", ")", ":", "\n", "            ", "method_kwargs", "=", "{", "\n", "\"proj_hidden_dim\"", ":", "2048", ",", "\n", "\"proj_output_dim\"", ":", "2048", ",", "\n", "\"lamb\"", ":", "5e-3", ",", "\n", "\"scale_loss\"", ":", "0.025", ",", "\n", "\"encode_indexes_into_labels\"", ":", "encode_indexes_into_labels", ",", "\n", "\"disable_knn_eval\"", ":", "True", ",", "\n", "}", "\n", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ")", "\n", "DATA_KWARGS_WRAPPED", "=", "{", "k", ":", "[", "v", "]", "for", "k", ",", "v", "in", "DATA_KWARGS", ".", "items", "(", ")", "}", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS_WRAPPED", ",", "**", "method_kwargs", "}", "\n", "\n", "kwargs", "[", "\"dali_device\"", "]", "=", "\"cpu\"", "\n", "kwargs", "[", "\"train_dir\"", "]", "=", "\"dummy_train\"", "\n", "kwargs", "[", "\"data_dir\"", "]", "=", "\".\"", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "\"custom\"", "\n", "\n", "kwargs", "[", "\"transform_kwargs\"", "]", "=", "dict", "(", "\n", "brightness", "=", "0.4", ",", "\n", "contrast", "=", "0.4", ",", "\n", "saturation", "=", "0.2", ",", "\n", "hue", "=", "0.1", ",", "\n", "gaussian_prob", "=", "0.5", ",", "\n", "solarization_prob", "=", "0.2", ",", "\n", "min_scale", "=", "0.08", ",", "\n", "max_scale", "=", "1.0", ",", "\n", ")", "\n", "kwargs", "[", "\"unique_augs\"", "]", "=", "1", "\n", "\n", "model", "=", "BarlowTwins", "(", "**", "kwargs", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", ")", "\n", "dali_datamodule", "=", "PretrainDALIDataModule", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "unique_augs", "=", "args", ".", "unique_augs", ",", "\n", "transform_kwargs", "=", "args", ".", "transform_kwargs", ",", "\n", "num_crops_per_aug", "=", "args", ".", "num_crops_per_aug", ",", "\n", "num_large_crops", "=", "args", ".", "num_large_crops", ",", "\n", "num_small_crops", "=", "args", ".", "num_small_crops", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "no_labels", "=", "args", ".", "no_labels", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", "dali_device", "=", "args", ".", "dali_device", ",", "\n", "encode_indexes_into_labels", "=", "args", ".", "encode_indexes_into_labels", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dali_datamodule", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.test_dali_dataloader.test_dali_linear": [[181, 218], ["utils.DummyDataset", "methods.utils.gen_base_kwargs", "torchvision.models.resnet.resnet18", "torch.nn.Identity", "solo.methods.linear.LinearModel", "argparse.Namespace", "solo.utils.dali_dataloader.ClassificationDALIDataModule", "pytorch_lightning.Trainer.from_argparse_args", "Trainer.from_argparse_args.fit"], "function", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.methods.utils.gen_base_kwargs"], ["", "", "", "def", "test_dali_linear", "(", ")", ":", "\n", "# creates a dummy dataset that autodeletes after usage", "\n", "    ", "with", "DummyDataset", "(", "\"./dummy_train\"", ",", "\"./dummy_val\"", ",", "128", ",", "4", ")", ":", "\n", "        ", "BASE_KWARGS", "=", "gen_base_kwargs", "(", "cifar", "=", "False", ",", "momentum", "=", "True", ")", "\n", "kwargs", "=", "{", "**", "BASE_KWARGS", ",", "**", "DATA_KWARGS", "}", "\n", "backbone", "=", "resnet18", "(", ")", "\n", "backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "kwargs", "[", "\"dali_device\"", "]", "=", "\"cpu\"", "\n", "kwargs", "[", "\"data_dir\"", "]", "=", "\".\"", "\n", "kwargs", "[", "\"train_dir\"", "]", "=", "\"dummy_train\"", "\n", "kwargs", "[", "\"val_dir\"", "]", "=", "\"dummy_val\"", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "\"custom\"", "\n", "\n", "del", "kwargs", "[", "\"backbone\"", "]", "\n", "\n", "model", "=", "LinearModel", "(", "backbone", ",", "**", "kwargs", ")", "\n", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "kwargs", ")", "\n", "dali_datamodule", "=", "ClassificationDALIDataModule", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "train_dir", "=", "args", ".", "train_dir", ",", "\n", "val_dir", "=", "args", ".", "val_dir", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "data_fraction", "=", "args", ".", "data_fraction", ",", "\n", "dali_device", "=", "args", ".", "dali_device", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "checkpoint_callback", "=", "False", ",", "\n", "limit_train_batches", "=", "2", ",", "\n", "limit_val_batches", "=", "2", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dali_datamodule", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__init__": [[31, 36], ["pathlib.Path", "pathlib.Path"], "methods", ["None"], ["}", "\n", "\n", "\n", "def", "additional_setup_pretrain", "(", "args", ":", "Namespace", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__enter__": [[37, 50], ["range", "range", "contextlib.suppress", "os.makedirs", "PIL.Image.fromarray().convert", "PIL.Image.fromarray().convert.save", "random.randint", "random.randint", "numpy.random.rand", "str", "PIL.Image.fromarray", "PIL.Image.fromarray().convert.astype", "str"], "methods", ["home.repos.pwc.inspect_result.vturrisi_solo-learn.utils.checkpointer.Checkpointer.save"], []], "home.repos.pwc.inspect_result.vturrisi_solo-learn.dali.utils.DummyDataset.__exit__": [[51, 56], ["contextlib.suppress", "shutil.rmtree", "contextlib.suppress", "shutil.rmtree"], "methods", ["None"], ["\n", "\n", "if", "args", ".", "dataset", "in", "N_CLASSES_PER_DATASET", ":", "\n", "        ", "args", ".", "num_classes", "=", "N_CLASSES_PER_DATASET", "[", "args", ".", "dataset", "]", "\n"]]}