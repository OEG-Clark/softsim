{"home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.__init__": [[28, 40], ["gensim.corpora.Dictionary", "BM25.BM25.buildDictionary", "BM25.BM25.TFIDF_Generator"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.buildDictionary", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.TFIDF_Generator"], ["\t", "def", "__init__", "(", "self", ",", "fn_docs", ",", "delimiter", "=", "' '", ")", ":", "\n", "\t\t", "self", ".", "dictionary", "=", "corpora", ".", "Dictionary", "(", ")", "\n", "self", ".", "DF", "=", "{", "}", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "DocTF", "=", "[", "]", "\n", "self", ".", "DocIDF", "=", "{", "}", "\n", "self", ".", "N", "=", "0", "\n", "self", ".", "DocAvgLen", "=", "0", "\n", "self", ".", "fn_docs", "=", "fn_docs", "\n", "self", ".", "DocLen", "=", "[", "]", "\n", "self", ".", "buildDictionary", "(", ")", "\n", "self", ".", "TFIDF_Generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.buildDictionary": [[41, 51], ["BM25.BM25.dictionary.add_documents", "open", "csv.reader", "raw_data.append", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "buildDictionary", "(", "self", ")", ":", "\n", "\t\t", "raw_data", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "fn_docs", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "csv_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "#for line in f.readlines():", "\n", "for", "line", "in", "csv_reader", ":", "\n", "#line = line.strip().split(\"\\t\")[1]", "\n", "\t\t\t\t", "line", "=", "line", "[", "1", "]", "\n", "raw_data", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "delimiter", ")", ")", "\n", "", "", "self", ".", "dictionary", ".", "add_documents", "(", "raw_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.TFIDF_Generator": [[52, 74], ["open", "csv.reader", "math.log", "line.strip().split", "len", "BM25.BM25.DocLen.append", "dict", "dict.items", "BM25.BM25.DocTF.append", "len", "line.strip", "BM25.BM25.dictionary.doc2bow", "len"], "methods", ["None"], ["", "def", "TFIDF_Generator", "(", "self", ",", "base", "=", "math", ".", "e", ")", ":", "\n", "\t\t", "docTotalLen", "=", "0", "\n", "with", "open", "(", "self", ".", "fn_docs", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "csv_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "#for line in f.readlines():", "\n", "for", "line", "in", "csv_reader", ":", "\n", "#line = line.strip().split(\"\\t\")[1]", "\n", "\t\t\t\t", "line", "=", "line", "[", "1", "]", "\n", "doc", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "docTotalLen", "+=", "len", "(", "doc", ")", "\n", "self", ".", "DocLen", ".", "append", "(", "len", "(", "doc", ")", ")", "\n", "#print self.dictionary.doc2bow(doc)", "\n", "bow", "=", "dict", "(", "[", "(", "term", ",", "freq", "*", "1.0", "/", "len", "(", "doc", ")", ")", "for", "term", ",", "freq", "in", "self", ".", "dictionary", ".", "doc2bow", "(", "doc", ")", "]", ")", "\n", "for", "term", ",", "tf", "in", "bow", ".", "items", "(", ")", ":", "\n", "\t\t\t\t\t", "if", "term", "not", "in", "self", ".", "DF", ":", "\n", "\t\t\t\t\t\t", "self", ".", "DF", "[", "term", "]", "=", "0", "\n", "", "self", ".", "DF", "[", "term", "]", "+=", "1", "\n", "", "self", ".", "DocTF", ".", "append", "(", "bow", ")", "\n", "self", ".", "N", "=", "self", ".", "N", "+", "1", "\n", "", "", "for", "term", "in", "self", ".", "DF", ":", "\n", "\t\t\t", "self", ".", "DocIDF", "[", "term", "]", "=", "math", ".", "log", "(", "1", "+", "(", "(", "self", ".", "N", "-", "self", ".", "DF", "[", "term", "]", "+", "0.5", ")", "/", "(", "self", ".", "DF", "[", "term", "]", "+", "0.5", ")", ")", ",", "base", ")", "\n", "", "self", ".", "DocAvgLen", "=", "docTotalLen", "/", "self", ".", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.BM25Score": [[76, 113], ["BM25.BM25.dictionary.doc2bow", "enumerate", "scores.append", "set", "set", "tmp_score.append", "sum", "dict().keys", "doc.keys", "numpy.zeros", "enumerate", "sklearn.cosine_similarity", "commonTerms.union.union.union", "BM25.BM25.dictionary.id2token[].lower().strip", "similar_words.extend", "set", "pdb.set_trace", "dict", "doc.keys", "len", "BM25.BM25.dictionary.id2token[].lower", "numpy.array", "enumerate", "query_vocab.index", "embedding_vocab.index"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity"], ["", "def", "BM25Score", "(", "self", ",", "Query", "=", "[", "]", ",", "k1", "=", "1.5", ",", "b", "=", "0.75", ",", "\n", "embedding_matrix", "=", "None", ",", "embedding_vocab", "=", "None", ",", "\n", "query_matrix", "=", "None", ",", "query_vocab", "=", "None", ",", "\n", "sim_threshold", "=", "0.30", ")", ":", "\n", "\t\t", "query_bow", "=", "self", ".", "dictionary", ".", "doc2bow", "(", "Query", ")", "\n", "scores", "=", "[", "]", "\n", "for", "idx", ",", "doc", "in", "enumerate", "(", "self", ".", "DocTF", ")", ":", "\n", "\t\t\t", "commonTerms", "=", "set", "(", "dict", "(", "query_bow", ")", ".", "keys", "(", ")", ")", "&", "set", "(", "doc", ".", "keys", "(", ")", ")", "\n", "if", "not", "embedding_matrix", "is", "None", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "query_words", "=", "Query", "\n", "doc_words", "=", "[", "self", ".", "dictionary", ".", "id2token", "[", "id", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "for", "id", "in", "doc", ".", "keys", "(", ")", "]", "\n", "query_vecs", "=", "query_matrix", "[", "np", ".", "array", "(", "[", "query_vocab", ".", "index", "(", "word", ")", "for", "word", "in", "query_words", "]", ")", ",", ":", "]", "\n", "#doc_vecs = embedding_matrix[np.array([embedding_vocab.index(word) for word in doc_words]), :]", "\n", "doc_vecs", "=", "np", ".", "zeros", "(", "(", "len", "(", "doc_words", ")", ",", "embedding_matrix", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "doc_words", ")", ":", "\n", "\t\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t\t", "doc_vecs", "[", "i", ",", ":", "]", "=", "embedding_matrix", "[", "embedding_vocab", ".", "index", "(", "word", ")", ",", ":", "]", "\n", "", "except", "ValueError", ":", "\n", "\t\t\t\t\t\t\t", "pass", "\n", "", "", "sim", "=", "pw", ".", "cosine_similarity", "(", "query_vecs", ",", "doc_vecs", ")", "\n", "#sim = eval.softmax(pw.cosine_similarity(query_vecs, doc_vecs), axis=1)", "\n", "similar_words", "=", "[", "]", "\n", "for", "row", "in", "sim", ":", "\n", "\t\t\t\t\t\t", "sim_words", "=", "[", "self", ".", "dictionary", ".", "token2id", "[", "doc_words", "[", "ind", "]", "]", "for", "ind", ",", "val", "in", "enumerate", "(", "row", ")", "if", "val", ">=", "sim_threshold", "]", "\n", "similar_words", ".", "extend", "(", "sim_words", ")", "\n", "", "commonTerms", "=", "commonTerms", ".", "union", "(", "set", "(", "similar_words", ")", ")", "\n", "", "except", "IndexError", ":", "\n", "\t\t\t\t\t", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "tmp_score", "=", "[", "]", "\n", "doc_terms_len", "=", "self", ".", "DocLen", "[", "idx", "]", "\n", "for", "term", "in", "commonTerms", ":", "\n", "\t\t\t\t", "upper", "=", "(", "doc", "[", "term", "]", "*", "(", "k1", "+", "1", ")", ")", "\n", "below", "=", "(", "(", "doc", "[", "term", "]", ")", "+", "k1", "*", "(", "1", "-", "b", "+", "b", "*", "doc_terms_len", "/", "self", ".", "DocAvgLen", ")", ")", "\n", "tmp_score", ".", "append", "(", "self", ".", "DocIDF", "[", "term", "]", "*", "upper", "/", "below", ")", "\n", "", "scores", ".", "append", "(", "sum", "(", "tmp_score", ")", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.TFIDF": [[114, 121], ["doc_tfidf.sort", "tfidf.append", "doc.items"], "methods", ["None"], ["", "def", "TFIDF", "(", "self", ")", ":", "\n", "\t\t", "tfidf", "=", "[", "]", "\n", "for", "doc", "in", "self", ".", "DocTF", ":", "\n", "\t\t\t", "doc_tfidf", "=", "[", "(", "term", ",", "tf", "*", "self", ".", "DocIDF", "[", "term", "]", ")", "for", "term", ",", "tf", "in", "doc", ".", "items", "(", ")", "]", "\n", "doc_tfidf", ".", "sort", "(", ")", "\n", "tfidf", ".", "append", "(", "doc_tfidf", ")", "\n", "", "return", "tfidf", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.Items": [[122, 128], ["BM25.BM25.dictionary.items", "sorted", "operator.itemgetter"], "methods", ["None"], ["", "def", "Items", "(", "self", ")", ":", "\n", "# Return a list [(term_idx, term_desc),]", "\n", "\t\t", "items", "=", "self", ".", "dictionary", ".", "items", "(", ")", "\n", "#items.sort()", "\n", "items", "=", "sorted", "(", "items", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.BM25.query_doc_overlap": [[129, 181], ["BM25.uwords", "BM25.ubigrams", "BM25.uwords", "len", "BM25.ubigrams", "len", "float", "float", "float", "float", "int", "float", "float", "float", "float", "len", "qword.split", "len", "BM25.uwords", "BM25.ubigrams"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams"], ["", "def", "query_doc_overlap", "(", "self", ",", "qwords", ",", "dwords", ")", ":", "\n", "\n", "# % Query words in doc.", "\n", "\t\t", "qwords_in_doc", "=", "0", "\n", "idf_qwords_in_doc", "=", "0.0", "\n", "idf_qwords", "=", "0.0", "\n", "for", "qword", "in", "uwords", "(", "qwords", ")", ":", "\n", "\t\t\t", "idf_qwords", "+=", "self", ".", "DocIDF", "[", "qword", "]", "\n", "for", "dword", "in", "uwords", "(", "dwords", ")", ":", "\n", "\t\t\t\t", "if", "qword", "==", "dword", ":", "\n", "\t\t\t\t\t", "idf_qwords_in_doc", "+=", "self", ".", "DocIDF", "[", "qword", "]", "\n", "qwords_in_doc", "+=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "qwords", ")", "<=", "0", ":", "\n", "\t\t\t", "qwords_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "qwords_in_doc_val", "=", "(", "float", "(", "qwords_in_doc", ")", "/", "\n", "float", "(", "len", "(", "uwords", "(", "qwords", ")", ")", ")", ")", "\n", "", "if", "idf_qwords", "<=", "0.0", ":", "\n", "\t\t\t", "idf_qwords_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "idf_qwords_in_doc_val", "=", "float", "(", "idf_qwords_in_doc", ")", "/", "float", "(", "idf_qwords", ")", "\n", "\n", "# % Query bigrams  in doc.", "\n", "", "qwords_bigrams_in_doc", "=", "0", "\n", "idf_qwords_bigrams_in_doc", "=", "0.0", "\n", "idf_bigrams", "=", "0.0", "\n", "for", "qword", "in", "ubigrams", "(", "qwords", ")", ":", "\n", "\t\t\t", "wrds", "=", "[", "int", "(", "w", ")", "for", "w", "in", "qword", ".", "split", "(", "'_'", ")", "]", "\n", "idf_bigrams", "+=", "self", ".", "DocIDF", "[", "wrds", "[", "0", "]", "]", "*", "self", ".", "DocIDF", "[", "wrds", "[", "1", "]", "]", "\n", "for", "dword", "in", "ubigrams", "(", "dwords", ")", ":", "\n", "\t\t\t\t", "if", "qword", "==", "dword", ":", "\n", "\t\t\t\t\t", "qwords_bigrams_in_doc", "+=", "1", "\n", "idf_qwords_bigrams_in_doc", "+=", "(", "self", ".", "DocIDF", "[", "wrds", "[", "0", "]", "]", "\n", "*", "self", ".", "DocIDF", "[", "wrds", "[", "1", "]", "]", ")", "\n", "break", "\n", "#if len(qwords) <= 0:", "\n", "", "", "", "if", "len", "(", "qwords", ")", "<=", "1", ":", "\n", "\t\t\t", "qwords_bigrams_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "qwords_bigrams_in_doc_val", "=", "(", "float", "(", "qwords_bigrams_in_doc", ")", "/", "\n", "float", "(", "len", "(", "ubigrams", "(", "qwords", ")", ")", ")", ")", "\n", "", "if", "idf_bigrams", "<=", "0.0", ":", "\n", "\t\t\t", "idf_qwords_bigrams_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "idf_qwords_bigrams_in_doc_val", "=", "(", "float", "(", "idf_qwords_bigrams_in_doc", ")", "/", "\n", "float", "(", "idf_bigrams", ")", ")", "\n", "\n", "", "return", "[", "qwords_in_doc_val", ",", "\n", "qwords_bigrams_in_doc_val", ",", "\n", "idf_qwords_in_doc_val", ",", "\n", "idf_qwords_bigrams_in_doc_val", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.uwords": [[11, 16], ["None"], "function", ["None"], ["def", "uwords", "(", "words", ")", ":", "\n", "\t", "uw", "=", "{", "}", "\n", "for", "w", "in", "words", ":", "\n", "\t\t", "uw", "[", "w", "]", "=", "1", "\n", "", "return", "[", "w", "for", "w", "in", "uw", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25.ubigrams": [[17, 26], ["range", "len", "str", "str"], "function", ["None"], ["", "def", "ubigrams", "(", "words", ")", ":", "\n", "\t", "uw", "=", "{", "}", "\n", "#prevw = \"<pw>\"", "\n", "#for w in words:", "\n", "#\tuw[str(prevw) + '_' + str(w)] = 1", "\n", "#\tprevw = str(w)", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "1", ")", ":", "\n", "\t\t", "uw", "[", "str", "(", "words", "[", "i", "]", ")", "+", "'_'", "+", "str", "(", "words", "[", "i", "+", "1", "]", ")", "]", "=", "1", "\n", "", "return", "[", "w", "for", "w", "in", "uw", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.relevance_score_task2.tokens": [[184, 186], ["w.lower", "text.split"], "function", ["None"], ["", "", "def", "tokens", "(", "text", ")", ":", "\n", "\t", "return", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "text", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.relevance_score_task2.get_one_hot": [[192, 206], ["numpy.zeros", "numpy.zeros", "enumerate", "total_vocab.index", "len", "word.strip", "query.strip().split", "len", "len", "total_vocab.index", "word.strip", "sent.strip().split", "query.strip", "sent.strip"], "function", ["None"], ["def", "get_one_hot", "(", "query", ",", "doc", ")", ":", "\n", "\n", "\t", "query_vecs", "=", "np", ".", "zeros", "(", "(", "1", ",", "len", "(", "total_vocab", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "indices", "=", "[", "total_vocab", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t", "query_vecs", "[", "0", ",", "index", "]", "=", "1.0", "\n", "\n", "", "doc_sents_vecs", "=", "np", ".", "zeros", "(", "(", "len", "(", "doc", ")", ",", "len", "(", "total_vocab", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "indices", "=", "[", "total_vocab", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t\t", "doc_sents_vecs", "[", "i", ",", "index", "]", "=", "1.0", "\n", "\n", "", "", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.relevance_score_task2.get_bigram": [[207, 220], ["numpy.array", "enumerate", "numpy.array", "cv.transform().todense", "np.array.append", "numpy.squeeze", "cv.transform", "numpy.array", "cv.transform().todense", "cv.transform"], "function", ["None"], ["", "def", "get_bigram", "(", "query", ",", "doc", ")", ":", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "\t", "query_vecs", "=", "np", ".", "array", "(", "cv", ".", "transform", "(", "[", "query", "]", ")", ".", "todense", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "#query_vecs = np.tile(query_vecs, [len(doc), 1])", "\n", "\n", "doc_sents_vecs", "=", "[", "]", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "doc_sents_vecs", ".", "append", "(", "np", ".", "squeeze", "(", "np", ".", "array", "(", "cv", ".", "transform", "(", "[", "sent", "]", ")", ".", "todense", "(", ")", ")", ",", "axis", "=", "0", ")", ")", "\n", "", "doc_sents_vecs", "=", "np", ".", "array", "(", "doc_sents_vecs", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.is_float": [[31, 33], ["FLOAT_REGEXP.match"], "function", ["None"], ["def", "is_float", "(", "str", ")", ":", "\n", "\t", "return", "True", "if", "FLOAT_REGEXP", ".", "match", "(", "str", ")", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.replace_num": [[34, 42], ["separate_title_and_abstracts.is_float", "new_tokens.append", "new_tokens.append"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.is_float"], ["", "def", "replace_num", "(", "tokens", ")", ":", "\n", "\t", "new_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "if", "is_float", "(", "token", ")", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "\"<num>\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "token", ")", "\n", "", "", "return", "new_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.preprocess_token": [[43, 45], ["char.isalpha"], "function", ["None"], ["", "def", "preprocess_token", "(", "token", ")", ":", "\n", "\t", "return", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "token", "if", "char", ".", "isalpha", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.remove_punctuation_and_replace_num": [[46, 57], ["separate_title_and_abstracts.replace_num", "token.strip", "separate_title_and_abstracts.preprocess_token", "tokenizer.tokenize", "token.lower", "token.isupper"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.replace_num", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.preprocess_token"], ["", "def", "remove_punctuation_and_replace_num", "(", "doc", ")", ":", "\n", "#doc_tokens = [token.strip(string.punctuation) for token in doc.split()]", "\n", "\t", "doc_tokens", "=", "[", "token", ".", "strip", "(", "string", ".", "punctuation", ")", "for", "token", "in", "tokenizer", ".", "tokenize", "(", "doc", ")", "]", "\n", "#all_caps_tokens = [token for token in doc_tokens if token.isupper()]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", ".", "isupper", "(", ")", "]", "\n", "#doc_tokens = [token for token in doc_tokens if not token in CAPS_REMOVE_LIST]", "\n", "#doc_tokens = [token for token in replace_num(doc_tokens)]", "\n", "doc_tokens", "=", "replace_num", "(", "doc_tokens", ")", "\n", "doc_tokens", "=", "[", "preprocess_token", "(", "token", ".", "lower", "(", ")", ")", "for", "token", "in", "doc_tokens", "]", "\n", "#return \" \".join(doc_tokens), all_caps_tokens", "\n", "return", "\" \"", ".", "join", "(", "doc_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.tokens": [[58, 60], ["w.lower", "text.split"], "function", ["None"], ["", "def", "tokens", "(", "text", ")", ":", "\n", "\t", "return", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "text", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.counts_to_sequence": [[61, 66], ["range", "len", "seq.extend", "int"], "function", ["None"], ["", "def", "counts_to_sequence", "(", "counts", ")", ":", "\n", "\t", "seq", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "counts", ")", ")", ":", "\n", "\t\t", "seq", ".", "extend", "(", "[", "i", "]", "*", "int", "(", "counts", "[", "i", "]", ")", ")", "\n", "", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.log_counts": [[67, 70], ["numpy.bincount", "numpy.floor", "numpy.log"], "function", ["None"], ["", "def", "log_counts", "(", "ids", ",", "vocab_size", ")", ":", "\n", "\t", "counts", "=", "np", ".", "bincount", "(", "ids", ",", "minlength", "=", "vocab_size", ")", "\n", "return", "np", ".", "floor", "(", "0.5", "+", "np", ".", "log", "(", "counts", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.separate_title_and_abstracts.preprocess": [[71, 85], ["vocab_to_id.get", "separate_title_and_abstracts.log_counts", "separate_title_and_abstracts.counts_to_sequence", "len", "separate_title_and_abstracts.tokens", "len", "str", "vocab_to_id.get"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.log_counts", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.counts_to_sequence", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens"], ["", "def", "preprocess", "(", "text", ",", "vocab_to_id", ",", "dataset_type", ")", ":", "\n", "\n", "\t", "ids", "=", "[", "vocab_to_id", ".", "get", "(", "x", ")", "for", "x", "in", "tokens", "(", "text", ")", "if", "not", "(", "vocab_to_id", ".", "get", "(", "x", ")", "is", "None", ")", "]", "\n", "\n", "if", "dataset_type", "==", "\"docnade\"", ":", "\n", "\t\t", "counts", "=", "log_counts", "(", "ids", ",", "len", "(", "vocab_to_id", ")", ")", "\n", "sequence", "=", "counts_to_sequence", "(", "counts", ")", "\n", "", "else", ":", "\n", "\t\t", "sequence", "=", "ids", "\n", "\n", "", "if", "len", "(", "sequence", ")", "==", "0", ":", "\n", "\t\t", "return", "None", "\n", "", "else", ":", "\n", "\t\t", "return", "' '", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "sequence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_test_set.is_float": [[27, 29], ["FLOAT_REGEXP.match"], "function", ["None"], ["def", "is_float", "(", "str", ")", ":", "\n", "\t", "return", "True", "if", "FLOAT_REGEXP", ".", "match", "(", "str", ")", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_test_set.replace_num": [[30, 38], ["convert_to_text_task2_test_set.is_float", "new_tokens.append", "new_tokens.append"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.is_float"], ["", "def", "replace_num", "(", "tokens", ")", ":", "\n", "\t", "new_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "if", "is_float", "(", "token", ")", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "\"<num>\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "token", ")", "\n", "", "", "return", "new_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_test_set.preprocess_token": [[39, 41], ["char.isalpha"], "function", ["None"], ["", "def", "preprocess_token", "(", "token", ")", ":", "\n", "\t", "return", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "token", "if", "char", ".", "isalpha", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_test_set.remove_punctuation_and_replace_num": [[42, 55], ["convert_to_text_task2_test_set.replace_num", "token.strip", "convert_to_text_task2_test_set.preprocess_token", "len", "print", "tokenizer.tokenize", "token.lower", "token.isupper"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.replace_num", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.preprocess_token"], ["", "def", "remove_punctuation_and_replace_num", "(", "doc", ")", ":", "\n", "\t", "doc_tokens", "=", "[", "token", ".", "strip", "(", "string", ".", "punctuation", ")", "for", "token", "in", "tokenizer", ".", "tokenize", "(", "doc", ")", "]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", ".", "isupper", "(", ")", "]", "\n", "doc_tokens", "=", "replace_num", "(", "doc_tokens", ")", "\n", "doc_tokens", "=", "[", "preprocess_token", "(", "token", ".", "lower", "(", ")", ")", "for", "token", "in", "doc_tokens", "]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", "in", "cachedStopWords", "]", "\n", "#if len(doc_tokens) > 1:", "\n", "#\treturn \" \".join(doc_tokens)", "\n", "#else:", "\n", "#\treturn ''", "\n", "if", "len", "(", "doc_tokens", ")", "==", "1", ":", "\n", "\t\t", "print", "(", "doc_tokens", ")", "\n", "", "return", "\" \"", ".", "join", "(", "doc_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.tokens": [[207, 209], ["w.lower", "text.split"], "function", ["None"], ["", "", "def", "tokens", "(", "text", ")", ":", "\n", "\t", "return", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "text", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_AB_EmbSum": [[259, 290], ["enumerate", "sklearn.cosine_similarity", "int", "query_vecs.append", "query.split", "numpy.squeeze", "doc_sents_vecs.append", "numpy.array().sum", "numpy.sum", "query_words_list.index", "query.strip().split", "docnade_vocab_large.index", "numpy.expand_dims", "sklearn.cosine_similarity", "sklearn.utils.extmath.softmax", "numpy.dot", "np.expand_dims.append", "len", "numpy.expand_dims", "word.strip", "sent.strip().split", "numpy.array", "query.strip", "numpy.array", "numpy.array", "sent.strip", "query_words_list.index"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax"], ["def", "get_AB_EmbSum", "(", "query", ",", "doc", ")", ":", "\n", "\n", "\t", "query_vecs", "=", "[", "]", "\n", "tokens", "=", "[", "int", "(", "query_words_list", ".", "index", "(", "word", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "query_emb", "=", "query_embedding_matrix", "[", "np", ".", "array", "(", "token", ")", ",", ":", "]", "\n", "query_vecs", ".", "append", "(", "query_emb", ")", "\n", "\n", "", "doc_sents_vecs", "=", "[", "]", "\n", "for", "j", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "tokens", "=", "[", "docnade_vocab_large", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t", "query_vector", "=", "query_embedding_matrix", "[", "query_words_list", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "#query_attentions[(query_attentions < 0.8)] = 0.0", "\n", "query_attentions", "=", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "\n", "", "EmbSum_attns", "=", "np", ".", "squeeze", "(", "EmbSum_attns", ")", "\n", "if", "len", "(", "EmbSum_attns", ".", "shape", ")", "==", "1", ":", "\n", "\t\t\t", "EmbSum_attns", "=", "np", ".", "expand_dims", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "", "doc_sents_vecs", ".", "append", "(", "EmbSum_attns", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "", "sim", "=", "pw", ".", "cosine_similarity", "(", "np", ".", "array", "(", "doc_sents_vecs", ")", ".", "sum", "(", "axis", "=", "1", ")", ",", "np", ".", "sum", "(", "query_vecs", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "#return query_vecs, doc_sents_vecs, sim", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_AB_EmbSum_sim": [[292, 325], ["enumerate", "sklearn.cosine_similarity", "int", "query_vecs.append", "query.split", "numpy.squeeze", "doc_sents_vecs.append", "numpy.array().sum", "numpy.sum", "query_words_list.index", "query.strip().split", "docnade_vocab_large.index", "numpy.expand_dims", "sklearn.cosine_similarity", "numpy.dot", "np.expand_dims.append", "len", "numpy.expand_dims", "word.strip", "sent.strip().split", "numpy.array", "query.strip", "numpy.array", "numpy.array", "sent.strip", "query_words_list.index"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity"], ["", "def", "get_AB_EmbSum_sim", "(", "query", ",", "doc", ")", ":", "\n", "\n", "\t", "query_vecs", "=", "[", "]", "\n", "tokens", "=", "[", "int", "(", "query_words_list", ".", "index", "(", "word", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "query_emb", "=", "query_embedding_matrix", "[", "np", ".", "array", "(", "token", ")", ",", ":", "]", "\n", "query_vecs", ".", "append", "(", "query_emb", ")", "\n", "\n", "", "doc_sents_vecs", "=", "[", "]", "\n", "for", "j", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "tokens", "=", "[", "docnade_vocab_large", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t", "query_vector", "=", "query_embedding_matrix", "[", "query_words_list", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "query_attentions", "[", "(", "query_attentions", "<", "0.8", ")", "]", "=", "0.0", "\n", "#query_attentions = softmax(query_attentions)", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "\n", "", "EmbSum_attns", "=", "np", ".", "squeeze", "(", "EmbSum_attns", ")", "\n", "if", "len", "(", "EmbSum_attns", ".", "shape", ")", "==", "1", ":", "\n", "\t\t\t", "EmbSum_attns", "=", "np", ".", "expand_dims", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "", "doc_sents_vecs", ".", "append", "(", "EmbSum_attns", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "", "sim", "=", "pw", ".", "cosine_similarity", "(", "np", ".", "array", "(", "doc_sents_vecs", ")", ".", "sum", "(", "axis", "=", "1", ")", ",", "np", ".", "sum", "(", "query_vecs", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "#return query_vecs, doc_sents_vecs", "\n", "#return query_vecs, doc_sents_vecs, sim", "\n", "return", "sim", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_EmbSum": [[327, 343], ["int", "query_vecs.append", "numpy.sum", "doc_sents_vecs.append", "query_words_list.index", "query.strip().split", "docnade_vocab_large.index", "word.strip", "sent.strip().split", "query.strip", "numpy.array", "numpy.array", "sent.strip"], "function", ["None"], ["", "def", "get_EmbSum", "(", "query", ",", "doc", ")", ":", "\n", "\n", "\t", "query_vecs", "=", "[", "]", "\n", "tokens", "=", "[", "int", "(", "query_words_list", ".", "index", "(", "word", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "query_emb", "=", "query_embedding_matrix", "[", "np", ".", "array", "(", "token", ")", ",", ":", "]", "\n", "query_vecs", ".", "append", "(", "query_emb", ")", "\n", "\n", "", "doc_sents_vecs", "=", "[", "]", "\n", "for", "sent", "in", "doc", ":", "\n", "\t\t", "tokens", "=", "[", "docnade_vocab_large", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "EmbSum", "=", "np", ".", "sum", "(", "Embs", ",", "axis", "=", "0", ")", "\n", "doc_sents_vecs", ".", "append", "(", "EmbSum", ")", "\n", "\n", "", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_one_hot": [[344, 358], ["numpy.zeros", "numpy.zeros", "enumerate", "total_vocab.index", "len", "len", "word.strip", "query.strip().split", "len", "len", "total_vocab.index", "word.strip", "sent.strip().split", "query.strip", "sent.strip"], "function", ["None"], ["", "def", "get_one_hot", "(", "query", ",", "doc", ")", ":", "\n", "\n", "\t", "query_vecs", "=", "np", ".", "zeros", "(", "(", "len", "(", "doc", ")", ",", "len", "(", "total_vocab", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "indices", "=", "[", "total_vocab", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t", "query_vecs", "[", ":", ",", "index", "]", "=", "1.0", "\n", "\n", "", "doc_sents_vecs", "=", "np", ".", "zeros", "(", "(", "len", "(", "doc", ")", ",", "len", "(", "total_vocab", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "indices", "=", "[", "total_vocab", ".", "index", "(", "word", ".", "strip", "(", ")", ")", "for", "word", "in", "sent", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t\t", "doc_sents_vecs", "[", "i", ",", "index", "]", "=", "1.0", "\n", "\n", "", "", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_bigram": [[359, 372], ["numpy.array", "numpy.tile", "enumerate", "numpy.array", "cv.transform().todense", "np.array.append", "len", "numpy.squeeze", "cv.transform", "numpy.array", "cv.transform().todense", "cv.transform"], "function", ["None"], ["", "def", "get_bigram", "(", "query", ",", "doc", ")", ":", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "\t", "query_vecs", "=", "np", ".", "array", "(", "cv", ".", "transform", "(", "[", "query", "]", ")", ".", "todense", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "query_vecs", "=", "np", ".", "tile", "(", "query_vecs", ",", "[", "len", "(", "doc", ")", ",", "1", "]", ")", "\n", "\n", "doc_sents_vecs", "=", "[", "]", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "\t\t", "doc_sents_vecs", ".", "append", "(", "np", ".", "squeeze", "(", "np", ".", "array", "(", "cv", ".", "transform", "(", "[", "sent", "]", ")", ".", "todense", "(", ")", ")", ",", "axis", "=", "0", ")", ")", "\n", "", "doc_sents_vecs", "=", "np", ".", "array", "(", "doc_sents_vecs", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "query_vecs", ",", "doc_sents_vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.supervised_model_exp_task2.get_bm25_ids": [[534, 542], ["ids.append"], "function", ["None"], ["def", "get_bm25_ids", "(", "tokens", ")", ":", "\n", "\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "try", ":", "\n", "\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens": [[51, 53], ["w.lower", "text.split"], "function", ["None"], ["", "def", "tokens", "(", "text", ")", ":", "\n", "\t", "return", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "text", ".", "split", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.counts_to_sequence": [[54, 59], ["range", "len", "seq.extend", "int"], "function", ["None"], ["", "def", "counts_to_sequence", "(", "counts", ")", ":", "\n", "\t", "seq", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "counts", ")", ")", ":", "\n", "\t\t", "seq", ".", "extend", "(", "[", "i", "]", "*", "int", "(", "counts", "[", "i", "]", ")", ")", "\n", "", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.log_counts": [[60, 63], ["numpy.bincount", "numpy.floor", "numpy.log"], "function", ["None"], ["", "def", "log_counts", "(", "ids", ",", "vocab_size", ")", ":", "\n", "\t", "counts", "=", "np", ".", "bincount", "(", "ids", ",", "minlength", "=", "vocab_size", ")", "\n", "return", "np", ".", "floor", "(", "0.5", "+", "np", ".", "log", "(", "counts", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.preprocess": [[64, 78], ["vocab_to_id.get", "preprocess_data.log_counts", "preprocess_data.counts_to_sequence", "len", "preprocess_data.tokens", "len", "str", "vocab_to_id.get"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.log_counts", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.counts_to_sequence", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens"], ["", "def", "preprocess", "(", "text", ",", "vocab_to_id", ",", "dataset_type", ")", ":", "\n", "\n", "\t", "ids", "=", "[", "vocab_to_id", ".", "get", "(", "x", ")", "for", "x", "in", "tokens", "(", "text", ")", "if", "not", "(", "vocab_to_id", ".", "get", "(", "x", ")", "is", "None", ")", "]", "\n", "\n", "if", "dataset_type", "==", "\"docnade\"", ":", "\n", "\t\t", "counts", "=", "log_counts", "(", "ids", ",", "len", "(", "vocab_to_id", ")", ")", "\n", "sequence", "=", "counts_to_sequence", "(", "counts", ")", "\n", "", "else", ":", "\n", "\t\t", "sequence", "=", "ids", "\n", "\n", "", "if", "len", "(", "sequence", ")", "==", "0", ":", "\n", "\t\t", "return", "None", "\n", "", "else", ":", "\n", "\t\t", "return", "' '", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "sequence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.TF": [[79, 83], ["sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.CountVectorizer.fit"], "function", ["None"], ["", "", "def", "TF", "(", "docs", ",", "max_features", "=", "2000", ")", ":", "\n", "\t", "cv", "=", "CountVectorizer", "(", "tokenizer", "=", "tokens", ",", "min_df", "=", "1", ",", "max_df", "=", "1.0", ",", "max_features", "=", "max_features", ",", "encoding", "=", "'utf-8'", ",", "decode_error", "=", "'ignore'", ")", "\n", "cv", ".", "fit", "(", "docs", ")", "\n", "return", "cv", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.load_file": [[85, 107], ["open", "line.split", "docs.append", "labels.append", "len", "print", "exit", "len", "str().strip().strip().strip", "str().strip().strip", "str().strip", "str"], "function", ["None"], ["", "def", "load_file", "(", "filename", ")", ":", "\n", "\t", "\"\"\"\n\tRead the tab delimited file containing the labels and the docs.\n\n\t\"\"\"", "\n", "labels", "=", "[", "]", "\n", "docs", "=", "[", "]", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "content", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "\n", "if", "len", "(", "content", ")", ">", "2", ":", "\n", "\t\t\t\t", "print", "(", "'incorrect read'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "len", "(", "content", "[", "1", "]", ")", "==", "0", ":", "continue", "\n", "\n", "docs", ".", "append", "(", "str", "(", "content", "[", "1", "]", ")", ".", "strip", "(", "'\\r'", ")", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "labels", ".", "append", "(", "content", "[", "0", "]", ")", "\n", "\n", "", "", "return", "docs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.str2bool": [[109, 116], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "\t", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "\t\t", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "\t\t", "return", "False", "\n", "", "else", ":", "\n", "\t\t", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.main": [[118, 242], ["preprocess_data.str2bool", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "preprocess_data.load_file", "preprocess_data.load_file", "preprocess_data.load_file", "print", "sklearn.utils.shuffle", "sklearn.utils.shuffle", "total_docs.extend", "total_docs.extend", "preprocess_data.TF", "TF.get_feature_names", "model.data.Dataset", "dict", "os.path.exists", "os.makedirs", "numpy.unique", "open", "csv.writer", "zip", "open", "csv.writer", "zip", "open", "csv.writer", "zip", "open", "f.write", "open", "zip", "os.path.isdir", "os.mkdir", "os.path.join", "open", "f.write", "preprocess_data.tokens", "csv.writer.writerow", "new_train_docs.append", "preprocess_data.tokens", "csv.writer.writerow", "new_val_docs.append", "preprocess_data.tokens", "csv.writer.writerow", "new_test_docs.append", "csv.writer.strip", "range", "open", "csv.writer", "model.data.Dataset.rows", "os.path.join", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "str().lower().strip", "f.readlines", "len", "preprocess_data.preprocess", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "str().lower", "removed_indices[].append", "y.split", "csv.writer.writerow", "csv.writer.writerow", "pdb.set_trace", "sorted", "new_label.append", "len", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "len", "str", "str().lower", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.load_file", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.TF", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.tokens", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.preprocess"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "\t", "args", ".", "split_train_val", "=", "str2bool", "(", "args", ".", "split_train_val", ")", "\n", "\n", "doc_train_filename", "=", "args", ".", "training_file", "\n", "doc_val_filename", "=", "args", ".", "validation_file", "\n", "doc_test_filename", "=", "args", ".", "test_file", "\n", "\n", "train_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"training.csv\"", ")", "\n", "val_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"validation.csv\"", ")", "\n", "test_csv_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"test.csv\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "data_output", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "args", ".", "data_output", ")", "\n", "\n", "", "docnade_vocabulary", "=", "args", ".", "vocab_size", "\n", "docnade_vocab_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"vocab_docnade.vocab\"", ")", "\n", "lstm_vocab_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"vocab_lstm.vocab\"", ")", "\n", "\n", "mapping_dict_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "\"mapping_dict.pkl\"", ")", "\n", "\n", "\n", "train_docs", ",", "train_docs_labels", "=", "load_file", "(", "doc_train_filename", ")", "\n", "test_docs", ",", "test_docs_labels", "=", "load_file", "(", "doc_test_filename", ")", "\n", "#if not args.split_train_val:", "\n", "val_docs", ",", "val_docs_labels", "=", "load_file", "(", "doc_val_filename", ")", "\n", "\n", "print", "(", "np", ".", "unique", "(", "train_docs_labels", ")", ")", "\n", "\n", "train_docs", ",", "train_docs_labels", "=", "shuffle", "(", "train_docs", ",", "train_docs_labels", ",", "random_state", "=", "123", ")", "\n", "val_docs", ",", "val_docs_labels", "=", "shuffle", "(", "val_docs", ",", "val_docs_labels", ",", "random_state", "=", "123", ")", "\n", "#test_docs, test_docs_labels = shuffle(test_docs, test_docs_labels, random_state=123)", "\n", "\n", "###########################################################################", "\n", "# Prepare CSV file", "\n", "\n", "new_train_docs", "=", "[", "]", "\n", "with", "open", "(", "train_csv_filename", ",", "'w'", ",", "newline", "=", "''", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "train_docs", ",", "train_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokens", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc_tokens", "=", "[", "token", "for", "token", "in", "new_doc_tokens", "if", "not", "token", "in", "cachedStopWords", "]", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_train_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "new_val_docs", "=", "[", "]", "\n", "with", "open", "(", "val_csv_filename", ",", "'w'", ",", "newline", "=", "''", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "val_docs", ",", "val_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokens", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc_tokens", "=", "[", "token", "for", "token", "in", "new_doc_tokens", "if", "not", "token", "in", "cachedStopWords", "]", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_val_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "new_test_docs", "=", "[", "]", "\n", "with", "open", "(", "test_csv_filename", ",", "'w'", ",", "newline", "=", "''", ")", "as", "csvfile", ":", "\n", "\t\t", "filewriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "doc", ",", "label", "in", "zip", "(", "test_docs", ",", "test_docs_labels", ")", ":", "\n", "\t\t\t", "new_doc_tokens", "=", "tokens", "(", "str", "(", "doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "new_doc_tokens", "=", "[", "token", "for", "token", "in", "new_doc_tokens", "if", "not", "token", "in", "cachedStopWords", "]", "\n", "new_doc", "=", "' '", ".", "join", "(", "new_doc_tokens", ")", "\n", "li", "=", "[", "str", "(", "label", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ",", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "filewriter", ".", "writerow", "(", "li", ")", "\n", "new_test_docs", ".", "append", "(", "str", "(", "new_doc", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "total_docs", "=", "[", "]", "\n", "total_docs", ".", "extend", "(", "new_train_docs", ")", "\n", "total_docs", ".", "extend", "(", "new_val_docs", ")", "\n", "#total_docs.extend(new_test_docs)", "\n", "\n", "# Saving docnade vocabulary", "\n", "#representer = TF(total_docs, max_features=docnade_vocabulary)", "\n", "representer", "=", "TF", "(", "total_docs", ",", "max_features", "=", "None", ")", "\n", "vocab_dict_docnade", "=", "representer", ".", "get_feature_names", "(", ")", "\n", "\n", "with", "open", "(", "docnade_vocab_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "vocab_dict_docnade", ")", ")", "\n", "\n", "# Preparing CSV files for DocNADE Tensorflow", "\n", "", "data", "=", "model", ".", "data", ".", "Dataset", "(", "args", ".", "data_output", ")", "\n", "\n", "with", "open", "(", "docnade_vocab_filename", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "vocab", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "vocab_to_id", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "data_output", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "args", ".", "data_output", ")", "\n", "\n", "", "labels", "=", "{", "}", "\n", "removed_indices", "=", "{", "\"training\"", ":", "[", "]", ",", "\"test\"", ":", "[", "]", ",", "\"validation\"", ":", "[", "]", "}", "\n", "for", "collection", "in", "data", ".", "collections", ":", "\n", "\t\t", "output_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "'{}_docnade.csv'", ".", "format", "(", "collection", ")", ")", "\n", "with", "open", "(", "output_path", ",", "'w'", ",", "newline", "=", "''", ")", "as", "f", ":", "\n", "#with open(output_path, 'w') as f:", "\n", "\t\t\t", "w", "=", "csv", ".", "writer", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "count", "=", "-", "1", "\n", "for", "y", ",", "x", "in", "data", ".", "rows", "(", "collection", ",", "num_epochs", "=", "1", ")", ":", "\n", "\t\t\t\t", "count", "+=", "1", "\n", "try", ":", "\n", "\t\t\t\t\t", "pre", "=", "preprocess", "(", "x", ",", "vocab_to_id", ",", "\"docnade\"", ")", "\n", "if", "pre", "is", "None", ":", "\n", "\t\t\t\t\t\t", "removed_indices", "[", "str", "(", "collection", ")", ".", "lower", "(", ")", "]", ".", "append", "(", "count", ")", "\n", "continue", "\n", "", "if", "':'", "in", "y", ":", "\n", "\t\t\t\t\t\t", "temp_labels", "=", "y", ".", "split", "(", "':'", ")", "\n", "new_label", "=", "[", "]", "\n", "for", "label", "in", "temp_labels", ":", "\n", "\t\t\t\t\t\t\t", "if", "label", "not", "in", "labels", ":", "\n", "\t\t\t\t\t\t\t\t", "labels", "[", "label", "]", "=", "len", "(", "labels", ")", "\n", "", "new_label", ".", "append", "(", "str", "(", "labels", "[", "label", "]", ")", ")", "\n", "", "temp_label", "=", "':'", ".", "join", "(", "new_label", ")", "\n", "w", ".", "writerow", "(", "(", "temp_label", ",", "pre", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "if", "y", "not", "in", "labels", ":", "\n", "\t\t\t\t\t\t\t", "labels", "[", "y", "]", "=", "len", "(", "labels", ")", "\n", "", "w", ".", "writerow", "(", "(", "labels", "[", "y", "]", ",", "pre", ")", ")", "\n", "", "", "except", ":", "\n", "\t\t\t\t\t", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_output", ",", "'labels.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "[", "k", "for", "k", "in", "sorted", "(", "labels", ",", "key", "=", "labels", ".", "get", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.preprocess_data.parse_args": [[244, 262], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--training-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--data-output'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to data output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "'the vocab size'", ")", "\n", "parser", ".", "add_argument", "(", "'--split-train-val'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to do train-val split'", ")", "\n", "parser", ".", "add_argument", "(", "'--split-num'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'number of documents in validation set'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.__init__": [[24, 36], ["gensim.corpora.Dictionary", "BM25_task2.BM25.buildDictionary", "BM25_task2.BM25.TFIDF_Generator"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.buildDictionary", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.TFIDF_Generator"], ["\t", "def", "__init__", "(", "self", ",", "fn_docs", ",", "delimiter", "=", "' '", ")", ":", "\n", "\t\t", "self", ".", "dictionary", "=", "corpora", ".", "Dictionary", "(", ")", "\n", "self", ".", "DF", "=", "{", "}", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "DocTF", "=", "[", "]", "\n", "self", ".", "DocIDF", "=", "{", "}", "\n", "self", ".", "N", "=", "0", "\n", "self", ".", "DocAvgLen", "=", "0", "\n", "self", ".", "fn_docs", "=", "fn_docs", "\n", "self", ".", "DocLen", "=", "[", "]", "\n", "self", ".", "buildDictionary", "(", ")", "\n", "self", ".", "TFIDF_Generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.buildDictionary": [[37, 42], ["BM25_task2.BM25.dictionary.add_documents", "raw_data.append", "line.strip().split", "line.strip"], "methods", ["None"], ["", "def", "buildDictionary", "(", "self", ")", ":", "\n", "\t\t", "raw_data", "=", "[", "]", "\n", "for", "line", "in", "self", ".", "fn_docs", ":", "\n", "\t\t\t", "raw_data", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "delimiter", ")", ")", "\n", "", "self", ".", "dictionary", ".", "add_documents", "(", "raw_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.TFIDF_Generator": [[43, 59], ["line.strip().split", "len", "BM25_task2.BM25.DocLen.append", "dict", "dict.items", "BM25_task2.BM25.DocTF.append", "math.log", "len", "line.strip", "BM25_task2.BM25.dictionary.doc2bow", "len"], "methods", ["None"], ["", "def", "TFIDF_Generator", "(", "self", ",", "base", "=", "math", ".", "e", ")", ":", "\n", "\t\t", "docTotalLen", "=", "0", "\n", "for", "line", "in", "self", ".", "fn_docs", ":", "\n", "\t\t\t", "doc", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "docTotalLen", "+=", "len", "(", "doc", ")", "\n", "self", ".", "DocLen", ".", "append", "(", "len", "(", "doc", ")", ")", "\n", "bow", "=", "dict", "(", "[", "(", "term", ",", "freq", "*", "1.0", "/", "len", "(", "doc", ")", ")", "for", "term", ",", "freq", "in", "self", ".", "dictionary", ".", "doc2bow", "(", "doc", ")", "]", ")", "\n", "for", "term", ",", "tf", "in", "bow", ".", "items", "(", ")", ":", "\n", "\t\t\t\t", "if", "term", "not", "in", "self", ".", "DF", ":", "\n", "\t\t\t\t\t", "self", ".", "DF", "[", "term", "]", "=", "0", "\n", "", "self", ".", "DF", "[", "term", "]", "+=", "1", "\n", "", "self", ".", "DocTF", ".", "append", "(", "bow", ")", "\n", "self", ".", "N", "=", "self", ".", "N", "+", "1", "\n", "", "for", "term", "in", "self", ".", "DF", ":", "\n", "\t\t\t", "self", ".", "DocIDF", "[", "term", "]", "=", "math", ".", "log", "(", "1", "+", "(", "(", "self", ".", "N", "-", "self", ".", "DF", "[", "term", "]", "+", "0.5", ")", "/", "(", "self", ".", "DF", "[", "term", "]", "+", "0.5", ")", ")", ",", "base", ")", "\n", "", "self", ".", "DocAvgLen", "=", "docTotalLen", "/", "self", ".", "N", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score": [[61, 102], ["BM25_task2.BM25.dictionary.doc2bow", "enumerate", "scores.append", "set", "set", "tmp_score.append", "sum", "dict().keys", "doc.keys", "numpy.zeros", "enumerate", "sklearn.cosine_similarity", "commonTerms.union.union.union", "BM25_task2.BM25.dictionary.token2id.items", "id2token[].lower().strip", "similar_words.extend", "set", "pdb.set_trace", "dict", "doc.keys", "len", "id2token[].lower", "numpy.array", "enumerate", "query_vocab.index", "embedding_vocab.index"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity"], ["", "def", "BM25Score", "(", "self", ",", "Query", "=", "[", "]", ",", "k1", "=", "1.5", ",", "b", "=", "0.75", ",", "\n", "embedding_matrix", "=", "None", ",", "embedding_vocab", "=", "None", ",", "\n", "query_matrix", "=", "None", ",", "query_vocab", "=", "None", ",", "\n", "sim_threshold", "=", "0.30", ")", ":", "\n", "\t\t", "query_bow", "=", "self", ".", "dictionary", ".", "doc2bow", "(", "Query", ")", "\n", "scores", "=", "[", "]", "\n", "for", "idx", ",", "doc", "in", "enumerate", "(", "self", ".", "DocTF", ")", ":", "\n", "\t\t\t", "commonTerms", "=", "set", "(", "dict", "(", "query_bow", ")", ".", "keys", "(", ")", ")", "&", "set", "(", "doc", ".", "keys", "(", ")", ")", "\n", "if", "not", "embedding_matrix", "is", "None", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "\t\t\t\t", "id2token", "=", "{", "id", ":", "word", "for", "word", ",", "id", "in", "self", ".", "dictionary", ".", "token2id", ".", "items", "(", ")", "}", "\n", "try", ":", "\n", "\t\t\t\t\t", "query_words", "=", "Query", "\n", "#doc_words = [self.dictionary.id2token[id].lower().strip() for id in doc.keys()]", "\n", "doc_words", "=", "[", "id2token", "[", "id", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "for", "id", "in", "doc", ".", "keys", "(", ")", "]", "\n", "query_vecs", "=", "query_matrix", "[", "np", ".", "array", "(", "[", "query_vocab", ".", "index", "(", "word", ")", "for", "word", "in", "query_words", "]", ")", ",", ":", "]", "\n", "#doc_vecs = embedding_matrix[np.array([embedding_vocab.index(word) for word in doc_words]), :]", "\n", "doc_vecs", "=", "np", ".", "zeros", "(", "(", "len", "(", "doc_words", ")", ",", "embedding_matrix", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "doc_words", ")", ":", "\n", "\t\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t\t", "doc_vecs", "[", "i", ",", ":", "]", "=", "embedding_matrix", "[", "embedding_vocab", ".", "index", "(", "word", ")", ",", ":", "]", "\n", "", "except", "ValueError", ":", "\n", "\t\t\t\t\t\t\t", "pass", "\n", "#import pdb; pdb.set_trace()", "\n", "", "", "sim", "=", "pw", ".", "cosine_similarity", "(", "query_vecs", ",", "doc_vecs", ")", "\n", "#sim = eval.softmax(pw.cosine_similarity(query_vecs, doc_vecs), axis=1)", "\n", "similar_words", "=", "[", "]", "\n", "for", "row", "in", "sim", ":", "\n", "\t\t\t\t\t\t", "sim_words", "=", "[", "self", ".", "dictionary", ".", "token2id", "[", "doc_words", "[", "ind", "]", "]", "for", "ind", ",", "val", "in", "enumerate", "(", "row", ")", "if", "val", ">=", "sim_threshold", "]", "\n", "similar_words", ".", "extend", "(", "sim_words", ")", "\n", "", "commonTerms", "=", "commonTerms", ".", "union", "(", "set", "(", "similar_words", ")", ")", "\n", "", "except", "IndexError", ":", "\n", "\t\t\t\t\t", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "tmp_score", "=", "[", "]", "\n", "doc_terms_len", "=", "self", ".", "DocLen", "[", "idx", "]", "\n", "for", "term", "in", "commonTerms", ":", "\n", "\t\t\t\t", "upper", "=", "(", "doc", "[", "term", "]", "*", "(", "k1", "+", "1", ")", ")", "\n", "below", "=", "(", "(", "doc", "[", "term", "]", ")", "+", "k1", "*", "(", "1", "-", "b", "+", "b", "*", "doc_terms_len", "/", "self", ".", "DocAvgLen", ")", ")", "\n", "tmp_score", ".", "append", "(", "self", ".", "DocIDF", "[", "term", "]", "*", "upper", "/", "below", ")", "\n", "", "scores", ".", "append", "(", "sum", "(", "tmp_score", ")", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.TFIDF": [[103, 110], ["doc_tfidf.sort", "tfidf.append", "doc.items"], "methods", ["None"], ["", "def", "TFIDF", "(", "self", ")", ":", "\n", "\t\t", "tfidf", "=", "[", "]", "\n", "for", "doc", "in", "self", ".", "DocTF", ":", "\n", "\t\t\t", "doc_tfidf", "=", "[", "(", "term", ",", "tf", "*", "self", ".", "DocIDF", "[", "term", "]", ")", "for", "term", ",", "tf", "in", "doc", ".", "items", "(", ")", "]", "\n", "doc_tfidf", ".", "sort", "(", ")", "\n", "tfidf", ".", "append", "(", "doc_tfidf", ")", "\n", "", "return", "tfidf", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.Items": [[111, 117], ["BM25_task2.BM25.dictionary.items", "sorted", "operator.itemgetter"], "methods", ["None"], ["", "def", "Items", "(", "self", ")", ":", "\n", "# Return a list [(term_idx, term_desc),]", "\n", "\t\t", "items", "=", "self", ".", "dictionary", ".", "items", "(", ")", "\n", "#items.sort()", "\n", "items", "=", "sorted", "(", "items", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.query_doc_overlap": [[118, 170], ["BM25_task2.uwords", "BM25_task2.ubigrams", "BM25_task2.uwords", "len", "BM25_task2.ubigrams", "len", "float", "float", "float", "float", "int", "float", "float", "float", "float", "len", "qword.split", "len", "BM25_task2.uwords", "BM25_task2.ubigrams"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams"], ["", "def", "query_doc_overlap", "(", "self", ",", "qwords", ",", "dwords", ")", ":", "\n", "\n", "# % Query words in doc.", "\n", "\t\t", "qwords_in_doc", "=", "0", "\n", "idf_qwords_in_doc", "=", "0.0", "\n", "idf_qwords", "=", "0.0", "\n", "for", "qword", "in", "uwords", "(", "qwords", ")", ":", "\n", "\t\t\t", "idf_qwords", "+=", "self", ".", "DocIDF", "[", "qword", "]", "\n", "for", "dword", "in", "uwords", "(", "dwords", ")", ":", "\n", "\t\t\t\t", "if", "qword", "==", "dword", ":", "\n", "\t\t\t\t\t", "idf_qwords_in_doc", "+=", "self", ".", "DocIDF", "[", "qword", "]", "\n", "qwords_in_doc", "+=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "qwords", ")", "<=", "0", ":", "\n", "\t\t\t", "qwords_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "qwords_in_doc_val", "=", "(", "float", "(", "qwords_in_doc", ")", "/", "\n", "float", "(", "len", "(", "uwords", "(", "qwords", ")", ")", ")", ")", "\n", "", "if", "idf_qwords", "<=", "0.0", ":", "\n", "\t\t\t", "idf_qwords_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "idf_qwords_in_doc_val", "=", "float", "(", "idf_qwords_in_doc", ")", "/", "float", "(", "idf_qwords", ")", "\n", "\n", "# % Query bigrams  in doc.", "\n", "", "qwords_bigrams_in_doc", "=", "0", "\n", "idf_qwords_bigrams_in_doc", "=", "0.0", "\n", "idf_bigrams", "=", "0.0", "\n", "for", "qword", "in", "ubigrams", "(", "qwords", ")", ":", "\n", "\t\t\t", "wrds", "=", "[", "int", "(", "w", ")", "for", "w", "in", "qword", ".", "split", "(", "'_'", ")", "]", "\n", "idf_bigrams", "+=", "self", ".", "DocIDF", "[", "wrds", "[", "0", "]", "]", "*", "self", ".", "DocIDF", "[", "wrds", "[", "1", "]", "]", "\n", "for", "dword", "in", "ubigrams", "(", "dwords", ")", ":", "\n", "\t\t\t\t", "if", "qword", "==", "dword", ":", "\n", "\t\t\t\t\t", "qwords_bigrams_in_doc", "+=", "1", "\n", "idf_qwords_bigrams_in_doc", "+=", "(", "self", ".", "DocIDF", "[", "wrds", "[", "0", "]", "]", "\n", "*", "self", ".", "DocIDF", "[", "wrds", "[", "1", "]", "]", ")", "\n", "break", "\n", "#if len(qwords) <= 0:", "\n", "", "", "", "if", "len", "(", "qwords", ")", "<=", "1", ":", "\n", "\t\t\t", "qwords_bigrams_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "qwords_bigrams_in_doc_val", "=", "(", "float", "(", "qwords_bigrams_in_doc", ")", "/", "\n", "float", "(", "len", "(", "ubigrams", "(", "qwords", ")", ")", ")", ")", "\n", "", "if", "idf_bigrams", "<=", "0.0", ":", "\n", "\t\t\t", "idf_qwords_bigrams_in_doc_val", "=", "0.0", "\n", "", "else", ":", "\n", "\t\t\t", "idf_qwords_bigrams_in_doc_val", "=", "(", "float", "(", "idf_qwords_bigrams_in_doc", ")", "/", "\n", "float", "(", "idf_bigrams", ")", ")", "\n", "\n", "", "return", "[", "qwords_in_doc_val", ",", "\n", "qwords_bigrams_in_doc_val", ",", "\n", "idf_qwords_in_doc_val", ",", "\n", "idf_qwords_bigrams_in_doc_val", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.uwords": [[11, 16], ["None"], "function", ["None"], ["def", "uwords", "(", "words", ")", ":", "\n", "\t", "uw", "=", "{", "}", "\n", "for", "w", "in", "words", ":", "\n", "\t\t", "uw", "[", "w", "]", "=", "1", "\n", "", "return", "[", "w", "for", "w", "in", "uw", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.ubigrams": [[17, 22], ["range", "len", "str", "str"], "function", ["None"], ["", "def", "ubigrams", "(", "words", ")", ":", "\n", "\t", "uw", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "1", ")", ":", "\n", "\t\t", "uw", "[", "str", "(", "words", "[", "i", "]", ")", "+", "'_'", "+", "str", "(", "words", "[", "i", "+", "1", "]", ")", "]", "=", "1", "\n", "", "return", "[", "w", "for", "w", "in", "uw", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.loadGloveModel": [[39, 63], ["print", "open", "print", "line.split", "numpy.array", "len", "os.path.join", "os.path.join", "float", "os.path.join", "os.path.join", "print", "exit"], "function", ["None"], ["def", "loadGloveModel", "(", "gloveFile", "=", "None", ",", "params", "=", "None", ")", ":", "\n", "\t", "if", "gloveFile", "is", "None", ":", "\n", "\t\t", "if", "params", ".", "hidden_size", "==", "50", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.50d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "100", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.100d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "200", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.200d.txt\"", ")", "\n", "", "elif", "params", ".", "hidden_size", "==", "300", ":", "\n", "\t\t\t", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.300d.txt\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "'Invalid dimension [%d] for Glove pretrained embedding matrix!!'", "%", "params", ".", "hidden_size", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "print", "(", "\"Loading Glove Model\"", ")", "\n", "f", "=", "open", "(", "gloveFile", ",", "'r'", ")", "\n", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "\t\t", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.loadBioModel": [[65, 72], ["print", "gensim.models.keyedvectors.KeyedVectors.load_word2vec_format", "print"], "function", ["None"], ["", "def", "loadBioModel", "(", "BioFile", "=", "None", ",", "params", "=", "None", ")", ":", "\n", "\t", "print", "(", "\"Loading BioNLP Model\"", ")", "\n", "#model = KeyedVectors.load_word2vec_format('./datasets/PubMed-w2v.bin', binary=True)", "\n", "model", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "'./datasets/PubMed-and-PMC-w2v.bin'", ",", "binary", "=", "True", ")", "\n", "\n", "print", "(", "\"Binary model loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.train": [[74, 784], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "tensorflow.Session", "tensorflow.placeholder", "tensorflow.summary.scalar", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.summary.merge_all", "tensorflow.train.Saver", "tensorflow.local_variables_initializer().run", "tensorflow.global_variables_initializer().run", "dataset.batches", "numpy.array", "numpy.array", "numpy.array", "range", "tensorflow.global_variables", "dataset.batches", "open", "next", "session.run", "losses.append", "tensorflow.ConfigProto", "tensorflow.local_variables_initializer", "tensorflow.global_variables_initializer", "line.strip", "next", "print", "dataset.batches", "numpy.mean", "numpy.exp", "print", "dataset.batches", "sklearn.metrics.accuracy_score", "print", "model.softmax", "model.evaluate_mAP", "print", "print", "sys.exit", "f.readlines", "dataset.rows", "dataset.rows", "dataset.rows", "session.run", "this_val_nll.append", "this_val_loss_normed.append", "numpy.mean", "print", "tf.train.Saver.save", "open", "f.write", "print", "dataset.batches", "session.run", "val_pred_labels.append", "val_pred_logits.append", "int", "print", "tf.train.Saver.save", "dataset.batches", "sklearn.utils.extmath.softmax", "sklearn.metrics.accuracy_score", "numpy.save", "numpy.save", "numpy.save", "enumerate", "numpy.array", "zip", "BM25.BM25", "id2label.values", "numpy.stack", "enumerate", "numpy.array", "zip", "zip", "numpy.load", "numpy.zeros", "enumerate", "numpy.array", "zip", "zip", "zip", "open", "f.write", "print", "dataset.batches", "sklearn.utils.extmath.softmax", "sklearn.metrics.accuracy_score", "numpy.save", "numpy.save", "numpy.save", "enumerate", "numpy.array", "zip", "BM25.BM25", "id2label.values", "numpy.stack", "enumerate", "numpy.array", "zip", "zip", "numpy.load", "numpy.zeros", "enumerate", "numpy.array", "zip", "zip", "zip", "numpy.array", "print", "tf.train.Saver.save", "open", "f.write", "print", "tensorflow.GPUOptions", "os.path.join", "next", "session.run", "test_pred_labels.append", "sklearn.utils.extmath.softmax.append", "numpy.array", "int", "os.path.join", "numpy.array", "os.path.join", "numpy.array", "os.path.join", "numpy.array", "np.array.append", "int", "dict_label[].append", "open", "dict_label.keys", "open", "csv.reader", "query.split.split", "BM25.BM25.BM25Score", "numpy.add", "bm25_extra_scores_list.append", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "open", "open", "csv.reader", "enumerate", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "os.path.join", "session.run", "test_pred_labels.append", "sklearn.utils.extmath.softmax.append", "numpy.array", "int", "os.path.join", "numpy.array", "os.path.join", "numpy.array", "os.path.join", "numpy.array", "np.array.append", "int", "dict_label[].append", "open", "dict_label.keys", "open", "csv.reader", "query.split.split", "BM25.BM25.BM25Score", "numpy.add", "bm25_extra_scores_list.append", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "open", "open", "csv.reader", "enumerate", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "os.path.join", "next", "numpy.unique", "os.path.join", "f.write", "line[].strip", "doc.split.split", "train_DocNADE.train.get_bm25_ids"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.get_bm25_ids"], ["", "def", "train", "(", "model", ",", "dataset", ",", "params", ")", ":", "\n", "\t", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'logs'", ")", "\n", "model_dir_ir", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_ir'", ")", "\n", "model_dir_ppl", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_ppl'", ")", "\n", "model_dir_sup", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_sup'", ")", "\n", "model_dir_mAP", "=", "os", ".", "path", ".", "join", "(", "params", ".", "model", ",", "'model_mAP'", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", ".", "num_cores", ",", "\n", "intra_op_parallelism_threads", "=", "params", ".", "num_cores", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "session", ":", "\n", "\t\t", "avg_loss", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'loss_ph'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss'", ",", "avg_loss", ")", "\n", "\n", "validation", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'validation_ph'", ")", "\n", "validation_accuracy", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ",", "'validation_acc'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'validation'", ",", "validation", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'validation_accuracy'", ",", "validation_accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", ",", "session", ".", "graph", ")", "\n", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "tf", ".", "local_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "\n", "losses", "=", "[", "]", "\n", "\n", "if", "params", ".", "input_type", "==", "\"both\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade'", "\n", "validation_filename", "=", "'validation_docnade'", "\n", "test_filename", "=", "'test_docnade'", "\n", "", "elif", "params", ".", "input_type", "==", "\"abstract\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade_abstracts'", "\n", "validation_filename", "=", "'validation_docnade_abstracts'", "\n", "test_filename", "=", "'test_docnade_abstracts'", "\n", "", "elif", "params", ".", "input_type", "==", "\"title\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade_titles'", "\n", "validation_filename", "=", "'validation_docnade_titles'", "\n", "test_filename", "=", "'test_docnade_titles'", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "\"Wrong value for params.input_type: \"", ",", "params", ".", "input_type", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t", "training_title_filename", "=", "'training_docnade_titles'", "\n", "validation_title_filename", "=", "'validation_docnade_titles'", "\n", "test_title_filename", "=", "'test_docnade_titles'", "\n", "\n", "# This currently streams from disk. You set num_epochs=1 and", "\n", "# wrap this call with something like itertools.cycle to keep", "\n", "# this data in memory.", "\n", "# shuffle: the order of words in the sentence for DocNADE", "\n", "\n", "#training_data = dataset.batches('training_docnade', params.batch_size, shuffle=True, multilabel=params.multi_label)", "\n", "", "training_data", "=", "dataset", ".", "batches", "(", "training_filename", ",", "params", ".", "batch_size", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t", "training_title_data", "=", "dataset", ".", "batches", "(", "training_title_filename", ",", "params", ".", "batch_size", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", "\n", "\n", "", "id2label", "=", "{", "0", ":", "\"Acute_Threat_Fear\"", ",", "1", ":", "\"Arousal\"", ",", "2", ":", "\"Circadian_Rhythms\"", ",", "3", ":", "\"Frustrative_Nonreward\"", ",", "\n", "4", ":", "\"Loss\"", ",", "5", ":", "\"Potential_Threat_Anxiety\"", ",", "6", ":", "\"Sleep_Wakefulness\"", ",", "7", ":", "\"Sustained_Threat\"", "}", "\n", "\n", "with", "open", "(", "params", ".", "dataset", "+", "\"/test_ids.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "ids", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "best_val_IR", "=", "0.0", "\n", "best_val_acc", "=", "0.0", "\n", "best_val_mAP", "=", "0.0", "\n", "best_val_nll", "=", "np", ".", "inf", "\n", "best_val_ppl", "=", "np", ".", "inf", "\n", "best_val_disc_accuracy", "=", "0.0", "\n", "\n", "best_test_IR", "=", "0.0", "\n", "best_test_nll", "=", "np", ".", "inf", "\n", "best_test_ppl", "=", "np", ".", "inf", "\n", "best_test_disc_accuracy", "=", "0.0", "\n", "\n", "patience", "=", "params", ".", "patience", "\n", "\n", "patience_count", "=", "0", "\n", "patience_count_ir", "=", "0", "\n", "best_train_nll", "=", "np", ".", "inf", "\n", "\n", "training_labels", "=", "np", ".", "array", "(", "\n", "#[[y] for y, _ in dataset.rows('training_docnade', num_epochs=1)]", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "training_filename", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "validation_labels", "=", "np", ".", "array", "(", "\n", "#[[y] for y, _ in dataset.rows('validation_docnade', num_epochs=1)]", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "validation_filename", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "test_labels", "=", "np", ".", "array", "(", "\n", "#[[y] for y, _ in dataset.rows('test_docnade', num_epochs=1)]", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "test_filename", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "#initial_weights = session.run(\"embeddings_lambda_list_unclipped:0\")", "\n", "#np.save(os.path.join(log_dir, \"initial_sup_weights.npy\"), initial_weights)", "\n", "\n", "for", "step", "in", "range", "(", "params", ".", "num_steps", "+", "1", ")", ":", "\n", "\t\t\t", "this_loss", "=", "-", "1.", "\n", "\n", "y", ",", "x", ",", "seq_lengths", "=", "next", "(", "training_data", ")", "\n", "\n", "train_feed_dict", "=", "{", "}", "\n", "train_feed_dict", "[", "model", ".", "x", "]", "=", "x", "\n", "train_feed_dict", "[", "model", ".", "y", "]", "=", "y", "\n", "train_feed_dict", "[", "model", ".", "seq_lengths", "]", "=", "seq_lengths", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t\t", "y_title", ",", "x_title", ",", "seq_lengths_title", "=", "next", "(", "training_title_data", ")", "\n", "\n", "train_feed_dict", "[", "model", ".", "x_title", "]", "=", "x_title", "\n", "train_feed_dict", "[", "model", ".", "seq_lengths_title", "]", "=", "seq_lengths_title", "\n", "\n", "", "_", ",", "loss", ",", "loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "opt", ",", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "train_feed_dict", ")", "\n", "this_loss", "=", "loss", "\n", "losses", ".", "append", "(", "this_loss", ")", "\n", "\n", "if", "(", "step", "%", "params", ".", "log_every", "==", "0", ")", ":", "\n", "\t\t\t\t", "print", "(", "'{}: {:.6f}'", ".", "format", "(", "step", ",", "this_loss", ")", ")", "\n", "\n", "", "if", "step", "and", "(", "step", "%", "params", ".", "validation_ppl_freq", ")", "==", "0", ":", "\n", "\n", "\t\t\t\t", "this_val_nll", "=", "[", "]", "\n", "this_val_loss_normed", "=", "[", "]", "\n", "# val_loss_unnormed is NLL", "\n", "this_val_nll_bw", "=", "[", "]", "\n", "this_val_loss_normed_bw", "=", "[", "]", "\n", "\n", "for", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "'validation_docnade'", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\n", "\t\t\t\t\t", "val_loss_normed", ",", "val_loss_unnormed", "=", "session", ".", "run", "(", "[", "model", ".", "loss_normed", ",", "model", ".", "loss_unnormed", "]", ",", "feed_dict", "=", "{", "\n", "model", ".", "x", ":", "val_x", ",", "\n", "model", ".", "y", ":", "val_y", ",", "\n", "model", ".", "seq_lengths", ":", "val_seq_lengths", "\n", "}", ")", "\n", "\n", "this_val_nll", ".", "append", "(", "val_loss_unnormed", ")", "\n", "this_val_loss_normed", ".", "append", "(", "val_loss_normed", ")", "\n", "\n", "", "total_val_nll", "=", "np", ".", "mean", "(", "this_val_nll", ")", "\n", "total_val_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_val_loss_normed", ")", ")", "\n", "\n", "if", "total_val_ppl", "<", "best_val_ppl", ":", "\n", "\t\t\t\t\t", "best_val_ppl", "=", "total_val_ppl", "\n", "print", "(", "'saving: {}'", ".", "format", "(", "model_dir_ppl", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "model_dir_ppl", "+", "'/model_ppl'", ",", "global_step", "=", "1", ")", "\n", "\n", "# Early stopping", "\n", "", "if", "total_val_nll", "<", "best_val_nll", ":", "\n", "\t\t\t\t\t", "best_val_nll", "=", "total_val_nll", "\n", "patience_count", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "patience_count", "+=", "1", "\n", "\n", "", "print", "(", "'This val PPL: {:.3f} (best val PPL: {:.3f},  best val loss: {:.3f}'", ".", "format", "(", "\n", "total_val_ppl", ",", "\n", "best_val_ppl", "or", "0.0", ",", "\n", "best_val_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Step: %i,\tval PPL: %s,\t best val PPL: %s,\tbest val loss: %s\\n\"", "%", "\n", "(", "step", ",", "total_val_ppl", ",", "best_val_ppl", ",", "best_val_nll", ")", ")", "\n", "\n", "", "if", "patience_count", ">", "patience", ":", "\n", "\t\t\t\t\t", "print", "(", "\"Early stopping criterion satisfied.\"", ")", "\n", "break", "\n", "\n", "", "", "if", "step", "and", "(", "step", "%", "params", ".", "validation_ir_freq", ")", "==", "0", ":", "\n", "\n", "## Classification accuracy", "\n", "\n", "\t\t\t\t", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t\t\t", "validation_title_data", "=", "dataset", ".", "batches", "(", "validation_title_filename", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", "\n", "validation_filename", "=", "'validation_docnade_abstracts'", "\n", "\n", "", "val_pred_labels", "=", "[", "]", "\n", "val_pred_logits", "=", "[", "]", "\n", "for", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "validation_filename", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t\t", "val_feed_dict", "=", "{", "}", "\n", "val_feed_dict", "[", "model", ".", "x", "]", "=", "val_x", "\n", "val_feed_dict", "[", "model", ".", "y", "]", "=", "val_y", "\n", "val_feed_dict", "[", "model", ".", "seq_lengths", "]", "=", "val_seq_lengths", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t\t\t\t", "val_y_title", ",", "val_x_title", ",", "val_seq_lengths_title", "=", "next", "(", "validation_title_data", ")", "\n", "\n", "val_feed_dict", "[", "model", ".", "x_title", "]", "=", "val_x_title", "\n", "val_feed_dict", "[", "model", ".", "seq_lengths_title", "]", "=", "val_seq_lengths_title", "\n", "\n", "", "pred_labels", ",", "pred_logits", "=", "session", ".", "run", "(", "[", "model", ".", "pred_labels", ",", "model", ".", "disc_output", "]", ",", "feed_dict", "=", "val_feed_dict", ")", "\n", "\n", "#val_pred_labels.append(pred_labels[0][0])", "\n", "val_pred_labels", ".", "append", "(", "pred_labels", "[", "0", "]", ")", "\n", "val_pred_logits", ".", "append", "(", "pred_logits", "[", "0", "]", ")", "\n", "\n", "", "val_true_labels", "=", "[", "int", "(", "label", "[", "0", "]", ")", "for", "label", "in", "validation_labels", "]", "\n", "\n", "val_acc", "=", "accuracy_score", "(", "val_true_labels", ",", "val_pred_labels", ")", "\n", "\n", "if", "val_acc", ">", "best_val_acc", ":", "\n", "\t\t\t\t\t", "best_val_acc", "=", "val_acc", "\n", "print", "(", "'saving: {}'", ".", "format", "(", "model_dir_sup", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "model_dir_sup", "+", "'/model_sup'", ",", "global_step", "=", "1", ")", "\n", "patience_count_ir", "=", "0", "\n", "\n", "test_pred_labels", "=", "[", "]", "\n", "test_pred_logits", "=", "[", "]", "\n", "for", "test_y", ",", "test_x", ",", "test_seq_lengths", "in", "dataset", ".", "batches", "(", "test_filename", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t\t\t", "test_feed_dict", "=", "{", "}", "\n", "test_feed_dict", "[", "model", ".", "x", "]", "=", "test_x", "\n", "test_feed_dict", "[", "model", ".", "y", "]", "=", "test_y", "\n", "test_feed_dict", "[", "model", ".", "seq_lengths", "]", "=", "test_seq_lengths", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t\t\t\t\t", "test_y_title", ",", "test_x_title", ",", "test_seq_lengths_title", "=", "next", "(", "validation_title_data", ")", "\n", "\n", "test_feed_dict", "[", "model", ".", "x_title", "]", "=", "test_x_title", "\n", "test_feed_dict", "[", "model", ".", "seq_lengths_title", "]", "=", "test_seq_lengths_title", "\n", "\n", "", "pred_labels", ",", "pred_logits", "=", "session", ".", "run", "(", "[", "model", ".", "pred_labels", ",", "model", ".", "disc_output", "]", ",", "feed_dict", "=", "test_feed_dict", ")", "\n", "\n", "#test_pred_labels.append(pred_labels[0][0])", "\n", "test_pred_labels", ".", "append", "(", "pred_labels", "[", "0", "]", ")", "\n", "test_pred_logits", ".", "append", "(", "pred_logits", "[", "0", "]", ")", "\n", "\n", "", "test_pred_logits", "=", "softmax", "(", "np", ".", "array", "(", "test_pred_logits", ")", ")", "\n", "\n", "test_true_labels", "=", "[", "int", "(", "label", "[", "0", "]", ")", "for", "label", "in", "test_labels", "]", "\n", "\n", "test_acc", "=", "accuracy_score", "(", "test_true_labels", ",", "test_pred_labels", ")", "\n", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_pred_logits.npy\"", ")", ",", "np", ".", "array", "(", "test_pred_logits", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_pred_labels.npy\"", ")", ",", "np", ".", "array", "(", "test_pred_labels", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_true_labels.npy\"", ")", ",", "np", ".", "array", "(", "test_true_labels", ")", ")", "\n", "\n", "docnade_probs", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "docnade_probs", ".", "append", "(", "test_pred_logits", "[", "i", ",", "label", "]", ")", "\n", "", "docnade_probs", "=", "np", ".", "array", "(", "docnade_probs", ")", "\n", "\n", "dict_label", "=", "{", "int", "(", "label", ")", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "docnade_probs", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "int", "(", "label", ")", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_docnade_classify.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "\n", "", "", "", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "docs", "=", "[", "line", "[", "1", "]", ".", "strip", "(", ")", "for", "line", "in", "file_reader", "]", "\n", "\n", "", "bm25", "=", "BM25", ".", "BM25", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "delimiter", "=", "' '", ")", "\n", "\n", "def", "get_bm25_ids", "(", "tokens", ")", ":", "\n", "\t\t\t\t\t\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t\t\t\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n", "", "bm25_extra_scores_list", "=", "[", "]", "\n", "#for query in queries:", "\n", "for", "value", "in", "id2label", ".", "values", "(", ")", ":", "\n", "\t\t\t\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "query", ")", "\n", "\n", "extra_features", "=", "[", "]", "\n", "for", "doc", "in", "docs", ":", "\n", "\t\t\t\t\t\t\t", "doc", "=", "doc", ".", "split", "(", ")", "\n", "#doc_ids = [bm25.dictionary.token2id[token] for token in doc]", "\n", "#query_ids = [bm25.dictionary.token2id[token] for token in query]", "\n", "doc_ids", "=", "get_bm25_ids", "(", "doc", ")", "\n", "query_ids", "=", "get_bm25_ids", "(", "query", ")", "\n", "\n", "feats", "=", "bm25", ".", "query_doc_overlap", "(", "query_ids", ",", "doc_ids", ")", "\n", "extra_features", ".", "append", "(", "np", ".", "sum", "(", "feats", ")", ")", "\n", "#scores = np.stack([np.array(scores), np.array(extra_features)], axis=1)", "\n", "", "scores", "=", "np", ".", "add", "(", "np", ".", "array", "(", "scores", ")", ",", "np", ".", "array", "(", "extra_features", ")", ")", "\n", "\n", "bm25_extra_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_extra_scores_matrix", "=", "np", ".", "stack", "(", "bm25_extra_scores_list", ",", "axis", "=", "1", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "relevance_score_bm25_extra", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "relevance_score_bm25_extra", ".", "append", "(", "bm25_extra_scores_matrix", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_bm25_extra", "=", "np", ".", "array", "(", "relevance_score_bm25_extra", ")", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_bm25_extra", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_bm25extra.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score", "=", "docnade_probs", "+", "relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_with_bm25extra.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "#with open(\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/vocab_docnade.vocab\", \"r\") as f:", "\n", "", "", "", "with", "open", "(", "\"./pretrained_embeddings/biggest_vocab.vocab\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "total_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "total_embedding_matrix", "=", "np", ".", "load", "(", "'./pretrained_embeddings/fasttext_embeddings_biggest_vocab.npy'", ")", "\n", "\n", "similarity_scores_Attention_Based_EmbSum", "=", "np", ".", "zeros", "(", "(", "len", "(", "test_true_labels", ")", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t\t\t\t", "tokens", "=", "[", "total_vocab", ".", "index", "(", "word", ")", "for", "word", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "total_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "#for i, query in enumerate(queries):", "\n", "for", "k", ",", "value", "in", "enumerate", "(", "id2label", ".", "values", "(", ")", ")", ":", "\n", "\t\t\t\t\t\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "query_vecs_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query_vector", "=", "total_embedding_matrix", "[", "total_vocab", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "#query_attentions[(query_attentions < 0.5)] = 0.0", "\n", "query_attentions", "=", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "query_vecs_attns", ".", "append", "(", "query_vector", ")", "\n", "", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "#query_EmbSum_vector = np.expand_dims(query_vecs[i], axis=0)", "\n", "query_EmbSum_vector", "=", "np", ".", "sum", "(", "query_vecs_attns", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "k", "]", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "\n", "", "", "", "relevance_score_att_embsum", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "relevance_score_att_embsum", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_att_embsum", "=", "np", ".", "array", "(", "relevance_score_att_embsum", ")", "\n", "\n", "#combined_relevance_score = relevance_score_svm + relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_att_embsum", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_att_based_embsum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score_classify_embsum", "=", "relevance_score_att_embsum", "+", "docnade_probs", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_att_based_embsum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score_classify_embsum_bm25extra", "=", "relevance_score_att_embsum", "+", "docnade_probs", "+", "relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum_bm25extra", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_att_based_embsum_bm25extra.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "\t\t\t\t\t", "patience_count_ir", "+=", "1", "\n", "\n", "", "print", "(", "'This val accuracy: {:.3f} (best val accuracy: {:.3f})'", ".", "format", "(", "\n", "val_acc", ",", "\n", "best_val_acc", "or", "0.0", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Step: %i,\tval accuracy: %s,\tbest val accuracy: %s\\n\"", "%", "\n", "(", "step", ",", "val_acc", ",", "best_val_acc", ")", ")", "\n", "\n", "", "if", "patience_count_ir", ">", "patience", ":", "\n", "#if (patience_count_ir > patience) or (step > 50):", "\n", "#final_weights = session.run(\"embeddings_lambda_list_unclipped:0\")", "\n", "#np.save(os.path.join(log_dir, \"final_sup_weights.npy\"), final_weights)", "\n", "\n", "\t\t\t\t\t", "print", "(", "\"Early stopping criterion satisfied.\"", ")", "\n", "\n", "test_pred_labels", "=", "[", "]", "\n", "test_pred_logits", "=", "[", "]", "\n", "for", "test_y", ",", "test_x", ",", "test_seq_lengths", "in", "dataset", ".", "batches", "(", "test_filename", ",", "params", ".", "validation_bs", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", ".", "multi_label", ")", ":", "\n", "\t\t\t\t\t\t", "test_feed_dict", "=", "{", "}", "\n", "test_feed_dict", "[", "model", ".", "x", "]", "=", "test_x", "\n", "test_feed_dict", "[", "model", ".", "y", "]", "=", "test_y", "\n", "test_feed_dict", "[", "model", ".", "seq_lengths", "]", "=", "test_seq_lengths", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "\t\t\t\t\t\t\t", "test_y_title", ",", "test_x_title", ",", "test_seq_lengths_title", "=", "next", "(", "validation_title_data", ")", "\n", "\n", "test_feed_dict", "[", "model", ".", "x_title", "]", "=", "test_x_title", "\n", "test_feed_dict", "[", "model", ".", "seq_lengths_title", "]", "=", "test_seq_lengths_title", "\n", "\n", "", "pred_labels", ",", "pred_logits", "=", "session", ".", "run", "(", "[", "model", ".", "pred_labels", ",", "model", ".", "disc_output", "]", ",", "feed_dict", "=", "test_feed_dict", ")", "\n", "\n", "#test_pred_labels.append(pred_labels[0][0])", "\n", "test_pred_labels", ".", "append", "(", "pred_labels", "[", "0", "]", ")", "\n", "test_pred_logits", ".", "append", "(", "pred_logits", "[", "0", "]", ")", "\n", "\n", "", "test_pred_logits", "=", "softmax", "(", "np", ".", "array", "(", "test_pred_logits", ")", ")", "\n", "\n", "test_true_labels", "=", "[", "int", "(", "label", "[", "0", "]", ")", "for", "label", "in", "test_labels", "]", "\n", "\n", "test_acc", "=", "accuracy_score", "(", "test_true_labels", ",", "test_pred_labels", ")", "\n", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_pred_logits_last_epoch.npy\"", ")", ",", "np", ".", "array", "(", "test_pred_logits", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_pred_labels_last_epoch.npy\"", ")", ",", "np", ".", "array", "(", "test_pred_labels", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"test_true_labels_last_epoch.npy\"", ")", ",", "np", ".", "array", "(", "test_true_labels", ")", ")", "\n", "\n", "docnade_probs", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "docnade_probs", ".", "append", "(", "test_pred_logits", "[", "i", ",", "label", "]", ")", "\n", "", "docnade_probs", "=", "np", ".", "array", "(", "docnade_probs", ")", "\n", "\n", "dict_label", "=", "{", "int", "(", "label", ")", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "docnade_probs", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "int", "(", "label", ")", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_docnade_classify_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "\n", "", "", "", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "docs", "=", "[", "line", "[", "1", "]", ".", "strip", "(", ")", "for", "line", "in", "file_reader", "]", "\n", "\n", "", "bm25", "=", "BM25", ".", "BM25", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "delimiter", "=", "' '", ")", "\n", "\n", "def", "get_bm25_ids", "(", "tokens", ")", ":", "\n", "\t\t\t\t\t\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t\t\t\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n", "", "bm25_extra_scores_list", "=", "[", "]", "\n", "#for query in queries:", "\n", "for", "value", "in", "id2label", ".", "values", "(", ")", ":", "\n", "\t\t\t\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "query", ")", "\n", "\n", "extra_features", "=", "[", "]", "\n", "for", "doc", "in", "docs", ":", "\n", "\t\t\t\t\t\t\t", "doc", "=", "doc", ".", "split", "(", ")", "\n", "#doc_ids = [bm25.dictionary.token2id[token] for token in doc]", "\n", "#query_ids = [bm25.dictionary.token2id[token] for token in query]", "\n", "doc_ids", "=", "get_bm25_ids", "(", "doc", ")", "\n", "query_ids", "=", "get_bm25_ids", "(", "query", ")", "\n", "\n", "feats", "=", "bm25", ".", "query_doc_overlap", "(", "query_ids", ",", "doc_ids", ")", "\n", "extra_features", ".", "append", "(", "np", ".", "sum", "(", "feats", ")", ")", "\n", "#scores = np.stack([np.array(scores), np.array(extra_features)], axis=1)", "\n", "", "scores", "=", "np", ".", "add", "(", "np", ".", "array", "(", "scores", ")", ",", "np", ".", "array", "(", "extra_features", ")", ")", "\n", "\n", "bm25_extra_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_extra_scores_matrix", "=", "np", ".", "stack", "(", "bm25_extra_scores_list", ",", "axis", "=", "1", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "relevance_score_bm25_extra", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "relevance_score_bm25_extra", ".", "append", "(", "bm25_extra_scores_matrix", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_bm25_extra", "=", "np", ".", "array", "(", "relevance_score_bm25_extra", ")", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_bm25_extra", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_bm25extra_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score", "=", "docnade_probs", "+", "relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_with_bm25extra_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "#with open(\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/vocab_docnade.vocab\", \"r\") as f:", "\n", "", "", "", "with", "open", "(", "\"./pretrained_embeddings/biggest_vocab.vocab\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "total_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "total_embedding_matrix", "=", "np", ".", "load", "(", "'./pretrained_embeddings/fasttext_embeddings_biggest_vocab.npy'", ")", "\n", "\n", "similarity_scores_Attention_Based_EmbSum", "=", "np", ".", "zeros", "(", "(", "len", "(", "test_true_labels", ")", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t\t\t\t", "tokens", "=", "[", "total_vocab", ".", "index", "(", "word", ")", "for", "word", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "total_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "#for i, query in enumerate(queries):", "\n", "for", "k", ",", "value", "in", "enumerate", "(", "id2label", ".", "values", "(", ")", ")", ":", "\n", "\t\t\t\t\t\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "query_vecs_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t\t\t\t\t\t\t", "query_vector", "=", "total_embedding_matrix", "[", "total_vocab", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "#query_attentions[(query_attentions < 0.5)] = 0.0", "\n", "query_attentions", "=", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "query_vecs_attns", ".", "append", "(", "query_vector", ")", "\n", "", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "#query_EmbSum_vector = np.expand_dims(query_vecs[i], axis=0)", "\n", "query_EmbSum_vector", "=", "np", ".", "sum", "(", "query_vecs_attns", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "k", "]", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "\n", "", "", "", "relevance_score_att_embsum", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "relevance_score_att_embsum", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_att_embsum", "=", "np", ".", "array", "(", "relevance_score_att_embsum", ")", "\n", "\n", "#combined_relevance_score = relevance_score_svm + relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_att_embsum", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_att_based_embsum_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score_classify_embsum", "=", "relevance_score_att_embsum", "+", "docnade_probs", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_att_based_embsum_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score_classify_embsum_bm25extra", "=", "relevance_score_att_embsum", "+", "docnade_probs", "+", "relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "test_true_labels", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum_bm25extra", ",", "ids", ",", "test_true_labels", ")", ":", "\n", "\t\t\t\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"task1_test_classify_att_based_embsum_bm25extra_last_epoch.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "break", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "\n", "## mAP Calculation", "\n", "\n", "", "val_pred_probs", "=", "eval", ".", "softmax", "(", "np", ".", "array", "(", "val_pred_logits", ")", ",", "axis", "=", "1", ")", "\n", "val_pred_probs", "=", "val_pred_probs", "[", "np", ".", "arange", "(", "len", "(", "val_pred_labels", ")", ")", ",", "np", ".", "array", "(", "val_pred_labels", ")", "]", "\n", "\n", "val_mAP", ",", "_", ",", "preds_dict", ",", "probs_dict", ",", "_", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "val_pred_probs", ")", "\n", "\n", "if", "val_mAP", ">", "best_val_mAP", ":", "\n", "\t\t\t\t\t", "best_val_mAP", "=", "val_mAP", "\n", "print", "(", "'saving: {}'", ".", "format", "(", "model_dir_mAP", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "model_dir_mAP", "+", "'/model_mAP'", ",", "global_step", "=", "1", ")", "\n", "patience_count_ir", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "patience_count_ir", "+=", "1", "\n", "\n", "", "print", "(", "'This val mAP: {:.3f} (best val mAP: {:.3f})'", ".", "format", "(", "\n", "val_mAP", ",", "\n", "best_val_mAP", "or", "0.0", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"training_info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "\"Step: %i,\tval mAP: %s,\tbest val mAP: %s\\n\"", "%", "\n", "(", "step", ",", "val_mAP", ",", "best_val_mAP", ")", ")", "\n", "\n", "", "if", "patience_count_ir", ">", "patience", ":", "\n", "\t\t\t\t\t", "print", "(", "\"Early stopping criterion satisfied.\"", ")", "\n", "break", "\n", "\n", "", "\"\"\"\n\t\t\t\tvalidation_vectors = m.vectors(\n\t\t\t\t\tmodel,\n\t\t\t\t\tdataset.batches(\n\t\t\t\t\t\t'validation_docnade',\n\t\t\t\t\t\tparams.validation_bs,\n\t\t\t\t\t\tnum_epochs=1,\n\t\t\t\t\t\tshuffle=True,\n\t\t\t\t\t\tmultilabel=params.multi_label\n\t\t\t\t\t),\n\t\t\t\t\tsession\n\t\t\t\t)\n\n\t\t\t\ttraining_vectors = m.vectors(\n\t\t\t\t\tmodel,\n\t\t\t\t\tdataset.batches(\n\t\t\t\t\t\t'training_docnade',\n\t\t\t\t\t\tparams.validation_bs,\n\t\t\t\t\t\tnum_epochs=1,\n\t\t\t\t\t\tshuffle=True,\n\t\t\t\t\t\tmultilabel=params.multi_label\n\t\t\t\t\t),\n\t\t\t\t\tsession\n\t\t\t\t)\n\n\t\t\t\tval = eval.evaluate(\n\t\t\t\t\ttraining_vectors,\n\t\t\t\t\tvalidation_vectors,\n\t\t\t\t\ttraining_labels,\n\t\t\t\t\tvalidation_labels,\n\t\t\t\t\trecall=[0.02],\n\t\t\t\t\tnum_classes=params.num_classes,\n\t\t\t\t\tmulti_label=params.multi_label\n\t\t\t\t)[0]\n\n\t\t\t\tif val > best_val_IR:\n\t\t\t\t\tbest_val_IR = val\n\t\t\t\t\tprint('saving: {}'.format(model_dir_ir))\n\t\t\t\t\tsaver.save(session, model_dir_ir + '/model_ir', global_step=1)\n\t\t\t\t\tpatience_count_ir = 0\n\t\t\t\telse:\n\t\t\t\t\tpatience_count_ir += 1\n\t\t\t\t\n\t\t\t\tprint('This val IR: {:.3f} (best val IR: {:.3f})'.format(\n\t\t\t\t\tval,\n\t\t\t\t\tbest_val_IR or 0.0\n\t\t\t\t))\n\n\t\t\t\t# logging information\n\t\t\t\twith open(os.path.join(log_dir, \"training_info.txt\"), \"a\") as f:\n\t\t\t\t\tf.write(\"Step: %i,\tval IR: %s,\tbest val IR: %s\\n\" % \n\t\t\t\t\t\t\t(step, val, best_val_IR))\n\t\t\t\t\t\n\t\t\t\tif patience_count_ir > patience:\n\t\t\t\t\tprint(\"Early stopping criterion satisfied.\")\n\t\t\t\t\tbreak\n\t\t\t\t\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.compute_coherence": [[789, 849], ["gensim.corpora.dictionary.Dictionary", "print", "print", "gensim.corpora.dictionary.Dictionary.doc2bow", "open", "len", "print", "print", "f.write", "f.write", "print", "print", "f.write", "f.write", "print", "print", "f.write", "gensim.models.CoherenceModel().get_coherence", "avg_coh_scores_dict[].append", "print", "f.write", "print", "numpy.mean", "numpy.mean", "gensim.models.CoherenceModel"], "function", ["None"], ["def", "compute_coherence", "(", "texts", ",", "list_of_topics", ",", "top_n_word_in_each_topic_list", ",", "reload_model_dir", ")", ":", "\n", "\n", "\t", "dictionary", "=", "Dictionary", "(", "texts", ")", "\n", "corpus", "=", "[", "dictionary", ".", "doc2bow", "(", "text", ")", "for", "text", "in", "texts", "]", "\n", "\n", "print", "(", "'corpus len:%s'", "%", "len", "(", "corpus", ")", ")", "\n", "print", "(", "'dictionary:%s'", "%", "dictionary", ")", "\n", "# https://github.com/earthquakesan/palmetto-py", "\n", "# compute_topic_coherence: PMI and other coherence types", "\n", "# from palmettopy.palmetto import Palmetto", "\n", "# palmetto = Palmetto()", "\n", "\n", "# coherence_types = [\"ca\", \"cp\", \"cv\", \"npmi\", \"uci\", \"umass\"] # for palmetto library", "\n", "coherence_types", "=", "[", "\"c_v\"", "]", "#, 'u_mass', 'c_v', 'c_uci', 'c_npmi'] # [\"c_v\"] # 'u_mass', 'c_v', 'c_uci', 'c_npmi',", "\n", "avg_coh_scores_dict", "=", "{", "}", "\n", "\n", "best_coh_type_value_topci_indx", "=", "{", "}", "\n", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t", "avg_coh_scores_dict", "[", "top_n", "]", "=", "[", "]", "\n", "best_coh_type_value_topci_indx", "[", "top_n", "]", "=", "[", "0", ",", "0", ",", "[", "]", "]", "# score, topic_indx, topics words", "\n", "\n", "\n", "", "h_num", "=", "0", "\n", "with", "open", "(", "reload_model_dir", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "topic_words_all", "in", "list_of_topics", ":", "\n", "\t\t\t", "h_num", "+=", "1", "\n", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t\t", "topic_words", "=", "[", "topic_words_all", "[", ":", "top_n", "]", "]", "\n", "for", "coh_type", "in", "coherence_types", ":", "\n", "\t\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t\t", "print", "(", "'top_n: %s Topic Num: %s \\nTopic Words: %s'", "%", "(", "top_n", ",", "h_num", ",", "topic_words", ")", ")", "\n", "f", ".", "write", "(", "'top_n: %s Topic Num: %s \\nTopic Words: %s\\n'", "%", "(", "top_n", ",", "h_num", ",", "topic_words", ")", ")", "\n", "# print('topic_words_top_10_abs[%s]:%s' % (h_num, topic_words_top_10_abs[h_num]))", "\n", "# PMI = palmetto.get_coherence(topic_words_top_10[h_num], coherence_type=coh_type)", "\n", "PMI", "=", "CoherenceModel", "(", "topics", "=", "topic_words", ",", "texts", "=", "texts", ",", "dictionary", "=", "dictionary", ",", "coherence", "=", "coh_type", ",", "processes", "=", "2", ")", ".", "get_coherence", "(", ")", "\n", "\n", "avg_coh_scores_dict", "[", "top_n", "]", ".", "append", "(", "PMI", ")", "\n", "\n", "if", "PMI", ">", "best_coh_type_value_topci_indx", "[", "top_n", "]", "[", "0", "]", ":", "\n", "\t\t\t\t\t\t\t", "best_coh_type_value_topci_indx", "[", "top_n", "]", "=", "[", "PMI", ",", "top_n", ",", "topic_words", "]", "\n", "\n", "", "print", "(", "'Coh_type:%s  Topic Num:%s COH score:%s'", "%", "(", "coh_type", ",", "h_num", ",", "PMI", ")", ")", "\n", "f", ".", "write", "(", "'Coh_type:%s  Topic Num:%s COH score:%s\\n'", "%", "(", "coh_type", ",", "h_num", ",", "PMI", ")", ")", "\n", "\n", "print", "(", "'--------------------------------------------------------------'", ")", "\n", "", "except", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "", "print", "(", "'========================================================================================================'", ")", "\n", "\n", "", "", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t", "print", "(", "'top scores for top_%s:%s'", "%", "(", "top_n", ",", "best_coh_type_value_topci_indx", "[", "top_n", "]", ")", ")", "\n", "print", "(", "'-------------------------------------------------------------------'", ")", "\n", "f", ".", "write", "(", "'top scores for top_%s:%s\\n'", "%", "(", "top_n", ",", "best_coh_type_value_topci_indx", "[", "top_n", "]", ")", ")", "\n", "f", ".", "write", "(", "'-------------------------------------------------------------------\\n'", ")", "\n", "\n", "", "for", "top_n", "in", "top_n_word_in_each_topic_list", ":", "\n", "\t\t\t", "print", "(", "'Avg COH for top_%s topic words: %s'", "%", "(", "top_n", ",", "np", ".", "mean", "(", "avg_coh_scores_dict", "[", "top_n", "]", ")", ")", ")", "\n", "print", "(", "'-------------------------------------------------------------------'", ")", "\n", "f", ".", "write", "(", "'Avg COH for top_%s topic words: %s\\n'", "%", "(", "top_n", ",", "np", ".", "mean", "(", "avg_coh_scores_dict", "[", "top_n", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "'-------------------------------------------------------------------\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.get_vectors_from_matrix": [[851, 861], ["numpy.array", "numpy.zeros", "vecs.append"], "function", ["None"], ["", "", "", "def", "get_vectors_from_matrix", "(", "matrix", ",", "batches", ")", ":", "\n", "# matrix: embedding matrix of shape = [vocab_size X embedding_size]", "\n", "\t", "vecs", "=", "[", "]", "\n", "for", "_", ",", "x", ",", "seq_length", "in", "batches", ":", "\n", "\t\t", "temp_vec", "=", "np", ".", "zeros", "(", "(", "matrix", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "indices", "=", "x", "[", "0", ",", ":", "seq_length", "[", "0", "]", "]", "\n", "for", "index", "in", "indices", ":", "\n", "\t\t\t", "temp_vec", "+=", "matrix", "[", "index", ",", ":", "]", "\n", "", "vecs", ".", "append", "(", "temp_vec", ")", "\n", "", "return", "np", ".", "array", "(", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.square_rooted": [[865, 867], ["round", "sqrt", "sum"], "function", ["None"], ["def", "square_rooted", "(", "x", ")", ":", "\n", "\t", "return", "round", "(", "sqrt", "(", "sum", "(", "[", "a", "*", "a", "for", "a", "in", "x", "]", ")", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity": [[868, 872], ["sum", "round", "train_DocNADE.square_rooted", "train_DocNADE.square_rooted", "float", "zip"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.square_rooted", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.square_rooted"], ["", "def", "cosine_similarity", "(", "x", ",", "y", ")", ":", "\n", "\t", "numerator", "=", "sum", "(", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "x", ",", "y", ")", ")", "\n", "denominator", "=", "square_rooted", "(", "x", ")", "*", "square_rooted", "(", "y", ")", "\n", "return", "round", "(", "numerator", "/", "float", "(", "denominator", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_acc_mAP": [[874, 1625], ["tensorflow.Session", "model.Dataset", "os.path.join", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.get_default_graph", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "data.Dataset.batches", "sklearn.metrics.accuracy_score", "print", "model.softmax", "model.evaluate_mAP", "print", "BM25.BM25", "numpy.stack", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.stack", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.unique", "np.unique.tolist", "numpy.concatenate", "numpy.concatenate", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.add", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.zeros", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.add", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.stack", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.add", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "numpy.add", "enumerate", "numpy.array", "model.evaluate_mAP", "print", "os.path.exists", "os.makedirs", "tensorflow.train.latest_checkpoint", "session_acc.run", "val_pred_labels.append", "val_pred_logits.append", "val_true_labels.append", "open", "f.write", "numpy.array", "open", "f.write", "open", "preds_dict.keys", "f.write", "numpy.array", "numpy.array", "open", "open", "csv.reader", "open", "f.readlines", "query.split.split", "BM25.BM25.BM25Score", "bm25_scores_list.append", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "query.split.split", "BM25.BM25.BM25Score", "numpy.add", "bm25_extra_scores_list.append", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "codecs.open", "codecs.open", "np.unique.extend", "numpy.load", "prior_embedding_matrices.append", "numpy.load", "numpy.zeros", "enumerate", "query_embedding_matrices.append", "numpy.load", "prior_embedding_matrices.append", "numpy.load", "numpy.zeros", "enumerate", "query_embedding_matrices.append", "numpy.eye", "prior_embedding_matrices.append", "query_embedding_matrices.append", "session_acc.run", "prior_embedding_matrices.append", "numpy.zeros", "enumerate", "query_embedding_matrices.append", "numpy.sum", "query_vecs.append", "sklearn.cosine_similarity", "sklearn.cosine_similarity", "sklearn.cosine_similarity", "numpy.add", "numpy.concatenate", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "model.softmax", "model.softmax", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "model.softmax", "model.softmax", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "query.split.split", "BM25.BM25.BM25Score", "bm25_with_emb_scores_list.append", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "model.softmax", "model.softmax", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "model.softmax", "model.softmax", "numpy.add", "np.array.append", "open", "f.write", "open", "preds_dict.keys", "f.write", "tensorflow.ConfigProto", "int", "os.path.join", "os.path.join", "os.path.join", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "enumerate", "os.path.join", "f.write", "f.write", "f.write", "f.write", "f.write", "BM25.BM25.dictionary.itervalues", "line[].strip", "line.lower().strip().split", "queries.append", "model.softmax", "os.path.join", "os.path.join", "f.write", "f.write", "f.write", "f.write", "f.write", "f.write", "doc.split.split", "train_DocNADE.train.get_bm25_ids"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.get_bm25_ids"], ["", "def", "reload_evaluation_acc_mAP", "(", "params", ")", ":", "\n", "\t", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "intra_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "session_acc", ":", "\n", "\n", "\t\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "\t\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "", "saver_ppl", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\"model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"model_sup/model_sup-1.meta\"", ")", "\n", "saver_ppl", ".", "restore", "(", "session_acc", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"model_sup/\"", ")", ")", "\n", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "predicted_labels", "=", "graph", ".", "get_tensor_by_name", "(", "\"pred_labels:0\"", ")", "\n", "disc_logits", "=", "graph", ".", "get_tensor_by_name", "(", "\"disc_logits:0\"", ")", "\n", "\n", "x", "=", "graph", ".", "get_tensor_by_name", "(", "\"x:0\"", ")", "\n", "y", "=", "graph", ".", "get_tensor_by_name", "(", "\"y:0\"", ")", "\n", "seq_lengths", "=", "graph", ".", "get_tensor_by_name", "(", "\"seq_lengths:0\"", ")", "\n", "\n", "if", "params", "[", "'input_type'", "]", "==", "\"both\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade'", "\n", "validation_filename", "=", "'validation_docnade'", "\n", "test_filename", "=", "'test_docnade'", "\n", "", "elif", "params", "[", "'input_type'", "]", "==", "\"abstract\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade_abstracts'", "\n", "validation_filename", "=", "'validation_docnade_abstracts'", "\n", "test_filename", "=", "'test_docnade_abstracts'", "\n", "", "elif", "params", "[", "'input_type'", "]", "==", "\"title\"", ":", "\n", "\t\t\t", "training_filename", "=", "'training_docnade_titles'", "\n", "validation_filename", "=", "'validation_docnade_titles'", "\n", "test_filename", "=", "'test_docnade_titles'", "\n", "\n", "## Classification accuracy", "\n", "\n", "#if params.use_title_separately:", "\n", "#\tvalidation_title_data = dataset.batches(validation_title_filename, params.validation_bs, num_epochs=1, shuffle=True, multilabel=params.multi_label)", "\n", "#\tvalidation_filename = 'validation_docnade_abstracts'", "\n", "\n", "", "val_true_labels", "=", "[", "]", "\n", "val_pred_labels", "=", "[", "]", "\n", "val_pred_logits", "=", "[", "]", "\n", "for", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "validation_filename", ",", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t", "val_feed_dict", "=", "{", "}", "\n", "val_feed_dict", "[", "x", "]", "=", "val_x", "\n", "val_feed_dict", "[", "y", "]", "=", "val_y", "\n", "val_feed_dict", "[", "seq_lengths", "]", "=", "val_seq_lengths", "\n", "\n", "#if params.use_title_separately:", "\n", "#\tval_y_title, val_x_title, val_seq_lengths_title = next(validation_title_data)", "\n", "\n", "#\tval_feed_dict[model.x_title] = val_x_title", "\n", "#\tval_feed_dict[model.seq_lengths_title] = val_seq_lengths_title", "\n", "\n", "pred_labels", ",", "pred_logits", "=", "session_acc", ".", "run", "(", "[", "predicted_labels", ",", "disc_logits", "]", ",", "feed_dict", "=", "val_feed_dict", ")", "\n", "\n", "#val_pred_labels.append(pred_labels[0][0])", "\n", "val_pred_labels", ".", "append", "(", "pred_labels", "[", "0", "]", ")", "\n", "val_pred_logits", ".", "append", "(", "pred_logits", "[", "0", "]", ")", "\n", "val_true_labels", ".", "append", "(", "int", "(", "val_y", ")", ")", "\n", "\n", "#val_true_labels = [int(label[0]) for label in validation_labels]", "\n", "\n", "", "val_acc", "=", "accuracy_score", "(", "val_true_labels", ",", "val_pred_labels", ")", "\n", "\n", "print", "(", "'This val accuracy: {:.3f}'", ".", "format", "(", "val_acc", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val accuracy: %s\\n\"", "%", "(", "val_acc", ")", ")", "\n", "\n", "## Using classification probability for relevance ranking and mAP calculation", "\n", "\n", "", "val_pred_probs", "=", "eval", ".", "softmax", "(", "np", ".", "array", "(", "val_pred_logits", ")", ",", "axis", "=", "1", ")", "\n", "val_pred_probs_temp", "=", "val_pred_probs", "[", "np", ".", "arange", "(", "len", "(", "val_pred_labels", ")", ")", ",", "np", ".", "array", "(", "val_pred_labels", ")", "]", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "val_pred_probs_temp", ")", "\n", "\n", "print", "(", "'This val mAP: {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP: %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "# misclassified", "\n", "", "temp", "=", "(", "np", ".", "array", "(", "val_pred_labels", ")", "==", "np", ".", "array", "(", "val_true_labels", ")", ")", "\n", "\n", "#val_pred_probs_full = eval.softmax(np.array(val_pred_logits), axis=1)", "\n", "\n", "indices", "=", "[", "index", "for", "index", ",", "val", "in", "enumerate", "(", "temp", ")", "if", "not", "val", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"misclassified.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "index", "in", "indices", ":", "\n", "#f.write(\"Val doc #\" + str(index+1) + \"\\n\")", "\n", "\t\t\t\t", "f", ".", "write", "(", "\"Val doc #\"", "+", "str", "(", "index", "+", "1", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"True label: \"", "+", "str", "(", "val_true_labels", "[", "index", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Pred label: \"", "+", "str", "(", "val_pred_labels", "[", "index", "]", ")", "+", "\"\\n\"", ")", "\n", "#f.write(\"Prediction probs: \" + \" \".join([str(prob) for prob in val_pred_probs_full[index, :]]) + \"\\n\")", "\n", "f", ".", "write", "(", "\"Prediction probs: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "prob", ")", "for", "prob", "in", "val_pred_probs", "[", "index", ",", ":", "]", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "## Using BM25 score for relevance ranking and mAP calculation", "\n", "\n", "#bm25 = BM25.BM25(params['dataset'] + \"/val_docs.txt\", delimiter=' ')", "\n", "", "", "bm25", "=", "BM25", ".", "BM25", "(", "params", "[", "'dataset'", "]", "+", "\"/validation.csv\"", ",", "delimiter", "=", "' '", ")", "\n", "\n", "bm25_vocab", "=", "[", "word", "for", "word", "in", "bm25", ".", "dictionary", ".", "itervalues", "(", ")", "]", "\n", "\n", "#with open(params['dataset'] + \"/val_docs.txt\", \"r\") as f:", "\n", "#\tdocs = [line.strip().split(\"\\t\")[1].lower().strip() for line in f.readlines()]", "\n", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "docs", "=", "[", "line", "[", "1", "]", ".", "strip", "(", ")", "for", "line", "in", "file_reader", "]", "\n", "\n", "", "queries", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/labels.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "\t\t\t\t", "label_tokens", "=", "line", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "\"_\"", ")", "\n", "label_tokens", "=", "[", "token", "for", "token", "in", "label_tokens", "if", "token", "]", "\n", "query", "=", "\" \"", ".", "join", "(", "label_tokens", ")", "\n", "queries", ".", "append", "(", "query", ")", "\n", "#queries.append(query_defs[query])", "\n", "\n", "", "", "def", "get_bm25_ids", "(", "tokens", ")", ":", "\n", "\t\t\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n", "", "bm25_scores_list", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "\t\t\t", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "query", ")", "\n", "bm25_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_scores_matrix", "=", "np", ".", "stack", "(", "bm25_scores_list", ",", "axis", "=", "1", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "bm25_scores_matrix", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "bm25_scores_matrix", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_bm25", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_bm25", ".", "append", "(", "bm25_scores_matrix", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_bm25", "=", "np", ".", "array", "(", "relevance_score_bm25", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_bm25", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 Extra for relevance ranking and mAP calculation", "\n", "\n", "", "bm25_extra_scores_list", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "\t\t\t", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "query", ")", "\n", "\n", "extra_features", "=", "[", "]", "\n", "for", "doc", "in", "docs", ":", "\n", "\t\t\t\t", "doc", "=", "doc", ".", "split", "(", ")", "\n", "#doc_ids = [bm25.dictionary.token2id[token] for token in doc]", "\n", "#query_ids = [bm25.dictionary.token2id[token] for token in query]", "\n", "doc_ids", "=", "get_bm25_ids", "(", "doc", ")", "\n", "query_ids", "=", "get_bm25_ids", "(", "query", ")", "\n", "\n", "feats", "=", "bm25", ".", "query_doc_overlap", "(", "query_ids", ",", "doc_ids", ")", "\n", "extra_features", ".", "append", "(", "np", ".", "sum", "(", "feats", ")", ")", "\n", "#scores = np.stack([np.array(scores), np.array(extra_features)], axis=1)", "\n", "", "scores", "=", "np", ".", "add", "(", "np", ".", "array", "(", "scores", ")", ",", "np", ".", "array", "(", "extra_features", ")", ")", "\n", "\n", "bm25_extra_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_extra_scores_matrix", "=", "np", ".", "stack", "(", "bm25_extra_scores_list", ",", "axis", "=", "1", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "bm25_extra_scores_matrix", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "bm25_extra_scores_matrix", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_bm25_extra", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_bm25_extra", ".", "append", "(", "bm25_extra_scores_matrix", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_bm25_extra", "=", "np", ".", "array", "(", "relevance_score_bm25_extra", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_bm25_extra", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 Extra): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 Extra): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_extra.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "with", "codecs", ".", "open", "(", "params", "[", "'docnadeVocab'", "]", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "\t\t\t", "docnade_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "codecs", ".", "open", "(", "\"./datasets/Task1_Augmented_Def_new/vocab_docnade.vocab\"", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "\t\t\t", "docnade_vocab_large", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "query_words", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "\t\t\t", "query_words", ".", "extend", "(", "query", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "query_words", "=", "np", ".", "unique", "(", "query_words", ")", "\n", "query_words_list", "=", "query_words", ".", "tolist", "(", ")", "\n", "\n", "prior_embedding_matrices", "=", "[", "]", "\n", "query_embedding_matrices", "=", "[", "]", "\n", "\n", "if", "params", "[", "'use_bio_prior'", "]", ":", "\n", "\t\t\t", "bio_embeddings", "=", "np", ".", "load", "(", "'./pretrained_embeddings/'", "+", "params", "[", "'bioemb_path'", "]", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "bio_embeddings", ")", "\n", "\n", "bio_embeddings_large", "=", "np", ".", "load", "(", "'./pretrained_embeddings/bionlp_embeddings_task1_without_acronyms_without_stopwords_augmented_def_new.npy'", ")", "\n", "query_bio_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "query_words", ")", ",", "bio_embeddings_large", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "query_words", ")", ":", "\n", "\t\t\t\t", "query_bio_embeddings", "[", "i", ",", ":", "]", "=", "bio_embeddings_large", "[", "int", "(", "docnade_vocab_large", ".", "index", "(", "word", ".", "strip", "(", ")", ")", ")", ",", ":", "]", "\n", "", "query_embedding_matrices", ".", "append", "(", "query_bio_embeddings", ")", "\n", "\n", "\n", "", "if", "params", "[", "'use_fasttext_prior'", "]", ":", "\n", "\t\t\t", "fasttext_embeddings", "=", "np", ".", "load", "(", "'./pretrained_embeddings/'", "+", "params", "[", "'fttemb_path'", "]", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "fasttext_embeddings", ")", "\n", "\n", "fasttext_embeddings_large", "=", "np", ".", "load", "(", "'./pretrained_embeddings/fasttext_embeddings_task1_without_acronyms_without_stopwords_augmented_def_new.npy'", ")", "\n", "query_fasttext_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "query_words", ")", ",", "fasttext_embeddings_large", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "query_words", ")", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "\t\t\t\t", "query_fasttext_embeddings", "[", "i", ",", ":", "]", "=", "fasttext_embeddings_large", "[", "int", "(", "docnade_vocab_large", ".", "index", "(", "word", ".", "strip", "(", ")", ")", ")", ",", ":", "]", "\n", "", "query_embedding_matrices", ".", "append", "(", "query_fasttext_embeddings", ")", "\n", "\n", "", "if", "params", "[", "'use_BOW_repesentation'", "]", ":", "\n", "#BOW_representations = np.eye(len(docnade_vocab), dtype=np.float32)", "\n", "\t\t\t", "BOW_representations", "=", "np", ".", "eye", "(", "len", "(", "docnade_vocab_large", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "#prior_embedding_matrices.append(BOW_representations)", "\n", "BOW_representations_docs", "=", "BOW_representations", "[", "np", ".", "array", "(", "[", "int", "(", "docnade_vocab_large", ".", "index", "(", "word", ")", ")", "for", "word", "in", "docnade_vocab", "]", ")", ",", ":", "]", "\n", "BOW_representations_queries", "=", "BOW_representations", "[", "np", ".", "array", "(", "[", "int", "(", "docnade_vocab_large", ".", "index", "(", "word", ")", ")", "for", "word", "in", "query_words", "]", ")", ",", ":", "]", "\n", "prior_embedding_matrices", ".", "append", "(", "BOW_representations_docs", ")", "\n", "query_embedding_matrices", ".", "append", "(", "BOW_representations_queries", ")", "\n", "\n", "", "if", "params", "[", "'use_DocNADE_W'", "]", ":", "\n", "\t\t\t", "DocNADE_W", "=", "session_acc", ".", "run", "(", "\"embedding:0\"", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "DocNADE_W", ")", "\n", "\n", "query_W_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "query_words", ")", ",", "DocNADE_W", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "query_words", ")", ":", "\n", "\t\t\t\t", "if", "word", "in", "docnade_vocab", ":", "\n", "\t\t\t\t\t", "query_W_embeddings", "[", "i", ",", ":", "]", "=", "DocNADE_W", "[", "int", "(", "docnade_vocab", ".", "index", "(", "word", ".", "strip", "(", ")", ")", ")", ",", ":", "]", "\n", "", "", "query_embedding_matrices", ".", "append", "(", "query_W_embeddings", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "docnade_embedding_matrix", "=", "np", ".", "concatenate", "(", "prior_embedding_matrices", ",", "axis", "=", "1", ")", "\n", "query_embedding_matrix", "=", "np", ".", "concatenate", "(", "query_embedding_matrices", ",", "axis", "=", "1", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "query_vecs", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "\t\t\t", "tokens", "=", "[", "int", "(", "query_words_list", ".", "index", "(", "word", ")", ")", "for", "word", "in", "query", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "query_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "EmbSum", "=", "np", ".", "sum", "(", "Embs", ",", "axis", "=", "0", ")", "\n", "query_vecs", ".", "append", "(", "EmbSum", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "if", "not", "params", "[", "'split_abstract_title'", "]", ":", "\n", "\t\t\t", "validation_vecs", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "row", "in", "file_reader", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "EmbSum", "=", "np", ".", "sum", "(", "Embs", ",", "axis", "=", "0", ")", "\n", "validation_vecs", ".", "append", "(", "EmbSum", ")", "\n", "\n", "", "", "similarity_scores", "=", "pw", ".", "cosine_similarity", "(", "np", ".", "array", "(", "validation_vecs", ")", ",", "np", ".", "array", "(", "query_vecs", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t", "validation_abstract_vecs", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade_abstracts.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "row", "in", "file_reader", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "EmbSum", "=", "np", ".", "sum", "(", "Embs", ",", "axis", "=", "0", ")", "\n", "validation_abstract_vecs", ".", "append", "(", "EmbSum", ")", "\n", "\n", "", "", "similarity_abstract_scores", "=", "pw", ".", "cosine_similarity", "(", "np", ".", "array", "(", "validation_abstract_vecs", ")", ",", "np", ".", "array", "(", "query_vecs", ")", ")", "\n", "\n", "validation_title_vecs", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade_titles.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "row", "in", "file_reader", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "EmbSum", "=", "np", ".", "sum", "(", "Embs", ",", "axis", "=", "0", ")", "\n", "validation_title_vecs", ".", "append", "(", "EmbSum", ")", "\n", "\n", "", "", "similarity_title_scores", "=", "pw", ".", "cosine_similarity", "(", "np", ".", "array", "(", "validation_title_vecs", ")", ",", "np", ".", "array", "(", "query_vecs", ")", ")", "\n", "\n", "similarity_scores", "=", "np", ".", "add", "(", "similarity_abstract_scores", ",", "similarity_title_scores", ")", "\n", "\n", "validation_vecs", "=", "np", ".", "concatenate", "(", "[", "validation_abstract_vecs", ",", "validation_title_vecs", "]", ",", "axis", "=", "1", ")", "\n", "\n", "#similarity_scores = pw.cosine_similarity(np.array(validation_vecs), np.array(query_vecs))", "\n", "", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score", ".", "append", "(", "similarity_scores", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score", "=", "np", ".", "array", "(", "relevance_score", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score", ")", "\n", "\n", "print", "(", "'This val mAP (with EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 + EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "similarity_scores_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores", ",", "axis", "=", "1", ")", ",", "eval", ".", "softmax", "(", "bm25_scores_matrix", ",", "axis", "=", "1", ")", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_combined", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_comb", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_comb", ".", "append", "(", "similarity_scores_combined", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_comb", "=", "np", ".", "array", "(", "relevance_score_comb", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_comb", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 and EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 and EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_and_EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using Attention based EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "similarity_scores_Attention_Based_EmbSum", "=", "np", ".", "zeros", "(", "(", "len", "(", "validation_vecs", ")", ",", "len", "(", "query_vecs", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "not", "params", "[", "'split_abstract_title'", "]", ":", "\n", "\t\t\t", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "for", "i", ",", "query", "in", "enumerate", "(", "queries", ")", ":", "\n", "\t\t\t\t\t\t", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "query_vecs_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t\t\t\t\t", "query_vector", "=", "query_embedding_matrix", "[", "query_words_list", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "query_attentions", "=", "eval", ".", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "query_vecs_attns", ".", "append", "(", "query_vector", ")", "\n", "", "if", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"sum\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "expand_dims", "(", "query_vecs", "[", "i", "]", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"concat\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "concatenate", "(", "EmbSum_attns", ",", "axis", "=", "1", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "concatenate", "(", "query_vecs_attns", ",", "axis", "=", "1", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"max\"", ":", "\n", "\t\t\t\t\t\t\t", "max_similarity", "=", "-", "1.1", "\n", "for", "q_vec", ",", "d_vec", "in", "zip", "(", "query_vecs_attns", ",", "EmbSum_attns", ")", ":", "\n", "\t\t\t\t\t\t\t\t", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "q_vec", ",", "d_vec", ")", "\n", "if", "similarity_score", "[", "0", "]", "[", "0", "]", ">", "max_similarity", ":", "\n", "\t\t\t\t\t\t\t\t\t", "max_similarity", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "=", "max_similarity", "\n", "", "", "", "", "", "else", ":", "\n", "\t\t\t", "Embs_titles", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade_titles.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "Embs_titles", ".", "append", "(", "Embs", ")", "\n", "\n", "", "", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/validation_docnade_abstracts.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t\t", "tokens", "=", "[", "int", "(", "index", ")", "for", "index", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "docnade_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "Embs_title", "=", "Embs_titles", "[", "j", "]", "\n", "for", "i", ",", "query", "in", "enumerate", "(", "queries", ")", ":", "\n", "\t\t\t\t\t\t", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "EmbSum_title_attns", "=", "[", "]", "\n", "query_vecs_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t\t\t\t\t", "query_vector", "=", "query_embedding_matrix", "[", "query_words_list", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "query_attentions", "=", "eval", ".", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "query_attentions_title", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs_title", ")", "\n", "query_attentions_title", "=", "eval", ".", "softmax", "(", "query_attentions_title", ")", "\n", "EmbSum_attentions_title", "=", "np", ".", "dot", "(", "query_attentions_title", ",", "Embs_title", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "EmbSum_title_attns", ".", "append", "(", "EmbSum_attentions_title", ")", "\n", "query_vecs_attns", ".", "append", "(", "query_vector", ")", "\n", "\n", "", "if", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"sum\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "expand_dims", "(", "query_vecs", "[", "i", "]", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"concat\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "concatenate", "(", "EmbSum_attns", ",", "axis", "=", "1", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "concatenate", "(", "query_vecs_attns", ",", "axis", "=", "1", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"max\"", ":", "\n", "\t\t\t\t\t\t\t", "max_similarity", "=", "-", "1.1", "\n", "for", "q_vec", ",", "d_vec", "in", "zip", "(", "query_vecs_attns", ",", "EmbSum_attns", ")", ":", "\n", "\t\t\t\t\t\t\t\t", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "q_vec", ",", "d_vec", ")", "\n", "if", "similarity_score", "[", "0", "]", "[", "0", "]", ">", "max_similarity", ":", "\n", "\t\t\t\t\t\t\t\t\t", "max_similarity", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "max_similarity", "\n", "\n", "", "if", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"sum\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_title_attns", ",", "axis", "=", "0", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "expand_dims", "(", "query_vecs", "[", "i", "]", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"concat\"", ":", "\n", "\t\t\t\t\t\t\t", "EmbSum", "=", "np", ".", "concatenate", "(", "EmbSum_title_attns", ",", "axis", "=", "1", ")", "\n", "query_EmbSum_vector", "=", "np", ".", "concatenate", "(", "query_vecs_attns", ",", "axis", "=", "1", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "elif", "params", "[", "'attention_EmbSum_type'", "]", "==", "\"max\"", ":", "\n", "\t\t\t\t\t\t\t", "max_similarity", "=", "-", "1.1", "\n", "for", "q_vec", ",", "d_vec", "in", "zip", "(", "query_vecs_attns", ",", "EmbSum_title_attns", ")", ":", "\n", "\t\t\t\t\t\t\t\t", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "q_vec", ",", "d_vec", ")", "\n", "if", "similarity_score", "[", "0", "]", "[", "0", "]", ">", "max_similarity", ":", "\n", "\t\t\t\t\t\t\t\t\t", "max_similarity", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "", "", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "i", "]", "+=", "max_similarity", "\n", "\n", "", "", "", "", "", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores_Attention_Based_EmbSum", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_Attention_Based_EmbSum", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_Attention_Based_EmbSum", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_Attention_Based_EmbSum", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_Attention_Based_EmbSum", "=", "np", ".", "array", "(", "relevance_score_Attention_Based_EmbSum", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_Attention_Based_EmbSum", ")", "\n", "\n", "print", "(", "'This val mAP (with attention based EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with attention based EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_attention_based_EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 + Attentione based EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "similarity_scores_Attention_Based_EmbSum_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_Attention_Based_EmbSum", ",", "axis", "=", "1", ")", ",", "eval", ".", "softmax", "(", "bm25_scores_matrix", ",", "axis", "=", "1", ")", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores_Attention_Based_EmbSum_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_Attention_Based_EmbSum_combined", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_Attention_Based_EmbSum_combined", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_Attention_Based_EmbSum_combined", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum_combined", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_Attention_Based_EmbSum_combined", "=", "np", ".", "array", "(", "relevance_score_Attention_Based_EmbSum_combined", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_Attention_Based_EmbSum_combined", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 and attention based EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 and attention based EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_and_attention_based_EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 with embeddings for relevance ranking and mAP calculation", "\n", "\n", "", "bm25_with_emb_scores_list", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "\t\t\t", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "Query", "=", "query", ",", "\n", "embedding_matrix", "=", "docnade_embedding_matrix", ",", "\n", "embedding_vocab", "=", "docnade_vocab", ",", "\n", "query_matrix", "=", "query_embedding_matrix", ",", "\n", "query_vocab", "=", "query_words_list", ",", "\n", "sim_threshold", "=", "0.20", ")", "\n", "bm25_with_emb_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_with_emb_scores_matrix", "=", "np", ".", "stack", "(", "bm25_with_emb_scores_list", ",", "axis", "=", "1", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "bm25_with_emb_scores_matrix", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "bm25_with_emb_scores_matrix", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_bm25_with_emb", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_bm25_with_emb", ".", "append", "(", "bm25_with_emb_scores_matrix", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_bm25_with_emb", "=", "np", ".", "array", "(", "relevance_score_bm25_with_emb", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_bm25_with_emb", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 using embeddings): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 using embeddings): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_using_embeddings.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 using embeddings + EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "similarity_scores_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores", ",", "axis", "=", "1", ")", ",", "eval", ".", "softmax", "(", "bm25_with_emb_scores_matrix", ",", "axis", "=", "1", ")", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_combined", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_comb", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_comb", ".", "append", "(", "similarity_scores_combined", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_comb", "=", "np", ".", "array", "(", "relevance_score_comb", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_comb", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 and EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 and EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_using_embeddings_and EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "## Using BM25 using embeddings + Attention based EmbSum for relevance ranking and mAP calculation", "\n", "\n", "", "similarity_scores_Attention_Based_EmbSum_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_Attention_Based_EmbSum", ",", "axis", "=", "1", ")", ",", "eval", ".", "softmax", "(", "bm25_with_emb_scores_matrix", ",", "axis", "=", "1", ")", ")", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t", "similarity_scores_Attention_Based_EmbSum_combined", "=", "np", ".", "add", "(", "eval", ".", "softmax", "(", "similarity_scores_Attention_Based_EmbSum_combined", ",", "axis", "=", "1", ")", ",", "val_pred_probs", ")", "\n", "\n", "", "relevance_score_Attention_Based_EmbSum_combined", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "val_pred_labels", ")", ":", "\n", "\t\t\t", "relevance_score_Attention_Based_EmbSum_combined", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum_combined", "[", "i", ",", "label", "]", ")", "\n", "", "relevance_score_Attention_Based_EmbSum_combined", "=", "np", ".", "array", "(", "relevance_score_Attention_Based_EmbSum_combined", ")", "\n", "\n", "val_mAP", ",", "val_AP_dict", ",", "preds_dict", ",", "probs_dict", ",", "indices_dict", "=", "eval", ".", "evaluate_mAP", "(", "val_true_labels", ",", "val_pred_labels", ",", "relevance_score_Attention_Based_EmbSum_combined", ")", "\n", "\n", "print", "(", "'This val mAP (with BM25 and attention based EmbSum): {:.3f}'", ".", "format", "(", "val_mAP", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_acc.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"val mAP (with BM25 and attention based EmbSum): %s\\n\"", "%", "(", "val_mAP", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_BM25_using_embeddings_and_attention_based_EmbSum.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "label", "in", "preds_dict", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "preds", "=", "preds_dict", "[", "label", "]", "\n", "probs", "=", "probs_dict", "[", "label", "]", "\n", "preds_indices", "=", "indices_dict", "[", "label", "]", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_probs", "=", "np", ".", "array", "(", "probs", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_indices", "=", "np", ".", "array", "(", "preds_indices", ")", "[", "sorted_indices", "]", "\n", "\n", "f", ".", "write", "(", "\"Cluster \"", "+", "str", "(", "label", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Average precision: \"", "+", "str", "(", "val_AP_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels: \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_probs", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_preds_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n=================================================================================\\n\\n\"", ")", "\n", "\n", "", "return", "docnade_embedding_matrix", ",", "query_embedding_matrix", ",", "query_vecs", ",", "queries", ",", "query_words_list", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_f1": [[1627, 1684], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "model.perform_classification_test", "total_labels.extend", "total_labels.extend", "MultiLabelBinarizer", "MultiLabelBinarizer.fit", "MultiLabelBinarizer.transform", "MultiLabelBinarizer.transform", "model.perform_classification_test_multi", "numpy.array", "numpy.array", "open", "f.write", "open", "f.write", "label.strip().split", "label.strip().split", "open", "f.write", "open", "f.write", "data.Dataset.rows", "data.Dataset.rows", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "label.strip", "label.strip"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test_multi", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows"], ["", "", "def", "reload_evaluation_f1", "(", "params", ",", "training_vectors", ",", "test_vectors", ",", "W_matrix", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Classification - F1", "\n", "\n", "\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "c_list", "=", "[", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1", ",", "0.5", ",", "1.0", ",", "3.0", ",", "5.0", ",", "10.0", ",", "100.0", ",", "500.0", ",", "1000.0", ",", "10000.0", "]", "\n", "#c_list = [1.0]", "\n", "\n", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "y_train", "=", "np", ".", "array", "(", "\n", "[", "y", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "y_test", "=", "np", ".", "array", "(", "\n", "[", "y", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "if", "not", "params", "[", "'multi_label'", "]", ":", "\n", "\t\t", "train_data", "=", "(", "training_vectors", ",", "np", ".", "array", "(", "y_train", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "test_data", "=", "(", "test_vectors", ",", "np", ".", "array", "(", "y_test", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "test_acc", ",", "test_f1", "=", "eval", ".", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest accuracy with h vector IR: %s\"", "%", "(", "test_acc", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest F1 score with h vector IR: %s\"", "%", "(", "test_f1", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "\t\t", "total_labels", "=", "[", "]", "\n", "\n", "y_train_new", "=", "[", "label", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "for", "label", "in", "y_train", "]", "\n", "y_test_new", "=", "[", "label", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "for", "label", "in", "y_test", "]", "\n", "\n", "total_labels", ".", "extend", "(", "y_train_new", ")", "\n", "total_labels", ".", "extend", "(", "y_test_new", ")", "\n", "\n", "from", "sklearn", ".", "preprocessing", "import", "MultiLabelBinarizer", "\n", "mlb", "=", "MultiLabelBinarizer", "(", ")", "\n", "mlb", ".", "fit", "(", "total_labels", ")", "\n", "y_train_one_hot", "=", "mlb", ".", "transform", "(", "y_train_new", ")", "\n", "y_test_one_hot", "=", "mlb", ".", "transform", "(", "y_test_new", ")", "\n", "\n", "train_data", "=", "(", "training_vectors", ",", "y_train_one_hot", ")", "\n", "test_data", "=", "(", "test_vectors", ",", "y_test_one_hot", ")", "\n", "\n", "test_acc", ",", "test_f1", "=", "eval", ".", "perform_classification_test_multi", "(", "train_data", ",", "test_data", ",", "c_list", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest accuracy with h vector IR: %s\"", "%", "(", "test_acc", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest F1 score with h vector IR: %s\"", "%", "(", "test_f1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_ir": [[1686, 1718], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "model.evaluate", "open", "f.write", "f.write", "os.path.join", "data.Dataset.rows", "data.Dataset.rows"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows"], ["", "", "", "def", "reload_evaluation_ir", "(", "params", ",", "training_vectors", ",", "test_vectors", ",", "W_matrix", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Information Retrieval", "\n", "\n", "\t\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "#ir_ratio_list = [0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1.0]", "\n", "ir_ratio_list", "=", "[", "0.02", "]", "\n", "\n", "training_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "test_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "test_ir_list", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "test_vectors", ",", "\n", "training_labels", ",", "\n", "test_labels", ",", "\n", "recall", "=", "ir_ratio_list", ",", "\n", "num_classes", "=", "params", "[", "'num_classes'", "]", ",", "\n", "multi_label", "=", "params", "[", "'multi_label'", "]", "\n", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nFractions list: %s\"", "%", "(", "ir_ratio_list", ")", ")", "\n", "f", ".", "write", "(", "\"\\nTest IR: %s\"", "%", "(", "test_ir_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_ppl": [[1720, 1836], ["tensorflow.Session", "model.Dataset", "os.path.join", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.get_default_graph", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "data.Dataset.batches", "numpy.mean", "numpy.exp", "print", "data.Dataset.batches", "numpy.mean", "numpy.exp", "print", "session_ppl.run", "sklearn.cosine_similarity", "session_ppl.run", "session_ppl.run", "session_ppl.run", "tensorflow.train.latest_checkpoint", "session_ppl.run", "this_val_nll.append", "this_val_loss_normed.append", "numpy.mean", "open", "f.write", "session_ppl.run", "this_test_nll.append", "this_test_loss_normed.append", "numpy.mean", "open", "f.write", "open", "numpy.argsort", "open", "enumerate", "tensorflow.ConfigProto", "os.path.join", "os.path.join", "w.strip", "f.write", "f.readlines", "numpy.arange", "numpy.arange", "tensorflow.GPUOptions", "len", "len", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity"], ["", "", "def", "reload_evaluation_ppl", "(", "params", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\t", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "intra_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "session_ppl", ":", "\n", "\n", "\t\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "saver_ppl", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\"model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"model_ppl/model_ppl-1.meta\"", ")", "\n", "saver_ppl", ".", "restore", "(", "session_ppl", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"model/\"", "+", "params", "[", "'reload_model_dir'", "]", "+", "\"model_ppl/\"", ")", ")", "\n", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "x", "=", "graph", ".", "get_tensor_by_name", "(", "\"x:0\"", ")", "\n", "y", "=", "graph", ".", "get_tensor_by_name", "(", "\"y:0\"", ")", "\n", "seq_lengths", "=", "graph", ".", "get_tensor_by_name", "(", "\"seq_lengths:0\"", ")", "\n", "loss_normed", "=", "graph", ".", "get_tensor_by_name", "(", "\"loss_normed_x:0\"", ")", "\n", "loss_unnormed", "=", "graph", ".", "get_tensor_by_name", "(", "\"loss_unnormed_x:0\"", ")", "\n", "\n", "# TODO: Validation PPL", "\n", "\n", "this_val_nll", "=", "[", "]", "\n", "this_val_loss_normed", "=", "[", "]", "\n", "# val_loss_unnormed is NLL", "\n", "this_val_nll_bw", "=", "[", "]", "\n", "this_val_loss_normed_bw", "=", "[", "]", "\n", "\n", "this_val_disc_accuracy", "=", "[", "]", "\n", "\n", "for", "val_y", ",", "val_x", ",", "val_seq_lengths", "in", "dataset", ".", "batches", "(", "'validation_docnade'", ",", "params", "[", "'validation_bs'", "]", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\n", "\t\t\t", "val_loss_normed", ",", "val_loss_unnormed", "=", "session_ppl", ".", "run", "(", "[", "loss_normed", ",", "loss_unnormed", "]", ",", "feed_dict", "=", "{", "\n", "x", ":", "val_x", ",", "\n", "y", ":", "val_y", ",", "\n", "seq_lengths", ":", "val_seq_lengths", "\n", "}", ")", "\n", "\n", "this_val_nll", ".", "append", "(", "val_loss_unnormed", ")", "\n", "this_val_loss_normed", ".", "append", "(", "val_loss_normed", ")", "\n", "\n", "\n", "", "total_val_nll", "=", "np", ".", "mean", "(", "this_val_nll", ")", "\n", "total_val_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_val_loss_normed", ")", ")", "\n", "\n", "print", "(", "'Val PPL: {:.3f},\tVal loss: {:.3f}\\n'", ".", "format", "(", "\n", "total_val_ppl", ",", "\n", "total_val_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ppl_\"", "+", "suffix", "+", "\".txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"Val PPL: %s,\tVal loss: %s\"", "%", "\n", "(", "total_val_ppl", ",", "total_val_nll", ")", ")", "\n", "\n", "# TODO: Test PPL", "\n", "\n", "", "this_test_nll", "=", "[", "]", "\n", "this_test_loss_normed", "=", "[", "]", "\n", "this_test_nll_bw", "=", "[", "]", "\n", "this_test_loss_normed_bw", "=", "[", "]", "\n", "this_test_disc_accuracy", "=", "[", "]", "\n", "\n", "for", "test_y", ",", "test_x", ",", "test_seq_lengths", "in", "dataset", ".", "batches", "(", "'test_docnade'", ",", "params", "[", "'test_bs'", "]", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\n", "\t\t\t", "test_loss_normed", ",", "test_loss_unnormed", "=", "session_ppl", ".", "run", "(", "[", "loss_normed", ",", "loss_unnormed", "]", ",", "feed_dict", "=", "{", "\n", "x", ":", "test_x", ",", "\n", "y", ":", "test_y", ",", "\n", "seq_lengths", ":", "test_seq_lengths", "\n", "}", ")", "\n", "\n", "this_test_nll", ".", "append", "(", "test_loss_unnormed", ")", "\n", "this_test_loss_normed", ".", "append", "(", "test_loss_normed", ")", "\n", "\n", "", "total_test_nll", "=", "np", ".", "mean", "(", "this_test_nll", ")", "\n", "total_test_ppl", "=", "np", ".", "exp", "(", "np", ".", "mean", "(", "this_test_loss_normed", ")", ")", "\n", "\n", "print", "(", "'Test PPL: {:.3f},\tTest loss: {:.3f}\\n'", ".", "format", "(", "\n", "total_test_ppl", ",", "\n", "total_test_nll", "\n", ")", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ppl_\"", "+", "suffix", "+", "\".txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"\\n\\nTest PPL: %s,\tTest loss: %s\"", "%", "\n", "(", "total_test_ppl", ",", "total_test_nll", ")", ")", "\n", "\n", "", "W_target", "=", "session_ppl", ".", "run", "(", "\"embedding:0\"", ")", "\n", "\n", "top_n_words", "=", "20", "\n", "\n", "# Nearest Neighbors", "\n", "with", "open", "(", "params", "[", "'docnadeVocab'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "W", "=", "W_target", "\n", "\n", "sim_mat", "=", "pw", ".", "cosine_similarity", "(", "W", ",", "W", ")", "\n", "sim_mat", "[", "np", ".", "arange", "(", "len", "(", "vocab_docnade", ")", ")", ",", "np", ".", "arange", "(", "len", "(", "vocab_docnade", ")", ")", "]", "=", "-", "1.0", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "sim_mat", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "with", "open", "(", "log_dir", "+", "\"/nearest_neighbours.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "counter", ",", "indices", "in", "enumerate", "(", "sorted_indices", "[", ":", ",", ":", "top_n_words", "]", ")", ":", "\n", "\t\t\t\t", "query_word", "=", "vocab_docnade", "[", "counter", "]", "\n", "nn_words", "=", "\" | \"", ".", "join", "(", "[", "vocab_docnade", "[", "index", "]", "+", "\" ( \"", "+", "str", "(", "sim_mat", "[", "counter", ",", "index", "]", ")", "+", "\" ) \"", "for", "index", "in", "indices", "]", ")", "\n", "line", "=", "query_word", "+", "\" :: \"", "+", "nn_words", "+", "\"\\n\"", "\n", "f", ".", "write", "(", "line", ")", "\n", "\n", "\n", "", "", "bias_W_target", "=", "session_ppl", ".", "run", "(", "\"bias:0\"", ")", "\n", "U_target", "=", "session_ppl", ".", "run", "(", "\"U:0\"", ")", "\n", "bias_U_target", "=", "session_ppl", ".", "run", "(", "\"b:0\"", ")", "\n", "\n", "return", "W_target", ",", "bias_W_target", ",", "U_target", ",", "bias_U_target", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_topics": [[1838, 1891], ["os.path.join", "range", "train_DocNADE.compute_coherence", "w_h_top_words_indices.append", "open", "open", "zip", "print", "open().readlines", "os.path.join", "w.strip", "os.path.join", "range", "topics_list_W.append", "print", "print", "print", "print", "f.write", "f.write", "f.write", "f.write", "str().strip", "texts.append", "numpy.array", "f.readlines", "len", "open", "str().strip.split", "numpy.argsort", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.compute_coherence"], ["", "", "def", "reload_evaluation_topics", "(", "W_target", ",", "U_target", ",", "params", ")", ":", "\n", "\n", "\t", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "# Topics with W matrix", "\n", "\n", "top_n_topic_words", "=", "20", "\n", "w_h_top_words_indices", "=", "[", "]", "\n", "W_topics", "=", "W_target", "\n", "topics_list_W", "=", "[", "]", "\n", "\n", "for", "h_num", "in", "range", "(", "np", ".", "array", "(", "W_topics", ")", ".", "shape", "[", "1", "]", ")", ":", "\n", "\t\t", "w_h_top_words_indices", ".", "append", "(", "np", ".", "argsort", "(", "W_topics", "[", ":", ",", "h_num", "]", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_n_topic_words", "]", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'docnadeVocab'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_ppl_W.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "w_h_top_words_indx", ",", "h_num", "in", "zip", "(", "w_h_top_words_indices", ",", "range", "(", "len", "(", "w_h_top_words_indices", ")", ")", ")", ":", "\n", "\t\t\t", "w_h_top_words", "=", "[", "vocab_docnade", "[", "w_indx", "]", "for", "w_indx", "in", "w_h_top_words_indx", "]", "\n", "\n", "topics_list_W", ".", "append", "(", "w_h_top_words", ")", "\n", "\n", "print", "(", "'h_num: %s'", "%", "h_num", ")", "\n", "print", "(", "'w_h_top_words_indx: %s'", "%", "w_h_top_words_indx", ")", "\n", "print", "(", "'w_h_top_words:%s'", "%", "w_h_top_words", ")", "\n", "print", "(", "'----------------------------------------------------------------------'", ")", "\n", "\n", "f", ".", "write", "(", "'h_num: %s\\n'", "%", "h_num", ")", "\n", "f", ".", "write", "(", "'w_h_top_words_indx: %s\\n'", "%", "w_h_top_words_indx", ")", "\n", "f", ".", "write", "(", "'w_h_top_words:%s\\n'", "%", "w_h_top_words", ")", "\n", "f", ".", "write", "(", "'----------------------------------------------------------------------\\n'", ")", "\n", "\n", "# TOPIC COHERENCE", "\n", "\n", "", "", "top_n_word_in_each_topic_list", "=", "[", "5", ",", "10", ",", "15", ",", "20", "]", "\n", "\n", "text_filenames", "=", "[", "\n", "params", "[", "'trainfile'", "]", ",", "\n", "params", "[", "'valfile'", "]", ",", "\n", "params", "[", "'testfile'", "]", "\n", "]", "\n", "\n", "# read original text documents as list of words", "\n", "texts", "=", "[", "]", "\n", "\n", "for", "file", "in", "text_filenames", ":", "\n", "\t\t", "print", "(", "'filename:%s'", ",", "file", ")", "\n", "for", "line", "in", "open", "(", "file", ",", "'r'", ")", ".", "readlines", "(", ")", ":", "\n", "\t\t\t", "document", "=", "str", "(", "line", ")", ".", "strip", "(", ")", "\n", "texts", ".", "append", "(", "document", ".", "split", "(", ")", ")", "\n", "\n", "", "", "compute_coherence", "(", "texts", ",", "topics_list_W", ",", "top_n_word_in_each_topic_list", ",", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"topics_coherence_W.txt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool": [[1893, 1900], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "\t", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "\t\t", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "\t\t", "return", "False", "\n", "", "else", ":", "\n", "\t\t", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.main": [[1902, 2123], ["train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "train_DocNADE.str2bool", "os.path.isdir", "os.path.isdir", "os.path.isdir", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "datetime.datetime.now", "model.Dataset", "model.DocNADE", "print", "train_DocNADE.train", "open", "json.load", "json.load", "train_DocNADE.reload_evaluation_ppl", "train_DocNADE.reload_evaluation_ir", "train_DocNADE.reload_evaluation_acc_mAP", "print", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "str", "str", "os.path.isdir", "os.mkdir", "codecs.open", "open", "f.write", "open", "numpy.load", "prior_embedding_matrices.append", "numpy.load", "prior_embedding_matrices.append", "numpy.concatenate", "numpy.load", "print", "numpy.load", "print", "tensorflow.Session", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.get_default_graph", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "tf.get_default_graph.get_tensor_by_name", "model.Dataset", "data.Dataset.batches", "numpy.squeeze", "data.Dataset.batches", "numpy.squeeze", "sess_ir.run", "str", "str", "str", "str", "str", "w.strip", "os.path.join", "json.dumps", "json.dumps", "line.strip", "new_bio_embs.append", "numpy.array", "new_ftt_embs.append", "numpy.array", "tensorflow.train.latest_checkpoint", "sess_ir.run", "np.squeeze.append", "numpy.array", "sess_ir.run", "np.squeeze.append", "numpy.array", "str", "str", "f.readlines", "vars", "f.readlines", "tensorflow.ConfigProto", "str", "str", "total_vocab.index", "total_vocab.index", "tensorflow.GPUOptions", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.str2bool", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.train", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_ppl", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.Embsum.reload_evaluation_ir", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.reload_evaluation_acc_mAP", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "\t", "args", ".", "reload", "=", "str2bool", "(", "args", ".", "reload", ")", "\n", "args", ".", "use_bio_prior", "=", "str2bool", "(", "args", ".", "use_bio_prior", ")", "\n", "args", ".", "use_fasttext_prior", "=", "str2bool", "(", "args", ".", "use_fasttext_prior", ")", "\n", "args", ".", "sup_projection", "=", "str2bool", "(", "args", ".", "sup_projection", ")", "\n", "args", ".", "sup_l2_regularization", "=", "str2bool", "(", "args", ".", "sup_l2_regularization", ")", "\n", "args", ".", "multi_label", "=", "str2bool", "(", "args", ".", "multi_label", ")", "\n", "args", ".", "run_supervised", "=", "str2bool", "(", "args", ".", "run_supervised", ")", "\n", "args", ".", "run_docnade", "=", "str2bool", "(", "args", ".", "run_docnade", ")", "\n", "args", ".", "weighted_supervised", "=", "str2bool", "(", "args", ".", "weighted_supervised", ")", "\n", "args", ".", "use_title_separately", "=", "str2bool", "(", "args", ".", "use_title_separately", ")", "\n", "\n", "if", "args", ".", "reload", ":", "\n", "\t\t", "with", "open", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"params.json\"", ")", "as", "f", ":", "\n", "\t\t\t", "params", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "#params['trainfile'] = args.trainfile", "\n", "#params['valfile'] = args.valfile", "\n", "#params['testfile'] = args.testfile", "\n", "\n", "", "params", "[", "'reload_model_dir'", "]", "=", "args", ".", "reload_model_dir", "\n", "\n", "reload_ir", "=", "False", "\n", "if", "os", ".", "path", ".", "isdir", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ir\"", ")", ":", "\n", "\t\t\t", "reload_ir", "=", "True", "\n", "\n", "", "reload_ppl", "=", "False", "\n", "if", "os", ".", "path", ".", "isdir", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_ppl\"", ")", ":", "\n", "\t\t\t", "reload_ppl", "=", "True", "\n", "\n", "", "reload_sup", "=", "False", "\n", "if", "os", ".", "path", ".", "isdir", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"/model_sup\"", ")", ":", "\n", "\t\t\t", "reload_sup", "=", "True", "\n", "\n", "# Reloading and evaluating on Perplexity, Topic Coherence and calculating Nearest Neighbors", "\n", "", "if", "reload_ppl", ":", "\n", "\n", "\t\t\t", "W_target", ",", "bias_W_target", ",", "U_target", ",", "bias_U_target", "=", "reload_evaluation_ppl", "(", "params", ",", "suffix", "=", "\"target\"", ")", "\n", "#reload_evaluation_topics(W_target, U_target, params)", "\n", "\n", "# Reloading and evaluating on Information Retrieval and Classification - F1", "\n", "", "if", "reload_ir", ":", "\n", "\n", "\t\t\t", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "intra_op_parallelism_threads", "=", "params", "[", "'num_cores'", "]", ",", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", ")", ")", "as", "sess_ir", ":", "\n", "\n", "\t\t\t\t", "saver_ir", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"model_ir/model_ir-1.meta\"", ")", "\n", "saver_ir", ".", "restore", "(", "sess_ir", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "\"model/\"", "+", "args", ".", "reload_model_dir", "+", "\"model_ir/\"", ")", ")", "\n", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "x", "=", "graph", ".", "get_tensor_by_name", "(", "\"x:0\"", ")", "\n", "seq_lengths", "=", "graph", ".", "get_tensor_by_name", "(", "\"seq_lengths:0\"", ")", "\n", "last_hidden", "=", "graph", ".", "get_tensor_by_name", "(", "\"last_hidden:0\"", ")", "\n", "\n", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "\n", "hidden_vectors_tr", "=", "[", "]", "\n", "for", "tr_y", ",", "tr_x", ",", "tr_seq_lengths", "in", "dataset", ".", "batches", "(", "'training_docnade'", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t\t\t", "hidden_vec", "=", "sess_ir", ".", "run", "(", "[", "last_hidden", "]", ",", "feed_dict", "=", "{", "\n", "x", ":", "tr_x", ",", "\n", "seq_lengths", ":", "tr_seq_lengths", "\n", "}", ")", "\n", "hidden_vectors_tr", ".", "append", "(", "hidden_vec", "[", "0", "]", ")", "\n", "", "hidden_vectors_tr", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "hidden_vectors_tr", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "hidden_vectors_test", "=", "[", "]", "\n", "for", "te_y", ",", "te_x", ",", "te_seq_lengths", "in", "dataset", ".", "batches", "(", "'test_docnade'", ",", "batch_size", "=", "1", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "True", ",", "multilabel", "=", "params", "[", "'multi_label'", "]", ")", ":", "\n", "\t\t\t\t\t", "hidden_vec", "=", "sess_ir", ".", "run", "(", "[", "last_hidden", "]", ",", "feed_dict", "=", "{", "\n", "x", ":", "te_x", ",", "\n", "seq_lengths", ":", "te_seq_lengths", "\n", "}", ")", "\n", "hidden_vectors_test", ".", "append", "(", "hidden_vec", "[", "0", "]", ")", "\n", "", "hidden_vectors_test", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "hidden_vectors_test", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "W_target", "=", "sess_ir", ".", "run", "(", "\"embedding:0\"", ")", "\n", "\n", "", "reload_evaluation_ir", "(", "params", ",", "hidden_vectors_tr", ",", "hidden_vectors_test", ",", "\n", "W_target", ",", "suffix", "=", "\"target\"", ")", "\n", "\"\"\"\n\t\t\treload_evaluation_f1(params, hidden_vectors_tr, hidden_vectors_test, \n\t\t\t\t\t\t\t\tW_target, suffix=\"target\")\n\t\t\t\"\"\"", "\n", "\n", "# Reloading and evaluating classification accuracy and mAP", "\n", "", "if", "reload_sup", ":", "\n", "\n", "\t\t\t", "params", "[", "'use_bio_prior'", "]", "=", "False", "\n", "params", "[", "'use_fasttext_prior'", "]", "=", "True", "\n", "params", "[", "'use_BOW_repesentation'", "]", "=", "False", "\n", "params", "[", "'use_DocNADE_W'", "]", "=", "False", "\n", "\n", "params", "[", "'split_abstract_title'", "]", "=", "False", "\n", "params", "[", "'include_sup_probs'", "]", "=", "False", "\n", "params", "[", "'attention_EmbSum_type'", "]", "=", "\"sum\"", "\n", "\n", "if", "params", "[", "'include_sup_probs'", "]", ":", "\n", "\t\t\t\t", "params", "[", "'model'", "]", "+=", "'_including_classification_loss'", "\n", "\n", "", "docnade_embedding_matrix", ",", "query_embedding_matrix", ",", "query_vecs", ",", "queries", ",", "query_words_list", "=", "reload_evaluation_acc_mAP", "(", "params", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "\t\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x'", ")", "\n", "x_bw", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x_bw'", ")", "\n", "if", "args", ".", "multi_label", ":", "\n", "\t\t\t", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'y'", ")", "\n", "", "else", ":", "\n", "\t\t\t", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'y'", ")", "\n", "", "seq_lengths", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'seq_lengths'", ")", "\n", "\n", "if", "args", ".", "use_title_separately", ":", "\n", "\t\t\t", "x_title", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ",", "name", "=", "'x_title'", ")", "\n", "seq_lengths_title", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ")", ",", "name", "=", "'seq_lengths_title'", ")", "\n", "", "else", ":", "\n", "\t\t\t", "x_title", "=", "None", "\n", "seq_lengths_title", "=", "None", "\n", "\n", "", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "\n", "regularization_strength", "=", "0.001", "\n", "\n", "if", "args", ".", "run_docnade", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_DocNADE\"", "\n", "\n", "", "if", "args", ".", "run_supervised", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Sup\"", "\n", "\n", "", "if", "args", ".", "weighted_supervised", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Weighted_\"", "+", "str", "(", "args", ".", "sup_weight_init", ")", "\n", "\n", "", "if", "args", ".", "sup_l2_regularization", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_l2_reg_\"", "+", "str", "(", "regularization_strength", ")", "\n", "\n", "", "if", "args", ".", "use_bio_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Emb_bio_\"", "+", "str", "(", "args", ".", "lambda_glove", ")", "\n", "\n", "", "if", "args", ".", "use_fasttext_prior", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Emb_ftt_\"", "+", "str", "(", "args", ".", "lambda_glove", ")", "\n", "\n", "", "if", "args", ".", "W_pretrained_path", "or", "args", ".", "U_pretrained_path", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Pretr_reload\"", "\n", "\n", "", "args", ".", "model", "+=", "\"_Act_\"", "+", "str", "(", "args", ".", "activation", ")", "+", "\"_Hid_\"", "+", "str", "(", "args", ".", "hidden_size", ")", "+", "\"_Vocab_\"", "+", "str", "(", "args", ".", "vocab_size", ")", "+", "\"_lr_\"", "+", "str", "(", "args", ".", "learning_rate", ")", "\n", "if", "args", ".", "sup_projection", ":", "\n", "\t\t\t", "args", ".", "model", "+=", "\"_Projection_\"", "+", "str", "(", "args", ".", "sup_projection_size", ")", "\n", "\n", "", "args", ".", "model", "+=", "\"_\"", "+", "str", "(", "now", ".", "day", ")", "+", "\"_\"", "+", "str", "(", "now", ".", "month", ")", "+", "\"_\"", "+", "str", "(", "now", ".", "year", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "model", ")", ":", "\n", "\t\t\t", "os", ".", "mkdir", "(", "args", ".", "model", ")", "\n", "\n", "", "docnade_vocab", "=", "args", ".", "docnadeVocab", "\n", "#with open(docnade_vocab, 'r') as f:", "\n", "with", "codecs", ".", "open", "(", "docnade_vocab", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "\t\t\t", "vocab_docnade", "=", "[", "w", ".", "strip", "(", ")", "for", "w", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model", ",", "'params.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "args", ")", ")", ")", "\n", "\n", "", "dataset", "=", "data", ".", "Dataset", "(", "args", ".", "dataset", ")", "\n", "\n", "docnade_embedding_matrix", "=", "None", "\n", "prior_emb_dim", "=", "None", "\n", "\n", "with", "open", "(", "\"./pretrained_embeddings/biggest_vocab.vocab\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "total_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "prior_embedding_matrices", "=", "[", "]", "\n", "\n", "if", "args", ".", "use_bio_prior", ":", "\n", "\t\t\t", "bio_embeddings", "=", "np", ".", "load", "(", "'./pretrained_embeddings/bionlp_embeddings_biggest_vocab.npy'", ")", "\n", "new_bio_embs", "=", "[", "]", "\n", "for", "word", "in", "vocab_docnade", ":", "\n", "\t\t\t\t", "new_bio_embs", ".", "append", "(", "bio_embeddings", "[", "total_vocab", ".", "index", "(", "word", ")", "]", ")", "\n", "#prior_embedding_matrices.append(bio_embeddings)", "\n", "", "prior_embedding_matrices", ".", "append", "(", "np", ".", "array", "(", "new_bio_embs", ")", ")", "\n", "\n", "", "if", "args", ".", "use_fasttext_prior", ":", "\n", "\t\t\t", "fasttext_embeddings", "=", "np", ".", "load", "(", "'./pretrained_embeddings/fasttext_embeddings_biggest_vocab.npy'", ")", "\n", "new_ftt_embs", "=", "[", "]", "\n", "for", "word", "in", "vocab_docnade", ":", "\n", "\t\t\t\t", "new_ftt_embs", ".", "append", "(", "fasttext_embeddings", "[", "total_vocab", ".", "index", "(", "word", ")", "]", ")", "\n", "#prior_embedding_matrices.append(fasttext_embeddings)", "\n", "", "prior_embedding_matrices", ".", "append", "(", "np", ".", "array", "(", "new_ftt_embs", ")", ")", "\n", "\n", "", "if", "args", ".", "use_bio_prior", "or", "args", ".", "use_fasttext_prior", ":", "\n", "\t\t\t", "docnade_embedding_matrix", "=", "np", ".", "concatenate", "(", "prior_embedding_matrices", ",", "axis", "=", "1", ")", "\n", "prior_emb_dim", "=", "docnade_embedding_matrix", ".", "shape", "[", "1", "]", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "W_pretrained_matrix", "=", "None", "\n", "if", "args", ".", "W_pretrained_path", ":", "\n", "\t\t\t", "W_pretrained_matrix", "=", "np", ".", "load", "(", "args", ".", "W_pretrained_path", ")", "\n", "print", "(", "\"pretrained W loaded.\"", ")", "\n", "\n", "", "U_pretrained_matrix", "=", "None", "\n", "if", "args", ".", "U_pretrained_path", ":", "\n", "\t\t\t", "U_pretrained_matrix", "=", "np", ".", "load", "(", "args", ".", "U_pretrained_path", ")", "\n", "print", "(", "\"pretrained U loaded.\"", ")", "\n", "\n", "", "model", "=", "m", ".", "DocNADE", "(", "x", ",", "y", ",", "seq_lengths", ",", "args", ",", "W_pretrained", "=", "W_pretrained_matrix", ",", "U_pretrained", "=", "U_pretrained_matrix", ",", "glove_embeddings", "=", "docnade_embedding_matrix", ",", "lambda_glove", "=", "args", ".", "lambda_glove", ",", "l2_reg_c", "=", "regularization_strength", ",", "prior_emb_dim", "=", "prior_emb_dim", ",", "x_title", "=", "x_title", ",", "seq_lengths_title", "=", "seq_lengths_title", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "print", "(", "\"DocNADE created\"", ")", "\n", "\n", "train", "(", "model", ",", "dataset", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.parse_args": [[2125, 2212], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to model output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to the input dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab-size'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "'the vocab size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden-size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'size of the hidden layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--activation'", ",", "type", "=", "str", ",", "default", "=", "'tanh'", ",", "\n", "help", "=", "'which activation to use: sigmoid|tanh'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0004", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-steps'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "'the number of steps to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-cores'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'the number of CPU cores to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-every'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-ppl-freq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-classes'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'number of classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-bio-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use BioNLP embeddings as prior information'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-fasttext-prior'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use fastText embeddings as prior information'", ")", "\n", "parser", ".", "add_argument", "(", "'--docnadeVocab'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'path to vocabulary file used by DocNADE'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-ppl-freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'print and log test PPL after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-ir-freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'print and log test IR after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'print and log test IR after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-bs'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size for validation evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-bs'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'the batch size for test evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-ir-freq'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'print loss after this many steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup-projection'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to do projection in supervised network'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup-projection-size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'supervised projection hidden size'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup-l2-regularization'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to add regularization loss in supervised network'", ")", "\n", "parser", ".", "add_argument", "(", "'--reload'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to reload model or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--reload-model-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path for model to be reloaded'", ")", "\n", "parser", ".", "add_argument", "(", "'--run-supervised'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use supervised model or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--run-docnade'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use docnade model or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--weighted-supervised'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use weighted supervised model or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--use-title-separately'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether to use titles separately or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--input-type'", ",", "type", "=", "str", ",", "default", "=", "\"both\"", ",", "\n", "help", "=", "'whether to use titles/abstracts/both for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--sup-weight-init'", ",", "type", "=", "float", ",", "default", "=", "-", "1.0", ",", "\n", "help", "=", "'initialization for weighted supervised model'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi-label'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "\n", "help", "=", "'whether dataset is multi-label or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--trainfile'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "'path to train text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--valfile'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "'path to validation text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--testfile'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "\n", "help", "=", "'path to test text file'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda-glove'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'combination weight for prior GloVe embeddings into docnade'", ")", "\n", "parser", ".", "add_argument", "(", "'--W-pretrained-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained W matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--U-pretrained-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained U matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--bioemb-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained BioNLP embedding matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--fttemb-path'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'path for pretrained BioNLP embedding matrix'", ")", "\n", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_train_dev_set.is_float": [[27, 29], ["FLOAT_REGEXP.match"], "function", ["None"], ["def", "is_float", "(", "str", ")", ":", "\n", "\t", "return", "True", "if", "FLOAT_REGEXP", ".", "match", "(", "str", ")", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_train_dev_set.replace_num": [[30, 38], ["convert_to_text_task2_train_dev_set.is_float", "new_tokens.append", "new_tokens.append"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.is_float"], ["", "def", "replace_num", "(", "tokens", ")", ":", "\n", "\t", "new_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "if", "is_float", "(", "token", ")", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "\"<num>\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "token", ")", "\n", "", "", "return", "new_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_train_dev_set.preprocess_token": [[39, 41], ["char.isalpha"], "function", ["None"], ["", "def", "preprocess_token", "(", "token", ")", ":", "\n", "\t", "return", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "token", "if", "char", ".", "isalpha", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task2_train_dev_set.remove_punctuation_and_replace_num": [[42, 53], ["convert_to_text_task2_train_dev_set.replace_num", "token.strip", "convert_to_text_task2_train_dev_set.preprocess_token", "tokenizer.tokenize", "token.lower", "token.isupper"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.replace_num", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.preprocess_token"], ["", "def", "remove_punctuation_and_replace_num", "(", "doc", ")", ":", "\n", "\t", "doc_tokens", "=", "[", "token", ".", "strip", "(", "string", ".", "punctuation", ")", "for", "token", "in", "tokenizer", ".", "tokenize", "(", "doc", ")", "]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", ".", "isupper", "(", ")", "]", "\n", "doc_tokens", "=", "replace_num", "(", "doc_tokens", ")", "\n", "doc_tokens", "=", "[", "preprocess_token", "(", "token", ".", "lower", "(", ")", ")", "for", "token", "in", "doc_tokens", "]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", "in", "cachedStopWords", "]", "\n", "#if len(doc_tokens) > 1:", "\n", "#\treturn \" \".join(doc_tokens)", "\n", "#else:", "\n", "#\treturn ''", "\n", "return", "\" \"", ".", "join", "(", "doc_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.perform_classification_test": [[37, 94], ["numpy.mean", "numpy.std", "sklearn.svm.SVC.fit", "sklearn.svm.SVC.predict", "sklearn.svm.SVC.predict_proba", "sklearn.metrics.accuracy_score", "test_acc.append", "test_pred_labels.append", "test_pred_probs.append", "numpy.vstack", "numpy.vstack", "LogisticRegression", "sklearn.svm.SVC"], "function", ["None"], ["", "", "def", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "\t", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "\t\t", "\"\"\"\n\t\ttemp_mat = np.vstack((docVectors_train, docVectors_test))\n\n\t\tmean = np.mean(temp_mat, axis=0)\n\t\tstd = np.std(temp_mat, axis=0)\n\t\ttemp_mat_normed = (temp_mat - mean) / std\n\n\t\tdocVectors_train = temp_mat_normed[:len(docVectors_train), :]\n\t\tdocVectors_test = temp_mat_normed[-len(docVectors_test):, :]\n\t\t\"\"\"", "\n", "\n", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "## Classification Accuracy", "\n", "", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "test_pred_labels", "=", "[", "]", "\n", "test_pred_probs", "=", "[", "]", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "\t\t", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t\t", "clf", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#clf = SVC(C=c, kernel='precomputed')", "\n", "#clf = SVC(C=c)", "\n", "\t\t\t", "clf", "=", "SVC", "(", "C", "=", "c", ",", "probability", "=", "True", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_test_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "pred_test_probs", "=", "clf", ".", "predict_proba", "(", "docVectors_test", ")", "\n", "\n", "acc_test", "=", "accuracy_score", "(", "test_labels", ",", "pred_test_labels", ")", "\n", "#f1_test = precision_recall_fscore_support(test_labels, pred_test_labels, pos_label=None, average='macro')[2]", "\n", "\n", "test_acc", ".", "append", "(", "acc_test", ")", "\n", "#test_f1.append(f1_test)", "\n", "\n", "test_pred_labels", ".", "append", "(", "pred_test_labels", ")", "\n", "test_pred_probs", ".", "append", "(", "pred_test_probs", ")", "\n", "\n", "", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t", "return", "test_acc", ",", "test_f1", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#return test_acc, test_f1, pred_test_probs", "\n", "\t\t", "return", "test_acc", ",", "test_f1", ",", "test_pred_probs", ",", "test_pred_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.reload_evaluation_f1": [[96, 227], ["model.Dataset", "os.path.join", "SVM_task2.perform_classification_test", "print", "print", "range", "print", "zip", "val_scores_dict.keys", "os.path.exists", "os.makedirs", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "open", "f.write", "open", "f.write", "len", "numpy.array", "numpy.unique", "enumerate", "numpy.mean", "acc_scores.append", "open", "f.write", "numpy.argmax", "val_scores_dict[].append", "val_ids_dict[].append", "numpy.mean", "classwise_scores.append", "open", "val_scores_dict.items", "open", "zip", "os.path.join", "os.path.join", "val_docs_pred_labels[].append", "val_docs_pred_probs[].append", "numpy.argmax", "val_pred_list.append", "os.path.join", "f.write", "f.write", "f.write", "f.write", "f.write", "os.path.join", "range", "f.write", "f.write", "f.write", "f.write", "f.write", "len", "numpy.argsort", "numpy.array", "numpy.array", "str", "str", "str", "str", "numpy.mean", "str", "str", "str", "str", "int", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test"], ["", "", "def", "reload_evaluation_f1", "(", "params", ",", "training_vectors", ",", "validation_vectors", ",", "training_labels", ",", "\n", "validation_labels", ",", "training_ids", ",", "validation_ids", ",", "val_labels", ",", "val_ids", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Classification - F1", "\n", "\n", "\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "#c_list = [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 3.0, 5.0, 10.0, 100.0, 500.0, 1000.0, 10000.0]", "\n", "#c_list = [1.0, 3.0, 5.0, 10.0, 100.0, 500.0, 1000.0, 10000.0]", "\n", "", "c_list", "=", "[", "1000.0", "]", "\n", "\n", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "val_acc", "=", "[", "]", "\n", "val_f1", "=", "[", "]", "\n", "\n", "test_acc_W", "=", "[", "]", "\n", "test_f1_W", "=", "[", "]", "\n", "val_acc_W", "=", "[", "]", "\n", "val_f1_W", "=", "[", "]", "\n", "\n", "#y_train = training_labels", "\n", "#y_test = validation_labels", "\n", "\n", "train_data", "=", "(", "np", ".", "array", "(", "training_vectors", ",", "dtype", "=", "np", ".", "float32", ")", ",", "np", ".", "array", "(", "training_labels", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "test_data", "=", "(", "np", ".", "array", "(", "validation_vectors", ",", "dtype", "=", "np", ".", "float32", ")", ",", "np", ".", "array", "(", "validation_labels", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "test_acc", ",", "test_f1", ",", "pred_probs", ",", "pred_labels", "=", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"svm\"", ",", "norm_before_classification", "=", "False", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"info.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "\"\\n\\nTest accuracy with h vector IR: %s\"", "%", "(", "test_acc", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "\"\\n\\nTest F1 score with h vector IR: %s\"", "%", "(", "test_f1", ")", ")", "\n", "\n", "", "print", "(", "\"Test acc: \"", ",", "test_acc", ")", "\n", "print", "(", "\"Test f1: \"", ",", "test_f1", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "acc_scores", "=", "[", "]", "\n", "best_acc_score", "=", "-", "1.0", "\n", "best_val_docs_pred_labels", "=", "{", "}", "\n", "best_val_docs_pred_probs", "=", "{", "}", "\n", "for", "j", "in", "range", "(", "len", "(", "c_list", ")", ")", ":", "\n", "\t\t", "temp_pred_labels", "=", "np", ".", "array", "(", "validation_labels", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_pred_probs", "=", "pred_probs", "[", "j", "]", "[", ":", ",", "1", "]", "\n", "\n", "unique_val_ids", "=", "np", ".", "unique", "(", "validation_ids", ")", "\n", "val_docs_pred_labels", "=", "{", "id", ":", "[", "]", "for", "id", "in", "unique_val_ids", "}", "\n", "val_docs_pred_probs", "=", "{", "id", ":", "[", "]", "for", "id", "in", "unique_val_ids", "}", "\n", "for", "i", ",", "id", "in", "enumerate", "(", "validation_ids", ")", ":", "\n", "\t\t\t", "val_docs_pred_labels", "[", "id", "]", ".", "append", "(", "temp_pred_labels", "[", "i", "]", ")", "\n", "val_docs_pred_probs", "[", "id", "]", ".", "append", "(", "temp_pred_probs", "[", "i", "]", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "val_pred_list", "=", "[", "]", "\n", "for", "id", "in", "unique_val_ids", ":", "\n", "\t\t\t", "max_index", "=", "np", ".", "argmax", "(", "val_docs_pred_probs", "[", "id", "]", ")", "\n", "val_pred_list", ".", "append", "(", "val_docs_pred_labels", "[", "id", "]", "[", "max_index", "]", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "#acc_score = accuracy_score(np.ones(len(val_pred_list), dtype=np.int8), np.array(val_pred_list))", "\n", "", "acc_score", "=", "np", ".", "mean", "(", "val_pred_list", ")", "\n", "\n", "acc_scores", ".", "append", "(", "acc_score", ")", "\n", "\n", "if", "acc_score", ">", "best_acc_score", ":", "\n", "\t\t\t", "best_acc_score", "=", "acc_score", "\n", "best_val_docs_pred_labels", "=", "val_docs_pred_labels", "\n", "best_val_docs_pred_probs", "=", "val_docs_pred_probs", "\n", "\n", "#precision, recall, f1, support = precision_recall_fscore_support(np.ones(len(val_pred_list), dtype=np.int8), np.array(val_pred_list), average='macro')", "\n", "\n", "#print(\"Test acc_score: \", acc_score)", "\n", "", "", "print", "(", "\"Validation acc_scores: \"", ",", "acc_scores", ")", "\n", "#print(\"Test precision: \", precision)", "\n", "#print(\"Test recall: \", recall)", "\n", "#print(\"Test f1: \", f1)", "\n", "#print(\"Test support: \", support)", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"info.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "#f.write(\"\\n\\nBest accuracy score: %s\" % (acc_score))", "\n", "\t\t", "f", ".", "write", "(", "\"\\n\\nValidation accuracy scores: %s\"", "%", "(", "acc_scores", ")", ")", "\n", "#f.write(\"\\n\\nBest precision score: %s\" % (precision))", "\n", "#f.write(\"\\n\\nBest recall score: %s\" % (recall))", "\n", "#f.write(\"\\n\\nBest f1 score: %s\" % (f1))", "\n", "#f.write(\"\\n\\nBest support score: %s\" % (support))", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "", "val_scores_dict", "=", "{", "}", "\n", "val_ids_dict", "=", "{", "}", "\n", "for", "label", ",", "id", "in", "zip", "(", "val_labels", ",", "val_ids", ")", ":", "\n", "\t\t", "if", "not", "label", "in", "val_scores_dict", ":", "\n", "\t\t\t", "val_scores_dict", "[", "label", "]", "=", "[", "]", "\n", "val_ids_dict", "[", "label", "]", "=", "[", "]", "\n", "", "max_index", "=", "np", ".", "argmax", "(", "best_val_docs_pred_probs", "[", "id", "]", ")", "\n", "pred_label", "=", "best_val_docs_pred_labels", "[", "id", "]", "[", "max_index", "]", "\n", "val_scores_dict", "[", "label", "]", ".", "append", "(", "pred_label", ")", "\n", "val_ids_dict", "[", "label", "]", ".", "append", "(", "id", ")", "\n", "\n", "", "classwise_scores", "=", "[", "]", "\n", "for", "label", "in", "val_scores_dict", ".", "keys", "(", ")", ":", "\n", "\t\t", "class_val_prec", "=", "np", ".", "mean", "(", "val_scores_dict", "[", "label", "]", ")", "\n", "classwise_scores", ".", "append", "(", "class_val_prec", ")", "\n", "\n", "", "with", "open", "(", "log_dir", "+", "\"/classwise_scores.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "label", ",", "scores", "in", "val_scores_dict", ".", "items", "(", ")", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"Label:  \"", "+", "label", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"ids:    \"", "+", "str", "(", "val_ids_dict", "[", "label", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"scores:  \"", "+", "str", "(", "scores", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"prec:  \"", "+", "str", "(", "np", ".", "mean", "(", "scores", ")", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "# logging information", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_clusters_with_SVM.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t", "for", "doc_counter", ",", "query", ",", "id", "in", "zip", "(", "range", "(", "len", "(", "val_pred_list", ")", ")", ",", "val_labels", ",", "val_ids", ")", ":", "\n", "\t\t\t", "sorted_indices", "=", "np", ".", "argsort", "(", "best_val_docs_pred_probs", "[", "id", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "relevance_labels", "=", "np", ".", "array", "(", "best_val_docs_pred_labels", "[", "id", "]", ")", "[", "sorted_indices", "]", "\n", "relevance_scores", "=", "np", ".", "array", "(", "best_val_docs_pred_probs", "[", "id", "]", ")", "[", "sorted_indices", "]", "\n", "f", ".", "write", "(", "\"Doc \"", "+", "str", "(", "doc_counter", ")", "+", "\": \"", "+", "str", "(", "query", ")", "+", "\": \"", "+", "str", "(", "id", ")", "+", "\"\\n\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_labels:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "int", "(", "l", ")", ")", "for", "l", "in", "relevance_labels", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Predicted_probs:   \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "relevance_scores", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"Sentence indices:  \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "l", ")", "for", "l", "in", "sorted_indices", "]", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "\"\\n=================================================================================\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.BOW_representation": [[231, 236], ["numpy.zeros", "int"], "function", ["None"], ["", "", "", "def", "BOW_representation", "(", "tokens", ",", "vocab_size", ")", ":", "\n", "\t", "vec", "=", "np", ".", "zeros", "(", "vocab_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "vec", "[", "int", "(", "token", ")", "]", "+=", "1.0", "\n", "", "return", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.get_bm25_ids": [[237, 245], ["ids.append"], "function", ["None"], ["", "def", "get_bm25_ids", "(", "bm25", ",", "tokens", ")", ":", "\n", "\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "try", ":", "\n", "\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.is_float": [[24, 26], ["FLOAT_REGEXP.match"], "function", ["None"], ["def", "is_float", "(", "str", ")", ":", "\n", "\t", "return", "True", "if", "FLOAT_REGEXP", ".", "match", "(", "str", ")", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.replace_num": [[27, 35], ["convert_to_text_task1.is_float", "new_tokens.append", "new_tokens.append"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.is_float"], ["", "def", "replace_num", "(", "tokens", ")", ":", "\n", "\t", "new_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "if", "is_float", "(", "token", ")", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "\"<num>\"", ")", "\n", "", "else", ":", "\n", "\t\t\t", "new_tokens", ".", "append", "(", "token", ")", "\n", "", "", "return", "new_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.preprocess_token": [[36, 38], ["char.isalpha"], "function", ["None"], ["", "def", "preprocess_token", "(", "token", ")", ":", "\n", "\t", "return", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "token", "if", "char", ".", "isalpha", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.remove_punctuation_and_replace_num": [[39, 46], ["convert_to_text_task1.replace_num", "token.strip", "convert_to_text_task1.preprocess_token", "tokenizer.tokenize", "token.lower", "token.isupper"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.replace_num", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.convert_to_text_task1.preprocess_token"], ["", "def", "remove_punctuation_and_replace_num", "(", "doc", ")", ":", "\n", "\t", "doc_tokens", "=", "[", "token", ".", "strip", "(", "string", ".", "punctuation", ")", "for", "token", "in", "tokenizer", ".", "tokenize", "(", "doc", ")", "]", "\n", "doc_tokens", "=", "[", "token", "for", "token", "in", "doc_tokens", "if", "not", "token", ".", "isupper", "(", ")", "]", "\n", "#doc_tokens = [token for token in doc_tokens if not token in CAPS_REMOVE_LIST]", "\n", "doc_tokens", "=", "replace_num", "(", "doc_tokens", ")", "\n", "doc_tokens", "=", "[", "preprocess_token", "(", "token", ".", "lower", "(", ")", ")", "for", "token", "in", "doc_tokens", "]", "\n", "return", "\" \"", ".", "join", "(", "doc_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task1.perform_classification_test": [[38, 100], ["numpy.mean", "numpy.std", "sklearn.svm.SVC.fit", "sklearn.svm.SVC.predict", "sklearn.svm.SVC.predict_proba", "sklearn.metrics.accuracy_score", "val_acc.append", "val_pred_labels.append", "val_pred_probs.append", "sklearn.svm.SVC.predict_proba", "sklearn.svm.SVC.predict", "test_pred_labels_list.append", "test_pred_probs_list.append", "numpy.vstack", "numpy.vstack", "LogisticRegression", "sklearn.svm.SVC"], "function", ["None"], ["", "", "def", "perform_classification_test", "(", "train_data", ",", "val_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "\t", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_val", ",", "val_labels", "=", "val_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "\t\t", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "## Classification Accuracy", "\n", "", "val_acc", "=", "[", "]", "\n", "val_f1", "=", "[", "]", "\n", "\n", "val_pred_labels", "=", "[", "]", "\n", "val_pred_probs", "=", "[", "]", "\n", "\n", "test_pred_probs_list", "=", "[", "]", "\n", "test_pred_labels_list", "=", "[", "]", "\n", "\n", "best_acc", "=", "0.0", "\n", "clf", "=", "None", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "\t\t", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t\t", "clf", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#clf = SVC(C=c, kernel='precomputed')", "\n", "#clf = SVC(C=c)", "\n", "\t\t\t", "clf", "=", "SVC", "(", "C", "=", "c", ",", "probability", "=", "True", ",", "random_state", "=", "42", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_val_labels", "=", "clf", ".", "predict", "(", "docVectors_val", ")", "\n", "pred_val_probs", "=", "clf", ".", "predict_proba", "(", "docVectors_val", ")", "\n", "\n", "acc_val", "=", "accuracy_score", "(", "val_labels", ",", "pred_val_labels", ")", "\n", "#f1_test = precision_recall_fscore_support(test_labels, pred_test_labels, pos_label=None, average='macro')[2]", "\n", "\n", "if", "acc_val", ">", "best_acc", ":", "\n", "\t\t\t", "best_acc", "=", "acc_val", "\n", "best_clf", "=", "clf", "\n", "\n", "", "val_acc", ".", "append", "(", "acc_val", ")", "\n", "\n", "val_pred_labels", ".", "append", "(", "pred_val_labels", ")", "\n", "val_pred_probs", ".", "append", "(", "pred_val_probs", ")", "\n", "\n", "test_pred_probs", "=", "clf", ".", "predict_proba", "(", "docVectors_test", ")", "\n", "test_pred_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "\n", "test_pred_labels_list", ".", "append", "(", "test_pred_labels", ")", "\n", "test_pred_probs_list", ".", "append", "(", "test_pred_probs", ")", "\n", "\n", "", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "\t\t", "return", "test_acc", ",", "test_f1", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#return test_acc, test_f1, pred_test_probs", "\n", "#return test_acc, test_f1, test_pred_probs, test_pred_labels", "\n", "#return val_acc, val_f1, test_pred_probs, test_pred_labels", "\n", "\t\t", "return", "val_acc", ",", "val_f1", ",", "test_pred_probs_list", ",", "test_pred_labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task1.reload_evaluation_f1": [[102, 377], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "numpy.array", "SVM_task1.perform_classification_test", "zip", "os.path.exists", "os.makedirs", "open", "f.readlines", "open", "numpy.array", "numpy.array", "numpy.array", "enumerate", "numpy.array", "zip", "BM25.BM25", "id2label.values", "numpy.stack", "enumerate", "numpy.array", "zip", "numpy.argmax", "zip", "print", "zip", "numpy.concatenate", "numpy.zeros", "enumerate", "numpy.array", "zip", "numpy.argmax", "zip", "print", "zip", "zip", "int", "int", "int", "line.lower().strip().split", "queries.append", "line.strip", "np.array.append", "int", "dict_label[].append", "open", "dict_label.keys", "open", "csv.reader", "query.split.split", "BM25.BM25.BM25Score", "numpy.add", "bm25_extra_scores_list.append", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "codecs.open", "numpy.load", "prior_embedding_matrices.append", "numpy.load", "prior_embedding_matrices.append", "numpy.eye", "prior_embedding_matrices.append", "open", "csv.reader", "enumerate", "np.array.append", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "dict_label[].append", "open", "dict_label.keys", "data.Dataset.rows", "data.Dataset.rows", "data.Dataset.rows", "f.readlines", "numpy.unique", "f.write", "line[].strip", "doc.split.split", "SVM_task1.reload_evaluation_f1.get_bm25_ids"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.BM25_task2.BM25.BM25Score", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task2.get_bm25_ids"], ["", "", "def", "reload_evaluation_f1", "(", "params", ",", "training_vectors", ",", "validation_vectors", ",", "test_vectors", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Classification - F1", "\n", "\n", "\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "#c_list = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]", "\n", "#c_list = [1.0, 3.0, 5.0, 10.0, 100.0, 500.0, 1000.0, 10000.0]", "\n", "#c_list = [0.05, 0.5]", "\n", "#c_list = [0.001, 0.01, 0.1, 10.0]", "\n", "", "c_list", "=", "[", "0.01", "]", "\n", "\n", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "val_acc", "=", "[", "]", "\n", "val_f1", "=", "[", "]", "\n", "\n", "test_acc_W", "=", "[", "]", "\n", "test_f1_W", "=", "[", "]", "\n", "val_acc_W", "=", "[", "]", "\n", "val_f1_W", "=", "[", "]", "\n", "\n", "y_train", "=", "np", ".", "array", "(", "\n", "[", "int", "(", "y", ")", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "y_val", "=", "np", ".", "array", "(", "\n", "[", "int", "(", "y", ")", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'validation_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "y_test", "=", "np", ".", "array", "(", "\n", "[", "int", "(", "y", ")", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "queries", "=", "[", "]", "\n", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/labels.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "\t\t\t", "label_tokens", "=", "line", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "\"_\"", ")", "\n", "label_tokens", "=", "[", "token", "for", "token", "in", "label_tokens", "if", "token", "]", "\n", "query", "=", "\" \"", ".", "join", "(", "label_tokens", ")", "\n", "queries", ".", "append", "(", "query", ")", "\n", "\n", "", "", "with", "open", "(", "params", "[", "'dataset'", "]", "+", "\"/test_ids.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t", "ids", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "#id2label = {0:\"Arousal\", 1:\"Circadian_Rhythms\", 2:\"Acute_Threat_Fear\", 3:\"Loss\", 4:\"Sleep_Wakefulness\", 5:\"Frustrative_Nonreward\", 6:\"Potential_Threat_Anxiety\", 7:\"Sustained_Threat\"}", "\n", "", "id2label", "=", "{", "0", ":", "\"Acute_Threat_Fear\"", ",", "1", ":", "\"Arousal\"", ",", "2", ":", "\"Circadian_Rhythms\"", ",", "3", ":", "\"Frustrative_Nonreward\"", ",", "\n", "4", ":", "\"Loss\"", ",", "5", ":", "\"Potential_Threat_Anxiety\"", ",", "6", ":", "\"Sleep_Wakefulness\"", ",", "7", ":", "\"Sustained_Threat\"", "}", "\n", "\n", "train_data", "=", "(", "training_vectors", ",", "np", ".", "array", "(", "y_train", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "validation_data", "=", "(", "validation_vectors", ",", "np", ".", "array", "(", "y_val", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "test_data", "=", "(", "test_vectors", ",", "np", ".", "array", "(", "y_test", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "#test_acc, test_f1 = perform_classification_test(train_data, test_data, c_list, classification_model=\"svm\", norm_before_classification=False)", "\n", "test_acc", ",", "test_f1", ",", "pred_probs_list", ",", "pred_labels_list", "=", "perform_classification_test", "(", "train_data", ",", "validation_data", ",", "\n", "test_data", ",", "c_list", ",", "classification_model", "=", "\"svm\"", ",", "norm_before_classification", "=", "False", ")", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "#try:", "\n", "for", "c", ",", "pred_probs", "in", "zip", "(", "c_list", ",", "pred_probs_list", ")", ":", "\n", "\t\t", "relevance_score_svm", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y_test", ")", ":", "\n", "\t\t\t", "relevance_score_svm", ".", "append", "(", "pred_probs", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_svm", "=", "np", ".", "array", "(", "relevance_score_svm", ")", "\n", "#except:", "\n", "#\timport pdb; pdb.set_trace()", "\n", "\n", "dict_label", "=", "{", "int", "(", "label", ")", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_svm", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "int", "(", "label", ")", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_svm_classify\"", "+", "str", "(", "c", ")", "+", "\".txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "#sys.exit()", "\n", "", "", "", "", "if", "evaluate_on_test", ":", "\n", "## Using BM25 Extra for relevance ranking and mAP calculation", "\n", "\n", "\t\t", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "docs", "=", "[", "line", "[", "1", "]", ".", "strip", "(", ")", "for", "line", "in", "file_reader", "]", "\n", "\n", "", "bm25", "=", "BM25", ".", "BM25", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "delimiter", "=", "' '", ")", "\n", "\n", "def", "get_bm25_ids", "(", "tokens", ")", ":", "\n", "\t\t\t", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t\t\t", "try", ":", "\n", "\t\t\t\t\t", "ids", ".", "append", "(", "bm25", ".", "dictionary", ".", "token2id", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "\t\t\t\t\t", "pass", "\n", "", "", "return", "ids", "\n", "\n", "", "bm25_extra_scores_list", "=", "[", "]", "\n", "#for query in queries:", "\n", "for", "value", "in", "id2label", ".", "values", "(", ")", ":", "\n", "\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query", "=", "query", ".", "split", "(", ")", "\n", "scores", "=", "bm25", ".", "BM25Score", "(", "query", ")", "\n", "\n", "extra_features", "=", "[", "]", "\n", "for", "doc", "in", "docs", ":", "\n", "\t\t\t\t", "doc", "=", "doc", ".", "split", "(", ")", "\n", "#doc_ids = [bm25.dictionary.token2id[token] for token in doc]", "\n", "#query_ids = [bm25.dictionary.token2id[token] for token in query]", "\n", "doc_ids", "=", "get_bm25_ids", "(", "doc", ")", "\n", "query_ids", "=", "get_bm25_ids", "(", "query", ")", "\n", "\n", "feats", "=", "bm25", ".", "query_doc_overlap", "(", "query_ids", ",", "doc_ids", ")", "\n", "extra_features", ".", "append", "(", "np", ".", "sum", "(", "feats", ")", ")", "\n", "#scores = np.stack([np.array(scores), np.array(extra_features)], axis=1)", "\n", "", "scores", "=", "np", ".", "add", "(", "np", ".", "array", "(", "scores", ")", ",", "np", ".", "array", "(", "extra_features", ")", ")", "\n", "\n", "bm25_extra_scores_list", ".", "append", "(", "scores", ")", "\n", "\n", "", "bm25_extra_scores_matrix", "=", "np", ".", "stack", "(", "bm25_extra_scores_list", ",", "axis", "=", "1", ")", "\n", "#import pdb; pdb.set_trace()", "\n", "relevance_score_bm25_extra", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y_test", ")", ":", "\n", "\t\t\t", "relevance_score_bm25_extra", ".", "append", "(", "bm25_extra_scores_matrix", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_bm25_extra", "=", "np", ".", "array", "(", "relevance_score_bm25_extra", ")", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_bm25_extra", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_bm25extra.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "#combined_relevance_score = relevance_score_svm + relevance_score_bm25_extra", "\n", "", "", "", "pseudo_prediction", "=", "np", ".", "argmax", "(", "pred_probs_list", "[", "0", "]", ",", "axis", "=", "1", ")", "\n", "combined_relevance_score", "=", "[", "]", "\n", "counter", "=", "0", "\n", "for", "svm_pred", ",", "bm25_score", ",", "svm_score", ",", "true_label", "in", "zip", "(", "pseudo_prediction", ",", "relevance_score_bm25_extra", ",", "relevance_score_svm", ",", "y_test", ")", ":", "\n", "#for svm_pred, bm25_score, svm_score, true_label in zip(pred_labels_list[0], relevance_score_bm25_extra, relevance_score_svm, y_test):", "\n", "#import pdb; pdb.set_trace()", "\n", "\t\t\t", "if", "true_label", "==", "svm_pred", ":", "\n", "\t\t\t\t", "combined_relevance_score", ".", "append", "(", "svm_score", "+", "bm25_score", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "combined_relevance_score", ".", "append", "(", "svm_score", ")", "\n", "", "", "print", "(", "counter", ")", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_svm_classify_with_bm25extra.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "with", "codecs", ".", "open", "(", "\"./pretrained_embeddings/biggest_vocab.vocab\"", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "\t\t\t", "total_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "prior_embedding_matrices", "=", "[", "]", "\n", "\n", "if", "params", "[", "'use_bio_prior'", "]", ":", "\n", "#bio_embeddings_large = np.load('./pretrained_embeddings/bionlp_embeddings_biggest_vocab.npy')", "\n", "\t\t\t", "bio_embeddings_large", "=", "np", ".", "load", "(", "'./pretrained_embeddings/'", "+", "params", "[", "'bioemb_path'", "]", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "bio_embeddings_large", ")", "\n", "\n", "", "if", "params", "[", "'use_fasttext_prior'", "]", ":", "\n", "#fasttext_embeddings_large = np.load('./pretrained_embeddings/fasttext_embeddings_biggest_vocab.npy')", "\n", "\t\t\t", "fasttext_embeddings_large", "=", "np", ".", "load", "(", "'./pretrained_embeddings/'", "+", "params", "[", "'fttemb_path'", "]", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "fasttext_embeddings_large", ")", "\n", "\n", "", "if", "params", "[", "'use_BOW_repesentation'", "]", ":", "\n", "\t\t\t", "BOW_representations", "=", "np", ".", "eye", "(", "len", "(", "total_vocab", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "prior_embedding_matrices", ".", "append", "(", "BOW_representations", ")", "\n", "\n", "", "total_embedding_matrix", "=", "np", ".", "concatenate", "(", "prior_embedding_matrices", ",", "axis", "=", "1", ")", "\n", "\n", "similarity_scores_Attention_Based_EmbSum", "=", "np", ".", "zeros", "(", "(", "len", "(", "y_test", ")", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "with", "open", "(", "\"./datasets/Task1_and_Task2_without_acronym_with_Task1_testdata_OOV_words/test.csv\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "\t\t\t", "file_reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "file_reader", ")", ":", "\n", "\t\t\t\t", "tokens", "=", "[", "total_vocab", ".", "index", "(", "word", ")", "for", "word", "in", "row", "[", "1", "]", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "Embs", "=", "total_embedding_matrix", "[", "np", ".", "array", "(", "tokens", ")", ",", ":", "]", "\n", "#for i, query in enumerate(queries):", "\n", "for", "k", ",", "value", "in", "enumerate", "(", "id2label", ".", "values", "(", ")", ")", ":", "\n", "\t\t\t\t\t", "query", "=", "\" \"", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "split", "(", "\"_\"", ")", ")", ".", "strip", "(", ")", "\n", "if", "query", "==", "\"frustrative nonreward\"", ":", "\n", "\t\t\t\t\t\t", "query", "=", "\"reward aggression\"", "\n", "", "if", "query", "==", "\"arousal\"", ":", "\n", "\t\t\t\t\t\t", "query", "+=", "\" affective states heart rate\"", "\n", "", "query_tokens", "=", "query", ".", "split", "(", ")", "\n", "EmbSum_attns", "=", "[", "]", "\n", "query_vecs_attns", "=", "[", "]", "\n", "for", "qword", "in", "query_tokens", ":", "\n", "\t\t\t\t\t\t", "query_vector", "=", "total_embedding_matrix", "[", "total_vocab", ".", "index", "(", "qword", ")", ",", ":", "]", "\n", "query_vector", "=", "np", ".", "expand_dims", "(", "query_vector", ",", "axis", "=", "0", ")", "\n", "query_attentions", "=", "pw", ".", "cosine_similarity", "(", "query_vector", ",", "Embs", ")", "\n", "#query_attentions[(query_attentions < 0.5)] = 0.0", "\n", "query_attentions", "=", "softmax", "(", "query_attentions", ")", "\n", "EmbSum_attentions", "=", "np", ".", "dot", "(", "query_attentions", ",", "Embs", ")", "\n", "EmbSum_attns", ".", "append", "(", "EmbSum_attentions", ")", "\n", "query_vecs_attns", ".", "append", "(", "query_vector", ")", "\n", "", "EmbSum", "=", "np", ".", "sum", "(", "EmbSum_attns", ",", "axis", "=", "0", ")", "\n", "#query_EmbSum_vector = np.expand_dims(query_vecs[i], axis=0)", "\n", "query_EmbSum_vector", "=", "np", ".", "sum", "(", "query_vecs_attns", ",", "axis", "=", "0", ")", "\n", "similarity_score", "=", "pw", ".", "cosine_similarity", "(", "query_EmbSum_vector", ",", "EmbSum", ")", "\n", "similarity_scores_Attention_Based_EmbSum", "[", "j", ",", "k", "]", "=", "similarity_score", "[", "0", "]", "[", "0", "]", "\n", "\n", "", "", "", "relevance_score_att_embsum", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "y_test", ")", ":", "\n", "\t\t\t", "relevance_score_att_embsum", ".", "append", "(", "similarity_scores_Attention_Based_EmbSum", "[", "i", ",", "int", "(", "label", ")", "]", ")", "\n", "", "relevance_score_att_embsum", "=", "np", ".", "array", "(", "relevance_score_att_embsum", ")", "\n", "\n", "#combined_relevance_score = relevance_score_svm + relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "relevance_score_att_embsum", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_att_based_embsum.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "#combined_relevance_score_classify_embsum = relevance_score_att_embsum + relevance_score_svm", "\n", "", "", "", "pseudo_prediction", "=", "np", ".", "argmax", "(", "pred_probs_list", "[", "0", "]", ",", "axis", "=", "1", ")", "\n", "combined_relevance_score_classify_embsum", "=", "[", "]", "\n", "#positive_half_scores = []", "\n", "#negative_half_scores = []", "\n", "counter", "=", "0", "\n", "for", "svm_pred", ",", "att_score", ",", "svm_score", ",", "true_label", "in", "zip", "(", "pseudo_prediction", ",", "relevance_score_att_embsum", ",", "relevance_score_svm", ",", "y_test", ")", ":", "\n", "#for svm_pred, att_score, svm_score, true_label in zip(pred_labels_list[0], relevance_score_bm25_extra, relevance_score_svm, y_test):", "\n", "#import pdb; pdb.set_trace()", "\n", "\t\t\t", "if", "true_label", "==", "svm_pred", ":", "\n", "\t\t\t\t", "combined_relevance_score_classify_embsum", ".", "append", "(", "svm_score", "+", "att_score", ")", "\n", "#positive_half_scores.append()", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "combined_relevance_score_classify_embsum", ".", "append", "(", "svm_score", ")", "\n", "", "", "print", "(", "counter", ")", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_classify_att_based_embsum.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "combined_relevance_score_classify_embsum_bm25extra", "=", "relevance_score_att_embsum", "+", "relevance_score_svm", "+", "relevance_score_bm25_extra", "\n", "\n", "dict_label", "=", "{", "label", ":", "[", "]", "for", "label", "in", "np", ".", "unique", "(", "y_test", ")", "}", "\n", "for", "score", ",", "id", ",", "label", "in", "zip", "(", "combined_relevance_score_classify_embsum_bm25extra", ",", "ids", ",", "y_test", ")", ":", "\n", "\t\t\t", "dict_label", "[", "label", "]", ".", "append", "(", "[", "id", ",", "score", "]", ")", "\n", "\n", "", "with", "open", "(", "\"task1_test_classify_att_based_embsum_bm25extra.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "\t\t\t", "for", "key", "in", "dict_label", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "id2label", "[", "int", "(", "key", ")", "]", "+", "\"\\n\"", ")", "\n", "for", "id", ",", "score", "in", "dict_label", "[", "key", "]", ":", "\n", "\t\t\t\t\t", "f", ".", "write", "(", "id", "+", "\"\\t\"", "+", "str", "(", "score", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.SVM_task1.BOW_representation": [[379, 384], ["numpy.zeros", "int"], "function", ["None"], ["", "", "", "", "", "def", "BOW_representation", "(", "tokens", ",", "vocab_size", ")", ":", "\n", "\t", "vec", "=", "np", ".", "zeros", "(", "vocab_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "\t\t", "vec", "[", "int", "(", "token", ")", "]", "+=", "1.0", "\n", "", "return", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.Embsum.loadGloveModel": [[32, 56], ["print", "open", "print", "line.split", "numpy.array", "len", "os.path.join", "os.path.join", "float", "os.path.join", "os.path.join", "print", "exit"], "function", ["None"], ["", "", "def", "loadGloveModel", "(", "gloveFile", "=", "None", ",", "hidden_size", "=", "None", ")", ":", "\n", "    ", "if", "gloveFile", "is", "None", ":", "\n", "        ", "if", "hidden_size", "==", "50", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.50d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "100", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.100d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "200", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.200d.txt\"", ")", "\n", "", "elif", "hidden_size", "==", "300", ":", "\n", "            ", "gloveFile", "=", "os", ".", "path", ".", "join", "(", "home_dir", ",", "\"resources/pretrained_embeddings/glove.6B.300d.txt\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Invalid dimension [%d] for Glove pretrained embedding matrix!!'", "%", "params", ".", "hidden_size", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "print", "(", "\"Loading Glove Model\"", ")", "\n", "f", "=", "open", "(", "gloveFile", ",", "'r'", ")", "\n", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "        ", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.Embsum.reload_evaluation_f1": [[58, 132], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "numpy.array", "os.path.exists", "os.makedirs", "model.perform_classification_test", "total_labels.extend", "MultiLabelBinarizer", "MultiLabelBinarizer.fit", "MultiLabelBinarizer.transform", "MultiLabelBinarizer.transform", "MultiLabelBinarizer.transform", "model.perform_classification_test_multi", "numpy.array", "numpy.array", "numpy.array", "open", "f.write", "open", "f.write", "label.strip().split", "label.strip().split", "label.strip().split", "open", "f.write", "open", "f.write", "data.Dataset.rows", "data.Dataset.rows", "data.Dataset.rows", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "label.strip", "label.strip", "label.strip"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test_multi", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows"], ["", "def", "reload_evaluation_f1", "(", "params", ",", "training_vectors", ",", "validation_vectors", ",", "test_vectors", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Classification - F1", "\n", "\n", "    ", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "", "c_list", "=", "[", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1", ",", "0.5", ",", "1.0", ",", "3.0", ",", "5.0", ",", "10.0", ",", "100.0", ",", "500.0", ",", "1000.0", ",", "10000.0", "]", "\n", "#c_list = [1.0]", "\n", "\n", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "val_acc", "=", "[", "]", "\n", "val_f1", "=", "[", "]", "\n", "\n", "test_acc_W", "=", "[", "]", "\n", "test_f1_W", "=", "[", "]", "\n", "val_acc_W", "=", "[", "]", "\n", "val_f1_W", "=", "[", "]", "\n", "\n", "y_train", "=", "np", ".", "array", "(", "\n", "[", "y", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "y_val", "=", "np", ".", "array", "(", "\n", "[", "y", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'validation_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "y_test", "=", "np", ".", "array", "(", "\n", "[", "y", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "if", "not", "params", "[", "'multi_label'", "]", ":", "\n", "        ", "train_data", "=", "(", "training_vectors", ",", "np", ".", "array", "(", "y_train", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "validation_data", "=", "(", "validation_vectors", ",", "np", ".", "array", "(", "y_val", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "test_data", "=", "(", "test_vectors", ",", "np", ".", "array", "(", "y_test", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n", "test_acc", ",", "test_f1", "=", "eval", ".", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\\n\\nTest accuracy with h vector IR: %s\"", "%", "(", "test_acc", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\\n\\nTest F1 score with h vector IR: %s\"", "%", "(", "test_f1", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "total_labels", "=", "[", "]", "\n", "\n", "y_train_new", "=", "[", "label", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "for", "label", "in", "y_train", "]", "\n", "y_val_new", "=", "[", "label", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "for", "label", "in", "y_val", "]", "\n", "y_test_new", "=", "[", "label", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "for", "label", "in", "y_test", "]", "\n", "\n", "total_labels", ".", "extend", "(", "y_train_new", ")", "\n", "#total_labels.extend(y_val_new)", "\n", "#total_labels.extend(y_test_new)", "\n", "\n", "from", "sklearn", ".", "preprocessing", "import", "MultiLabelBinarizer", "\n", "mlb", "=", "MultiLabelBinarizer", "(", ")", "\n", "mlb", ".", "fit", "(", "total_labels", ")", "\n", "y_train_one_hot", "=", "mlb", ".", "transform", "(", "y_train_new", ")", "\n", "y_val_one_hot", "=", "mlb", ".", "transform", "(", "y_val_new", ")", "\n", "y_test_one_hot", "=", "mlb", ".", "transform", "(", "y_test_new", ")", "\n", "\n", "train_data", "=", "(", "training_vectors", ",", "y_train_one_hot", ")", "\n", "validation_data", "=", "(", "validation_vectors", ",", "y_val_one_hot", ")", "\n", "test_data", "=", "(", "test_vectors", ",", "y_test_one_hot", ")", "\n", "\n", "test_acc", ",", "test_f1", "=", "eval", ".", "perform_classification_test_multi", "(", "train_data", ",", "test_data", ",", "c_list", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\\n\\nTest accuracy with h vector IR: %s\"", "%", "(", "test_acc", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"\\n\\nTest F1 score with h vector IR: %s\"", "%", "(", "test_f1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.Embsum.reload_evaluation_ir": [[134, 168], ["model.Dataset", "os.path.join", "numpy.array", "numpy.array", "model.evaluate", "os.path.exists", "os.makedirs", "open", "f.write", "f.write", "os.path.join", "data.Dataset.rows", "data.Dataset.rows"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows"], ["", "", "", "def", "reload_evaluation_ir", "(", "params", ",", "training_vectors", ",", "validation_vectors", ",", "test_vectors", ",", "suffix", "=", "\"\"", ")", ":", "\n", "\n", "### Information Retrieval", "\n", "\n", "\t", "dataset", "=", "data", ".", "Dataset", "(", "params", "[", "'dataset'", "]", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model'", "]", ",", "'logs'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "", "ir_ratio_list", "=", "[", "0.0001", ",", "0.0005", ",", "0.001", ",", "0.002", ",", "0.005", ",", "0.01", ",", "0.02", ",", "0.05", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.5", ",", "0.8", ",", "1.0", "]", "\n", "#ir_ratio_list = [0.02]", "\n", "\n", "training_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'training_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "test_labels", "=", "np", ".", "array", "(", "\n", "[", "[", "y", "]", "for", "y", ",", "_", "in", "dataset", ".", "rows", "(", "'test_docnade'", ",", "num_epochs", "=", "1", ")", "]", "\n", ")", "\n", "\n", "test_ir_list", "=", "eval", ".", "evaluate", "(", "\n", "training_vectors", ",", "\n", "test_vectors", ",", "\n", "training_labels", ",", "\n", "test_labels", ",", "\n", "recall", "=", "ir_ratio_list", ",", "\n", "num_classes", "=", "params", "[", "'num_classes'", "]", ",", "\n", "multi_label", "=", "params", "[", "'multi_label'", "]", "\n", ")", "\n", "\n", "# logging information", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"reload_info_ir.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "\t\t", "f", ".", "write", "(", "\"\\n\\nFractions list: %s\"", "%", "(", "ir_ratio_list", ")", ")", "\n", "f", ".", "write", "(", "\"\\nTest IR: %s\"", "%", "(", "test_ir_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.DocNADE.__init__": [[149, 532], ["tensorflow.shape", "tensorflow.scan", "tensorflow.transpose", "tensorflow.concat", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.reshape", "model_DocNADE.linear", "model_DocNADE.masked_sequence_cross_entropy_loss", "tensorflow.Variable", "model_DocNADE.gradients", "tensorflow.shape", "tensorflow.device", "tensorflow.nn.embedding_lookup", "tensorflow.get_variable", "tensorflow.transpose", "tensorflow.sigmoid", "tensorflow.scan", "tensorflow.transpose", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.argmax", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.zeros", "tensorflow.tanh", "tensorflow.range", "tensorflow.to_int32", "tensorflow.get_variable", "tensorflow.sigmoid", "tensorflow.multiply", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.transpose", "tensorflow.scan", "tensorflow.transpose", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.train.AdamOptimizer", "tensorflow.trainable_variables", "tensorflow.constant_initializer", "tensorflow.nn.relu", "print", "exit", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.nn.embedding_lookup", "tensorflow.multiply", "tensorflow.nn.embedding_lookup", "tensorflow.scan", "tensorflow.transpose", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.nn.embedding_lookup", "tensorflow.range", "tensorflow.transpose", "tensorflow.sigmoid", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.random_uniform_initializer", "print", "sys.exit", "tensorflow.transpose", "tensorflow.sigmoid", "tensorflow.to_int32", "tensorflow.range", "tensorflow.sigmoid", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.nn.xw_plus_b", "tensorflow.tanh", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.nn.l2_loss", "tensorflow.random_uniform_initializer", "tensorflow.constant_initializer", "tensorflow.range", "tensorflow.tanh", "tensorflow.to_int32", "tensorflow.tanh", "tensorflow.nn.xw_plus_b", "tensorflow.nn.relu", "print", "exit", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.to_int32", "tensorflow.nn.relu", "print", "exit", "tensorflow.nn.relu", "print", "exit", "tensorflow.nn.xw_plus_b"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.linear", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.masked_sequence_cross_entropy_loss", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.gradients"], ["    ", "def", "__init__", "(", "self", ",", "x", ",", "y", ",", "seq_lengths", ",", "params", ",", "\n", "W_pretrained", "=", "None", ",", "U_pretrained", "=", "None", ",", "\n", "glove_embeddings", "=", "None", ",", "lambda_glove", "=", "0.0", ",", "\n", "l2_reg_c", "=", "1.0", ",", "prior_emb_dim", "=", "0", ",", "\n", "x_title", "=", "None", ",", "seq_lengths_title", "=", "None", ")", ":", "\n", "        ", "self", ".", "x", "=", "x", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "seq_lengths", "=", "seq_lengths", "\n", "\n", "self", ".", "x_title", "=", "x_title", "\n", "self", ".", "seq_lengths_title", "=", "seq_lengths_title", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "self", ".", "b_s", "=", "tf", ".", "shape", "(", "x", ")", "\n", "self", ".", "lambda_glove", "=", "lambda_glove", "\n", "\n", "# Do an embedding lookup for each word in each sequence", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "if", "W_pretrained", "is", "None", ":", "\n", "                ", "max_embed_init", "=", "1.0", "/", "(", "params", ".", "vocab_size", "*", "params", ".", "hidden_size", ")", "\n", "W", "=", "tf", ".", "get_variable", "(", "\n", "'embedding'", ",", "\n", "[", "params", ".", "vocab_size", ",", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_embed_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "W", "=", "tf", ".", "get_variable", "(", "\n", "'embedding'", ",", "\n", "initializer", "=", "W_pretrained", "\n", ")", "\n", "\n", "", "self", ".", "embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W", ",", "x", ")", "\n", "\n", "if", "not", "glove_embeddings", "is", "None", ":", "\n", "                ", "glove_prior", "=", "tf", ".", "get_variable", "(", "\n", "'glove_prior'", ",", "\n", "initializer", "=", "glove_embeddings", ",", "\n", "trainable", "=", "False", "\n", ")", "\n", "\"\"\"\n                self.embeddings_prior = tf.nn.embedding_lookup(glove_prior, x)\n                \n                if params.run_docnade:\n                    # Lambda multiplication\n                    if not self.lambda_glove < 0.0:\n                        self.embeddings_prior = tf.scalar_mul(self.lambda_glove, self.embeddings_prior)\n                    \n                    self.embeddings = tf.add(self.embeddings, self.embeddings_prior)\n                \"\"\"", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "\n", "'bias'", ",", "\n", "[", "params", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", "\n", ")", "\n", "\n", "# Compute the hidden layer inputs: each gets summed embeddings of", "\n", "# previous words", "\n", "", "def", "sum_embeddings", "(", "previous", ",", "current", ")", ":", "\n", "            ", "return", "previous", "+", "current", "\n", "\n", "", "h", "=", "tf", ".", "scan", "(", "sum_embeddings", ",", "tf", ".", "transpose", "(", "self", ".", "embeddings", ",", "[", "1", ",", "2", ",", "0", "]", ")", ")", "\n", "h", "=", "tf", ".", "transpose", "(", "h", ",", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "\n", "h", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "zeros", "(", "[", "batch_size", ",", "1", ",", "params", ".", "hidden_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "h", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "pre_act", "=", "h", "\n", "\n", "# Apply activation", "\n", "if", "params", ".", "activation", "==", "'sigmoid'", ":", "\n", "            ", "h", "=", "tf", ".", "sigmoid", "(", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'tanh'", ":", "\n", "            ", "h", "=", "tf", ".", "tanh", "(", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'relu'", ":", "\n", "            ", "h", "=", "tf", ".", "nn", ".", "relu", "(", "h", "+", "bias", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Invalid value for activation: %s'", "%", "(", "params", ".", "activation", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "self", ".", "aft_act", "=", "h", "\n", "\n", "# Extract final state for each sequence in the batch", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "range", "(", "batch_size", ")", ",", "\n", "tf", ".", "to_int32", "(", "seq_lengths", ")", "\n", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "indices", "=", "indices", "\n", "\n", "#if not params.run_supervised:", "\n", "#    self.h = tf.gather_nd(h, indices, name='last_hidden')", "\n", "self", ".", "h", "=", "tf", ".", "gather_nd", "(", "h", ",", "indices", ",", "name", "=", "'last_hidden'", ")", "\n", "\n", "h", "=", "h", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "h", "=", "tf", ".", "reshape", "(", "h", ",", "[", "-", "1", ",", "params", ".", "hidden_size", "]", ")", "\n", "\n", "################################# SUPERVISED NETWORK ###################################", "\n", "\n", "if", "params", ".", "run_supervised", ":", "\n", "\n", "            ", "if", "params", ".", "run_docnade", "and", "(", "not", "glove_embeddings", "is", "None", ")", ":", "\n", "#sup_matrix = tf.add(W, glove_prior, name='add_embeddings')", "\n", "#sup_matrix = tf.concat([W, glove_prior], axis=1, name='concat_embeddings')", "\n", "#sup_input_size = params.hidden_size", "\n", "#sup_input_size = params.hidden_size + prior_emb_dim", "\n", "                ", "sup_matrix", "=", "glove_prior", "\n", "sup_input_size", "=", "prior_emb_dim", "\n", "", "elif", "(", "not", "params", ".", "run_docnade", ")", "and", "(", "not", "glove_embeddings", "is", "None", ")", ":", "\n", "                ", "sup_matrix", "=", "glove_prior", "\n", "sup_input_size", "=", "prior_emb_dim", "\n", "", "elif", "(", "glove_embeddings", "is", "None", ")", ":", "\n", "                ", "sup_matrix", "=", "W", "\n", "sup_input_size", "=", "params", ".", "hidden_size", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Wrong combination of params.run_docnade and glove_prior.\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "#sup_input_size = tf.shape(sup_matrix)[1]", "\n", "\n", "", "if", "params", ".", "weighted_supervised", ":", "\n", "                ", "max_embed_init", "=", "1.0", "/", "(", "params", ".", "vocab_size", ")", "\n", "\n", "if", "params", ".", "sup_weight_init", "<", "0.0", ":", "\n", "                    ", "weight_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_embed_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "weight_initializer", "=", "tf", ".", "constant_initializer", "(", "params", ".", "sup_weight_init", ")", "\n", "\n", "", "embeddings_lambda_list", "=", "tf", ".", "get_variable", "(", "\n", "'embeddings_lambda_list_unclipped'", ",", "\n", "[", "params", ".", "vocab_size", ",", "1", "]", ",", "\n", "initializer", "=", "weight_initializer", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "#self.embeddings_lambda_list = tf.clip_by_value(embeddings_lambda_list, 0.0, 1.0, name='embeddings_lambda_list')", "\n", "self", ".", "embeddings_lambda_list", "=", "tf", ".", "sigmoid", "(", "embeddings_lambda_list", ",", "name", "=", "'embeddings_lambda_list'", ")", "\n", "\n", "sup_matrix_weighted", "=", "tf", ".", "multiply", "(", "sup_matrix", ",", "self", ".", "embeddings_lambda_list", ")", "\n", "\n", "self", ".", "weighted_sup_lookup", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "sup_matrix_weighted", ",", "x", ")", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "                    ", "self", ".", "weighted_sup_title_lookup", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "sup_matrix_weighted", ",", "x_title", ")", "\n", "\n", "", "if", "params", ".", "run_docnade", ":", "\n", "                    ", "W_weighted", "=", "tf", ".", "multiply", "(", "W", ",", "self", ".", "embeddings_lambda_list", ")", "\n", "self", ".", "weighted_embeddings", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_weighted", ",", "x", ")", "\n", "\n", "weighted_h_docnade", "=", "tf", ".", "scan", "(", "sum_embeddings", ",", "tf", ".", "transpose", "(", "self", ".", "weighted_embeddings", ",", "[", "1", ",", "2", ",", "0", "]", ")", ")", "\n", "weighted_h_docnade", "=", "tf", ".", "transpose", "(", "weighted_h_docnade", ",", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "\n", "weighted_embeddings_indices", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "range", "(", "batch_size", ")", ",", "\n", "tf", ".", "to_int32", "(", "seq_lengths", ")", "-", "1", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "h", "=", "tf", ".", "gather_nd", "(", "weighted_h_docnade", ",", "weighted_embeddings_indices", ",", "name", "=", "'last_hidden'", ")", "\n", "\n", "# Apply activation", "\n", "if", "params", ".", "activation", "==", "'sigmoid'", ":", "\n", "                        ", "self", ".", "h", "=", "tf", ".", "sigmoid", "(", "self", ".", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'tanh'", ":", "\n", "                        ", "self", ".", "h", "=", "tf", ".", "tanh", "(", "self", ".", "h", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'relu'", ":", "\n", "                        ", "self", ".", "h", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "h", "+", "bias", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'Invalid value for activation: %s'", "%", "(", "params", ".", "activation", ")", ")", "\n", "exit", "(", ")", "\n", "", "", "", "else", ":", "\n", "                ", "self", ".", "weighted_sup_lookup", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "sup_matrix", ",", "x", ")", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "                    ", "self", ".", "weighted_sup_title_lookup", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "sup_matrix", ",", "x_title", ")", "\n", "\n", "", "", "weighted_h", "=", "tf", ".", "scan", "(", "sum_embeddings", ",", "tf", ".", "transpose", "(", "self", ".", "weighted_sup_lookup", ",", "[", "1", ",", "2", ",", "0", "]", ")", ")", "\n", "weighted_h", "=", "tf", ".", "transpose", "(", "weighted_h", ",", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "\n", "#weighted_h = tf.concat([", "\n", "#    #tf.zeros([batch_size, 1, params.hidden_size], dtype=tf.float32), weighted_h", "\n", "#    tf.zeros([batch_size, 1, sup_input_size], dtype=tf.float32), weighted_h", "\n", "#], axis=1)", "\n", "\n", "sup_indices", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "range", "(", "batch_size", ")", ",", "\n", "tf", ".", "to_int32", "(", "seq_lengths", ")", "-", "1", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "h_sup", "=", "tf", ".", "gather_nd", "(", "weighted_h", ",", "sup_indices", ",", "name", "=", "'sup_input_hidden'", ")", "\n", "\n", "\"\"\"\n            if params.run_docnade:\n                # Apply activation\n                if params.activation == 'sigmoid':\n                    #self.h = tf.sigmoid(self.h + bias)\n                    self.h = tf.sigmoid(self.h)\n                elif params.activation == 'tanh':\n                    #self.h = tf.tanh(self.h + bias)\n                    self.h = tf.tanh(self.h)\n                elif params.activation == 'relu':\n                    #self.h = tf.nn.relu(self.h + bias)\n                    self.h = tf.nn.relu(self.h)\n                else:\n                    print('Invalid value for activation: %s' % (params.activation))\n                    exit()    \n            \"\"\"", "\n", "\n", "if", "params", ".", "use_title_separately", ":", "\n", "                ", "weighted_title_h", "=", "tf", ".", "scan", "(", "sum_embeddings", ",", "tf", ".", "transpose", "(", "self", ".", "weighted_sup_title_lookup", ",", "[", "1", ",", "2", ",", "0", "]", ")", ")", "\n", "weighted_title_h", "=", "tf", ".", "transpose", "(", "weighted_title_h", ",", "[", "2", ",", "0", ",", "1", "]", ")", "\n", "\n", "sup_indices_title", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "range", "(", "batch_size", ")", ",", "\n", "tf", ".", "to_int32", "(", "seq_lengths_title", ")", "-", "1", "\n", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "h_title", "=", "tf", ".", "gather_nd", "(", "weighted_title_h", ",", "sup_indices_title", ",", "name", "=", "'last_hidden_title'", ")", "\n", "\n", "if", "params", ".", "run_docnade", ":", "\n", "# Apply activation", "\n", "                    ", "if", "params", ".", "activation", "==", "'sigmoid'", ":", "\n", "                        ", "self", ".", "h_title", "=", "tf", ".", "sigmoid", "(", "self", ".", "h_title", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'tanh'", ":", "\n", "                        ", "self", ".", "h_title", "=", "tf", ".", "tanh", "(", "self", ".", "h_title", "+", "bias", ")", "\n", "", "elif", "params", ".", "activation", "==", "'relu'", ":", "\n", "                        ", "self", ".", "h_title", "=", "tf", ".", "nn", ".", "relu", "(", "self", ".", "h_title", "+", "bias", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'Invalid value for activation: %s'", "%", "(", "params", ".", "activation", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "self", ".", "h", "=", "tf", ".", "concat", "(", "[", "\n", "self", ".", "h_title", ",", "self", ".", "h", "\n", "]", ",", "axis", "=", "1", ",", "name", "=", "'last_hidden_comb'", ")", "\n", "\n", "sup_input_size", "=", "2", "*", "sup_input_size", "\n", "\n", "#self.disc_h = self.weighted_h", "\n", "\n", "", "if", "params", ".", "sup_projection", ":", "\n", "                ", "max_U1_init", "=", "1.0", "/", "(", "sup_input_size", "*", "params", ".", "sup_projection_size", ")", "\n", "U1", "=", "tf", ".", "get_variable", "(", "\n", "'U1_supervised'", ",", "\n", "[", "sup_input_size", ",", "params", ".", "sup_projection_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_U1_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "d1", "=", "tf", ".", "get_variable", "(", "\n", "'d1_supervised'", ",", "\n", "[", "params", ".", "sup_projection_size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "#sup_hidden = tf.nn.xw_plus_b(self.h, U1, d1, name='disc_hidden')", "\n", "#sup_hidden = tf.nn.xw_plus_b(self.h_sup, U1, d1, name='disc_hidden')", "\n", "\n", "# Apply activation", "\n", "if", "params", ".", "activation", "==", "'sigmoid'", ":", "\n", "                    ", "sup_hidden", "=", "tf", ".", "sigmoid", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_sup", ",", "U1", ",", "d1", ",", "name", "=", "'disc_hidden'", ")", ")", "\n", "", "elif", "params", ".", "activation", "==", "'tanh'", ":", "\n", "                    ", "sup_hidden", "=", "tf", ".", "tanh", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_sup", ",", "U1", ",", "d1", ",", "name", "=", "'disc_hidden'", ")", ")", "\n", "", "elif", "params", ".", "activation", "==", "'relu'", ":", "\n", "                    ", "sup_hidden", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_sup", ",", "U1", ",", "d1", ",", "name", "=", "'disc_hidden'", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Invalid value for activation: %s'", "%", "(", "params", ".", "activation", ")", ")", "\n", "exit", "(", ")", "\n", "\n", "", "sup_hidden", "=", "tf", ".", "concat", "(", "[", "\n", "self", ".", "h", ",", "sup_hidden", "\n", "]", ",", "axis", "=", "1", ",", "name", "=", "'last_hidden_comb'", ")", "\n", "params", ".", "sup_projection_size", "=", "params", ".", "sup_projection_size", "+", "params", ".", "hidden_size", "\n", "\n", "max_U2_init", "=", "1.0", "/", "(", "params", ".", "sup_projection_size", "*", "params", ".", "num_classes", ")", "\n", "U2", "=", "tf", ".", "get_variable", "(", "\n", "'U2_supervised'", ",", "\n", "[", "params", ".", "sup_projection_size", ",", "params", ".", "num_classes", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_U2_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "d2", "=", "tf", ".", "get_variable", "(", "\n", "'d2_supervised'", ",", "\n", "[", "params", ".", "num_classes", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "disc_logits", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "sup_hidden", ",", "U2", ",", "d2", ",", "name", "=", "'disc_logits'", ")", "\n", "\n", "\"\"\"\n                # Apply activation\n                if params.activation == 'sigmoid':\n                    disc_logits = tf.sigmoid(tf.nn.xw_plus_b(sup_hidden, U2, d2, name='disc_logits'))\n                elif params.activation == 'tanh':\n                    disc_logits = tf.tanh(tf.nn.xw_plus_b(sup_hidden, U2, d2, name='disc_logits'))\n                elif params.activation == 'relu':\n                    disc_logits = tf.nn.relu(tf.nn.xw_plus_b(sup_hidden, U2, d2, name='disc_logits'))\n                else:\n                    print('Invalid value for activation: %s' % (params.activation))\n                    exit()\n                \"\"\"", "\n", "\n", "l2_reg_loss", "=", "tf", ".", "nn", ".", "l2_loss", "(", "U1", ")", "+", "tf", ".", "nn", ".", "l2_loss", "(", "d1", ")", "+", "tf", ".", "nn", ".", "l2_loss", "(", "U2", ")", "+", "tf", ".", "nn", ".", "l2_loss", "(", "d2", ")", "\n", "\n", "", "else", ":", "\n", "                ", "max_U_init", "=", "1.0", "/", "(", "params", ".", "hidden_size", "*", "params", ".", "num_classes", ")", "\n", "U", "=", "tf", ".", "get_variable", "(", "\n", "'U_supervised'", ",", "\n", "[", "sup_input_size", ",", "params", ".", "num_classes", "]", ",", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "\n", "maxval", "=", "max_U_init", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "d", "=", "tf", ".", "get_variable", "(", "\n", "'d_supervised'", ",", "\n", "[", "params", ".", "num_classes", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "\n", "trainable", "=", "True", "\n", ")", "\n", "\n", "#disc_logits = tf.nn.xw_plus_b(self.disc_h, U, d, name='disc_logits')", "\n", "#disc_logits = tf.nn.xw_plus_b(self.h, U, d, name='disc_logits')", "\n", "disc_logits", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "self", ".", "h_sup", ",", "U", ",", "d", ",", "name", "=", "'disc_logits'", ")", "\n", "\n", "l2_reg_loss", "=", "tf", ".", "nn", ".", "l2_loss", "(", "U", ")", "+", "tf", ".", "nn", ".", "l2_loss", "(", "d", ")", "\n", "\n", "", "self", ".", "disc_output", "=", "disc_logits", "\n", "\n", "labels", "=", "y", "\n", "disc_loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "\n", "logits", "=", "disc_logits", ",", "\n", ")", "\n", "self", ".", "disc_loss", "=", "tf", ".", "reduce_mean", "(", "disc_loss", ",", "name", "=", "'disc_loss'", ")", "\n", "self", ".", "pred_labels", "=", "tf", ".", "argmax", "(", "disc_logits", ",", "axis", "=", "1", ",", "name", "=", "'pred_labels'", ")", "\n", "\n", "############################################################################################", "\n", "\n", "", "self", ".", "logits", ",", "U_new", "=", "linear", "(", "h", ",", "params", ".", "vocab_size", ",", "scope", "=", "'softmax'", ",", "U_pretrained", "=", "U_pretrained", ")", "\n", "loss_function", "=", "None", "\n", "\n", "self", ".", "loss_normed", ",", "self", ".", "labels", ",", "self", ".", "mask", ",", "self", ".", "loss_unnormed", "=", "masked_sequence_cross_entropy_loss", "(", "\n", "x", ",", "\n", "seq_lengths", ",", "\n", "self", ".", "logits", ",", "\n", "loss_function", "=", "loss_function", ",", "\n", "norm_by_seq_lengths", "=", "True", ",", "\n", "name", "=", "\"x\"", "\n", ")", "\n", "\n", "#self.total_loss = tf.identity(self.loss_unnormed, name=\"total_loss\")", "\n", "self", ".", "total_loss", "=", "0.0", "\n", "\n", "if", "params", ".", "run_docnade", ":", "\n", "            ", "self", ".", "total_loss", "+=", "self", ".", "loss_unnormed", "\n", "\n", "", "if", "params", ".", "run_supervised", ":", "\n", "            ", "self", ".", "total_loss", "+=", "self", ".", "disc_loss", "\n", "\n", "if", "params", ".", "sup_l2_regularization", ":", "\n", "                ", "self", ".", "total_loss", "+=", "l2_reg_c", "*", "l2_reg_loss", "\n", "\n", "# Optimiser", "\n", "", "", "step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "self", ".", "opt", "=", "gradients", "(", "\n", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "params", ".", "learning_rate", ")", ",", "\n", "loss", "=", "self", ".", "total_loss", ",", "\n", "vars", "=", "tf", ".", "trainable_variables", "(", ")", ",", "\n", "step", "=", "step", "\n", ")", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.vectors": [[14, 24], ["numpy.array", "vecs.extend", "session.run"], "function", ["None"], ["def", "vectors", "(", "model", ",", "data", ",", "session", ")", ":", "\n", "    ", "vecs", "=", "[", "]", "\n", "for", "_", ",", "x", ",", "seq_lengths", "in", "data", ":", "\n", "        ", "vecs", ".", "extend", "(", "\n", "session", ".", "run", "(", "[", "model", ".", "h", "]", ",", "feed_dict", "=", "{", "\n", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "seq_lengths", ":", "seq_lengths", "\n", "}", ")", "[", "0", "]", "\n", ")", "\n", "", "return", "np", ".", "array", "(", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.loss": [[26, 36], ["loss.append", "sum", "len", "session.run"], "function", ["None"], ["", "def", "loss", "(", "model", ",", "data", ",", "session", ")", ":", "\n", "    ", "loss", "=", "[", "]", "\n", "for", "_", ",", "x", ",", "seq_lengths", "in", "data", ":", "\n", "        ", "loss", ".", "append", "(", "\n", "session", ".", "run", "(", "[", "model", ".", "loss", "]", ",", "feed_dict", "=", "{", "\n", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "seq_lengths", ":", "seq_lengths", "\n", "}", ")", "[", "0", "]", "\n", ")", "\n", "", "return", "sum", "(", "loss", ")", "/", "len", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.gradients": [[38, 67], ["opt.compute_gradients", "opt.apply_gradients", "zip", "tensorflow.python.ops.clip_ops.clip_by_global_norm", "isinstance", "list", "print", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "zip", "tensorflow.python.ops.clip_ops.global_norm"], "function", ["None"], ["", "def", "gradients", "(", "opt", ",", "loss", ",", "vars", ",", "step", ",", "max_gradient_norm", "=", "None", ",", "dont_clip", "=", "[", "]", ")", ":", "\n", "    ", "gradients", "=", "opt", ".", "compute_gradients", "(", "loss", ",", "vars", ")", "\n", "if", "max_gradient_norm", "is", "not", "None", ":", "\n", "        ", "to_clip", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "gradients", "if", "v", ".", "name", "not", "in", "dont_clip", "]", "\n", "not_clipped", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "gradients", "if", "v", ".", "name", "in", "dont_clip", "]", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "to_clip", ")", "\n", "clipped_gradients", ",", "_", "=", "clip_ops", ".", "clip_by_global_norm", "(", "\n", "gradients", ",", "\n", "max_gradient_norm", "\n", ")", "\n", "gradients", "=", "list", "(", "zip", "(", "clipped_gradients", ",", "variables", ")", ")", "+", "not_clipped", "\n", "\n", "# Add histograms for variables, gradients and gradient norms", "\n", "", "for", "gradient", ",", "variable", "in", "gradients", ":", "\n", "        ", "if", "isinstance", "(", "gradient", ",", "ops", ".", "IndexedSlices", ")", ":", "\n", "            ", "grad_values", "=", "gradient", ".", "values", "\n", "", "else", ":", "\n", "            ", "grad_values", "=", "gradient", "\n", "", "if", "grad_values", "is", "None", ":", "\n", "            ", "print", "(", "'warning: missing gradient: {}'", ".", "format", "(", "variable", ".", "name", ")", ")", "\n", "", "if", "grad_values", "is", "not", "None", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "name", ",", "variable", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "name", "+", "'/gradients'", ",", "grad_values", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\n", "variable", ".", "name", "+", "'/gradient_norm'", ",", "\n", "clip_ops", ".", "global_norm", "(", "[", "grad_values", "]", ")", "\n", ")", "\n", "\n", "", "", "return", "opt", ".", "apply_gradients", "(", "gradients", ",", "global_step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.linear": [[69, 97], ["tensorflow.constant_initializer", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "numpy.sqrt", "input.get_shape", "input.get_shape"], "function", ["None"], ["", "def", "linear", "(", "input", ",", "output_dim", ",", "scope", "=", "None", ",", "stddev", "=", "None", ",", "U_pretrained", "=", "None", ")", ":", "\n", "    ", "const", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "\n", "if", "U_pretrained", "is", "None", ":", "\n", "        ", "if", "stddev", ":", "\n", "            ", "norm", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ",", "seed", "=", "tf_op_seed", ")", "\n", "", "else", ":", "\n", "            ", "norm", "=", "tf", ".", "random_normal_initializer", "(", "\n", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "input", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", ")", ",", "\n", "seed", "=", "tf_op_seed", "\n", ")", "\n", "\n", "", "U", "=", "tf", ".", "get_variable", "(", "\n", "'U'", ",", "\n", "[", "input", ".", "get_shape", "(", ")", "[", "1", "]", ",", "output_dim", "]", ",", "\n", "initializer", "=", "norm", "\n", ")", "\n", "", "else", ":", "\n", "        ", "U", "=", "tf", ".", "get_variable", "(", "\n", "'U'", ",", "\n", "initializer", "=", "U_pretrained", "\n", ")", "\n", "\n", "", "b", "=", "tf", ".", "get_variable", "(", "'b'", ",", "[", "output_dim", "]", ",", "initializer", "=", "const", ")", "\n", "\n", "input_logits", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "input", ",", "U", ",", "b", ")", "\n", "\n", "return", "input_logits", ",", "U", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.model_DocNADE.masked_sequence_cross_entropy_loss": [[99, 146], ["tensorflow.reshape", "tensorflow.less", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.range", "tensorflow.reshape", "tensorflow.where", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "loss_function", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.to_float"], "function", ["None"], ["", "def", "masked_sequence_cross_entropy_loss", "(", "\n", "x", ",", "\n", "seq_lengths", ",", "\n", "logits", ",", "\n", "loss_function", "=", "None", ",", "\n", "norm_by_seq_lengths", "=", "True", ",", "\n", "name", "=", "\"\"", "\n", ")", ":", "\n", "    ", "'''\n    Compute the cross-entropy loss between all elements in x and logits.\n    Masks out the loss for all positions greater than the sequence\n    length (as we expect that sequences may be padded).\n\n    Optionally, also either use a different loss function (eg: sampled\n    softmax), and/or normalise the loss for each sequence by the\n    sequence length.\n    '''", "\n", "batch_size", "=", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", "]", ")", "\n", "\n", "\n", "max_doc_length", "=", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "\n", "mask", "=", "tf", ".", "less", "(", "\n", "tf", ".", "range", "(", "0", ",", "max_doc_length", ",", "1", ")", ",", "\n", "tf", ".", "reshape", "(", "seq_lengths", ",", "[", "batch_size", ",", "1", "]", ")", "\n", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "[", "-", "1", "]", ")", "\n", "mask", "=", "tf", ".", "to_float", "(", "tf", ".", "where", "(", "\n", "mask", ",", "\n", "tf", ".", "ones_like", "(", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", ")", ")", "\n", "\n", "if", "loss_function", "is", "None", ":", "\n", "        ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "\n", "labels", "=", "labels", "\n", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "loss_function", "(", "logits", ",", "labels", ")", "\n", "", "loss", "*=", "mask", "\n", "loss", "=", "tf", ".", "reshape", "(", "loss", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "loss", ",", "axis", "=", "1", ")", "\n", "loss_unnormed", "=", "loss", "\n", "if", "norm_by_seq_lengths", ":", "\n", "        ", "loss", "=", "loss", "/", "tf", ".", "to_float", "(", "seq_lengths", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "loss", ",", "name", "=", "\"loss_normed_\"", "+", "name", ")", ",", "labels", ",", "mask", ",", "tf", ".", "reduce_mean", "(", "loss_unnormed", ",", "name", "=", "\"loss_unnormed_\"", "+", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.compare_labels": [[11, 49], ["numpy.asarray", "numpy.array", "print", "exit", "numpy.ones", "numpy.asarray", "numpy.dot", "print", "isinstance", "isinstance", "print", "exit", "numpy.array", "len", "len", "numpy.array", "print", "numpy.ones", "numpy.sum"], "function", ["None"], ["def", "compare_labels", "(", "train_labels", ",", "test_label", ",", "label_type", "=", "\"\"", ",", "evaluation_type", "=", "\"\"", ",", "labels_to_count", "=", "[", "]", ")", ":", "\n", "#train_labels = train_labels[:, labels_to_count]", "\n", "#test_label = test_label[labels_to_count]", "\n", "\n", "    ", "vec_goodLabel", "=", "[", "]", "\n", "\n", "train_labels", "=", "np", ".", "asarray", "(", "train_labels", ")", "\n", "\n", "if", "label_type", "==", "\"single\"", ":", "\n", "        ", "if", "not", "(", "isinstance", "(", "test_label", ",", "int", ")", "or", "isinstance", "(", "train_labels", "[", "0", "]", ",", "int", ")", ")", ":", "\n", "            ", "print", "(", "\"Labels are not instances of int\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "test_labels", "=", "np", ".", "ones", "(", "train_labels", ".", "shape", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "*", "test_label", "\n", "\n", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "train_labels", "==", "test_labels", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "", "elif", "label_type", "==", "\"multi\"", ":", "\n", "        ", "if", "not", "len", "(", "train_labels", "[", "0", "]", ")", "==", "len", "(", "test_label", ")", ":", "\n", "            ", "print", "(", "\"Mismatched label vector length\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "test_labels", "=", "np", ".", "asarray", "(", "test_label", ")", "\n", "labels_comparison_vec", "=", "np", ".", "dot", "(", "train_labels", ",", "test_labels", ")", "\n", "\n", "if", "evaluation_type", "==", "\"relaxed\"", ":", "\n", "            ", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "labels_comparison_vec", "!=", "0", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "\n", "", "elif", "evaluation_type", "==", "\"strict\"", ":", "\n", "            ", "test_label_vec", "=", "np", ".", "ones", "(", "train_labels", ".", "shape", "[", "0", "]", ")", "*", "np", ".", "sum", "(", "test_label", ")", "\n", "vec_goodLabel", "=", "np", ".", "array", "(", "(", "labels_comparison_vec", "==", "test_label_vec", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Invalid evaluation_type value.\"", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"Invalid label_type value.\"", ")", "\n", "\n", "", "return", "vec_goodLabel", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_IR_prec": [[50, 157], ["numpy.mean", "print", "exit", "numpy.floor", "enumerate", "enumerate", "len", "len", "range", "numpy.argsort", "numpy.zeros", "evaluate.compare_labels", "enumerate", "numpy.argsort", "numpy.zeros", "evaluate.compare_labels", "enumerate", "len", "numpy.sum", "float", "open", "enumerate", "len", "list_totalRetrievalCount.append", "open", "enumerate", "int", "len", "prec_label_wise[].append", "f.write", "f.write", "numpy.floor", "numpy.sum", "numpy.sum", "float", "f.write", "f.write", "f.write", "f.write", "int", "int", "int", "str", "str"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.compare_labels", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.compare_labels"], ["", "def", "perform_IR_prec", "(", "kernel_matrix_test", ",", "train_labels", ",", "test_labels", ",", "list_percRetrieval", "=", "None", ",", "single_precision", "=", "False", ",", "label_type", "=", "\"\"", ",", "evaluation", "=", "\"\"", ",", "index2label_dict", "=", "None", ",", "labels_to_not_count", "=", "[", "]", ",", "corpus_docs", "=", "None", ",", "query_docs", "=", "None", ",", "IR_filename", "=", "\"\"", ",", "top_n_retrieval", "=", "20", ")", ":", "\n", "    ", "'''\n    :param kernel_matrix_test: shape: size = |test_samples| x |train_samples|\n    :param train_labels:              size = |train_samples| or |train_samples| x num_labels\n    :param test_labels:               size = |test_samples| or |test_samples| x num_labels\n    :param list_percRetrieval:        list of fractions at which IR has to be calculated\n    :param single_precision:          True, if only one fraction is used\n    :param label_type:                \"single\" or \"multi\"\n    :param evaluation:                \"strict\" or \"relaxed\", only for \n    :return:\n    '''", "\n", "#print('Computing IR prec......')", "\n", "\n", "if", "not", "len", "(", "test_labels", ")", "==", "len", "(", "kernel_matrix_test", ")", ":", "\n", "        ", "print", "(", "'mismatched samples in test_labels and kernel_matrix_test'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "labels_to_count", "=", "[", "]", "\n", "#if labels_to_not_count:", "\n", "#    for index, label in index2label_dict.iteritems():", "\n", "#        if not label in labels_to_not_count:", "\n", "#            labels_to_count.append(int(index))", "\n", "\n", "prec", "=", "[", "]", "\n", "prec_label_wise", "=", "{", "label", ":", "[", "]", "for", "label", "in", "range", "(", "test_labels", ".", "shape", "[", "1", "]", ")", "}", "\n", "\n", "if", "single_precision", ":", "\n", "        ", "vec_simIndexSorted", "=", "np", ".", "argsort", "(", "kernel_matrix_test", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "prec_num_docs", "=", "np", ".", "floor", "(", "list_percRetrieval", "[", "0", "]", "*", "kernel_matrix_test", ".", "shape", "[", "1", "]", ")", "\n", "#prec_num_docs = list_percRetrieval[0]", "\n", "vec_simIndexSorted_prec", "=", "vec_simIndexSorted", "[", ":", ",", ":", "int", "(", "prec_num_docs", ")", "]", "\n", "\n", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted_prec", ")", ":", "\n", "            ", "if", "label_type", "==", "\"multi\"", ":", "\n", "                ", "classQuery", "=", "test_labels", "[", "counter", ",", ":", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "classQuery", "=", "test_labels", "[", "counter", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", "]", "\n", "", "list_percPrecision", "=", "np", ".", "zeros", "(", "len", "(", "list_percRetrieval", ")", ")", "\n", "\n", "vec_goodLabel", "=", "compare_labels", "(", "tr_labels", ",", "classQuery", ",", "label_type", "=", "label_type", ",", "evaluation_type", "=", "evaluation", ",", "labels_to_count", "=", "labels_to_count", ")", "\n", "\n", "list_percPrecision", "[", "0", "]", "=", "np", ".", "sum", "(", "vec_goodLabel", ")", "/", "float", "(", "len", "(", "vec_goodLabel", ")", ")", "\n", "\n", "prec", "+=", "[", "list_percPrecision", "]", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "classQuery", ")", ":", "\n", "                ", "if", "label", "==", "1", ":", "\n", "                    ", "prec_label_wise", "[", "i", "]", ".", "append", "(", "list_percPrecision", "[", "0", "]", ")", "\n", "\n", "", "", "", "if", "(", "corpus_docs", "is", "not", "None", ")", "and", "(", "query_docs", "is", "not", "None", ")", "and", "(", "IR_filename", "!=", "\"\"", ")", ":", "\n", "            ", "with", "open", "(", "IR_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", "[", ":", ",", ":", "top_n_retrieval", "]", ")", ":", "\n", "                    ", "f", ".", "write", "(", "\"Query\\t::\\t\"", "+", "query_docs", "[", "counter", "]", "+", "\"\\n\\n\"", ")", "\n", "#for index in indices[:int(kernel_matrix_test.shape[1] * 0.02)]:", "\n", "for", "index", "in", "indices", "[", ":", "top_n_retrieval", "]", ":", "\n", "                        ", "f", ".", "write", "(", "str", "(", "kernel_matrix_test", "[", "counter", ",", "index", "]", ")", "+", "\"\\t::\\t\"", "+", "corpus_docs", "[", "index", "]", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "", "", "", "", "else", ":", "\n", "        ", "vec_simIndexSorted", "=", "np", ".", "argsort", "(", "kernel_matrix_test", ",", "axis", "=", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", ")", ":", "\n", "\n", "#indices = np.delete(indices, 0)", "\n", "\n", "            ", "if", "label_type", "==", "\"multi\"", ":", "\n", "                ", "classQuery", "=", "test_labels", "[", "counter", ",", ":", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "classQuery", "=", "test_labels", "[", "counter", "]", "\n", "tr_labels", "=", "train_labels", "[", "indices", "]", "\n", "", "list_percPrecision", "=", "np", ".", "zeros", "(", "len", "(", "list_percRetrieval", ")", ")", "\n", "\n", "vec_goodLabel", "=", "compare_labels", "(", "tr_labels", ",", "classQuery", ",", "label_type", "=", "label_type", ",", "evaluation_type", "=", "evaluation", ",", "labels_to_count", "=", "labels_to_count", ")", "\n", "\n", "list_totalRetrievalCount", "=", "[", "]", "\n", "for", "frac", "in", "list_percRetrieval", ":", "\n", "                ", "list_totalRetrievalCount", ".", "append", "(", "np", ".", "floor", "(", "frac", "*", "kernel_matrix_test", ".", "shape", "[", "1", "]", ")", ")", "\n", "#list_totalRetrievalCount.append(frac)", "\n", "\n", "", "countGoodLabel", "=", "0", "\n", "for", "indexRetrieval", ",", "totalRetrievalCount", "in", "enumerate", "(", "list_totalRetrievalCount", ")", ":", "\n", "                ", "if", "indexRetrieval", "==", "0", ":", "\n", "                    ", "countGoodLabel", "+=", "np", ".", "sum", "(", "vec_goodLabel", "[", ":", "int", "(", "totalRetrievalCount", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "countGoodLabel", "+=", "np", ".", "sum", "(", "vec_goodLabel", "[", "int", "(", "lastTotalRetrievalCount", ")", ":", "int", "(", "totalRetrievalCount", ")", "]", ")", "\n", "\n", "", "list_percPrecision", "[", "indexRetrieval", "]", "=", "countGoodLabel", "/", "float", "(", "totalRetrievalCount", ")", "\n", "lastTotalRetrievalCount", "=", "totalRetrievalCount", "\n", "\n", "", "prec", "+=", "[", "list_percPrecision", "]", "# vec_simIndexSorted[:int(list_totalRetrievalCount[0])]", "\n", "\n", "", "if", "(", "corpus_docs", "is", "not", "None", ")", "and", "(", "query_docs", "is", "not", "None", ")", "and", "(", "IR_filename", "!=", "\"\"", ")", ":", "\n", "            ", "with", "open", "(", "IR_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "for", "counter", ",", "indices", "in", "enumerate", "(", "vec_simIndexSorted", "[", ":", ",", ":", "top_n_retrieval", "]", ")", ":", "\n", "                    ", "f", ".", "write", "(", "\"Query\\t::\\t\"", "+", "query_docs", "[", "counter", "]", "+", "\"\\n\\n\"", ")", "\n", "#for index in indices[:int(kernel_matrix_test.shape[1] * 0.02)]:", "\n", "for", "index", "in", "indices", "[", ":", "top_n_retrieval", "]", ":", "\n", "                        ", "f", ".", "write", "(", "str", "(", "kernel_matrix_test", "[", "counter", ",", "index", "]", ")", "+", "\"\\t::\\t\"", "+", "corpus_docs", "[", "index", "]", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "\n", "", "", "", "", "prec", "=", "np", ".", "mean", "(", "prec", ",", "axis", "=", "0", ")", "\n", "\n", "return", "prec", ",", "prec_label_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test": [[159, 191], ["numpy.mean", "numpy.std", "sklearn.svm.SVC.fit", "sklearn.svm.SVC.predict", "sklearn.metrics.accuracy_score", "test_acc.append", "test_f1.append", "numpy.vstack", "numpy.vstack", "sklearn.linear_model.LogisticRegression", "sklearn.metrics.precision_recall_fscore_support", "sklearn.svm.SVC"], "function", ["None"], ["", "def", "perform_classification_test", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "    ", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "        ", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "## Classification Accuracy", "\n", "", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "        ", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "            ", "clf", "=", "LogisticRegression", "(", "C", "=", "c", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#clf = SVC(C=c, kernel='precomputed')", "\n", "            ", "clf", "=", "SVC", "(", "C", "=", "c", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_test_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "\n", "acc_test", "=", "accuracy_score", "(", "test_labels", ",", "pred_test_labels", ")", "\n", "f1_test", "=", "precision_recall_fscore_support", "(", "test_labels", ",", "pred_test_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'macro'", ")", "[", "2", "]", "\n", "\n", "test_acc", ".", "append", "(", "acc_test", ")", "\n", "test_f1", ".", "append", "(", "f1_test", ")", "\n", "\n", "", "return", "test_acc", ",", "test_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_classification_test_multi": [[192, 224], ["numpy.mean", "numpy.std", "sklearn.multiclass.OneVsRestClassifier.fit", "sklearn.multiclass.OneVsRestClassifier.predict", "sklearn.metrics.accuracy_score", "test_acc.append", "test_f1.append", "numpy.vstack", "numpy.vstack", "sklearn.multiclass.OneVsRestClassifier", "sklearn.metrics.precision_recall_fscore_support", "sklearn.linear_model.LogisticRegression", "sklearn.multiclass.OneVsRestClassifier", "sklearn.svm.SVC"], "function", ["None"], ["", "def", "perform_classification_test_multi", "(", "train_data", ",", "test_data", ",", "c_list", ",", "classification_model", "=", "\"logistic\"", ",", "norm_before_classification", "=", "False", ")", ":", "\n", "    ", "docVectors_train", ",", "train_labels", "=", "train_data", "\n", "docVectors_test", ",", "test_labels", "=", "test_data", "\n", "\n", "if", "norm_before_classification", ":", "\n", "        ", "mean", "=", "np", ".", "mean", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "np", ".", "vstack", "(", "(", "docVectors_train", ",", "docVectors_test", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "docVectors_train", "=", "(", "docVectors_train", "-", "mean", ")", "/", "std", "\n", "docVectors_test", "=", "(", "docVectors_test", "-", "mean", ")", "/", "std", "\n", "\n", "## Classification Accuracy", "\n", "", "test_acc", "=", "[", "]", "\n", "test_f1", "=", "[", "]", "\n", "\n", "for", "c", "in", "c_list", ":", "\n", "        ", "if", "classification_model", "==", "\"logistic\"", ":", "\n", "            ", "clf", "=", "OneVsRestClassifier", "(", "LogisticRegression", "(", "C", "=", "c", ")", ",", "n_jobs", "=", "5", ")", "\n", "", "elif", "classification_model", "==", "\"svm\"", ":", "\n", "#clf = OneVsRestClassifier(SVC(C=c, kernel='precomputed'))", "\n", "            ", "clf", "=", "OneVsRestClassifier", "(", "SVC", "(", "C", "=", "c", ")", ")", "\n", "\n", "", "clf", ".", "fit", "(", "docVectors_train", ",", "train_labels", ")", "\n", "pred_test_labels", "=", "clf", ".", "predict", "(", "docVectors_test", ")", "\n", "\n", "acc_test", "=", "accuracy_score", "(", "test_labels", ",", "pred_test_labels", ")", "\n", "f1_test", "=", "precision_recall_fscore_support", "(", "test_labels", ",", "pred_test_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'macro'", ")", "[", "2", "]", "\n", "\n", "test_acc", ".", "append", "(", "acc_test", ")", "\n", "test_f1", ".", "append", "(", "f1_test", ")", "\n", "\n", "", "return", "test_acc", ",", "test_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.closest_docs_by_index": [[226, 231], ["range", "numpy.array", "len", "docs.append"], "function", ["None"], ["", "def", "closest_docs_by_index", "(", "sim", ",", "order", ",", "query_vectors", ",", "n_docs", ")", ":", "\n", "    ", "docs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "query_vectors", ")", ")", ":", "\n", "        ", "docs", ".", "append", "(", "order", "[", ":", ",", "i", "]", "[", "0", ":", "n_docs", "]", ")", "\n", "", "return", "np", ".", "array", "(", "docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.precision": [[233, 240], ["len", "float", "len", "len"], "function", ["None"], ["", "def", "precision", "(", "label", ",", "predictions", ")", ":", "\n", "    ", "if", "len", "(", "predictions", ")", ":", "\n", "        ", "return", "float", "(", "\n", "len", "(", "[", "x", "for", "x", "in", "predictions", "if", "label", "in", "x", "]", ")", "\n", ")", "/", "len", "(", "predictions", ")", "\n", "", "else", ":", "\n", "        ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate": [[242, 307], ["total_labels.extend", "total_labels.extend", "sklearn.preprocessing.MultiLabelBinarizer", "sklearn.preprocessing.MultiLabelBinarizer.fit", "sklearn.preprocessing.MultiLabelBinarizer.transform", "sklearn.preprocessing.MultiLabelBinarizer.transform", "evaluate.perform_IR_prec", "len", "len", "sklearn.cosine_similarity", "label[].split", "label[].split", "sklearn.cosine_similarity", "len", "numpy.argsort", "int", "evaluate.closest_docs_by_index", "range", "results.append", "str", "results.append", "len", "str", "range", "evaluate.precision", "range"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.perform_IR_prec", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.None.train_DocNADE.cosine_similarity", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.closest_docs_by_index", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.precision"], ["", "", "def", "evaluate", "(", "\n", "corpus_vectors", ",", "\n", "query_vectors", ",", "\n", "corpus_labels", ",", "\n", "query_labels", ",", "\n", "recall", "=", "[", "0.02", "]", ",", "\n", "num_classes", "=", "None", ",", "\n", "multi_label", "=", "False", ",", "\n", "query_docs", "=", "None", ",", "\n", "corpus_docs", "=", "None", ",", "\n", "IR_filename", "=", "\"\"", ",", "\n", "top_n_retrieval", "=", "20", "\n", ")", ":", "\n", "    ", "if", "multi_label", ":", "\n", "\n", "        ", "splitted_query_labels", "=", "[", "label", "[", "0", "]", ".", "split", "(", "':'", ")", "for", "label", "in", "query_labels", "]", "\n", "splitted_corpus_labels", "=", "[", "label", "[", "0", "]", ".", "split", "(", "':'", ")", "for", "label", "in", "corpus_labels", "]", "\n", "\n", "total_labels", "=", "[", "]", "\n", "total_labels", ".", "extend", "(", "splitted_query_labels", ")", "\n", "total_labels", ".", "extend", "(", "splitted_corpus_labels", ")", "\n", "\n", "mlb", "=", "MultiLabelBinarizer", "(", "classes", "=", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", ")", "\n", "mlb", ".", "fit", "(", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", ")", "\n", "\n", "query_one_hot_labels", "=", "mlb", ".", "transform", "(", "splitted_query_labels", ")", "\n", "corpus_one_hot_labels", "=", "mlb", ".", "transform", "(", "splitted_corpus_labels", ")", "\n", "\n", "similarity_matrix", "=", "pw", ".", "cosine_similarity", "(", "corpus_vectors", ",", "query_vectors", ")", ".", "T", "\n", "if", "len", "(", "recall", ")", "==", "1", ":", "\n", "            ", "single_precision", "=", "True", "\n", "", "else", ":", "\n", "            ", "single_precision", "=", "False", "\n", "\n", "", "results", ",", "results_label_wise", "=", "perform_IR_prec", "(", "similarity_matrix", ",", "corpus_one_hot_labels", ",", "query_one_hot_labels", ",", "list_percRetrieval", "=", "recall", ",", "single_precision", "=", "single_precision", ",", "label_type", "=", "\"multi\"", ",", "evaluation", "=", "\"relaxed\"", ",", "corpus_docs", "=", "corpus_docs", ",", "query_docs", "=", "query_docs", ",", "IR_filename", "=", "IR_filename", ",", "top_n_retrieval", "=", "top_n_retrieval", ")", "\n", "", "else", ":", "\n", "        ", "corpus_size", "=", "len", "(", "corpus_labels", ")", "\n", "query_size", "=", "len", "(", "query_labels", ")", "\n", "\n", "results", "=", "[", "]", "\n", "results_label_wise", "=", "{", "}", "\n", "\n", "sim", "=", "pw", ".", "cosine_similarity", "(", "corpus_vectors", ",", "query_vectors", ")", "\n", "order", "=", "np", ".", "argsort", "(", "sim", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "for", "r", "in", "recall", ":", "\n", "            ", "n_docs", "=", "int", "(", "(", "corpus_size", "*", "r", ")", "+", "0.5", ")", "\n", "if", "not", "n_docs", ":", "\n", "                ", "results", ".", "append", "(", "0.0", ")", "\n", "continue", "\n", "\n", "", "closest", "=", "closest_docs_by_index", "(", "sim", ",", "order", ",", "query_vectors", ",", "n_docs", ")", "\n", "\n", "avg", "=", "0.0", "\n", "for", "i", "in", "range", "(", "query_size", ")", ":", "\n", "                ", "doc_labels", "=", "query_labels", "[", "i", "]", "\n", "doc_avg", "=", "0.0", "\n", "for", "label", "in", "doc_labels", ":", "\n", "                    ", "doc_avg", "+=", "precision", "(", "label", ",", "corpus_labels", "[", "closest", "[", "i", "]", "]", ")", "\n", "", "doc_avg", "/=", "len", "(", "doc_labels", ")", "\n", "avg", "+=", "doc_avg", "\n", "", "avg", "/=", "query_size", "\n", "results", ".", "append", "(", "avg", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_AP": [[309, 318], ["enumerate", "numpy.mean", "prec_list.append", "float"], "function", ["None"], ["", "def", "evaluate_AP", "(", "pred_labels", ")", ":", "\n", "    ", "prec_list", "=", "[", "]", "\n", "\n", "cumulative_sum", "=", "0", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "pred_labels", ")", ":", "\n", "        ", "cumulative_sum", "+=", "label", "\n", "prec_list", ".", "append", "(", "float", "(", "cumulative_sum", ")", "/", "(", "i", "+", "1", ")", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "prec_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_mAP": [[320, 364], ["numpy.unique", "zip", "preds_dict[].append", "preds_labels_dict[].append", "preds_indices_dict[].append", "probs_dict[].append", "numpy.mean", "len", "len", "evaluate.evaluate_AP", "AP_list.append", "numpy.argsort", "numpy.array"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_AP"], ["", "def", "evaluate_mAP", "(", "true_labels", ",", "pred_labels", ",", "pred_probs", ")", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "    ", "labels", "=", "np", ".", "unique", "(", "true_labels", ")", "\n", "preds_dict", "=", "{", "label", ":", "[", "]", "for", "label", "in", "labels", "}", "\n", "preds_labels_dict", "=", "{", "label", ":", "[", "]", "for", "label", "in", "labels", "}", "\n", "preds_indices_dict", "=", "{", "label", ":", "[", "]", "for", "label", "in", "labels", "}", "\n", "probs_dict", "=", "{", "label", ":", "[", "]", "for", "label", "in", "labels", "}", "\n", "index", "=", "0", "\n", "for", "true", ",", "pred", ",", "prob", "in", "zip", "(", "true_labels", ",", "pred_labels", ",", "pred_probs", ")", ":", "\n", "        ", "if", "true", "==", "pred", ":", "\n", "            ", "identifier", "=", "1", "\n", "", "else", ":", "\n", "            ", "identifier", "=", "0", "\n", "", "preds_dict", "[", "pred", "]", ".", "append", "(", "identifier", ")", "\n", "preds_labels_dict", "[", "pred", "]", ".", "append", "(", "true", ")", "\n", "preds_indices_dict", "[", "pred", "]", ".", "append", "(", "index", ")", "\n", "probs_dict", "[", "pred", "]", ".", "append", "(", "prob", ")", "\n", "index", "+=", "1", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "sorted_preds_dict", "=", "{", "label", ":", "[", "]", "for", "label", "in", "labels", "}", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "preds", "=", "preds_dict", "[", "label", "]", "\n", "\n", "if", "len", "(", "preds", ")", "!=", "0", ":", "\n", "            ", "probs", "=", "probs_dict", "[", "label", "]", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "probs", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_preds", "=", "np", ".", "array", "(", "preds", ")", "[", "sorted_indices", "]", "\n", "sorted_preds_dict", "[", "label", "]", "=", "sorted_preds", "\n", "\n", "#import pdb; pdb.set_trace()", "\n", "\n", "", "", "AP_dict", "=", "{", "label", ":", "0.0", "for", "label", "in", "labels", "}", "\n", "AP_list", "=", "[", "]", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "sorted_labels", "=", "sorted_preds_dict", "[", "label", "]", "\n", "if", "len", "(", "sorted_labels", ")", "!=", "0", ":", "\n", "            ", "label_AP", "=", "evaluate_AP", "(", "sorted_labels", ")", "\n", "AP_list", ".", "append", "(", "label_AP", ")", "\n", "AP_dict", "[", "label", "]", "=", "label_AP", "\n", "\n", "", "", "return", "np", ".", "mean", "(", "AP_list", ")", ",", "AP_dict", ",", "preds_labels_dict", ",", "probs_dict", ",", "preds_indices_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.softmax": [[365, 407], ["numpy.atleast_2d", "numpy.exp", "numpy.expand_dims", "next", "float", "numpy.expand_dims", "numpy.sum", "len", "p.flatten.flatten", "numpy.max", "enumerate"], "function", ["None"], ["", "def", "softmax", "(", "X", ",", "theta", "=", "1.0", ",", "axis", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Compute the softmax of each element along an axis of X.\n\n    Parameters\n    ----------\n    X: ND-Array. Probably should be floats. \n    theta (optional): float parameter, used as a multiplier\n        prior to exponentiation. Default = 1.0\n    axis (optional): axis to compute values along. Default is the \n        first non-singleton axis.\n\n    Returns an array the same size as X. The result will sum to 1\n    along the specified axis.\n    \"\"\"", "\n", "\n", "# make X at least 2d", "\n", "y", "=", "np", ".", "atleast_2d", "(", "X", ")", "\n", "\n", "# find axis", "\n", "if", "axis", "is", "None", ":", "\n", "        ", "axis", "=", "next", "(", "j", "[", "0", "]", "for", "j", "in", "enumerate", "(", "y", ".", "shape", ")", "if", "j", "[", "1", "]", ">", "1", ")", "\n", "\n", "# multiply y against the theta parameter, ", "\n", "", "y", "=", "y", "*", "float", "(", "theta", ")", "\n", "\n", "# subtract the max for numerical stability", "\n", "y", "=", "y", "-", "np", ".", "expand_dims", "(", "np", ".", "max", "(", "y", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "\n", "# exponentiate y", "\n", "y", "=", "np", ".", "exp", "(", "y", ")", "\n", "\n", "# take the sum along the specified axis", "\n", "ax_sum", "=", "np", ".", "expand_dims", "(", "np", ".", "sum", "(", "y", ",", "axis", "=", "axis", ")", ",", "axis", ")", "\n", "\n", "# finally: divide elementwise", "\n", "p", "=", "y", "/", "ax_sum", "\n", "\n", "# flatten if X was 1D", "\n", "if", "len", "(", "X", ".", "shape", ")", "==", "1", ":", "p", "=", "p", ".", "flatten", "(", ")", "\n", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.most_relevant": [[408, 416], ["evaluate.evaluate_AP", "numpy.argsort", "numpy.array"], "function", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.evaluate.evaluate_AP"], ["", "def", "most_relevant", "(", "true_relevance_labels", ",", "relevance_scores", ")", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "\t", "indices", "=", "np", ".", "argsort", "(", "relevance_scores", ")", "[", ":", ":", "-", "1", "]", "\n", "sorted_relevance_scores", "=", "relevance_scores", "[", "indices", "]", "\n", "sorted_true_relevance_labels", "=", "np", ".", "array", "(", "true_relevance_labels", ")", "[", "indices", "]", "\n", "AP", "=", "evaluate_AP", "(", "sorted_true_relevance_labels", ")", "\n", "#AP = 0.0", "\n", "return", "AP", ",", "sorted_true_relevance_labels", ",", "sorted_relevance_scores", ",", "indices", "\n", "", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.__init__": [[48, 52], ["glob.glob", "data.file_name"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.file_name"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "files", "=", "glob", ".", "glob", "(", "path", "+", "'/*.csv'", ")", "\n", "self", ".", "collections", "=", "{", "file_name", "(", "file", ")", ":", "file", "for", "file", "in", "files", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows": [[53, 69], ["ValueError", "open", "csv.reader"], "methods", ["None"], ["", "def", "rows", "(", "self", ",", "collection_name", ",", "num_epochs", "=", "None", ")", ":", "\n", "        ", "if", "collection_name", "not", "in", "self", ".", "collections", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Collection not found: {}'", ".", "format", "(", "collection_name", ")", "\n", ")", "\n", "", "epoch", "=", "0", "\n", "while", "True", ":", "\n", "#with open(self.collections[collection_name], 'rb', newline='') as f:", "\n", "            ", "with", "open", "(", "self", ".", "collections", "[", "collection_name", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "r", "=", "csv", ".", "reader", "(", "f", ")", "\n", "for", "row", "in", "r", ":", "\n", "                    ", "yield", "row", "\n", "", "", "epoch", "+=", "1", "\n", "if", "num_epochs", "and", "(", "epoch", ">=", "num_epochs", ")", ":", "\n", "#raise StopIteration", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset._batch_iter": [[70, 73], ["itertools.zip_longest", "data.Dataset.rows"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.rows"], ["", "", "", "def", "_batch_iter", "(", "self", ",", "collection_name", ",", "batch_size", ",", "num_epochs", ")", ":", "\n", "        ", "gen", "=", "[", "self", ".", "rows", "(", "collection_name", ",", "num_epochs", ")", "]", "*", "batch_size", "\n", "return", "itertools", ".", "zip_longest", "(", "fillvalue", "=", "None", ",", "*", "gen", ")", "\n", "#return izip_longest(fillvalue=None, *gen)", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches": [[75, 84], ["data.Dataset._batch_iter", "zip", "data.format_row", "keras.pad_sequences", "keras.pad_sequences", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset._batch_iter", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.format_row"], ["", "def", "batches", "(", "self", ",", "collection_name", ",", "batch_size", ",", "num_epochs", "=", "None", ",", "shuffle", "=", "True", ",", "max_len", "=", "None", ",", "multilabel", "=", "False", ")", ":", "\n", "        ", "for", "batch", "in", "self", ".", "_batch_iter", "(", "collection_name", ",", "batch_size", ",", "num_epochs", ")", ":", "\n", "            ", "data", "=", "[", "format_row", "(", "row", ",", "shuffle", "=", "shuffle", ",", "multilabel", "=", "multilabel", ")", "for", "row", "in", "batch", "if", "row", "]", "\n", "y", ",", "x", ",", "seq_lengths", "=", "zip", "(", "*", "data", ")", "\n", "if", "not", "max_len", "is", "None", ":", "\n", "                ", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "maxlen", "=", "max_len", ",", "padding", "=", "'post'", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "padding", "=", "'post'", ")", "\n", "", "yield", "np", ".", "array", "(", "y", ")", ",", "x", ",", "np", ".", "array", "(", "seq_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset.batches_bidirectional": [[85, 96], ["data.Dataset._batch_iter", "zip", "data.format_row_bidirectional", "keras.pad_sequences", "keras.pad_sequences", "keras.pad_sequences", "keras.pad_sequences", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.Dataset._batch_iter", "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.format_row_bidirectional"], ["", "", "def", "batches_bidirectional", "(", "self", ",", "collection_name", ",", "batch_size", ",", "num_epochs", "=", "None", ",", "shuffle", "=", "True", ",", "max_len", "=", "None", ",", "multilabel", "=", "False", ")", ":", "\n", "        ", "for", "batch", "in", "self", ".", "_batch_iter", "(", "collection_name", ",", "batch_size", ",", "num_epochs", ")", ":", "\n", "            ", "data", "=", "[", "format_row_bidirectional", "(", "row", ",", "shuffle", "=", "shuffle", ",", "multilabel", "=", "multilabel", ")", "for", "row", "in", "batch", "if", "row", "]", "\n", "y", ",", "x", ",", "x_rev", ",", "seq_lengths", "=", "zip", "(", "*", "data", ")", "\n", "if", "not", "max_len", "is", "None", ":", "\n", "                ", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "maxlen", "=", "max_len", ",", "padding", "=", "'post'", ")", "\n", "x_rev", "=", "pp", ".", "pad_sequences", "(", "x_rev", ",", "maxlen", "=", "max_len", ",", "padding", "=", "'post'", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "pp", ".", "pad_sequences", "(", "x", ",", "padding", "=", "'post'", ")", "\n", "x_rev", "=", "pp", ".", "pad_sequences", "(", "x_rev", ",", "padding", "=", "'post'", ")", "\n", "", "yield", "np", ".", "array", "(", "y", ")", ",", "x", ",", "x_rev", ",", "np", ".", "array", "(", "seq_lengths", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.file_name": [[19, 21], ["os.path.basename().replace", "os.path.basename"], "function", ["None"], ["def", "file_name", "(", "abs_path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "basename", "(", "abs_path", ")", ".", "replace", "(", "'.csv'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.format_row": [[23, 33], ["numpy.array", "numpy.random.shuffle", "int", "len", "int", "len", "raw_x.split"], "function", ["None"], ["", "def", "format_row", "(", "row", ",", "shuffle", "=", "True", ",", "multilabel", "=", "False", ")", ":", "\n", "    ", "y", ",", "raw_x", "=", "row", "\n", "x", "=", "np", ".", "array", "(", "[", "int", "(", "v", ")", "for", "v", "in", "raw_x", ".", "split", "(", ")", "]", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "x", ")", "\n", "\n", "", "if", "multilabel", ":", "\n", "        ", "return", "[", "y", ",", "x", ",", "len", "(", "x", ")", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "int", "(", "y", ")", ",", "x", ",", "len", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YatinChaudhary_RDoC_Task.model.data.format_row_bidirectional": [[34, 45], ["numpy.array", "numpy.random.shuffle", "int", "len", "int", "len", "raw_x.split"], "function", ["None"], ["", "", "def", "format_row_bidirectional", "(", "row", ",", "shuffle", "=", "True", ",", "multilabel", "=", "False", ")", ":", "\n", "    ", "y", ",", "raw_x", "=", "row", "\n", "x", "=", "np", ".", "array", "(", "[", "int", "(", "v", ")", "for", "v", "in", "raw_x", ".", "split", "(", ")", "]", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "x", ")", "\n", "", "x_rev", "=", "x", "[", ":", ":", "-", "1", "]", "\n", "\n", "if", "multilabel", ":", "\n", "        ", "return", "[", "y", ",", "x", ",", "x_rev", ",", "len", "(", "x", ")", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "int", "(", "y", ")", ",", "x", ",", "x_rev", ",", "len", "(", "x", ")", "]", "\n", "\n"]]}