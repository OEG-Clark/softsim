{"home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.extract_target_vocab": [[29, 42], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.concept_cui_mapping": [[43, 53], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "triplets", "=", "sample", "[", "'population condition'", "]", "+", "sample", "[", "'intervention applied'", "]", "+", "sample", "[", "'outcome condition'", "]", "\n", "for", "triplet", "in", "triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.extract_synonyms": [[54, 62], ["nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set", "synonyms.append", "l.name"], "function", ["None"], ["", "def", "extract_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonyms", ".", "append", "(", "l", ".", "name", "(", ")", ")", "\n", "\n", "", "", "return", "list", "(", "set", "(", "synonyms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.display": [[64, 74], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.prepare_data_for_label_training": [[77, 174], ["collections.defaultdict", "range", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "list", "set", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower", "nltk.tokenize.word_tokenize", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "len", "len", "joint_training_with_label_synonyms.extract_synonyms", "new_word_seq.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower.lower", "len", "len", "len", "random.sample", "concept.lower.lower"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms"], ["", "def", "prepare_data_for_label_training", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", ";", "concepts", "=", "defaultdict", "(", "list", ")", "\n", "aspects", "=", "[", "'population condition'", ",", "'intervention applied'", ",", "'outcome condition'", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "concepts", "[", "aspect", "]", "+=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "concepts", "[", "aspect", "]", "=", "list", "(", "set", "(", "concepts", "[", "aspect", "]", ")", ")", "\n", "\n", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t", "input_text", "=", "concept", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "", "for", "it", "in", "range", "(", "4", ")", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t\t", "input_text", "=", "concept", ".", "lower", "(", ")", "\n", "input_word_seq", "=", "word_tokenize", "(", "input_text", ")", "\n", "new_word_seq", "=", "[", "]", "\n", "for", "word", "in", "input_word_seq", ":", "\n", "\t\t\t\t\t", "synonyms", "=", "extract_synonyms", "(", "word", ")", "\n", "if", "len", "(", "synonyms", ")", ">", "0", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "rd", ".", "sample", "(", "synonyms", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "word", "\n", "", "new_word_seq", ".", "append", "(", "rand_syn", ")", "\n", "\n", "", "input_text", "=", "' '", ".", "join", "(", "new_word_seq", ")", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "\n", "", "", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.prepare_data": [[178, 218], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.train": [[222, 276], ["joint_training_with_label_synonyms.prepare_data", "joint_training_with_label_synonyms.prepare_data_for_label_training", "print", "range", "model.train.train", "print", "random.sample", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "joint_training_with_label_synonyms.validate", "print", "numpy.mean", "range", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "random.random", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "all_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X_1", ",", "Mask_1", ",", "Y_p_1", ",", "Y_i_1", ",", "Y_o_1", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "X_2", ",", "Mask_2", ",", "Y_p_2", ",", "Y_i_2", ",", "Y_o_2", "=", "prepare_data_for_label_training", "(", "all_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "# X = np.vstack((X_1, X_2)); Mask = np.vstack((Mask_1, Mask_2)); Y_p = np.vstack((Y_p_1, Y_p_2)); Y_i = np.vstack((Y_i_1, Y_i_2)); Y_o = np.vstack((Y_o_1, Y_o_2))", "\n", "# shfl_idxs = rd.sample(range(X.shape[0]), X.shape[0])", "\n", "# X = X[shfl_idxs]; Mask = Mask[shfl_idxs]; Y_p = Y_p[shfl_idxs]; Y_i = Y_i[shfl_idxs]; Y_o = Y_o[shfl_idxs]", "\n", "print", "(", "'num docs: '", ",", "X_1", ".", "shape", "[", "0", "]", ",", "\" num of labels: \"", ",", "X_2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "best_f1_score", "=", "-", "100", ";", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X_1", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "if", "rd", ".", "random", "(", ")", "<", "0.5", "or", "ep", ">", "70", ":", "\n", "\t\t\t\t", "X", "=", "X_1", ";", "Mask", "=", "Mask_1", ";", "Y_p", "=", "Y_p_1", ";", "Y_i", "=", "Y_i_1", ";", "Y_o", "=", "Y_o_1", "\n", "", "else", ":", "\n", "\t\t\t\t", "X", "=", "X_2", ";", "Mask", "=", "Mask_2", ";", "Y_p", "=", "Y_p_2", ";", "Y_i", "=", "Y_i_2", ";", "Y_o", "=", "Y_o_2", "\n", "\n", "", "indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "batch_size", ")", "\n", "\n", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/synonym_full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.validate": [[278, 358], ["model.eval.eval", "joint_training_with_label_synonyms.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", ";", "pred_labels_mat_i", "=", "[", "]", ";", "pred_labels_mat_o", "=", "[", "]", ";", "i", "=", "0", "\n", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms.tune_threshold": [[360, 370], ["joint_training_with_label_synonyms.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.cnn_classifier_train.extract_target_vocab": [[27, 40], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.cnn_classifier_train.prepare_data": [[52, 100], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", "\n", "Y_p", "=", "[", "]", "\n", "Y_i", "=", "[", "]", "\n", "Y_o", "=", "[", "]", "\n", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", "\n", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", "\n", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", "\n", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", "\n", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.cnn_classifier_train.train": [[101, 144], ["cnn_classifier_train.prepare_data", "range", "model.train.train", "print", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "cnn_classifier_train.validate", "print", "numpy.mean", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "best_f1_score", "=", "-", "100", "\n", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/cnn_based/full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.cnn_classifier_train.validate": [[146, 229], ["model.eval.eval", "cnn_classifier_train.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", "\n", "pred_labels_mat_i", "=", "[", "]", "\n", "pred_labels_mat_o", "=", "[", "]", "\n", "\n", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.cnn_classifier_train.tune_threshold": [[231, 241], ["cnn_classifier_train.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.extract_target_vocab": [[29, 42], ["sorted", "enumerate", "list", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "sorted", "(", "list", "(", "set", "(", "vocab", ")", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.concept_cui_mapping": [[43, 53], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "triplets", "=", "sample", "[", "'population condition'", "]", "+", "sample", "[", "'intervention applied'", "]", "+", "sample", "[", "'outcome condition'", "]", "\n", "for", "triplet", "in", "triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.extract_synonyms": [[54, 62], ["nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set", "synonyms.append", "l.name"], "function", ["None"], ["", "def", "extract_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonyms", ".", "append", "(", "l", ".", "name", "(", ")", ")", "\n", "\n", "", "", "return", "list", "(", "set", "(", "synonyms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.display": [[64, 74], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.prepare_data_for_label_training": [[77, 180], ["collections.defaultdict", "range", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "list", "set", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower", "nltk.tokenize.word_tokenize", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "len", "len", "joint_training_with_label_synonyms_aspects.extract_synonyms", "new_word_seq.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower.lower", "len", "len", "len", "sentence_to_prepend_based_on_aspect[].lower", "random.sample", "concept.lower.lower", "sentence_to_prepend_based_on_aspect[].lower"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms"], ["", "def", "prepare_data_for_label_training", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", ";", "concepts", "=", "defaultdict", "(", "list", ")", "\n", "aspects", "=", "[", "'population condition'", ",", "'intervention applied'", ",", "'outcome condition'", "]", "\n", "\n", "sentence_to_prepend_based_on_aspect", "=", "{", "\n", "'population condition'", ":", "'The population of the trials was '", ",", "\n", "'intervention applied'", ":", "'The intervention applied was '", ",", "\n", "'outcome condition'", ":", "'The outcome of the study was '", "\n", "}", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "concepts", "[", "aspect", "]", "+=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "concepts", "[", "aspect", "]", "=", "list", "(", "set", "(", "concepts", "[", "aspect", "]", ")", ")", "\n", "\n", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t", "input_text", "=", "concept", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "", "for", "it", "in", "range", "(", "4", ")", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t\t", "input_text", "=", "concept", ".", "lower", "(", ")", "\n", "input_word_seq", "=", "word_tokenize", "(", "input_text", ")", "\n", "new_word_seq", "=", "[", "]", "\n", "for", "word", "in", "input_word_seq", ":", "\n", "\t\t\t\t\t", "synonyms", "=", "extract_synonyms", "(", "word", ")", "\n", "if", "len", "(", "synonyms", ")", ">", "0", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "rd", ".", "sample", "(", "synonyms", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "word", "\n", "", "new_word_seq", ".", "append", "(", "rand_syn", ")", "\n", "\n", "", "input_text", "=", "' '", ".", "join", "(", "new_word_seq", ")", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "\n", "", "", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.prepare_data": [[182, 222], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.train": [[226, 282], ["joint_training_with_label_synonyms_aspects.prepare_data", "joint_training_with_label_synonyms_aspects.prepare_data_for_label_training", "print", "range", "model.train.train", "print", "random.sample", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "joint_training_with_label_synonyms_aspects.validate", "print", "numpy.mean", "range", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "random.random", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "all_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X_1", ",", "Mask_1", ",", "Y_p_1", ",", "Y_i_1", ",", "Y_o_1", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "X_2", ",", "Mask_2", ",", "Y_p_2", ",", "Y_i_2", ",", "Y_o_2", "=", "prepare_data_for_label_training", "(", "all_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "# X = np.vstack((X_1, X_2)); Mask = np.vstack((Mask_1, Mask_2)); Y_p = np.vstack((Y_p_1, Y_p_2)); Y_i = np.vstack((Y_i_1, Y_i_2)); Y_o = np.vstack((Y_o_1, Y_o_2))", "\n", "# shfl_idxs = rd.sample(range(X.shape[0]), X.shape[0])", "\n", "# X = X[shfl_idxs]; Mask = Mask[shfl_idxs]; Y_p = Y_p[shfl_idxs]; Y_i = Y_i[shfl_idxs]; Y_o = Y_o[shfl_idxs]", "\n", "print", "(", "'num docs: '", ",", "X_1", ".", "shape", "[", "0", "]", ",", "\" num of labels: \"", ",", "X_2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "best_f1_score", "=", "-", "100", ";", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X_1", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "if", "rd", ".", "random", "(", ")", "<", "0.5", "or", "ep", ">", "70", ":", "\n", "\t\t\t\t", "X", "=", "X_1", ";", "Mask", "=", "Mask_1", ";", "Y_p", "=", "Y_p_1", ";", "Y_i", "=", "Y_i_1", ";", "Y_o", "=", "Y_o_1", "\n", "is_label_training", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t\t", "X", "=", "X_2", ";", "Mask", "=", "Mask_2", ";", "Y_p", "=", "Y_p_2", ";", "Y_i", "=", "Y_i_2", ";", "Y_o", "=", "Y_o_2", "\n", "is_label_training", "=", "True", "\n", "\n", "", "indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "batch_size", ")", "\n", "\n", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ",", "is_label_training", "=", "is_label_training", ",", "noise_weight", "=", "1.0", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/aspect_full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.validate": [[284, 363], ["model.eval.eval", "joint_training_with_label_synonyms_aspects.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", ";", "pred_labels_mat_i", "=", "[", "]", ";", "pred_labels_mat_o", "=", "[", "]", ";", "i", "=", "0", "\n", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects.tune_threshold": [[365, 375], ["joint_training_with_label_synonyms_aspects.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.extract_target_vocab": [[28, 41], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.concept_cui_mapping": [[42, 52], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "triplets", "=", "sample", "[", "'population condition'", "]", "+", "sample", "[", "'intervention applied'", "]", "+", "sample", "[", "'outcome condition'", "]", "\n", "for", "triplet", "in", "triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.display": [[53, 63], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.prepare_data_for_label_training": [[66, 115], ["collections.defaultdict", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "list", "set", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data_for_label_training", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", ";", "concepts", "=", "defaultdict", "(", "list", ")", "\n", "aspects", "=", "[", "'population condition'", ",", "'intervention applied'", ",", "'outcome condition'", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "concepts", "[", "aspect", "]", "+=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "concepts", "[", "aspect", "]", "=", "list", "(", "set", "(", "concepts", "[", "aspect", "]", ")", ")", "\n", "\n", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t", "input_text", "=", "concept", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.prepare_data": [[119, 159], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.train": [[163, 217], ["joint_training_labels_and_texts.prepare_data", "joint_training_labels_and_texts.prepare_data_for_label_training", "print", "range", "model.train.train", "print", "random.sample", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "joint_training_labels_and_texts.validate", "print", "numpy.mean", "range", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "random.random", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "all_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X_1", ",", "Mask_1", ",", "Y_p_1", ",", "Y_i_1", ",", "Y_o_1", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "X_2", ",", "Mask_2", ",", "Y_p_2", ",", "Y_i_2", ",", "Y_o_2", "=", "prepare_data_for_label_training", "(", "all_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "# X = np.vstack((X_1, X_2)); Mask = np.vstack((Mask_1, Mask_2)); Y_p = np.vstack((Y_p_1, Y_p_2)); Y_i = np.vstack((Y_i_1, Y_i_2)); Y_o = np.vstack((Y_o_1, Y_o_2))", "\n", "# shfl_idxs = rd.sample(range(X.shape[0]), X.shape[0])", "\n", "# X = X[shfl_idxs]; Mask = Mask[shfl_idxs]; Y_p = Y_p[shfl_idxs]; Y_i = Y_i[shfl_idxs]; Y_o = Y_o[shfl_idxs]", "\n", "print", "(", "'num docs: '", ",", "X_1", ".", "shape", "[", "0", "]", ",", "\" num of labels: \"", ",", "X_2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "best_f1_score", "=", "-", "100", ";", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X_1", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "if", "rd", ".", "random", "(", ")", "<", "0.5", "or", "ep", ">", "40", ":", "\n", "\t\t\t\t", "X", "=", "X_1", ";", "Mask", "=", "Mask_1", ";", "Y_p", "=", "Y_p_1", ";", "Y_i", "=", "Y_i_1", ";", "Y_o", "=", "Y_o_1", "\n", "", "else", ":", "\n", "\t\t\t\t", "X", "=", "X_2", ";", "Mask", "=", "Mask_2", ";", "Y_p", "=", "Y_p_2", ";", "Y_i", "=", "Y_i_2", ";", "Y_o", "=", "Y_o_2", "\n", "\n", "", "indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "batch_size", ")", "\n", "\n", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.validate": [[219, 299], ["model.eval.eval", "joint_training_labels_and_texts.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", ";", "pred_labels_mat_i", "=", "[", "]", ";", "pred_labels_mat_o", "=", "[", "]", ";", "i", "=", "0", "\n", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_labels_and_texts.tune_threshold": [[301, 311], ["joint_training_labels_and_texts.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.extract_target_vocab": [[29, 42], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.concept_cui_mapping": [[43, 53], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "triplets", "=", "sample", "[", "'population condition'", "]", "+", "sample", "[", "'intervention applied'", "]", "+", "sample", "[", "'outcome condition'", "]", "\n", "for", "triplet", "in", "triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.extract_synonyms": [[54, 62], ["nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set", "synonyms.append", "l.name"], "function", ["None"], ["", "def", "extract_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonyms", ".", "append", "(", "l", ".", "name", "(", ")", ")", "\n", "\n", "", "", "return", "list", "(", "set", "(", "synonyms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.display": [[64, 74], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.prepare_data_for_label_training": [[77, 180], ["collections.defaultdict", "range", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "list", "set", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower", "nltk.tokenize.word_tokenize", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "len", "len", "joint_training_with_label_synonyms_aspects_no_sentences.extract_synonyms", "new_word_seq.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower.lower", "len", "len", "len", "sentence_to_prepend_based_on_aspect[].lower", "random.sample", "concept.lower.lower", "sentence_to_prepend_based_on_aspect[].lower"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms"], ["", "def", "prepare_data_for_label_training", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", ";", "concepts", "=", "defaultdict", "(", "list", ")", "\n", "aspects", "=", "[", "'population condition'", ",", "'intervention applied'", ",", "'outcome condition'", "]", "\n", "\n", "sentence_to_prepend_based_on_aspect", "=", "{", "\n", "'population condition'", ":", "'population condition'", ",", "\n", "'intervention applied'", ":", "'intervention applied'", ",", "\n", "'outcome condition'", ":", "'outcome condition'", "\n", "}", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "concepts", "[", "aspect", "]", "+=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "concepts", "[", "aspect", "]", "=", "list", "(", "set", "(", "concepts", "[", "aspect", "]", ")", ")", "\n", "\n", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t", "input_text", "=", "concept", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "", "for", "it", "in", "range", "(", "4", ")", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t\t", "input_text", "=", "concept", ".", "lower", "(", ")", "\n", "input_word_seq", "=", "word_tokenize", "(", "input_text", ")", "\n", "new_word_seq", "=", "[", "]", "\n", "for", "word", "in", "input_word_seq", ":", "\n", "\t\t\t\t\t", "synonyms", "=", "extract_synonyms", "(", "word", ")", "\n", "if", "len", "(", "synonyms", ")", ">", "0", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "rd", ".", "sample", "(", "synonyms", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "word", "\n", "", "new_word_seq", ".", "append", "(", "rand_syn", ")", "\n", "\n", "", "input_text", "=", "' '", ".", "join", "(", "new_word_seq", ")", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "\n", "", "", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.prepare_data": [[182, 222], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.train": [[226, 282], ["joint_training_with_label_synonyms_aspects_no_sentences.prepare_data", "joint_training_with_label_synonyms_aspects_no_sentences.prepare_data_for_label_training", "print", "range", "model.train.train", "print", "random.sample", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "joint_training_with_label_synonyms_aspects_no_sentences.validate", "print", "numpy.mean", "range", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "random.random", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "all_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X_1", ",", "Mask_1", ",", "Y_p_1", ",", "Y_i_1", ",", "Y_o_1", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "X_2", ",", "Mask_2", ",", "Y_p_2", ",", "Y_i_2", ",", "Y_o_2", "=", "prepare_data_for_label_training", "(", "all_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "# X = np.vstack((X_1, X_2)); Mask = np.vstack((Mask_1, Mask_2)); Y_p = np.vstack((Y_p_1, Y_p_2)); Y_i = np.vstack((Y_i_1, Y_i_2)); Y_o = np.vstack((Y_o_1, Y_o_2))", "\n", "# shfl_idxs = rd.sample(range(X.shape[0]), X.shape[0])", "\n", "# X = X[shfl_idxs]; Mask = Mask[shfl_idxs]; Y_p = Y_p[shfl_idxs]; Y_i = Y_i[shfl_idxs]; Y_o = Y_o[shfl_idxs]", "\n", "print", "(", "'num docs: '", ",", "X_1", ".", "shape", "[", "0", "]", ",", "\" num of labels: \"", ",", "X_2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "best_f1_score", "=", "-", "100", ";", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X_1", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "if", "rd", ".", "random", "(", ")", "<", "0.5", "or", "ep", ">", "70", ":", "\n", "\t\t\t\t", "X", "=", "X_1", ";", "Mask", "=", "Mask_1", ";", "Y_p", "=", "Y_p_1", ";", "Y_i", "=", "Y_i_1", ";", "Y_o", "=", "Y_o_1", "\n", "is_label_training", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t\t", "X", "=", "X_2", ";", "Mask", "=", "Mask_2", ";", "Y_p", "=", "Y_p_2", ";", "Y_i", "=", "Y_i_2", ";", "Y_o", "=", "Y_o_2", "\n", "is_label_training", "=", "True", "\n", "\n", "", "indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "batch_size", ")", "\n", "\n", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ",", "is_label_training", "=", "is_label_training", ",", "noise_weight", "=", "0.0", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/aspect_full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.validate": [[284, 363], ["model.eval.eval", "joint_training_with_label_synonyms_aspects_no_sentences.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", ";", "pred_labels_mat_i", "=", "[", "]", ";", "pred_labels_mat_o", "=", "[", "]", ";", "i", "=", "0", "\n", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_sentences.tune_threshold": [[365, 375], ["joint_training_with_label_synonyms_aspects_no_sentences.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.extract_target_vocab": [[29, 42], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ",", "aspect", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "aspect", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "# vocab += [triplet[2] for triplet in sample['intervention applied'] if triplet[2] != \"NULL\"]", "\n", "# vocab += [triplet[2] for triplet in sample['outcome condition'] if triplet[2] != \"NULL\"]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.concept_cui_mapping": [[44, 54], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ",", "aspect", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "all_triplets", "=", "sample", "[", "aspect", "]", "\n", "for", "triplet", "in", "all_triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.convert_to_doc_labels": [[55, 70], ["len", "print", "numpy.zeros", "numpy.zeros", "enumerate", "enumerate", "list", "len", "numpy.max", "numpy.max", "numpy.min", "set", "list", "len", "len", "cui_to_idx.values"], "function", ["None"], ["", "def", "convert_to_doc_labels", "(", "Y", ",", "O", ",", "doc_idx", ",", "concepts", ",", "concept_to_cui", ",", "cui_to_idx", ")", ":", "\n", "\t", "num_docs", "=", "len", "(", "list", "(", "set", "(", "doc_idx", ")", ")", ")", "\n", "print", "(", "\"num docs: \"", ",", "num_docs", ",", "\" num cuis: \"", ",", "len", "(", "cui_to_idx", ")", ",", "\" max cui idx: \"", ",", "np", ".", "max", "(", "list", "(", "cui_to_idx", ".", "values", "(", ")", ")", ")", ",", "\" max doc idx: \"", ",", "np", ".", "max", "(", "doc_idx", ")", ",", "\" min doc idx: \"", ",", "np", ".", "min", "(", "doc_idx", ")", ")", "\n", "true_label_matrix", "=", "np", ".", "zeros", "(", "(", "num_docs", ",", "len", "(", "cui_to_idx", ")", ")", ")", "\n", "pred_label_matrix", "=", "np", ".", "zeros", "(", "(", "num_docs", ",", "len", "(", "cui_to_idx", ")", ")", ")", "\n", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "Y", ")", ":", "\n", "\t\t", "if", "y", "==", "1", ":", "\n", "\t\t\t", "true_label_matrix", "[", "doc_idx", "[", "i", "]", ",", "cui_to_idx", "[", "concept_to_cui", "[", "concepts", "[", "i", "]", "]", "]", "]", "=", "1", "\n", "\n", "", "", "for", "i", ",", "y", "in", "enumerate", "(", "O", ")", ":", "\n", "\t\t", "if", "y", "==", "1", ":", "\n", "\t\t\t", "pred_label_matrix", "[", "doc_idx", "[", "i", "]", ",", "cui_to_idx", "[", "concept_to_cui", "[", "concepts", "[", "i", "]", "]", "]", "]", "=", "1", "\n", "\n", "", "", "return", "true_label_matrix", ",", "pred_label_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.prepare_data": [[82, 164], ["print", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "random.sample", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "numpy.zeros", "numpy.sum", "range", "tokenizer.tokenize", "len", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "np.vstack.append", "np.vstack.append", "np.vstack.append", "doc_idx.append", "concepts.append", "print", "random.sample", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "np.vstack.append", "np.vstack.append", "np.vstack.append", "doc_idx.append", "concepts.append", "len", "numpy.sum", "len", "len", "tokenizer.tokenize", "len", "len", "list", "tokenizer.tokenize", "input_text.lower", "len", "len", "list", "concept_to_cui.keys", "concept_to_cui.keys", "len", "len", "len", "label.lower", "concept_to_cui.keys", "label.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "for_test", "=", "False", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Xt", "=", "[", "]", ";", "Y", "=", "[", "]", ";", "M", "=", "[", "]", ";", "Mt", "=", "[", "]", ";", "doc_idx", "=", "[", "]", ";", "concepts", "=", "[", "]", ";", "i", "=", "-", "1", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "\n", "src_idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "src_idx_seq", ")", "]", "=", "src_idx_seq", "\n", "\n", "# input padding mask ", "\n", "inp_mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "inp_mask", "[", "0", ":", "len", "(", "src_idx_seq", ")", "]", "=", "1", "\n", "\n", "positive_labels", "=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "if", "len", "(", "positive_labels", ")", ">", "0", ":", "\n", "\t\t\t", "i", "+=", "1", "\n", "\n", "", "for", "label", "in", "positive_labels", ":", "\n", "\t\t\t", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "label", ".", "lower", "(", ")", ")", "[", "0", ":", "10", "]", "\n", "tgt_idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "tgt_seq", "=", "np", ".", "zeros", "(", "10", ")", "\n", "tgt_seq", "[", "0", ":", "len", "(", "tgt_idx_seq", ")", "]", "=", "tgt_idx_seq", "\n", "Xt", ".", "append", "(", "tgt_seq", ")", "\n", "\n", "# input padding mask ", "\n", "tgt_mask", "=", "np", ".", "zeros", "(", "10", ")", "\n", "tgt_mask", "[", "0", ":", "len", "(", "tgt_idx_seq", ")", "]", "=", "1", "\n", "Mt", ".", "append", "(", "tgt_mask", ")", "\n", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "M", ".", "append", "(", "inp_mask", ")", "\n", "Y", ".", "append", "(", "1", ")", "\n", "doc_idx", ".", "append", "(", "i", ")", "\n", "concepts", ".", "append", "(", "label", ")", "\n", "\n", "", "if", "for_test", ":", "\n", "\t\t\t", "negative_labels", "=", "[", "label", "for", "label", "in", "list", "(", "concept_to_cui", ".", "keys", "(", ")", ")", "if", "label", "not", "in", "positive_labels", "]", "\n", "print", "(", "\"size of concept to cui dict: \"", ",", "len", "(", "concept_to_cui", ".", "keys", "(", ")", ")", ",", "\"length of negative_labels: \"", ",", "len", "(", "negative_labels", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t", "negative_labels", "=", "rd", ".", "sample", "(", "list", "(", "concept_to_cui", ".", "keys", "(", ")", ")", ",", "100", "*", "len", "(", "positive_labels", ")", ")", "\n", "\n", "", "for", "label", "in", "negative_labels", ":", "\n", "\t\t\t", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "label", ".", "lower", "(", ")", ")", "[", "0", ":", "10", "]", "\n", "tgt_idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "tgt_seq", "=", "np", ".", "zeros", "(", "10", ")", "\n", "tgt_seq", "[", "0", ":", "len", "(", "tgt_idx_seq", ")", "]", "=", "tgt_idx_seq", "\n", "Xt", ".", "append", "(", "tgt_seq", ")", "\n", "\n", "# input padding mask ", "\n", "tgt_mask", "=", "np", ".", "zeros", "(", "10", ")", "\n", "tgt_mask", "[", "0", ":", "len", "(", "tgt_idx_seq", ")", "]", "=", "1", "\n", "Mt", ".", "append", "(", "tgt_mask", ")", "\n", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "M", ".", "append", "(", "inp_mask", ")", "\n", "Y", ".", "append", "(", "0", ")", "\n", "doc_idx", ".", "append", "(", "i", ")", "\n", "concepts", ".", "append", "(", "label", ")", "\n", "\n", "", "", "print", "(", "\"Y-1: \"", ",", "np", ".", "sum", "(", "Y", ")", ",", "\" Y-0\"", ",", "len", "(", "Y", ")", "-", "np", ".", "sum", "(", "Y", ")", ")", "\n", "\n", "\n", "X", "=", "np", ".", "vstack", "(", "X", ")", "\n", "Xt", "=", "np", ".", "vstack", "(", "Xt", ")", "\n", "Y", "=", "np", ".", "vstack", "(", "Y", ")", "\n", "M", "=", "np", ".", "vstack", "(", "M", ")", "\n", "Mt", "=", "np", ".", "vstack", "(", "Mt", ")", "\n", "\n", "shuffled_indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "X", ".", "shape", "[", "0", "]", ")", "\n", "X", "=", "X", "[", "shuffled_indices", "]", "\n", "Xt", "=", "Xt", "[", "shuffled_indices", "]", "\n", "Y", "=", "Y", "[", "shuffled_indices", "]", "\n", "M", "=", "M", "[", "shuffled_indices", "]", "\n", "Mt", "=", "Mt", "[", "shuffled_indices", "]", "\n", "# print (\"before: \", doc_idx)", "\n", "doc_idx", "=", "[", "doc_idx", "[", "idx", "]", "for", "idx", "in", "shuffled_indices", "]", "\n", "# print (\"after: \", doc_idx)", "\n", "concepts", "=", "[", "concepts", "[", "idx", "]", "for", "idx", "in", "shuffled_indices", "]", "\n", "\n", "return", "X", ",", "Xt", ",", "Y", ",", "M", ",", "Mt", ",", "doc_idx", ",", "concepts", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.train": [[166, 211], ["transfer_labels_bert_train.prepare_data", "print", "print", "range", "model.train.train", "print", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "criterion", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "transfer_labels_bert_train.validate", "print", "numpy.mean", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "torch.mean.data.cpu"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X", ",", "Xt", ",", "Y", ",", "M", ",", "Mt", ",", "_", ",", "_", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "print", "(", "\"Entered training function ...\"", ")", "\n", "print", "(", "\"X shape: \"", ",", "X", ".", "shape", ",", "\" Xt Shape: \"", ",", "Xt", ".", "shape", ",", "\" Y Shape: \"", ",", "Y", ".", "shape", ",", "\" M Shape: \"", ",", "M", ".", "shape", ",", "\" Mt shape: \"", ",", "Mt", ".", "shape", ")", "\n", "\n", "best_f1_score", "=", "-", "100", "\n", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "x", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "m", "=", "torch", ".", "tensor", "(", "M", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "xt", "=", "torch", ".", "tensor", "(", "Xt", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "mt", "=", "torch", ".", "tensor", "(", "Mt", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "y", "=", "torch", ".", "tensor", "(", "Y", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "o", "=", "model", "(", "x", ",", "m", ",", "xt", ",", "mt", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "criterion", "(", "o", ",", "y", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/'", "+", "aspect", "+", "'_'", "+", "'full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.validate": [[213, 257], ["model.eval.eval", "transfer_labels_bert_train.prepare_data", "numpy.concatenate", "transfer_labels_bert_train.convert_to_doc_labels", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "o.data.to().numpy().flatten.data.to().numpy().flatten", "np.concatenate.append", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "o.data.to().numpy().flatten.data.to().numpy", "o.data.to().numpy().flatten.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.convert_to_doc_labels", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ",", "test", "=", "False", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Xt", ",", "Y", ",", "M", ",", "Mt", ",", "doc_idx", ",", "concepts", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "for_test", "=", "test", ")", "\n", "# print (\"Entered test function ...\")", "\n", "# print (\"X shape: \", X.shape, \" Xt Shape: \", Xt.shape, \" Y Shape: \", Y.shape, \" M Shape: \", M.shape, \" Mt shape: \", Mt.shape)", "\n", "\n", "O", "=", "[", "]", ";", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "x", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "m", "=", "torch", ".", "tensor", "(", "M", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "xt", "=", "torch", ".", "tensor", "(", "Xt", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "mt", "=", "torch", ".", "tensor", "(", "Mt", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "o", "=", "model", "(", "x", ",", "m", ",", "xt", ",", "mt", ")", "\n", "o", "=", "F", ".", "sigmoid", "(", "o", ")", "\n", "\n", "o", "[", "o", ">=", "threshold", "]", "=", "1", "\n", "o", "[", "o", "<", "threshold", "]", "=", "0", "\n", "\n", "o", "=", "o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "O", ".", "append", "(", "o", ")", "\n", "i", "+=", "4", "\n", "print", "(", "i", ",", "\"/\"", ",", "X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "O", "=", "np", ".", "concatenate", "(", "O", ")", "\n", "\n", "\n", "Y", ",", "O", "=", "convert_to_doc_labels", "(", "Y", ",", "O", ",", "doc_idx", ",", "concepts", ",", "concept_to_cui", ",", "cui_to_idx", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro", ",", "f1_score_macro", "=", "f1_score", "(", "Y", ",", "O", ")", "\n", "pr_score_micro", ",", "pr_score_macro", "=", "precision_score", "(", "Y", ",", "O", ")", "\n", "re_score_micro", ",", "re_score_macro", "=", "recall_score", "(", "Y", ",", "O", ")", "\n", "results", "[", "'f1_score_micro'", "]", "=", "f1_score_micro", "\n", "results", "[", "'f1_score_macro'", "]", "=", "f1_score_macro", "\n", "results", "[", "'pr_score_micro'", "]", "=", "pr_score_micro", "\n", "results", "[", "'pr_score_macro'", "]", "=", "pr_score_macro", "\n", "results", "[", "'re_score_micro'", "]", "=", "re_score_micro", "\n", "results", "[", "'re_score_macro'", "]", "=", "re_score_macro", "\n", "\n", "# display(results)", "\n", "\n", "return", "f1_score_micro", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.transfer_labels_bert_train.tune_threshold": [[259, 269], ["transfer_labels_bert_train.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.extract_target_vocab": [[27, 40], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.display": [[41, 51], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.prepare_data": [[52, 100], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", "\n", "Y_p", "=", "[", "]", "\n", "Y_i", "=", "[", "]", "\n", "Y_o", "=", "[", "]", "\n", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", "\n", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", "\n", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", "\n", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", "\n", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.train": [[101, 146], ["bert_classifier_train.prepare_data", "range", "model.train.train", "print", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "bert_classifier_train.validate", "print", "numpy.mean", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\n", "\n", "\t", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "best_f1_score", "=", "-", "100", "\n", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "i", ":", "i", "+", "batch_size", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.validate": [[148, 231], ["model.eval.eval", "bert_classifier_train.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", "\n", "pred_labels_mat_i", "=", "[", "]", "\n", "pred_labels_mat_o", "=", "[", "]", "\n", "\n", "i", "=", "0", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.bert_classifier_train.tune_threshold": [[233, 243], ["bert_classifier_train.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_target_vocab": [[29, 42], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.concept_cui_mapping": [[43, 53], ["None"], "function", ["None"], ["", "def", "concept_cui_mapping", "(", "data", ")", ":", "\n", "\t", "cui_to_concept", "=", "{", "}", ";", "concept_to_cui", "=", "{", "}", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "triplets", "=", "sample", "[", "'population condition'", "]", "+", "sample", "[", "'intervention applied'", "]", "+", "sample", "[", "'outcome condition'", "]", "\n", "for", "triplet", "in", "triplets", ":", "\n", "\t\t\t", "if", "triplet", "[", "1", "]", "!=", "'NULL'", "and", "triplet", "[", "2", "]", "!=", "'NULL'", ":", "\n", "\t\t\t\t", "concept_to_cui", "[", "triplet", "[", "1", "]", "]", "=", "triplet", "[", "2", "]", "\n", "cui_to_concept", "[", "triplet", "[", "2", "]", "]", "=", "triplet", "[", "1", "]", "\n", "\n", "", "", "", "return", "cui_to_concept", ",", "concept_to_cui", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms": [[54, 62], ["nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set", "synonyms.append", "l.name"], "function", ["None"], ["", "def", "extract_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonyms", ".", "append", "(", "l", ".", "name", "(", ")", ")", "\n", "\n", "", "", "return", "list", "(", "set", "(", "synonyms", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.display": [[64, 74], ["print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "display", "(", "results", ")", ":", "\n", "\t", "print", "(", "\"F1 Score Micro Population: \"", ",", "f1_score_micro_p", ")", "\n", "print", "(", "\"F1 Score Macro Population: \"", ",", "f1_score_macro_p", ")", "\n", "print", "(", "\"F1 Score Micro intervention: \"", ",", "f1_score_micro_i", ")", "\n", "print", "(", "\"F1 Score Macro intervention: \"", ",", "f1_score_macro_i", ")", "\n", "print", "(", "\"F1 Score Micro Outcome: \"", ",", "f1_score_micro_o", ")", "\n", "print", "(", "\"F1 Score Macro Outcome: \"", ",", "f1_score_macro_o", ")", "\n", "\n", "print", "(", "\"F1 Score Macro: \"", ",", "(", "f1_score_macro_p", "+", "f1_score_macro_i", "+", "f1_score_macro_o", ")", "/", "3.0", ")", "\n", "print", "(", "\"F1 Score Micro: \"", ",", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training": [[77, 180], ["collections.defaultdict", "range", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "list", "set", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower", "nltk.tokenize.word_tokenize", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "len", "len", "joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms", "new_word_seq.append", "tokenizer.tokenize", "len", "len", "len", "concept.lower.lower", "len", "len", "len", "sentence_to_prepend_based_on_aspect[].lower", "random.sample", "concept.lower.lower", "sentence_to_prepend_based_on_aspect[].lower"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.extract_synonyms"], ["", "def", "prepare_data_for_label_training", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", ";", "concepts", "=", "defaultdict", "(", "list", ")", "\n", "aspects", "=", "[", "'population condition'", ",", "'intervention applied'", ",", "'outcome condition'", "]", "\n", "\n", "sentence_to_prepend_based_on_aspect", "=", "{", "\n", "'population condition'", ":", "'The population of the trials was '", ",", "\n", "'intervention applied'", ":", "'The intervention applied was '", ",", "\n", "'outcome condition'", ":", "'The outcome of the study was '", "\n", "}", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "concepts", "[", "aspect", "]", "+=", "[", "triplet", "[", "1", "]", "for", "triplet", "in", "article", "[", "aspect", "]", "if", "triplet", "[", "1", "]", "!=", "\"NULL\"", "]", "\n", "\n", "", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "concepts", "[", "aspect", "]", "=", "list", "(", "set", "(", "concepts", "[", "aspect", "]", ")", ")", "\n", "\n", "", "for", "aspect", "in", "aspects", ":", "\n", "\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t", "input_text", "=", "concept", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "", "for", "it", "in", "range", "(", "4", ")", ":", "\n", "\t\t", "for", "aspect", "in", "aspects", ":", "\n", "\t\t\t", "for", "concept", "in", "concepts", "[", "aspect", "]", ":", "\n", "\t\t\t\t", "input_text", "=", "concept", ".", "lower", "(", ")", "\n", "input_word_seq", "=", "word_tokenize", "(", "input_text", ")", "\n", "new_word_seq", "=", "[", "]", "\n", "for", "word", "in", "input_word_seq", ":", "\n", "\t\t\t\t\t", "synonyms", "=", "extract_synonyms", "(", "word", ")", "\n", "if", "len", "(", "synonyms", ")", ">", "0", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "rd", ".", "sample", "(", "synonyms", ",", "1", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "rand_syn", "=", "word", "\n", "", "new_word_seq", ".", "append", "(", "rand_syn", ")", "\n", "\n", "", "input_text", "=", "' '", ".", "join", "(", "new_word_seq", ")", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "sentence_to_prepend_based_on_aspect", "[", "aspect", "]", ".", "lower", "(", ")", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'population condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'intervention applied'", ":", "\n", "\t\t\t\t\t", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "if", "aspect", "==", "'outcome condition'", ":", "\n", "\t\t\t\t\t", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "concept_to_cui", "[", "concept", "]", "]", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "\n", "", "", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data": [[182, 222], ["numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "numpy.vstack", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "numpy.zeros", "np.vstack.append", "tokenizer.tokenize", "len", "len", "len", "len", "len", "input_text.lower"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "X", "=", "[", "]", ";", "Y_p", "=", "[", "]", ";", "Y_i", "=", "[", "]", ";", "Y_o", "=", "[", "]", ";", "Mask", "=", "[", "]", "\n", "\n", "for", "article", "in", "data", ":", "\n", "\t\t", "input_text", "=", "article", "[", "'population text'", "]", "+", "article", "[", "'intervention text'", "]", "+", "article", "[", "'outcome text'", "]", "\n", "tokenized_text", "=", "tokenizer", ".", "tokenize", "(", "'[CLS] '", "+", "input_text", ".", "lower", "(", ")", ")", "[", "0", ":", "512", "]", "\n", "idx_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "src_seq", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "src_seq", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "idx_seq", "\n", "X", ".", "append", "(", "src_seq", ")", "\n", "\n", "# input padding mask ", "\n", "mask", "=", "np", ".", "zeros", "(", "max_seq_len", ")", "\n", "mask", "[", "0", ":", "len", "(", "idx_seq", ")", "]", "=", "1", "\n", "Mask", ".", "append", "(", "mask", ")", "\n", "\n", "# population target", "\n", "tgt_seq_p", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_p", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "p_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_p", "[", "tgt_idx_p", "]", "=", "1", "\n", "Y_p", ".", "append", "(", "tgt_seq_p", ")", "\n", "\n", "# intervention target", "\n", "tgt_seq_i", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_i", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "i_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_i", "[", "tgt_idx_i", "]", "=", "1", "\n", "Y_i", ".", "append", "(", "tgt_seq_i", ")", "\n", "\n", "# outcome target", "\n", "tgt_seq_o", "=", "np", ".", "zeros", "(", "len", "(", "cui_to_idx", ")", ")", "\n", "tgt_idx_o", "=", "[", "cui_to_idx", "[", "triplet", "[", "2", "]", "]", "for", "triplet", "in", "article", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "!=", "\"NULL\"", "\n", "and", "o_label_cnt", "[", "triplet", "[", "2", "]", "]", ">", "0", "]", "\n", "tgt_seq_o", "[", "tgt_idx_o", "]", "=", "1", "\n", "Y_o", ".", "append", "(", "tgt_seq_o", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", ";", "Y_p", "=", "np", ".", "vstack", "(", "Y_p", ")", ";", "Y_i", "=", "np", ".", "vstack", "(", "Y_i", ")", ";", "Y_o", "=", "np", ".", "vstack", "(", "Y_o", ")", ";", "Mask", "=", "np", ".", "vstack", "(", "Mask", ")", "\n", "\n", "return", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train": [[226, 282], ["joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "print", "range", "model.train.train", "print", "random.sample", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.train.", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "print", "optimizer.zero_grad", "torch.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "list_losses.append", "joint_training_with_label_synonyms_aspects_no_noise.validate", "print", "numpy.mean", "range", "model.train.parameters", "torch.mean.data.cpu().numpy", "torch.save", "torch.save", "torch.save", "random.random", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.train.state_dict", "criterion", "torch.mean.data.cpu", "criterion", "criterion"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data_for_label_training", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.train", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "train", "(", "model", ",", "train_data", ",", "val_data", ",", "all_data", ",", "criterion", ",", "cui_to_idx", ",", "idx_to_cui", ",", "tokenizer", ")", ":", "\n", "\t", "X_1", ",", "Mask_1", ",", "Y_p_1", ",", "Y_i_1", ",", "Y_o_1", "=", "prepare_data", "(", "train_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "X_2", ",", "Mask_2", ",", "Y_p_2", ",", "Y_i_2", ",", "Y_o_2", "=", "prepare_data_for_label_training", "(", "all_data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "# X = np.vstack((X_1, X_2)); Mask = np.vstack((Mask_1, Mask_2)); Y_p = np.vstack((Y_p_1, Y_p_2)); Y_i = np.vstack((Y_i_1, Y_i_2)); Y_o = np.vstack((Y_o_1, Y_o_2))", "\n", "# shfl_idxs = rd.sample(range(X.shape[0]), X.shape[0])", "\n", "# X = X[shfl_idxs]; Mask = Mask[shfl_idxs]; Y_p = Y_p[shfl_idxs]; Y_i = Y_i[shfl_idxs]; Y_o = Y_o[shfl_idxs]", "\n", "print", "(", "'num docs: '", ",", "X_1", ".", "shape", "[", "0", "]", ",", "\" num of labels: \"", ",", "X_2", ".", "shape", "[", "0", "]", ")", "\n", "\n", "best_f1_score", "=", "-", "100", ";", "list_losses", "=", "[", "]", "\n", "for", "ep", "in", "range", "(", "max_epochs", ")", ":", "\n", "\t\t", "model", "=", "model", ".", "train", "(", ")", "\n", "i", "=", "0", "\n", "while", "i", "<", "X_1", ".", "shape", "[", "0", "]", ":", "\n", "\t\t\t", "if", "rd", ".", "random", "(", ")", "<", "0.5", "or", "ep", ">", "70", ":", "\n", "\t\t\t\t", "X", "=", "X_1", ";", "Mask", "=", "Mask_1", ";", "Y_p", "=", "Y_p_1", ";", "Y_i", "=", "Y_i_1", ";", "Y_o", "=", "Y_o_1", "\n", "is_label_training", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t\t", "X", "=", "X_2", ";", "Mask", "=", "Mask_2", ";", "Y_p", "=", "Y_p_2", ";", "Y_i", "=", "Y_i_2", ";", "Y_o", "=", "Y_o_2", "\n", "is_label_training", "=", "True", "\n", "\n", "", "indices", "=", "rd", ".", "sample", "(", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ",", "batch_size", ")", "\n", "\n", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "target_p", "=", "torch", ".", "tensor", "(", "Y_p", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_i", "=", "torch", ".", "tensor", "(", "Y_i", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "target_o", "=", "torch", ".", "tensor", "(", "Y_o", "[", "indices", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output_p", ",", "output_i", ",", "output_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ",", "is_label_training", "=", "is_label_training", ",", "noise_weight", "=", "0.0", ")", "\n", "\n", "# computing the loss over the prediction", "\n", "loss", "=", "(", "criterion", "(", "output_p", ",", "target_p", ")", "+", "criterion", "(", "output_i", ",", "target_i", ")", "+", "criterion", "(", "output_o", ",", "target_o", ")", ")", "*", "1", "/", "3.0", "\n", "loss", "=", "torch", ".", "sum", "(", "loss", ",", "dim", "=", "(", "1", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "print", "(", "\"loss: \"", ",", "loss", ")", "\n", "\n", "# back-propagation", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "list_losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "i", "+=", "batch_size", "\n", "\n", "", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "val_data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "'../saved_models/bert_based/english_labels/aspect_full_model.pt'", ")", "\n", "# torch.save(model.bert.state_dict(), '../saved_models/bert_based/bert_retrained_mesh_model.pt')", "\n", "best_f1_score", "=", "f1_score_curr", "\n", "\n", "", "", "print", "(", "\"Loss after epochs \"", ",", "ep", ",", "\":  \"", ",", "np", ".", "mean", "(", "list_losses", ")", ")", "\n", "list_losses", "=", "[", "]", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate": [[284, 363], ["model.eval.eval", "joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "numpy.vstack", "numpy.vstack", "numpy.vstack", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "eval.eval.f1_score", "eval.eval.precision_score", "eval.eval.recall_score", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.eval.", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "predict_p.data.to().numpy.data.to().numpy", "predict_i.data.to().numpy.data.to().numpy", "predict_o.data.to().numpy.data.to().numpy", "np.vstack.append", "np.vstack.append", "np.vstack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predict_p.data.to().numpy.data.to", "predict_i.data.to().numpy.data.to", "predict_o.data.to().numpy.data.to"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.prepare_data", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", ":", "\n", "\t", "model", "=", "model", ".", "eval", "(", ")", "\n", "X", ",", "Mask", ",", "Y_p", ",", "Y_i", ",", "Y_o", "=", "prepare_data", "(", "data", ",", "cui_to_idx", ",", "tokenizer", ")", "\n", "\n", "pred_labels_mat_p", "=", "[", "]", ";", "pred_labels_mat_i", "=", "[", "]", ";", "pred_labels_mat_o", "=", "[", "]", ";", "i", "=", "0", "\n", "\n", "while", "i", "<", "X", ".", "shape", "[", "0", "]", ":", "\n", "\t\t", "input_idx_seq", "=", "torch", ".", "tensor", "(", "X", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "Mask", "[", "i", ":", "i", "+", "4", "]", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "predict_p", ",", "predict_i", ",", "predict_o", "=", "model", "(", "input_idx_seq", ",", "input_mask", ")", "\n", "\n", "predict_p", "=", "F", ".", "sigmoid", "(", "predict_p", ")", "\n", "predict_i", "=", "F", ".", "sigmoid", "(", "predict_i", ")", "\n", "predict_o", "=", "F", ".", "sigmoid", "(", "predict_o", ")", "\n", "\n", "predict_p", "[", "predict_p", ">=", "threshold", "]", "=", "1", "\n", "predict_p", "[", "predict_p", "<", "threshold", "]", "=", "0", "\n", "predict_i", "[", "predict_i", ">=", "threshold", "]", "=", "1", "\n", "predict_i", "[", "predict_i", "<", "threshold", "]", "=", "0", "\n", "predict_o", "[", "predict_o", ">=", "threshold", "]", "=", "1", "\n", "predict_o", "[", "predict_o", "<", "threshold", "]", "=", "0", "\n", "\n", "predict_p", "=", "predict_p", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_i", "=", "predict_i", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "predict_o", "=", "predict_o", ".", "data", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", "\n", "\n", "# target_p = Y_p[i:i+4]", "\n", "# target_i = Y_i[i:i+4]", "\n", "# target_o = Y_o[i:i+4]", "\n", "\n", "pred_labels_mat_p", ".", "append", "(", "predict_p", ")", "\n", "pred_labels_mat_i", ".", "append", "(", "predict_i", ")", "\n", "pred_labels_mat_o", ".", "append", "(", "predict_o", ")", "\n", "\n", "i", "+=", "4", "\n", "\n", "# true_labels_mat_p = np.vstack(true_labels_mat_p)", "\n", "# true_labels_mat_i = np.vstack(true_labels_mat_i)", "\n", "# true_labels_mat_o = np.vstack(true_labels_mat_o)", "\n", "\n", "", "pred_labels_mat_p", "=", "np", ".", "vstack", "(", "pred_labels_mat_p", ")", "\n", "pred_labels_mat_i", "=", "np", ".", "vstack", "(", "pred_labels_mat_i", ")", "\n", "pred_labels_mat_o", "=", "np", ".", "vstack", "(", "pred_labels_mat_o", ")", "\n", "\n", "results", "=", "{", "}", "\n", "f1_score_micro_p", ",", "f1_score_macro_p", "=", "f1_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "pr_score_micro_p", ",", "pr_score_macro_p", "=", "precision_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "re_score_micro_p", ",", "re_score_macro_p", "=", "recall_score", "(", "Y_p", ",", "pred_labels_mat_p", ")", "\n", "results", "[", "'f1_score_micro_p'", "]", "=", "f1_score_micro_p", "\n", "results", "[", "'f1_score_macro_p'", "]", "=", "f1_score_macro_p", "\n", "results", "[", "'pr_score_micro_p'", "]", "=", "pr_score_micro_p", "\n", "results", "[", "'pr_score_macro_p'", "]", "=", "pr_score_macro_p", "\n", "results", "[", "'re_score_micro_p'", "]", "=", "re_score_micro_p", "\n", "results", "[", "'re_score_macro_p'", "]", "=", "re_score_macro_p", "\n", "\n", "f1_score_micro_i", ",", "f1_score_macro_i", "=", "f1_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "pr_score_micro_i", ",", "pr_score_macro_i", "=", "precision_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "re_score_micro_i", ",", "re_score_macro_i", "=", "recall_score", "(", "Y_i", ",", "pred_labels_mat_i", ")", "\n", "results", "[", "'f1_score_micro_i'", "]", "=", "f1_score_micro_i", "\n", "results", "[", "'f1_score_macro_i'", "]", "=", "f1_score_macro_i", "\n", "results", "[", "'pr_score_micro_i'", "]", "=", "pr_score_micro_i", "\n", "results", "[", "'pr_score_macro_i'", "]", "=", "pr_score_macro_i", "\n", "results", "[", "'re_score_micro_i'", "]", "=", "re_score_micro_i", "\n", "results", "[", "'re_score_macro_i'", "]", "=", "re_score_macro_i", "\n", "\n", "f1_score_micro_o", ",", "f1_score_macro_o", "=", "f1_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "pr_score_micro_o", ",", "pr_score_macro_o", "=", "precision_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "re_score_micro_o", ",", "re_score_macro_o", "=", "recall_score", "(", "Y_o", ",", "pred_labels_mat_o", ")", "\n", "results", "[", "'f1_score_micro_o'", "]", "=", "f1_score_micro_o", "\n", "results", "[", "'f1_score_macro_o'", "]", "=", "f1_score_macro_o", "\n", "results", "[", "'pr_score_micro_o'", "]", "=", "pr_score_micro_o", "\n", "results", "[", "'pr_score_macro_o'", "]", "=", "pr_score_macro_o", "\n", "results", "[", "'re_score_micro_o'", "]", "=", "re_score_micro_o", "\n", "results", "[", "'re_score_macro_o'", "]", "=", "re_score_macro_o", "\n", "results", "[", "'avg_micro_f1_score'", "]", "=", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", "\n", "\n", "# display(results)", "\n", "\n", "return", "(", "f1_score_micro_p", "+", "f1_score_micro_i", "+", "f1_score_micro_o", ")", "/", "3.0", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.tune_threshold": [[365, 375], ["joint_training_with_label_synonyms_aspects_no_noise.validate", "print"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.src.joint_training_with_label_synonyms_aspects_no_noise.validate"], ["", "def", "tune_threshold", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ")", ":", "\n", "\t", "best_threshold", "=", "0.0", "\n", "best_f1_score", "=", "-", "100", "\n", "for", "threshold", "in", "threshold_list", ":", "\n", "\t\t", "f1_score_curr", ",", "_", "=", "validate", "(", "model", ",", "data", ",", "cui_to_idx", ",", "tokenizer", ",", "threshold", ")", "\n", "print", "(", "\"F1 score: \"", ",", "f1_score_curr", ",", "\" at threshold: \"", ",", "threshold", ")", "\n", "if", "f1_score_curr", ">", "best_f1_score", ":", "\n", "\t\t\t\t", "best_f1_score", "=", "f1_score_curr", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.preprocessing.generate_batches.mesh_name_to_id_mapping": [[9, 19], ["open", "f.readlines", "mapping.strip().split", "mapping.strip"], "function", ["None"], ["def", "mesh_name_to_id_mapping", "(", ")", ":", "\n", "\t", "with", "open", "(", "'../data/bioasq_dataset/MeSH_name_id_mapping_2017.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "mappings", "=", "f", ".", "readlines", "(", ")", "\n", "mappings", "=", "[", "mapping", ".", "strip", "(", ")", ".", "split", "(", "\"=\"", ")", "for", "mapping", "in", "mappings", "]", "\n", "\n", "", "mappings_dict", "=", "{", "}", "\n", "for", "mapping", "in", "mappings", ":", "\n", "\t\t", "mappings_dict", "[", "mapping", "[", "0", "]", "]", "=", "mapping", "[", "1", "]", "\n", "\n", "", "return", "mappings_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.preprocessing.generate_batches.generate_batches": [[22, 45], ["generate_batches.mesh_name_to_id_mapping", "enumerate", "open", "records.append", "len", "json.load", "open", "json.dump", "open", "json.dump", "str", "str"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.preprocessing.generate_batches.mesh_name_to_id_mapping"], ["", "def", "generate_batches", "(", ")", ":", "\n", "\n", "\t", "with", "open", "(", "'../../seq-to-tree/data/bioasq_dataset/allMeSH_2017.json'", ",", "'r'", ",", "encoding", "=", "\"utf8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "\t\t", "training_docs", "=", "json", ".", "load", "(", "f", ")", "[", "'articles'", "]", "\n", "\n", "", "english_name_to_mesh_id", "=", "mesh_name_to_id_mapping", "(", ")", "\n", "\n", "records", "=", "[", "]", "\n", "for", "i", ",", "doc", "in", "enumerate", "(", "training_docs", ")", ":", "\n", "\t\t", "abstract", "=", "doc", "[", "'abstractText'", "]", "\n", "mesh_labels", "=", "[", "english_name_to_mesh_id", "[", "mesh_name", "]", "for", "mesh_name", "in", "doc", "[", "'meshMajor'", "]", "]", "\n", "records", ".", "append", "(", "{", "'abstract'", ":", "abstract", ",", "'mesh_labels'", ":", "mesh_labels", "}", ")", "\n", "\n", "# write the dara into file", "\n", "if", "(", "i", "+", "1", ")", "%", "file_size", "==", "0", ":", "\n", "\t\t\t", "with", "open", "(", "'../data/bioasq_dataset/train_data/'", "+", "str", "(", "(", "i", "+", "1", ")", "//", "file_size", ")", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t\t", "json", ".", "dump", "(", "records", ",", "f", ")", "\n", "records", "=", "[", "]", "\n", "\n", "# write the left over data into file", "\n", "", "", "", "if", "len", "(", "records", ")", ">", "0", ":", "\n", "\t\t", "with", "open", "(", "'../data/bioasq_dataset/train_data/'", "+", "str", "(", "(", "(", "i", "+", "1", ")", "//", "file_size", ")", "+", "1", ")", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t", "json", ".", "dump", "(", "records", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.utils.embedding_operations.read_embeddings": [[3, 34], ["enumerate", "range", "numpy.vstack", "open", "f.readlines", "line.strip().split.strip().split", "len", "float", "np.vstack.append", "line.strip().split.strip", "np.vstack.append", "np.vstack.append", "numpy.array", "numpy.zeros_like", "numpy.array", "numpy.random.standard_normal().tolist", "numpy.random.standard_normal", "len"], "function", ["None"], ["def", "read_embeddings", "(", "file", ",", "vocab", ")", ":", "\n", "\t", "word_to_ind", "=", "{", "}", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "vocab", ")", ":", "\n", "\t\t", "word_to_ind", "[", "word", "]", "=", "i", "\n", "\n", "", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t", "data", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "lines", "=", "data", "[", "1", ":", "]", "\n", "\n", "word_emb_dict", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "line", "[", "0", "]", "\n", "embedding", "=", "[", "float", "(", "v", ")", "for", "v", "in", "line", "[", "1", ":", "]", "]", "\n", "if", "word", "in", "word_to_ind", ":", "\n", "\t\t\t", "word_emb_dict", "[", "word", "]", "=", "embedding", "\n", "\n", "", "", "emb_mat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "vocab", ")", ")", ":", "\n", "\t\t", "if", "vocab", "[", "i", "]", "in", "word_emb_dict", ":", "\n", "\t\t\t", "if", "i", "==", "0", ":", "\n", "\t\t\t\t", "emb_mat", ".", "append", "(", "np", ".", "zeros_like", "(", "word_emb_dict", "[", "vocab", "[", "i", "]", "]", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "emb_mat", ".", "append", "(", "np", ".", "array", "(", "word_emb_dict", "[", "vocab", "[", "i", "]", "]", ")", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "emb_mat", ".", "append", "(", "np", ".", "array", "(", "np", ".", "random", ".", "standard_normal", "(", "len", "(", "embedding", ")", ")", ".", "tolist", "(", ")", ")", ")", "\n", "\n", "", "", "emb_mat", "=", "np", ".", "vstack", "(", "emb_mat", ")", "\n", "\n", "return", "emb_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.CNNModel.__init__": [[8, 29], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.__init__"], ["\t", "def", "__init__", "(", "self", ",", "n_tgt_vocab", ",", "dropout", "=", "0.1", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_word_emb", "=", "nn", ".", "Embedding", "(", "100000", ",", "200", ",", "padding_idx", "=", "0", ")", "\n", "# self.conv_layer_1 = nn.Conv1d(d_word_vec, 1024, 3, padding=1, stride=1)", "\n", "\n", "self", ".", "conv_layer_1_1", "=", "nn", ".", "Conv1d", "(", "200", ",", "1024", ",", "1", ",", "padding", "=", "0", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv_layer_1_3", "=", "nn", ".", "Conv1d", "(", "200", ",", "1024", ",", "3", ",", "padding", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv_layer_1_5", "=", "nn", ".", "Conv1d", "(", "200", ",", "1024", ",", "5", ",", "padding", "=", "2", ",", "stride", "=", "1", ")", "\n", "\n", "# self.conv_layer_2 = nn.Conv1d(3072, 512, 3, padding=1, stride=1)", "\n", "# self.conv_layer_3 = nn.Conv1d(512, 256, 3, padding=1, stride=1)", "\n", "# self.conv_layer_4 = nn.Conv1d(256, 256, 3, padding=1, stride=1)", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool1d", "(", "1000", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "# self.fc_layer_1 = nn.Linear((len_max_seq//16)*256, 256)", "\n", "self", ".", "layer_norm_1", "=", "nn", ".", "LayerNorm", "(", "768", ")", "\n", "self", ".", "fc_layer_1", "=", "nn", ".", "Linear", "(", "3072", ",", "768", ")", "\n", "self", ".", "output_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_3", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "relu_activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.CNNModel.forward": [[31, 74], ["Models.CNNModel.src_word_emb", "Models.CNNModel.permute", "Models.CNNModel.conv_layer_1_1", "Models.CNNModel.relu_activation", "Models.CNNModel.maxpool", "Models.CNNModel.conv_layer_1_3", "Models.CNNModel.relu_activation", "Models.CNNModel.maxpool", "Models.CNNModel.conv_layer_1_5", "Models.CNNModel.relu_activation", "Models.CNNModel.maxpool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.CNNModel.dropout", "Models.CNNModel.relu_activation", "Models.CNNModel.output_layer_1", "Models.CNNModel.output_layer_2", "Models.CNNModel.output_layer_3", "Models.CNNModel.view", "Models.CNNModel.fc_layer_1", "Models.CNNModel.dropout", "Models.CNNModel.dropout", "Models.CNNModel.dropout", "Models.CNNModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_idxs", ")", ":", "\n", "\t\t", "output", "=", "self", ".", "src_word_emb", "(", "input_idxs", ")", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# output = self.conv_layer_1(output)", "\n", "# output = self.relu_activation(output)", "\n", "# output = self.maxpool(output)", "\n", "\n", "output_1", "=", "self", ".", "conv_layer_1_1", "(", "output", ")", "\n", "output_1", "=", "self", ".", "relu_activation", "(", "output_1", ")", "\n", "output_1", "=", "self", ".", "maxpool", "(", "output_1", ")", "\n", "\n", "output_3", "=", "self", ".", "conv_layer_1_3", "(", "output", ")", "\n", "output_3", "=", "self", ".", "relu_activation", "(", "output_3", ")", "\n", "output_3", "=", "self", ".", "maxpool", "(", "output_3", ")", "\n", "\n", "output_5", "=", "self", ".", "conv_layer_1_5", "(", "output", ")", "\n", "output_5", "=", "self", ".", "relu_activation", "(", "output_5", ")", "\n", "output_5", "=", "self", ".", "maxpool", "(", "output_5", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "(", "output_1", ",", "output_3", ",", "output_5", ")", ",", "1", ")", "\n", "\n", "# output = self.conv_layer_2(output)", "\n", "# output = self.relu_activation(output)", "\n", "\n", "# output = self.maxpool(output)", "\n", "\n", "# output = self.conv_layer_3(output)", "\n", "# output = self.relu_activation(output)", "\n", "# output = self.maxpool(output)", "\n", "\n", "# output = self.conv_layer_4(output)", "\n", "# output = self.relu_activation(output)", "\n", "# output = self.maxpool(output)", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "output", ".", "view", "(", "output", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "output_fc_layer", "=", "self", ".", "relu_activation", "(", "self", ".", "fc_layer_1", "(", "output", ")", ")", "\n", "# output_fc_layer = self.layer_norm_1(self.fc_layer_1(output))", "\n", "target_p", "=", "self", ".", "output_layer_1", "(", "self", ".", "dropout", "(", "output_fc_layer", ")", ")", "\n", "target_i", "=", "self", ".", "output_layer_2", "(", "self", ".", "dropout", "(", "output_fc_layer", ")", ")", "\n", "target_o", "=", "self", ".", "output_layer_3", "(", "self", ".", "dropout", "(", "output_fc_layer", ")", ")", "\n", "\n", "return", "target_p", ",", "target_i", ",", "target_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTCLassifierModel.__init__": [[77, 87], ["torch.Module.__init__", "pytorch_pretrained_bert.BertModel.from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.__init__"], ["\t", "def", "__init__", "(", "self", ",", "n_tgt_vocab", ",", "dropout", "=", "0.1", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "# self.bert.load_state_dict(torch.load('../saved_models/bert_based/bert_retrained_mesh_model.pt'))", "\n", "self", ".", "fc_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_3", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "output_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_3", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTCLassifierModel.forward": [[88, 103], ["Models.BERTCLassifierModel.bert", "Models.BERTCLassifierModel.fc_layer_1", "Models.BERTCLassifierModel.fc_layer_2", "Models.BERTCLassifierModel.fc_layer_3", "Models.BERTCLassifierModel.output_layer_1", "Models.BERTCLassifierModel.output_layer_2", "Models.BERTCLassifierModel.output_layer_3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_idxs", ",", "input_mask", ")", ":", "\n", "\t\t", "enc_out", ",", "_", "=", "self", ".", "bert", "(", "input_idxs", ",", "attention_mask", "=", "input_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "\n", "# extract encoding for the [CLS] token", "\n", "enc_out", "=", "enc_out", "[", ":", ",", "0", ",", ":", "]", "\n", "enc_out_1", "=", "self", ".", "fc_layer_1", "(", "enc_out", ")", "\n", "enc_out_2", "=", "self", ".", "fc_layer_2", "(", "enc_out", ")", "\n", "enc_out_3", "=", "self", ".", "fc_layer_3", "(", "enc_out", ")", "\n", "\n", "# pass the embedding for [CLS] token to the final classification layer", "\n", "target_p", "=", "self", ".", "output_layer_1", "(", "enc_out_1", ")", "\n", "target_i", "=", "self", ".", "output_layer_2", "(", "enc_out_2", ")", "\n", "target_o", "=", "self", ".", "output_layer_3", "(", "enc_out_3", ")", "\n", "\n", "return", "target_p", ",", "target_i", ",", "target_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTCLassifierModelAspect.__init__": [[106, 116], ["torch.Module.__init__", "pytorch_pretrained_bert.BertModel.from_pretrained", "Models.BERTCLassifierModelAspect.bert.load_state_dict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.__init__"], ["\t", "def", "__init__", "(", "self", ",", "n_tgt_vocab", ",", "dropout", "=", "0.1", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "self", ".", "bert", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'../saved_models/bert_based/bert_retrained_mesh_model.pt'", ")", ")", "\n", "self", ".", "fc_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_3", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "output_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "self", ".", "output_layer_3", "=", "nn", ".", "Linear", "(", "768", ",", "n_tgt_vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTCLassifierModelAspect.forward": [[117, 140], ["Models.BERTCLassifierModelAspect.bert", "Models.BERTCLassifierModelAspect.fc_layer_1", "Models.BERTCLassifierModelAspect.fc_layer_2", "Models.BERTCLassifierModelAspect.fc_layer_3", "Models.BERTCLassifierModelAspect.output_layer_1", "Models.BERTCLassifierModelAspect.output_layer_2", "Models.BERTCLassifierModelAspect.output_layer_3", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_idxs", ",", "input_mask", ",", "is_label_training", "=", "False", ",", "noise_weight", "=", "0.0", ")", ":", "\n", "\t\t", "enc_out", ",", "_", "=", "self", ".", "bert", "(", "input_idxs", ",", "attention_mask", "=", "input_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "\n", "# extract encoding for the [CLS] token", "\n", "enc_out", "=", "enc_out", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "if", "is_label_training", ":", "\n", "# add noise to the representation", "\n", "\t\t\t", "rand_out", "=", "torch", ".", "randn_like", "(", "enc_out", ")", "\n", "rand_out", "=", "rand_out", "/", "(", "torch", ".", "norm", "(", "rand_out", ",", "dim", "=", "1", ")", "[", ":", ",", "None", "]", ")", "\n", "rand_out", "=", "noise_weight", "*", "torch", ".", "norm", "(", "enc_out", ",", "dim", "=", "1", ")", "[", ":", ",", "None", "]", "*", "rand_out", "\n", "enc_out", "=", "enc_out", "+", "rand_out", "\n", "\n", "", "enc_out_1", "=", "self", ".", "fc_layer_1", "(", "enc_out", ")", "\n", "enc_out_2", "=", "self", ".", "fc_layer_2", "(", "enc_out", ")", "\n", "enc_out_3", "=", "self", ".", "fc_layer_3", "(", "enc_out", ")", "\n", "\n", "# pass the embedding for [CLS] token to the final classification layer", "\n", "target_p", "=", "self", ".", "output_layer_1", "(", "enc_out_1", ")", "\n", "target_i", "=", "self", ".", "output_layer_2", "(", "enc_out_2", ")", "\n", "target_o", "=", "self", ".", "output_layer_3", "(", "enc_out_3", ")", "\n", "\n", "return", "target_p", ",", "target_i", ",", "target_o", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.__init__": [[143, 151], ["torch.Module.__init__", "pytorch_pretrained_bert.BertModel.from_pretrained", "Models.BERTClassifierLabelTransfer.bert.load_state_dict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.__init__"], ["\t", "def", "__init__", "(", "self", ",", "dropout", "=", "0.1", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "self", ".", "bert", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'../saved_models/bert_based/bert_retrained_mesh_model.pt'", ")", ")", "\n", "self", ".", "fc_layer_1", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_2", "=", "nn", ".", "Linear", "(", "768", ",", "768", ")", "\n", "self", ".", "fc_layer_3", "=", "nn", ".", "Linear", "(", "768", "*", "2", ",", "768", ")", "\n", "self", ".", "output_layer", "=", "nn", ".", "Linear", "(", "768", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.model.Models.BERTClassifierLabelTransfer.forward": [[153, 170], ["Models.BERTClassifierLabelTransfer.bert", "Models.BERTClassifierLabelTransfer.bert", "Models.BERTClassifierLabelTransfer.fc_layer_1", "Models.BERTClassifierLabelTransfer.fc_layer_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.BERTClassifierLabelTransfer.fc_layer_3", "Models.BERTClassifierLabelTransfer.output_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_idxs", ",", "input_mask", ",", "target_idxs", ",", "target_mask", ")", ":", "\n", "\t\t", "enc_out", ",", "_", "=", "self", ".", "bert", "(", "input_idxs", ",", "attention_mask", "=", "input_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "tgt_out", ",", "_", "=", "self", ".", "bert", "(", "target_idxs", ",", "attention_mask", "=", "target_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "\n", "# extract encoding for the [CLS] token", "\n", "enc_out", "=", "enc_out", "[", ":", ",", "0", ",", ":", "]", "\n", "tgt_out", "=", "tgt_out", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "enc_out", "=", "self", ".", "fc_layer_1", "(", "enc_out", ")", "\n", "tgt_out", "=", "self", ".", "fc_layer_2", "(", "tgt_out", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "enc_out", ",", "tgt_out", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "fc_layer_3", "(", "out", ")", "\n", "# pass the embedding for [CLS] token to the final classification layer", "\n", "target", "=", "self", ".", "output_layer", "(", "out", ")", "\n", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.analysis.stats_pico.extract_target_vocab": [[4, 17], ["list", "enumerate", "set"], "function", ["None"], ["def", "extract_target_vocab", "(", "data", ")", ":", "\n", "\t", "vocab", "=", "[", "]", "\n", "for", "sample", "in", "data", ":", "\n", "\t\t", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'population condition'", "]", "if", "triplet", "[", "2", "]", "is", "not", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'intervention applied'", "]", "if", "triplet", "[", "2", "]", "is", "not", "\"NULL\"", "]", "\n", "vocab", "+=", "[", "triplet", "[", "2", "]", "for", "triplet", "in", "sample", "[", "'outcome condition'", "]", "if", "triplet", "[", "2", "]", "is", "not", "\"NULL\"", "]", "\n", "", "idx_to_cui", "=", "list", "(", "set", "(", "vocab", ")", ")", "\n", "\n", "cui_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "cui", "in", "enumerate", "(", "idx_to_cui", ")", ":", "\n", "\t\t", "cui_to_idx", "[", "cui", "]", "=", "idx", "\n", "\n", "", "return", "idx_to_cui", ",", "cui_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.analysis.stats_pico.update_label_count": [[19, 26], ["None"], "function", ["None"], ["", "def", "update_label_count", "(", "label_cnt", ",", "labels", ")", ":", "\n", "\t", "for", "label", "in", "labels", ":", "\n", "\t\t", "if", "label", "in", "label_cnt", ":", "\n", "\t\t\t", "label_cnt", "[", "label", "]", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t", "label_cnt", "[", "label", "]", "=", "1", "\n", "", "", "return", "label_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score": [[6, 11], ["sklearn.metrics.f1_score", "sklearn.metrics.f1_score"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.f1_score"], ["def", "f1_score", "(", "true_label_mat", ",", "pred_label_mat", ")", ":", "\n", "\t", "f1_score_micro", "=", "scikit_f1_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'micro'", ")", "\n", "f1_score_macro", "=", "scikit_f1_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "f1_score_micro", ",", "f1_score_macro", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score": [[13, 18], ["sklearn.metrics.precision_score", "sklearn.metrics.precision_score"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.precision_score"], ["", "def", "precision_score", "(", "true_label_mat", ",", "pred_label_mat", ")", ":", "\n", "\t", "precision_score_micro", "=", "scikit_precision_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'micro'", ")", "\n", "precision_score_macro", "=", "scikit_precision_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "precision_score_micro", ",", "precision_score_macro", "\n", "\n"]], "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score": [[20, 25], ["sklearn.metrics.recall_score", "sklearn.metrics.recall_score"], "function", ["home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score", "home.repos.pwc.inspect_result.gauravsc_pico-tagging.eval.eval.recall_score"], ["", "def", "recall_score", "(", "true_label_mat", ",", "pred_label_mat", ")", ":", "\n", "\t", "recall_score_micro", "=", "scikit_recall_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'micro'", ")", "\n", "recall_score_macro", "=", "scikit_recall_score", "(", "true_label_mat", ",", "pred_label_mat", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "recall_score_micro", ",", "recall_score_macro", "", "", ""]]}