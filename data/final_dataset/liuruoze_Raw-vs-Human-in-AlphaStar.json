{"home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.Transformer.__init__": [[22, 36], ["torch.Module.__init__", "alphastar_transformer.Encoder", "alphastar_transformer.Transformer.parameters", "p.dim", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "\n", "self", ",", "d_model", "=", "256", ",", "d_inner", "=", "1024", ",", "\n", "n_layers", "=", "3", ",", "n_head", "=", "2", ",", "d_k", "=", "128", ",", "d_v", "=", "128", ",", "dropout", "=", "0.1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "d_model", "=", "d_model", ",", "d_inner", "=", "d_inner", ",", "\n", "n_layers", "=", "n_layers", ",", "n_head", "=", "n_head", ",", "d_k", "=", "d_k", ",", "d_v", "=", "d_v", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.Transformer.forward": [[37, 41], ["alphastar_transformer.Transformer.encoder"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "enc_output", ",", "*", "_", "=", "self", ".", "encoder", "(", "x", ")", "\n", "\n", "return", "enc_output", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.Encoder.__init__": [[47, 58], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "alphastar_transformer.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "\n", "self", ",", "n_layers", "=", "3", ",", "n_head", "=", "2", ",", "d_k", "=", "128", ",", "d_v", "=", "128", ",", "\n", "d_model", "=", "256", ",", "d_inner", "=", "1024", ",", "dropout", "=", "0.1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "layer_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "EncoderLayer", "(", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.Encoder.forward": [[59, 73], ["alphastar_transformer.Encoder.layer_norm", "enc_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "return_attns", "=", "False", ")", ":", "\n", "        ", "enc_slf_attn_list", "=", "[", "]", "\n", "\n", "# -- Forward", "\n", "enc_output", "=", "x", "\n", "for", "enc_layer", "in", "self", ".", "layer_stack", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "enc_layer", "(", "enc_output", ")", "\n", "enc_slf_attn_list", "+=", "[", "enc_slf_attn", "]", "if", "return_attns", "else", "[", "]", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "if", "return_attns", ":", "\n", "            ", "return", "enc_output", ",", "enc_slf_attn_list", "\n", "", "return", "enc_output", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.EncoderLayer.__init__": [[80, 84], ["torch.Module.__init__", "alphastarmini.third.transformer.SubLayers.MultiHeadAttention", "alphastarmini.third.transformer.SubLayers.PositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "d_model", "=", "256", ",", "d_inner", "=", "1024", ",", "n_head", "=", "2", ",", "d_k", "=", "128", ",", "d_v", "=", "128", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.EncoderLayer.forward": [[85, 90], ["alphastar_transformer.EncoderLayer.slf_attn", "alphastar_transformer.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "slf_attn_mask", "=", "None", ")", ":", "\n", "        ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "\n", "enc_input", ",", "enc_input", ",", "enc_input", ",", "mask", "=", "slf_attn_mask", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.alphastar_transformer.test": [[92, 94], ["None"], "function", ["None"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.levenshtein_recur": [[16, 24], ["min", "len", "len", "edit_distance.levenshtein_recur", "edit_distance.levenshtein_recur", "edit_distance.levenshtein_recur"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.levenshtein_recur", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.levenshtein_recur", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.levenshtein_recur"], ["def", "levenshtein_recur", "(", "a", ",", "b", ")", ":", "\n", "    ", "if", "not", "a", ":", "\n", "        ", "return", "len", "(", "b", ")", "\n", "", "if", "not", "b", ":", "\n", "        ", "return", "len", "(", "a", ")", "\n", "", "return", "min", "(", "levenshtein_recur", "(", "a", "[", "1", ":", "]", ",", "b", "[", "1", ":", "]", ")", "+", "(", "a", "[", "0", "]", "!=", "b", "[", "0", "]", ")", ",", "\n", "levenshtein_recur", "(", "a", "[", "1", ":", "]", ",", "b", ")", "+", "1", ",", "\n", "levenshtein_recur", "(", "a", ",", "b", "[", "1", ":", "]", ")", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.hammingDist": [[26, 29], ["sum", "len", "len", "zip"], "function", ["None"], ["", "def", "hammingDist", "(", "s1", ",", "s2", ")", ":", "\n", "    ", "assert", "len", "(", "s1", ")", "==", "len", "(", "s2", ")", "\n", "return", "sum", "(", "[", "ch1", "!=", "ch2", "for", "ch1", ",", "ch2", "in", "zip", "(", "s1", ",", "s2", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.test": [[31, 80], ["print", "print", "print", "print", "print", "print", "print", "print", "print", "time.time", "print", "time.time", "print", "time.time", "print", "time.time", "print", "print", "print", "print", "print", "time.time", "print", "time.time", "print", "time.time", "print", "time.time", "print", "levenshtein", "levenshtein", "levenshtein", "levenshtein", "levenshtein", "levenshtein", "levenshtein", "Levenshtein.distance", "edit_distance.levenshtein_recur", "edit_distance.hammingDist", "Levenshtein.hamming", "Levenshtein.hamming", "edit_distance.hammingDist", "chr", "chr", "chr", "chr", "random.randrange", "range", "random.randrange", "range", "random.randrange", "range", "random.randrange", "range"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.levenshtein_recur", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.hammingDist", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.edit_distance.hammingDist"], ["", "def", "test", "(", ")", ":", "\n", "    ", "levenshtein", "=", "levenshtein_recur", "\n", "\n", "Start", "=", "0", "\n", "Stop", "=", "565", "\n", "limit", "=", "10", "\n", "list_1", "=", "''", ".", "join", "(", "[", "chr", "(", "random", ".", "randrange", "(", "Start", ",", "Stop", ")", ")", "for", "iter", "in", "range", "(", "limit", ")", "]", ")", "\n", "list_2", "=", "''", ".", "join", "(", "[", "chr", "(", "random", ".", "randrange", "(", "Start", ",", "Stop", ")", ")", "for", "iter", "in", "range", "(", "limit", ")", "]", ")", "\n", "print", "(", "list_1", ")", "\n", "print", "(", "list_2", ")", "\n", "\n", "print", "(", "\"distance between 'cat', 'chello'\"", ",", "levenshtein", "(", "'cat'", ",", "'chello'", ")", ")", "\n", "print", "(", "\"distance between '', 'chello'\"", ",", "levenshtein", "(", "''", ",", "'chello'", ")", ")", "\n", "print", "(", "\"distance between 'cat', ''\"", ",", "levenshtein", "(", "'cat'", ",", "''", ")", ")", "\n", "print", "(", "\"distance between 'cat', 'chello'\"", ",", "levenshtein", "(", "'cat'", ",", "'chello'", ")", ")", "\n", "print", "(", "\"distance between 'cat', 'cate'\"", ",", "levenshtein", "(", "'cat'", ",", "'cate'", ")", ")", "\n", "print", "(", "\"distance between 'cat', 'ca'\"", ",", "levenshtein", "(", "'cat'", ",", "'ca'", ")", ")", "\n", "print", "(", "\"distance between 'cat', 'cad'\"", ",", "levenshtein", "(", "'cat'", ",", "'cad'", ")", ")", "\n", "\n", "begin", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"distance between list_1, list_2\"", ",", "Levenshtein", ".", "distance", "(", "list_1", ",", "list_2", ")", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f\"Total runtime of the Levenshtein.distance is {end - begin}\"", ")", "\n", "\n", "begin", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"distance between list_1, list_2\"", ",", "levenshtein_recur", "(", "list_1", ",", "list_2", ")", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f\"Total runtime of the levenshtein_recur is {end - begin}\"", ")", "\n", "\n", "print", "(", "\"hamming distance between 'cat', 'cad'\"", ",", "hammingDist", "(", "'cat'", ",", "'cad'", ")", ")", "\n", "print", "(", "\"hamming distance between 'cat', 'cad'\"", ",", "Levenshtein", ".", "hamming", "(", "'cat'", ",", "'cad'", ")", ")", "\n", "\n", "Start", "=", "0", "\n", "Stop", "=", "565", "\n", "limit", "=", "100", "\n", "list_1", "=", "''", ".", "join", "(", "[", "chr", "(", "random", ".", "randrange", "(", "Start", ",", "Stop", ")", ")", "for", "iter", "in", "range", "(", "limit", ")", "]", ")", "\n", "list_2", "=", "''", ".", "join", "(", "[", "chr", "(", "random", ".", "randrange", "(", "Start", ",", "Stop", ")", ")", "for", "iter", "in", "range", "(", "limit", ")", "]", ")", "\n", "print", "(", "list_1", ")", "\n", "print", "(", "list_2", ")", "\n", "\n", "begin", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"hamming distance between list_1, list_2\"", ",", "Levenshtein", ".", "hamming", "(", "list_1", ",", "list_2", ")", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f\"Total runtime of the Levenshtein.hamming is {end - begin}\"", ")", "\n", "\n", "begin", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"hamming distance between list_1, list_2\"", ",", "hammingDist", "(", "list_1", ",", "list_2", ")", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "f\"Total runtime of the hammingDist is {end - begin}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.multinomial.stable_multinomial": [[14, 35], ["torch.log.clamp", "numpy.clip", "torch.exp", "torch.exp", "torch.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "probs.clamp.clamp", "torch.log", "torch.log", "torch.log", "print", "print", "print", "torch.log.max", "probs.clamp.max", "probs.clamp.min"], "function", ["None"], ["def", "stable_multinomial", "(", "probs", "=", "None", ",", "logits", "=", "None", ",", "temperature", "=", "1", ",", "num_samples", "=", "1", ",", "\n", "min_prob", "=", "1e-10", ",", "max_logit", "=", "1e+10", ",", "\n", "min_temperature", "=", "1e-10", ",", "max_temperature", "=", "1e+10", ")", ":", "\n", "    ", "'''\n        this stable_multinomial will avoid THCNumerics<T>::ge(val, zero) failed\n    '''", "\n", "\n", "if", "probs", "is", "not", "None", ":", "\n", "        ", "probs", "=", "probs", ".", "clamp", "(", "min", "=", "min_prob", ")", "\n", "logits", "=", "torch", ".", "log", "(", "probs", ")", "\n", "\n", "", "logits", "=", "logits", ".", "clamp", "(", "max", "=", "max_logit", ")", "\n", "temperature", "=", "np", ".", "clip", "(", "temperature", ",", "min_temperature", ",", "max_temperature", ")", "\n", "logits", "=", "(", "logits", "-", "logits", ".", "max", "(", ")", ")", "/", "temperature", "\n", "probs", "=", "torch", ".", "exp", "(", "logits", ")", "\n", "\n", "print", "(", "'probs:'", ",", "probs", ")", "if", "debug", "else", "None", "\n", "print", "(", "'max probs:'", ",", "probs", ".", "max", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "'min probs:'", ",", "probs", ".", "min", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "return", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.glu.GLU.__init__": [[21, 27], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "384", ",", "context_size", "=", "1024", ",", "\n", "output_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "context_size", ",", "input_size", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.glu.GLU.forward": [[28, 41], ["glu.GLU.sigmoid", "glu.GLU.fc_2", "glu.GLU.fc_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "context", ")", ":", "\n", "# context shape: [batch_size x context_size]", "\n", "        ", "gate", "=", "self", ".", "sigmoid", "(", "self", ".", "fc_1", "(", "context", ")", ")", "\n", "# gate shape: [batch_size x input_size]", "\n", "\n", "# The line is the same as below: gated_input = torch.mul(gate, x)", "\n", "# x shape: [batch_size x input_size]", "\n", "gated_input", "=", "gate", "*", "x", "\n", "\n", "# gated_input shape: [batch_size x input_size]", "\n", "output", "=", "self", ".", "fc_2", "(", "gated_input", ")", "\n", "# output shape: [batch_size x output_size]", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.glu.test": [[43, 57], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "GatingLinearUnit", "GatingLinearUnit.forward", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "context", "=", "torch", ".", "randn", "(", "5", ",", "32", ")", "\n", "x", "=", "torch", ".", "randn", "(", "5", ",", "16", ")", "\n", "output_size", "=", "24", "\n", "\n", "GLU", "=", "GatingLinearUnit", "(", "input_size", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "context_size", "=", "context", ".", "shape", "[", "-", "1", "]", ",", "\n", "output_size", "=", "output_size", ")", "\n", "print", "(", "'context:'", ",", "context", ")", "if", "debug", "else", "None", "\n", "print", "(", "'x:'", ",", "x", ")", "if", "debug", "else", "None", "\n", "\n", "output", "=", "GLU", ".", "forward", "(", "x", ",", "context", ")", "\n", "print", "(", "'output:'", ",", "output", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index": [[30, 38], ["utils.get_unit_tpye_name_and_race", "utils.get_unit_tpye_index", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.get_unit_tpye_name_and_race", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.get_unit_tpye_index"], ["def", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", ":", "\n", "    ", "unit_tpye_name", ",", "race", "=", "get_unit_tpye_name_and_race", "(", "unit_type", ")", "\n", "print", "(", "'unit_tpye_name, race:'", ",", "unit_tpye_name", ",", "race", ")", "if", "debug", "else", "None", "\n", "\n", "unit_type_index", "=", "get_unit_tpye_index", "(", "unit_tpye_name", ",", "race", ")", "\n", "print", "(", "'unit_type_index:'", ",", "unit_type_index", ")", "if", "debug", "else", "None", "\n", "\n", "return", "unit_type_index", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.get_unit_tpye_name_and_race": [[40, 46], ["race"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.race"], ["", "def", "get_unit_tpye_name_and_race", "(", "unit_type", ")", ":", "\n", "    ", "for", "race", "in", "(", "Neutral", ",", "Protoss", ",", "Terran", ",", "Zerg", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "race", "(", "unit_type", ")", ",", "race", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "# Wrong race.", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.get_unit_tpye_index": [[48, 63], ["enumerate", "list", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "get_unit_tpye_index", "(", "unit_type_name", ",", "race", ")", ":", "\n", "    ", "begin_index", "=", "0", "\n", "if", "race", "==", "Neutral", ":", "\n", "        ", "begin_index", "=", "0", "\n", "", "elif", "race", "==", "Protoss", ":", "\n", "        ", "begin_index", "=", "len", "(", "Neutral", ")", "\n", "", "elif", "race", "==", "Terran", ":", "\n", "        ", "begin_index", "=", "len", "(", "Neutral", ")", "+", "len", "(", "Protoss", ")", "\n", "", "elif", "race", "==", "Zerg", ":", "\n", "        ", "begin_index", "=", "len", "(", "Neutral", ")", "+", "len", "(", "Protoss", ")", "+", "len", "(", "Terran", ")", "\n", "\n", "", "for", "i", ",", "e", "in", "enumerate", "(", "list", "(", "race", ")", ")", ":", "\n", "        ", "if", "e", "==", "unit_type_name", ":", "\n", "            ", "return", "i", "+", "begin_index", "\n", "", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unpackbits_for_largenumber": [[65, 72], ["numpy.issubdtype", "list", "x.reshape.reshape", "ValueError", "numpy.arange().reshape", "numpy.arange"], "function", ["None"], ["", "def", "unpackbits_for_largenumber", "(", "x", ",", "num_bits", ")", ":", "\n", "    ", "if", "np", ".", "issubdtype", "(", "x", ".", "dtype", ",", "np", ".", "floating", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"numpy data type needs to be int-like\"", ")", "\n", "", "xshape", "=", "list", "(", "x", ".", "shape", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "mask", "=", "2", "**", "np", ".", "arange", "(", "num_bits", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "reshape", "(", "[", "1", ",", "num_bits", "]", ")", "\n", "return", "(", "x", "&", "mask", ")", ".", "astype", "(", "bool", ")", ".", "astype", "(", "int", ")", ".", "reshape", "(", "xshape", "+", "[", "num_bits", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow": [[74, 95], ["torch.zeros", "torch.zeros", "torch.zeros", "print", "utils.unit_tpye_to_unit_type_index"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index"], ["", "def", "calculate_unit_counts_bow", "(", "obs", ")", ":", "\n", "    ", "unit_counts", "=", "obs", "[", "\"unit_counts\"", "]", "\n", "print", "(", "'unit_counts:'", ",", "unit_counts", ")", "if", "debug", "else", "None", "\n", "unit_counts_bow", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "for", "u_c", "in", "unit_counts", ":", "\n", "        ", "unit_type", "=", "u_c", "[", "0", "]", "\n", "unit_count", "=", "u_c", "[", "1", "]", "\n", "assert", "unit_type", ">=", "0", "\n", "# the unit_count can not be negetive number", "\n", "assert", "unit_count", ">=", "0", "\n", "\n", "# the unit_type should not be more than the SFS.unit_counts_bow", "\n", "# if it is, make it to be 0 now. (0 means nothing now)", "\n", "# the most impact one is ShieldBattery = 1910        ", "\n", "# find a better way to do it: transform it to unit_type_index!", "\n", "unit_type_index", "=", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "if", "unit_type_index", ">=", "SFS", ".", "unit_counts_bow", ":", "\n", "            ", "unit_type_index", "=", "0", "\n", "\n", "", "unit_counts_bow", "[", "0", ",", "unit_type", "]", "=", "unit_count", "\n", "", "return", "unit_counts_bow", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_build_order": [[97, 121], ["utils.calculate_unit_counts_bow", "utils.calculate_unit_counts_bow", "torch.sum().item", "torch.sum().item", "torch.sum().item", "print", "diff.numpy", "numpy.where", "torch.sum", "torch.sum", "torch.sum", "print", "previous_bo.append"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow"], ["", "def", "calculate_build_order", "(", "previous_bo", ",", "obs", ",", "next_obs", ")", ":", "\n", "# calculate the build order", "\n", "    ", "ucb", "=", "calculate_unit_counts_bow", "(", "obs", ")", "\n", "next_ucb", "=", "calculate_unit_counts_bow", "(", "next_obs", ")", "\n", "diff", "=", "next_ucb", "-", "ucb", "\n", "\n", "# the probe, drone, and SCV are not counted in build order", "\n", "worker_type_list", "=", "[", "84", ",", "104", ",", "45", "]", "\n", "# the pylon, drone, and supplypot are not counted in build order", "\n", "supply_type_list", "=", "[", "60", ",", "106", ",", "19", "]", "\n", "diff", "[", "0", ",", "worker_type_list", "]", "=", "0", "\n", "diff", "[", "0", ",", "supply_type_list", "]", "=", "0", "\n", "\n", "diff_count", "=", "torch", ".", "sum", "(", "diff", ")", ".", "item", "(", ")", "\n", "print", "(", "\"diff between unit_counts_bow\"", ",", "diff_count", ")", "if", "debug", "else", "None", "\n", "if", "diff_count", "==", "1.0", ":", "\n", "        ", "diff_numpy", "=", "diff", ".", "numpy", "(", ")", "\n", "index_list", "=", "np", ".", "where", "(", "diff_numpy", ">=", "1.0", ")", "\n", "print", "(", "\"index_list:\"", ",", "index_list", ")", "if", "debug", "else", "None", "\n", "index", "=", "index_list", "[", "1", "]", "[", "0", "]", "\n", "if", "index", "not", "in", "worker_type_list", "and", "index", "not", "in", "supply_type_list", ":", "\n", "            ", "previous_bo", ".", "append", "(", "index", ")", "\n", "\n", "", "", "return", "previous_bo", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.load_latest_model": [[123, 135], ["list", "list.sort", "os.path.join", "print", "torch.load", "torch.load", "torch.load", "filter", "len", "print", "os.listdir"], "function", ["None"], ["", "def", "load_latest_model", "(", "model_type", ",", "path", ")", ":", "\n", "    ", "models", "=", "list", "(", "filter", "(", "lambda", "x", ":", "model_type", "in", "x", ",", "os", ".", "listdir", "(", "path", ")", ")", ")", "\n", "if", "len", "(", "models", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"No models are found!\"", ")", "\n", "return", "None", "\n", "\n", "", "models", ".", "sort", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "models", "[", "-", "1", "]", ")", "\n", "print", "(", "\"load model from {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.load_the_model": [[137, 140], ["torch.load", "torch.load", "torch.load"], "function", ["None"], ["", "def", "load_the_model", "(", "model_path", ")", ":", "\n", "    ", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.show_map_data_test": [[142, 189], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show", "matplotlib.imshow", "matplotlib.show"], "function", ["None"], ["", "def", "show_map_data_test", "(", "obs", ",", "map_width", "=", "128", ",", "show_original", "=", "True", ",", "show_resacel", "=", "True", ")", ":", "\n", "    ", "use_small_map", "=", "False", "\n", "small_map_width", "=", "32", "\n", "\n", "resize_type", "=", "np", ".", "uint8", "\n", "save_type", "=", "np", ".", "float16", "\n", "\n", "# note, in pysc2-1.2, obs[\"feature_minimap\"][\"height_map\"] can be shown straight,", "\n", "# however, in pysc-3.0, that can not be show straight, must be transformed to numpy arrary firstly;", "\n", "height_map", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"height_map\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "height_map", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "visibility_map", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"visibility_map\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "visibility_map", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "creep", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"creep\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "creep", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "player_relative", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"player_relative\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "player_relative", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "# the below three maps are all zero, this may due to we connnect to a 3.16.1 version SC2,", "\n", "# may be different when we connect to 4.10 version SC2.", "\n", "", "alerts", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"alerts\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "alerts", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "pathable", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"pathable\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "pathable", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "buildable", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"buildable\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "buildable", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.show_numpy_image": [[191, 197], ["matplotlib.imshow", "matplotlib.show"], "function", ["None"], ["", "def", "show_numpy_image", "(", "numpy_image", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "imgplot", "=", "plt", ".", "imshow", "(", "numpy_image", ")", "\n", "plt", ".", "show", "(", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot": [[199, 205], ["res.reshape", "numpy.eye", "numpy.array().reshape", "list", "numpy.array"], "function", ["None"], ["", "def", "np_one_hot", "(", "targets", ",", "nb_classes", ")", ":", "\n", "    ", "\"\"\"This is for numpy array\n\n    \"\"\"", "\n", "res", "=", "np", ".", "eye", "(", "nb_classes", ")", "[", "np", ".", "array", "(", "targets", ")", ".", "reshape", "(", "-", "1", ")", "]", "\n", "return", "res", ".", "reshape", "(", "list", "(", "targets", ".", "shape", ")", "+", "[", "nb_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.one_hot_embedding": [[207, 227], ["torch.eye", "torch.eye", "torch.eye", "labels.get_device", "y.to.to"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "one_hot_embedding", "(", "labels", ",", "num_classes", ")", ":", "\n", "    ", "\"\"\"Embedding labels to one-hot form.\n\n    Args:\n      labels: (LongTensor) class labels, sized [N,].\n      num_classes: (int) number of classes.\n\n    Returns:\n      (tensor) encoded labels, sized [N, #classes].\n    \"\"\"", "\n", "cuda_check", "=", "labels", ".", "is_cuda", "\n", "if", "cuda_check", ":", "\n", "        ", "get_cuda_device", "=", "labels", ".", "get_device", "(", ")", "\n", "\n", "", "y", "=", "torch", ".", "eye", "(", "num_classes", ")", "\n", "\n", "if", "cuda_check", ":", "\n", "        ", "y", "=", "y", ".", "to", "(", "get_cuda_device", ")", "\n", "\n", "", "return", "y", "[", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot": [[229, 245], ["y_tensor.type().view.type().view", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "y_one_hot.to.view", "y.get_device", "isinstance", "y_one_hot.to.to", "isinstance", "torch.autograd.Variable", "y_tensor.type().view.type", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.max", "torch.max", "torch.max", "y_tensor.type().view.size"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "to_one_hot", "(", "y", ",", "n_dims", "=", "None", ")", ":", "\n", "    ", "\"\"\" Take integer y (tensor or variable) with n dims and convert it to 1-hot representation with n+1 dims. \"\"\"", "\n", "cuda_check", "=", "y", ".", "is_cuda", "\n", "if", "cuda_check", ":", "\n", "        ", "get_cuda_device", "=", "y", ".", "get_device", "(", ")", "\n", "\n", "", "y_tensor", "=", "y", ".", "data", "if", "isinstance", "(", "y", ",", "Variable", ")", "else", "y", "\n", "y_tensor", "=", "y_tensor", ".", "type", "(", "torch", ".", "LongTensor", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "n_dims", "=", "n_dims", "if", "n_dims", "is", "not", "None", "else", "int", "(", "torch", ".", "max", "(", "y_tensor", ")", ")", "+", "1", "\n", "y_one_hot", "=", "torch", ".", "zeros", "(", "y_tensor", ".", "size", "(", ")", "[", "0", "]", ",", "n_dims", ")", ".", "scatter_", "(", "1", ",", "y_tensor", ",", "1", ")", "\n", "y_one_hot", "=", "y_one_hot", ".", "view", "(", "*", "y", ".", "shape", ",", "-", "1", ")", "\n", "\n", "if", "cuda_check", ":", "\n", "        ", "y_one_hot", "=", "y_one_hot", ".", "to", "(", "get_cuda_device", ")", "\n", "\n", "", "return", "Variable", "(", "y_one_hot", ")", "if", "isinstance", "(", "y", ",", "Variable", ")", "else", "y_one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_be_queued": [[247, 261], ["None"], "function", ["None"], ["", "def", "action_can_be_queued", "(", "action_type", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether can be queued\n\n    Inputs: action_type, int\n    Outputs: true or false\n    \"\"\"", "\n", "need_args", "=", "actions", ".", "RAW_FUNCTIONS", "[", "action_type", "]", ".", "args", "\n", "result", "=", "False", "\n", "for", "arg", "in", "need_args", ":", "\n", "        ", "if", "arg", ".", "name", "==", "'queued'", ":", "\n", "            ", "result", "=", "True", "\n", "break", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_be_queued_mask": [[263, 279], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "action_types.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "action_type.item", "utils.action_can_be_queued", "action_types.cpu().detach().numpy.cpu().detach", "print", "action_types.cpu().detach().numpy.cpu"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_be_queued"], ["", "def", "action_can_be_queued_mask", "(", "action_types", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether can be queued\n\n    Inputs: action_types\n    Outputs: mask\n    \"\"\"", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "action_types", ")", "\n", "action_types", "=", "action_types", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", ",", "action_type", "in", "enumerate", "(", "action_types", ")", ":", "\n", "        ", "action_type_index", "=", "action_type", ".", "item", "(", ")", "\n", "print", "(", "'i:'", ",", "i", ",", "'action_type_index:'", ",", "action_type_index", ")", "if", "debug", "else", "None", "\n", "mask", "[", "i", "]", "=", "action_can_be_queued", "(", "action_type_index", ")", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity_types": [[281, 314], ["torch.zeros", "torch.zeros", "torch.zeros", "utils.unit_tpye_to_unit_type_index", "print", "print", "utils.unit_tpye_to_unit_type_index", "utils.unit_tpye_to_unit_type_index"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index"], ["", "def", "action_can_apply_to_entity_types", "(", "action_type", ")", ":", "\n", "    ", "\"\"\"\n    find the entity_types which the action_type can be applied to\n    TAG: TODO\n\n    Inputs: action_type\n    Outputs: mask of applied entity_types\n    \"\"\"", "\n", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "SCHP", ".", "max_unit_type", ")", "\n", "\n", "# note: this can be done when we know which action_type can apply", "\n", "# to certain unit_types which need strong prior knowledge, at present", "\n", "# I don't find there is such an api in pysc2", "\n", "# Thus now we only return a mask means all unit_types accept the action_type", "\n", "if", "action_type", "==", "0", ":", "\n", "#Function.raw_ability(64, \"Train_Probe_quick\", raw_cmd, 1006),", "\n", "        ", "unit_type", "=", "59", "\n", "unit_type_index", "=", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "mask", "[", "0", ",", "unit_type_index", "]", "=", "1", "\n", "print", "(", "\"find Train_Probe_quick\"", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"mask[0, 59]\"", ",", "mask", "[", "0", ",", "unit_type_index", "]", ")", "if", "debug", "else", "None", "\n", "", "elif", "action_type", "==", "1", ":", "\n", "#Function.raw_ability(35, \"Build_Pylon_pt\", raw_cmd_pt, 881),", "\n", "        ", "unit_type", "=", "84", "\n", "unit_type_index", "=", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "mask", "[", "0", ",", "unit_type_index", "]", "=", "1", "\n", "", "elif", "action_type", "==", "2", ":", "\n", "# Function.raw_ability(102, \"Harvest_Gather_unit\", raw_cmd_unit, 3666),", "\n", "        ", "unit_type", "=", "84", "\n", "unit_type_index", "=", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "mask", "[", "0", ",", "unit_type_index", "]", "=", "1", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity_types_mask": [[316, 337], ["action_types.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "torch.cat", "torch.cat", "torch.cat", "action_type.item", "utils.action_can_apply_to_entity_types", "mask_list.append", "action_types.cpu().detach().numpy.cpu().detach", "print", "action_types.cpu().detach().numpy.cpu"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity_types"], ["", "def", "action_can_apply_to_entity_types_mask", "(", "action_types", ")", ":", "\n", "    ", "\"\"\"\n    find the entity_types which the action_type can be applied to\n\n    Inputs: batch of action_type\n    Outputs: mask\n    \"\"\"", "\n", "mask_list", "=", "[", "]", "\n", "action_types", "=", "action_types", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", ",", "action_type", "in", "enumerate", "(", "action_types", ")", ":", "\n", "        ", "action_type_index", "=", "action_type", ".", "item", "(", ")", "\n", "\n", "print", "(", "'i:'", ",", "i", ",", "'action_type_index:'", ",", "action_type_index", ")", "if", "debug", "else", "None", "\n", "\n", "mask", "=", "action_can_apply_to_entity_types", "(", "action_type_index", ")", "\n", "mask_list", ".", "append", "(", "mask", ")", "\n", "\n", "", "batch_mask", "=", "torch", ".", "cat", "(", "mask_list", ",", "dim", "=", "0", ")", "\n", "\n", "return", "batch_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity": [[339, 351], ["None"], "function", ["None"], ["", "def", "action_can_apply_to_entity", "(", "action_type", ")", ":", "\n", "    ", "\"\"\"\n    find the entity_types which the action_type can be applied to\n    TAG: TODO\n\n    Inputs: action_type\n    Outputs: the list of applied entity_types\n    \"\"\"", "\n", "if", "action_type", "%", "2", "==", "0", ":", "\n", "        ", "return", "[", "0", ",", "2", ",", "4", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "1", ",", "3", ",", "7", ",", "11", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw": [[353, 369], ["None"], "function", ["None"], ["", "", "def", "action_type_index_map_raw", "(", "action_type", ")", ":", "\n", "# map action type form (0,1,2,...) to raw function id  (64, 35, 102, ...)", "\n", "\n", "    ", "raw_function_id", "=", "0", "\n", "\n", "if", "action_type", "==", "0", ":", "\n", "#Function.raw_ability(64, \"Train_Probe_quick\", raw_cmd, 1006),", "\n", "        ", "raw_function_id", "=", "64", "\n", "", "elif", "action_type", "==", "1", ":", "\n", "#Function.raw_ability(35, \"Build_Pylon_pt\", raw_cmd_pt, 881),", "\n", "        ", "raw_function_id", "=", "35", "\n", "", "elif", "action_type", "==", "2", ":", "\n", "# Function.raw_ability(102, \"Harvest_Gather_unit\", raw_cmd_unit, 3666),", "\n", "        ", "raw_function_id", "=", "102", "\n", "\n", "", "return", "raw_function_id", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_human": [[371, 397], ["None"], "function", ["None"], ["", "def", "action_type_index_map_human", "(", "action_type", ")", ":", "\n", "# map action type form (0,1,2,...) to human function id  (64, 35, 102, ...)", "\n", "\n", "    ", "function_id", "=", "0", "\n", "\n", "if", "action_type", "==", "0", ":", "\n", "\n", "        ", "function_id", "=", "485", "# Function.ability(485, \"Train_Probe_quick\", cmd_quick, 1006),", "\n", "\n", "", "elif", "action_type", "==", "1", ":", "\n", "\n", "        ", "function_id", "=", "70", "# Function.ability(70, \"Build_Pylon_screen\", cmd_screen, 881),", "\n", "\n", "", "elif", "action_type", "==", "2", ":", "\n", "\n", "        ", "function_id", "=", "264", "# Function.ability(264, \"Harvest_Gather_screen\", cmd_screen, 3666),", "\n", "\n", "", "elif", "action_type", "==", "3", ":", "\n", "\n", "        ", "function_id", "=", "1", "# Function.ui_func(1, \"move_camera\", move_camera), ", "\n", "\n", "", "elif", "action_type", "==", "4", ":", "\n", "\n", "        ", "function_id", "=", "2", "# Function.ui_func(2, \"select_point\", select_point),", "\n", "\n", "", "return", "function_id", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_selecting_units": [[399, 414], ["utils.action_type_index_map_raw"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw"], ["", "def", "action_involve_selecting_units", "(", "action_type_index", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type_index whether involve selecting units\n\n    Inputs: action_type_index\n    Outputs: true or false\n    \"\"\"", "\n", "\n", "need_args", "=", "actions", ".", "RAW_FUNCTIONS", "[", "action_type_index_map_raw", "(", "action_type_index", ")", "]", ".", "args", "\n", "result", "=", "False", "\n", "for", "arg", "in", "need_args", ":", "\n", "        ", "if", "arg", ".", "name", "==", "'unit_tags'", ":", "\n", "            ", "result", "=", "True", "\n", "break", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_selecting_units_mask": [[416, 435], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "action_types.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "action_type.item", "utils.action_involve_selecting_units", "action_types.cpu().detach().numpy.cpu().detach", "print", "action_types.cpu().detach().numpy.cpu"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_selecting_units"], ["", "def", "action_involve_selecting_units_mask", "(", "action_types", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether involve selecting units\n\n    Inputs: batch action_types\n    Outputs: mask\n    \"\"\"", "\n", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "action_types", ")", "\n", "action_types", "=", "action_types", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", ",", "action_type", "in", "enumerate", "(", "action_types", ")", ":", "\n", "        ", "action_type_index", "=", "action_type", ".", "item", "(", ")", "\n", "\n", "print", "(", "'i:'", ",", "i", ",", "'action_type_index:'", ",", "action_type_index", ")", "if", "debug", "else", "None", "\n", "\n", "mask", "[", "i", "]", "=", "action_involve_selecting_units", "(", "action_type_index", ")", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_units": [[437, 451], ["utils.action_type_index_map_raw"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw"], ["", "def", "action_involve_targeting_units", "(", "action_type_index", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether involve targeting units\n\n    Inputs: action_type_index\n    Outputs: true or false\n    \"\"\"", "\n", "need_args", "=", "actions", ".", "RAW_FUNCTIONS", "[", "action_type_index_map_raw", "(", "action_type_index", ")", "]", ".", "args", "\n", "result", "=", "False", "\n", "for", "arg", "in", "need_args", ":", "\n", "        ", "if", "arg", ".", "name", "==", "'target_unit_tag'", ":", "\n", "            ", "result", "=", "True", "\n", "break", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_units_mask": [[453, 472], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "action_types.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "action_type.item", "utils.action_involve_targeting_units", "action_types.cpu().detach().numpy.cpu().detach", "print", "action_types.cpu().detach().numpy.cpu"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_units"], ["", "def", "action_involve_targeting_units_mask", "(", "action_types", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether involve targeting units\n\n    Inputs: batch action_types\n    Outputs: mask\n    \"\"\"", "\n", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "action_types", ")", "\n", "action_types", "=", "action_types", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", ",", "action_type", "in", "enumerate", "(", "action_types", ")", ":", "\n", "        ", "action_type_index", "=", "action_type", ".", "item", "(", ")", "\n", "\n", "print", "(", "'i:'", ",", "i", ",", "'action_type_index:'", ",", "action_type_index", ")", "if", "debug", "else", "None", "\n", "\n", "mask", "[", "i", "]", "=", "action_involve_targeting_units", "(", "action_type_index", ")", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_location": [[474, 498], ["utils.action_type_index_map_raw", "utils.action_type_index_map_human"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_human"], ["", "def", "action_involve_targeting_location", "(", "action_type_index", ",", "raw", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type_index whether involve targeting location\n    Inputs: action_type_index\n    Outputs: true or false\n    \"\"\"", "\n", "if", "raw", ":", "\n", "        ", "need_args", "=", "actions", ".", "RAW_FUNCTIONS", "[", "action_type_index_map_raw", "(", "action_type_index", ")", "]", ".", "args", "\n", "result", "=", "False", "\n", "for", "arg", "in", "need_args", ":", "\n", "            ", "if", "arg", ".", "name", "==", "'world'", ":", "\n", "                ", "result", "=", "True", "\n", "break", "\n", "", "", "", "else", ":", "\n", "        ", "need_args", "=", "actions", ".", "FUNCTIONS", "[", "action_type_index_map_human", "(", "action_type_index", ")", "]", ".", "args", "\n", "result", "=", "False", "\n", "for", "arg", "in", "need_args", ":", "\n", "            ", "if", "arg", ".", "name", "==", "'screen'", ":", "\n", "                ", "result", "=", "True", "\n", "break", "\n", "", "if", "arg", ".", "name", "==", "'minimap'", ":", "\n", "                ", "result", "=", "True", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_location_mask": [[500, 519], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "action_types.cpu().detach().numpy.cpu().detach().numpy", "enumerate", "action_type.item", "utils.action_involve_targeting_location", "action_types.cpu().detach().numpy.cpu().detach", "print", "action_types.cpu().detach().numpy.cpu"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_location"], ["", "def", "action_involve_targeting_location_mask", "(", "action_types", ",", "raw", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    test the action_type whether involve targeting location\n\n    Inputs: batch action_types\n    Outputs: mask\n    \"\"\"", "\n", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "action_types", ")", "\n", "action_types", "=", "action_types", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", ",", "action_type", "in", "enumerate", "(", "action_types", ")", ":", "\n", "        ", "action_type_index", "=", "action_type", ".", "item", "(", ")", "\n", "\n", "print", "(", "'i:'", ",", "i", ",", "'action_type_index:'", ",", "action_type_index", ")", "if", "debug", "else", "None", "\n", "\n", "mask", "[", "i", "]", "=", "action_involve_targeting_location", "(", "action_type_index", ",", "raw", "=", "raw", ")", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.test": [[521, 524], ["print"], "function", ["None"], ["", "def", "test", "(", ")", ":", "\n", "\n", "    ", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Modules.ScaledDotProductAttention.__init__": [[10, 14], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Modules.ScaledDotProductAttention.forward": [[15, 26], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Modules.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "attn.masked_fill.masked_fill.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "\n", "", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Layers.EncoderLayer.__init__": [[13, 17], ["torch.Module.__init__", "transformer.SubLayers.MultiHeadAttention", "transformer.SubLayers.PositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Layers.EncoderLayer.forward": [[18, 23], ["Layers.EncoderLayer.slf_attn", "Layers.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "slf_attn_mask", "=", "None", ")", ":", "\n", "        ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "\n", "enc_input", ",", "enc_input", ",", "enc_input", ",", "mask", "=", "slf_attn_mask", ")", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Layers.DecoderLayer.__init__": [[28, 33], ["torch.Module.__init__", "transformer.SubLayers.MultiHeadAttention", "transformer.SubLayers.MultiHeadAttention", "transformer.SubLayers.PositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "enc_attn", "=", "MultiHeadAttention", "(", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Layers.DecoderLayer.forward": [[34, 43], ["Layers.DecoderLayer.slf_attn", "Layers.DecoderLayer.enc_attn", "Layers.DecoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "dec_input", ",", "enc_output", ",", "\n", "slf_attn_mask", "=", "None", ",", "dec_enc_attn_mask", "=", "None", ")", ":", "\n", "        ", "dec_output", ",", "dec_slf_attn", "=", "self", ".", "slf_attn", "(", "\n", "dec_input", ",", "dec_input", ",", "dec_input", ",", "mask", "=", "slf_attn_mask", ")", "\n", "dec_output", ",", "dec_enc_attn", "=", "self", ".", "enc_attn", "(", "\n", "dec_output", ",", "enc_output", ",", "enc_output", ",", "mask", "=", "dec_enc_attn_mask", ")", "\n", "dec_output", "=", "self", ".", "pos_ffn", "(", "dec_output", ")", "\n", "return", "dec_output", ",", "dec_slf_attn", ",", "dec_enc_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.PositionalEncoding.__init__": [[25, 30], ["torch.Module.__init__", "Models.PositionalEncoding.register_buffer", "Models.PositionalEncoding._get_sinusoid_encoding_table"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.PositionalEncoding._get_sinusoid_encoding_table"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "n_position", "=", "200", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Not a parameter", "\n", "self", ".", "register_buffer", "(", "'pos_table'", ",", "self", ".", "_get_sinusoid_encoding_table", "(", "n_position", ",", "d_hid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.PositionalEncoding._get_sinusoid_encoding_table": [[31, 43], ["numpy.array", "numpy.sin", "numpy.cos", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "Models.PositionalEncoding._get_sinusoid_encoding_table.get_position_angle_vec"], "methods", ["None"], ["", "def", "_get_sinusoid_encoding_table", "(", "self", ",", "n_position", ",", "d_hid", ")", ":", "\n", "        ", "''' Sinusoid position encoding table '''", "\n", "# TODO: make it with torch instead of numpy", "\n", "\n", "def", "get_position_angle_vec", "(", "position", ")", ":", "\n", "            ", "return", "[", "position", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "hid_j", "//", "2", ")", "/", "d_hid", ")", "for", "hid_j", "in", "range", "(", "d_hid", ")", "]", "\n", "\n", "", "sinusoid_table", "=", "np", ".", "array", "(", "[", "get_position_angle_vec", "(", "pos_i", ")", "for", "pos_i", "in", "range", "(", "n_position", ")", "]", ")", "\n", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "sinusoid_table", "[", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "sinusoid_table", "[", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "sinusoid_table", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.PositionalEncoding.forward": [[44, 46], ["Models.PositionalEncoding.pos_table[].clone().detach", "Models.PositionalEncoding.pos_table[].clone", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "+", "self", ".", "pos_table", "[", ":", ",", ":", "x", ".", "size", "(", "1", ")", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Encoder.__init__": [[51, 64], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "Models.PositionalEncoding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "transformer.Layers.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "\n", "self", ",", "n_src_vocab", ",", "d_word_vec", ",", "n_layers", ",", "n_head", ",", "d_k", ",", "d_v", ",", "\n", "d_model", ",", "d_inner", ",", "pad_idx", ",", "dropout", "=", "0.1", ",", "n_position", "=", "200", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "src_word_emb", "=", "nn", ".", "Embedding", "(", "n_src_vocab", ",", "d_word_vec", ",", "padding_idx", "=", "pad_idx", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_word_vec", ",", "n_position", "=", "n_position", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "layer_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "EncoderLayer", "(", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Encoder.forward": [[65, 82], ["Models.Encoder.dropout", "Models.Encoder.layer_norm", "Models.Encoder.position_enc", "enc_layer", "Models.Encoder.src_word_emb"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_seq", ",", "src_mask", ",", "return_attns", "=", "False", ")", ":", "\n", "\n", "        ", "enc_slf_attn_list", "=", "[", "]", "\n", "\n", "# -- Forward", "\n", "\n", "enc_output", "=", "self", ".", "dropout", "(", "self", ".", "position_enc", "(", "self", ".", "src_word_emb", "(", "src_seq", ")", ")", ")", "\n", "\n", "for", "enc_layer", "in", "self", ".", "layer_stack", ":", "\n", "            ", "enc_output", ",", "enc_slf_attn", "=", "enc_layer", "(", "enc_output", ",", "slf_attn_mask", "=", "src_mask", ")", "\n", "enc_slf_attn_list", "+=", "[", "enc_slf_attn", "]", "if", "return_attns", "else", "[", "]", "\n", "\n", "", "enc_output", "=", "self", ".", "layer_norm", "(", "enc_output", ")", "\n", "\n", "if", "return_attns", ":", "\n", "            ", "return", "enc_output", ",", "enc_slf_attn_list", "\n", "", "return", "enc_output", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Decoder.__init__": [[87, 100], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "Models.PositionalEncoding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "transformer.Layers.DecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "\n", "self", ",", "n_trg_vocab", ",", "d_word_vec", ",", "n_layers", ",", "n_head", ",", "d_k", ",", "d_v", ",", "\n", "d_model", ",", "d_inner", ",", "pad_idx", ",", "n_position", "=", "200", ",", "dropout", "=", "0.1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "trg_word_emb", "=", "nn", ".", "Embedding", "(", "n_trg_vocab", ",", "d_word_vec", ",", "padding_idx", "=", "pad_idx", ")", "\n", "self", ".", "position_enc", "=", "PositionalEncoding", "(", "d_word_vec", ",", "n_position", "=", "n_position", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "layer_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "DecoderLayer", "(", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Decoder.forward": [[101, 119], ["Models.Decoder.dropout", "Models.Decoder.layer_norm", "Models.Decoder.position_enc", "dec_layer", "Models.Decoder.trg_word_emb"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "trg_seq", ",", "trg_mask", ",", "enc_output", ",", "src_mask", ",", "return_attns", "=", "False", ")", ":", "\n", "\n", "        ", "dec_slf_attn_list", ",", "dec_enc_attn_list", "=", "[", "]", ",", "[", "]", "\n", "\n", "# -- Forward", "\n", "dec_output", "=", "self", ".", "dropout", "(", "self", ".", "position_enc", "(", "self", ".", "trg_word_emb", "(", "trg_seq", ")", ")", ")", "\n", "\n", "for", "dec_layer", "in", "self", ".", "layer_stack", ":", "\n", "            ", "dec_output", ",", "dec_slf_attn", ",", "dec_enc_attn", "=", "dec_layer", "(", "\n", "dec_output", ",", "enc_output", ",", "slf_attn_mask", "=", "trg_mask", ",", "dec_enc_attn_mask", "=", "src_mask", ")", "\n", "dec_slf_attn_list", "+=", "[", "dec_slf_attn", "]", "if", "return_attns", "else", "[", "]", "\n", "dec_enc_attn_list", "+=", "[", "dec_enc_attn", "]", "if", "return_attns", "else", "[", "]", "\n", "\n", "", "dec_output", "=", "self", ".", "layer_norm", "(", "dec_output", ")", "\n", "\n", "if", "return_attns", ":", "\n", "            ", "return", "dec_output", ",", "dec_slf_attn_list", ",", "dec_enc_attn_list", "\n", "", "return", "dec_output", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Transformer.__init__": [[124, 164], ["torch.Module.__init__", "Models.Encoder", "Models.Decoder", "torch.Linear", "torch.Linear", "Models.Transformer.parameters", "p.dim", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "\n", "self", ",", "n_src_vocab", ",", "n_trg_vocab", ",", "src_pad_idx", ",", "trg_pad_idx", ",", "\n", "d_word_vec", "=", "512", ",", "d_model", "=", "512", ",", "d_inner", "=", "2048", ",", "\n", "n_layers", "=", "6", ",", "n_head", "=", "8", ",", "d_k", "=", "64", ",", "d_v", "=", "64", ",", "dropout", "=", "0.1", ",", "n_position", "=", "200", ",", "\n", "trg_emb_prj_weight_sharing", "=", "True", ",", "emb_src_trg_weight_sharing", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "src_pad_idx", ",", "self", ".", "trg_pad_idx", "=", "src_pad_idx", ",", "trg_pad_idx", "\n", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "n_src_vocab", "=", "n_src_vocab", ",", "n_position", "=", "n_position", ",", "\n", "d_word_vec", "=", "d_word_vec", ",", "d_model", "=", "d_model", ",", "d_inner", "=", "d_inner", ",", "\n", "n_layers", "=", "n_layers", ",", "n_head", "=", "n_head", ",", "d_k", "=", "d_k", ",", "d_v", "=", "d_v", ",", "\n", "pad_idx", "=", "src_pad_idx", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "decoder", "=", "Decoder", "(", "\n", "n_trg_vocab", "=", "n_trg_vocab", ",", "n_position", "=", "n_position", ",", "\n", "d_word_vec", "=", "d_word_vec", ",", "d_model", "=", "d_model", ",", "d_inner", "=", "d_inner", ",", "\n", "n_layers", "=", "n_layers", ",", "n_head", "=", "n_head", ",", "d_k", "=", "d_k", ",", "d_v", "=", "d_v", ",", "\n", "pad_idx", "=", "trg_pad_idx", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "trg_word_prj", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_trg_vocab", ",", "bias", "=", "False", ")", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "assert", "d_model", "==", "d_word_vec", ",", "'To facilitate the residual connections, \\\n         the dimensions of all module outputs shall be the same.'", "\n", "\n", "self", ".", "x_logit_scale", "=", "1.", "\n", "if", "trg_emb_prj_weight_sharing", ":", "\n", "# Share the weight between target word embedding & last dense layer", "\n", "            ", "self", ".", "trg_word_prj", ".", "weight", "=", "self", ".", "decoder", ".", "trg_word_emb", ".", "weight", "\n", "self", ".", "x_logit_scale", "=", "(", "d_model", "**", "-", "0.5", ")", "\n", "\n", "", "if", "emb_src_trg_weight_sharing", ":", "\n", "            ", "self", ".", "encoder", ".", "src_word_emb", ".", "weight", "=", "self", ".", "decoder", ".", "trg_word_emb", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.Transformer.forward": [[166, 176], ["Models.get_pad_mask", "Models.Transformer.encoder", "Models.Transformer.decoder", "seq_logit.view", "Models.get_pad_mask", "Models.get_subsequent_mask", "Models.Transformer.trg_word_prj", "seq_logit.size"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_pad_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_pad_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_subsequent_mask"], ["", "", "def", "forward", "(", "self", ",", "src_seq", ",", "trg_seq", ")", ":", "\n", "\n", "        ", "src_mask", "=", "get_pad_mask", "(", "src_seq", ",", "self", ".", "src_pad_idx", ")", "\n", "trg_mask", "=", "get_pad_mask", "(", "trg_seq", ",", "self", ".", "trg_pad_idx", ")", "&", "get_subsequent_mask", "(", "trg_seq", ")", "\n", "\n", "enc_output", ",", "*", "_", "=", "self", ".", "encoder", "(", "src_seq", ",", "src_mask", ")", "\n", "dec_output", ",", "*", "_", "=", "self", ".", "decoder", "(", "trg_seq", ",", "trg_mask", ",", "enc_output", ",", "src_mask", ")", "\n", "seq_logit", "=", "self", ".", "trg_word_prj", "(", "dec_output", ")", "*", "self", ".", "x_logit_scale", "\n", "\n", "return", "seq_logit", ".", "view", "(", "-", "1", ",", "seq_logit", ".", "size", "(", "2", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_pad_mask": [[11, 13], ["None"], "function", ["None"], ["def", "get_pad_mask", "(", "seq", ",", "pad_idx", ")", ":", "\n", "    ", "return", "(", "seq", "!=", "pad_idx", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_subsequent_mask": [[15, 21], ["seq.size", "torch.triu", "torch.triu", "torch.ones", "torch.ones"], "function", ["None"], ["", "def", "get_subsequent_mask", "(", "seq", ")", ":", "\n", "    ", "''' For masking out the subsequent info. '''", "\n", "sz_b", ",", "len_s", "=", "seq", ".", "size", "(", ")", "\n", "subsequent_mask", "=", "(", "1", "-", "torch", ".", "triu", "(", "\n", "torch", ".", "ones", "(", "(", "1", ",", "len_s", ",", "len_s", ")", ",", "device", "=", "seq", ".", "device", ")", ",", "diagonal", "=", "1", ")", ")", ".", "bool", "(", ")", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator.__init__": [[12, 37], ["torch.Module.__init__", "Translator.Translator.model.eval", "Translator.Translator.register_buffer", "Translator.Translator.register_buffer", "Translator.Translator.register_buffer", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.eval"], ["def", "__init__", "(", "\n", "self", ",", "model", ",", "beam_size", ",", "max_seq_len", ",", "\n", "src_pad_idx", ",", "trg_pad_idx", ",", "trg_bos_idx", ",", "trg_eos_idx", ")", ":", "\n", "\n", "\n", "        ", "super", "(", "Translator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "alpha", "=", "0.7", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "src_pad_idx", "=", "src_pad_idx", "\n", "self", ".", "trg_bos_idx", "=", "trg_bos_idx", "\n", "self", ".", "trg_eos_idx", "=", "trg_eos_idx", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'init_seq'", ",", "torch", ".", "LongTensor", "(", "[", "[", "trg_bos_idx", "]", "]", ")", ")", "\n", "self", ".", "register_buffer", "(", "\n", "'blank_seqs'", ",", "\n", "torch", ".", "full", "(", "(", "beam_size", ",", "max_seq_len", ")", ",", "trg_pad_idx", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "self", ".", "blank_seqs", "[", ":", ",", "0", "]", "=", "self", ".", "trg_bos_idx", "\n", "self", ".", "register_buffer", "(", "\n", "'len_map'", ",", "\n", "torch", ".", "arange", "(", "1", ",", "max_seq_len", "+", "1", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._model_decode": [[39, 43], ["transformer.Models.get_subsequent_mask", "Translator.Translator.model.decoder", "torch.softmax", "torch.softmax", "torch.softmax", "Translator.Translator.model.trg_word_prj"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_subsequent_mask"], ["", "def", "_model_decode", "(", "self", ",", "trg_seq", ",", "enc_output", ",", "src_mask", ")", ":", "\n", "        ", "trg_mask", "=", "get_subsequent_mask", "(", "trg_seq", ")", "\n", "dec_output", ",", "*", "_", "=", "self", ".", "model", ".", "decoder", "(", "trg_seq", ",", "trg_mask", ",", "enc_output", ",", "src_mask", ")", "\n", "return", "F", ".", "softmax", "(", "self", ".", "model", ".", "trg_word_prj", "(", "dec_output", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._get_init_state": [[45, 58], ["Translator.Translator.model.encoder", "Translator.Translator._model_decode", "dec_output[].topk", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "Translator.Translator.blank_seqs.clone().detach", "enc_output.repeat.repeat.repeat", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "Translator.Translator.blank_seqs.clone"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._model_decode"], ["", "def", "_get_init_state", "(", "self", ",", "src_seq", ",", "src_mask", ")", ":", "\n", "        ", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "enc_output", ",", "*", "_", "=", "self", ".", "model", ".", "encoder", "(", "src_seq", ",", "src_mask", ")", "\n", "dec_output", "=", "self", ".", "_model_decode", "(", "self", ".", "init_seq", ",", "enc_output", ",", "src_mask", ")", "\n", "\n", "best_k_probs", ",", "best_k_idx", "=", "dec_output", "[", ":", ",", "-", "1", ",", ":", "]", ".", "topk", "(", "beam_size", ")", "\n", "\n", "scores", "=", "torch", ".", "log", "(", "best_k_probs", ")", ".", "view", "(", "beam_size", ")", "\n", "gen_seq", "=", "self", ".", "blank_seqs", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "gen_seq", "[", ":", ",", "1", "]", "=", "best_k_idx", "[", "0", "]", "\n", "enc_output", "=", "enc_output", ".", "repeat", "(", "beam_size", ",", "1", ",", "1", ")", "\n", "return", "enc_output", ",", "gen_seq", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._get_the_best_score_and_idx": [[60, 84], ["dec_output[].topk", "scores.view().topk", "len", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.log().view", "scores.view", "scores.size", "scores.view", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "_get_the_best_score_and_idx", "(", "self", ",", "gen_seq", ",", "dec_output", ",", "scores", ",", "step", ")", ":", "\n", "        ", "assert", "len", "(", "scores", ".", "size", "(", ")", ")", "==", "1", "\n", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "\n", "# Get k candidates for each beam, k^2 candidates in total.", "\n", "best_k2_probs", ",", "best_k2_idx", "=", "dec_output", "[", ":", ",", "-", "1", ",", ":", "]", ".", "topk", "(", "beam_size", ")", "\n", "\n", "# Include the previous scores.", "\n", "scores", "=", "torch", ".", "log", "(", "best_k2_probs", ")", ".", "view", "(", "beam_size", ",", "-", "1", ")", "+", "scores", ".", "view", "(", "beam_size", ",", "1", ")", "\n", "\n", "# Get the best k candidates from k^2 candidates.", "\n", "scores", ",", "best_k_idx_in_k2", "=", "scores", ".", "view", "(", "-", "1", ")", ".", "topk", "(", "beam_size", ")", "\n", "\n", "# Get the corresponding positions of the best k candidiates.", "\n", "best_k_r_idxs", ",", "best_k_c_idxs", "=", "best_k_idx_in_k2", "//", "beam_size", ",", "best_k_idx_in_k2", "%", "beam_size", "\n", "best_k_idx", "=", "best_k2_idx", "[", "best_k_r_idxs", ",", "best_k_c_idxs", "]", "\n", "\n", "# Copy the corresponding previous tokens.", "\n", "gen_seq", "[", ":", ",", ":", "step", "]", "=", "gen_seq", "[", "best_k_r_idxs", ",", ":", "step", "]", "\n", "# Set the best tokens in this beam search step", "\n", "gen_seq", "[", ":", ",", "step", "]", "=", "best_k_idx", "\n", "\n", "return", "gen_seq", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator.translate_sentence": [[86, 115], ["[].tolist", "src_seq.size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer.Models.get_pad_mask", "Translator.Translator._get_init_state", "range", "Translator.Translator._model_decode", "Translator.Translator._get_the_best_score_and_idx", "Translator.Translator.len_map.masked_fill().min", "scores.div().max", "ans_idx.item.item.item", "Translator.Translator.len_map.masked_fill", "scores.div", "seq_lens.float", "eos_locs.sum"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Models.get_pad_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._get_init_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._model_decode", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Translator.Translator._get_the_best_score_and_idx"], ["", "def", "translate_sentence", "(", "self", ",", "src_seq", ")", ":", "\n", "# Only accept batch size equals to 1 in this function.", "\n", "# TODO: expand to batch operation.", "\n", "        ", "assert", "src_seq", ".", "size", "(", "0", ")", "==", "1", "\n", "\n", "src_pad_idx", ",", "trg_eos_idx", "=", "self", ".", "src_pad_idx", ",", "self", ".", "trg_eos_idx", "\n", "max_seq_len", ",", "beam_size", ",", "alpha", "=", "self", ".", "max_seq_len", ",", "self", ".", "beam_size", ",", "self", ".", "alpha", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "src_mask", "=", "get_pad_mask", "(", "src_seq", ",", "src_pad_idx", ")", "\n", "enc_output", ",", "gen_seq", ",", "scores", "=", "self", ".", "_get_init_state", "(", "src_seq", ",", "src_mask", ")", "\n", "\n", "ans_idx", "=", "0", "# default", "\n", "for", "step", "in", "range", "(", "2", ",", "max_seq_len", ")", ":", "# decode up to max length", "\n", "                ", "dec_output", "=", "self", ".", "_model_decode", "(", "gen_seq", "[", ":", ",", ":", "step", "]", ",", "enc_output", ",", "src_mask", ")", "\n", "gen_seq", ",", "scores", "=", "self", ".", "_get_the_best_score_and_idx", "(", "gen_seq", ",", "dec_output", ",", "scores", ",", "step", ")", "\n", "\n", "# Check if all path finished", "\n", "# -- locate the eos in the generated sequences", "\n", "eos_locs", "=", "gen_seq", "==", "trg_eos_idx", "\n", "# -- replace the eos with its position for the length penalty use", "\n", "seq_lens", ",", "_", "=", "self", ".", "len_map", ".", "masked_fill", "(", "~", "eos_locs", ",", "max_seq_len", ")", ".", "min", "(", "1", ")", "\n", "# -- check if all beams contain eos", "\n", "if", "(", "eos_locs", ".", "sum", "(", "1", ")", ">", "0", ")", ".", "sum", "(", "0", ")", ".", "item", "(", ")", "==", "beam_size", ":", "\n", "# TODO: Try different terminate conditions.", "\n", "                    ", "_", ",", "ans_idx", "=", "scores", ".", "div", "(", "seq_lens", ".", "float", "(", ")", "**", "alpha", ")", ".", "max", "(", "0", ")", "\n", "ans_idx", "=", "ans_idx", ".", "item", "(", ")", "\n", "break", "\n", "", "", "", "return", "gen_seq", "[", "ans_idx", "]", "[", ":", "seq_lens", "[", "ans_idx", "]", "]", ".", "tolist", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.__init__": [[7, 13], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "init_lr", ",", "d_model", ",", "n_warmup_steps", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "init_lr", "=", "init_lr", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_warmup_steps", "=", "n_warmup_steps", "\n", "self", ".", "n_steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.step_and_update_lr": [[15, 19], ["Optim.ScheduledOptim._update_learning_rate", "Optim.ScheduledOptim._optimizer.step"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim._update_learning_rate", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step"], ["", "def", "step_and_update_lr", "(", "self", ")", ":", "\n", "        ", "\"Step with the inner optimizer\"", "\n", "self", ".", "_update_learning_rate", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad": [[21, 24], ["Optim.ScheduledOptim._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"Zero out the gradients with the inner optimizer\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim._get_lr_scale": [[26, 30], ["min"], "methods", ["None"], ["", "def", "_get_lr_scale", "(", "self", ")", ":", "\n", "        ", "d_model", "=", "self", ".", "d_model", "\n", "n_steps", ",", "n_warmup_steps", "=", "self", ".", "n_steps", ",", "self", ".", "n_warmup_steps", "\n", "return", "(", "d_model", "**", "-", "0.5", ")", "*", "min", "(", "n_steps", "**", "(", "-", "0.5", ")", ",", "n_steps", "*", "n_warmup_steps", "**", "(", "-", "1.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim._update_learning_rate": [[32, 40], ["Optim.ScheduledOptim._get_lr_scale"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim._get_lr_scale"], ["", "def", "_update_learning_rate", "(", "self", ")", ":", "\n", "        ", "''' Learning rate scheduling per step '''", "\n", "\n", "self", ".", "n_steps", "+=", "1", "\n", "lr", "=", "self", ".", "init_lr", "*", "self", ".", "_get_lr_scale", "(", ")", "\n", "\n", "for", "param_group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.SubLayers.MultiHeadAttention.__init__": [[16, 32], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.third.transformer.Modules.ScaledDotProductAttention", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.SubLayers.MultiHeadAttention.forward": [[33, 70], ["SubLayers.MultiHeadAttention.layer_norm", "SubLayers.MultiHeadAttention.w_qs().view", "SubLayers.MultiHeadAttention.w_ks().view", "SubLayers.MultiHeadAttention.w_vs().view", "SubLayers.MultiHeadAttention.attention", "SubLayers.MultiHeadAttention.transpose().contiguous().view", "SubLayers.MultiHeadAttention.dropout", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.transpose", "SubLayers.MultiHeadAttention.transpose", "SubLayers.MultiHeadAttention.transpose", "mask.unsqueeze.unsqueeze.unsqueeze", "SubLayers.MultiHeadAttention.fc", "SubLayers.MultiHeadAttention.w_qs", "SubLayers.MultiHeadAttention.w_ks", "SubLayers.MultiHeadAttention.w_vs", "SubLayers.MultiHeadAttention.transpose().contiguous", "SubLayers.MultiHeadAttention.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "q", "\n", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "# print('q.shape:', q.shape) if debug else None", "\n", "\n", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# For head axis broadcasting.", "\n", "\n", "", "q", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ",", "mask", "=", "mask", ")", "\n", "\n", "# q = (b, n, lq, dk) k = (b, n, lk, dk), atten = q x k_t = (b, n, lq, lk)", "\n", "# v = (b, n, lv, dv), assert lv = lk", "\n", "# atten x v = (b, n, lq, dv)", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "q", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "q", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "q", ")", ")", "\n", "\n", "# q = (b, lq, n * dv) x (n * d_v, d_m) = (b, lq, d_m)", "\n", "q", "=", "q", "+", "residual", "\n", "\n", "return", "q", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.SubLayers.PositionwiseFeedForward.__init__": [[75, 81], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "# position-wise", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.SubLayers.PositionwiseFeedForward.forward": [[82, 92], ["SubLayers.PositionwiseFeedForward.layer_norm", "SubLayers.PositionwiseFeedForward.w_2", "SubLayers.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "SubLayers.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "w_2", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "x", "+", "residual", "\n", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_feature_label.print_tensor_list": [[31, 37], ["isinstance", "load_feature_label.print_tensor_list", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_pickle.print_tensor_list"], ["def", "print_tensor_list", "(", "tensor_list", ")", ":", "\n", "    ", "for", "l", "in", "tensor_list", ":", "\n", "        ", "if", "isinstance", "(", "l", ",", "list", ")", ":", "\n", "            ", "print_tensor_list", "(", "l", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "l", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_feature_label.test": [[39, 88], ["print", "os.listdir", "print", "os.listdir.sort", "alphastarmini.core.arch.agent.Agent", "tqdm.tqdm", "print", "print", "len", "print", "torch.load", "range", "len", "len", "len", "print", "print", "alphastarmini.core.sl.feature.Feature.feature2state", "alphastarmini.core.sl.label.Label.label2action", "print", "print", "print", "traj.append", "traceback.print_exc", "len"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.feature2state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.label2action"], ["", "", "", "def", "test", "(", ")", ":", "\n", "    ", "DATA_PATH", "=", "FLAGS", ".", "replay_data_path", "\n", "print", "(", "'data path:'", ",", "DATA_PATH", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "replay_files", ".", "sort", "(", ")", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "j", "=", "0", "\n", "replay_length_list", "=", "[", "]", "\n", "traj_list", "=", "[", "]", "\n", "for", "replay_file", "in", "tqdm", "(", "replay_files", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "replay_path", "=", "DATA_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "\n", "traj", "=", "[", "]", "\n", "m", "=", "torch", ".", "load", "(", "replay_path", ")", "\n", "features", "=", "m", "[", "'features'", "]", "\n", "labels", "=", "m", "[", "'labels'", "]", "\n", "\n", "assert", "len", "(", "features", ")", "==", "len", "(", "labels", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "                ", "feature", "=", "features", "[", "i", ":", "i", "+", "1", ",", ":", "]", "\n", "label", "=", "labels", "[", "i", ":", "i", "+", "1", ",", ":", "]", "\n", "isfinal", "=", "0", "\n", "if", "i", "==", "len", "(", "features", ")", "-", "1", ":", "\n", "                    ", "isfinal", "=", "1", "\n", "\n", "", "print", "(", "'feature.shape:'", ",", "feature", ".", "shape", ")", "\n", "print", "(", "'label.shape:'", ",", "label", ".", "shape", ")", "\n", "\n", "state", "=", "Feature", ".", "feature2state", "(", "feature", ")", "\n", "action_gt", "=", "Label", ".", "label2action", "(", "label", ")", "\n", "\n", "print", "(", "\"action_gt:\"", ",", "action_gt", ")", "\n", "print", "(", "'state:'", ",", "state", ")", "\n", "print", "(", "'isfinal:'", ",", "isfinal", ")", "\n", "#action_logits_prdict = agent.action_logits_by_state(state)", "\n", "#print(\"action_logits_prdict:\", action_logits_prdict)", "\n", "\n", "traj", ".", "append", "(", "[", "state", ",", "action_gt", ",", "isfinal", "]", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "print", "(", "\"end\"", ")", "\n", "print", "(", "\"replay_length_list:\"", ",", "replay_length_list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_replay_info.check_info": [[55, 65], ["print", "print", "print"], "function", ["None"], ["def", "check_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_actual", "\n", "player2_race", "=", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_actual", "\n", "\n", "print", "(", "'map_name:'", ",", "map_name", ")", "\n", "print", "(", "'player1_race:'", ",", "player1_race", ")", "\n", "print", "(", "'player2_race:'", ",", "player2_race", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_replay_info.store_info": [[67, 82], ["None"], "function", ["None"], ["", "def", "store_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "RACE", "[", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_requested", "-", "1", "]", "\n", "player2_race", "=", "RACE", "[", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_requested", "-", "1", "]", "\n", "game_duration_loops", "=", "replay_info", ".", "game_duration_loops", "\n", "game_duration_seconds", "=", "replay_info", ".", "game_duration_seconds", "\n", "game_version", "=", "replay_info", ".", "game_version", "\n", "game_result", "=", "RESULT", "[", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_result", ".", "result", "-", "1", "]", "\n", "return", "[", "map_name", ",", "\n", "game_version", ",", "\n", "game_result", ",", "\n", "player1_race", ",", "\n", "player2_race", ",", "\n", "game_duration_loops", ",", "\n", "game_duration_seconds", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_replay_info.main": [[84, 192], ["pysc2.run_configs.get", "print", "os.listdir", "print", "set", "pysc2.lib.point.Point", "pysc2.lib.point.Point", "s2clientprotocol.sc2api_pb2.InterfaceOptions", "point.Point.assign_to", "point.Point.assign_to", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "len", "run_configs.get.start", "tqdm.tqdm", "s2clientprotocol.sc2api_pb2.SpatialCameraSetup", "set.add", "load_replay_info.check_info", "print", "run_configs.get.replay_data", "controller.replay_info", "s2clientprotocol.sc2api_pb2.RequestStartReplay", "print", "print", "print", "print", "controller.start_replay", "print", "pysc2.lib.features.features_from_game_info", "print", "print", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.array", "print", "print", "result.append", "controller.observe", "controller.step", "print", "print", "print", "controller.game_info", "range", "features.features_from_game_info.transform_obs", "type", "load_replay_info.store_info", "print", "features.features_from_game_info.reverse_action", "print", "print", "print", "print", "type"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.check_info", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.store_info"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "run_config", "=", "run_configs", ".", "get", "(", "version", "=", "\"3.16.1\"", ")", "\n", "print", "(", "'REPLAY_PATH:'", ",", "REPLAY_PATH", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "REPLAY_PATH", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "\n", "result", "=", "[", "]", "\n", "map_set", "=", "set", "(", ")", "\n", "\n", "screen_resolution", "=", "point", ".", "Point", "(", "32", ",", "32", ")", "\n", "minimap_resolution", "=", "point", ".", "Point", "(", "32", ",", "32", ")", "\n", "camera_width", "=", "24", "\n", "random_seed", "=", "42", "\n", "\n", "interface", "=", "sc_pb", ".", "InterfaceOptions", "(", "\n", "raw", "=", "True", ",", "score", "=", "True", ",", "\n", "feature_layer", "=", "sc_pb", ".", "SpatialCameraSetup", "(", "width", "=", "camera_width", ")", ")", "\n", "screen_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "resolution", ")", "\n", "minimap_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "minimap_resolution", ")", "\n", "\n", "with", "run_config", ".", "start", "(", "full_screen", "=", "False", ")", "as", "controller", ":", "\n", "        ", "for", "replay_file", "in", "tqdm", "(", "replay_files", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "replay_path", "=", "REPLAY_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "replay_data", "=", "run_config", ".", "replay_data", "(", "replay_path", ")", "\n", "replay_info", "=", "controller", ".", "replay_info", "(", "replay_data", ")", "\n", "\n", "start_replay", "=", "sc_pb", ".", "RequestStartReplay", "(", "\n", "replay_data", "=", "replay_data", ",", "\n", "options", "=", "interface", ",", "\n", "disable_fog", "=", "FLAGS", ".", "disable_fog", ",", "\n", "observed_player_id", "=", "FLAGS", ".", "observed_player", ")", "\n", "\n", "print", "(", "\" Replay info \"", ".", "center", "(", "60", ",", "\"-\"", ")", ")", "\n", "print", "(", "replay_info", ")", "\n", "print", "(", "\"-\"", "*", "60", ")", "\n", "\n", "print", "(", "\"------start_replay\"", ")", "\n", "controller", ".", "start_replay", "(", "start_replay", ")", "\n", "print", "(", "\"------feature_layer\"", ")", "\n", "#feature_layer = features.Features(controller.game_info())", "\n", "#", "\n", "feature_layer", "=", "features", ".", "features_from_game_info", "(", "game_info", "=", "controller", ".", "game_info", "(", ")", ")", "\n", "\n", "print", "(", "\"------end feature_layer\"", ")", "\n", "frame_num", "=", "replay_info", ".", "game_duration_loops", "\n", "print", "(", "\"frame_num:\"", ",", "frame_num", ")", "\n", "step_num", "=", "frame_num", "//", "FLAGS", ".", "step_mul", "\n", "print", "(", "\"step_num:\"", ",", "step_num", ")", "\n", "path", "=", "FLAGS", ".", "save_path", "\n", "\n", "# init data", "\n", "player_data", "=", "np", ".", "zeros", "(", "(", "step_num", ",", "1", "+", "11", ")", ")", "\n", "unit_data", "=", "np", ".", "zeros", "(", "(", "step_num", ",", "1", "+", "7", ")", ")", "\n", "score_data", "=", "np", ".", "zeros", "(", "(", "step_num", ",", "1", "+", "13", ")", ")", "\n", "\n", "frame_array", "=", "[", "(", "x", "+", "1", ")", "*", "FLAGS", ".", "step_mul", "for", "x", "in", "range", "(", "step_num", ")", "]", "\n", "player_data", "[", ":", ",", "0", "]", "=", "unit_data", "[", ":", ",", "0", "]", "=", "score_data", "[", ":", ",", "0", "]", "=", "frame_array", "\n", "\n", "order_data", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "print", "(", "\"------controller.observe()\"", ")", "\n", "while", "True", ":", "\n", "                    ", "o", "=", "controller", ".", "observe", "(", ")", "\n", "\n", "try", ":", "\n", "                        ", "obs", "=", "feature_layer", ".", "transform_obs", "(", "o", ")", "\n", "\n", "if", "o", ".", "player_result", ":", "# end of game", "\n", "                            ", "print", "(", "o", ".", "player_result", ")", "\n", "break", "\n", "\n", "", "if", "o", ".", "actions", ":", "\n", "# pass", "\n", "                            ", "func", "=", "feature_layer", ".", "reverse_action", "(", "o", ".", "actions", "[", "0", "]", ")", "\n", "print", "(", "'func:'", ",", "func", ")", "\n", "\n", "", "", "except", "Exception", "as", "inst", ":", "\n", "                        ", "print", "(", "type", "(", "inst", ")", ")", "\n", "print", "(", "inst", ".", "args", ")", "\n", "print", "(", "inst", ")", "\n", "\n", "", "controller", ".", "step", "(", ")", "\n", "\n", "# We only test the first one replay            ", "\n", "", "", "except", "Exception", "as", "inst", ":", "\n", "                ", "print", "(", "type", "(", "inst", ")", ")", "\n", "print", "(", "inst", ".", "args", ")", "\n", "print", "(", "inst", ")", "\n", "\n", "break", "\n", "\n", "continue", "\n", "\n", "", "break", "\n", "\n", "map_set", ".", "add", "(", "replay_info", ".", "map_name", ")", "\n", "\n", "if", "check_info", "(", "replay_info", ")", ":", "\n", "                ", "print", "(", "'check right!'", ",", "replay_file", ")", "\n", "result", ".", "append", "(", "[", "replay_file", "]", "+", "store_info", "(", "replay_info", ")", ")", "\n", "#shutil.copy(replay_path, COPY_PATH)", "\n", "\n", "", "", "", "df", "=", "pd", ".", "DataFrame", "(", "result", ",", "columns", "=", "[", "'Replay File'", ",", "'Map Name'", ",", "'Game Version'", ",", "'Game Result'", ",", "'Player1 Race'", ",", "'Player2 Race'", ",", "'Game Loops'", ",", "'Game Duration'", "]", ")", "\n", "df", ".", "to_csv", "(", "path_or_buf", "=", "SAVE_PATH", ")", "\n", "\n", "print", "(", "map_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.check_info": [[75, 85], ["print", "print", "print"], "function", ["None"], ["def", "check_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_actual", "\n", "player2_race", "=", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_actual", "\n", "\n", "print", "(", "'map_name:'", ",", "map_name", ")", "\n", "print", "(", "'player1_race:'", ",", "player1_race", ")", "\n", "print", "(", "'player2_race:'", ",", "player2_race", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.getFeatureAndLabel": [[87, 103], ["agent.state_by_obs", "alphastarmini.core.sl.feature.Feature.state2feature", "agent.func_call_to_action", "agent.func_call_to_action.toLogits", "alphastarmini.core.sl.label.Label.action2label", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.state_by_obs", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label"], ["", "def", "getFeatureAndLabel", "(", "obs", ",", "func_call", ",", "agent", ")", ":", "\n", "    ", "print", "(", "\"begin s:\"", ")", "if", "debug", "else", "None", "\n", "s", ",", "tag_list", "=", "agent", ".", "state_by_obs", "(", "obs", ",", "return_tag_list", "=", "True", ")", "\n", "feature", "=", "Feature", ".", "state2feature", "(", "s", ")", "\n", "print", "(", "\"feature:\"", ",", "feature", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature.shape:\"", ",", "feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"begin a:\"", ")", "if", "debug", "else", "None", "\n", "action", "=", "agent", ".", "func_call_to_action", "(", "func_call", ",", "obs", "=", "obs", ")", "\n", "# tag_list = agent.get_tag_list(obs)", "\n", "a", "=", "action", ".", "toLogits", "(", "tag_list", ")", "\n", "label", "=", "Label", ".", "action2label", "(", "a", ")", "\n", "print", "(", "\"label:\"", ",", "label", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"label.shape:\"", ",", "label", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "feature", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.getObsAndFunc": [[105, 142], ["None"], "function", ["None"], ["", "def", "getObsAndFunc", "(", "obs", ",", "func_call", ",", "agent", ")", ":", "\n", "    ", "last_actions", "=", "obs", "[", "\"last_actions\"", "]", "\n", "upgrades", "=", "obs", "[", "\"upgrades\"", "]", "\n", "unit_counts", "=", "obs", "[", "\"unit_counts\"", "]", "\n", "feature_effects", "=", "obs", "[", "\"feature_effects\"", "]", "\n", "raw_effects", "=", "obs", "[", "\"raw_effects\"", "]", "\n", "\n", "feature_minimap", "=", "obs", "[", "\"feature_minimap\"", "]", "\n", "\n", "height_map", "=", "feature_minimap", "[", "\"height_map\"", "]", "\n", "visibility_map", "=", "feature_minimap", "[", "\"visibility_map\"", "]", "\n", "creep", "=", "feature_minimap", "[", "\"creep\"", "]", "\n", "player_relative", "=", "feature_minimap", "[", "\"player_relative\"", "]", "\n", "alerts", "=", "feature_minimap", "[", "\"alerts\"", "]", "\n", "pathable", "=", "feature_minimap", "[", "\"pathable\"", "]", "\n", "buildable", "=", "feature_minimap", "[", "\"buildable\"", "]", "\n", "\n", "step_dict", "=", "{", "'raw_units'", ":", "obs", "[", "\"raw_units\"", "]", "[", ":", "AHP", ".", "max_entities", "]", ",", "\n", "'player'", ":", "obs", "[", "\"player\"", "]", ",", "\n", "\n", "'last_actions'", ":", "last_actions", ",", "\n", "'upgrades'", ":", "upgrades", ",", "\n", "'unit_counts'", ":", "unit_counts", ",", "\n", "'feature_effects'", ":", "feature_effects", ",", "\n", "'raw_effects'", ":", "raw_effects", ",", "\n", "\n", "'height_map'", ":", "height_map", ",", "\n", "'visibility_map'", ":", "visibility_map", ",", "\n", "'creep'", ":", "creep", ",", "\n", "'player_relative'", ":", "player_relative", ",", "\n", "'alerts'", ":", "alerts", ",", "\n", "'pathable'", ":", "pathable", ",", "\n", "'buildable'", ":", "buildable", ",", "\n", "\n", "'func_call'", ":", "func_call", "}", "\n", "\n", "return", "step_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.getFuncCall": [[144, 170], ["feat.reverse_raw_action", "ValueError"], "function", ["None"], ["", "def", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ",", "use_raw", "=", "True", ")", ":", "\n", "    ", "func_call", "=", "None", "\n", "\n", "if", "use_raw", ":", "\n", "        ", "if", "prev_obs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"use raw function call must input prev_obs\"", ")", "\n", "\n", "", "raw_func_call", "=", "feat", ".", "reverse_raw_action", "(", "o", ".", "actions", "[", "0", "]", ",", "prev_obs", ")", "\n", "\n", "if", "raw_func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "# no op", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "168", ":", "\n", "# camera move", "\n", "#print(\"find camera move!\")", "\n", "# print(raw_func_call)", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "1", ":", "\n", "# smart screen", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "func_call", "=", "raw_func_call", "\n", "\n", "", "return", "func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.run_alphastar_replay": [[172, 360], ["pysc2.run_configs.get", "os.listdir", "os.listdir.sort", "pysc2.lib.point.Point", "pysc2.lib.point.Point", "s2clientprotocol.sc2api_pb2.InterfaceOptions", "point.Point.assign_to", "point.Point.assign_to", "alphastarmini.core.arch.agent.Agent", "print", "run_configs.get.start", "s2clientprotocol.sc2api_pb2.SpatialCameraSetup", "print", "run_configs.get.replay_data", "controller.replay_info", "s2clientprotocol.sc2api_pb2.RequestStartReplay", "controller.start_replay", "pysc2.lib.features.features_from_game_info", "F.features_from_game_info.observation_spec", "F.features_from_game_info.action_spec", "print", "replay_length_list.append", "noop_length_list.append", "print", "print", "controller.observe", "controller.step", "traceback.print_exc", "controller.game_info", "F.features_from_game_info.transform_obs", "print", "print", "traceback.print_exc", "test_alphastar_replay.getFuncCall", "traceback.print_exc"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFuncCall"], ["", "def", "run_alphastar_replay", "(", "player_id", "=", "1", ",", "on_server", "=", "False", ")", ":", "\n", "    ", "if", "on_server", ":", "\n", "        ", "REPLAY_PATH", "=", "\"/home/liuruoze/mini-AlphaStar/data/filtered_replays_1/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "FLAGS", ".", "max_steps_of_replay", "\n", "max_replays", "=", "FLAGS", ".", "max_replays", "\n", "", "else", ":", "\n", "        ", "REPLAY_PATH", "=", "\"data/Replays/replays_paper_ready/Final/Protoss/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "FLAGS", ".", "max_steps_of_replay", "\n", "max_replays", "=", "1", "\n", "\n", "", "run_config", "=", "run_configs", ".", "get", "(", "version", "=", "FLAGS", ".", "replay_version", ")", "\n", "#print('REPLAY_PATH:', REPLAY_PATH)", "\n", "replay_files", "=", "os", ".", "listdir", "(", "REPLAY_PATH", ")", "\n", "replay_files", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "\n", "screen_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "screen_resolution", ",", "FLAGS", ".", "screen_resolution", ")", "\n", "minimap_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "minimap_resolution", ",", "FLAGS", ".", "minimap_resolution", ")", "\n", "camera_width", "=", "24", "\n", "\n", "# By default raw actions select, act and revert the selection. This is useful", "\n", "# if you're playing simultaneously with the agent so it doesn't steal your", "\n", "# selection. This inflates APM (due to deselect) and makes the actions hard", "\n", "# to follow in a replay. Setting this to true will cause raw actions to do", "\n", "# select, act, but not revert the selection.", "\n", "raw_affects_selection", "=", "False", "\n", "\n", "# Changes the coordinates in raw.proto to be relative to the playable area.", "\n", "# The map_size and playable_area will be the diagonal of the real playable area.", "\n", "raw_crop_to_playable_area", "=", "False", "\n", "\n", "interface", "=", "sc_pb", ".", "InterfaceOptions", "(", "\n", "raw", "=", "True", ",", "\n", "score", "=", "True", ",", "\n", "# Omit to disable.", "\n", "feature_layer", "=", "sc_pb", ".", "SpatialCameraSetup", "(", "width", "=", "camera_width", ")", ",", "\n", "# Omit to disable.", "\n", "render", "=", "None", ",", "\n", "# By default cloaked units are completely hidden. This shows some details.", "\n", "show_cloaked", "=", "False", ",", "\n", "# By default burrowed units are completely hidden. This shows some details for those that produce a shadow.", "\n", "show_burrowed_shadows", "=", "False", ",", "\n", "# Return placeholder units (buildings to be constructed), both for raw and feature layers.", "\n", "show_placeholders", "=", "False", ",", "\n", "# see below", "\n", "raw_affects_selection", "=", "raw_affects_selection", ",", "\n", "# see below", "\n", "raw_crop_to_playable_area", "=", "raw_crop_to_playable_area", "\n", ")", "\n", "\n", "screen_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "resolution", ")", "\n", "minimap_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "minimap_resolution", ")", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "j", "=", "0", "\n", "replay_length_list", "=", "[", "]", "\n", "noop_length_list", "=", "[", "]", "\n", "\n", "with", "run_config", ".", "start", "(", "full_screen", "=", "False", ")", "as", "controller", ":", "\n", "\n", "        ", "for", "replay_file", "in", "replay_files", ":", "\n", "            ", "try", ":", "\n", "                ", "replay_path", "=", "REPLAY_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "replay_data", "=", "run_config", ".", "replay_data", "(", "replay_path", ")", "\n", "replay_info", "=", "controller", ".", "replay_info", "(", "replay_data", ")", "\n", "\n", "start_replay", "=", "sc_pb", ".", "RequestStartReplay", "(", "\n", "replay_data", "=", "replay_data", ",", "\n", "options", "=", "interface", ",", "\n", "disable_fog", "=", "False", ",", "# FLAGS.disable_fog", "\n", "observed_player_id", "=", "player_id", ",", "\n", "map_data", "=", "None", ",", "\n", "realtime", "=", "False", "\n", ")", "\n", "\n", "#print(\" Replay info \".center(60, \"-\")) if debug else None", "\n", "print", "(", "replay_info", ".", "player_info", ")", "if", "debug", "else", "None", "\n", "#print(\"-\" * 60) if debug else None", "\n", "controller", ".", "start_replay", "(", "start_replay", ")", "\n", "# The below several arguments are default set to False, so we shall enable them.", "\n", "\n", "# use_feature_units: Whether to include feature_unit observations.", "\n", "\n", "# use_raw_units: Whether to include raw unit data in observations. This", "\n", "# differs from feature_units because it includes units outside the", "\n", "# screen and hidden units, and because unit positions are given in", "\n", "# terms of world units instead of screen units.", "\n", "\n", "# use_raw_actions: [bool] Whether to use raw actions as the interface.", "\n", "# Same as specifying action_space=ActionSpace.RAW.", "\n", "\n", "# use_unit_counts: Whether to include unit_counts observation. Disabled by", "\n", "# default since it gives information outside the visible area. ", "\n", "\n", "'''\n                show_cloaked: Whether to show limited information for cloaked units.\n                show_burrowed_shadows: Whether to show limited information for burrowed\n                      units that leave a shadow on the ground (ie widow mines and moving\n                      roaches and infestors).\n                show_placeholders: Whether to show buildings that are queued for\n                      construction.\n                '''", "\n", "\n", "feat", "=", "F", ".", "features_from_game_info", "(", "game_info", "=", "controller", ".", "game_info", "(", ")", ",", "\n", "use_feature_units", "=", "True", ",", "use_raw_units", "=", "True", ",", "\n", "use_unit_counts", "=", "True", ",", "use_raw_actions", "=", "True", ",", "\n", "show_cloaked", "=", "True", ",", "show_burrowed_shadows", "=", "True", ",", "\n", "show_placeholders", "=", "True", ")", "\n", "#print(\"feat obs spec:\", feat.observation_spec()) if debug else None", "\n", "#print(\"feat action spec:\", feat.action_spec()) if debug else None", "\n", "prev_obs", "=", "None", "\n", "i", "=", "0", "\n", "save_steps", "=", "0", "\n", "noop_count", "=", "0", "\n", "camera_count", "=", "0", "\n", "all_op_count", "=", "0", "\n", "\n", "feature_list", ",", "label_list", "=", "[", "]", ",", "[", "]", "\n", "step_dict", "=", "{", "}", "\n", "\n", "# set the obs and action spec", "\n", "obs_spec", "=", "feat", ".", "observation_spec", "(", ")", "\n", "act_spec", "=", "feat", ".", "action_spec", "(", ")", "\n", "\n", "while", "True", ":", "\n", "                    ", "o", "=", "controller", ".", "observe", "(", ")", "\n", "try", ":", "\n", "                        ", "obs", "=", "feat", ".", "transform_obs", "(", "o", ")", "\n", "\n", "try", ":", "\n", "                            ", "func_call", "=", "None", "\n", "no_op", "=", "False", "\n", "\n", "if", "o", ".", "actions", "and", "prev_obs", ":", "\n", "                                ", "func_call", "=", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ")", "\n", "\n", "if", "func_call", ".", "function", ".", "value", "==", "168", ":", "\n", "                                    ", "camera_count", "+=", "1", "\n", "\n", "", "if", "func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "                                    ", "no_op", "=", "True", "\n", "func_call", "=", "None", "\n", "", "", "else", ":", "\n", "                                ", "no_op", "=", "True", "\n", "\n", "", "if", "no_op", ":", "\n", "                                ", "pass", "\n", "", "else", ":", "\n", "                                ", "all_op_count", "+=", "1", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "i", ">=", "max_steps_of_replay", ":", "# test the first n frames", "\n", "                            ", "print", "(", "\"max frames test, break out!\"", ")", "\n", "break", "\n", "\n", "", "if", "o", ".", "player_result", ":", "# end of game", "\n", "                            ", "print", "(", "o", ".", "player_result", ")", "\n", "break", "\n", "\n", "", "", "except", "Exception", "as", "inst", ":", "\n", "                        ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "controller", ".", "step", "(", ")", "\n", "prev_obs", "=", "obs", "\n", "i", "+=", "1", "\n", "\n", "", "print", "(", "\"player_id\"", ",", "player_id", ",", "\"camera_count\"", ",", "camera_count", ",", "\"all_op_count\"", ",", "all_op_count", ",", "\n", "\"no_camera_op_rate\"", ",", "1.0", "-", "camera_count", "/", "(", "all_op_count", "+", "1e-9", ")", ")", "\n", "\n", "j", "+=", "1", "\n", "replay_length_list", ".", "append", "(", "save_steps", ")", "\n", "noop_length_list", ".", "append", "(", "noop_count", ")", "\n", "# We only test the first one replay   ", "\n", "\n", "", "except", "Exception", "as", "inst", ":", "\n", "                ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "j", ">=", "max_replays", ":", "# test the first n frames", "\n", "                ", "print", "(", "\"max replays test, break out!\"", ")", "\n", "break", "\n", "\n", "", "", "", "print", "(", "\"end\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.test": [[362, 365], ["test_alphastar_replay.run_alphastar_replay"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.test_alphastar_replay.run_alphastar_replay"], ["", "def", "test", "(", "on_server", "=", "False", ")", ":", "\n", "#run_alphastar_replay(player_id=1, on_server=on_server)", "\n", "    ", "run_alphastar_replay", "(", "player_id", "=", "2", ",", "on_server", "=", "on_server", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.__init__": [[27, 30], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Feature", ",", "self", ")", ".", "__init__", "(", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature": [[31, 65], ["scalar_list[].reshape", "torch.cat", "batch_entities_tensor.reshape", "map_data.reshape", "torch.cat", "print", "print", "print", "print"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "state2feature", "(", "state", ")", ":", "\n", "        ", "''' \n        input: MsState \n        outoput: [batch_size x feature_embedding_size]\n        '''", "\n", "\n", "'''not used:\n        map_data = state[2]\n        batch_entities_tensor = state[1]\n        scalar_list = state[0]\n        '''", "\n", "\n", "map_data", "=", "state", ".", "map_state", "\n", "batch_entities_tensor", "=", "state", ".", "entity_state", "\n", "scalar_list", "=", "state", ".", "statistical_state", "\n", "\n", "batch_size", "=", "map_data", ".", "shape", "[", "0", "]", "\n", "bbo_index", "=", "ScalarFeature", ".", "beginning_build_order", "\n", "scalar_list", "[", "bbo_index", "]", "=", "scalar_list", "[", "bbo_index", "]", ".", "reshape", "(", "batch_size", ",", "SFS", "[", "bbo_index", "]", ")", "\n", "for", "z", "in", "scalar_list", ":", "\n", "            ", "print", "(", "\"z.shape:\"", ",", "z", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "", "feature_1", "=", "torch", ".", "cat", "(", "scalar_list", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"feature_1.shape:\"", ",", "feature_1", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "feature_2", "=", "batch_entities_tensor", ".", "reshape", "(", "batch_size", ",", "AHP", ".", "max_entities", "*", "AHP", ".", "embedding_size", ")", "\n", "print", "(", "\"feature_2.shape:\"", ",", "feature_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "feature_3", "=", "map_data", ".", "reshape", "(", "batch_size", ",", "AHP", ".", "map_channels", "*", "AHP", ".", "minimap_size", "*", "AHP", ".", "minimap_size", ")", "\n", "print", "(", "\"feature_3.shape:\"", ",", "feature_3", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "feature", "=", "torch", ".", "cat", "(", "[", "feature_1", ",", "feature_2", ",", "feature_3", "]", ",", "dim", "=", "1", ")", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.getSize": [[66, 79], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "getSize", "(", ")", ":", "\n", "\n", "# note: do not use AHP.scalar_feature_size", "\n", "#feature_1_size = AHP.scalar_feature_size", "\n", "        ", "size_all", "=", "0", "\n", "for", "i", "in", "ScalarFeature", ":", "\n", "            ", "size_all", "+=", "SFS", "[", "i", "]", "\n", "", "feature_1_size", "=", "size_all", "\n", "\n", "feature_2_size", "=", "AHP", ".", "max_entities", "*", "AHP", ".", "embedding_size", "\n", "feature_3_size", "=", "AHP", ".", "map_channels", "*", "AHP", ".", "minimap_size", "*", "AHP", ".", "minimap_size", "\n", "return", "feature_1_size", "+", "feature_2_size", "+", "feature_3_size", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.feature2state": [[80, 139], ["scalar_list[].reshape", "feature_2.reshape", "feature_3.reshape", "alphastarmini.core.rl.state.MsState", "print", "print", "scalar_list.append", "print", "print", "int", "print", "print", "print"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "feature2state", "(", "feature", ")", ":", "\n", "        ", "''' \n        input: [batch_size x feature_embedding_size]\n        outoput: MsState\n        '''", "\n", "batch_size", "=", "feature", ".", "shape", "[", "0", "]", "\n", "\n", "# note: do not use AHP.scalar_feature_size", "\n", "#feature_1_size = AHP.scalar_feature_size", "\n", "\n", "size_all", "=", "0", "\n", "for", "i", "in", "ScalarFeature", ":", "\n", "            ", "size_all", "+=", "SFS", "[", "i", "]", "\n", "", "feature_1_size", "=", "size_all", "\n", "\n", "feature_2_size", "=", "AHP", ".", "max_entities", "*", "AHP", ".", "embedding_size", "\n", "feature_3_size", "=", "AHP", ".", "map_channels", "*", "AHP", ".", "minimap_size", "*", "AHP", ".", "minimap_size", "\n", "\n", "print", "(", "\"feature_1_size + feature_2_size + feature_3_size:\"", ",", "\n", "feature_1_size", "+", "feature_2_size", "+", "feature_3_size", ")", "if", "debug", "else", "None", "\n", "print", "(", "'feature.shape[1]:'", ",", "feature", ".", "shape", "[", "1", "]", ")", "if", "debug", "else", "None", "\n", "assert", "feature_1_size", "+", "feature_2_size", "+", "feature_3_size", "==", "feature", ".", "shape", "[", "1", "]", "\n", "\n", "feature_1", "=", "feature", "[", ":", ",", ":", "feature_1_size", "]", "\n", "scalar_list", "=", "[", "]", "\n", "last_index", "=", "0", "\n", "\n", "for", "i", "in", "ScalarFeature", ":", "\n", "            ", "scalar_feature", "=", "feature_1", "[", ":", ",", "last_index", ":", "last_index", "+", "SFS", "[", "i", "]", "]", "\n", "print", "(", "'added scalar_feature.shape:'", ",", "scalar_feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "scalar_list", ".", "append", "(", "scalar_feature", ")", "\n", "last_index", "+=", "SFS", "[", "i", "]", "\n", "\n", "", "bbo_index", "=", "ScalarFeature", ".", "beginning_build_order", "\n", "\n", "print", "(", "'batch_size:'", ",", "batch_size", ")", "if", "debug", "else", "None", "\n", "print", "(", "'scalar_list[bbo_index].shape:'", ",", "scalar_list", "[", "bbo_index", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "scalar_list", "[", "bbo_index", "]", "=", "scalar_list", "[", "bbo_index", "]", ".", "reshape", "(", "batch_size", ",", "\n", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", "[", "bbo_index", "]", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "\n", "feature_2", "=", "feature", "[", ":", ",", "feature_1_size", ":", "feature_1_size", "+", "feature_2_size", "]", "\n", "batch_entities_tensor", "=", "feature_2", ".", "reshape", "(", "batch_size", ",", "AHP", ".", "max_entities", ",", "AHP", ".", "embedding_size", ")", "\n", "\n", "print", "(", "\"feature[:, -feature_3_size:].shape:\"", ",", "feature", "[", ":", ",", "-", "feature_3_size", ":", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature[:, feature_1_size + feature_2_size:].shape:\"", ",", "\n", "feature", "[", ":", ",", "feature_1_size", "+", "feature_2_size", ":", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# assert feature[:, -feature_3_size:] == feature[:, feature_1_size + feature_2_size:]", "\n", "#", "\n", "feature_3", "=", "feature", "[", ":", ",", "-", "feature_3_size", ":", "]", "\n", "map_data", "=", "feature_3", ".", "reshape", "(", "batch_size", ",", "AHP", ".", "map_channels", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "\n", "state", "=", "MsState", "(", "entity_state", "=", "batch_entities_tensor", ",", "\n", "statistical_state", "=", "scalar_list", ",", "map_state", "=", "map_data", ")", "\n", "\n", "# not used:", "\n", "# return [scalar_list, batch_entities_tensor, map_data]", "\n", "return", "state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.__init__": [[55, 58], ["torch.nn.parallel.DataParallel.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gpu0_bsz", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "gpu0_bsz", "=", "gpu0_bsz", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.forward": [[59, 86], ["balanced_data_parallel.BalancedDataParallel.scatter", "print", "print", "print", "balanced_data_parallel.BalancedDataParallel.parallel_apply", "balanced_data_parallel.BalancedDataParallel.gather", "balanced_data_parallel.BalancedDataParallel.module", "str", "str", "len", "balanced_data_parallel.BalancedDataParallel.module", "balanced_data_parallel.BalancedDataParallel.replicate", "balanced_data_parallel.BalancedDataParallel.replicate", "str", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.scatter", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.parallel_apply"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "device_ids", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "if", "self", ".", "gpu0_bsz", "==", "0", ":", "\n", "            ", "device_ids", "=", "self", ".", "device_ids", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "device_ids", "=", "self", ".", "device_ids", "\n", "", "inputs", ",", "kwargs", "=", "self", ".", "scatter", "(", "inputs", ",", "kwargs", ",", "device_ids", ")", "\n", "\n", "print", "(", "'len(inputs): '", ",", "str", "(", "len", "(", "inputs", ")", ")", ")", "\n", "print", "(", "'self.device_ids[:len(inputs)]'", ",", "str", "(", "self", ".", "device_ids", "[", ":", "len", "(", "inputs", ")", "]", ")", ")", "\n", "\n", "if", "len", "(", "self", ".", "device_ids", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", "[", "0", "]", ",", "**", "kwargs", "[", "0", "]", ")", "\n", "", "if", "self", ".", "gpu0_bsz", "==", "0", ":", "\n", "            ", "replicas", "=", "self", ".", "replicate", "(", "self", ".", "module", ",", "self", ".", "device_ids", ")", "\n", "", "else", ":", "\n", "            ", "replicas", "=", "self", ".", "replicate", "(", "self", ".", "module", ",", "self", ".", "device_ids", "[", ":", "len", "(", "inputs", ")", "]", ")", "\n", "\n", "# replicas = self.replicate(self.module, device_ids[:len(inputs)])", "\n", "", "if", "self", ".", "gpu0_bsz", "==", "0", ":", "\n", "            ", "replicas", "=", "replicas", "[", "1", ":", "]", "\n", "\n", "", "print", "(", "'replicas:'", ",", "str", "(", "len", "(", "replicas", ")", ")", ")", "\n", "\n", "outputs", "=", "self", ".", "parallel_apply", "(", "replicas", ",", "device_ids", ",", "inputs", ",", "kwargs", ")", "\n", "return", "self", ".", "gather", "(", "outputs", ",", "self", ".", "output_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.parallel_apply": [[87, 89], ["torch.nn.parallel.parallel_apply.parallel_apply", "len"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.parallel_apply"], ["", "def", "parallel_apply", "(", "self", ",", "replicas", ",", "device_ids", ",", "inputs", ",", "kwargs", ")", ":", "\n", "        ", "return", "parallel_apply", "(", "replicas", ",", "inputs", ",", "kwargs", ",", "device_ids", "[", ":", "len", "(", "inputs", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.BalancedDataParallel.scatter": [[90, 111], ["inputs[].size", "len", "print", "print", "print", "print", "print", "balanced_data_parallel.scatter_kwargs", "range", "super().scatter", "sum"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.scatter_kwargs", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.scatter"], ["", "def", "scatter", "(", "self", ",", "inputs", ",", "kwargs", ",", "device_ids", ")", ":", "\n", "        ", "bsz", "=", "inputs", "[", "0", "]", ".", "size", "(", "self", ".", "dim", ")", "\n", "num_dev", "=", "len", "(", "self", ".", "device_ids", ")", "\n", "gpu0_bsz", "=", "self", ".", "gpu0_bsz", "\n", "bsz_unit", "=", "(", "bsz", "-", "gpu0_bsz", ")", "//", "(", "num_dev", "-", "1", ")", "\n", "if", "gpu0_bsz", "<", "bsz_unit", ":", "\n", "            ", "chunk_sizes", "=", "[", "gpu0_bsz", "]", "+", "[", "bsz_unit", "]", "*", "(", "num_dev", "-", "1", ")", "\n", "delta", "=", "bsz", "-", "sum", "(", "chunk_sizes", ")", "\n", "for", "i", "in", "range", "(", "delta", ")", ":", "\n", "                ", "chunk_sizes", "[", "i", "+", "1", "]", "+=", "1", "\n", "", "if", "gpu0_bsz", "==", "0", ":", "\n", "                ", "chunk_sizes", "=", "chunk_sizes", "[", "1", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "scatter", "(", "inputs", ",", "kwargs", ",", "device_ids", ")", "\n", "\n", "", "print", "(", "'bsz: '", ",", "bsz", ")", "\n", "print", "(", "'num_dev: '", ",", "num_dev", ")", "\n", "print", "(", "'gpu0_bsz: '", ",", "gpu0_bsz", ")", "\n", "print", "(", "'bsz_unit: '", ",", "bsz_unit", ")", "\n", "print", "(", "'chunk_sizes: '", ",", "chunk_sizes", ")", "\n", "return", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "device_ids", ",", "chunk_sizes", ",", "dim", "=", "self", ".", "dim", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.scatter": [[7, 39], ["isinstance", "balanced_data_parallel.scatter.scatter_map"], "function", ["None"], ["def", "scatter", "(", "inputs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", "=", "0", ")", ":", "\n", "    ", "r\"\"\"\n    Slices tensors into approximately equal chunks and\n    distributes them across given GPUs. Duplicates\n    references to objects that are not tensors.\n    \"\"\"", "\n", "def", "scatter_map", "(", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "Scatter", ".", "apply", "(", "target_gpus", ",", "chunk_sizes", ",", "dim", ",", "obj", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "'obj'", ",", "obj", ".", "size", "(", ")", ")", "\n", "print", "(", "'dim'", ",", "dim", ")", "\n", "print", "(", "'chunk_sizes'", ",", "chunk_sizes", ")", "\n", "quit", "(", ")", "\n", "", "", "if", "isinstance", "(", "obj", ",", "tuple", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "list", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "dict", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "type", "(", "obj", ")", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ".", "items", "(", ")", ")", ")", ")", ")", "\n", "", "return", "[", "obj", "for", "targets", "in", "target_gpus", "]", "\n", "\n", "# After scatter_map is called, a scatter_map cell will exist. This cell", "\n", "# has a reference to the actual function scatter_map, which has references", "\n", "# to a closure that has a reference to the scatter_map cell (because the", "\n", "# fn is recursive). To avoid this reference cycle, we set the function to", "\n", "# None, clearing the cell", "\n", "", "try", ":", "\n", "        ", "return", "scatter_map", "(", "inputs", ")", "\n", "", "finally", ":", "\n", "        ", "scatter_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.balanced_data_parallel.scatter_kwargs": [[41, 52], ["tuple", "tuple", "balanced_data_parallel.scatter", "balanced_data_parallel.scatter", "len", "len", "tuple.extend", "len", "len", "tuple.extend", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.scatter", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.scatter"], ["", "", "def", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", "=", "0", ")", ":", "\n", "    ", "r\"\"\"Scatter with support for kwargs dictionary\"\"\"", "\n", "inputs", "=", "scatter", "(", "inputs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", ")", "if", "inputs", "else", "[", "]", "\n", "kwargs", "=", "scatter", "(", "kwargs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", ")", "if", "kwargs", "else", "[", "]", "\n", "if", "len", "(", "inputs", ")", "<", "len", "(", "kwargs", ")", ":", "\n", "        ", "inputs", ".", "extend", "(", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "kwargs", ")", "-", "len", "(", "inputs", ")", ")", "]", ")", "\n", "", "elif", "len", "(", "kwargs", ")", "<", "len", "(", "inputs", ")", ":", "\n", "        ", "kwargs", ".", "extend", "(", "[", "{", "}", "for", "_", "in", "range", "(", "len", "(", "inputs", ")", "-", "len", "(", "kwargs", ")", ")", "]", ")", "\n", "", "inputs", "=", "tuple", "(", "inputs", ")", "\n", "kwargs", "=", "tuple", "(", "kwargs", ")", "\n", "return", "inputs", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.analyze_replay_statistic.check_info": [[75, 85], ["print", "print", "print"], "function", ["None"], ["def", "check_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_actual", "\n", "player2_race", "=", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_actual", "\n", "\n", "print", "(", "'map_name:'", ",", "map_name", ")", "\n", "print", "(", "'player1_race:'", ",", "player1_race", ")", "\n", "print", "(", "'player2_race:'", ",", "player2_race", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.analyze_replay_statistic.getFeatureAndLabel": [[87, 103], ["agent.state_by_obs", "alphastarmini.core.sl.feature.Feature.state2feature", "agent.func_call_to_action", "agent.func_call_to_action.toLogits", "alphastarmini.core.sl.label.Label.action2label", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.state_by_obs", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label"], ["", "def", "getFeatureAndLabel", "(", "obs", ",", "func_call", ",", "agent", ")", ":", "\n", "    ", "print", "(", "\"begin s:\"", ")", "if", "debug", "else", "None", "\n", "s", ",", "tag_list", "=", "agent", ".", "state_by_obs", "(", "obs", ",", "return_tag_list", "=", "True", ")", "\n", "feature", "=", "Feature", ".", "state2feature", "(", "s", ")", "\n", "print", "(", "\"feature:\"", ",", "feature", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature.shape:\"", ",", "feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"begin a:\"", ")", "if", "debug", "else", "None", "\n", "action", "=", "agent", ".", "func_call_to_action", "(", "func_call", ",", "obs", "=", "obs", ")", "\n", "# tag_list = agent.get_tag_list(obs)", "\n", "a", "=", "action", ".", "toLogits", "(", "tag_list", ")", "\n", "label", "=", "Label", ".", "action2label", "(", "a", ")", "\n", "print", "(", "\"label:\"", ",", "label", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"label.shape:\"", ",", "label", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "feature", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.analyze_replay_statistic.getObsAndFunc": [[105, 142], ["None"], "function", ["None"], ["", "def", "getObsAndFunc", "(", "obs", ",", "func_call", ",", "agent", ")", ":", "\n", "    ", "last_actions", "=", "obs", "[", "\"last_actions\"", "]", "\n", "upgrades", "=", "obs", "[", "\"upgrades\"", "]", "\n", "unit_counts", "=", "obs", "[", "\"unit_counts\"", "]", "\n", "feature_effects", "=", "obs", "[", "\"feature_effects\"", "]", "\n", "raw_effects", "=", "obs", "[", "\"raw_effects\"", "]", "\n", "\n", "feature_minimap", "=", "obs", "[", "\"feature_minimap\"", "]", "\n", "\n", "height_map", "=", "feature_minimap", "[", "\"height_map\"", "]", "\n", "visibility_map", "=", "feature_minimap", "[", "\"visibility_map\"", "]", "\n", "creep", "=", "feature_minimap", "[", "\"creep\"", "]", "\n", "player_relative", "=", "feature_minimap", "[", "\"player_relative\"", "]", "\n", "alerts", "=", "feature_minimap", "[", "\"alerts\"", "]", "\n", "pathable", "=", "feature_minimap", "[", "\"pathable\"", "]", "\n", "buildable", "=", "feature_minimap", "[", "\"buildable\"", "]", "\n", "\n", "step_dict", "=", "{", "'raw_units'", ":", "obs", "[", "\"raw_units\"", "]", "[", ":", "AHP", ".", "max_entities", "]", ",", "\n", "'player'", ":", "obs", "[", "\"player\"", "]", ",", "\n", "\n", "'last_actions'", ":", "last_actions", ",", "\n", "'upgrades'", ":", "upgrades", ",", "\n", "'unit_counts'", ":", "unit_counts", ",", "\n", "'feature_effects'", ":", "feature_effects", ",", "\n", "'raw_effects'", ":", "raw_effects", ",", "\n", "\n", "'height_map'", ":", "height_map", ",", "\n", "'visibility_map'", ":", "visibility_map", ",", "\n", "'creep'", ":", "creep", ",", "\n", "'player_relative'", ":", "player_relative", ",", "\n", "'alerts'", ":", "alerts", ",", "\n", "'pathable'", ":", "pathable", ",", "\n", "'buildable'", ":", "buildable", ",", "\n", "\n", "'func_call'", ":", "func_call", "}", "\n", "\n", "return", "step_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.analyze_replay_statistic.getFuncCall": [[144, 203], ["feat.reverse_raw_action", "feat.reverse_action", "ValueError", "print", "action.HasField", "print", "enumerate", "raw_act.HasField", "pysc2.lib.units.Protoss", "analyze_replay_statistic.getFuncCall.find_tag_position"], "function", ["None"], ["", "def", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ",", "use_raw", "=", "True", ")", ":", "\n", "    ", "func_call", "=", "None", "\n", "\n", "if", "use_raw", ":", "\n", "        ", "if", "prev_obs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"use raw function call must input prev_obs\"", ")", "\n", "\n", "", "raw_func_call", "=", "feat", ".", "reverse_raw_action", "(", "o", ".", "actions", "[", "0", "]", ",", "prev_obs", ")", "\n", "\n", "if", "raw_func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "# no op", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "168", ":", "\n", "# camera move", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "1", ":", "\n", "# smart screen", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "print", "(", "'expert raw func_call: '", ",", "raw_func_call", ")", "if", "debug", "else", "None", "\n", "action", "=", "o", ".", "actions", "[", "0", "]", "\n", "\n", "raw_tags", "=", "prev_obs", "[", "\"raw_units\"", "]", "[", ":", ",", "29", "]", "# 29 is FeatureUnit.tag", "\n", "raw_unit_type", "=", "prev_obs", "[", "\"raw_units\"", "]", "[", ":", ",", "0", "]", "# 0 is FeatureUnit.unit_type", "\n", "\n", "#print('raw_tags:', raw_tags)", "\n", "#print('len(raw_tags):', len(raw_tags))", "\n", "\n", "def", "find_tag_position", "(", "original_tag", ")", ":", "\n", "                ", "for", "i", ",", "tag", "in", "enumerate", "(", "raw_tags", ")", ":", "\n", "                    ", "if", "tag", "==", "original_tag", ":", "\n", "                        ", "return", "i", "\n", "#logging.warning(\"Not found tag! %s\", original_tag)", "\n", "", "", "return", "-", "1", "\n", "\n", "", "if", "action", ".", "HasField", "(", "\"action_raw\"", ")", ":", "\n", "                ", "raw_act", "=", "action", ".", "action_raw", "\n", "if", "raw_act", ".", "HasField", "(", "\"unit_command\"", ")", ":", "\n", "                    ", "uc", "=", "raw_act", ".", "unit_command", "\n", "ability_id", "=", "uc", ".", "ability_id", "\n", "queue_command", "=", "uc", ".", "queue_command", "\n", "unit_tags", "=", "(", "find_tag_position", "(", "t", ")", "for", "t", "in", "uc", ".", "unit_tags", ")", "\n", "unit_tags", "=", "[", "t", "for", "t", "in", "unit_tags", "if", "t", "!=", "-", "1", "]", "\n", "unit_index", "=", "unit_tags", "[", "0", "]", "\n", "print", "(", "'unit_index:'", ",", "unit_index", ")", "if", "debug", "else", "None", "\n", "print", "(", "'unit_tag:'", ",", "raw_tags", "[", "unit_index", "]", ")", "if", "debug", "else", "None", "\n", "unit_type_id", "=", "raw_unit_type", "[", "unit_index", "]", "\n", "unit_type_name", "=", "Unit", ".", "Protoss", "(", "unit_type_id", ")", "\n", "print", "(", "'Protoss unit_type:'", ",", "unit_type_name", ")", "if", "debug", "else", "None", "\n", "\n", "", "", "", "func_call", "=", "raw_func_call", "\n", "", "else", ":", "\n", "\n", "        ", "feat_func_call", "=", "feat", ".", "reverse_action", "(", "o", ".", "actions", "[", "0", "]", ")", "\n", "print", "(", "'expert feature func_call: '", ",", "feat_func_call", ")", "if", "debug", "else", "None", "\n", "\n", "func_call", "=", "feat_func_call", "\n", "\n", "", "return", "func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.analyze_replay_statistic.test": [[205, 411], ["pysc2.run_configs.get", "print", "os.listdir", "print", "os.listdir.sort", "pysc2.lib.point.Point", "pysc2.lib.point.Point", "s2clientprotocol.sc2api_pb2.InterfaceOptions", "point.Point.assign_to", "point.Point.assign_to", "alphastarmini.core.arch.agent.Agent", "alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "print", "print", "print", "len", "run_configs.get.start", "tqdm.tqdm", "s2clientprotocol.sc2api_pb2.SpatialCameraSetup", "print", "run_configs.get.replay_data", "controller.replay_info", "s2clientprotocol.sc2api_pb2.RequestStartReplay", "controller.start_replay", "pysc2.lib.features.features_from_game_info", "F.features_from_game_info.observation_spec", "F.features_from_game_info.action_spec", "alphastarmini.core.rl.alphastar_agent.AlphaStarAgent.setup", "alphastarmini.core.rl.alphastar_agent.AlphaStarAgent.initial_state", "replay_length_list.append", "noop_length_list.append", "print", "print", "print", "print", "print", "print", "controller.observe", "controller.step", "traceback.print_exc", "controller.game_info", "F.features_from_game_info.observation_spec", "F.features_from_game_info.action_spec", "F.features_from_game_info.transform_obs", "alphastarmini.lib.utils.calculate_build_order", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape().numpy().tolist", "print", "print", "traceback.print_exc", "print", "print", "analyze_replay_statistic.getFuncCall", "alphastarmini.core.rl.alphastar_agent.AlphaStarAgent.step_logits", "traceback.print_exc", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape().numpy", "sum", "print", "random.uniform", "pysc2.lib.actions.FunctionCall.init_with_validation", "print", "print", "print", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape", "alphastarmini.lib.utils.calculate_unit_counts_bow"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_build_order", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFuncCall", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow"], ["", "def", "test", "(", "on_server", "=", "False", ")", ":", "\n", "\n", "    ", "if", "on_server", ":", "\n", "        ", "REPLAY_PATH", "=", "\"/home/liuruoze/mini-AlphaStar/data/filtered_replays_1/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "FLAGS", ".", "max_steps_of_replay", "\n", "max_replays", "=", "FLAGS", ".", "max_replays", "\n", "", "else", ":", "\n", "        ", "REPLAY_PATH", "=", "\"data/Replays/filtered_replays_1/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "60", "*", "60", "*", "22.4", "\n", "max_replays", "=", "1", "\n", "\n", "", "run_config", "=", "run_configs", ".", "get", "(", "version", "=", "FLAGS", ".", "replay_version", ")", "\n", "print", "(", "'REPLAY_PATH:'", ",", "REPLAY_PATH", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "REPLAY_PATH", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "replay_files", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "\n", "screen_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "screen_resolution", ",", "FLAGS", ".", "screen_resolution", ")", "\n", "minimap_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "minimap_resolution", ",", "FLAGS", ".", "minimap_resolution", ")", "\n", "camera_width", "=", "24", "\n", "\n", "# By default raw actions select, act and revert the selection. This is useful", "\n", "# if you're playing simultaneously with the agent so it doesn't steal your", "\n", "# selection. This inflates APM (due to deselect) and makes the actions hard", "\n", "# to follow in a replay. Setting this to true will cause raw actions to do", "\n", "# select, act, but not revert the selection.", "\n", "raw_affects_selection", "=", "False", "\n", "\n", "# Changes the coordinates in raw.proto to be relative to the playable area.", "\n", "# The map_size and playable_area will be the diagonal of the real playable area.", "\n", "raw_crop_to_playable_area", "=", "False", "\n", "\n", "interface", "=", "sc_pb", ".", "InterfaceOptions", "(", "\n", "raw", "=", "True", ",", "\n", "score", "=", "True", ",", "\n", "# Omit to disable.", "\n", "feature_layer", "=", "sc_pb", ".", "SpatialCameraSetup", "(", "width", "=", "camera_width", ")", ",", "\n", "# Omit to disable.", "\n", "render", "=", "None", ",", "\n", "# By default cloaked units are completely hidden. This shows some details.", "\n", "show_cloaked", "=", "False", ",", "\n", "# By default burrowed units are completely hidden. This shows some details for those that produce a shadow.", "\n", "show_burrowed_shadows", "=", "False", ",", "\n", "# Return placeholder units (buildings to be constructed), both for raw and feature layers.", "\n", "show_placeholders", "=", "False", ",", "\n", "# see below", "\n", "raw_affects_selection", "=", "raw_affects_selection", ",", "\n", "# see below", "\n", "raw_crop_to_playable_area", "=", "raw_crop_to_playable_area", "\n", ")", "\n", "\n", "screen_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "resolution", ")", "\n", "minimap_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "minimap_resolution", ")", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "j", "=", "0", "\n", "replay_length_list", "=", "[", "]", "\n", "noop_length_list", "=", "[", "]", "\n", "\n", "mAS_agent", "=", "AlphaStarAgent", "(", "name", "=", "'replay_compare'", ")", "\n", "\n", "with", "run_config", ".", "start", "(", "full_screen", "=", "False", ")", "as", "controller", ":", "\n", "\n", "        ", "for", "replay_file", "in", "tqdm", "(", "replay_files", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "replay_path", "=", "REPLAY_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "replay_data", "=", "run_config", ".", "replay_data", "(", "replay_path", ")", "\n", "replay_info", "=", "controller", ".", "replay_info", "(", "replay_data", ")", "\n", "\n", "start_replay", "=", "sc_pb", ".", "RequestStartReplay", "(", "\n", "replay_data", "=", "replay_data", ",", "\n", "options", "=", "interface", ",", "\n", "disable_fog", "=", "False", ",", "# FLAGS.disable_fog", "\n", "observed_player_id", "=", "1", ",", "# FLAGS.observed_player", "\n", "map_data", "=", "None", ",", "\n", "realtime", "=", "False", "\n", ")", "\n", "\n", "print", "(", "\" Replay info \"", ".", "center", "(", "60", ",", "\"-\"", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "replay_info", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"-\"", "*", "60", ")", "if", "debug", "else", "None", "\n", "controller", ".", "start_replay", "(", "start_replay", ")", "\n", "# The below several arguments are default set to False, so we shall enable them.", "\n", "\n", "# use_feature_units: Whether to include feature_unit observations.", "\n", "\n", "# use_raw_units: Whether to include raw unit data in observations. This", "\n", "# differs from feature_units because it includes units outside the", "\n", "# screen and hidden units, and because unit positions are given in", "\n", "# terms of world units instead of screen units.", "\n", "\n", "# use_raw_actions: [bool] Whether to use raw actions as the interface.", "\n", "# Same as specifying action_space=ActionSpace.RAW.", "\n", "\n", "# use_unit_counts: Whether to include unit_counts observation. Disabled by", "\n", "# default since it gives information outside the visible area. ", "\n", "\n", "'''\n                show_cloaked: Whether to show limited information for cloaked units.\n                show_burrowed_shadows: Whether to show limited information for burrowed\n                      units that leave a shadow on the ground (ie widow mines and moving\n                      roaches and infestors).\n                show_placeholders: Whether to show buildings that are queued for\n                      construction.\n                '''", "\n", "\n", "feat", "=", "F", ".", "features_from_game_info", "(", "game_info", "=", "controller", ".", "game_info", "(", ")", ",", "\n", "use_feature_units", "=", "True", ",", "use_raw_units", "=", "True", ",", "\n", "use_unit_counts", "=", "True", ",", "use_raw_actions", "=", "True", ",", "\n", "show_cloaked", "=", "True", ",", "show_burrowed_shadows", "=", "True", ",", "\n", "show_placeholders", "=", "True", ")", "\n", "print", "(", "\"feat obs spec:\"", ",", "feat", ".", "observation_spec", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feat action spec:\"", ",", "feat", ".", "action_spec", "(", ")", ")", "if", "debug", "else", "None", "\n", "prev_obs", "=", "None", "\n", "i", "=", "0", "\n", "save_steps", "=", "0", "\n", "noop_count", "=", "0", "\n", "feature_list", ",", "label_list", "=", "[", "]", ",", "[", "]", "\n", "step_dict", "=", "{", "}", "\n", "\n", "# set the obs and action spec", "\n", "obs_spec", "=", "feat", ".", "observation_spec", "(", ")", "\n", "act_spec", "=", "feat", ".", "action_spec", "(", ")", "\n", "mAS_agent", ".", "setup", "(", "obs_spec", ",", "act_spec", ")", "\n", "\n", "# initial build order", "\n", "player_bo", "=", "[", "]", "\n", "player_memory", "=", "mAS_agent", ".", "initial_state", "(", ")", "\n", "\n", "while", "True", ":", "\n", "                    ", "o", "=", "controller", ".", "observe", "(", ")", "\n", "try", ":", "\n", "                        ", "obs", "=", "feat", ".", "transform_obs", "(", "o", ")", "\n", "\n", "if", "prev_obs", "is", "not", "None", ":", "\n", "# calculate the build order", "\n", "                            ", "player_bo", "=", "U", ".", "calculate_build_order", "(", "player_bo", ",", "prev_obs", ",", "obs", ")", "\n", "print", "(", "\"player build order:\"", ",", "player_bo", ")", "if", "debug", "else", "None", "\n", "\n", "# calculate the unit counts of bag", "\n", "player_ucb", "=", "U", ".", "calculate_unit_counts_bow", "(", "prev_obs", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "\"player unit count of bow:\"", ",", "sum", "(", "player_ucb", ")", ")", "if", "debug", "else", "None", "\n", "\n", "", "try", ":", "\n", "                            ", "func_call", "=", "None", "\n", "no_op", "=", "False", "\n", "if", "o", ".", "actions", "and", "prev_obs", ":", "\n", "                                ", "func_call", "=", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ")", "\n", "if", "func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "                                    ", "no_op", "=", "True", "\n", "func_call", "=", "None", "\n", "", "", "else", ":", "\n", "                                ", "no_op", "=", "True", "\n", "\n", "", "if", "no_op", ":", "\n", "                                ", "print", "(", "'expert func: no op'", ")", "if", "debug", "else", "None", "\n", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "FLAGS", ".", "no_op_threshold", ":", "\n", "                                    ", "print", "(", "'get no op !'", ")", "if", "debug", "else", "None", "\n", "noop_count", "+=", "1", "\n", "func_call", "=", "A", ".", "FunctionCall", ".", "init_with_validation", "(", "\"no_op\"", ",", "[", "]", ",", "raw", "=", "True", ")", "\n", "\n", "", "", "if", "func_call", "is", "not", "None", ":", "\n", "                                ", "player_step", "=", "mAS_agent", ".", "step_logits", "(", "obs", ",", "player_memory", ")", "\n", "player_function_call", ",", "player_action", ",", "player_logits", ",", "player_new_memory", "=", "player_step", "\n", "player_memory", "=", "player_new_memory", "\n", "\n", "print", "(", "'expert raw func_call: '", ",", "func_call", ")", "if", "1", "else", "None", "\n", "print", "(", "'agent raw func_call: '", ",", "player_function_call", ")", "if", "1", "else", "None", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "i", ">=", "max_steps_of_replay", ":", "# test the first n frames", "\n", "                            ", "print", "(", "\"max frames test, break out!\"", ")", "\n", "break", "\n", "\n", "", "if", "o", ".", "player_result", ":", "# end of game", "\n", "                            ", "print", "(", "o", ".", "player_result", ")", "\n", "break", "\n", "\n", "", "", "except", "Exception", "as", "inst", ":", "\n", "                        ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "controller", ".", "step", "(", ")", "\n", "prev_obs", "=", "obs", "\n", "i", "+=", "1", "\n", "\n", "", "j", "+=", "1", "\n", "replay_length_list", ".", "append", "(", "save_steps", ")", "\n", "noop_length_list", ".", "append", "(", "noop_count", ")", "\n", "# We only test the first one replay            ", "\n", "", "except", "Exception", "as", "inst", ":", "\n", "                ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "j", ">=", "max_replays", ":", "# test the first n frames", "\n", "                ", "print", "(", "\"max replays test, break out!\"", ")", "\n", "break", "\n", "\n", "", "", "", "print", "(", "\"end\"", ")", "\n", "print", "(", "\"replay_length_list:\"", ",", "replay_length_list", ")", "\n", "print", "(", "\"noop_length_list:\"", ",", "noop_length_list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.__init__": [[27, 30], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Label", ",", "self", ")", ".", "__init__", "(", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.actionlist2label": [[31, 50], ["target_location_encoding.reshape.reshape.reshape", "torch.cat", "print", "print"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "actionlist2label", "(", "actionlist", ")", ":", "\n", "        ", "''' \n        input: args action list \n        outoput: [batch_size x label_feature_size]\n        '''", "\n", "# TOCHANGE", "\n", "tue_index", "=", "LabelIndex", ".", "target_location_encoding", "\n", "target_location_encoding", "=", "action", "[", "tue_index", "]", "\n", "batch_size", "=", "target_location_encoding", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "\"target_location_encoding.shape before:\"", ",", "target_location_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "target_location_encoding", "=", "target_location_encoding", ".", "reshape", "(", "batch_size", ",", "LS", "[", "tue_index", "]", ")", "\n", "print", "(", "\"target_location_encoding.shape after:\"", ",", "target_location_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "action", "[", "tue_index", "]", "=", "target_location_encoding", "\n", "\n", "label", "=", "torch", ".", "cat", "(", "action", ",", "dim", "=", "1", ")", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.getSize": [[51, 57], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "getSize", "(", ")", ":", "\n", "        ", "last_index", "=", "0", "\n", "for", "i", "in", "LabelIndex", ":", "\n", "            ", "last_index", "+=", "LS", "[", "i", "]", "\n", "", "return", "last_index", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label": [[58, 84], ["target_location_encoding.reshape.reshape.reshape", "units_encoding.reshape.reshape.reshape", "target_unit_encoding.reshape.reshape.reshape", "torch.cat", "print", "print", "action.toList"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.toList"], ["", "@", "staticmethod", "\n", "def", "action2label", "(", "action", ")", ":", "\n", "        ", "''' \n        input: args action logits (tensor) \n        outoput: [batch_size x label_feature_size]\n        '''", "\n", "target_location_index", "=", "LabelIndex", ".", "target_location_encoding", "\n", "target_location_encoding", "=", "action", ".", "target_location", "\n", "batch_size", "=", "target_location_encoding", ".", "shape", "[", "0", "]", "\n", "print", "(", "\"target_location_encoding.shape before:\"", ",", "target_location_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "target_location_encoding", "=", "target_location_encoding", ".", "reshape", "(", "batch_size", ",", "LS", "[", "target_location_index", "]", ")", "\n", "print", "(", "\"target_location_encoding.shape after:\"", ",", "target_location_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "action", ".", "target_location", "=", "target_location_encoding", "\n", "\n", "units_index", "=", "LabelIndex", ".", "select_units_encoding", "\n", "units_encoding", "=", "action", ".", "units", "\n", "units_encoding", "=", "units_encoding", ".", "reshape", "(", "batch_size", ",", "LS", "[", "units_index", "]", ")", "\n", "action", ".", "units", "=", "units_encoding", "\n", "\n", "target_unit_index", "=", "LabelIndex", ".", "target_unit_encoding", "\n", "target_unit_encoding", "=", "action", ".", "target_unit", "\n", "target_unit_encoding", "=", "target_unit_encoding", ".", "reshape", "(", "batch_size", ",", "LS", "[", "target_unit_index", "]", ")", "\n", "action", ".", "target_unit", "=", "target_unit_encoding", "\n", "\n", "label", "=", "torch", ".", "cat", "(", "action", ".", "toList", "(", ")", ",", "dim", "=", "1", ")", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.label2action": [[85, 119], ["action_list[].reshape", "action_list[].reshape", "action_list[].reshape", "alphastarmini.core.rl.action.ArgsActionLogits", "action_list.append", "print", "int", "print", "int", "int", "print"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "label2action", "(", "label", ")", ":", "\n", "        ", "''' \n        input: [batch_size x label_feature_size]\n        outoput: args action logits (tensor)\n        '''", "\n", "\n", "batch_size", "=", "label", ".", "shape", "[", "0", "]", "\n", "action", "=", "None", "\n", "\n", "action_list", "=", "[", "]", "\n", "last_index", "=", "0", "\n", "for", "i", "in", "LabelIndex", ":", "\n", "            ", "label_i", "=", "label", "[", ":", ",", "last_index", ":", "last_index", "+", "LS", "[", "i", "]", "]", "\n", "print", "(", "'added label_i.shape:'", ",", "label_i", ".", "shape", ")", "if", "debug", "else", "None", "\n", "action_list", ".", "append", "(", "label_i", ")", "\n", "last_index", "+=", "LS", "[", "i", "]", "\n", "\n", "", "tue_index", "=", "LabelIndex", ".", "target_location_encoding", "\n", "print", "(", "\"action_list[tue_index].shape before:\"", ",", "action_list", "[", "tue_index", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "action_list", "[", "tue_index", "]", "=", "action_list", "[", "tue_index", "]", ".", "reshape", "(", "batch_size", ",", "SCHP", ".", "world_size", ",", "\n", "int", "(", "LS", "[", "tue_index", "]", "/", "SCHP", ".", "world_size", ")", ")", "\n", "print", "(", "\"action_list[tue_index].shape before:\"", ",", "action_list", "[", "tue_index", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "units_index", "=", "LabelIndex", ".", "select_units_encoding", "\n", "action_list", "[", "units_index", "]", "=", "action_list", "[", "units_index", "]", ".", "reshape", "(", "batch_size", ",", "AHP", ".", "max_selected", ",", "\n", "int", "(", "LS", "[", "units_index", "]", "/", "AHP", ".", "max_selected", ")", ")", "\n", "\n", "target_unit_index", "=", "LabelIndex", ".", "target_unit_encoding", "\n", "action_list", "[", "target_unit_index", "]", "=", "action_list", "[", "target_unit_index", "]", ".", "reshape", "(", "batch_size", ",", "1", ",", "\n", "int", "(", "LS", "[", "target_unit_index", "]", ")", ")", "\n", "\n", "action", "=", "ArgsActionLogits", "(", "*", "action_list", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.label2actionlist": [[120, 147], ["action_list[].reshape", "action_list.append", "print", "int", "print", "print"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "label2actionlist", "(", "label", ")", ":", "\n", "        ", "''' \n        input: [batch_size x label_feature_size]\n        outoput: args action list\n        '''", "\n", "\n", "# TOCHANGE", "\n", "batch_size", "=", "label", ".", "shape", "[", "0", "]", "\n", "action", "=", "None", "\n", "\n", "action_list", "=", "[", "]", "\n", "last_index", "=", "0", "\n", "for", "i", "in", "LabelIndex", ":", "\n", "            ", "label_i", "=", "label", "[", ":", ",", "last_index", ":", "last_index", "+", "LS", "[", "i", "]", "]", "\n", "print", "(", "'added label_i.shape:'", ",", "label_i", ".", "shape", ")", "if", "debug", "else", "None", "\n", "action_list", ".", "append", "(", "label_i", ")", "\n", "last_index", "+=", "LS", "[", "i", "]", "\n", "\n", "", "tue_index", "=", "LabelIndex", ".", "target_location_encoding", "\n", "print", "(", "\"action_list[tue_index].shape before:\"", ",", "action_list", "[", "tue_index", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "action_list", "[", "tue_index", "]", "=", "action_list", "[", "tue_index", "]", ".", "reshape", "(", "batch_size", ",", "SCHP", ".", "world_size", ",", "\n", "int", "(", "LS", "[", "tue_index", "]", "/", "SCHP", ".", "world_size", ")", ")", "\n", "print", "(", "\"action_list[tue_index].shape before:\"", ",", "action_list", "[", "tue_index", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "action", "=", "action_list", "\n", "return", "action", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_loss.get_sl_loss": [[19, 64], ["alphastarmini.core.sl.feature.Feature.getSize", "alphastarmini.core.sl.label.Label.getSize", "traj_batch[].reshape", "traj_batch[].reshape", "alphastarmini.core.sl.feature.Feature.feature2state", "alphastarmini.core.sl.label.Label.label2action", "Feature.feature2state.to", "Label.label2action.to", "sl_loss.get_sl_loss.unroll"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.getSize", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.getSize", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.feature2state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.label2action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.unroll"], ["def", "get_sl_loss", "(", "traj_batch", ",", "model", ")", ":", "\n", "# criterion = nn.CrossEntropyLoss()", "\n", "# due to CrossEntropyLoss only accepts loss with lables.shape = [N]", "\n", "# we define a loss accept soft_target, which label.shape = [N, C] ", "\n", "    ", "def", "cross_entropy", "(", "pred", ",", "soft_targets", ")", ":", "\n", "# class is always in the last dim", "\n", "        ", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "-", "soft_targets", "*", "logsoftmax", "(", "pred", ")", ",", "-", "1", ")", ")", "\n", "", "criterion", "=", "cross_entropy", "\n", "\n", "loss", "=", "0", "\n", "feature_size", "=", "Feature", ".", "getSize", "(", ")", "\n", "label_size", "=", "Label", ".", "getSize", "(", ")", "\n", "\n", "print", "(", "'traj_batch.shape:'", ",", "traj_batch", ".", "shape", ")", "if", "1", "else", "None", "\n", "batch_size", "=", "traj_batch", ".", "shape", "[", "0", "]", "\n", "seq_len", "=", "traj_batch", ".", "shape", "[", "1", "]", "\n", "\n", "feature", "=", "traj_batch", "[", ":", ",", ":", ",", ":", "feature_size", "]", ".", "reshape", "(", "batch_size", "*", "seq_len", ",", "feature_size", ")", "\n", "label", "=", "traj_batch", "[", ":", ",", ":", ",", "feature_size", ":", "feature_size", "+", "label_size", "]", ".", "reshape", "(", "batch_size", "*", "seq_len", ",", "label_size", ")", "\n", "is_final", "=", "traj_batch", "[", ":", ",", ":", ",", "-", "1", ":", "]", "\n", "\n", "state", "=", "Feature", ".", "feature2state", "(", "feature", ")", "\n", "print", "(", "'state:'", ",", "state", ")", "if", "debug", "else", "None", "\n", "\n", "action_gt", "=", "Label", ".", "label2action", "(", "label", ")", "\n", "print", "(", "'action_gt:'", ",", "action_gt", ")", "if", "debug", "else", "None", "\n", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "print", "(", "\"model.device:\"", ",", "device", ")", "if", "debug", "else", "None", "\n", "\n", "state", ".", "to", "(", "device", ")", "\n", "action_gt", ".", "to", "(", "device", ")", "\n", "\n", "def", "unroll", "(", "state", ",", "batch_size", "=", "None", ",", "sequence_length", "=", "None", ")", ":", "\n", "        ", "action_pt", ",", "_", ",", "_", "=", "model", ".", "forward", "(", "state", ",", "batch_size", "=", "batch_size", ",", "sequence_length", "=", "sequence_length", ",", "return_logits", "=", "True", ")", "\n", "return", "action_pt", "\n", "\n", "", "action_pt", "=", "unroll", "(", "state", ",", "batch_size", "=", "batch_size", ",", "sequence_length", "=", "seq_len", ")", "\n", "print", "(", "'action_pt:'", ",", "action_pt", ")", "if", "debug", "else", "None", "\n", "\n", "loss", "=", "get_classify_loss", "(", "action_pt", ",", "action_gt", ",", "criterion", ")", "\n", "print", "(", "'loss:'", ",", "loss", ")", "if", "debug", "else", "None", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_loss.get_classify_loss": [[66, 113], ["criterion", "criterion", "criterion", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "criterion", "criterion", "criterion", "print", "print", "print", "print", "print", "print", "action_pt.target_location.reshape", "action_gt.target_location.reshape"], "function", ["None"], ["", "def", "get_classify_loss", "(", "action_pt", ",", "action_gt", ",", "criterion", ")", ":", "\n", "    ", "loss", "=", "0", "\n", "\n", "action_type_loss", "=", "criterion", "(", "action_pt", ".", "action_type", ",", "action_gt", ".", "action_type", ")", "\n", "loss", "+=", "action_type_loss", "\n", "\n", "delay_loss", "=", "criterion", "(", "action_pt", ".", "delay", ",", "action_gt", ".", "delay", ")", "\n", "loss", "+=", "delay_loss", "\n", "\n", "queue_loss", "=", "criterion", "(", "action_pt", ".", "queue", ",", "action_gt", ".", "queue", ")", "\n", "loss", "+=", "queue_loss", "\n", "\n", "units_loss", "=", "torch", ".", "tensor", "(", "[", "0", "]", ")", "\n", "if", "action_gt", ".", "units", "is", "not", "None", "and", "action_pt", ".", "units", "is", "not", "None", ":", "\n", "        ", "print", "(", "'action_gt.units.shape:'", ",", "action_gt", ".", "units", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_pt.units.shape:'", ",", "action_pt", ".", "units", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "units_size", "=", "action_gt", ".", "units", ".", "shape", "[", "-", "1", "]", "\n", "\n", "units_loss", "=", "criterion", "(", "action_pt", ".", "units", ",", "action_gt", ".", "units", ")", "\n", "# units_loss = 0", "\n", "loss", "+=", "units_loss", "\n", "\n", "", "target_unit_loss", "=", "torch", ".", "tensor", "(", "[", "0", "]", ")", "\n", "if", "action_gt", ".", "target_unit", "is", "not", "None", "and", "action_pt", ".", "target_unit", "is", "not", "None", ":", "\n", "        ", "print", "(", "'action_gt.target_unit.shape:'", ",", "action_gt", ".", "target_unit", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_pt.target_unit.shape:'", ",", "action_pt", ".", "target_unit", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "units_size", "=", "action_gt", ".", "target_unit", ".", "shape", "[", "-", "1", "]", "\n", "\n", "target_unit_loss", "=", "criterion", "(", "action_pt", ".", "target_unit", ",", "action_gt", ".", "target_unit", ")", "\n", "loss", "+=", "target_unit_loss", "\n", "\n", "", "target_location_loss", "=", "torch", ".", "tensor", "(", "[", "0", "]", ")", "\n", "if", "action_gt", ".", "target_location", "is", "not", "None", "and", "action_pt", ".", "target_location", "is", "not", "None", ":", "\n", "        ", "print", "(", "'action_gt.target_location.shape:'", ",", "action_gt", ".", "target_location", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_pt.target_location.shape:'", ",", "action_pt", ".", "target_location", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "batch_size", "=", "action_gt", ".", "target_location", ".", "shape", "[", "0", "]", "\n", "\n", "target_location_loss", "=", "criterion", "(", "action_pt", ".", "target_location", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "action_gt", ".", "target_location", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ")", "\n", "loss", "+=", "target_location_loss", "\n", "\n", "# test, only return action_type_loss", "\n", "# return loss", "\n", "", "loss_list", "=", "[", "action_type_loss", ",", "delay_loss", ",", "queue_loss", ",", "units_loss", ",", "target_unit_loss", ",", "target_location_loss", "]", "\n", "return", "loss", ",", "loss_list", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.__init__": [[27, 33], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "initialed", "=", "False", "\n", "self", ".", "feature_size", "=", "None", "\n", "self", ".", "label_size", "=", "None", "\n", "self", ".", "replay_length_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_trainable_data": [[34, 85], ["print", "os.listdir", "print", "os.listdir.sort", "enumerate", "print", "print", "len", "print", "torch.load", "print", "print", "torch.zeros", "torch.cat", "traj_list.append", "dataset.SC2ReplayData.replay_length_list.append", "len", "len", "traceback.print_exc"], "methods", ["None"], ["", "def", "get_trainable_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "out_features", "=", "None", "\n", "\n", "print", "(", "'data path:'", ",", "path", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "replay_files", ".", "sort", "(", ")", "\n", "\n", "traj_list", "=", "[", "]", "\n", "for", "i", ",", "replay_file", "in", "enumerate", "(", "replay_files", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "i", ">", "15", ":", "\n", "                    ", "break", "\n", "", "replay_path", "=", "path", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "\n", "m", "=", "torch", ".", "load", "(", "replay_path", ")", "\n", "features", "=", "m", "[", "'features'", "]", "\n", "labels", "=", "m", "[", "'labels'", "]", "\n", "assert", "len", "(", "features", ")", "==", "len", "(", "labels", ")", "\n", "\n", "if", "self", ".", "feature_size", ":", "\n", "                    ", "assert", "self", ".", "feature_size", "==", "features", ".", "shape", "[", "1", "]", "\n", "assert", "self", ".", "label_size", "==", "labels", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "self", ".", "feature_size", "=", "features", ".", "shape", "[", "1", "]", "\n", "self", ".", "label_size", "=", "labels", ".", "shape", "[", "1", "]", "\n", "\n", "", "print", "(", "'self.feature_size:'", ",", "self", ".", "feature_size", ")", "\n", "print", "(", "'self.label_size:'", ",", "self", ".", "label_size", ")", "\n", "\n", "is_final", "=", "torch", ".", "zeros", "(", "[", "features", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "is_final", "[", "features", ".", "shape", "[", "0", "]", "-", "1", ",", "0", "]", "=", "1", "\n", "\n", "one_traj", "=", "torch", ".", "cat", "(", "[", "features", ",", "labels", ",", "is_final", "]", ",", "dim", "=", "1", ")", "\n", "\n", "traj_list", ".", "append", "(", "one_traj", ")", "\n", "self", ".", "replay_length_list", ".", "append", "(", "one_traj", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "print", "(", "\"end\"", ")", "\n", "print", "(", "\"self.replay_length_list:\"", ",", "self", ".", "replay_length_list", ")", "\n", "\n", "# note: do not do below line because memory can not affort thig big tensor", "\n", "#out_features = torch.cat(out_features_list, dim=0)", "\n", "\n", "self", ".", "initialed", "=", "True", "\n", "return", "traj_list", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.filter_data": [[86, 91], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "filter_data", "(", "feature", ",", "label", ")", ":", "\n", "        ", "tmp_feature", "=", "None", "\n", "\n", "return", "tmp_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_training_data": [[92, 97], ["int", "print", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "print", "(", "'training_size:'", ",", "training_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_val_data": [[98, 104], ["int", "int", "print", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_val_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "print", "(", "'val_size:'", ",", "val_size", ")", "\n", "return", "trajs", "[", "training_size", ":", "training_size", "+", "val_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_test_data": [[105, 112], ["int", "int", "int", "print", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_test_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "test_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "test", ")", "\n", "print", "(", "'test_size:'", ",", "test_size", ")", "\n", "return", "trajs", "[", "-", "test_size", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_training_for_val_data": [[113, 118], ["int", "print", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_val_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "print", "(", "'training_size:'", ",", "training_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_training_for_test_data": [[119, 125], ["int", "int", "print", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_test_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "print", "(", "'training_for_test_size:'", ",", "training_size", "+", "val_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "+", "val_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayData.get_training_for_deploy_data": [[126, 133], ["int", "int", "int", "print", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_deploy_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "test_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "test", ")", "\n", "print", "(", "'training_for_deploy_size:'", ",", "training_size", "+", "val_size", "+", "test_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "+", "val_size", "+", "test_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayDataset.__init__": [[137, 142], ["torch.utils.data.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "traj_list", ",", "seq_length", ",", "training", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "traj_list", "=", "traj_list", "\n", "self", ".", "seq_length", "=", "seq_length", "\n", "#print(\"self.seq_length:\", self.seq_length)", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayDataset.__getitem__": [[144, 169], ["enumerate", "torch.cat", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "old_start", "=", "0", "\n", "begin", "=", "index", "*", "self", ".", "seq_length", "\n", "end", "=", "(", "index", "+", "1", ")", "*", "self", ".", "seq_length", "\n", "\n", "for", "i", ",", "one_traj", "in", "enumerate", "(", "self", ".", "traj_list", ")", ":", "\n", "            ", "new_start", "=", "old_start", "+", "one_traj", ".", "shape", "[", "0", "]", "\n", "#print('old_start:', old_start)", "\n", "#print('new_start:', new_start)             ", "\n", "\n", "if", "begin", ">=", "new_start", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "index_begin", "=", "begin", "-", "old_start", "\n", "if", "end", "<", "new_start", ":", "\n", "                    ", "index_end", "=", "end", "-", "old_start", "\n", "return", "one_traj", "[", "index_begin", ":", "index_end", ",", ":", "]", "\n", "", "elif", "i", "<", "len", "(", "self", ".", "traj_list", ")", "-", "1", ":", "\n", "                    ", "next_traj", "=", "self", ".", "traj_list", "[", "i", "+", "1", "]", "\n", "\n", "first_part", "=", "one_traj", "[", "index_begin", ":", ",", ":", "]", "\n", "second_part", "=", "next_traj", "[", ":", "self", ".", "seq_length", "-", "len", "(", "first_part", ")", ",", ":", "]", "\n", "return", "torch", ".", "cat", "(", "[", "first_part", ",", "second_part", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "old_start", "=", "new_start", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.SC2ReplayDataset.__len__": [[170, 177], ["int"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "max_len", "=", "0", "\n", "for", "one_traj", "in", "self", ".", "traj_list", ":", "\n", "            ", "max_len", "+=", "one_traj", ".", "shape", "[", "0", "]", "\n", "", "max_len", "-=", "self", ".", "seq_length", "\n", "\n", "return", "int", "(", "max_len", "/", "self", ".", "seq_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset.test": [[179, 181], ["None"], "function", ["None"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_tensor.train_for_val": [[81, 127], ["alphastarmini.core.sl.dataset.SC2ReplayData.get_training_for_val_data", "alphastarmini.core.sl.dataset.SC2ReplayData.get_val_data", "alphastarmini.core.sl.dataset.SC2ReplayDataset", "alphastarmini.core.sl.dataset.SC2ReplayDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "alphastarmini.core.arch.agent.Agent", "alphastarmini.core.arch.agent.Agent.to", "torch.optim.Adam", "range", "torch.save", "alphastarmini.core.arch.agent.Agent.model.parameters", "alphastarmini.core.arch.agent.Agent.model.train", "print", "traj.to().float.to().float", "torch.autograd.detect_anomaly", "alphastarmini.core.arch.agent.Agent.get_sl_loss", "torch.optim.Adam.zero_grad", "agent.get_sl_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "agent.get_sl_loss.item", "traj.to().float.to", "alphastarmini.core.arch.agent.Agent.model.parameters"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_for_val_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_val_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_loss.get_sl_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["def", "train_for_val", "(", "feature", ",", "replay_data", ")", ":", "\n", "    ", "train_feature", "=", "SC2ReplayData", ".", "get_training_for_val_data", "(", "feature", ")", "\n", "val_feature", "=", "SC2ReplayData", ".", "get_val_data", "(", "feature", ")", "\n", "\n", "train_set", "=", "SC2ReplayDataset", "(", "train_feature", ",", "seq_length", "=", "SEQ_LEN", ",", "training", "=", "NORM", ")", "\n", "val_set", "=", "SC2ReplayDataset", "(", "val_feature", ",", "seq_length", "=", "SEQ_LEN", ",", "training", "=", "False", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "BATCH_SIZE", ",", "num_workers", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_set", ",", "batch_size", "=", "BATCH_SIZE", ",", "num_workers", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "\n", "#model = load_latest_model() if RESTORE else choose_model(MODEL)", "\n", "# model.to(DEVICE)", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "agent", ".", "to", "(", "DEVICE", ")", "\n", "\n", "optimizer", "=", "Adam", "(", "agent", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "LEARNING_RATE", ",", "weight_decay", "=", "WEIGHT_DECAY", ")", "\n", "\n", "train_loss", "=", "0", "\n", "for", "epoch", "in", "range", "(", "NUM_EPOCHS", ")", ":", "\n", "        ", "agent", ".", "model", ".", "train", "(", ")", "\n", "\n", "loss_sum", "=", "0.0", "\n", "i", "=", "0", "\n", "for", "traj", "in", "train_loader", ":", "\n", "            ", "traj", "=", "traj", ".", "to", "(", "DEVICE", ")", ".", "float", "(", ")", "\n", "\n", "with", "torch", ".", "autograd", ".", "detect_anomaly", "(", ")", ":", "\n", "                ", "loss", "=", "agent", ".", "get_sl_loss", "(", "traj", ",", "replay_data", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "# note, we don't need retain_graph=True if we set hidden_state.detach()", "\n", "\n", "# add a grad clip", "\n", "parameters", "=", "[", "p", "for", "p", "in", "agent", ".", "model", ".", "parameters", "(", ")", "if", "p", "is", "not", "None", "and", "p", ".", "requires_grad", "]", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "parameters", ",", "CLIP", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "loss_sum", "+=", "loss", ".", "item", "(", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "train_loss", "=", "loss_sum", "/", "(", "i", "+", "1e-9", ")", "\n", "#val_loss = eval(model, criterion, val_loader, train_set, val_set)", "\n", "print", "(", "\"Train loss: {:.6f}.\"", ".", "format", "(", "train_loss", ")", ")", "\n", "#print(\"Train loss: {:.6f}, Val loss: {:.6f}.\".format(train_loss, val_loss))", "\n", "\n", "", "torch", ".", "save", "(", "agent", ".", "model", ",", "SAVE_PATH", "+", "\"_val\"", "+", "\".pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_tensor.eval": [[129, 151], ["model.eval", "len", "feature.to().float.to().float", "target.to().float.to().float", "agent.unroll", "criterion", "print", "print", "print", "agent.unroll.size", "criterion.item", "feature.to().float.to", "target.to().float.to", "feature.to().float.size", "target.to().float.size", "agent.unroll.size"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.eval", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.unroll", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "eval", "(", "model", ",", "criterion", ",", "data_loader", ",", "train_set", ",", "val_set", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "n_samples", "=", "len", "(", "val_set", ")", "\n", "loss_sum", "=", "0.0", "\n", "\n", "for", "feature", ",", "target", "in", "data_loader", ":", "\n", "        ", "feature", "=", "feature", ".", "to", "(", "DEVICE", ")", ".", "float", "(", ")", "\n", "target", "=", "target", ".", "to", "(", "DEVICE", ")", ".", "float", "(", ")", "\n", "\n", "output", "=", "agent", ".", "unroll", "(", "feature", ")", "\n", "\n", "if", "debug", ":", "\n", "            ", "print", "(", "\"feature.size(): \"", ",", "feature", ".", "size", "(", ")", ")", "\n", "print", "(", "\"target.size(): \"", ",", "target", ".", "size", "(", ")", ")", "\n", "print", "(", "\"output.size(): \"", ",", "output", ".", "size", "(", ")", ")", "\n", "break", "\n", "\n", "", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "loss_sum", "+=", "output", ".", "size", "(", "0", ")", "*", "loss", ".", "item", "(", ")", "\n", "\n", "", "return", "loss_sum", "/", "n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_tensor.test": [[153, 169], ["alphastarmini.core.sl.dataset.SC2ReplayData", "alphastarmini.core.sl.dataset.SC2ReplayData.get_trainable_data", "sl_train_by_tensor.train_for_val", "train_for_test", "train_for_deploy", "sl_train_by_tensor.train_for_val"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_trainable_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.train_for_val", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.train_for_val"], ["", "def", "test", "(", "on_server", ")", ":", "\n", "# get all the data", "\n", "# Note: The feature here is actually feature+label", "\n", "    ", "replay_data", "=", "SC2ReplayData", "(", ")", "\n", "features", "=", "replay_data", ".", "get_trainable_data", "(", "PATH", ")", "\n", "\n", "#print('out_features:', features)", "\n", "\n", "if", "TYPE", "==", "'val'", ":", "\n", "        ", "train_for_val", "(", "features", ",", "replay_data", ")", "# select the best hyper-parameters", "\n", "", "elif", "TYPE", "==", "'test'", ":", "\n", "        ", "train_for_test", "(", "features", ",", "replay_data", ")", "# for test the performance in real life", "\n", "", "elif", "TYPE", "==", "'deploy'", ":", "\n", "        ", "train_for_deploy", "(", "features", ",", "replay_data", ")", "# only used for production", "\n", "", "else", ":", "\n", "        ", "train_for_val", "(", "features", ",", "replay_data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_pickle.print_tensor_list": [[32, 38], ["isinstance", "load_pickle.print_tensor_list", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_pickle.print_tensor_list"], ["def", "print_tensor_list", "(", "tensor_list", ")", ":", "\n", "    ", "for", "l", "in", "tensor_list", ":", "\n", "        ", "if", "isinstance", "(", "l", ",", "list", ")", ":", "\n", "            ", "print_tensor_list", "(", "l", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "l", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.load_pickle.test": [[40, 84], ["print", "os.listdir", "print", "os.listdir.sort", "alphastarmini.core.arch.agent.Agent", "print", "print", "len", "print", "open", "pickle.load", "pickle.load.keys", "traceback.print_exc", "alphastarmini.core.arch.agent.Agent.get_state_and_action_from_pickle", "alphastarmini.core.sl.feature.Feature.state2feature", "alphastarmini.core.arch.agent.Agent.func_call_to_action().toTenser", "agent.func_call_to_action().toTenser.toLogits", "alphastarmini.core.sl.label.Label.action2label", "print", "print", "print", "print", "print", "print", "print", "alphastarmini.core.arch.agent.Agent.func_call_to_action", "agent.func_call_to_action().toTenser.get_shape"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_state_and_action_from_pickle", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toTenser", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape"], ["", "", "", "def", "test", "(", ")", ":", "\n", "    ", "DATA_PATH", "=", "FLAGS", ".", "replay_data_path", "\n", "print", "(", "'data path:'", ",", "DATA_PATH", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "replay_files", ".", "sort", "(", ")", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "j", "=", "0", "\n", "replay_length_list", "=", "[", "]", "\n", "traj_list", "=", "[", "]", "\n", "for", "replay_file", "in", "replay_files", ":", "\n", "        ", "try", ":", "\n", "            ", "replay_path", "=", "DATA_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "\n", "with", "open", "(", "replay_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "b", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "keys", "=", "b", ".", "keys", "(", ")", "\n", "#print('keys:', keys)", "\n", "for", "key", "in", "keys", ":", "\n", "                    ", "obs", "=", "b", "[", "key", "]", "\n", "s", "=", "agent", ".", "get_state_and_action_from_pickle", "(", "obs", ")", "\n", "feature", "=", "Feature", ".", "state2feature", "(", "s", ")", "\n", "print", "(", "\"feature:\"", ",", "feature", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature.shape:\"", ",", "feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"begin a:\"", ")", "if", "debug", "else", "None", "\n", "func_call", "=", "obs", "[", "'func_call'", "]", "\n", "action", "=", "agent", ".", "func_call_to_action", "(", "func_call", ")", ".", "toTenser", "(", ")", "\n", "#tag_list = agent.get_tag_list(obs)", "\n", "print", "(", "'action.get_shape:'", ",", "action", ".", "get_shape", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "logits", "=", "action", ".", "toLogits", "(", ")", "\n", "print", "(", "'logits.shape:'", ",", "logits", ")", "if", "debug", "else", "None", "\n", "label", "=", "Label", ".", "action2label", "(", "logits", ")", "\n", "print", "(", "\"label:\"", ",", "label", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"label.shape:\"", ",", "label", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "print", "(", "\"end\"", ")", "\n", "print", "(", "\"replay_length_list:\"", ",", "replay_length_list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.check_info": [[87, 97], ["print", "print", "print"], "function", ["None"], ["def", "check_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_actual", "\n", "player2_race", "=", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_actual", "\n", "\n", "print", "(", "'map_name:'", ",", "map_name", ")", "\n", "print", "(", "'player1_race:'", ",", "player1_race", ")", "\n", "print", "(", "'player2_race:'", ",", "player2_race", ")", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.store_info": [[99, 122], ["None"], "function", ["None"], ["", "def", "store_info", "(", "replay_info", ")", ":", "\n", "    ", "map_name", "=", "replay_info", ".", "map_name", "\n", "player1_race", "=", "RACE", "[", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_info", ".", "race_requested", "-", "1", "]", "\n", "player2_race", "=", "RACE", "[", "replay_info", ".", "player_info", "[", "1", "]", ".", "player_info", ".", "race_requested", "-", "1", "]", "\n", "game_duration_loops", "=", "replay_info", ".", "game_duration_loops", "\n", "game_duration_seconds", "=", "replay_info", ".", "game_duration_seconds", "\n", "game_version", "=", "replay_info", ".", "game_version", "\n", "game_result", "=", "RESULT", "[", "replay_info", ".", "player_info", "[", "0", "]", ".", "player_result", ".", "result", "-", "1", "]", "\n", "return", "[", "map_name", ",", "\n", "game_version", ",", "\n", "game_result", ",", "\n", "player1_race", ",", "\n", "player2_race", ",", "\n", "game_duration_loops", ",", "\n", "game_duration_seconds", "]", "\n", "\n", "'''\n    a = agent.action_by_obs(obs)\n    print(\"a:\", a) if debug else None\n    print(\"predict func:\", A.RAW_FUNCTIONS[a.action_type]) if debug else None\n    func_id = a.action_type\n    print(\"feat action spec functions:\", feat.action_spec().functions[func_id]) if debug else None\n    '''", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFeatureAndLabel": [[124, 140], ["agent.state_by_obs", "alphastarmini.core.sl.feature.Feature.state2feature", "agent.func_call_to_action", "agent.func_call_to_action.toLogits", "alphastarmini.core.sl.label.Label.action2label", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.state_by_obs", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label"], ["", "def", "getFeatureAndLabel", "(", "obs", ",", "func_call", ",", "agent", ")", ":", "\n", "    ", "print", "(", "\"begin s:\"", ")", "if", "debug", "else", "None", "\n", "s", ",", "tag_list", "=", "agent", ".", "state_by_obs", "(", "obs", ",", "return_tag_list", "=", "True", ")", "\n", "feature", "=", "Feature", ".", "state2feature", "(", "s", ")", "\n", "print", "(", "\"feature:\"", ",", "feature", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature.shape:\"", ",", "feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"begin a:\"", ")", "if", "debug", "else", "None", "\n", "action", "=", "agent", ".", "func_call_to_action", "(", "func_call", ",", "obs", "=", "obs", ")", "\n", "# tag_list = agent.get_tag_list(obs)", "\n", "a", "=", "action", ".", "toLogits", "(", "tag_list", ")", "\n", "label", "=", "Label", ".", "action2label", "(", "a", ")", "\n", "print", "(", "\"label:\"", ",", "label", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"label.shape:\"", ",", "label", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "feature", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getObsAndFunc": [[142, 225], ["numpy.array", "numpy.array", "bool_bo.astype.astype", "bool_bu.astype.astype", "print", "print", "numpy.random.rand", "numpy.random.rand", "print", "print", "print", "print", "print", "sum"], "function", ["None"], ["", "def", "getObsAndFunc", "(", "obs", ",", "func_call", ",", "agent", ",", "z", ")", ":", "\n", "# add z", "\n", "    ", "[", "bo", ",", "bu", "]", "=", "z", "\n", "\n", "# for build order has nothing, we make it be a list has only one item:", "\n", "# if len(bo) == 0:", "\n", "#    bo = [0]", "\n", "\n", "bo", "=", "np", ".", "array", "(", "bo", ")", "\n", "bu", "=", "np", ".", "array", "(", "bu", ")", "\n", "\n", "print", "(", "\"bo\"", ",", "bo", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"bu\"", ",", "bu", ")", "if", "debug", "else", "None", "\n", "\n", "# Extract build order and build units vectors from replay", "\n", "# bo = replay.get_BO(replay.home_player)", "\n", "# bu = replay.get_BU(replay.home_player)", "\n", "\n", "BO_PROBABILITY", "=", "0.8", "\n", "BU_PROBABILITY", "=", "0.5", "\n", "\n", "# Sample Boolean variables bool_BO and bool_BU", "\n", "# bool_bo = np.float(np.random.rand(*bo.shape) < BO_PROBABILITY)", "\n", "# bool_bu = np.float(np.random.rand(*bu.shape) < BU_PROBABILITY)", "\n", "\n", "bool_bo", "=", "np", ".", "random", ".", "rand", "(", "*", "bo", ".", "shape", ")", "<", "BO_PROBABILITY", "\n", "bool_bu", "=", "np", ".", "random", ".", "rand", "(", "*", "bu", ".", "shape", ")", "<", "BU_PROBABILITY", "\n", "\n", "bool_bo", "=", "bool_bo", ".", "astype", "(", "'float32'", ")", "\n", "bool_bu", "=", "bool_bu", ".", "astype", "(", "'float32'", ")", "\n", "\n", "print", "(", "\"bool_bo\"", ",", "bool_bo", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"bool_bu\"", ",", "bool_bu", ")", "if", "debug", "else", "None", "\n", "\n", "# Generate masked build order and build units", "\n", "masked_bo", "=", "bool_bo", "*", "bo", "\n", "masked_bu", "=", "bool_bu", "*", "bu", "\n", "\n", "print", "(", "\"masked_bo\"", ",", "masked_bo", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"masked_bu\"", ",", "masked_bu", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"sum(masked_bu)\"", ",", "sum", "(", "masked_bu", ")", ")", "if", "debug", "else", "None", "\n", "\n", "last_actions", "=", "obs", "[", "\"last_actions\"", "]", "\n", "upgrades", "=", "obs", "[", "\"upgrades\"", "]", "\n", "unit_counts", "=", "obs", "[", "\"unit_counts\"", "]", "\n", "feature_effects", "=", "obs", "[", "\"feature_effects\"", "]", "\n", "raw_effects", "=", "obs", "[", "\"raw_effects\"", "]", "\n", "\n", "feature_minimap", "=", "obs", "[", "\"feature_minimap\"", "]", "\n", "\n", "height_map", "=", "feature_minimap", "[", "\"height_map\"", "]", "\n", "visibility_map", "=", "feature_minimap", "[", "\"visibility_map\"", "]", "\n", "creep", "=", "feature_minimap", "[", "\"creep\"", "]", "\n", "player_relative", "=", "feature_minimap", "[", "\"player_relative\"", "]", "\n", "alerts", "=", "feature_minimap", "[", "\"alerts\"", "]", "\n", "pathable", "=", "feature_minimap", "[", "\"pathable\"", "]", "\n", "buildable", "=", "feature_minimap", "[", "\"buildable\"", "]", "\n", "\n", "step_dict", "=", "{", "'raw_units'", ":", "obs", "[", "\"raw_units\"", "]", "[", ":", "AHP", ".", "max_entities", "]", ",", "\n", "'player'", ":", "obs", "[", "\"player\"", "]", ",", "\n", "\n", "'last_actions'", ":", "last_actions", ",", "\n", "'upgrades'", ":", "upgrades", ",", "\n", "'unit_counts'", ":", "unit_counts", ",", "\n", "'feature_effects'", ":", "feature_effects", ",", "\n", "'raw_effects'", ":", "raw_effects", ",", "\n", "\n", "'height_map'", ":", "height_map", ",", "\n", "'visibility_map'", ":", "visibility_map", ",", "\n", "'creep'", ":", "creep", ",", "\n", "'player_relative'", ":", "player_relative", ",", "\n", "'alerts'", ":", "alerts", ",", "\n", "'pathable'", ":", "pathable", ",", "\n", "'buildable'", ":", "buildable", ",", "\n", "\n", "'game_loop'", ":", "obs", "[", "\"game_loop\"", "]", ",", "\n", "\n", "'masked_bo'", ":", "masked_bo", ",", "\n", "'masked_bu'", ":", "masked_bu", ",", "\n", "\n", "'func_call'", ":", "func_call", "}", "\n", "\n", "return", "step_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFuncCall": [[227, 286], ["feat.reverse_raw_action", "feat.reverse_action", "ValueError", "print", "action.HasField", "print", "enumerate", "raw_act.HasField", "pysc2.lib.units.Protoss", "transform_replay_data.getFuncCall.find_tag_position"], "function", ["None"], ["", "def", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ",", "use_raw", "=", "True", ")", ":", "\n", "    ", "func_call", "=", "None", "\n", "\n", "if", "use_raw", ":", "\n", "        ", "if", "prev_obs", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"use raw function call must input prev_obs\"", ")", "\n", "\n", "", "raw_func_call", "=", "feat", ".", "reverse_raw_action", "(", "o", ".", "actions", "[", "0", "]", ",", "prev_obs", ")", "\n", "\n", "if", "raw_func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "# no op", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "168", ":", "\n", "# camera move", "\n", "            ", "pass", "\n", "", "elif", "raw_func_call", ".", "function", ".", "value", "==", "1", ":", "\n", "# smart screen", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "print", "(", "'expert raw func_call: '", ",", "raw_func_call", ")", "if", "debug", "else", "None", "\n", "action", "=", "o", ".", "actions", "[", "0", "]", "\n", "\n", "raw_tags", "=", "prev_obs", "[", "\"raw_units\"", "]", "[", ":", ",", "29", "]", "# 29 is FeatureUnit.tag", "\n", "raw_unit_type", "=", "prev_obs", "[", "\"raw_units\"", "]", "[", ":", ",", "0", "]", "# 0 is FeatureUnit.unit_type", "\n", "\n", "#print('raw_tags:', raw_tags)", "\n", "#print('len(raw_tags):', len(raw_tags))", "\n", "\n", "def", "find_tag_position", "(", "original_tag", ")", ":", "\n", "                ", "for", "i", ",", "tag", "in", "enumerate", "(", "raw_tags", ")", ":", "\n", "                    ", "if", "tag", "==", "original_tag", ":", "\n", "                        ", "return", "i", "\n", "#logging.warning(\"Not found tag! %s\", original_tag)", "\n", "", "", "return", "-", "1", "\n", "\n", "", "if", "action", ".", "HasField", "(", "\"action_raw\"", ")", ":", "\n", "                ", "raw_act", "=", "action", ".", "action_raw", "\n", "if", "raw_act", ".", "HasField", "(", "\"unit_command\"", ")", ":", "\n", "                    ", "uc", "=", "raw_act", ".", "unit_command", "\n", "ability_id", "=", "uc", ".", "ability_id", "\n", "queue_command", "=", "uc", ".", "queue_command", "\n", "unit_tags", "=", "(", "find_tag_position", "(", "t", ")", "for", "t", "in", "uc", ".", "unit_tags", ")", "\n", "unit_tags", "=", "[", "t", "for", "t", "in", "unit_tags", "if", "t", "!=", "-", "1", "]", "\n", "unit_index", "=", "unit_tags", "[", "0", "]", "\n", "print", "(", "'unit_index:'", ",", "unit_index", ")", "if", "debug", "else", "None", "\n", "print", "(", "'unit_tag:'", ",", "raw_tags", "[", "unit_index", "]", ")", "if", "debug", "else", "None", "\n", "unit_type_id", "=", "raw_unit_type", "[", "unit_index", "]", "\n", "unit_type_name", "=", "Unit", ".", "Protoss", "(", "unit_type_id", ")", "\n", "print", "(", "'Protoss unit_type:'", ",", "unit_type_name", ")", "if", "debug", "else", "None", "\n", "\n", "", "", "", "func_call", "=", "raw_func_call", "\n", "", "else", ":", "\n", "\n", "        ", "feat_func_call", "=", "feat", ".", "reverse_action", "(", "o", ".", "actions", "[", "0", "]", ")", "\n", "print", "(", "'expert feature func_call: '", ",", "feat_func_call", ")", "if", "1", "else", "None", "\n", "\n", "func_call", "=", "feat_func_call", "\n", "\n", "", "return", "func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.test": [[288, 515], ["pysc2.run_configs.get", "print", "os.listdir", "print", "os.listdir.sort", "pysc2.lib.point.Point", "pysc2.lib.point.Point", "s2clientprotocol.sc2api_pb2.InterfaceOptions", "point.Point.assign_to", "point.Point.assign_to", "alphastarmini.core.arch.agent.Agent", "print", "print", "print", "len", "run_configs.get.start", "tqdm.tqdm", "s2clientprotocol.sc2api_pb2.SpatialCameraSetup", "print", "run_configs.get.replay_data", "controller.replay_info", "s2clientprotocol.sc2api_pb2.RequestStartReplay", "controller.start_replay", "pysc2.lib.features.features_from_game_info", "print", "print", "replay_length_list.append", "noop_length_list.append", "print", "print", "print", "print", "print", "print", "controller.observe", "controller.step", "torch.cat", "torch.cat", "torch.save", "traceback.print_exc", "random.randint", "controller.game_info", "F.features_from_game_info.observation_spec", "F.features_from_game_info.action_spec", "F.features_from_game_info.transform_obs", "print", "print", "alphastarmini.lib.utils.calculate_build_order", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape().numpy().tolist", "print", "print", "traceback.print_exc", "replay_file.replace", "open", "pickle.dump", "print", "print", "transform_replay_data.getFuncCall", "traceback.print_exc", "replay_file.replace", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape().numpy", "sum", "print", "random.uniform", "pysc2.lib.actions.FunctionCall.init_with_validation", "transform_replay_data.getFeatureAndLabel", "feature_list.append", "label_list.append", "print", "transform_replay_data.getObsAndFunc", "alphastarmini.lib.utils.calculate_unit_counts_bow().reshape", "alphastarmini.lib.utils.calculate_unit_counts_bow"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_build_order", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFuncCall", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getFeatureAndLabel", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.transform_replay_data.getObsAndFunc", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow"], ["", "def", "test", "(", "on_server", "=", "False", ")", ":", "\n", "\n", "    ", "if", "on_server", ":", "\n", "        ", "REPLAY_PATH", "=", "\"/home/liuruoze/data4/mini-AlphaStar/data/filtered_replays_1/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "FLAGS", ".", "max_steps_of_replay", "\n", "max_replays", "=", "FLAGS", ".", "max_replays", "\n", "", "else", ":", "\n", "        ", "REPLAY_PATH", "=", "\"data/Replays/filtered_replays_1/\"", "\n", "COPY_PATH", "=", "None", "\n", "SAVE_PATH", "=", "\"./result.csv\"", "\n", "max_steps_of_replay", "=", "120", "*", "22.4", "# 60 * 60 * 22.4", "\n", "max_replays", "=", "5", "# 1", "\n", "\n", "", "run_config", "=", "run_configs", ".", "get", "(", "version", "=", "FLAGS", ".", "replay_version", ")", "\n", "print", "(", "'REPLAY_PATH:'", ",", "REPLAY_PATH", ")", "\n", "replay_files", "=", "os", ".", "listdir", "(", "REPLAY_PATH", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "replay_files", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "\n", "screen_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "screen_resolution", ",", "FLAGS", ".", "screen_resolution", ")", "\n", "minimap_resolution", "=", "point", ".", "Point", "(", "FLAGS", ".", "minimap_resolution", ",", "FLAGS", ".", "minimap_resolution", ")", "\n", "camera_width", "=", "24", "\n", "\n", "# By default raw actions select, act and revert the selection. This is useful", "\n", "# if you're playing simultaneously with the agent so it doesn't steal your", "\n", "# selection. This inflates APM (due to deselect) and makes the actions hard", "\n", "# to follow in a replay. Setting this to true will cause raw actions to do", "\n", "# select, act, but not revert the selection.", "\n", "raw_affects_selection", "=", "False", "\n", "\n", "# Changes the coordinates in raw.proto to be relative to the playable area.", "\n", "# The map_size and playable_area will be the diagonal of the real playable area.", "\n", "raw_crop_to_playable_area", "=", "False", "\n", "\n", "interface", "=", "sc_pb", ".", "InterfaceOptions", "(", "\n", "raw", "=", "True", ",", "\n", "score", "=", "True", ",", "\n", "# Omit to disable.", "\n", "feature_layer", "=", "sc_pb", ".", "SpatialCameraSetup", "(", "width", "=", "camera_width", ")", ",", "\n", "# Omit to disable.", "\n", "render", "=", "None", ",", "\n", "# By default cloaked units are completely hidden. This shows some details.", "\n", "show_cloaked", "=", "False", ",", "\n", "# By default burrowed units are completely hidden. This shows some details for those that produce a shadow.", "\n", "show_burrowed_shadows", "=", "False", ",", "\n", "# Return placeholder units (buildings to be constructed), both for raw and feature layers.", "\n", "show_placeholders", "=", "False", ",", "\n", "# see below", "\n", "raw_affects_selection", "=", "raw_affects_selection", ",", "\n", "# see below", "\n", "raw_crop_to_playable_area", "=", "raw_crop_to_playable_area", "\n", ")", "\n", "\n", "screen_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "resolution", ")", "\n", "minimap_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "minimap_resolution", ")", "\n", "\n", "agent", "=", "Agent", "(", ")", "\n", "j", "=", "0", "\n", "replay_length_list", "=", "[", "]", "\n", "noop_length_list", "=", "[", "]", "\n", "with", "run_config", ".", "start", "(", "full_screen", "=", "False", ")", "as", "controller", ":", "\n", "\n", "        ", "for", "replay_file", "in", "tqdm", "(", "replay_files", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "replay_path", "=", "REPLAY_PATH", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "\n", "replay_data", "=", "run_config", ".", "replay_data", "(", "replay_path", ")", "\n", "replay_info", "=", "controller", ".", "replay_info", "(", "replay_data", ")", "\n", "\n", "start_replay", "=", "sc_pb", ".", "RequestStartReplay", "(", "\n", "replay_data", "=", "replay_data", ",", "\n", "options", "=", "interface", ",", "\n", "disable_fog", "=", "False", ",", "# FLAGS.disable_fog", "\n", "observed_player_id", "=", "random", ".", "randint", "(", "1", ",", "2", ")", ",", "# 1 or 2, wo random select it. FLAGS.observed_player", "\n", "map_data", "=", "None", ",", "\n", "realtime", "=", "False", "\n", ")", "\n", "\n", "print", "(", "\" Replay info \"", ".", "center", "(", "60", ",", "\"-\"", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "replay_info", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"-\"", "*", "60", ")", "if", "debug", "else", "None", "\n", "controller", ".", "start_replay", "(", "start_replay", ")", "\n", "# The below several arguments are default set to False, so we shall enable them.", "\n", "\n", "# use_feature_units: Whether to include feature_unit observations.", "\n", "\n", "# use_raw_units: Whether to include raw unit data in observations. This", "\n", "# differs from feature_units because it includes units outside the", "\n", "# screen and hidden units, and because unit positions are given in", "\n", "# terms of world units instead of screen units.", "\n", "\n", "# use_raw_actions: [bool] Whether to use raw actions as the interface.", "\n", "# Same as specifying action_space=ActionSpace.RAW.", "\n", "\n", "# use_unit_counts: Whether to include unit_counts observation. Disabled by", "\n", "# default since it gives information outside the visible area. ", "\n", "\n", "'''\n                show_cloaked: Whether to show limited information for cloaked units.\n                show_burrowed_shadows: Whether to show limited information for burrowed\n                      units that leave a shadow on the ground (ie widow mines and moving\n                      roaches and infestors).\n                show_placeholders: Whether to show buildings that are queued for\n                      construction.\n                '''", "\n", "\n", "feat", "=", "F", ".", "features_from_game_info", "(", "game_info", "=", "controller", ".", "game_info", "(", ")", ",", "\n", "use_feature_units", "=", "True", ",", "use_raw_units", "=", "True", ",", "\n", "use_unit_counts", "=", "True", ",", "use_raw_actions", "=", "True", ",", "\n", "show_cloaked", "=", "True", ",", "show_burrowed_shadows", "=", "True", ",", "\n", "show_placeholders", "=", "True", ")", "\n", "print", "(", "\"feat obs spec:\"", ",", "feat", ".", "observation_spec", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feat action spec:\"", ",", "feat", ".", "action_spec", "(", ")", ")", "if", "debug", "else", "None", "\n", "prev_obs", "=", "None", "\n", "i", "=", "0", "\n", "save_steps", "=", "0", "\n", "noop_count", "=", "0", "\n", "feature_list", ",", "label_list", "=", "[", "]", ",", "[", "]", "\n", "step_dict", "=", "{", "}", "\n", "\n", "# initial build order", "\n", "player_bo", "=", "[", "]", "\n", "player_ucb", "=", "[", "]", "\n", "\n", "while", "True", ":", "\n", "                    ", "o", "=", "controller", ".", "observe", "(", ")", "\n", "try", ":", "\n", "                        ", "obs", "=", "feat", ".", "transform_obs", "(", "o", ")", "\n", "\n", "if", "prev_obs", "is", "not", "None", ":", "\n", "# calculate the build order", "\n", "                            ", "player_bo", "=", "U", ".", "calculate_build_order", "(", "player_bo", ",", "prev_obs", ",", "obs", ")", "\n", "print", "(", "\"player build order:\"", ",", "player_bo", ")", "if", "debug", "else", "None", "\n", "\n", "# calculate the unit counts of bag", "\n", "player_ucb", "=", "U", ".", "calculate_unit_counts_bow", "(", "prev_obs", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "\"player unit count of bow:\"", ",", "sum", "(", "player_ucb", ")", ")", "if", "debug", "else", "None", "\n", "\n", "", "try", ":", "\n", "                            ", "func_call", "=", "None", "\n", "no_op", "=", "False", "\n", "if", "o", ".", "actions", "and", "prev_obs", ":", "\n", "                                ", "func_call", "=", "getFuncCall", "(", "o", ",", "feat", ",", "prev_obs", ")", "\n", "if", "func_call", ".", "function", ".", "value", "==", "0", ":", "\n", "                                    ", "no_op", "=", "True", "\n", "func_call", "=", "None", "\n", "", "", "else", ":", "\n", "                                ", "no_op", "=", "True", "\n", "\n", "", "if", "no_op", ":", "\n", "                                ", "print", "(", "'expert func: no op'", ")", "if", "debug", "else", "None", "\n", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "FLAGS", ".", "no_op_threshold", ":", "\n", "                                    ", "print", "(", "'get no op !'", ")", "if", "debug", "else", "None", "\n", "noop_count", "+=", "1", "\n", "func_call", "=", "A", ".", "FunctionCall", ".", "init_with_validation", "(", "\"no_op\"", ",", "[", "]", ",", "raw", "=", "True", ")", "\n", "\n", "", "", "if", "func_call", "is", "not", "None", ":", "\n", "                                ", "save_steps", "+=", "1", "\n", "z", "=", "[", "player_bo", ",", "player_ucb", "]", "\n", "\n", "if", "SAVE_TYPE", "==", "SaveType", ".", "torch_tensor", ":", "\n", "                                    ", "feature", ",", "label", "=", "getFeatureAndLabel", "(", "obs", ",", "func_call", ",", "agent", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "\n", "", "elif", "SAVE_TYPE", "==", "SaveType", ".", "python_pickle", ":", "\n", "                                    ", "the_dict", "=", "getObsAndFunc", "(", "obs", ",", "func_call", ",", "agent", ",", "z", ")", "\n", "step_dict", "[", "i", "]", "=", "the_dict", "\n", "\n", "", "elif", "SAVE_TYPE", "==", "SaveType", ".", "numpy_array", ":", "\n", "                                    ", "pass", "\n", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "                            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "i", ">=", "max_steps_of_replay", ":", "# test the first n frames", "\n", "                            ", "print", "(", "\"max frames test, break out!\"", ")", "\n", "break", "\n", "\n", "", "if", "o", ".", "player_result", ":", "# end of game", "\n", "                            ", "print", "(", "o", ".", "player_result", ")", "\n", "break", "\n", "\n", "", "", "except", "Exception", "as", "inst", ":", "\n", "                        ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "controller", ".", "step", "(", ")", "\n", "prev_obs", "=", "obs", "\n", "i", "+=", "1", "\n", "\n", "", "print", "(", "'begin save!'", ")", "\n", "\n", "if", "SAVE_TYPE", "==", "SaveType", ".", "torch_tensor", ":", "\n", "                    ", "features", "=", "torch", ".", "cat", "(", "feature_list", ",", "dim", "=", "0", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "label_list", ",", "dim", "=", "0", ")", "\n", "print", "(", "'features.shape:'", ",", "features", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'labels.shape:'", ",", "labels", ".", "shape", ")", "if", "debug", "else", "None", "\n", "m", "=", "{", "'features'", ":", "features", ",", "'labels'", ":", "labels", "}", "\n", "file_name", "=", "FLAGS", ".", "save_path", "+", "replay_file", ".", "replace", "(", "'.SC2Replay'", ",", "''", ")", "+", "'.pt'", "\n", "torch", ".", "save", "(", "m", ",", "file_name", ")", "\n", "\n", "", "elif", "SAVE_TYPE", "==", "SaveType", ".", "python_pickle", ":", "\n", "                    ", "file_name", "=", "FLAGS", ".", "save_path", "+", "replay_file", ".", "replace", "(", "'.SC2Replay'", ",", "''", ")", "+", "'.pickle'", "\n", "with", "open", "(", "file_name", ",", "'wb'", ")", "as", "handle", ":", "\n", "                        ", "pickle", ".", "dump", "(", "step_dict", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "", "elif", "SAVE_TYPE", "==", "SaveType", ".", "numpy_array", ":", "\n", "                    ", "pass", "\n", "\n", "", "print", "(", "'end save!'", ")", "\n", "\n", "j", "+=", "1", "\n", "replay_length_list", ".", "append", "(", "save_steps", ")", "\n", "noop_length_list", ".", "append", "(", "noop_count", ")", "\n", "# We only test the first one replay            ", "\n", "", "except", "Exception", "as", "inst", ":", "\n", "                ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "j", ">=", "max_replays", ":", "# test the first n frames", "\n", "                ", "print", "(", "\"max replays test, break out!\"", ")", "\n", "break", "\n", "\n", "", "", "", "print", "(", "\"end\"", ")", "\n", "print", "(", "\"replay_length_list:\"", ",", "replay_length_list", ")", "\n", "print", "(", "\"noop_length_list:\"", ",", "noop_length_list", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.OneReplayDataset.__init__": [[51, 61], ["torch.utils.data.Dataset.__init__", "list", "traj_dict.keys", "alphastarmini.core.arch.agent.Agent"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "traj_dict", ",", "agent", "=", "None", ",", "seq_length", "=", "AHP", ".", "sequence_length", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "traj_dict", "=", "traj_dict", "\n", "\n", "# if we use \"self.keys =traj_dict.keys()\", this will cause a shallow copy problem, refer", "\n", "# keys-objects-when-num-workers-0/43951/4", "\n", "self", ".", "keys", "=", "list", "(", "traj_dict", ".", "keys", "(", ")", ")", "\n", "self", ".", "seq_len", "=", "seq_length", "\n", "self", ".", "agent", "=", "agent", "if", "agent", "is", "not", "None", "else", "Agent", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.OneReplayDataset.__getitem__": [[62, 88], ["torch.cat", "torch.cat", "torch.zeros", "torch.cat", "dataset_pickle.obs2feature", "feature_list.append", "label_list.append", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.obs2feature"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "key_list", "=", "self", ".", "keys", "[", "index", ":", "index", "+", "self", ".", "seq_len", "]", "\n", "feature_list", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "obs_list", "=", "[", "]", "\n", "\n", "for", "key", "in", "key_list", ":", "\n", "            ", "obs", "=", "self", ".", "traj_dict", "[", "key", "]", "\n", "\n", "feature", ",", "label", "=", "obs2feature", "(", "obs", ",", "self", ".", "agent", ")", "\n", "feature_list", ".", "append", "(", "feature", ")", "\n", "label_list", ".", "append", "(", "label", ")", "\n", "\n", "", "features", "=", "torch", ".", "cat", "(", "feature_list", ",", "dim", "=", "0", ")", "\n", "print", "(", "\"features.shape:\"", ",", "features", ".", "shape", ")", "if", "0", "else", "None", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "label_list", ",", "dim", "=", "0", ")", "\n", "print", "(", "\"labels.shape:\"", ",", "labels", ".", "shape", ")", "if", "0", "else", "None", "\n", "\n", "is_final", "=", "torch", ".", "zeros", "(", "[", "features", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "\n", "one_traj", "=", "torch", ".", "cat", "(", "[", "features", ",", "labels", ",", "is_final", "]", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"one_traj.shape:\"", ",", "one_traj", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "one_traj", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.OneReplayDataset.__len__": [[89, 91], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "keys", ")", "-", "self", ".", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.__init__": [[95, 98], ["torch.utils.data.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "traj_loader_list", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "traj_loader_list", "=", "traj_loader_list", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset._get_random_trajectory": [[99, 107], ["next", "iter"], "methods", ["None"], ["", "def", "_get_random_trajectory", "(", "self", ",", "index", ")", ":", "\n", "        ", "traj_loader", "=", "self", ".", "traj_loader_list", "[", "index", "]", "\n", "\n", "# note: don't use \"for traj in traj_loader\" which is too slow", "\n", "# we only need one item from traj_loader now", "\n", "the_item", "=", "next", "(", "iter", "(", "traj_loader", ")", ")", "\n", "\n", "return", "the_item", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.__getitem__": [[108, 115], ["dataset_pickle.AllReplayDataset._get_random_trajectory", "replay.squeeze.squeeze.squeeze", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset._get_random_trajectory"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "replay", "=", "self", ".", "_get_random_trajectory", "(", "index", ")", "\n", "print", "(", "'replay.shape:'", ",", "replay", ".", "shape", ")", "if", "0", "else", "None", "\n", "replay", "=", "replay", ".", "squeeze", "(", "0", ")", "\n", "print", "(", "'replay.shape:'", ",", "replay", ".", "shape", ")", "if", "0", "else", "None", "\n", "\n", "return", "replay", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.__len__": [[116, 118], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "traj_loader_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_trainable_data": [[119, 147], ["os.listdir", "print", "os.listdir.sort", "enumerate", "len", "random.shuffle", "tqdm.tqdm.tqdm", "print", "open", "pickle.load", "dataset_pickle.OneReplayDataset", "torch.utils.data.DataLoader", "traj_loader_list.append", "traceback.print_exc"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_trainable_data", "(", "replay_data_path", ",", "agent", "=", "None", ",", "max_file_size", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "replay_files", "=", "os", ".", "listdir", "(", "replay_data_path", ")", "\n", "print", "(", "'length of replay_files:'", ",", "len", "(", "replay_files", ")", ")", "\n", "\n", "replay_files", ".", "sort", "(", ")", "\n", "if", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "replay_files", ")", "\n", "\n", "", "traj_loader_list", "=", "[", "]", "\n", "for", "i", ",", "replay_file", "in", "enumerate", "(", "tqdm", "(", "replay_files", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "max_file_size", "is", "not", "None", ":", "\n", "                    ", "if", "i", ">=", "max_file_size", ":", "\n", "                        ", "break", "\n", "\n", "", "", "replay_path", "=", "replay_data_path", "+", "replay_file", "\n", "print", "(", "'replay_path:'", ",", "replay_path", ")", "if", "debug", "else", "None", "\n", "\n", "with", "open", "(", "replay_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "                    ", "traj_dict", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "traj_dataset", "=", "OneReplayDataset", "(", "traj_dict", "=", "traj_dict", ",", "agent", "=", "agent", ")", "\n", "traj_loader", "=", "DataLoader", "(", "traj_dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ")", "\n", "traj_loader_list", ".", "append", "(", "traj_loader", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "traceback", ".", "print_exc", "(", ")", "\n", "", "", "return", "traj_loader_list", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_data": [[148, 153], ["int", "print", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "print", "(", "'training_size:'", ",", "training_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_val_data": [[154, 162], ["int", "int", "print", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_val_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "if", "val_size", "==", "0", "and", "len", "(", "trajs", ")", ">=", "5", ":", "\n", "            ", "val_size", "=", "1", "\n", "", "print", "(", "'val_size:'", ",", "val_size", ")", "\n", "return", "trajs", "[", "-", "val_size", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_test_data": [[163, 170], ["int", "int", "int", "print", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_test_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "test_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "test", ")", "\n", "print", "(", "'test_size:'", ",", "test_size", ")", "\n", "return", "trajs", "[", "-", "test_size", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_for_val_data": [[171, 178], ["int", "print", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_val_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "if", "training_size", "==", "0", "and", "len", "(", "trajs", ")", "==", "1", ":", "\n", "            ", "training_size", "=", "1", "\n", "", "print", "(", "'training_size:'", ",", "training_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_for_test_data": [[179, 185], ["int", "int", "print", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_test_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "print", "(", "'training_for_test_size:'", ",", "training_size", "+", "val_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "+", "val_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_for_deploy_data": [[186, 193], ["int", "int", "int", "print", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_training_for_deploy_data", "(", "trajs", ")", ":", "\n", "        ", "training_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "training", ")", "\n", "val_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "val", ")", "\n", "test_size", "=", "int", "(", "len", "(", "trajs", ")", "*", "DATASET_SPLIT_RATIO", ".", "test", ")", "\n", "print", "(", "'training_for_deploy_size:'", ",", "training_size", "+", "val_size", "+", "test_size", ")", "\n", "return", "trajs", "[", "0", ":", "training_size", "+", "val_size", "+", "test_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.obs2feature": [[29, 47], ["agent.get_state_and_action_from_pickle", "alphastarmini.core.sl.feature.Feature.state2feature", "agent.func_call_to_action().toTenser", "agent.func_call_to_action().toTenser.toLogits", "alphastarmini.core.sl.label.Label.action2label", "print", "print", "print", "print", "print", "print", "print", "agent.func_call_to_action", "agent.func_call_to_action().toTenser.get_shape"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_state_and_action_from_pickle", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.state2feature", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toTenser", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.label.Label.action2label", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape"], ["def", "obs2feature", "(", "obs", ",", "agent", ")", ":", "\n", "    ", "s", "=", "agent", ".", "get_state_and_action_from_pickle", "(", "obs", ")", "\n", "feature", "=", "Feature", ".", "state2feature", "(", "s", ")", "\n", "print", "(", "\"feature:\"", ",", "feature", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"feature.shape:\"", ",", "feature", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"begin a:\"", ")", "if", "debug", "else", "None", "\n", "func_call", "=", "obs", "[", "'func_call'", "]", "\n", "action", "=", "agent", ".", "func_call_to_action", "(", "func_call", ")", ".", "toTenser", "(", ")", "\n", "#tag_list = agent.get_tag_list(obs)", "\n", "print", "(", "'action.get_shape:'", ",", "action", ".", "get_shape", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "logits", "=", "action", ".", "toLogits", "(", ")", "\n", "print", "(", "'logits.shape:'", ",", "logits", ")", "if", "debug", "else", "None", "\n", "label", "=", "Label", ".", "action2label", "(", "logits", ")", "\n", "print", "(", "\"label:\"", ",", "label", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"label.shape:\"", ",", "label", ".", "shape", ")", "if", "debug", "else", "None", "\n", "return", "feature", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.test": [[195, 197], ["None"], "function", ["None"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.train_for_val": [[93, 189], ["datetime.datetime.now", "tensorboardX.SummaryWriter", "alphastarmini.core.sl.dataset_pickle.AllReplayDataset.get_training_for_val_data", "alphastarmini.core.sl.dataset_pickle.AllReplayDataset.get_val_data", "alphastarmini.core.sl.dataset_pickle.AllReplayDataset", "alphastarmini.core.sl.dataset_pickle.AllReplayDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "agent.model.to", "torch.optim.Adam", "range", "alphastarmini.lib.utils.load_latest_model", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "agent.model.parameters", "agent.model.train", "range", "sl_train_by_pickle.eval", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "torch.save", "torch.save", "datetime.now.strftime", "next", "traj.to().float.to().float", "alphastarmini.core.sl.sl_loss.get_sl_loss", "torch.optim.Adam.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "loss.item", "print", "tensorboardX.SummaryWriter.add_scalar", "traj.to().float.clone().detach", "iter", "print", "loss.item", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "tensorboardX.SummaryWriter.add_scalar", "traj.to().float.to", "print", "agent.model.parameters", "loss.item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "traj.to().float.clone", "torch.equal", "torch.equal", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item", "loss_list[].item"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_training_for_val_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_val_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.load_latest_model", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.eval", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_loss.get_sl_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["def", "train_for_val", "(", "replays", ",", "replay_data", ",", "agent", ")", ":", "\n", "    ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "summary_path", "=", "\"./log/\"", "+", "now", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "+", "\"/\"", "\n", "writer", "=", "SummaryWriter", "(", "summary_path", ")", "\n", "\n", "train_replays", "=", "AllReplayDataset", ".", "get_training_for_val_data", "(", "replays", ")", "\n", "val_replays", "=", "AllReplayDataset", ".", "get_val_data", "(", "replays", ")", "\n", "\n", "train_set", "=", "AllReplayDataset", "(", "train_replays", ")", "\n", "val_set", "=", "AllReplayDataset", "(", "val_replays", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "BATCH_SIZE", ",", "shuffle", "=", "True", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_set", ",", "batch_size", "=", "BATCH_SIZE", ",", "shuffle", "=", "False", ")", "\n", "\n", "if", "RESTORE", ":", "\n", "        ", "agent", ".", "model", "=", "load_latest_model", "(", "model_type", "=", "MODEL", ",", "path", "=", "MODEL_PATH", ")", "\n", "\n", "", "print", "(", "'torch.cuda.device_count():'", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "        ", "pass", "\n", "# print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")", "\n", "# dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs", "\n", "# agent.model = nn.DataParallel(agent.model)", "\n", "\n", "", "agent", ".", "model", ".", "to", "(", "DEVICE", ")", "\n", "# agent.model.cuda()", "\n", "\n", "optimizer", "=", "Adam", "(", "agent", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "LEARNING_RATE", ",", "weight_decay", "=", "WEIGHT_DECAY", ")", "\n", "\n", "train_loss", "=", "0", "\n", "batch_iter", "=", "0", "\n", "for", "epoch", "in", "range", "(", "NUM_EPOCHS", ")", ":", "\n", "        ", "agent", ".", "model", ".", "train", "(", ")", "\n", "\n", "loss_sum", "=", "0.0", "\n", "i", "=", "0", "\n", "last_traj", "=", "None", "\n", "\n", "for", "j", "in", "range", "(", "NUM_ITERS", ")", ":", "\n", "            ", "traj", "=", "next", "(", "iter", "(", "train_loader", ")", ")", "\n", "\n", "print", "(", "'traj.shape:'", ",", "traj", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "traj", "=", "traj", ".", "to", "(", "DEVICE", ")", ".", "float", "(", ")", "\n", "\n", "if", "last_traj", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"traj == last_traj ?\"", ",", "torch", ".", "equal", "(", "traj", ",", "last_traj", ")", ")", "if", "debug", "else", "None", "\n", "\n", "# with torch.autograd.detect_anomaly():", "\n", "", "loss", ",", "loss_list", "=", "Loss", ".", "get_sl_loss", "(", "traj", ",", "agent", ".", "model", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "# note, we don't need retain_graph=True if we set hidden_state.detach()", "\n", "\n", "# add a grad clip", "\n", "parameters", "=", "[", "p", "for", "p", "in", "agent", ".", "model", ".", "parameters", "(", ")", "if", "p", "is", "not", "None", "and", "p", ".", "requires_grad", "]", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "parameters", ",", "CLIP", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "loss_sum", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "print", "(", "\"One batch loss: {:.6f}.\"", ".", "format", "(", "loss", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/Loss'", ",", "loss", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "if", "True", ":", "\n", "                ", "print", "(", "\"One batch action_type_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "0", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/action_type_loss'", ",", "loss_list", "[", "0", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch delay_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "1", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/delay_loss'", ",", "loss_list", "[", "1", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch queue_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "2", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/queue_loss'", ",", "loss_list", "[", "2", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch units_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "3", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/units_loss'", ",", "loss_list", "[", "3", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch target_unit_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "4", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/target_unit_loss'", ",", "loss_list", "[", "4", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch target_location_loss loss: {:.6f}.\"", ".", "format", "(", "loss_list", "[", "5", "]", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/target_location_loss'", ",", "loss_list", "[", "5", "]", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "", "last_traj", "=", "traj", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "i", "+=", "1", "\n", "batch_iter", "+=", "1", "\n", "\n", "", "train_loss", "=", "loss_sum", "/", "(", "i", "+", "1e-9", ")", "\n", "val_loss", "=", "eval", "(", "agent", ",", "val_loader", ")", "\n", "\n", "print", "(", "\"Train loss: {:.6f}.\"", ".", "format", "(", "train_loss", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Loss'", ",", "train_loss", ",", "epoch", ")", "\n", "print", "(", "\"Val loss: {:.6f}.\"", ".", "format", "(", "val_loss", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'Val/Loss'", ",", "val_loss", ",", "epoch", ")", "\n", "\n", "print", "(", "\"beign to save model in \"", "+", "SAVE_PATH", ")", "\n", "torch", ".", "save", "(", "agent", ".", "model", ",", "SAVE_PATH", "+", "\"\"", "+", "\".pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.eval": [[191, 205], ["agent.model.eval", "traj.to().float.to().float", "alphastarmini.core.sl.sl_loss.get_sl_loss", "loss.item", "traj.to().float.to"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.eval", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_loss.get_sl_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "", "def", "eval", "(", "agent", ",", "val_loader", ")", ":", "\n", "    ", "agent", ".", "model", ".", "eval", "(", ")", "\n", "\n", "loss_sum", "=", "0.0", "\n", "i", "=", "0", "\n", "for", "traj", "in", "val_loader", ":", "\n", "        ", "traj", "=", "traj", ".", "to", "(", "DEVICE", ")", ".", "float", "(", ")", "\n", "\n", "loss", ",", "_", "=", "Loss", ".", "get_sl_loss", "(", "traj", ",", "agent", ".", "model", ")", "\n", "loss_sum", "+=", "loss", ".", "item", "(", ")", "\n", "i", "+=", "1", "\n", "\n", "", "val_loss", "=", "loss_sum", "/", "(", "i", "+", "1e-9", ")", "\n", "return", "val_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.test": [[207, 231], ["alphastarmini.core.arch.agent.Agent", "alphastarmini.core.sl.dataset_pickle.AllReplayDataset.get_trainable_data", "sl_train_by_pickle.train_for_val", "train_for_test", "train_for_deploy", "sl_train_by_pickle.train_for_val"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.dataset_pickle.AllReplayDataset.get_trainable_data", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.train_for_val", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.sl_train_by_pickle.train_for_val"], ["", "def", "test", "(", "on_server", ")", ":", "\n", "# get all the data", "\n", "# Note: The feature here is actually feature+label", "\n", "\n", "    ", "agent", "=", "Agent", "(", ")", "\n", "\n", "replays", "=", "AllReplayDataset", ".", "get_trainable_data", "(", "replay_data_path", "=", "PATH", ",", "agent", "=", "agent", ",", "\n", "max_file_size", "=", "FILE_SIZE", ",", "shuffle", "=", "True", ")", "\n", "\n", "'''\n    for replay in replays:\n        print('replay', replay)\n        for tensor in replay:\n            print('tensor:', tensor)\n    '''", "\n", "\n", "if", "TYPE", "==", "'val'", ":", "\n", "        ", "train_for_val", "(", "replays", ",", "None", ",", "agent", ")", "# select the best hyper-parameters", "\n", "", "elif", "TYPE", "==", "'test'", ":", "\n", "        ", "train_for_test", "(", "replays", ",", "None", ",", "agent", ")", "# for test the performance in real life", "\n", "", "elif", "TYPE", "==", "'deploy'", ":", "\n", "        ", "train_for_deploy", "(", "replays", ",", "None", ",", "agent", ")", "# only used for production", "\n", "", "else", ":", "\n", "        ", "train_for_val", "(", "replays", ",", "None", ",", "agent", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.multi_node_training.synchronize": [[6, 19], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["None"], ["def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.Core.__init__": [[25, 36], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", "=", "AHP", ".", "original_1024", ",", "hidden_dim", "=", "AHP", ".", "lstm_hidden_dim", ",", "\n", "batch_size", "=", "AHP", ".", "batch_size", ",", "\n", "sequence_length", "=", "AHP", ".", "sequence_length", ",", "\n", "n_layers", "=", "AHP", ".", "lstm_layers", ",", "drop_prob", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "hidden_dim", ",", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "drop_prob", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.Core.forward": [[42, 95], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_tensor.reshape.reshape.reshape", "core.Core.forward_lstm", "lstm_output.reshape.reshape.reshape", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "core.Core.init_hidden_state", "print", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.Core.forward_lstm", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state"], ["", "def", "forward", "(", "self", ",", "embedded_scalar", ",", "embedded_entity", ",", "embedded_spatial", ",", "\n", "batch_size", "=", "None", ",", "sequence_length", "=", "None", ",", "hidden_state", "=", "None", ")", ":", "\n", "# note: the input_shape[0] is batch_seq_size, we only transfrom it to [batch_size, seq_size, ...]", "\n", "# before input it into the lstm", "\n", "# shapes of embedded_entity, embedded_spatial, embedded_scalar are all [batch_seq_size x embedded_size]", "\n", "        ", "print", "(", "'embedded_scalar.shape:'", ",", "embedded_scalar", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_entity.shape:'", ",", "embedded_entity", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_spatial.shape:'", ",", "embedded_spatial", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "batch_seq_size", "=", "embedded_scalar", ".", "shape", "[", "0", "]", "\n", "print", "(", "'batch_size:'", ",", "batch_size", ")", "if", "debug", "else", "None", "\n", "print", "(", "'self.batch_size:'", ",", "self", ".", "batch_size", ")", "if", "debug", "else", "None", "\n", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "self", ".", "batch_size", "\n", "sequence_length", "=", "sequence_length", "if", "sequence_length", "is", "not", "None", "else", "self", ".", "sequence_length", "\n", "\n", "print", "(", "'batch_seq_size:'", ",", "batch_seq_size", ")", "if", "debug", "else", "None", "\n", "print", "(", "'batch_size:'", ",", "batch_size", ")", "if", "debug", "else", "None", "\n", "print", "(", "'sequence_length:'", ",", "sequence_length", ")", "if", "debug", "else", "None", "\n", "\n", "assert", "batch_seq_size", "==", "batch_size", "*", "sequence_length", "\n", "assert", "batch_seq_size", "==", "embedded_entity", ".", "shape", "[", "0", "]", "\n", "assert", "batch_seq_size", "==", "embedded_spatial", ".", "shape", "[", "0", "]", "\n", "\n", "print", "(", "'embedded_scalar is nan:'", ",", "torch", ".", "isnan", "(", "embedded_scalar", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_entity is nan:'", ",", "torch", ".", "isnan", "(", "embedded_entity", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_spatial is nan:'", ",", "torch", ".", "isnan", "(", "embedded_spatial", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "input_tensor", "=", "torch", ".", "cat", "(", "[", "embedded_scalar", ",", "embedded_entity", ",", "embedded_spatial", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# note, before input to the LSTM", "\n", "# we transform the shape from [batch_seq_size, embedding_size] ", "\n", "# to the actual [batch_size, seq_size, embedding_size] ", "\n", "print", "(", "'input_tensor.shape:'", ",", "input_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "embedding_size", "=", "input_tensor", ".", "shape", "[", "-", "1", "]", "\n", "#input_tensor = input_tensor.unsqueeze(1)", "\n", "\n", "input_tensor", "=", "input_tensor", ".", "reshape", "(", "batch_size", ",", "sequence_length", ",", "embedding_size", ")", "\n", "print", "(", "'input_tensor.shape:'", ",", "input_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "'input_tensor is nan:'", ",", "torch", ".", "isnan", "(", "input_tensor", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "if", "hidden_state", "is", "None", ":", "\n", "            ", "hidden_state", "=", "self", ".", "init_hidden_state", "(", "batch_size", "=", "batch_size", ")", "\n", "\n", "", "lstm_output", ",", "hidden_state", "=", "self", ".", "forward_lstm", "(", "input_tensor", ",", "hidden_state", ")", "\n", "# lstm_output shape: [batch_size, seq_size, hidden_dim]", "\n", "print", "(", "'lstm_output.shape:'", ",", "lstm_output", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# note, after the LSTM", "\n", "# we transform the shape from [batch_size, seq_size, hidden_dim] ", "\n", "# to the actual [batch_seq_size, hidden_dim] ", "\n", "\n", "lstm_output", "=", "lstm_output", ".", "reshape", "(", "batch_size", "*", "sequence_length", ",", "self", ".", "hidden_dim", ")", "\n", "return", "lstm_output", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.Core.forward_lstm": [[96, 115], ["core.Core.lstm"], "methods", ["None"], ["", "def", "forward_lstm", "(", "self", ",", "x", ",", "hidden", ")", ":", "\n", "# note: No projection is used.", "\n", "# note: The outputs of the LSTM are the outputs of this module.", "\n", "        ", "lstm_out", ",", "hidden", "=", "self", ".", "lstm", "(", "x", ",", "hidden", ")", "\n", "\n", "# DIFF: We apply layer norm to the gates.", "\n", "\n", "'''\n        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n        \n        out = self.dropout(lstm_out)\n        out = self.fc(out)\n        out = self.sigmoid(out)\n        \n        out = out.view(batch_size, -1)\n        out = out[:,-1]\n        '''", "\n", "\n", "return", "lstm_out", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.Core.init_hidden_state": [[116, 126], ["next", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "core.Core.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "init_hidden_state", "(", "self", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "'''\n        weight = next(self.parameters()).data\n        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))        \n                  '''", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "hidden", "=", "(", "torch", ".", "zeros", "(", "self", ".", "n_layers", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ".", "to", "(", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "self", ".", "n_layers", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ".", "to", "(", "device", ")", ")", "\n", "return", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.core.test": [[128, 131], ["print"], "function", ["None"], ["", "", "def", "test", "(", ")", ":", "\n", "\n", "    ", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.__init__": [[46, 57], ["torch.Module.__init__", "alphastarmini.core.arch.scalar_encoder.ScalarEncoder", "alphastarmini.core.arch.entity_encoder.EntityEncoder", "alphastarmini.core.arch.spatial_encoder.SpatialEncoder", "alphastarmini.core.arch.core.Core", "alphastarmini.core.arch.action_type_head.ActionTypeHead", "alphastarmini.core.arch.selected_units_head.SelectedUnitsHead", "alphastarmini.core.arch.location_head.LocationHead", "arch_model.ArchModel.init_baselines"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.init_baselines"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ArchModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scalar_encoder", "=", "ScalarEncoder", "(", ")", "\n", "self", ".", "entity_encoder", "=", "EntityEncoder", "(", ")", "\n", "self", ".", "spatial_encoder", "=", "SpatialEncoder", "(", ")", "\n", "self", ".", "core", "=", "Core", "(", ")", "\n", "self", ".", "action_type_head", "=", "ActionTypeHead", "(", ")", "\n", "self", ".", "selected_units_head", "=", "SelectedUnitsHead", "(", ")", "\n", "self", ".", "location_head", "=", "LocationHead", "(", ")", "\n", "# init all baselines", "\n", "self", ".", "init_baselines", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.init_baselines": [[58, 60], ["alphastarmini.core.arch.baseline.Baseline"], "methods", ["None"], ["", "def", "init_baselines", "(", "self", ")", ":", "\n", "        ", "self", ".", "winloss_baseline", "=", "Baseline", "(", "baseline_type", "=", "'winloss'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.count_parameters": [[61, 63], ["sum", "p.numel", "arch_model.ArchModel.parameters"], "methods", ["None"], ["", "def", "count_parameters", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_entity": [[64, 66], ["arch_model.ArchModel.entity_encoder.preprocess"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess"], ["", "def", "preprocess_entity", "(", "self", ",", "e_list", ")", ":", "\n", "        ", "return", "self", ".", "entity_encoder", ".", "preprocess", "(", "e_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_spatial": [[67, 69], ["arch_model.ArchModel.spatial_encoder.preprocess"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess"], ["", "def", "preprocess_spatial", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "spatial_encoder", ".", "preprocess", "(", "obs", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_scalar": [[70, 72], ["arch_model.ArchModel.scalar_encoder.preprocess"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess"], ["", "def", "preprocess_scalar", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "scalar_encoder", ".", "preprocess", "(", "obs", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.init_hidden_state": [[73, 75], ["arch_model.ArchModel.core.init_hidden_state"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state"], ["", "def", "init_hidden_state", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "core", ".", "init_hidden_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.forward": [[76, 143], ["arch_model.ArchModel.entity_encoder", "arch_model.ArchModel.spatial_encoder", "arch_model.ArchModel.scalar_encoder", "arch_model.ArchModel.core", "arch_model.ArchModel.action_type_head", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "arch_model.ArchModel.location_head", "alphastarmini.core.rl.action.ArgsAction", "alphastarmini.core.rl.action.ArgsActionLogits", "print", "print", "print", "print", "arch_model.ArchModel.selected_units_head", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "arch_model.ArchModel.winloss_baseline.forward", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "def", "forward", "(", "self", ",", "state", ",", "batch_size", "=", "None", ",", "sequence_length", "=", "None", ",", "hidden_state", "=", "None", ",", "return_logits", "=", "False", ",", "\n", "baseline_state", "=", "None", ",", "baseline_opponent_state", "=", "None", ",", "return_baseline", "=", "False", ")", ":", "\n", "# shapes of embedded_entity, embedded_spatial, embedded_scalar are all [batch_size x embedded_size]", "\n", "        ", "entity_embeddings", ",", "embedded_entity", "=", "self", ".", "entity_encoder", "(", "state", ".", "entity_state", ")", "\n", "\n", "pos_index", "=", "SCHP", ".", "max_unit_type", "+", "AHP", ".", "entity_x_y_index", "# 13 + 1 + 5 + 5", "\n", "entity_x_y", "=", "state", ".", "entity_state", "[", ":", ",", ":", ",", "pos_index", ":", "pos_index", "+", "8", "*", "2", "]", "\n", "\n", "map_skip", ",", "embedded_spatial", "=", "self", ".", "spatial_encoder", "(", "state", ".", "map_state", ",", "entity_embeddings", ",", "entity_x_y", ")", "\n", "embedded_scalar", ",", "scalar_context", "=", "self", ".", "scalar_encoder", "(", "state", ".", "statistical_state", ")", "\n", "\n", "print", "(", "\"entity_embeddings.shape:\"", ",", "entity_embeddings", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "lstm_output", ",", "hidden_state", "=", "self", ".", "core", "(", "embedded_scalar", ",", "embedded_entity", ",", "embedded_spatial", ",", "\n", "batch_size", ",", "sequence_length", ",", "hidden_state", ")", "\n", "\n", "print", "(", "'lstm_output.shape:'", ",", "lstm_output", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'lstm_output is nan:'", ",", "torch", ".", "isnan", "(", "lstm_output", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "action_type_logits", ",", "action_type", ",", "autoregressive_embedding", "=", "self", ".", "action_type_head", "(", "lstm_output", ",", "scalar_context", ")", "\n", "print", "(", "\"action_type:\"", ",", "action_type", ")", "if", "debug", "else", "None", "\n", "\n", "#delay_logits, delay, autoregressive_embedding = self.delay_head(autoregressive_embedding)", "\n", "#queue_logits, queue, autoregressive_embedding = self.queue_head(autoregressive_embedding, action_type, embedded_entity)", "\n", "delay_logits", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "delay", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "queue_logits", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "queue", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "if", "P", ".", "use_raw_action", ":", "\n", "            ", "units_logits", ",", "units", ",", "autoregressive_embedding", "=", "self", ".", "selected_units_head", "(", "autoregressive_embedding", ",", "action_type", ",", "entity_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "units_logits", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "units", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "#target_unit_logits, target_unit = self.target_unit_head(autoregressive_embedding, action_type, entity_embeddings)", "\n", "", "target_unit_logits", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "target_unit", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "\n", "target_location_logits", ",", "target_location", "=", "self", ".", "location_head", "(", "autoregressive_embedding", ",", "action_type", ",", "map_skip", ")", "\n", "\n", "# return [action_type_logits, delay_logits, queue_logits, units_logits, target_unit_logits, target_location_logits], ", "\n", "#[action_type, delay, queue, units, target_unit, target_location]", "\n", "action", "=", "ArgsAction", "(", "action_type", "=", "action_type", ",", "delay", "=", "delay", ",", "queue", "=", "queue", ",", "\n", "units", "=", "units", ",", "target_unit", "=", "target_unit", ",", "target_location", "=", "target_location", ")", "\n", "action_logits", "=", "ArgsActionLogits", "(", "action_type", "=", "action_type_logits", ",", "delay", "=", "delay_logits", ",", "queue", "=", "queue_logits", ",", "\n", "units", "=", "units_logits", ",", "target_unit", "=", "target_unit_logits", ",", "\n", "target_location", "=", "target_location_logits", ")", "\n", "\n", "if", "return_logits", ":", "\n", "\n", "            ", "if", "return_baseline", ":", "\n", "                ", "winloss_baseline_value", "=", "self", ".", "winloss_baseline", ".", "forward", "(", "lstm_output", ",", "baseline_state", ",", "baseline_opponent_state", ")", "\n", "build_order_baseline_value", "=", "torch", ".", "zeros", "(", "1", ")", "# self.build_order_baseline.forward(lstm_output, baseline_state, baseline_opponent_state)", "\n", "built_units_baseline_value", "=", "torch", ".", "zeros", "(", "1", ")", "# self.built_units_baseline.forward(lstm_output, baseline_state, baseline_opponent_state)", "\n", "upgrades_baseline_value", "=", "torch", ".", "zeros", "(", "1", ")", "# self.upgrades_baseline.forward(lstm_output, baseline_state, baseline_opponent_state)", "\n", "effects_baseline_value", "=", "torch", ".", "zeros", "(", "1", ")", "# self.effects_baseline.forward(lstm_output, baseline_state, baseline_opponent_state)", "\n", "\n", "baseline_value_list", "=", "[", "winloss_baseline_value", ",", "build_order_baseline_value", ",", "built_units_baseline_value", ",", "\n", "upgrades_baseline_value", ",", "effects_baseline_value", "]", "\n", "\n", "return", "baseline_value_list", ",", "action_logits", ",", "action", ",", "hidden_state", "\n", "\n", "", "return", "action_logits", ",", "action", ",", "hidden_state", "\n", "\n", "", "return", "action", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.test": [[145, 319], ["arch_model.ArchModel", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "alphastarmini.core.arch.entity_encoder.Entity", "alphastarmini.core.arch.entity_encoder.Entity", "e_list.append", "e_list.append", "arch_model.ArchModel.preprocess_entity", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "range", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "alphastarmini.lib.utils.to_one_hot", "map_list.append", "torch.zeros", "torch.zeros", "torch.zeros", "map_list.append", "torch.cat", "torch.cat", "torch.cat", "alphastarmini.core.rl.state.MsState", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "arch_model.ArchModel.forward", "print", "torch.optim.Adam", "print", "print", "int", "print", "torch.cat.detach().clone", "batch_entities_list.append", "print", "print", "print", "int", "print", "print", "print", "ArchModel.parameters", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "range", "print", "print", "print", "print", "print", "print", "action.toLogits", "print", "arch_model.ArchModel.forward", "torch.optim.Adam.zero_grad", "sum", "loss.backward", "torch.optim.Adam.step", "print", "print", "action.get_shape", "arch_model.ArchModel.count_parameters", "torch.cat.detach", "print", "print", "print", "print", "action_logits.action_type.sum", "print", "h.detach", "c.detach", "base.sum"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_entity", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.count_parameters"], ["", "", "def", "test", "(", ")", ":", "\n", "# init model", "\n", "    ", "arch_model", "=", "ArchModel", "(", ")", "\n", "batch_size", "=", "AHP", ".", "batch_size", "*", "AHP", ".", "sequence_length", "\n", "# dummy scalar list", "\n", "scalar_list", "=", "[", "]", "\n", "\n", "agent_statistics", "=", "torch", ".", "ones", "(", "batch_size", ",", "SFS", ".", "agent_statistics", ")", "\n", "home_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "home_race", ")", "\n", "away_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "away_race", ")", "\n", "upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "enemy_upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "time", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "time", ")", "\n", "\n", "available_actions", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "available_actions", ")", "\n", "unit_counts_bow", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "mmr", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "mmr", ")", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "units_buildings", ")", "\n", "effects", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "effects", ")", "\n", "upgrade", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrade", ")", "\n", "\n", "beginning_build_order", "=", "torch", ".", "randn", "(", "batch_size", ",", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "last_delay", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_delay", ")", "\n", "last_action_type", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_action_type", ")", "\n", "last_repeat_queued", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_repeat_queued", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "home_race", ")", "\n", "scalar_list", ".", "append", "(", "away_race", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "enemy_upgrades", ")", "\n", "scalar_list", ".", "append", "(", "time", ")", "\n", "\n", "scalar_list", ".", "append", "(", "available_actions", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "mmr", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "scalar_list", ".", "append", "(", "last_delay", ")", "\n", "scalar_list", ".", "append", "(", "last_action_type", ")", "\n", "scalar_list", ".", "append", "(", "last_repeat_queued", ")", "\n", "\n", "# dummy entity list", "\n", "e_list", "=", "[", "]", "\n", "e1", "=", "Entity", "(", "115", ",", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "0", ",", "100", ",", "60", ",", "50", ",", "4", ",", "8", ",", "95", ",", "0.2", ",", "0.0", ",", "0.0", ",", "140", ",", "60", ",", "100", ",", "\n", "1", ",", "123", ",", "218", ",", "3", ",", "True", ",", "False", ",", "True", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "3.0", ",", "[", "2", ",", "3", "]", ",", "2", ",", "1", ",", "0", ",", "True", ",", "False", ")", "\n", "e2", "=", "Entity", "(", "1908", ",", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "2", ",", "1500", ",", "0", ",", "200", ",", "0", ",", "4", ",", "15", ",", "0.5", ",", "0.8", ",", "0.5", ",", "1500", ",", "0", ",", "250", ",", "\n", "2", ",", "69", ",", "7", ",", "3", ",", "True", ",", "False", ",", "False", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "10", ",", "16", ",", "0.0", ",", "[", "1", "]", ",", "1", ",", "1", ",", "0", ",", "False", ",", "False", ")", "\n", "e_list", ".", "append", "(", "e1", ")", "\n", "e_list", ".", "append", "(", "e2", ")", "\n", "\n", "# preprocess entity list", "\n", "entities_tensor", "=", "arch_model", ".", "preprocess_entity", "(", "e_list", ")", "\n", "print", "(", "'entities_tensor.shape:'", ",", "entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "batch_entities_tensor", "=", "torch", ".", "unsqueeze", "(", "entities_tensor", ",", "dim", "=", "0", ")", "\n", "batch_entities_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "batch_entities_tensor_copy", "=", "batch_entities_tensor", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "batch_entities_list", ".", "append", "(", "batch_entities_tensor_copy", ")", "\n", "\n", "", "batch_entities_tensor", "=", "torch", ".", "cat", "(", "batch_entities_list", ",", "dim", "=", "0", ")", "\n", "print", "(", "'batch_entities_tensor.shape:'", ",", "batch_entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# dummy map list", "\n", "map_list", "=", "[", "]", "\n", "map_data_1", "=", "torch", ".", "zeros", "(", "batch_size", ",", "1", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_data_1_one_hot", "=", "L", ".", "to_one_hot", "(", "map_data_1", ",", "2", ")", "\n", "print", "(", "'map_data_1_one_hot.shape:'", ",", "map_data_1_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "map_list", ".", "append", "(", "map_data_1", ")", "\n", "map_data_2", "=", "torch", ".", "zeros", "(", "batch_size", ",", "11", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_list", ".", "append", "(", "map_data_2", ")", "\n", "map_data", "=", "torch", ".", "cat", "(", "map_list", ",", "dim", "=", "1", ")", "\n", "\n", "state", "=", "MsState", "(", "entity_state", "=", "batch_entities_tensor", ",", "statistical_state", "=", "scalar_list", ",", "map_state", "=", "map_data", ")", "\n", "print", "(", "\"Multi-source state:\"", ",", "state", ")", "if", "debug", "else", "None", "\n", "\n", "# dummy scalar list", "\n", "scalar_list", "=", "[", "]", "\n", "\n", "agent_statistics", "=", "torch", ".", "ones", "(", "batch_size", ",", "SFS", ".", "agent_statistics", ")", "\n", "upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "unit_counts_bow", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "units_buildings", ")", "\n", "effects", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "effects", ")", "\n", "upgrade", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrade", ")", "\n", "beginning_build_order", "=", "torch", ".", "randn", "(", "batch_size", ",", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "\n", "opponenet_scalar_out", "=", "scalar_list", "\n", "\n", "action_logits", ",", "action", ",", "_", "=", "arch_model", ".", "forward", "(", "state", ",", "batch_size", "=", "AHP", ".", "batch_size", ",", "sequence_length", "=", "AHP", ".", "sequence_length", ",", "return_logits", "=", "True", ")", "\n", "\n", "if", "action", ".", "action_type", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"action:\"", ",", "action", ".", "action_type", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"action is None!\"", ")", "\n", "\n", "# test loss and backward", "\n", "", "print", "(", "\"Test backward!\"", ")", "\n", "print", "(", "\"action_logits.action_type:\"", ",", "action_logits", ".", "action_type", ")", "if", "debug", "else", "None", "\n", "\n", "# if MiniStar_Arch_Hyper_Parameters is used, and Mini_Scale = 16,", "\n", "# then batch_size = 96 / 16 = 6, sequence_length = 64 / 16 = 4, batch_seq_size = 6 * 4 = 24.", "\n", "# Thus shape = [24, number_of_action_types=564]", "\n", "print", "(", "\"action_logits.action_type.shape:\"", ",", "action_logits", ".", "action_type", ".", "shape", ")", "if", "1", "else", "None", "\n", "\n", "optimizer", "=", "Adam", "(", "arch_model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "with", "torch", ".", "autograd", ".", "set_detect_anomaly", "(", "True", ")", ":", "\n", "        ", "hidden_state", "=", "None", "\n", "\n", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "\n", "# important, if not set, below error will raise:", "\n", "# Trying to backward through the graph a second time, but the buffers have already ", "\n", "# been freed. Specify retain_graph=True when calling backward the first time", "\n", "            ", "if", "hidden_state", "is", "not", "None", ":", "\n", "                ", "(", "h", ",", "c", ")", "=", "hidden_state", "\n", "hidden_state", "=", "(", "h", ".", "detach", "(", ")", ",", "c", ".", "detach", "(", ")", ")", "\n", "\n", "", "baseline_value", ",", "action_logits", ",", "action", ",", "new_hidden_state", "=", "arch_model", ".", "forward", "(", "state", ",", "hidden_state", "=", "hidden_state", ",", "\n", "return_logits", "=", "True", ",", "baseline_state", "=", "scalar_list", ",", "\n", "baseline_opponent_state", "=", "opponenet_scalar_out", ",", "\n", "return_baseline", "=", "True", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "print", "(", "\"action_logits.action_type:\"", ",", "action_logits", ".", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_logits.action_type.shape:\"", ",", "action_logits", ".", "action_type", ".", "shape", ")", "if", "1", "else", "None", "\n", "\n", "print", "(", "\"baseline_value:\"", ",", "baseline_value", ")", "if", "debug", "else", "None", "\n", "#print(\"baseline_value.shape:\", baseline_value.shape) if 1 else None", "\n", "\n", "print", "(", "\"new_hidden_state.shape:\"", ",", "new_hidden_state", "[", "0", "]", ".", "shape", ")", "if", "1", "else", "None", "\n", "\n", "loss_base", "=", "sum", "(", "[", "base", ".", "sum", "(", ")", "for", "base", "in", "baseline_value", "]", ")", "\n", "\n", "loss", "=", "action_logits", ".", "action_type", ".", "sum", "(", ")", "+", "loss_base", "\n", "print", "(", "\"loss:\"", ",", "loss", ")", "if", "debug", "else", "None", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "hidden_state", "=", "new_hidden_state", "\n", "\n", "", "", "print", "(", "\"End test backward!\"", ")", "\n", "\n", "if", "action", ".", "target_unit", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_unit:\"", ",", "action", ".", "target_unit", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_unit is None!\"", ")", "\n", "\n", "", "if", "action", ".", "target_location", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_location:\"", ",", "action", ".", "target_location", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_location is None!\"", ")", "\n", "\n", "", "print", "(", "\"action is:\"", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action shape is:\"", ",", "action", ".", "get_shape", "(", ")", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"ArchModel parameters:\"", ",", "arch_model", ".", "count_parameters", "(", ")", ")", "if", "1", "else", "None", "\n", "\n", "print", "(", "\"action.toLogits():\"", ",", "action", ".", "toLogits", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.selected_units_head.SelectedUnitsHead.__init__": [[31, 68], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "embedding_size", "=", "AHP", ".", "entity_embedding_size", ",", "\n", "max_number_of_unit_types", "=", "SCHP", ".", "max_unit_type", ",", "is_sl_training", "=", "True", ",", "\n", "temperature", "=", "0.8", ",", "max_selected", "=", "AHP", ".", "max_selected", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "original_32", "=", "AHP", ".", "original_32", ",", "\n", "autoregressive_embedding_size", "=", "AHP", ".", "autoregressive_embedding_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_sl_training", "=", "is_sl_training", "\n", "if", "not", "self", ".", "is_sl_training", ":", "\n", "            ", "self", ".", "temperature", "=", "temperature", "\n", "", "else", ":", "\n", "            ", "self", ".", "temperature", "=", "1.0", "\n", "\n", "", "self", ".", "max_number_of_unit_types", "=", "max_number_of_unit_types", "\n", "self", ".", "func_embed", "=", "nn", ".", "Linear", "(", "max_number_of_unit_types", ",", "original_256", ")", "# with relu", "\n", "\n", "self", ".", "conv_1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "embedding_size", ",", "\n", "out_channels", "=", "original_32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "autoregressive_embedding_size", ",", "original_256", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_32", ")", "\n", "\n", "self", ".", "small_lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "original_32", ",", "hidden_size", "=", "original_32", ",", "num_layers", "=", "1", ",", "\n", "dropout", "=", "0.0", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "max_selected", "=", "max_selected", "\n", "\n", "self", ".", "max_entities", "=", "AHP", ".", "max_entities", "\n", "\n", "self", ".", "fc_3", "=", "nn", ".", "Linear", "(", "autoregressive_embedding_size", ",", "self", ".", "max_entities", ")", "\n", "\n", "# self.fc_4 = nn.Linear(autoregressive_embedding_size, original_32)", "\n", "# self.layer_norm_k = nn.LayerNorm([self.max_entities, original_32], eps=1e-09, elementwise_affine=False)", "\n", "# self.layer_norm_q = nn.LayerNorm(original_32, eps=1e-09, elementwise_affine=False)", "\n", "\n", "self", ".", "project", "=", "nn", ".", "Linear", "(", "original_32", ",", "autoregressive_embedding_size", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.selected_units_head.SelectedUnitsHead.preprocess": [[69, 71], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.selected_units_head.SelectedUnitsHead.forward": [[72, 207], ["alphastarmini.lib.utils.action_can_apply_to_entity_types_mask", "unit_types_one_hot.to.to.to", "torch.relu", "torch.relu", "torch.relu", "selected_units_head.SelectedUnitsHead.conv_1().transpose", "alphastarmini.lib.utils.action_involve_selecting_units_mask", "selected_units_head.SelectedUnitsHead.fc_3", "selected_units_head.SelectedUnitsHead.div", "selected_units_head.SelectedUnitsHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "alphastarmini.lib.utils.to_one_hot().squeeze", "alphastarmini.lib.utils.to_one_hot().squeeze.unsqueeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "selected_units_head.SelectedUnitsHead.project", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "next", "print", "selected_units_head.SelectedUnitsHead.func_embed", "print", "print", "print", "print", "print", "print", "print", "print", "selected_units_head.SelectedUnitsHead.div.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "selected_units_head.SelectedUnitsHead.parameters", "selected_units_head.SelectedUnitsHead.conv_1", "print", "alphastarmini.lib.utils.to_one_hot", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "alphastarmini.lib.utils.action_involve_selecting_units_mask.float", "entity_embeddings.transpose", "action_type.item"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity_types_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_selecting_units_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot"], ["", "def", "forward", "(", "self", ",", "autoregressive_embedding", ",", "action_type", ",", "entity_embeddings", ")", ":", "\n", "        ", "'''\n        Inputs:\n            autoregressive_embedding: [batch_size x autoregressive_embedding_size]\n            action_type: [batch_size x 1]\n            entity_embeddings: [batch_size x entity_size x embedding_size]\n        Output:\n            units_logits: [batch_size x max_selected x entity_size]\n            units: [batch_size x max_selected x 1]\n            autoregressive_embedding: [batch_size x autoregressive_embedding_size]\n        '''", "\n", "\n", "batch_size", "=", "entity_embeddings", ".", "shape", "[", "0", "]", "\n", "entity_size", "=", "entity_embeddings", ".", "shape", "[", "-", "2", "]", "\n", "unit_types_one_hot", "=", "L", ".", "action_can_apply_to_entity_types_mask", "(", "action_type", ")", "\n", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "print", "(", "\"device:\"", ",", "device", ")", "if", "debug", "else", "None", "\n", "# note! to(device) on tensor is not in-place operation, so don't only use unit_types_one_hot.to(device)", "\n", "unit_types_one_hot", "=", "unit_types_one_hot", ".", "to", "(", "device", ")", "\n", "\n", "the_func_embed", "=", "F", ".", "relu", "(", "self", ".", "func_embed", "(", "unit_types_one_hot", ")", ")", "\n", "key", "=", "self", ".", "conv_1", "(", "entity_embeddings", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "# key shape [batch_size, entity_size, embedd_size]   ", "\n", "print", "(", "\"key:\"", ",", "key", ")", "if", "debug", "else", "None", "\n", "\n", "# key = self.layer_norm_k(key)", "\n", "# print(\"key:\", key) if debug else None", "\n", "\n", "units_logits", "=", "[", "]", "\n", "units", "=", "[", "]", "\n", "\n", "select_unit_mask", "=", "L", ".", "action_involve_selecting_units_mask", "(", "action_type", ")", "\n", "\n", "if", "action_type", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "print", "(", "\"action_type:\"", ",", "action_type", ".", "item", "(", ")", ")", "if", "1", "else", "None", "\n", "\n", "# x = self.fc_1(autoregressive_embedding)", "\n", "# z_1 = the_func_embed + x", "\n", "# z_2 = self.fc_2(F.relu(z_1)).unsqueeze(1)", "\n", "# print(\"z_2:\", z_2) if 1 else None", "\n", "# y = torch.bmm(key, z_2.transpose(-1, -2)).squeeze(-1)", "\n", "\n", "# print(\"key.shape:\", key.shape) if debug else None", "\n", "# print(\"autoregressive_embedding.shape:\", autoregressive_embedding.shape) if debug else None", "\n", "\n", "# q = self.fc_4(autoregressive_embedding)", "\n", "# # shape [batch_size, embedd_size]", "\n", "# print(\"q:\", q) if debug else None", "\n", "# q = self.layer_norm_q(q)", "\n", "# print(\"q:\", q) if debug else None", "\n", "# y = torch.matmul(key, q.unsqueeze(-1)).squeeze(-1) / (AHP.original_32 ** 0.5)", "\n", "\n", "#y_1 = self.fc_3(autoregressive_embedding)", "\n", "#y = self.fc_4(F.relu(y_1))", "\n", "\n", "# y = torch.bmm(key, x.transpose(-1, -2))", "\n", "# print(\"y:\", y) if 1 else None", "\n", "# y = y.squeeze(-1)", "\n", "\n", "", "y", "=", "self", ".", "fc_3", "(", "autoregressive_embedding", ")", "\n", "print", "(", "\"y.shape:\"", ",", "y", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entity_logits", "=", "y", ".", "div", "(", "self", ".", "temperature", ")", "\n", "# entity_logits shape: [batch_size x entity_size]", "\n", "print", "(", "\"entity_logits:\"", ",", "entity_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"entity_logits.shape:\"", ",", "entity_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entity_probs", "=", "self", ".", "softmax", "(", "entity_logits", ")", "\n", "# entity_probs shape: [batch_size x entity_size]", "\n", "print", "(", "\"entity_probs:\"", ",", "entity_probs", ")", "if", "1", "else", "None", "\n", "print", "(", "\"entity_probs.shape:\"", ",", "entity_probs", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entity_id", "=", "torch", ".", "multinomial", "(", "entity_probs", ",", "1", ")", "\n", "# TODO: Wenhai: If this entity_id is a EOF, end the selection", "\n", "\n", "# entity_id shape: [batch_size x 1]", "\n", "print", "(", "\"entity_id:\"", ",", "entity_id", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"entity_id.shape:\"", ",", "entity_id", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# note, we add a dimension where is in the seq_one to help", "\n", "# we concat to the one : [batch_size x max_selected x ?]", "\n", "units_logits", ".", "append", "(", "entity_logits", ".", "unsqueeze", "(", "-", "2", ")", ")", "\n", "units", ".", "append", "(", "entity_id", ".", "unsqueeze", "(", "-", "2", ")", ")", "\n", "\n", "# AlphaStar: The one-hot position of the selected entity is multiplied by the keys,", "\n", "entity_one_hot", "=", "L", ".", "to_one_hot", "(", "entity_id", ",", "entity_size", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "# entity_one_hot shape: [batch_size x entity_size]", "\n", "print", "(", "\"entity_one_hot:\"", ",", "entity_one_hot", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"entity_one_hot.shape:\"", ",", "entity_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entity_one_hot_unsqueeze", "=", "entity_one_hot", ".", "unsqueeze", "(", "-", "2", ")", "\n", "# entity_one_hot_unsqueeze shape: [batch_size x seq_len x entity_size], note seq_len =1 ", "\n", "# key_shape: [batch_size x entity_size x key_size], note key_size = 32", "\n", "out", "=", "torch", ".", "bmm", "(", "entity_one_hot_unsqueeze", ",", "key", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "# out shape: [batch_size x key_size]", "\n", "print", "(", "\"out:\"", ",", "out", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"out.shape:\"", ",", "out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: reduced by the mean across the entities,", "\n", "# Wenhai: should be key mean", "\n", "# Ruo-Ze: should be out mean", "\n", "# mean = torch.mean(entity_one_hot, dim=-1, keepdim=True)", "\n", "mean", "=", "torch", ".", "mean", "(", "out", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# mean shape: [batch_size x 1]", "\n", "\n", "out", "=", "out", "-", "mean", "\n", "print", "(", "\"out:\"", ",", "out", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"out.shape:\"", ",", "out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: passed through a linear layer of size 1024,", "\n", "t", "=", "self", ".", "project", "(", "out", ")", "\n", "print", "(", "\"t:\"", ",", "t", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"t.shape:\"", ",", "t", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: and added to `autoregressive_embedding` for subsequent iterations.", "\n", "assert", "autoregressive_embedding", ".", "shape", "==", "t", ".", "shape", "\n", "autoregressive_embedding", "=", "autoregressive_embedding", "+", "t", "*", "select_unit_mask", ".", "float", "(", ")", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "\n", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "\n", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# QUESTION: When to break?", "\n", "\n", "units_logits", "=", "torch", ".", "cat", "(", "units_logits", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"units_logits:\"", ",", "units_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"units_logits.shape:\"", ",", "units_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# units_logits: [batch_size x max_selected x entity_size]", "\n", "units", "=", "torch", ".", "cat", "(", "units", ",", "dim", "=", "1", ")", "\n", "# units: [batch_size x max_selected x 1]", "\n", "\n", "# autoregressive_embedding: [batch_size x autoregressive_embedding_size]", "\n", "return", "units_logits", ",", "units", ",", "autoregressive_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.selected_units_head.test": [[209, 244], ["torch.randn", "torch.randn", "torch.randn", "torch.randint", "torch.randint", "torch.randint", "torch.randn", "torch.randn", "torch.randn", "selected_units_head.SelectedUnitsHead", "selected_units_head.SelectedUnitsHead.forward", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "autoregressive_embedding", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "action_type", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "SFS", ".", "available_actions", ",", "size", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "entity_embeddings", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "max_entities", ",", "AHP", ".", "entity_embedding_size", ")", "\n", "\n", "selected_units_head", "=", "SelectedUnitsHead", "(", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "\n", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "\n", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "units_logits", ",", "units", ",", "autoregressive_embedding", "=", "selected_units_head", ".", "forward", "(", "\n", "autoregressive_embedding", ",", "action_type", ",", "entity_embeddings", ")", "\n", "\n", "if", "units_logits", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"units_logits:\"", ",", "units_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"units_logits.shape:\"", ",", "units_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"units_logits is None!\"", ")", "\n", "\n", "", "if", "units", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"units:\"", ",", "units", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"units.shape:\"", ",", "units", ".", "shape", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"units is None!\"", ")", "\n", "\n", "", "print", "(", "\"autoregressive_embedding:\"", ",", "\n", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "\n", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.__init__": [[40, 46], ["alphastarmini.core.arch.arch_model.ArchModel", "agent.Agent.set_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.set_weights"], ["    ", "def", "__init__", "(", "self", ",", "weights", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "ArchModel", "(", ")", "\n", "self", ".", "hidden_state", "=", "None", "\n", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_weights", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state": [[47, 52], ["agent.Agent.model.init_hidden_state"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state"], ["", "", "def", "init_hidden_state", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "model", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "model", ".", "init_hidden_state", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.device": [[53, 56], ["next", "agent.Agent.model.parameters"], "methods", ["None"], ["", "", "def", "device", "(", "self", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.to": [[57, 59], ["agent.Agent.model.to"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "to", "(", "self", ",", "DEVICE", ")", ":", "\n", "        ", "self", ".", "model", ".", "to", "(", "DEVICE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.unroll": [[60, 71], ["alphastarmini.core.sl.feature.Feature.feature2state", "agent.Agent.action_logits_by_state", "action_output.append", "agent.Agent.init_hidden_state"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.sl.feature.Feature.feature2state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_logits_by_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state"], ["", "def", "unroll", "(", "self", ",", "one_traj", ")", ":", "\n", "        ", "action_output", "=", "[", "]", "\n", "for", "traj_step", "in", "one_traj", ":", "\n", "            ", "(", "feature", ",", "label", ",", "is_final", ")", "=", "traj_step", "\n", "state", "=", "Feature", ".", "feature2state", "(", "feature", ")", "\n", "action_logits_prdict", ",", "self", ".", "hidden_state", "=", "self", ".", "action_logits_by_state", "(", "state", ",", "self", ".", "hidden_state", ")", "\n", "action_output", ".", "append", "(", "action_logits_prdict", ")", "\n", "if", "is_final", ":", "\n", "                ", "self", ".", "hidden_state", "=", "self", ".", "init_hidden_state", "(", ")", "\n", "\n", "", "", "return", "action_output", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_all": [[72, 80], ["agent.Agent.preprocess_state_entity", "agent.Agent.preprocess_state_scalar", "agent.Agent.preprocess_state_spatial", "alphastarmini.core.rl.state.MsState"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_entity", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_scalar", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_spatial"], ["", "def", "preprocess_state_all", "(", "self", ",", "obs", ",", "build_order", "=", "None", ")", ":", "\n", "        ", "batch_entities_tensor", "=", "self", ".", "preprocess_state_entity", "(", "obs", ")", "\n", "scalar_list", "=", "self", ".", "preprocess_state_scalar", "(", "obs", ",", "build_order", "=", "build_order", ")", "\n", "map_data", "=", "self", ".", "preprocess_state_spatial", "(", "obs", ")", "\n", "state", "=", "MsState", "(", "entity_state", "=", "batch_entities_tensor", ",", "\n", "statistical_state", "=", "scalar_list", ",", "map_state", "=", "map_data", ")", "\n", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_state_and_action_from_pickle": [[81, 89], ["agent.Agent.preprocess_state_entity", "agent.Agent.preprocess_state_scalar", "agent.Agent.preprocess_state_spatial", "alphastarmini.core.rl.state.MsState"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_entity", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_scalar", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_spatial"], ["", "def", "get_state_and_action_from_pickle", "(", "self", ",", "obs", ")", ":", "\n", "        ", "batch_entities_tensor", "=", "self", ".", "preprocess_state_entity", "(", "obs", ")", "\n", "scalar_list", "=", "self", ".", "preprocess_state_scalar", "(", "obs", ")", "\n", "map_data", "=", "self", ".", "preprocess_state_spatial", "(", "obs", ")", "\n", "state", "=", "MsState", "(", "entity_state", "=", "batch_entities_tensor", ",", "\n", "statistical_state", "=", "scalar_list", ",", "map_state", "=", "map_data", ")", "\n", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_scalar_list": [[90, 155], ["torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "alphastarmini.lib.utils.calculate_unit_counts_bow", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "print", "print", "print", "print", "print", "print", "int", "print", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "print", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow"], ["", "def", "get_scalar_list", "(", "self", ",", "obs", ",", "build_order", "=", "None", ")", ":", "\n", "        ", "scalar_list", "=", "[", "]", "\n", "\n", "# implement the agent_statistics", "\n", "player", "=", "obs", "[", "\"player\"", "]", "\n", "player_statistics", "=", "player", "[", "1", ":", "]", "\n", "agent_statistics", "=", "torch", ".", "tensor", "(", "player_statistics", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'agent_statistics:'", ",", "agent_statistics", ")", "if", "debug", "else", "None", "\n", "\n", "# implement the upgrades", "\n", "upgrades", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "upgrades", ")", "\n", "obs_upgrades", "=", "obs", "[", "\"upgrades\"", "]", "\n", "print", "(", "'obs_upgrades:'", ",", "obs_upgrades", ")", "if", "debug", "else", "None", "\n", "for", "u", "in", "obs_upgrades", ":", "\n", "            ", "assert", "u", ">=", "0", "\n", "assert", "u", "<", "SFS", ".", "upgrades", "\n", "upgrades", "[", "0", ",", "u", "]", "=", "1", "\n", "\n", "# implement the unit_counts_bow", "\n", "", "unit_counts_bow", "=", "L", ".", "calculate_unit_counts_bow", "(", "obs", ")", "\n", "print", "(", "'unit_counts_bow:'", ",", "unit_counts_bow", ")", "if", "debug", "else", "None", "\n", "print", "(", "'torch.sum(unit_counts_bow):'", ",", "torch", ".", "sum", "(", "unit_counts_bow", ")", ")", "if", "debug", "else", "None", "\n", "\n", "# TODO: implement the units_buildings", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "1", ",", "SFS", ".", "units_buildings", ")", "\n", "\n", "# implement the effects", "\n", "effects", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "effects", ")", "\n", "# we now use feature_effects to represent it", "\n", "feature_effects", "=", "obs", "[", "\"feature_effects\"", "]", "\n", "print", "(", "'feature_effects:'", ",", "feature_effects", ")", "if", "debug", "else", "None", "\n", "for", "effect", "in", "feature_effects", ":", "\n", "            ", "e", "=", "effect", ".", "effect_id", "\n", "assert", "e", ">=", "0", "\n", "assert", "e", "<", "SFS", ".", "effects", "\n", "effects", "[", "0", ",", "e", "]", "=", "1", "\n", "# the raw effects are reserved for use", "\n", "", "raw_effects", "=", "obs", "[", "\"raw_effects\"", "]", "\n", "print", "(", "'raw_effects:'", ",", "raw_effects", ")", "if", "debug", "else", "None", "\n", "\n", "# now we simplely make upgrade the same as upgrades", "\n", "upgrade", "=", "upgrades", "\n", "\n", "# implement the build order", "\n", "# TODO: add the pos of buildings", "\n", "beginning_build_order", "=", "torch", ".", "zeros", "(", "1", ",", "SCHP", ".", "count_beginning_build_order", ",", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "print", "(", "'beginning_build_order.shape:'", ",", "beginning_build_order", ".", "shape", ")", "if", "debug", "else", "None", "\n", "if", "build_order", "is", "not", "None", ":", "\n", "# implement the beginning_build_order               ", "\n", "            ", "for", "i", ",", "bo", "in", "enumerate", "(", "build_order", ")", ":", "\n", "                ", "if", "i", "<", "20", ":", "\n", "                    ", "assert", "bo", "<", "SFS", ".", "unit_counts_bow", "\n", "beginning_build_order", "[", "0", ",", "i", ",", "bo", "]", "=", "1", "\n", "", "", "print", "(", "\"beginning_build_order:\"", ",", "beginning_build_order", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"sum(beginning_build_order):\"", ",", "torch", ".", "sum", "(", "beginning_build_order", ")", ".", "item", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "\n", "return", "scalar_list", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_baseline_state": [[156, 163], ["agent.Agent.get_scalar_list", "agent.Agent.get_scalar_list"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_scalar_list", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_scalar_list"], ["", "def", "preprocess_baseline_state", "(", "self", ",", "home_obs", ",", "away_obs", ",", "build_order", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "1", "\n", "\n", "agent_scalar_list", "=", "self", ".", "get_scalar_list", "(", "home_obs", ",", "build_order", ")", "\n", "opponenet_scalar_out", "=", "self", ".", "get_scalar_list", "(", "away_obs", ")", "\n", "\n", "return", "agent_scalar_list", ",", "opponenet_scalar_out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_scalar": [[164, 309], ["torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "alphastarmini.lib.utils.calculate_unit_counts_bow", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "print", "print", "print", "obs[].item", "print", "obs[].item", "print", "print", "print", "print", "print", "print", "int", "print", "enumerate", "print", "print", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "print", "print", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "print", "alphastarmini.lib.utils.unpackbits_for_largenumber", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.calculate_unit_counts_bow", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unpackbits_for_largenumber"], ["", "def", "preprocess_state_scalar", "(", "self", ",", "obs", ",", "build_order", "=", "None", ")", ":", "\n", "        ", "scalar_list", "=", "[", "]", "\n", "\n", "player", "=", "obs", "[", "\"player\"", "]", "\n", "print", "(", "'player:'", ",", "player", ")", "if", "debug", "else", "None", "\n", "\n", "# The first is player_id, so we don't need it.", "\n", "player_statistics", "=", "player", "[", "1", ":", "]", "\n", "print", "(", "'player_statistics:'", ",", "player_statistics", ")", "if", "debug", "else", "None", "\n", "\n", "# player_statistics = np.log(player_statistics + 1)", "\n", "# print('player_statistics:', player_statistics)", "\n", "\n", "# agent_statistics = torch.ones(1, 10)", "\n", "agent_statistics", "=", "torch", ".", "tensor", "(", "player_statistics", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'player_statistics:'", ",", "agent_statistics", ")", "if", "debug", "else", "None", "\n", "\n", "home_race", "=", "torch", ".", "zeros", "(", "1", ",", "5", ")", "\n", "if", "\"home_race_requested\"", "in", "obs", ":", "\n", "            ", "home_race_requested", "=", "obs", "[", "\"home_race_requested\"", "]", ".", "item", "(", ")", "\n", "print", "(", "'home_race_requested:'", ",", "home_race_requested", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "            ", "home_race_requested", "=", "0", "\n", "", "assert", "home_race_requested", ">=", "0", "and", "home_race_requested", "<=", "4", "\n", "home_race", "[", "0", ",", "home_race_requested", "]", "=", "1", "\n", "print", "(", "'home_race:'", ",", "home_race", ")", "if", "debug", "else", "None", "\n", "\n", "away_race", "=", "torch", ".", "zeros", "(", "1", ",", "5", ")", "\n", "if", "\"away_race_requested\"", "in", "obs", ":", "\n", "            ", "away_race_requested", "=", "obs", "[", "\"away_race_requested\"", "]", ".", "item", "(", ")", "\n", "print", "(", "'away_race_requested:'", ",", "away_race_requested", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "            ", "away_race_requested", "=", "0", "\n", "", "assert", "away_race_requested", ">=", "0", "and", "away_race_requested", "<=", "4", "\n", "away_race", "[", "0", ",", "away_race_requested", "]", "=", "1", "\n", "print", "(", "'away_race:'", ",", "away_race", ")", "if", "debug", "else", "None", "\n", "\n", "if", "\"action_result\"", "in", "obs", ":", "\n", "            ", "action_result", "=", "obs", "[", "\"action_result\"", "]", "\n", "print", "(", "'action_result:'", ",", "action_result", ")", "if", "debug", "else", "None", "\n", "\n", "", "if", "\"alerts\"", "in", "obs", ":", "\n", "            ", "alerts", "=", "obs", "[", "\"alerts\"", "]", "\n", "print", "(", "'alerts:'", ",", "alerts", ")", "if", "debug", "else", "None", "\n", "\n", "# implement the upgrades", "\n", "", "upgrades", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "upgrades", ")", "\n", "obs_upgrades", "=", "obs", "[", "\"upgrades\"", "]", "\n", "print", "(", "'obs_upgrades:'", ",", "obs_upgrades", ")", "if", "debug", "else", "None", "\n", "for", "u", "in", "obs_upgrades", ":", "\n", "            ", "assert", "u", ">=", "0", "\n", "assert", "u", "<", "SFS", ".", "upgrades", "\n", "upgrades", "[", "0", ",", "u", "]", "=", "1", "\n", "\n", "# question: how to know enemy's upgrades?", "\n", "", "enemy_upgrades", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "upgrades", ")", "\n", "\n", "# time conver to gameloop", "\n", "time", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "time", ")", "\n", "game_loop", "=", "obs", "[", "\"game_loop\"", "]", "\n", "print", "(", "'game_loop:'", ",", "game_loop", ")", "if", "debug", "else", "None", "\n", "\n", "time_encoding", "=", "torch", ".", "tensor", "(", "L", ".", "unpackbits_for_largenumber", "(", "game_loop", ",", "num_bits", "=", "64", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'time_encoding:'", ",", "time_encoding", ")", "if", "debug", "else", "None", "\n", "# note, we use binary encoding here for time", "\n", "time", "=", "time_encoding", "\n", "#time[0, 0] = game_loop", "\n", "\n", "# implement the available_actions", "\n", "# note: if we use raw action, this key doesn't exist", "\n", "# the_available_actions = obs[\"available_actions\"] ", "\n", "# print('the_available_actions:', the_available_actions) if 1 else None", "\n", "available_actions", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "available_actions", ")", "\n", "\n", "# implement the unit_counts_bow", "\n", "unit_counts_bow", "=", "L", ".", "calculate_unit_counts_bow", "(", "obs", ")", "\n", "print", "(", "'unit_counts_bow:'", ",", "unit_counts_bow", ")", "if", "debug", "else", "None", "\n", "print", "(", "'torch.sum(unit_counts_bow):'", ",", "torch", ".", "sum", "(", "unit_counts_bow", ")", ")", "if", "debug", "else", "None", "\n", "\n", "# implement the build order", "\n", "beginning_build_order", "=", "torch", ".", "zeros", "(", "1", ",", "SCHP", ".", "count_beginning_build_order", ",", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "print", "(", "'beginning_build_order.shape:'", ",", "beginning_build_order", ".", "shape", ")", "if", "debug", "else", "None", "\n", "if", "build_order", "is", "not", "None", ":", "\n", "# implement the beginning_build_order               ", "\n", "            ", "for", "i", ",", "bo", "in", "enumerate", "(", "build_order", ")", ":", "\n", "                ", "if", "i", "<", "20", ":", "\n", "                    ", "assert", "bo", "<", "SFS", ".", "unit_counts_bow", "\n", "beginning_build_order", "[", "0", ",", "i", ",", "bo", "]", "=", "1", "\n", "", "", "print", "(", "\"beginning_build_order:\"", ",", "beginning_build_order", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"sum(beginning_build_order):\"", ",", "torch", ".", "sum", "(", "beginning_build_order", ")", ".", "item", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "", "mmr", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "mmr", ")", "\n", "units_buildings", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "units_buildings", ")", "\n", "\n", "# implement the effects", "\n", "effects", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "effects", ")", "\n", "# we now use feature_effects to represent it", "\n", "feature_effects", "=", "obs", "[", "\"feature_effects\"", "]", "\n", "print", "(", "'feature_effects:'", ",", "feature_effects", ")", "if", "debug", "else", "None", "\n", "for", "effect", "in", "feature_effects", ":", "\n", "            ", "e", "=", "effect", ".", "effect_id", "\n", "assert", "e", ">=", "0", "\n", "assert", "e", "<", "SFS", ".", "effects", "\n", "effects", "[", "0", ",", "e", "]", "=", "1", "\n", "# the raw effects are reserved for use", "\n", "", "raw_effects", "=", "obs", "[", "\"raw_effects\"", "]", "\n", "print", "(", "'raw_effects:'", ",", "raw_effects", ")", "if", "debug", "else", "None", "\n", "\n", "# implement the upgrade", "\n", "upgrade", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "upgrades", ")", "\n", "for", "u", "in", "obs_upgrades", ":", "\n", "            ", "assert", "u", ">=", "0", "\n", "assert", "u", "<", "SFS", ".", "upgrades", "\n", "upgrade", "[", "0", ",", "u", "]", "=", "1", "\n", "\n", "", "last_delay", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "last_delay", ")", "\n", "\n", "# implement the last action", "\n", "# note: if we use raw action, this property is always empty", "\n", "last_actions", "=", "obs", "[", "\"last_actions\"", "]", "\n", "print", "(", "'last_actions:'", ",", "last_actions", ")", "if", "debug", "else", "None", "\n", "last_action_type", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "last_action_type", ")", "\n", "\n", "last_repeat_queued", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "last_repeat_queued", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "home_race", ")", "\n", "scalar_list", ".", "append", "(", "away_race", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "enemy_upgrades", ")", "\n", "scalar_list", ".", "append", "(", "time", ")", "\n", "\n", "scalar_list", ".", "append", "(", "available_actions", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "mmr", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "scalar_list", ".", "append", "(", "last_delay", ")", "\n", "scalar_list", ".", "append", "(", "last_action_type", ")", "\n", "scalar_list", ".", "append", "(", "last_repeat_queued", ")", "\n", "\n", "return", "scalar_list", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_entity": [[310, 430], ["our_unit_list.extend", "probe_list.sort", "our_unit_list.extend", "enumerate", "agent.Agent.model.preprocess_entity", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "print", "print", "print", "len", "print", "alphastarmini.core.arch.entity_encoder.Entity", "e_list.append", "tag_list.append", "len", "len", "print", "nexus_list.append", "probe_list.append", "idle_probe_list.append"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_entity"], ["", "def", "preprocess_state_entity", "(", "self", ",", "obs", ",", "return_tag_list", "=", "False", ")", ":", "\n", "        ", "raw_units", "=", "obs", "[", "\"raw_units\"", "]", "\n", "\n", "our_unit_list", "=", "[", "]", "\n", "nexus_list", "=", "[", "]", "\n", "probe_list", "=", "[", "]", "\n", "idle_probe_list", "=", "[", "]", "\n", "for", "u", "in", "raw_units", ":", "\n", "# only include the units we have", "\n", "            ", "if", "u", ".", "alliance", "==", "1", ":", "\n", "# our_unit_list.append(u)", "\n", "                ", "if", "u", ".", "unit_type", "==", "59", ":", "\n", "                    ", "nexus_list", ".", "append", "(", "u", ")", "\n", "", "if", "u", ".", "unit_type", "==", "84", ":", "\n", "                    ", "probe_list", ".", "append", "(", "u", ")", "\n", "if", "u", ".", "order_length", "==", "0", ":", "\n", "                        ", "idle_probe_list", ".", "append", "(", "u", ")", "\n", "\n", "", "", "", "", "our_unit_list", ".", "extend", "(", "nexus_list", ")", "\n", "\n", "def", "myFunc", "(", "e", ")", ":", "\n", "            ", "return", "e", ".", "tag", "\n", "# note we must ensure the index is the same across state -> action", "\n", "", "probe_list", ".", "sort", "(", "reverse", "=", "False", ",", "key", "=", "myFunc", ")", "\n", "our_unit_list", ".", "extend", "(", "probe_list", ")", "\n", "\n", "#print(\"preprocess: our_unit_list\", our_unit_list) if 1 else None", "\n", "print", "(", "\"preprocess: len(our_unit_list)\"", ",", "len", "(", "our_unit_list", ")", ")", "if", "debug", "else", "None", "\n", "for", "u", "in", "our_unit_list", ":", "\n", "            ", "print", "(", "u", ".", "tag", ")", "if", "debug", "else", "None", "\n", "\n", "", "e_list", "=", "[", "]", "\n", "tag_list", "=", "[", "]", "\n", "\n", "index", "=", "0", "\n", "for", "i", ",", "raw_unit", "in", "enumerate", "(", "our_unit_list", ")", ":", "\n", "            ", "unit_type", "=", "raw_unit", ".", "unit_type", "\n", "alliance", "=", "raw_unit", ".", "alliance", "\n", "tag", "=", "raw_unit", ".", "tag", "\n", "# note: wo only consider the entities not beyond the max number", "\n", "if", "index", "<", "AHP", ".", "max_entities", ":", "\n", "                ", "e", "=", "Entity", "(", ")", "\n", "e", ".", "unit_type", "=", "raw_unit", ".", "unit_type", "\n", "# e.unit_attributes = None", "\n", "e", ".", "alliance", "=", "raw_unit", ".", "alliance", "\n", "e", ".", "health", "=", "raw_unit", ".", "health", "\n", "e", ".", "shield", "=", "raw_unit", ".", "shield", "\n", "e", ".", "energy", "=", "raw_unit", ".", "energy", "\n", "e", ".", "cargo_space_taken", "=", "raw_unit", ".", "cargo_space_taken", "\n", "e", ".", "cargo_space_max", "=", "raw_unit", ".", "cargo_space_max", "\n", "e", ".", "build_progress", "=", "raw_unit", ".", "build_progress", "\n", "e", ".", "current_health_ratio", "=", "raw_unit", ".", "health_ratio", "\n", "e", ".", "current_shield_ratio", "=", "raw_unit", ".", "shield_ratio", "\n", "e", ".", "current_energy_ratio", "=", "raw_unit", ".", "energy_ratio", "\n", "# e.health_max = None", "\n", "# e.shield_max = None", "\n", "# e.energy_max = None", "\n", "e", ".", "display_type", "=", "raw_unit", ".", "display_type", "\n", "e", ".", "x", "=", "raw_unit", ".", "x", "\n", "e", ".", "y", "=", "raw_unit", ".", "y", "\n", "e", ".", "is_cloaked", "=", "raw_unit", ".", "cloak", "\n", "e", ".", "is_powered", "=", "raw_unit", ".", "is_powered", "\n", "e", ".", "is_hallucination", "=", "raw_unit", ".", "hallucination", "\n", "e", ".", "is_active", "=", "raw_unit", ".", "active", "\n", "e", ".", "is_on_screen", "=", "raw_unit", ".", "is_on_screen", "\n", "e", ".", "is_in_cargo", "=", "raw_unit", ".", "is_in_cargo", "\n", "e", ".", "current_minerals", "=", "raw_unit", ".", "mineral_contents", "\n", "e", ".", "current_vespene", "=", "raw_unit", ".", "vespene_contents", "\n", "# e.mined_minerals = None", "\n", "# e.mined_vespene = None", "\n", "e", ".", "assigned_harvesters", "=", "raw_unit", ".", "assigned_harvesters", "\n", "e", ".", "ideal_harvesters", "=", "raw_unit", ".", "ideal_harvesters", "\n", "e", ".", "weapon_cooldown", "=", "raw_unit", ".", "weapon_cooldown", "\n", "e", ".", "order_length", "=", "raw_unit", ".", "order_length", "\n", "e", ".", "order_1", "=", "raw_unit", ".", "order_id_0", "\n", "e", ".", "order_2", "=", "raw_unit", ".", "order_id_1", "\n", "e", ".", "order_3", "=", "raw_unit", ".", "order_id_2", "\n", "e", ".", "order_4", "=", "raw_unit", ".", "order_id_3", "\n", "e", ".", "order_progress_1", "=", "raw_unit", ".", "order_progress_0", "\n", "e", ".", "order_progress_2", "=", "raw_unit", ".", "order_progress_1", "\n", "e", ".", "buff_id_1", "=", "raw_unit", ".", "buff_id_0", "\n", "e", ".", "buff_id_2", "=", "raw_unit", ".", "buff_id_1", "\n", "e", ".", "addon_unit_type", "=", "raw_unit", ".", "addon_unit_type", "\n", "e", ".", "attack_upgrade_level", "=", "raw_unit", ".", "attack_upgrade_level", "\n", "e", ".", "armor_upgrade_level", "=", "raw_unit", ".", "armor_upgrade_level", "\n", "e", ".", "shield_upgrade_level", "=", "raw_unit", ".", "shield_upgrade_level", "\n", "e", ".", "is_selected", "=", "raw_unit", ".", "is_selected", "\n", "# e.is_targeted = None ", "\n", "\n", "# add tag", "\n", "# note: we use tag to find the right index of entity", "\n", "e", ".", "tag", "=", "raw_unit", ".", "tag", "\n", "e_list", ".", "append", "(", "e", ")", "\n", "\n", "# note: the unit_tags and target_unit_tag in pysc2 actions", "\n", "# are actually index in _raw_tags!", "\n", "# so they are different from the tags really used by a SC2-action!", "\n", "# thus we only need to append index, not sc2 tags          ", "\n", "# tag_list.append(e.tag)", "\n", "tag_list", ".", "append", "(", "i", ")", "# we only need to append index, not sc2 tags ", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "index", "+=", "1", "\n", "\n", "", "print", "(", "\"len(e_list)\"", ",", "len", "(", "e_list", ")", ")", "if", "debug", "else", "None", "\n", "\n", "# preprocess entity list", "\n", "entities_tensor", "=", "self", ".", "model", ".", "preprocess_entity", "(", "e_list", ")", "\n", "\n", "print", "(", "\"entities_tensor: len(e_list)\"", ",", "len", "(", "e_list", ")", ")", "if", "debug", "else", "None", "\n", "for", "u", "in", "e_list", ":", "\n", "            ", "print", "(", "u", ".", "tag", ")", "if", "debug", "else", "None", "\n", "\n", "", "batch_entities_tensor", "=", "torch", ".", "unsqueeze", "(", "entities_tensor", ",", "dim", "=", "0", ")", "\n", "\n", "if", "return_tag_list", ":", "\n", "            ", "return", "batch_entities_tensor", ",", "tag_list", "\n", "\n", "", "return", "batch_entities_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_spatial": [[431, 435], ["agent.Agent.model.preprocess_spatial"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_spatial"], ["", "def", "preprocess_state_spatial", "(", "self", ",", "obs", ")", ":", "\n", "        ", "map_data", "=", "self", ".", "model", ".", "preprocess_spatial", "(", "obs", ")", "\n", "\n", "return", "map_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_by_obs": [[436, 440], ["agent.Agent.preprocess_state_all", "agent.Agent.model.forward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_all", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "def", "action_by_obs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "state", "=", "self", ".", "preprocess_state_all", "(", "obs", ")", "\n", "action", "=", "self", ".", "model", ".", "forward", "(", "state", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_by_state": [[441, 444], ["agent.Agent.model.forward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "def", "action_by_state", "(", "self", ",", "state", ")", ":", "\n", "        ", "action", "=", "self", ".", "model", ".", "forward", "(", "state", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_logits_by_state": [[445, 454], ["agent.Agent.model.forward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "def", "action_logits_by_state", "(", "self", ",", "state", ",", "hidden_state", "=", "None", ",", "single_inference", "=", "False", ")", ":", "\n", "        ", "batch_size", "=", "1", "if", "single_inference", "else", "None", "\n", "sequence_length", "=", "1", "if", "single_inference", "else", "None", "\n", "\n", "action_logits", ",", "actions", ",", "new_state", "=", "self", ".", "model", ".", "forward", "(", "state", ",", "batch_size", "=", "batch_size", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "hidden_state", "=", "hidden_state", ",", "\n", "return_logits", "=", "True", ")", "\n", "return", "action_logits", ",", "actions", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.state_by_obs": [[455, 462], ["agent.Agent.preprocess_state_all"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_all"], ["", "def", "state_by_obs", "(", "self", ",", "obs", ",", "return_tag_list", "=", "False", ")", ":", "\n", "        ", "state", ",", "tag_list", "=", "self", ".", "preprocess_state_all", "(", "obs", ",", "return_tag_list", ")", "\n", "\n", "if", "tag_list", "and", "return_tag_list", ":", "\n", "            ", "return", "state", ",", "tag_list", "\n", "\n", "", "return", "state", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.func_call_to_action": [[463, 507], ["alphastarmini.core.rl.action.ArgsAction", "print", "print", "print", "print", "print", "print", "pysc2.lib.units.get_unit_type", "print", "print", "int", "print"], "methods", ["None"], ["", "def", "func_call_to_action", "(", "self", ",", "func_call", ",", "obs", "=", "None", ")", ":", "\n", "# note: this is a pysc2 action, and the ", "\n", "# unit_tags and target_unit_tag are actually index in _raw_tags!", "\n", "# so they are different from the tags really used by a SC2-action!", "\n", "        ", "func", "=", "func_call", ".", "function", "\n", "args", "=", "func_call", ".", "arguments", "\n", "\n", "print", "(", "'function:'", ",", "func", ")", "if", "debug", "else", "None", "\n", "print", "(", "'function value:'", ",", "func", ".", "value", ")", "if", "debug", "else", "None", "\n", "print", "(", "'arguments:'", ",", "args", ")", "if", "debug", "else", "None", "\n", "\n", "args_action", "=", "ArgsAction", "(", "use_tag", "=", "True", ")", "\n", "args_action", ".", "action_type", "=", "func", ".", "value", "\n", "\n", "# use a non-smart method to calculate the args of the action", "\n", "need_args", "=", "A", ".", "RAW_FUNCTIONS", "[", "func", "]", ".", "args", "\n", "i", "=", "0", "\n", "for", "arg", "in", "need_args", ":", "\n", "            ", "print", "(", "\"arg:\"", ",", "arg", ")", "if", "debug", "else", "None", "\n", "if", "arg", ".", "name", "==", "'queued'", ":", "\n", "                ", "args_action", ".", "queue", "=", "args", "[", "i", "]", "[", "0", "]", ".", "value", "\n", "i", "=", "i", "+", "1", "\n", "", "elif", "arg", ".", "name", "==", "'unit_tags'", ":", "\n", "                ", "args_action", ".", "units", "=", "args", "[", "i", "]", "\n", "i", "=", "i", "+", "1", "\n", "", "elif", "arg", ".", "name", "==", "'target_unit_tag'", ":", "\n", "                ", "args_action", ".", "target_unit", "=", "args", "[", "i", "]", "[", "0", "]", "\n", "i", "=", "i", "+", "1", "\n", "", "elif", "arg", ".", "name", "==", "'world'", ":", "\n", "                ", "scale_factor", "=", "0.5", "if", "SCHP", ".", "world_size", "==", "128", "else", "1", "\n", "print", "(", "'args[i]:'", ",", "args", "[", "i", "]", ")", "if", "debug", "else", "None", "\n", "args_action", ".", "target_location", "=", "[", "int", "(", "x", "*", "scale_factor", ")", "for", "x", "in", "args", "[", "i", "]", "]", "\n", "print", "(", "'args_action.target_location:'", ",", "args_action", ".", "target_location", ")", "if", "debug", "else", "None", "\n", "i", "=", "i", "+", "1", "\n", "\n", "", "", "if", "obs", "is", "not", "None", ":", "\n", "            ", "units", "=", "args_action", ".", "units", "\n", "print", "(", "'units index:'", ",", "units", ")", "\n", "if", "units", "is", "not", "None", ":", "\n", "                ", "unit_type", "=", "get_unit_type", "(", "obs", "[", "\"raw_units\"", "]", "[", "units", "[", "0", "]", "]", ".", "unit_type", ")", "\n", "print", "(", "'selected unit is:'", ",", "unit_type", ")", "\n", "\n", "", "", "print", "(", "'args_action:'", ",", "args_action", ")", "if", "debug", "else", "None", "\n", "return", "args_action", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_to_func_call_RAS": [[508, 624], ["action.action_type.item", "alphastarmini.lib.utils.action_type_index_map_raw", "action.delay.item", "action.queue.item", "action.units.cpu().detach().reshape().numpy().tolist", "action.target_unit.item", "action.target_location.cpu().detach().reshape().numpy().tolist", "pysc2.lib.actions.FunctionCall.init_with_validation", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "action.get_shape", "action.units.cpu().detach().reshape().numpy", "action.target_location.cpu().detach().reshape().numpy", "print", "numpy.random.randint", "numpy.random.randint", "action.units.cpu().detach().reshape", "action.target_location.cpu().detach().reshape", "args.append", "args.append", "args.append", "print", "agent.Agent.action_to_func_call_RAS.to_list"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape"], ["", "def", "action_to_func_call_RAS", "(", "self", ",", "action", ",", "action_spec", ",", "obs", ",", "use_random_args", "=", "False", ")", ":", "\n", "# assert the action is single", "\n", "        ", "print", "(", "'action:'", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action.get_shape():'", ",", "action", ".", "get_shape", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "action_id", "=", "action", ".", "action_type", ".", "item", "(", ")", "\n", "print", "(", "'action_id:'", ",", "action_id", ")", "if", "debug", "else", "None", "\n", "\n", "function_id", "=", "L", ".", "action_type_index_map_raw", "(", "action_id", ")", "\n", "# function_id = 35  # TODO: Only in test, when training delete it!", "\n", "\n", "print", "(", "'action_id:'", ",", "action_id", ")", "if", "debug", "else", "None", "\n", "print", "(", "'function_id:'", ",", "function_id", ")", "if", "debug", "else", "None", "\n", "\n", "delay", "=", "action", ".", "delay", ".", "item", "(", ")", "\n", "print", "(", "'delay:'", ",", "delay", ")", "if", "debug", "else", "None", "\n", "\n", "queue", "=", "action", ".", "queue", ".", "item", "(", ")", "\n", "print", "(", "'queue:'", ",", "queue", ")", "if", "debug", "else", "None", "\n", "\n", "# we assume single inference", "\n", "units", "=", "action", ".", "units", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'units:'", ",", "units", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit", "=", "action", ".", "target_unit", ".", "item", "(", ")", "\n", "print", "(", "'target_unit:'", ",", "target_unit", ")", "if", "debug", "else", "None", "\n", "\n", "# we assume single inference", "\n", "target_location", "=", "action", ".", "target_location", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'target_location:'", ",", "target_location", ")", "if", "debug", "else", "None", "\n", "\n", "need_args", "=", "action_spec", ".", "functions", "[", "function_id", "]", ".", "args", "\n", "args", "=", "[", "]", "\n", "\n", "def", "to_list", "(", "i", ")", ":", "\n", "            ", "return", "[", "i", "]", "\n", "\n", "", "for", "unit", "in", "obs", "[", "\"raw_units\"", "]", ":", "\n", "            ", "if", "unit", ".", "unit_type", "==", "59", ":", "\n", "                ", "pass", "\n", "\n", "", "", "units_args", "=", "[", "]", "\n", "if", "not", "use_random_args", ":", "\n", "            ", "for", "arg", "in", "need_args", ":", "\n", "                ", "print", "(", "\"arg:\"", ",", "arg", ")", "if", "debug", "else", "None", "\n", "rand", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", "\n", "\n", "if", "arg", ".", "name", "==", "'queued'", ":", "\n", "                    ", "size", "=", "arg", ".", "sizes", "[", "0", "]", "\n", "if", "queue", "<", "0", "or", "queue", ">", "size", "-", "1", ":", "\n", "                        ", "args", ".", "append", "(", "rand", ")", "\n", "print", "(", "\"argument queue beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                        ", "args", ".", "append", "(", "to_list", "(", "queue", ")", ")", "\n", "", "", "elif", "arg", ".", "name", "==", "'unit_tags'", ":", "\n", "# the unit_tags size is actually the max selected number", "\n", "                    ", "size", "=", "arg", ".", "sizes", "[", "0", "]", "\n", "\n", "for", "unit_index", "in", "units", ":", "\n", "                        ", "if", "unit_index", "<", "0", "or", "unit_index", ">", "size", "-", "1", ":", "\n", "                            ", "units_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument unit_index beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                            ", "units_args", ".", "append", "(", "unit_index", ")", "\n", "\n", "", "", "args", ".", "append", "(", "units_args", ")", "\n", "\n", "", "elif", "arg", ".", "name", "==", "'target_unit_tag'", ":", "\n", "                    ", "size", "=", "arg", ".", "sizes", "[", "0", "]", "\n", "target", "=", "None", "\n", "if", "target_unit", "<", "0", "or", "target_unit", ">", "size", "-", "1", ":", "\n", "                        ", "target", "=", "rand", "\n", "print", "(", "\"argument target_unit beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                        ", "target", "=", "to_list", "(", "target_unit", ")", "\n", "\n", "", "args", ".", "append", "(", "target", ")", "\n", "\n", "", "elif", "arg", ".", "name", "==", "'world'", ":", "\n", "                    ", "world_args", "=", "[", "]", "\n", "\n", "for", "val", ",", "size", "in", "zip", "(", "target_location", ",", "arg", ".", "sizes", ")", ":", "\n", "                        ", "if", "val", "<", "0", "or", "val", ">", "size", "-", "1", ":", "\n", "                            ", "world_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "elif", "val", "==", "0", ":", "\n", "                            ", "world_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world is 0, we change it to random!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                            ", "world_args", ".", "append", "(", "val", ")", "\n", "", "", "print", "(", "'world_args:'", ",", "world_args", ")", "if", "debug", "else", "None", "\n", "\n", "# for move camera, select fixed postion", "\n", "if", "function_id", "==", "168", ":", "\n", "                        ", "world_args", "=", "[", "40", ",", "50", "]", "\n", "print", "(", "'world_args for move camera:'", ",", "world_args", ")", "if", "debug", "else", "None", "\n", "\n", "", "if", "function_id", "==", "35", ":", "\n", "# for Build_Pylon_pt, select randomly from some predined postion", "\n", "                        ", "rand_x", "=", "random", ".", "randint", "(", "-", "5", ",", "5", ")", "\n", "rand_y", "=", "random", ".", "randint", "(", "-", "5", ",", "5", ")", "\n", "\n", "world_args", "=", "[", "40", "+", "rand_x", "*", "2", ",", "50", "+", "rand_y", "*", "2", "]", "\n", "print", "(", "'world_args for build pylon:'", ",", "world_args", ")", "if", "debug", "else", "None", "\n", "\n", "", "args", ".", "append", "(", "world_args", ")", "\n", "", "", "", "else", ":", "\n", "            ", "args", "=", "[", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", "\n", "for", "arg", "in", "action_spec", ".", "functions", "[", "function_id", "]", ".", "args", "]", "\n", "\n", "", "print", "(", "'args:'", ",", "args", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar use the raw actions", "\n", "func_call", "=", "A", ".", "FunctionCall", ".", "init_with_validation", "(", "function", "=", "function_id", ",", "arguments", "=", "args", ",", "raw", "=", "True", ")", "\n", "\n", "return", "func_call", ",", "units_args", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_to_func_call_HAS": [[625, 736], ["action.action_type.item", "alphastarmini.lib.utils.action_type_index_map_human", "action.delay.item", "action.queue.item", "action.units.cpu().detach().reshape().numpy().tolist", "action.target_unit.item", "action.target_location.cpu().detach().reshape().numpy().tolist", "pysc2.lib.actions.FunctionCall.init_with_validation", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "action.get_shape", "action.units.cpu().detach().reshape().numpy", "action.target_location.cpu().detach().reshape().numpy", "print", "print", "numpy.random.randint", "numpy.random.randint", "action.units.cpu().detach().reshape", "action.target_location.cpu().detach().reshape", "args.append", "args.append", "zip", "args.append", "print", "agent.Agent.action_to_func_call_RAS.to_list"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_human", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape"], ["", "def", "action_to_func_call_HAS", "(", "self", ",", "action", ",", "action_spec", ",", "obs", ",", "use_random_args", "=", "False", ")", ":", "\n", "# assert the action is single", "\n", "        ", "print", "(", "'action_to_func_call_HAS:'", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action:'", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action.get_shape():'", ",", "action", ".", "get_shape", "(", ")", ")", "if", "debug", "else", "None", "\n", "\n", "action_id", "=", "action", ".", "action_type", ".", "item", "(", ")", "\n", "print", "(", "'action_id:'", ",", "action_id", ")", "if", "debug", "else", "None", "\n", "\n", "function_id", "=", "L", ".", "action_type_index_map_human", "(", "action_id", ")", "\n", "\n", "#function_id = -1", "\n", "print", "(", "'function_id:'", ",", "function_id", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"available_actions:\"", ",", "obs", ".", "available_actions", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"function_id is available:\"", ",", "function_id", "in", "(", "obs", ".", "available_actions", ")", ")", "if", "debug", "else", "None", "\n", "\n", "if", "not", "function_id", "in", "(", "obs", ".", "available_actions", ")", ":", "\n", "            ", "function_id", "=", "0", "# np.random.choice(obs.available_actions)", "\n", "\n", "#print('stop', stop)", "\n", "\n", "", "delay", "=", "action", ".", "delay", ".", "item", "(", ")", "\n", "print", "(", "'delay:'", ",", "delay", ")", "if", "debug", "else", "None", "\n", "\n", "queue", "=", "action", ".", "queue", ".", "item", "(", ")", "\n", "print", "(", "'queue:'", ",", "queue", ")", "if", "debug", "else", "None", "\n", "\n", "# we assume single inference", "\n", "units", "=", "action", ".", "units", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'units:'", ",", "units", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit", "=", "action", ".", "target_unit", ".", "item", "(", ")", "\n", "print", "(", "'target_unit:'", ",", "target_unit", ")", "if", "debug", "else", "None", "\n", "\n", "# we assume single inference", "\n", "target_location", "=", "action", ".", "target_location", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "reshape", "(", "-", "1", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'target_location:'", ",", "target_location", ")", "if", "debug", "else", "None", "\n", "\n", "need_args", "=", "action_spec", ".", "functions", "[", "function_id", "]", ".", "args", "\n", "args", "=", "[", "]", "\n", "\n", "def", "to_list", "(", "i", ")", ":", "\n", "            ", "return", "[", "i", "]", "\n", "\n", "", "units_args", "=", "[", "]", "\n", "if", "not", "use_random_args", ":", "\n", "            ", "for", "arg", "in", "need_args", ":", "\n", "                ", "print", "(", "\"arg:\"", ",", "arg", ")", "if", "debug", "else", "None", "\n", "rand", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", "\n", "\n", "if", "arg", ".", "name", "==", "'queued'", ":", "\n", "                    ", "size", "=", "arg", ".", "sizes", "[", "0", "]", "\n", "if", "queue", "<", "0", "or", "queue", ">", "size", "-", "1", ":", "\n", "                        ", "args", ".", "append", "(", "rand", ")", "\n", "print", "(", "\"argument queue beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                        ", "args", ".", "append", "(", "to_list", "(", "queue", ")", ")", "\n", "\n", "", "", "elif", "arg", ".", "name", "==", "'screen'", ":", "\n", "                    ", "screen_args", "=", "[", "]", "\n", "\n", "# note target location for world is 256 x 256", "\n", "# but in human space, we defualt set the screen size to 64 x 64", "\n", "for", "val", ",", "size", "in", "zip", "(", "target_location", ",", "arg", ".", "sizes", ")", ":", "\n", "# so we default divide it by 4", "\n", "                        ", "val", "=", "int", "(", "val", "/", "4", ")", "\n", "if", "val", "<", "0", "or", "val", ">", "size", "-", "1", ":", "\n", "                            ", "screen_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "elif", "val", "==", "0", ":", "\n", "                            ", "screen_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world is 0, we change it to random!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                            ", "screen_args", ".", "append", "(", "val", ")", "\n", "", "", "print", "(", "'screen_args:'", ",", "screen_args", ")", "if", "debug", "else", "None", "\n", "\n", "args", ".", "append", "(", "screen_args", ")", "\n", "\n", "", "elif", "arg", ".", "name", "==", "'minimap'", ":", "\n", "                    ", "minimap_args", "=", "[", "]", "\n", "\n", "# note target location for world is 256 x 256", "\n", "# but in human space, we defualt set the minimap size to 64 x 64", "\n", "for", "val", ",", "size", "in", "zip", "(", "target_location", ",", "arg", ".", "sizes", ")", ":", "\n", "# so we default divide it by 4", "\n", "                        ", "val", "=", "int", "(", "val", "/", "4", ")", "\n", "if", "val", "<", "0", "or", "val", ">", "size", "-", "1", ":", "\n", "                            ", "minimap_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world beyond the size!\"", ")", "if", "debug", "else", "None", "\n", "", "elif", "val", "==", "0", ":", "\n", "                            ", "minimap_args", ".", "append", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", ")", "\n", "print", "(", "\"argument world is 0, we change it to random!\"", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "                            ", "minimap_args", ".", "append", "(", "val", ")", "\n", "", "", "print", "(", "'minimap_args:'", ",", "minimap_args", ")", "if", "debug", "else", "None", "\n", "\n", "args", ".", "append", "(", "minimap_args", ")", "\n", "", "else", ":", "\n", "                    ", "args", ".", "append", "(", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "print", "(", "'use_random_args!'", ")", "if", "debug", "else", "None", "\n", "args", "=", "[", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", "\n", "for", "arg", "in", "action_spec", ".", "functions", "[", "function_id", "]", ".", "args", "]", "\n", "\n", "", "print", "(", "'args:'", ",", "args", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar use the raw actions", "\n", "func_call", "=", "A", ".", "FunctionCall", ".", "init_with_validation", "(", "function", "=", "function_id", ",", "arguments", "=", "args", ",", "raw", "=", "False", ")", "\n", "\n", "return", "func_call", ",", "units_args", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.unroll_traj": [[737, 744], ["agent.Agent.model.forward"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "def", "unroll_traj", "(", "self", ",", "state_all", ",", "initial_state", ",", "baseline_state", "=", "None", ",", "baseline_opponent_state", "=", "None", ")", ":", "\n", "        ", "baseline_value_list", ",", "action_logits", ",", "_", ",", "_", "=", "self", ".", "model", ".", "forward", "(", "state_all", ",", "batch_size", "=", "None", ",", "sequence_length", "=", "None", ",", "\n", "hidden_state", "=", "initial_state", ",", "return_logits", "=", "True", ",", "\n", "baseline_state", "=", "baseline_state", ",", "\n", "baseline_opponent_state", "=", "baseline_opponent_state", ",", "\n", "return_baseline", "=", "True", ")", "\n", "return", "baseline_value_list", ",", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.get_weights": [[745, 750], ["agent.Agent.model.state_dict"], "methods", ["None"], ["", "def", "get_weights", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "model", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.set_weights": [[751, 754], ["agent.Agent.model.load_state_dict"], "methods", ["None"], ["", "", "def", "set_weights", "(", "self", ",", "weights", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "weights", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.test": [[756, 848], ["agent.Agent", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "alphastarmini.core.arch.entity_encoder.Entity", "alphastarmini.core.arch.entity_encoder.Entity", "e_list.append", "e_list.append", "Agent.model.preprocess_entity", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "range", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "alphastarmini.lib.utils.to_one_hot", "map_list.append", "torch.zeros", "torch.zeros", "torch.zeros", "map_list.append", "torch.cat", "torch.cat", "torch.cat", "alphastarmini.core.rl.state.MsState", "agent.Agent.action_by_state", "agent.Agent.action_logits_by_state", "int", "print", "torch.cat.detach().clone", "batch_entities_list.append", "print", "print", "print", "print", "print", "print", "print", "torch.cat.detach"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.arch_model.ArchModel.preprocess_entity", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_by_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_logits_by_state"], ["", "", "def", "test", "(", ")", ":", "\n", "\n", "    ", "agent", "=", "Agent", "(", ")", "\n", "\n", "batch_size", "=", "AHP", ".", "batch_size", "*", "AHP", ".", "sequence_length", "\n", "# dummy scalar list", "\n", "scalar_list", "=", "[", "]", "\n", "\n", "agent_statistics", "=", "torch", ".", "ones", "(", "batch_size", ",", "SFS", ".", "agent_statistics", ")", "\n", "home_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "home_race", ")", "\n", "away_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "away_race", ")", "\n", "upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "enemy_upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "time", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "time", ")", "\n", "\n", "available_actions", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "available_actions", ")", "\n", "unit_counts_bow", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "mmr", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "mmr", ")", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "units_buildings", ")", "\n", "effects", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "effects", ")", "\n", "upgrade", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrade", ")", "\n", "\n", "beginning_build_order", "=", "torch", ".", "randn", "(", "batch_size", ",", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "last_delay", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_delay", ")", "\n", "last_action_type", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_action_type", ")", "\n", "last_repeat_queued", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_repeat_queued", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "home_race", ")", "\n", "scalar_list", ".", "append", "(", "away_race", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "enemy_upgrades", ")", "\n", "scalar_list", ".", "append", "(", "time", ")", "\n", "\n", "scalar_list", ".", "append", "(", "available_actions", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "mmr", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "scalar_list", ".", "append", "(", "last_delay", ")", "\n", "scalar_list", ".", "append", "(", "last_action_type", ")", "\n", "scalar_list", ".", "append", "(", "last_repeat_queued", ")", "\n", "\n", "# dummy entity list", "\n", "e_list", "=", "[", "]", "\n", "e1", "=", "Entity", "(", "115", ",", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "0", ",", "100", ",", "60", ",", "50", ",", "4", ",", "8", ",", "95", ",", "0.2", ",", "0.0", ",", "0.0", ",", "140", ",", "60", ",", "100", ",", "\n", "1", ",", "123", ",", "218", ",", "3", ",", "True", ",", "False", ",", "True", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "3.0", ",", "[", "2", ",", "3", "]", ",", "2", ",", "1", ",", "0", ",", "True", ",", "False", ")", "\n", "e2", "=", "Entity", "(", "1908", ",", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "2", ",", "1500", ",", "0", ",", "200", ",", "0", ",", "4", ",", "15", ",", "0.5", ",", "0.8", ",", "0.5", ",", "1500", ",", "0", ",", "250", ",", "\n", "2", ",", "69", ",", "7", ",", "3", ",", "True", ",", "False", ",", "False", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "10", ",", "16", ",", "0.0", ",", "[", "1", "]", ",", "1", ",", "1", ",", "0", ",", "False", ",", "False", ")", "\n", "e_list", ".", "append", "(", "e1", ")", "\n", "e_list", ".", "append", "(", "e2", ")", "\n", "\n", "# preprocess entity list", "\n", "entities_tensor", "=", "agent", ".", "model", ".", "preprocess_entity", "(", "e_list", ")", "\n", "print", "(", "'entities_tensor.shape:'", ",", "entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "batch_entities_tensor", "=", "torch", ".", "unsqueeze", "(", "entities_tensor", ",", "dim", "=", "0", ")", "\n", "batch_entities_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "batch_entities_tensor_copy", "=", "batch_entities_tensor", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "batch_entities_list", ".", "append", "(", "batch_entities_tensor_copy", ")", "\n", "\n", "", "batch_entities_tensor", "=", "torch", ".", "cat", "(", "batch_entities_list", ",", "dim", "=", "0", ")", "\n", "print", "(", "'batch_entities_tensor.shape:'", ",", "batch_entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# dummy map list", "\n", "map_list", "=", "[", "]", "\n", "map_data_1", "=", "torch", ".", "zeros", "(", "batch_size", ",", "1", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_data_1_one_hot", "=", "L", ".", "to_one_hot", "(", "map_data_1", ",", "2", ")", "\n", "print", "(", "'map_data_1_one_hot.shape:'", ",", "map_data_1_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "map_list", ".", "append", "(", "map_data_1", ")", "\n", "map_data_2", "=", "torch", ".", "zeros", "(", "batch_size", ",", "17", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_list", ".", "append", "(", "map_data_2", ")", "\n", "map_data", "=", "torch", ".", "cat", "(", "map_list", ",", "dim", "=", "1", ")", "\n", "\n", "state", "=", "MsState", "(", "entity_state", "=", "batch_entities_tensor", ",", "statistical_state", "=", "scalar_list", ",", "map_state", "=", "map_data", ")", "\n", "\n", "print", "(", "\"Multi-source state:\"", ",", "state", ")", "if", "1", "else", "None", "\n", "\n", "action", "=", "agent", ".", "action_by_state", "(", "state", ")", "\n", "print", "(", "\"action is:\"", ",", "action", ")", "if", "1", "else", "None", "\n", "\n", "action_logits", ",", "actions", ",", "hidden_state", "=", "agent", ".", "action_logits_by_state", "(", "state", ")", "\n", "print", "(", "\"action_logits is:\"", ",", "action_logits", ")", "if", "1", "else", "None", "\n", "print", "(", "\"actions is:\"", ",", "actions", ")", "if", "1", "else", "None", "\n", "\n", "if", "debug", ":", "\n", "        ", "print", "(", "\"This is a test!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.target_unit_head.TargetUnitHead.__init__": [[29, 56], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "embedding_size", "=", "AHP", ".", "entity_embedding_size", ",", "\n", "max_number_of_unit_types", "=", "SCHP", ".", "max_unit_type", ",", "\n", "is_sl_training", "=", "True", ",", "temperature", "=", "0.8", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "original_32", "=", "AHP", ".", "original_32", ",", "\n", "max_selected", "=", "1", ",", "autoregressive_embedding_size", "=", "AHP", ".", "autoregressive_embedding_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_sl_training", "=", "is_sl_training", "\n", "if", "not", "self", ".", "is_sl_training", ":", "\n", "            ", "self", ".", "temperature", "=", "temperature", "\n", "", "else", ":", "\n", "            ", "self", ".", "temperature", "=", "1.0", "\n", "\n", "", "self", ".", "max_number_of_unit_types", "=", "max_number_of_unit_types", "\n", "self", ".", "func_embed", "=", "nn", ".", "Linear", "(", "max_number_of_unit_types", ",", "original_256", ")", "# with relu", "\n", "\n", "self", ".", "conv_1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "embedding_size", ",", "\n", "out_channels", "=", "original_32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "autoregressive_embedding_size", ",", "original_256", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_32", ")", "\n", "\n", "self", ".", "small_lstm", "=", "nn", ".", "LSTM", "(", "original_32", ",", "original_32", ",", "1", ",", "dropout", "=", "0.0", ",", "batch_first", "=", "True", ")", "\n", "\n", "# We mostly target one unit", "\n", "self", ".", "max_selected", "=", "1", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.target_unit_head.TargetUnitHead.preprocess": [[57, 59], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.target_unit_head.TargetUnitHead.forward": [[60, 186], ["alphastarmini.lib.utils.action_can_apply_to_entity_types_mask", "unit_types_one_hot.to.to.to", "torch.relu", "torch.relu", "torch.relu", "target_unit_head.TargetUnitHead.conv_1().transpose", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "alphastarmini.lib.utils.action_involve_targeting_units_mask", "next", "target_unit_head.TargetUnitHead.func_embed", "print", "print", "print", "print", "target_unit_head.TargetUnitHead.fc_1", "target_unit_head.TargetUnitHead.fc_2", "z_2.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "y.squeeze.squeeze.squeeze", "y.squeeze.squeeze.div", "target_unit_head.TargetUnitHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "target_unit_logits_list.append", "target_unit_list.append", "print", "print", "print", "alphastarmini.lib.utils.action_involve_targeting_units_mask.float().unsqueeze", "print", "alphastarmini.lib.utils.action_involve_targeting_units_mask.long().unsqueeze", "target_unit_head.TargetUnitHead.parameters", "target_unit_head.TargetUnitHead.conv_1", "print", "print", "print", "print", "print", "print", "target_unit_head.TargetUnitHead.small_lstm", "target_unit_head.TargetUnitHead.small_lstm", "print", "print", "query.transpose", "print", "print", "print", "print", "print", "print", "y.squeeze.div.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "torch.multinomial.unsqueeze", "entity_embeddings.transpose", "alphastarmini.lib.utils.action_involve_targeting_units_mask.float", "alphastarmini.lib.utils.action_involve_targeting_units_mask.long"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_apply_to_entity_types_mask", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_units_mask"], ["", "def", "forward", "(", "self", ",", "autoregressive_embedding", ",", "action_type", ",", "entity_embeddings", ")", ":", "\n", "        ", "'''\n        Inputs:\n            autoregressive_embedding: [batch_size x autoregressive_embedding_size]\n            action_type: [batch_size x 1]\n            entity_embeddings: [batch_size x entity_size x embedding_size]\n        Output:\n            target_unit_logits: [batch_size x max_selected x entity_size]\n            target_unit: [batch_size x max_selected x 1]\n        '''", "\n", "\n", "batch_size", "=", "entity_embeddings", ".", "shape", "[", "0", "]", "\n", "assert", "autoregressive_embedding", ".", "shape", "[", "0", "]", "==", "action_type", ".", "shape", "[", "0", "]", "\n", "assert", "autoregressive_embedding", ".", "shape", "[", "0", "]", "==", "entity_embeddings", ".", "shape", "[", "0", "]", "\n", "# entity_embeddings shape is [batch_size x entity_size x embedding_size]", "\n", "entity_size", "=", "entity_embeddings", ".", "shape", "[", "-", "2", "]", "\n", "\n", "# `func_embed` is computed the same as in the Selected Units head, ", "\n", "# and used in the same way for the query (added to the output of the `autoregressive_embedding` ", "\n", "# passed through a linear of size 256).", "\n", "unit_types_one_hot", "=", "L", ".", "action_can_apply_to_entity_types_mask", "(", "action_type", ")", "\n", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "unit_types_one_hot", "=", "unit_types_one_hot", ".", "to", "(", "device", ")", "\n", "\n", "assert", "unit_types_one_hot", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "max_number_of_unit_types", "\n", "# unit_types_mask shape: [batch_size x self.max_number_of_unit_types]", "\n", "the_func_embed", "=", "F", ".", "relu", "(", "self", ".", "func_embed", "(", "unit_types_one_hot", ")", ")", "\n", "# the_func_embed shape: [batch_size x 256]", "\n", "print", "(", "\"the_func_embed:\"", ",", "the_func_embed", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"the_func_embed.shape:\"", ",", "the_func_embed", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# Because we mostly target one unit, we don't need a mask.", "\n", "\n", "# The query is then passed through a ReLU and a linear of size 32, ", "\n", "# and the query is applied to the keys which are created the ", "\n", "# same way as in the Selected Units head to get `target_unit_logits`.", "\n", "# input : [batch_size x entity_size x embedding_size]", "\n", "key", "=", "self", ".", "conv_1", "(", "entity_embeddings", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "# output : [batch_size x entity_size x key_size], note key_size = 32", "\n", "print", "(", "\"key:\"", ",", "key", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"key.shape:\"", ",", "key", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit_logits_list", "=", "[", "]", "\n", "target_unit_list", "=", "[", "]", "\n", "hidden", "=", "None", "\n", "\n", "# note: repeated for selecting up to one unit", "\n", "max_selected", "=", "self", ".", "max_selected", "\n", "for", "i", "in", "range", "(", "max_selected", ")", ":", "\n", "            ", "x", "=", "self", ".", "fc_1", "(", "autoregressive_embedding", ")", "\n", "print", "(", "\"x:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "assert", "the_func_embed", ".", "shape", "==", "x", ".", "shape", "\n", "z_1", "=", "the_func_embed", "+", "x", "\n", "print", "(", "\"z_1:\"", ",", "z_1", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"z_1.shape:\"", ",", "z_1", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "z_2", "=", "self", ".", "fc_2", "(", "z_1", ")", "\n", "print", "(", "\"z_2:\"", ",", "z_2", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"z_2.shape:\"", ",", "z_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "z_2", "=", "z_2", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# The result is fed into a LSTM with size 32 and zero initial state to get a query.", "\n", "if", "i", "==", "0", ":", "\n", "                ", "query", ",", "hidden", "=", "self", ".", "small_lstm", "(", "z_2", ")", "\n", "", "else", ":", "\n", "                ", "query", ",", "hidden", "=", "self", ".", "small_lstm", "(", "z_2", ",", "hidden", ")", "\n", "", "print", "(", "\"query:\"", ",", "query", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"query.shape:\"", ",", "query", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: The query is then passed through a ReLU and a linear of size 32, ", "\n", "# AlphaStar: and the query is applied to the keys which are created the same way as in ", "\n", "# AlphaStar: the Selected Units head to get `target_unit_logits`.", "\n", "\n", "# below is matrix multiply", "\n", "# key_shape: [batch_size x entity_size x key_size], note key_size = 32", "\n", "# query_shape: [batch_size x seq_len x hidden_size], note hidden_size is also 32, seq_len = 1", "\n", "y", "=", "torch", ".", "bmm", "(", "key", ",", "query", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "print", "(", "\"y:\"", ",", "y", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"y.shape:\"", ",", "y", ".", "shape", ")", "if", "debug", "else", "None", "\n", "y", "=", "y", ".", "squeeze", "(", "-", "1", ")", "\n", "# y shape: [batch_size x entity_size]", "\n", "\n", "target_unit_logits", "=", "y", ".", "div", "(", "self", ".", "temperature", ")", "\n", "# target_unit_logits shape: [batch_size x entity_size]", "\n", "print", "(", "\"target_unit_logits:\"", ",", "target_unit_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_unit_logits.shape:\"", ",", "target_unit_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit_probs", "=", "self", ".", "softmax", "(", "target_unit_logits", ")", "\n", "# target_unit_probs shape: [batch_size x entity_size]", "\n", "\n", "# AlphaStar: `target_unit` is sampled from `target_unit_logits` using a multinomial with temperature 0.8.", "\n", "target_unit_id", "=", "torch", ".", "multinomial", "(", "target_unit_probs", ",", "1", ")", "\n", "# target_unit_id shape: [batch_size x 1]", "\n", "print", "(", "\"target_unit_id:\"", ",", "target_unit_id", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_unit_id.shape:\"", ",", "target_unit_id", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# note, we add a dimension where is in the seq_one to help", "\n", "# we concat to the one : [batch_size x max_selected x ?]", "\n", "target_unit_logits_list", ".", "append", "(", "target_unit_logits", ".", "unsqueeze", "(", "-", "2", ")", ")", "\n", "target_unit_list", ".", "append", "(", "target_unit_id", ".", "unsqueeze", "(", "-", "2", ")", ")", "\n", "\n", "# Note that since this is one of the two terminal arguments (along ", "\n", "# with Location Head, since no action has both a target unit and a ", "\n", "# target location), it does not return `autoregressive_embedding`.", "\n", "\n", "# note: we only select one unit, so return the first one", "\n", "", "target_unit_logits", "=", "torch", ".", "cat", "(", "target_unit_logits_list", ",", "dim", "=", "1", ")", "\n", "# target_unit_logits: [batch_size x max_selected x entity_size]", "\n", "target_unit", "=", "torch", ".", "cat", "(", "target_unit_list", ",", "dim", "=", "1", ")", "\n", "# target_units: [batch_size x max_selected x 1]", "\n", "\n", "# AlphaStar: If `action_type` does not involve targetting units, this head is ignored.", "\n", "target_unit_mask", "=", "L", ".", "action_involve_targeting_units_mask", "(", "action_type", ")", "\n", "# target_unit_mask: [batch_size x 1]", "\n", "print", "(", "\"target_unit_mask:\"", ",", "target_unit_mask", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"target_unit_logits.shape:\"", ",", "target_unit_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_unit_mask.shape:\"", ",", "target_unit_mask", ".", "shape", ")", "if", "debug", "else", "None", "\n", "target_unit_logits", "=", "target_unit_logits", "*", "target_unit_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "print", "(", "\"target_unit.shape:\"", ",", "target_unit", ".", "shape", ")", "if", "debug", "else", "None", "\n", "target_unit", "=", "target_unit", "*", "target_unit_mask", ".", "long", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "return", "target_unit_logits", ",", "target_unit", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.target_unit_head.test": [[188, 217], ["torch.randn", "torch.randn", "torch.randn", "torch.randint", "torch.randint", "torch.randint", "torch.randn", "torch.randn", "torch.randn", "target_unit_head.TargetUnitHead", "target_unit_head.TargetUnitHead.forward", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "action_type_sample", "=", "352", "# func: 352/Effect_WidowMineAttack_unit (1/queued [2]; 2/unit_tags [512]; 3/target_unit_tag [512])", "\n", "\n", "batch_size", "=", "2", "\n", "autoregressive_embedding", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "action_type", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "SFS", ".", "available_actions", ",", "size", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "entity_embeddings", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "max_entities", ",", "AHP", ".", "entity_embedding_size", ")", "\n", "\n", "target_units_head", "=", "TargetUnitHead", "(", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit_logits", ",", "target_unit", "=", "target_units_head", ".", "forward", "(", "autoregressive_embedding", ",", "action_type", ",", "entity_embeddings", ")", "\n", "\n", "if", "target_unit_logits", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_unit_logits:\"", ",", "target_unit_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_unit_logits.shape:\"", ",", "target_unit_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_unit_logits is None!\"", ")", "\n", "\n", "", "if", "target_unit", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_unit:\"", ",", "target_unit", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_unit.shape:\"", ",", "target_unit", ".", "shape", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_unit is None!\"", ")", "\n", "\n", "", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.action_type_head.ActionTypeHead.__init__": [[34, 69], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "alphastarmini.lib.glu.GLU", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.lib.glu.GLU", "alphastarmini.lib.glu.GLU", "torch.Softmax", "torch.Softmax", "torch.Softmax", "alphastarmini.core.arch.spatial_encoder.ResBlock1D", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "lstm_dim", "=", "AHP", ".", "lstm_hidden_dim", ",", "n_resblocks", "=", "AHP", ".", "n_resblocks", ",", "\n", "is_sl_training", "=", "True", ",", "temperature", "=", "0.8", ",", "original_256", "=", "AHP", ".", "original_256", ",", "\n", "max_action_num", "=", "LS", ".", "action_type_encoding", ",", "context_size", "=", "AHP", ".", "context_size", ",", "\n", "autoregressive_embedding_size", "=", "AHP", ".", "autoregressive_embedding_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_sl_training", "=", "is_sl_training", "\n", "if", "not", "self", ".", "is_sl_training", ":", "\n", "            ", "self", ".", "temperature", "=", "temperature", "\n", "", "else", ":", "\n", "            ", "self", ".", "temperature", "=", "1.0", "\n", "\n", "", "self", ".", "embed_fc", "=", "nn", ".", "Linear", "(", "lstm_dim", ",", "original_256", ")", "# with relu", "\n", "self", ".", "resblock_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ResBlock1D", "(", "inplanes", "=", "original_256", ",", "planes", "=", "original_256", ",", "seq_len", "=", "1", ")", "\n", "for", "_", "in", "range", "(", "n_resblocks", ")", "]", ")", "\n", "\n", "self", ".", "max_action_num", "=", "max_action_num", "\n", "\n", "# Function.raw_ability(35, \"Build_Pylon_pt\", raw_cmd_pt, 881),", "\n", "# Function.raw_ability(64, \"Train_Probe_quick\", raw_cmd, 1006),", "\n", "# Function.raw_ui_func(0, \"no_op\", raw_no_op),", "\n", "# Function.raw_ui_func(168, \"raw_move_camera\", raw_move_camera),", "\n", "# Function.raw_ability(1, \"Smart_pt\", raw_cmd_pt, 1),", "\n", "\n", "# or all other HAS functions", "\n", "\n", "self", ".", "glu_1", "=", "GLU", "(", "input_size", "=", "original_256", ",", "context_size", "=", "context_size", ",", "\n", "output_size", "=", "self", ".", "max_action_num", ")", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "self", ".", "max_action_num", ",", "original_256", ")", "\n", "self", ".", "glu_2", "=", "GLU", "(", "input_size", "=", "original_256", ",", "context_size", "=", "context_size", ",", "\n", "output_size", "=", "autoregressive_embedding_size", ")", "\n", "self", ".", "glu_3", "=", "GLU", "(", "input_size", "=", "lstm_dim", ",", "context_size", "=", "context_size", ",", "\n", "output_size", "=", "autoregressive_embedding_size", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.action_type_head.ActionTypeHead.preprocess": [[70, 72], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.action_type_head.ActionTypeHead.forward": [[73, 159], ["action_type_head.ActionTypeHead.embed_fc", "resblock.unsqueeze", "torch.relu", "torch.relu", "torch.relu", "resblock.squeeze", "action_type_head.ActionTypeHead.glu_1", "action_type_head.ActionTypeHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "action_type.reshape.reshape.reshape", "alphastarmini.lib.utils.to_one_hot", "action_type_one_hot.squeeze.squeeze.squeeze", "torch.relu", "torch.relu", "torch.relu", "action_type_head.ActionTypeHead.glu_2", "action_type_head.ActionTypeHead.glu_3", "resblock", "print", "print", "print", "print", "action_type_head.ActionTypeHead.reshape", "print", "print", "print", "print", "action_type.reshape.reshape.get_device", "next", "print", "print", "action_type_one_hot.squeeze.squeeze.get_device", "action_type_head.ActionTypeHead.fc_1", "print", "print", "print", "print", "action_type_head.ActionTypeHead.parameters"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot"], ["", "def", "forward", "(", "self", ",", "lstm_output", ",", "scalar_context", ")", ":", "\n", "        ", "batch_size", "=", "lstm_output", ".", "shape", "[", "0", "]", "\n", "\n", "# AlphaStar: The action type head embeds `lstm_output` into a 1D tensor of size 256", "\n", "x", "=", "self", ".", "embed_fc", "(", "lstm_output", ")", "\n", "\n", "# AlphaStar: passes it through 16 ResBlocks with layer normalization each of size 256, and applies a ReLU. ", "\n", "# QUESTION: There is no map, how to use resblocks?", "\n", "# ANSWER: USE resblock1D", "\n", "# input shape is [batch_size x seq_size x embedding_size]", "\n", "# note that embedding_size is equal to channel_size in conv1d", "\n", "# we change this to [batch_size x embedding_size x seq_size]", "\n", "#x = x.transpose(1, 2)", "\n", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "\n", "for", "resblock", "in", "self", ".", "resblock_stack", ":", "\n", "            ", "x", "=", "resblock", "(", "x", ")", "\n", "", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "#x = transpose(1, 2)", "\n", "x", "=", "x", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# AlphaStar: The output is converted to a tensor with one logit for each possible ", "\n", "# AlphaStar: action type through a `GLU` gated by `scalar_context`.", "\n", "action_type_logits", "=", "self", ".", "glu_1", "(", "x", ",", "scalar_context", ")", "\n", "print", "(", "\"action_type_logits:\"", ",", "action_type_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type_logits.shape:\"", ",", "action_type_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: `action_type` is sampled from these logits using a multinomial with temperature 0.8. ", "\n", "# AlphaStar: Note that during supervised learning, `action_type` will be the ground truth human action ", "\n", "# AlphaStar: type, and temperature is 1.0 (and similarly for all other arguments).", "\n", "action_type_logits", "=", "action_type_logits", "/", "self", ".", "temperature", "\n", "\n", "action_type_probs", "=", "self", ".", "softmax", "(", "action_type_logits", ")", "\n", "print", "(", "\"action_type_probs:\"", ",", "action_type_probs", ")", "if", "1", "else", "None", "\n", "print", "(", "\"action_type_probs.shape:\"", ",", "action_type_probs", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# note, torch.multinomial need samples to non-negative, finite and have a non-zero sum", "\n", "# which is different with tf.multinomial which can accept negative values like log(action_type_probs)", "\n", "action_type", "=", "torch", ".", "multinomial", "(", "action_type_probs", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", ",", "1", ")", "\n", "#action_type = stable_multinomial(logits=action_type_logits, temperature=self.temperature)", "\n", "print", "(", "\"action_type:\"", ",", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type.shape:\"", ",", "action_type", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "action_type", "=", "action_type", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "print", "(", "\"action_type:\"", ",", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type.shape:\"", ",", "action_type", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "cuda_check", "=", "action_type", ".", "is_cuda", "\n", "if", "cuda_check", ":", "\n", "            ", "get_cuda_device", "=", "action_type", ".", "get_device", "(", ")", "\n", "\n", "", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "# change action_type to one_hot version", "\n", "action_type_one_hot", "=", "L", ".", "to_one_hot", "(", "action_type", ",", "self", ".", "max_action_num", ")", "\n", "print", "(", "\"action_type_one_hot:\"", ",", "action_type_one_hot", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type_one_hot.shape:\"", ",", "action_type_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# to make the dim of delay_one_hot as delay", "\n", "action_type_one_hot", "=", "action_type_one_hot", ".", "squeeze", "(", "-", "2", ")", "\n", "\n", "cuda_check", "=", "action_type_one_hot", ".", "is_cuda", "\n", "if", "cuda_check", ":", "\n", "            ", "get_cuda_device", "=", "action_type_one_hot", ".", "get_device", "(", ")", "\n", "\n", "# AlphaStar: `autoregressive_embedding` is then generated by first applying a ReLU ", "\n", "# AlphaStar: and linear layer of size 256 to the one-hot version of `action_type`", "\n", "", "z", "=", "F", ".", "relu", "(", "self", ".", "fc_1", "(", "action_type_one_hot", ")", ")", "\n", "# AlphaStar: and projecting it to a 1D tensor of size 1024 through a `GLU` gated by `scalar_context`.", "\n", "z", "=", "self", ".", "glu_2", "(", "z", ",", "scalar_context", ")", "\n", "# AlphaStar: That projection is added to another projection of `lstm_output` into a 1D tensor of size ", "\n", "# AlphaStar: 1024 gated by `scalar_context` to yield `autoregressive_embedding`.", "\n", "#lstm_output = lstm_output.reshape(-1, lstm_output.shape[-1])", "\n", "\n", "print", "(", "\"lstm_output:\"", ",", "lstm_output", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"lstm_output.shape:\"", ",", "lstm_output", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "t", "=", "self", ".", "glu_3", "(", "lstm_output", ",", "scalar_context", ")", "\n", "print", "(", "\"t:\"", ",", "t", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"t.shape:\"", ",", "t", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# the add operation may auto broadcasting, so we need an assert test", "\n", "\n", "assert", "z", ".", "shape", "==", "t", ".", "shape", "\n", "autoregressive_embedding", "=", "z", "+", "t", "\n", "\n", "return", "action_type_logits", ",", "action_type", ",", "autoregressive_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.action_type_head.test": [[161, 183], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "action_type_head.ActionTypeHead", "action_type_head.ActionTypeHead.forward", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "lstm_output", "=", "torch", ".", "randn", "(", "batch_size", "*", "AHP", ".", "sequence_length", ",", "AHP", ".", "lstm_hidden_dim", ")", "\n", "scalar_context", "=", "torch", ".", "randn", "(", "batch_size", "*", "AHP", ".", "sequence_length", ",", "AHP", ".", "context_size", ")", "\n", "action_type_head", "=", "ActionTypeHead", "(", ")", "\n", "\n", "print", "(", "\"lstm_output:\"", ",", "lstm_output", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"lstm_output.shape:\"", ",", "lstm_output", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"scalar_context:\"", ",", "scalar_context", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"scalar_context.shape:\"", ",", "scalar_context", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "action_type_logits", ",", "action_type", ",", "autoregressive_embedding", "=", "action_type_head", ".", "forward", "(", "lstm_output", ",", "scalar_context", ")", "\n", "\n", "print", "(", "\"action_type_logits:\"", ",", "action_type_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type_logits.shape:\"", ",", "action_type_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type:\"", ",", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_type.shape:\"", ",", "action_type", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.queue_head.QueueHead.__init__": [[29, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "AHP", ".", "autoregressive_embedding_size", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "\n", "max_queue", "=", "SFS", ".", "last_repeat_queued", ",", "is_sl_training", "=", "True", ",", "temperature", "=", "0.8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_sl_training", "=", "is_sl_training", "\n", "if", "not", "self", ".", "is_sl_training", ":", "\n", "            ", "self", ".", "temperature", "=", "temperature", "\n", "", "else", ":", "\n", "            ", "self", ".", "temperature", "=", "1.0", "\n", "\n", "", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "input_size", ",", "original_256", ")", "# with relu", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_256", ")", "# with relu", "\n", "self", ".", "max_queue", "=", "max_queue", "\n", "\n", "self", ".", "embed_fc", "=", "nn", ".", "Linear", "(", "original_256", ",", "max_queue", ")", "# no relu", "\n", "\n", "self", ".", "fc_3", "=", "nn", ".", "Linear", "(", "max_queue", ",", "original_256", ")", "# with relu", "\n", "self", ".", "fc_4", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_256", ")", "# with relu", "\n", "self", ".", "project", "=", "nn", ".", "Linear", "(", "original_256", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.queue_head.QueueHead.preprocess": [[52, 54], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.queue_head.QueueHead.forward": [[56, 99], ["queue_head.QueueHead.fc_1", "queue_head.QueueHead.relu", "queue_head.QueueHead.fc_2", "queue_head.QueueHead.relu", "queue_head.QueueHead.embed_fc().div", "queue_head.QueueHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "alphastarmini.lib.utils.one_hot_embedding", "queue_one_hot.squeeze.squeeze.squeeze", "queue_head.QueueHead.relu", "queue_head.QueueHead.relu", "queue_head.QueueHead.project", "alphastarmini.lib.utils.action_can_be_queued_mask().float", "print", "queue_head.QueueHead.fc_3", "queue_head.QueueHead.fc_4", "print", "queue_head.QueueHead.embed_fc", "alphastarmini.lib.utils.action_can_be_queued_mask"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.one_hot_embedding", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_can_be_queued_mask"], ["", "def", "forward", "(", "self", ",", "autoregressive_embedding", ",", "action_type", ",", "embedded_entity", "=", "None", ")", ":", "\n", "# AlphaStar: Queued Head is similar to the delay head except a temperature of 0.8 ", "\n", "# AlphaStar: is applied to the logits before sampling,", "\n", "        ", "x", "=", "self", ".", "fc_1", "(", "autoregressive_embedding", ")", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "fc_2", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "# note: temperature is used here, compared to delay head", "\n", "queue_logits", "=", "self", ".", "embed_fc", "(", "x", ")", ".", "div", "(", "self", ".", "temperature", ")", "\n", "queue_probs", "=", "self", ".", "softmax", "(", "queue_logits", ")", "\n", "# AlphaStar: the size of `queued_logits` is 2 (for queueing and not queueing),", "\n", "queue", "=", "torch", ".", "multinomial", "(", "queue_probs", ",", "1", ")", "\n", "\n", "# similar to action_type here, change it to one_hot version", "\n", "queue_one_hot", "=", "L", ".", "one_hot_embedding", "(", "queue", ",", "self", ".", "max_queue", ")", "\n", "# to make the dim of queue_one_hot as queue", "\n", "queue_one_hot", "=", "queue_one_hot", ".", "squeeze", "(", "-", "2", ")", "\n", "\n", "z", "=", "self", ".", "relu", "(", "self", ".", "fc_3", "(", "queue_one_hot", ")", ")", "\n", "z", "=", "self", ".", "relu", "(", "self", ".", "fc_4", "(", "z", ")", ")", "\n", "t", "=", "self", ".", "project", "(", "z", ")", "\n", "# make sure autoregressive_embedding has the same shape as y, prevent the auto broadcasting", "\n", "assert", "autoregressive_embedding", ".", "shape", "==", "t", ".", "shape", "\n", "\n", "# AlphaStar: and the projected `queued` is not added to `autoregressive_embedding` ", "\n", "# AlphaStar: if queuing is not possible for the chosen `action_type`", "\n", "# note: projected `queued` is not added to `autoregressive_embedding` if queuing is not ", "\n", "# possible for the chosen `action_type`", "\n", "\n", "assert", "action_type", ".", "shape", "[", "0", "]", "==", "autoregressive_embedding", ".", "shape", "[", "0", "]", "\n", "mask", "=", "L", ".", "action_can_be_queued_mask", "(", "action_type", ")", ".", "float", "(", ")", "\n", "print", "(", "\"mask:\"", ",", "mask", ")", "if", "debug", "else", "None", "\n", "autoregressive_embedding", "=", "autoregressive_embedding", "+", "mask", "*", "t", "\n", "\n", "''' # below code only consider the cases when action_type is scalar\n        if L.action_can_be_queued(action_type):\n            autoregressive_embedding = autoregressive_embedding + t\n        else:\n            print(\"None add to autoregressive_embedding!\") if debug else None\n        '''", "\n", "\n", "return", "queue_logits", ",", "queue", ",", "autoregressive_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.queue_head.test": [[101, 120], ["torch.randn", "torch.randn", "torch.randn", "torch.randint", "torch.randint", "torch.randint", "queue_head.QueueHead", "queue_head.QueueHead.forward", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "autoregressive_embedding", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "action_type", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "SFS", ".", "available_actions", ",", "size", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "queue_head", "=", "QueueHead", "(", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "queue_logits", ",", "queue", ",", "autoregressive_embedding", "=", "queue_head", ".", "forward", "(", "autoregressive_embedding", ",", "action_type", ")", "\n", "\n", "print", "(", "\"queue_logits:\"", ",", "queue_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"queue_logits.shape:\"", ",", "queue_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"queue:\"", ",", "queue", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"queue.shape:\"", ",", "queue", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.ResBlockFiLM.__init__": [[29, 37], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "location_head.ResBlockFiLM.reset"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset"], ["    ", "def", "__init__", "(", "self", ",", "filter_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "filter_size", ",", "filter_size", ",", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "filter_size", ",", "filter_size", ",", "kernel_size", "=", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "filter_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.ResBlockFiLM.forward": [[38, 53], ["location_head.ResBlockFiLM.conv1", "torch.relu", "torch.relu", "torch.relu", "location_head.ResBlockFiLM.conv2", "location_head.ResBlockFiLM.bn", "gamma.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "beta.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "torch.relu", "torch.relu", "torch.relu", "gamma.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "beta.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "gamma", ",", "beta", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "resid", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "resid", ")", "\n", "out", "=", "self", ".", "bn", "(", "out", ")", "\n", "\n", "gamma", "=", "gamma", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "beta", "=", "beta", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "out", "=", "gamma", "*", "out", "+", "beta", "\n", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "out", "+", "resid", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.ResBlockFiLM.reset": [[54, 60], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# deprecated, should try to find others", "\n", "# kaiming_uniform(self.conv1.weight)", "\n", "# self.conv1.bias.data.zero_()", "\n", "# kaiming_uniform(self.conv2.weight)", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.FiLM.__init__": [[63, 73], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Linear", "torch.Linear", "torch.Linear", "location_head.FiLM.resblocks.append", "location_head.ResBlockFiLM"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_resblock", "=", "4", ",", "conv_hidden", "=", "128", ",", "gate_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_resblock", "=", "n_resblock", "\n", "self", ".", "conv_hidden", "=", "conv_hidden", "\n", "\n", "self", ".", "resblocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_resblock", ")", ":", "\n", "            ", "self", ".", "resblocks", ".", "append", "(", "ResBlockFiLM", "(", "conv_hidden", ")", ")", "\n", "\n", "", "self", ".", "film_net", "=", "nn", ".", "Linear", "(", "gate_size", ",", "conv_hidden", "*", "2", "*", "n_resblock", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.FiLM.reset": [[74, 79], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# deprecated, should try to find others", "\n", "# kaiming_uniform(self.film_net.weight)", "\n", "# self.film_net.bias.data.zero_()", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.FiLM.forward": [[80, 88], ["location_head.FiLM.film_net().chunk", "enumerate", "resblock", "location_head.FiLM.film_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "gate", ")", ":", "\n", "        ", "out", "=", "x", "\n", "film", "=", "self", ".", "film_net", "(", "gate", ")", ".", "chunk", "(", "self", ".", "n_resblock", "*", "2", ",", "1", ")", "\n", "\n", "for", "i", ",", "resblock", "in", "enumerate", "(", "self", ".", "resblocks", ")", ":", "\n", "            ", "out", "=", "resblock", "(", "out", ",", "film", "[", "i", "*", "2", "]", ",", "film", "[", "i", "*", "2", "+", "1", "]", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.LocationHead.__init__": [[98, 138], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "location_head.FiLM", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Softmax", "torch.Softmax", "torch.Softmax", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "autoregressive_embedding_size", "=", "AHP", ".", "autoregressive_embedding_size", ",", "\n", "output_map_size", "=", "SCHP", ".", "world_size", ",", "is_sl_training", "=", "True", ",", "\n", "max_map_channels", "=", "AHP", ".", "location_head_max_map_channels", ",", "\n", "temperature", "=", "0.8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_sl_training", "=", "is_sl_training", "\n", "if", "not", "self", ".", "is_sl_training", ":", "\n", "            ", "self", ".", "temperature", "=", "temperature", "\n", "", "else", ":", "\n", "            ", "self", ".", "temperature", "=", "1.0", "\n", "\n", "", "mmc", "=", "max_map_channels", "\n", "\n", "self", ".", "ds_1", "=", "nn", ".", "Conv2d", "(", "mmc", "+", "4", ",", "mmc", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "film_net", "=", "FiLM", "(", "n_resblock", "=", "4", ",", "conv_hidden", "=", "mmc", ",", "gate_size", "=", "autoregressive_embedding_size", ")", "\n", "\n", "self", ".", "us_1", "=", "nn", ".", "ConvTranspose2d", "(", "mmc", ",", "int", "(", "mmc", "/", "2", ")", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "us_2", "=", "nn", ".", "ConvTranspose2d", "(", "int", "(", "mmc", "/", "2", ")", ",", "int", "(", "mmc", "/", "4", ")", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "us_3", "=", "nn", ".", "ConvTranspose2d", "(", "int", "(", "mmc", "/", "4", ")", ",", "int", "(", "mmc", "/", "8", ")", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "us_4", "=", "nn", ".", "ConvTranspose2d", "(", "int", "(", "mmc", "/", "8", ")", ",", "int", "(", "mmc", "/", "16", ")", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "us_4_original", "=", "nn", ".", "ConvTranspose2d", "(", "int", "(", "mmc", "/", "8", ")", ",", "1", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "# note: in mAS, we add a upsampling layer to transfer from 8x8 to 256x256", "\n", "self", ".", "us_5", "=", "nn", ".", "ConvTranspose2d", "(", "int", "(", "mmc", "/", "16", ")", ",", "1", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "output_map_size", "=", "output_map_size", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.LocationHead.preprocess": [[139, 141], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.LocationHead.forward": [[142, 272], ["int", "autoregressive_embedding.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "location_head.LocationHead.film_net", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu.reshape", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "y_2.div", "location_head.LocationHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial.squeeze().cpu().numpy().tolist", "torch.multinomial.squeeze().cpu().numpy().tolist", "torch.multinomial.squeeze().cpu().numpy().tolist", "enumerate", "alphastarmini.lib.utils.action_involve_targeting_location_mask", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "target_location_logits.reshape.reshape.reshape", "print", "print", "print", "print", "location_head.LocationHead.ds_1", "location_head.LocationHead.us_1", "location_head.LocationHead.us_2", "location_head.LocationHead.us_3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "print", "next", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "alphastarmini.lib.utils.action_involve_targeting_location_mask.float().unsqueeze", "alphastarmini.lib.utils.action_involve_targeting_location_mask.long", "torch.relu", "torch.relu", "torch.relu", "location_head.LocationHead.us_4", "location_head.LocationHead.us_5", "location_head.LocationHead.us_4_original", "location_head.LocationHead.parameters", "torch.multinomial.squeeze().cpu().numpy", "torch.multinomial.squeeze().cpu().numpy", "torch.multinomial.squeeze().cpu().numpy", "target_location_x.item", "target_location_y.item", "print", "print", "alphastarmini.lib.utils.action_involve_targeting_location_mask.float", "torch.multinomial.squeeze().cpu", "torch.multinomial.squeeze().cpu", "torch.multinomial.squeeze().cpu", "torch.multinomial.squeeze", "torch.multinomial.squeeze", "torch.multinomial.squeeze"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_involve_targeting_location_mask"], ["", "def", "forward", "(", "self", ",", "autoregressive_embedding", ",", "action_type", ",", "map_skip", ")", ":", "\n", "        ", "'''\n        Inputs:\n            autoregressive_embedding: [batch_size x autoregressive_embedding_size]\n            action_type: [batch_size x 1]\n            map_skip: [batch_size x entity_size x embedding_size]\n        Output:\n            target_location_logits: [batch_size x self.output_map_size x self.output_map_size]\n            location_out: [batch_size x 1]\n        '''", "\n", "\n", "# AlphaStar: `autoregressive_embedding` is reshaped to have the same height/width as the final skip in `map_skip` ", "\n", "# AlphaStar: (which was just before map information was reshaped to a 1D embedding) with 4 channels", "\n", "batch_size", "=", "map_skip", ".", "shape", "[", "0", "]", "\n", "assert", "autoregressive_embedding", ".", "shape", "[", "0", "]", "==", "action_type", ".", "shape", "[", "0", "]", "\n", "assert", "autoregressive_embedding", ".", "shape", "[", "0", "]", "==", "map_skip", ".", "shape", "[", "0", "]", "\n", "reshap_size", "=", "map_skip", ".", "shape", "[", "-", "1", "]", "\n", "reshape_channels", "=", "int", "(", "AHP", ".", "autoregressive_embedding_size", "/", "(", "reshap_size", "*", "reshap_size", ")", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "autoregressive_embedding_map", "=", "autoregressive_embedding", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "reshap_size", ",", "reshap_size", ")", "\n", "print", "(", "\"autoregressive_embedding_map.shape:\"", ",", "autoregressive_embedding_map", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: and the two are concatenated together along the channel dimension,", "\n", "# map skip shape: (-1, 128, 16, 16)", "\n", "# x shape: (-1, 132, 16, 16)", "\n", "print", "(", "\"map_skip.shape:\"", ",", "map_skip", ".", "shape", ")", "if", "debug", "else", "None", "\n", "x", "=", "torch", ".", "cat", "(", "[", "autoregressive_embedding_map", ",", "map_skip", "]", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: passed through a ReLU, ", "\n", "# AlphaStar: passed through a 2D convolution with 128 channels and kernel size 1,    ", "\n", "# AlphaStar: then passed through another ReLU.", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "ds_1", "(", "F", ".", "relu", "(", "x", ")", ")", ")", "\n", "\n", "# AlphaStar: The 3D tensor (height, width, and channels) is then passed through a series of Gated ResBlocks ", "\n", "# AlphaStar: with 128 channels, kernel size 3, and FiLM, gated on `autoregressive_embedding`  ", "\n", "# note: FilM is Feature-wise Linear Modulation, please see the paper \"FiLM: Visual Reasoning with ", "\n", "# a General Conditioning Layer\"", "\n", "# in here we use 4 Gated ResBlocks, and the value can be changde", "\n", "x", "=", "self", ".", "film_net", "(", "x", ",", "gate", "=", "autoregressive_embedding", ")", "\n", "\n", "# x shape (-1, 128, 16, 16)", "\n", "# AlphaStar: and using the elements of `map_skip` in order of last ResBlock skip to first.", "\n", "x", "=", "x", "+", "map_skip", "\n", "\n", "# AlphaStar: Afterwards, it is upsampled 2x by each of a series of transposed 2D convolutions ", "\n", "# AlphaStar: with kernel size 4 and channel sizes 128, 64, 16, and 1 respectively ", "\n", "# AlphaStar: (upsampled beyond the 128x128 input to 256x256 target location selection).", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "us_1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "us_2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "us_3", "(", "x", ")", ")", "\n", "\n", "if", "AHP", "==", "MAHP", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "us_4", "(", "x", ")", ")", "\n", "# only in mAS, we need one more upsample step", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "us_5", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "us_4_original", "(", "x", ")", ")", "\n", "\n", "# AlphaStar: Those final logits are flattened and sampled (masking out invalid locations using `action_type`, ", "\n", "# AlphaStar: such as those outside the camera for build actions) with temperature 0.8 ", "\n", "# AlphaStar: to get the actual target position.", "\n", "# x shape: (-1, 1, 256, 256)", "\n", "", "print", "(", "'x.shape:'", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "y", "=", "x", ".", "reshape", "(", "batch_size", ",", "1", "*", "self", ".", "output_map_size", "*", "self", ".", "output_map_size", ")", "\n", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "# AlphaStar: (masking out invalid locations using `action_type`, such as those outside ", "\n", "# the camera for build actions)", "\n", "# TODO: use action to decide the mask", "\n", "mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "1", "*", "self", ".", "output_map_size", "*", "self", ".", "output_map_size", ",", "device", "=", "device", ")", "\n", "print", "(", "\"mask:\"", ",", "mask", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"mask.shape:\"", ",", "mask", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# assert y.shape == mask.shape", "\n", "y_2", "=", "y", "*", "mask", "\n", "print", "(", "\"y_2:\"", ",", "y_2", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"y_2.shape:\"", ",", "y_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_location_logits", "=", "y_2", ".", "div", "(", "self", ".", "temperature", ")", "\n", "print", "(", "\"target_location_logits:\"", ",", "target_location_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_location_logits.shape:\"", ",", "target_location_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_location_probs", "=", "self", ".", "softmax", "(", "target_location_logits", ")", "\n", "location_id", "=", "torch", ".", "multinomial", "(", "target_location_probs", ",", "num_samples", "=", "1", ",", "replacement", "=", "True", ")", "\n", "print", "(", "\"location_id:\"", ",", "location_id", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"location_id.shape:\"", ",", "location_id", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "location_out", "=", "location_id", ".", "squeeze", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "print", "(", "\"location_out:\"", ",", "location_out", ")", "if", "debug", "else", "None", "\n", "# print(\"location_out.shape:\", location_out.shape) if debug else None", "\n", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "location_id", ")", ":", "\n", "            ", "target_location_y", "=", "idx", "//", "self", ".", "output_map_size", "\n", "target_location_x", "=", "idx", "-", "self", ".", "output_map_size", "*", "target_location_y", "\n", "if", "not", "P", ".", "use_raw_action", ":", "\n", "                ", "print", "(", "\"target_location_y, target_location_x\"", ",", "target_location_y", ",", "target_location_x", ")", "if", "debug", "else", "None", "\n", "# for test ", "\n", "#target_location_y = torch.tensor([80])", "\n", "# for test ", "\n", "#target_location_x = torch.tensor([200])", "\n", "# note! sc2 and pysc2 all accept the position as [x, y], so x be the first, y be the last!", "\n", "# this is not right : location_out[i] = [target_location_y.item(), target_location_x.item()]", "\n", "# below is right! so the location point map to the point in the matrix!", "\n", "", "location_out", "[", "i", "]", "=", "[", "target_location_x", ".", "item", "(", ")", ",", "target_location_y", ".", "item", "(", ")", "]", "\n", "\n", "# AlphaStar: If `action_type` does not involve targetting location, this head is ignored.", "\n", "", "target_location_mask", "=", "L", ".", "action_involve_targeting_location_mask", "(", "action_type", ",", "raw", "=", "P", ".", "use_raw_action", ")", "\n", "# target_location_mask: [batch_size x 1]", "\n", "print", "(", "\"action_type:\"", ",", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_location_mask:\"", ",", "target_location_mask", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"location_out:\"", ",", "location_out", ")", "if", "debug", "else", "None", "\n", "location_out", "=", "np", ".", "array", "(", "location_out", ")", "\n", "print", "(", "\"location_out:\"", ",", "location_out", ")", "if", "debug", "else", "None", "\n", "location_out", "=", "torch", ".", "tensor", "(", "location_out", ",", "device", "=", "device", ")", "\n", "print", "(", "\"location_out:\"", ",", "location_out", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"location_out.shape:\"", ",", "location_out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_location_logits", "=", "target_location_logits", ".", "reshape", "(", "-", "1", ",", "self", ".", "output_map_size", ",", "self", ".", "output_map_size", ")", "\n", "target_location_logits", "=", "target_location_logits", "*", "target_location_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "location_out", "=", "location_out", "*", "target_location_mask", ".", "long", "(", ")", "\n", "if", "not", "P", ".", "use_raw_action", ":", "\n", "            ", "print", "(", "\"location_out\"", ",", "location_out", ")", "if", "1", "else", "None", "\n", "\n", "", "location_out", "=", "location_out", "\n", "\n", "return", "target_location_logits", ",", "location_out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.location_head.test": [[274, 306], ["torch.randn", "torch.randn", "torch.randn", "torch.randint", "torch.randint", "torch.randint", "location_head.LocationHead", "location_head.LocationHead.forward", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "autoregressive_embedding", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "action_type_sample", "=", "65", "# func: 65/Effect_PsiStorm_pt (1/queued [2]; 2/unit_tags [512]; 0/world [0, 0])", "\n", "action_type", "=", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "SFS", ".", "available_actions", ",", "size", "=", "(", "batch_size", ",", "1", ")", ")", "\n", "\n", "if", "AHP", "==", "MAHP", ":", "\n", "        ", "map_skip", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "location_head_max_map_channels", ",", "8", ",", "8", ")", "\n", "", "else", ":", "\n", "        ", "map_skip", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "location_head_max_map_channels", ",", "16", ",", "16", ")", "\n", "\n", "", "location_head", "=", "LocationHead", "(", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_location_logits", ",", "target_location", "=", "location_head", ".", "forward", "(", "autoregressive_embedding", ",", "action_type", ",", "map_skip", ")", "\n", "\n", "if", "target_location_logits", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_location_logits:\"", ",", "target_location_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_location_logits.shape:\"", ",", "target_location_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_location_logits is None!\"", ")", "\n", "\n", "", "if", "target_location", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"target_location:\"", ",", "target_location", ")", "if", "debug", "else", "None", "\n", "# print(\"target_location.shape:\", target_location.shape) if debug else None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"target_location is None!\"", ")", "\n", "\n", "", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.scalar_encoder.ScalarEncoder.__init__": [[29, 69], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.lib.alphastar_transformer.Transformer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "n_statistics", "=", "10", ",", "n_upgrades", "=", "SFS", ".", "upgrades", ",", "\n", "n_action_num", "=", "SFS", ".", "available_actions", ",", "n_units_buildings", "=", "SFS", ".", "unit_counts_bow", ",", "\n", "n_effects", "=", "SFS", ".", "effects", ",", "n_upgrade", "=", "SFS", ".", "upgrade", ",", "\n", "n_possible_actions", "=", "SFS", ".", "last_action_type", ",", "\n", "n_delay", "=", "SFS", ".", "last_delay", ",", "\n", "n_possible_values", "=", "SFS", ".", "last_repeat_queued", ",", "\n", "original_32", "=", "AHP", ".", "original_32", ",", "\n", "original_64", "=", "AHP", ".", "original_64", ",", "\n", "original_128", "=", "AHP", ".", "original_128", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "\n", "original_512", "=", "AHP", ".", "original_512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "statistics_fc", "=", "nn", ".", "Linear", "(", "n_statistics", ",", "original_64", ")", "# with relu", "\n", "self", ".", "home_race_fc", "=", "nn", ".", "Linear", "(", "5", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "away_race_fc", "=", "nn", ".", "Linear", "(", "5", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "upgrades_fc", "=", "nn", ".", "Linear", "(", "n_upgrades", ",", "original_128", ")", "# with relu", "\n", "self", ".", "enemy_upgrades_fc", "=", "nn", ".", "Linear", "(", "n_upgrades", ",", "original_128", ")", "# with relu", "\n", "self", ".", "time_fc", "=", "original_64", "# a transformer positional encoder", "\n", "\n", "# additional features", "\n", "self", ".", "available_actions_fc", "=", "nn", ".", "Linear", "(", "n_action_num", ",", "original_64", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "unit_counts_bow_fc", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "original_64", ")", "# A bag-of-words unit count from `entity_list`, with relu", "\n", "self", ".", "mmr_fc", "=", "nn", ".", "Linear", "(", "7", ",", "original_64", ")", "# mmr is from 0 to 6 (by divison by 1000), with relu", "\n", "\n", "self", ".", "units_buildings_fc", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "effects_fc", "=", "nn", ".", "Linear", "(", "n_effects", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "upgrade_fc", "=", "nn", ".", "Linear", "(", "n_upgrade", ",", "original_32", ")", "# with relu, also goto scalar_context. What is the difference with upgrades_fc?", "\n", "\n", "self", ".", "before_beginning_build_order", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "16", ")", "# without relu", "\n", "self", ".", "beginning_build_order_transformer", "=", "Transformer", "(", "d_model", "=", "16", ",", "d_inner", "=", "32", ",", "\n", "n_layers", "=", "3", ",", "n_head", "=", "2", ",", "d_k", "=", "8", ",", "d_v", "=", "8", ",", "dropout", "=", "0.1", ")", "\n", "# [20, num_entity_types], into transformer with q,k,v, also goto scalar_context", "\n", "self", ".", "last_delay_fc", "=", "nn", ".", "Linear", "(", "n_delay", ",", "original_64", ")", "# with relu", "\n", "self", ".", "last_action_type_fc", "=", "nn", ".", "Linear", "(", "n_possible_actions", ",", "original_128", ")", "# with relu", "\n", "self", ".", "last_repeat_queued_fc", "=", "nn", ".", "Linear", "(", "n_possible_values", ",", "original_256", ")", "# with relu", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "AHP", ".", "scalar_encoder_fc1_input", ",", "original_512", ")", "# with relu", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "AHP", ".", "scalar_encoder_fc2_input", ",", "original_512", ")", "# with relu", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.scalar_encoder.ScalarEncoder.preprocess": [[70, 88], ["np.zeros", "len", "enumerate"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "obs", ",", "entity_list", ")", ":", "\n", "\n", "        ", "agent_statistics", "=", "None", "\n", "race", "=", "None", "\n", "upgrades", "=", "None", "\n", "enemy_upgrades", "=", "None", "\n", "time", "=", "None", "\n", "\n", "vocab", "=", "None", "\n", "bag_vector", "=", "np", ".", "zeros", "(", "len", "(", "vocab", ")", ")", "\n", "for", "entity", "in", "entity_list", ":", "\n", "            ", "w", "=", "entity", ".", "type", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "vocab", ")", ":", "\n", "                ", "if", "word", "==", "w", ":", "\n", "                    ", "bag_vector", "[", "i", "]", "+=", "1", "\n", "", "", "", "unit_counts_bow", "=", "bag_vector", "\n", "\n", "return", "agent_statistics", ",", "race", ",", "upgrades", ",", "enemy_upgrades", ",", "time", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.scalar_encoder.ScalarEncoder.forward": [[89, 227], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.relu", "torch.relu", "torch.relu", "embedded_scalar_list.append", "scalar_context_list.append", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "embedded_scalar_list.append", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "scalar_encoder.ScalarEncoder.beginning_build_order_transformer", "torch.relu.reshape", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "print", "print", "print", "print", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "scalar_encoder.ScalarEncoder.statistics_fc", "scalar_encoder.ScalarEncoder.home_race_fc", "scalar_encoder.ScalarEncoder.away_race_fc", "scalar_encoder.ScalarEncoder.upgrades_fc", "scalar_encoder.ScalarEncoder.enemy_upgrades_fc", "scalar_encoder.ScalarEncoder.available_actions_fc", "scalar_encoder.ScalarEncoder.unit_counts_bow_fc", "scalar_encoder.ScalarEncoder.mmr_fc", "scalar_encoder.ScalarEncoder.units_buildings_fc", "scalar_encoder.ScalarEncoder.effects_fc", "scalar_encoder.ScalarEncoder.upgrade_fc", "print", "print", "scalar_encoder.ScalarEncoder.before_beginning_build_order", "print", "print", "print", "print", "scalar_encoder.ScalarEncoder.last_delay_fc", "scalar_encoder.ScalarEncoder.last_action_type_fc", "scalar_encoder.ScalarEncoder.last_repeat_queued_fc", "scalar_encoder.ScalarEncoder.fc_1", "scalar_encoder.ScalarEncoder.fc_2", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "scalar_encoder.ScalarEncoder.relu", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "scalar_list", ")", ":", "\n", "        ", "[", "agent_statistics", ",", "home_race", ",", "away_race", ",", "upgrades", ",", "enemy_upgrades", ",", "time", ",", "available_actions", ",", "unit_counts_bow", ",", "\n", "mmr", ",", "units_buildings", ",", "effects", ",", "upgrade", ",", "beginning_build_order", ",", "last_delay", ",", "last_action_type", ",", "\n", "last_repeat_queued", "]", "=", "scalar_list", "\n", "\n", "embedded_scalar_list", "=", "[", "]", "\n", "scalar_context_list", "=", "[", "]", "\n", "\n", "# agent_statistics: Embedded by taking log(agent_statistics + 1) and passing through a linear of size 64 and a ReLU", "\n", "\n", "print", "(", "'agent_statistics:'", ",", "agent_statistics", ")", "if", "debug", "else", "None", "\n", "print", "(", "'agent_statistics+1:'", ",", "agent_statistics", "+", "1", ")", "if", "debug", "else", "None", "\n", "print", "(", "'torch.log(agent_statistics + 1):'", ",", "torch", ".", "log", "(", "agent_statistics", "+", "1", ")", ")", "if", "debug", "else", "None", "\n", "\n", "the_log_statistics", "=", "torch", ".", "log", "(", "agent_statistics", "+", "1", ")", "\n", "if", "torch", ".", "isnan", "(", "the_log_statistics", ")", ".", "any", "(", ")", ":", "\n", "            ", "print", "(", "'Find NAN the_log_statistics !'", ",", "the_log_statistics", ")", "\n", "eps", "=", "1e-9", "\n", "the_log_statistics", "=", "torch", ".", "log", "(", "self", ".", "relu", "(", "agent_statistics", "+", "1", ")", "+", "eps", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "the_log_statistics", ")", ".", "any", "(", ")", ":", "\n", "                ", "print", "(", "'Find NAN the_log_statistics !'", ",", "the_log_statistics", ")", "\n", "the_log_statistics", "=", "torch", ".", "ones_like", "(", "agent_statistics", ")", "\n", "\n", "", "", "x", "=", "F", ".", "relu", "(", "self", ".", "statistics_fc", "(", "the_log_statistics", ")", ")", "\n", "embedded_scalar_list", ".", "append", "(", "x", ")", "\n", "scalar_context_list", ".", "append", "(", "x", ")", "\n", "\n", "# race: Both races are embedded into a one-hot with maximum 5, and embedded through a linear of size 32 and a ReLU.", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "home_race_fc", "(", "home_race", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "# The embedding is also added to `scalar_context`.", "\n", "# scalar_context_list.append(x)", "\n", "\n", "# race: Both races are embedded into a one-hot with maximum 5, and embedded through a linear of size 32 and a ReLU.", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "away_race_fc", "(", "away_race", ")", ")", "\n", "# TODO: During training, the opponent's requested race is hidden in 10% of matches, to simulate playing against the Random race.", "\n", "# embedded_scalar_list.append(x)", "\n", "# The embedding is also added to `scalar_context`.", "\n", "# scalar_context_list.append(x)", "\n", "# TODO: If we don't know the opponent's race (either because they are random or it is hidden), ", "\n", "# we add their true race to the observation once we observe one of their units.", "\n", "\n", "# upgrades: The boolean vector of whether an upgrade is present is embedded through a linear of size 128 and a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "upgrades_fc", "(", "upgrades", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# enemy_upgrades: Embedded the same as upgrades", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "enemy_upgrades_fc", "(", "enemy_upgrades", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# TODO: time: A transformer positional encoder encoded the time into a 1D tensor of size 64", "\n", "x", "=", "time", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# available_actions: From `entity_list`, we compute which actions may be available and which can never be available. ", "\n", "# For example, the agent controls a Stalker and has researched the Blink upgrade, ", "\n", "# then the Blink action may be available (even though in practice it may be on cooldown). ", "\n", "# The boolean vector of action availability is passed through a linear of size 64 and a ReLU.", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "available_actions_fc", "(", "available_actions", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "# The embedding is also added to `scalar_context`", "\n", "# scalar_context_list.append(x)", "\n", "\n", "# unit_counts_bow: A bag-of-words unit count from `entity_list`. ", "\n", "# The unit count vector is embedded by square rooting, passing through a linear layer, and passing through a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "unit_counts_bow_fc", "(", "unit_counts_bow", ")", ")", "\n", "embedded_scalar_list", ".", "append", "(", "x", ")", "\n", "\n", "# mmr: During supervised learning, this is the MMR of the player we are trying to imitate. Elsewhere, this is fixed at 6200. ", "\n", "# MMR is mapped to a one-hot of min(mmr / 1000, 6) with maximum 6, then passed through a linear of size 64 and a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "mmr_fc", "(", "mmr", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# cumulative_statistics: The cumulative statistics (including units, buildings, effects, and upgrades) are preprocessed ", "\n", "# into a boolean vector of whether or not statistic is present in a human game. ", "\n", "# That vector is split into 3 sub-vectors of units/buildings, effects, and upgrades, ", "\n", "# and each subvector is passed through a linear of size 32 and a ReLU, and concatenated together.", "\n", "# The embedding is also added to `scalar_context`", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "units_buildings_fc", "(", "units_buildings", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "# scalar_context_list.append(x)", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "effects_fc", "(", "effects", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "# scalar_context_list.append(x)", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "upgrade_fc", "(", "upgrade", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "# scalar_context_list.append(x)", "\n", "\n", "# beginning_build_order: The first 20 constructed entities are converted to a 2D tensor of size ", "\n", "# [20, num_entity_types], concatenated with indices and the binary encodings ", "\n", "# (as in the Entity Encoder) of where entities were constructed (if applicable). ", "\n", "# The concatenation is passed through a transformer similar to the one in the entity encoder, ", "\n", "# but with keys, queries, and values of 8 and with a MLP hidden size of 32. ", "\n", "# The embedding is also added to `scalar_context`.", "\n", "print", "(", "\"beginning_build_order:\"", ",", "beginning_build_order", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"beginning_build_order.shape:\"", ",", "beginning_build_order", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "x", "=", "self", ".", "beginning_build_order_transformer", "(", "self", ".", "before_beginning_build_order", "(", "beginning_build_order", ")", ")", "\n", "print", "(", "\"x:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "SCHP", ".", "count_beginning_build_order", "*", "16", ")", "\n", "print", "(", "\"x:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# embedded_scalar_list.append(x)", "\n", "# scalar_context_list.append(x)", "\n", "\n", "# last_delay: The delay between when we last acted and the current observation, in game steps. ", "\n", "# This may be different from what we requested due to network latency or APM limits. ", "\n", "# It is encoded into a one-hot with maximum 128 and passed through a linear of size 64 and a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "last_delay_fc", "(", "last_delay", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# last_action_type: The last action type is encoded into a one-hot with maximum equal ", "\n", "# to the number of possible actions, and passed through a linear of size 128 and a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "last_action_type_fc", "(", "last_action_type", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# last_repeat_queued: Some other action arguments (queued and repeat) are one-hots with ", "\n", "# maximum equal to the number of possible values for those arguments, ", "\n", "# and jointly passed through a linear of size 256 and ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "last_repeat_queued_fc", "(", "last_repeat_queued", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# for x in embedded_scalar_list:", "\n", "#    print('embedded_scalar shape:', x.shape)", "\n", "\n", "embedded_scalar", "=", "torch", ".", "cat", "(", "embedded_scalar_list", ",", "dim", "=", "1", ")", "\n", "embedded_scalar_out", "=", "F", ".", "relu", "(", "self", ".", "fc_1", "(", "embedded_scalar", ")", ")", "\n", "\n", "scalar_context", "=", "torch", ".", "cat", "(", "scalar_context_list", ",", "dim", "=", "1", ")", "\n", "scalar_context_out", "=", "F", ".", "relu", "(", "self", ".", "fc_2", "(", "scalar_context", ")", ")", "\n", "\n", "return", "embedded_scalar_out", ",", "scalar_context_out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.scalar_encoder.test": [[229, 286], ["scalar_encoder.ScalarEncoder", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_encoder.ScalarEncoder.forward", "int", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "\n", "    ", "scalar_encoder", "=", "ScalarEncoder", "(", ")", "\n", "\n", "batch_size", "=", "2", "\n", "# dummy scalar list", "\n", "scalar_list", "=", "[", "]", "\n", "\n", "agent_statistics", "=", "torch", ".", "ones", "(", "batch_size", ",", "SFS", ".", "agent_statistics", ")", "\n", "home_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "home_race", ")", "\n", "away_race", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "away_race", ")", "\n", "upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "enemy_upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "time", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "time", ")", "\n", "\n", "available_actions", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "available_actions", ")", "\n", "unit_counts_bow", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "mmr", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "mmr", ")", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "units_buildings", ")", "\n", "effects", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "effects", ")", "\n", "upgrade", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrade", ")", "\n", "\n", "beginning_build_order", "=", "torch", ".", "randn", "(", "batch_size", ",", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "last_delay", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_delay", ")", "\n", "last_action_type", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_action_type", ")", "\n", "last_repeat_queued", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "last_repeat_queued", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "home_race", ")", "\n", "scalar_list", ".", "append", "(", "away_race", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "enemy_upgrades", ")", "\n", "scalar_list", ".", "append", "(", "time", ")", "\n", "\n", "scalar_list", ".", "append", "(", "available_actions", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "mmr", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "scalar_list", ".", "append", "(", "last_delay", ")", "\n", "scalar_list", ".", "append", "(", "last_action_type", ")", "\n", "scalar_list", ".", "append", "(", "last_repeat_queued", ")", "\n", "\n", "embedded_scalar", ",", "scalar_context", "=", "scalar_encoder", ".", "forward", "(", "scalar_list", ")", "\n", "\n", "print", "(", "\"embedded_scalar:\"", ",", "embedded_scalar", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"embedded_scalar.shape:\"", ",", "embedded_scalar", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"scalar_context:\"", ",", "scalar_context", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"scalar_context.shape:\"", ",", "scalar_context", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "debug", ":", "\n", "        ", "print", "(", "\"This is a test!\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.__init__": [[34, 64], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "spatial_encoder.ResBlock", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "n_resblocks", "=", "4", ",", "original_32", "=", "AHP", ".", "original_32", ",", "\n", "original_64", "=", "AHP", ".", "original_64", ",", "\n", "original_128", "=", "AHP", ".", "original_128", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "\n", "original_512", "=", "AHP", ".", "original_512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplanes", "=", "AHP", ".", "map_channels", "\n", "self", ".", "project", "=", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "original_32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "# ds means downsampling", "\n", "self", ".", "ds_1", "=", "nn", ".", "Conv2d", "(", "original_32", ",", "original_64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "ds_2", "=", "nn", ".", "Conv2d", "(", "original_64", ",", "original_128", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "ds_3", "=", "nn", ".", "Conv2d", "(", "original_128", ",", "original_128", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "resblock_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ResBlock", "(", "inplanes", "=", "original_128", ",", "planes", "=", "original_128", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", "\n", "for", "_", "in", "range", "(", "n_resblocks", ")", "]", ")", "\n", "\n", "if", "AHP", "==", "MAHP", ":", "\n", "# note: in mAS, we replace 128x128 to 64x64, and the result 16x16 also to 8x8", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "8", "*", "8", "*", "original_128", ",", "original_256", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "16", "*", "16", "*", "original_128", ",", "original_256", ")", "# position-wise", "\n", "\n", "", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "original_256", ",", "original_32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "map_width", "=", "AHP", ".", "minimap_size", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.preprocess": [[65, 68], ["spatial_encoder.get_map_data"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.get_map_data"], ["", "def", "preprocess", "(", "self", ",", "obs", ",", "entity_embeddings", ")", ":", "\n", "        ", "map_data", "=", "get_map_data", "(", "obs", ")", "\n", "return", "map_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.scatter": [[69, 112], ["torch.relu().transpose", "torch.relu().transpose", "torch.relu().transpose", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "print", "print", "len", "range", "next", "print", "range", "torch.relu", "torch.relu", "torch.relu", "spatial_encoder.SpatialEncoder.parameters", "spatial_encoder.SpatialEncoder.conv1", "spatial_encoder.SpatialEncoder.scatter.bits2value"], "methods", ["None"], ["", "def", "scatter", "(", "self", ",", "entity_embeddings", ",", "entity_x_y", ")", ":", "\n", "# `entity_embeddings` are embedded through a size 32 1D convolution, followed by a ReLU,", "\n", "        ", "print", "(", "\"entity_embeddings.shape:\"", ",", "entity_embeddings", ".", "shape", ")", "if", "debug", "else", "None", "\n", "reduced_entity_embeddings", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "entity_embeddings", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "print", "(", "\"reduced_entity_embeddings.shape:\"", ",", "reduced_entity_embeddings", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# then scattered into a map layer so that the size 32 vector at a specific ", "\n", "# location corresponds to the units placed there.", "\n", "\n", "def", "bits2value", "(", "bits", ")", ":", "\n", "# change from the bits to dec values.", "\n", "            ", "l", "=", "len", "(", "bits", ")", "\n", "v", "=", "0", "\n", "g", "=", "1", "\n", "for", "i", "in", "range", "(", "l", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                ", "v", "+=", "bits", "[", "i", "]", "*", "g", "\n", "g", "*=", "2", "\n", "", "return", "v", "\n", "\n", "# shape [batch_size x entity_size x embedding_size]", "\n", "", "batch_size", "=", "reduced_entity_embeddings", ".", "shape", "[", "0", "]", "\n", "entity_size", "=", "reduced_entity_embeddings", ".", "shape", "[", "1", "]", "\n", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "scatter_map", "=", "torch", ".", "zeros", "(", "batch_size", ",", "AHP", ".", "original_32", ",", "self", ".", "map_width", ",", "self", ".", "map_width", ",", "device", "=", "device", ")", "\n", "\n", "print", "(", "\"scatter_map.shape:\"", ",", "scatter_map", ".", "shape", ")", "if", "debug", "else", "None", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "entity_size", ")", ":", "\n", "# can not be masked entity", "\n", "                ", "if", "entity_x_y", "[", "i", ",", "j", ",", "0", "]", "!=", "-", "1e9", ":", "\n", "                    ", "x", "=", "entity_x_y", "[", "i", ",", "j", ",", ":", "8", "]", "\n", "y", "=", "entity_x_y", "[", "i", ",", "j", ",", "8", ":", "]", "\n", "x", "=", "bits2value", "(", "x", ")", "\n", "y", "=", "bits2value", "(", "y", ")", "\n", "\n", "# note, we reduce 128 to 64, so the x and y should also be", "\n", "# 128 is half of 256, 64 is half of 128, so we divide by 4", "\n", "x", "=", "int", "(", "x", "/", "4", ")", "\n", "y", "=", "int", "(", "y", "/", "4", ")", "\n", "scatter_map", "[", "i", ",", ":", ",", "y", ",", "x", "]", "+=", "reduced_entity_embeddings", "[", "i", ",", "j", ",", ":", "]", "\n", "\n", "#print(\"scatter_map:\", scatter_map[0, :, 23, 19]) if 1 else None", "\n", "", "", "", "return", "scatter_map", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.SpatialEncoder.forward": [[113, 148], ["torch.relu", "torch.relu", "torch.relu", "spatial_encoder.SpatialEncoder.ds_1", "spatial_encoder.SpatialEncoder.ds_2", "spatial_encoder.SpatialEncoder.ds_3", "resblock.reshape", "spatial_encoder.SpatialEncoder.fc", "torch.relu", "torch.relu", "torch.relu", "spatial_encoder.SpatialEncoder.project", "resblock"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "entity_embeddings", ",", "entity_x_y", ")", ":", "\n", "#scatter_map = self.scatter(entity_embeddings, entity_x_y)", "\n", "\n", "#x = torch.cat([scatter_map, x], dim=1)", "\n", "# After preprocessing, the planes are concatenated, projected to 32 channels ", "\n", "# by a 2D convolution with kernel size, self.map_width 1, passed through a ReLU", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "project", "(", "x", ")", ")", "\n", "\n", "# then downsampled from 128x128 to 16x16 through 3 2D convolutions and ReLUs ", "\n", "# with channel size 64, 128, and 128 respectively. ", "\n", "# The kernel size for those 3 downsampling convolutions is 4, and the stride is 2.", "\n", "# note: in mAS, we replace 128x128 to 64x64, and the result 16x16 also to 8x8", "\n", "x", "=", "self", ".", "ds_1", "(", "x", ")", "\n", "x", "=", "self", ".", "ds_2", "(", "x", ")", "\n", "x", "=", "self", ".", "ds_3", "(", "x", ")", "\n", "\n", "# 4 ResBlocks with 128 channels and kernel size 3 and applied to the downsampled map, ", "\n", "# with the skip connections placed into `map_skip`.", "\n", "map_skip", "=", "x", "\n", "for", "resblock", "in", "self", ".", "resblock_stack", ":", "\n", "            ", "x", "=", "resblock", "(", "x", ")", "\n", "\n", "# note if we add the follow line, it will output \"can not comput gradient error\"", "\n", "# map_skip += x", "\n", "# so we try to change to the follow line, which will not make a in-place operation", "\n", "map_skip", "=", "map_skip", "+", "x", "\n", "\n", "", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# The ResBlock output is embedded into a 1D tensor of size 256 by a linear layer ", "\n", "# and a ReLU, which becomes `embedded_spatial`.", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "embedded_spatial", "=", "F", ".", "relu", "(", "x", ")", "\n", "\n", "return", "map_skip", ",", "embedded_spatial", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlock.__init__": [[211, 221], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", "=", "128", ",", "planes", "=", "128", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlock.forward": [[222, 239], ["spatial_encoder.ResBlock.conv1", "spatial_encoder.ResBlock.bn1", "spatial_encoder.ResBlock.relu", "spatial_encoder.ResBlock.conv2", "spatial_encoder.ResBlock.bn2", "spatial_encoder.ResBlock.relu", "spatial_encoder.ResBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "out", "+", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.GatedResBlock.__init__": [[243, 257], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", "=", "128", ",", "planes", "=", "128", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "conv1_mask", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "conv2_mask", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.GatedResBlock.forward": [[258, 265], ["torch.relu", "torch.relu", "torch.relu", "spatial_encoder.GatedResBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "spatial_encoder.GatedResBlock.bn1", "spatial_encoder.GatedResBlock.conv2", "spatial_encoder.GatedResBlock.sigmoid", "spatial_encoder.GatedResBlock.conv1", "spatial_encoder.GatedResBlock.sigmoid", "spatial_encoder.GatedResBlock.conv2_mask", "spatial_encoder.GatedResBlock.conv1_mask"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", "*", "self", ".", "sigmoid", "(", "self", ".", "conv1_mask", "(", "x", ")", ")", ")", ")", "\n", "x", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x", ")", "*", "self", ".", "sigmoid", "(", "self", ".", "conv2_mask", "(", "x", ")", ")", ")", "\n", "x", "+=", "residual", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlockImproved.__init__": [[269, 277], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", "=", "128", ",", "planes", "=", "128", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResBlockImproved", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlockImproved.forward": [[280, 288], ["torch.relu", "torch.relu", "torch.relu", "spatial_encoder.ResBlockImproved.conv1", "torch.relu", "torch.relu", "torch.relu", "spatial_encoder.ResBlockImproved.conv2", "spatial_encoder.ResBlockImproved.bn1", "spatial_encoder.ResBlockImproved.bn2"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "x", "+", "residual", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlock1D.__init__": [[292, 300], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "seq_len", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResBlock1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "ln1", "=", "nn", ".", "LayerNorm", "(", "[", "planes", ",", "seq_len", "]", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "ln2", "=", "nn", ".", "LayerNorm", "(", "[", "planes", ",", "seq_len", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.ResBlock1D.forward": [[301, 309], ["torch.relu", "torch.relu", "torch.relu", "spatial_encoder.ResBlock1D.conv1", "torch.relu", "torch.relu", "torch.relu", "spatial_encoder.ResBlock1D.conv2", "spatial_encoder.ResBlock1D.ln1", "spatial_encoder.ResBlock1D.ln2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "ln1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "ln2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "x", "+", "residual", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.get_map_data": [[150, 207], ["numpy.expand_dims().astype", "alphastarmini.lib.utils.np_one_hot().astype", "alphastarmini.lib.utils.np_one_hot().astype", "alphastarmini.lib.utils.np_one_hot().astype", "alphastarmini.lib.utils.np_one_hot().astype", "alphastarmini.lib.utils.np_one_hot().astype", "alphastarmini.lib.utils.np_one_hot().astype", "numpy.concatenate", "numpy.transpose", "torch.tensor", "torch.tensor", "torch.tensor", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.expand_dims", "alphastarmini.lib.utils.np_one_hot", "alphastarmini.lib.utils.np_one_hot", "alphastarmini.lib.utils.np_one_hot", "alphastarmini.lib.utils.np_one_hot", "alphastarmini.lib.utils.np_one_hot", "alphastarmini.lib.utils.np_one_hot", "feature_minimap[].reshape", "feature_minimap[].reshape", "feature_minimap[].reshape", "feature_minimap[].reshape", "feature_minimap[].reshape", "feature_minimap[].reshape", "feature_minimap[].reshape"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.np_one_hot"], ["", "", "def", "get_map_data", "(", "obs", ",", "map_width", "=", "AHP", ".", "minimap_size", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "'''\n    TODO: camera: One-hot with maximum 2 of whether a location is within the camera, this refers to mimimap\n    TODO: scattered_entities: 32 float values from entity embeddings\n    default map_width is 128\n    '''", "\n", "if", "\"feature_minimap\"", "in", "obs", ":", "\n", "        ", "feature_minimap", "=", "obs", "[", "\"feature_minimap\"", "]", "\n", "", "else", ":", "\n", "        ", "feature_minimap", "=", "obs", "\n", "\n", "", "save_type", "=", "np", ".", "float32", "\n", "\n", "# A: height_map: Float of (height_map / 255.0)", "\n", "height_map", "=", "np", ".", "expand_dims", "(", "feature_minimap", "[", "\"height_map\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", "/", "255.0", ",", "-", "1", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'height_map:'", ",", "height_map", ")", "if", "verbose", "else", "None", "\n", "print", "(", "'height_map.shape:'", ",", "height_map", ".", "shape", ")", "if", "verbose", "else", "None", "\n", "\n", "# A: visibility: One-hot with maximum 4", "\n", "visibility", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"visibility_map\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "4", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'visibility:'", ",", "visibility", ")", "if", "verbose", "else", "None", "\n", "print", "(", "'visibility.shape:'", ",", "visibility", ".", "shape", ")", "if", "verbose", "else", "None", "\n", "\n", "# A: creep: One-hot with maximum 2", "\n", "creep", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"creep\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "2", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'creep:'", ",", "creep", ")", "if", "verbose", "else", "None", "\n", "\n", "# A: entity_owners: One-hot with maximum 5", "\n", "entity_owners", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"player_relative\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "5", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'entity_owners:'", ",", "entity_owners", ")", "if", "verbose", "else", "None", "\n", "\n", "# the bottom 3 maps are missed in pysc1.2 and pysc2.0", "\n", "# however, the 3 maps can be found on s2clientprotocol/spatial.proto", "\n", "# actually, the 3 maps can be found on pysc3.0", "\n", "\n", "# A: alerts: One-hot with maximum 2", "\n", "alerts", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"alerts\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "2", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'alerts:'", ",", "alerts", ")", "if", "verbose", "else", "None", "\n", "\n", "# A: pathable: One-hot with maximum 2", "\n", "pathable", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"pathable\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "2", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'pathable:'", ",", "pathable", ")", "if", "verbose", "else", "None", "\n", "\n", "# A: buildable: One-hot with maximum 2", "\n", "buildable", "=", "L", ".", "np_one_hot", "(", "feature_minimap", "[", "\"buildable\"", "]", ".", "reshape", "(", "-", "1", ",", "map_width", ",", "map_width", ")", ",", "2", ")", ".", "astype", "(", "save_type", ")", "\n", "print", "(", "'buildable:'", ",", "buildable", ")", "if", "verbose", "else", "None", "\n", "\n", "out_channels", "=", "1", "# + 4 + 5 + 2", "\n", "\n", "map_data", "=", "np", ".", "concatenate", "(", "[", "height_map", "]", ",", "axis", "=", "3", ")", "\n", "map_data", "=", "np", ".", "transpose", "(", "map_data", ",", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "print", "(", "'map_data.shape:'", ",", "map_data", ".", "shape", ")", "if", "verbose", "else", "None", "\n", "\n", "map_data", "=", "torch", ".", "tensor", "(", "map_data", ")", "\n", "print", "(", "'torch map_data.shape:'", ",", "map_data", ".", "shape", ")", "if", "verbose", "else", "None", "\n", "\n", "return", "map_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.spatial_encoder.test": [[311, 335], ["spatial_encoder.SpatialEncoder", "torch.zeros", "torch.zeros", "torch.zeros", "alphastarmini.lib.utils.to_one_hot", "map_list.append", "torch.zeros", "torch.zeros", "torch.zeros", "map_list.append", "torch.cat", "torch.cat", "torch.cat", "spatial_encoder.SpatialEncoder.forward", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "spatial_encoder", "=", "SpatialEncoder", "(", ")", "\n", "batch_size", "=", "2", "\n", "# dummy map list", "\n", "map_list", "=", "[", "]", "\n", "map_data_1", "=", "torch", ".", "zeros", "(", "batch_size", ",", "1", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_data_1_one_hot", "=", "L", ".", "to_one_hot", "(", "map_data_1", ",", "2", ")", "\n", "print", "(", "'map_data_1_one_hot.shape:'", ",", "map_data_1_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "map_list", ".", "append", "(", "map_data_1", ")", "\n", "map_data_2", "=", "torch", ".", "zeros", "(", "batch_size", ",", "17", ",", "AHP", ".", "minimap_size", ",", "AHP", ".", "minimap_size", ")", "\n", "map_list", ".", "append", "(", "map_data_2", ")", "\n", "map_data", "=", "torch", ".", "cat", "(", "map_list", ",", "dim", "=", "1", ")", "\n", "\n", "map_skip", ",", "embedded_spatial", "=", "spatial_encoder", ".", "forward", "(", "map_data", ")", "\n", "\n", "print", "(", "'map_skip:'", ",", "map_skip", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_spatial:'", ",", "embedded_spatial", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "'map_skip.shape:'", ",", "map_skip", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_spatial.shape:'", ",", "embedded_spatial", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "debug", ":", "\n", "        ", "print", "(", "\"This is a test!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.EntityEncoder.__init__": [[42, 103], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.lib.alphastar_transformer.Transformer", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "dropout", "=", "0.1", ",", "original_256", "=", "AHP", ".", "original_256", ",", "\n", "original_1024", "=", "AHP", ".", "original_1024", ",", "\n", "original_128", "=", "AHP", ".", "original_128", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# below is value form max value of one-hot encoding in alphastar", "\n", "self", ".", "max_entities", "=", "AHP", ".", "max_entities", "\n", "self", ".", "max_unit_type", "=", "SCHP", ".", "max_unit_type", "# default is 256", "\n", "self", ".", "max_alliance", "=", "5", "\n", "\n", "self", ".", "max_health", "=", "1500", "\n", "self", ".", "max_shield", "=", "1000", "\n", "self", ".", "max_energy", "=", "200", "\n", "\n", "self", ".", "max_cargo_space_used", "=", "9", "\n", "self", ".", "max_cargo_space_maximum", "=", "9", "\n", "\n", "self", ".", "max_display_type", "=", "5", "# AlphaStar: 4. RuntimeError: index 4 is out of bounds for dimension 1 with size 4", "\n", "self", ".", "max_cloakState", "=", "5", "\n", "\n", "self", ".", "max_is_powered", "=", "2", "\n", "self", ".", "max_is_hallucination", "=", "2", "\n", "self", ".", "max_is_active", "=", "2", "\n", "self", ".", "max_is_on_screen", "=", "2", "\n", "self", ".", "max_is_in_cargo", "=", "2", "\n", "\n", "self", ".", "max_current_minerals", "=", "19", "\n", "self", ".", "max_current_vespene", "=", "26", "\n", "\n", "self", ".", "max_mined_minerals", "=", "1800", "\n", "self", ".", "max_mined_vespene", "=", "2500", "\n", "\n", "self", ".", "max_assigned_harvesters", "=", "25", "# AlphaStar: 24. RuntimeError: index 24 is out of bounds for dimension 1 with size 24", "\n", "self", ".", "max_ideal_harvesters", "=", "17", "\n", "\n", "self", ".", "max_weapon_cooldown", "=", "32", "\n", "self", ".", "max_order_queue_length", "=", "9", "\n", "\n", "self", ".", "max_order_progress", "=", "10", "\n", "\n", "self", ".", "max_order_ids", "=", "SCHP", ".", "max_order_ids", "\n", "self", ".", "max_buffer_ids", "=", "SCHP", ".", "max_buffer_ids", "\n", "self", ".", "max_add_on_type", "=", "SCHP", ".", "max_add_on_type", "\n", "\n", "self", ".", "max_weapon_upgrades", "=", "4", "\n", "self", ".", "max_armor_upgrades", "=", "4", "\n", "self", ".", "max_shield_upgrades", "=", "4", "\n", "\n", "self", ".", "max_was_selected", "=", "2", "\n", "self", ".", "max_was_targeted", "=", "2", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "embedd", "=", "nn", ".", "Linear", "(", "AHP", ".", "embedding_size", ",", "original_256", ")", "\n", "self", ".", "transformer", "=", "Transformer", "(", "d_model", "=", "original_256", ",", "d_inner", "=", "original_1024", ",", "\n", "n_layers", "=", "3", ",", "n_head", "=", "2", ",", "d_k", "=", "original_128", ",", "\n", "d_v", "=", "original_128", ",", "dropout", "=", "0.1", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "original_256", ",", "original_256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_256", ")", "\n", "\n", "self", ".", "real_entities_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.EntityEncoder.preprocess": [[107, 311], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "alphastarmini.lib.utils.unit_tpye_to_unit_type_index", "alphastarmini.lib.utils.to_one_hot().reshape", "field_encoding_list.append", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "field_encoding_list.append", "alphastarmini.lib.utils.one_hot_embedding().reshape", "field_encoding_list.append", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "field_encoding_list.append", "alphastarmini.lib.utils.to_one_hot().reshape", "field_encoding_list.append", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "field_encoding_list.append", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "field_encoding_list.append", "int", "alphastarmini.lib.utils.to_one_hot().reshape", "int", "alphastarmini.lib.utils.to_one_hot().reshape", "int", "alphastarmini.lib.utils.to_one_hot().reshape", "int", "alphastarmini.lib.utils.to_one_hot().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "field_encoding_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "alphastarmini.lib.utils.to_one_hot().reshape", "print", "print", "print", "entity_tensor_list.append", "print", "print", "alphastarmini.lib.utils.to_one_hot", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "alphastarmini.lib.utils.one_hot_embedding", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "alphastarmini.lib.utils.to_one_hot", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "min", "alphastarmini.lib.utils.to_one_hot", "min", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.unpackbits", "numpy.unpackbits", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "alphastarmini.lib.utils.to_one_hot", "numpy.array", "numpy.array", "int", "int", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "min"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.unit_tpye_to_unit_type_index", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.one_hot_embedding", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot"], ["", "def", "preprocess", "(", "self", ",", "entity_list", ")", ":", "\n", "#all_entities_tensor = torch.zeros(self.max_entities, embedding_size)", "\n", "        ", "entity_tensor_list", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "entity", "in", "entity_list", ":", "\n", "            ", "field_encoding_list", "=", "[", "]", "\n", "\n", "# comments below have this style:", "\n", "# A: alphastar description", "\n", "# B: s2clientprotocol description", "\n", "# C: my notes", "\n", "\n", "# A: unit_type: One-hot with maximum self.max_unit_type (including unknown unit-type)", "\n", "# B: optional uint32 unit_type = 4;", "\n", "# C: with maximum self.max_unit_type", "\n", "unit_type", "=", "entity", ".", "unit_type", "\n", "print", "(", "'unit_type:'", ",", "unit_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "'self.max_unit_type:'", ",", "self", ".", "max_unit_type", ")", "if", "debug", "else", "None", "\n", "\n", "unit_type_index", "=", "L", ".", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "print", "(", "'unit_type_index:'", ",", "unit_type_index", ")", "if", "debug", "else", "None", "\n", "assert", "unit_type_index", ">=", "0", "and", "unit_type_index", "<=", "self", ".", "max_unit_type", "\n", "\n", "unit_type_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "unit_type_index", "]", ")", ",", "self", ".", "max_unit_type", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'unit_type_encoding:'", ",", "unit_type_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "unit_type_encoding", ")", "\n", "\n", "# A: unit_attributes: One boolean for each of the 13 unit attributes", "\n", "# B: not found", "\n", "# C: lack", "\n", "unit_attributes_encoding", "=", "torch", ".", "tensor", "(", "entity", ".", "unit_attributes", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'unit_attributes_encoding:'", ",", "unit_attributes_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "unit_attributes_encoding", ")", "\n", "\n", "# A: alliance: One-hot with maximum 5 (including unknown alliance)", "\n", "# B: optional Alliance alliance = 2; not max is 4, not 5", "\n", "# C: use A", "\n", "alliance_encoding", "=", "L", ".", "one_hot_embedding", "(", "torch", ".", "tensor", "(", "[", "entity", ".", "alliance", "]", ")", ",", "self", ".", "max_alliance", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'alliance_encoding:'", ",", "alliance_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "alliance_encoding", ")", "\n", "\n", "# A: build_progress: Float of build progress, in [0, 1]", "\n", "# B: optional float build_progress = 9;        // Range: [0.0, 1.0]", "\n", "# C: None", "\n", "build_progress_encoding", "=", "torch", ".", "tensor", "(", "[", "entity", ".", "build_progress", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'build_progress_encoding:'", ",", "build_progress_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "build_progress_encoding", ")", "\n", "\n", "# A: display_type: One-hot with maximum 5", "\n", "# B: note: in s2clientprotocol raw.proto, display type only has 4 values, type of enum DisplayType,", "\n", "# C: we keep in consistent with s2clientprotocol", "\n", "display_type_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "entity", ".", "display_type", "]", ")", ",", "self", ".", "max_display_type", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'display_type_encoding:'", ",", "display_type_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "display_type_encoding", ")", "\n", "\n", "# A: x_position: Binary encoding of entity x-coordinate, in game units", "\n", "# B: optional Point pos = 6;", "\n", "# C: use np.unpackbits", "\n", "x", "=", "entity", ".", "x", "\n", "print", "(", "'x:'", ",", "x", ")", "if", "debug", "else", "None", "\n", "x_encoding", "=", "torch", ".", "tensor", "(", "np", ".", "unpackbits", "(", "np", ".", "array", "(", "[", "x", "]", ",", "np", ".", "uint8", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'x_encoding:'", ",", "x_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "x_encoding", ")", "\n", "\n", "# A: y_position: Binary encoding of entity y-coordinate, in game units", "\n", "# B: optional Point pos = 6;", "\n", "# C: use np.unpackbits", "\n", "y", "=", "entity", ".", "y", "\n", "print", "(", "'y:'", ",", "y", ")", "if", "debug", "else", "None", "\n", "y_encoding", "=", "torch", ".", "tensor", "(", "np", ".", "unpackbits", "(", "np", ".", "array", "(", "[", "y", "]", ",", "np", ".", "uint8", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'y_encoding:'", ",", "y_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "y_encoding", ")", "\n", "\n", "# A: current_minerals: One-hot of (current_minerals / 100) with maximum 19, rounding down", "\n", "# B: optional int32 mineral_contents = 18; (maybe)", "\n", "# C: I am not sure mineral_contents corrseponds to current_minerals", "\n", "print", "(", "'entity.current_minerals:'", ",", "entity", ".", "current_minerals", ")", "if", "debug", "else", "None", "\n", "current_minerals", "=", "int", "(", "entity", ".", "current_minerals", "/", "100", ")", "\n", "print", "(", "'current_minerals:'", ",", "current_minerals", ")", "if", "debug", "else", "None", "\n", "current_minerals_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "current_minerals", "]", ")", ",", "self", ".", "max_current_minerals", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'current_minerals_encoding.shape:'", ",", "current_minerals_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(current_minerals_encoding)", "\n", "\n", "# A: current_vespene: One-hot of (current_vespene / 100) with maximum 26, rounding down", "\n", "# B: optional int32 vespene_contents = 19; (maybe)", "\n", "# C: I am not sure vespene_contents corrseponds to current_vespene", "\n", "print", "(", "'entity.current_vespene:'", ",", "entity", ".", "current_vespene", ")", "if", "debug", "else", "None", "\n", "current_vespene", "=", "int", "(", "entity", ".", "current_vespene", "/", "100", ")", "\n", "print", "(", "'current_vespene:'", ",", "current_vespene", ")", "if", "debug", "else", "None", "\n", "current_vespene_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "current_vespene", "]", ")", ",", "self", ".", "max_current_vespene", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'current_vespene_encoding.shape:'", ",", "current_vespene_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(current_vespene_encoding)", "\n", "\n", "# A: mined_minerals: One-hot of sqrt(min(mined_minerals, 1800)) with maximum sqrt(1800), rounding down", "\n", "# B: not found", "\n", "# C: wait to be resolved by other ways", "\n", "print", "(", "'entity.mined_minerals:'", ",", "entity", ".", "mined_minerals", ")", "if", "debug", "else", "None", "\n", "mined_minerals", "=", "int", "(", "min", "(", "entity", ".", "mined_minerals", ",", "self", ".", "max_mined_minerals", ")", "**", "0.5", ")", "\n", "print", "(", "'mined_minerals:'", ",", "mined_minerals", ")", "if", "debug", "else", "None", "\n", "mined_minerals_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "mined_minerals", "]", ")", ",", "int", "(", "self", ".", "max_mined_minerals", "**", "0.5", ")", "+", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'mined_minerals_encoding.shape:'", ",", "mined_minerals_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(mined_minerals_encoding)", "\n", "\n", "# A: mined_vespene: One-hot of sqrt(min(mined_vespene, 2500)) with maximum sqrt(2500), rounding down", "\n", "# B: not found", "\n", "# C: wait to be resolved by other ways", "\n", "print", "(", "'entity.mined_vespene:'", ",", "entity", ".", "mined_vespene", ")", "if", "debug", "else", "None", "\n", "mined_vespene", "=", "int", "(", "min", "(", "entity", ".", "mined_vespene", ",", "self", ".", "max_mined_vespene", ")", "**", "0.5", ")", "\n", "print", "(", "'mined_vespene:'", ",", "mined_vespene", ")", "if", "debug", "else", "None", "\n", "mined_vespene_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "mined_vespene", "]", ")", ",", "int", "(", "self", ".", "max_mined_vespene", "**", "0.5", ")", "+", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'mined_vespene_encoding.shape:'", ",", "mined_vespene_encoding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(mined_vespene_encoding)", "\n", "\n", "# A: assigned_harvesters: One-hot with maximum 24", "\n", "# B: optional int32 assigned_harvesters = 28;", "\n", "# C: None", "\n", "assigned_harvesters_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "min", "(", "entity", ".", "assigned_harvesters", ",", "24", ")", "]", ")", ",", "self", ".", "max_assigned_harvesters", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'assigned_harvesters_encoding:'", ",", "assigned_harvesters_encoding", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(assigned_harvesters_encoding)", "\n", "\n", "# A: ideal_harvesters: One-hot with maximum 17", "\n", "# B: optional int32 ideal_harvesters = 29;", "\n", "# C: None", "\n", "ideal_harvesters_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "entity", ".", "ideal_harvesters", "]", ")", ",", "self", ".", "max_ideal_harvesters", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'ideal_harvesters_encoding:'", ",", "ideal_harvesters_encoding", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(ideal_harvesters_encoding)", "\n", "\n", "# A: order_queue_length: One-hot with maximum 9", "\n", "# B: repeated UnitOrder orders = 22; Not populated for enemies;", "\n", "# C: equal to FeatureUnit.order_length", "\n", "order_queue_length", "=", "entity", ".", "order_length", "\n", "order_queue_length_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "order_queue_length", "]", ")", ",", "self", ".", "max_order_queue_length", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'order_queue_length_encoding:'", ",", "order_queue_length_encoding", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(order_queue_length_encoding)", "\n", "\n", "# A: order_1: One-hot across all order IDs", "\n", "# B: below is the definition of order", "\n", "'''\n                message UnitOrder {\n                      optional uint32 ability_id = 1;\n                      oneof target {\n                        Point target_world_space_pos = 2;\n                        uint64 target_unit_tag = 3;\n                      }\n                      optional float progress = 4;              // Progress of train abilities. Range: [0.0, 1.0]\n                    }\n            '''", "\n", "# C: actually this is across all ability_ids in orders, lack: a vector for all ability_ids", "\n", "order_1", "=", "entity", ".", "order_id_1", "\n", "print", "(", "'order_1:'", ",", "order_1", ")", "if", "debug", "else", "None", "\n", "order_1_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "order_1", "]", ")", ",", "self", ".", "max_order_ids", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'order_1_encoding:'", ",", "order_1_encoding", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(order_1_encoding)", "\n", "\n", "# A: buffs: Boolean for each buff of whether or not it is active. Only the first two buffs are tracked", "\n", "# B: None", "\n", "# C: in mAS, we ingore buff_id_2", "\n", "buff_id_1", "=", "entity", ".", "buff_id_1", "\n", "print", "(", "'buff_id_1:'", ",", "buff_id_1", ")", "if", "debug", "else", "None", "\n", "buff_id_1_encoding", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "buff_id_1", "]", ")", ",", "self", ".", "max_buffer_ids", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "print", "(", "'buff_id_1_encoding:'", ",", "buff_id_1_encoding", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(buff_id_1_encoding)            ", "\n", "\n", "order_progress_1_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "order_progress_1_encoding_2", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "max_order_progress", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "order_progress_1", "=", "entity", ".", "order_progress_1", "\n", "print", "(", "'order_progress_1:'", ",", "order_progress_1", ")", "if", "debug", "else", "None", "\n", "\n", "if", "order_progress_1", "is", "not", "None", ":", "\n", "                ", "order_progress_1_encoding", "=", "torch", ".", "tensor", "(", "[", "order_progress_1", "/", "100.", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "order_progress_1_encoding_2", "=", "L", ".", "to_one_hot", "(", "torch", ".", "tensor", "(", "[", "order_progress_1", "/", "10", "]", ")", ",", "\n", "self", ".", "max_order_progress", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "print", "(", "'order_progress_1_encoding:'", ",", "order_progress_1_encoding", ")", "if", "debug", "else", "None", "\n", "field_encoding_list", ".", "append", "(", "order_progress_1_encoding", ")", "\n", "print", "(", "'order_progress_1_encoding_2:'", ",", "order_progress_1_encoding_2", ")", "if", "debug", "else", "None", "\n", "# field_encoding_list.append(order_progress_1_encoding_2)", "\n", "\n", "entity_tensor", "=", "torch", ".", "cat", "(", "field_encoding_list", ",", "dim", "=", "1", ")", "\n", "print", "(", "'entity_tensor.shape:'", ",", "entity_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# There are up to 512 of these preprocessed entities, and any entities after 512 are ignored.", "\n", "if", "index", "<", "self", ".", "max_entities", ":", "\n", "                ", "entity_tensor_list", ".", "append", "(", "entity_tensor", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "index", "=", "index", "+", "1", "\n", "\n", "", "all_entities_tensor", "=", "torch", ".", "cat", "(", "entity_tensor_list", ",", "dim", "=", "0", ")", "\n", "\n", "# count how many real entities we have", "\n", "self", ".", "real_entities_size", "=", "all_entities_tensor", ".", "shape", "[", "0", "]", "\n", "print", "(", "'self.real_entities_size:'", ",", "self", ".", "real_entities_size", ")", "if", "debug", "else", "None", "\n", "\n", "# We use a bias of -1e9 for any of the 512 entries that doesn't refer to an entity.", "\n", "if", "all_entities_tensor", ".", "shape", "[", "0", "]", "<", "self", ".", "max_entities", ":", "\n", "            ", "bias_length", "=", "self", ".", "max_entities", "-", "all_entities_tensor", ".", "shape", "[", "0", "]", "\n", "bias", "=", "torch", ".", "zeros", "(", "[", "bias_length", ",", "AHP", ".", "embedding_size", "]", ")", "\n", "bias", "[", ":", ",", ":", "]", "=", "-", "1e9", "\n", "print", "(", "'bias:'", ",", "bias", ")", "if", "debug", "else", "None", "\n", "print", "(", "'bias.shape:'", ",", "bias", ".", "shape", ")", "if", "debug", "else", "None", "\n", "all_entities_tensor", "=", "torch", ".", "cat", "(", "[", "all_entities_tensor", ",", "bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "return", "all_entities_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.EntityEncoder.forward": [[312, 343], ["entity_encoder.EntityEncoder.embedd", "entity_encoder.EntityEncoder.transformer", "torch.relu().transpose", "torch.relu().transpose", "torch.relu().transpose", "torch.relu", "torch.relu", "torch.relu", "print", "print", "print", "print", "print", "print", "entity_encoder.EntityEncoder.fc1", "print", "print", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.relu", "torch.relu", "torch.relu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "entity_encoder.EntityEncoder.conv1", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.relu().transpose", "torch.relu().transpose", "torch.relu().transpose", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# assert the input shape is : batch_seq_size x entities_size x embeding_size", "\n", "# note: because the feature size of entity is not equal to 256, so it can not fed into transformer directly.", "\n", "# thus, we add a embedding layer to transfer it to right size.", "\n", "        ", "print", "(", "'entity_input is nan:'", ",", "torch", ".", "isnan", "(", "x", ")", ".", "any", "(", ")", ")", "if", "debug", "else", "None", "\n", "x", "=", "self", ".", "embedd", "(", "x", ")", "\n", "\n", "# x is batch_entities_tensor (dim = 3). Shape: batch_size x entities_size x embeding_size", "\n", "# change: x is batch_seq_entities_tensor (dim = 4). Shape: batch_size x seq_size x entities_size x embeding_size", "\n", "print", "(", "'x.shape:'", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "out", "=", "self", ".", "transformer", "(", "x", ")", "\n", "print", "(", "'out.shape:'", ",", "out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entity_embeddings", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "F", ".", "relu", "(", "out", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "print", "(", "'entity_embeddings.shape:'", ",", "entity_embeddings", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# note, dim=1 means the mean is across all entities in one timestep", "\n", "# The mean of the transformer output across across the units  ", "\n", "# is fed through a linear layer of size 256 and a ReLU to yield `embedded_entity`", "\n", "\n", "# masked by the missing entries", "\n", "print", "(", "'out.shape:'", ",", "out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "masked_out", "=", "out", "[", ":", ",", ":", "self", ".", "real_entities_size", ",", ":", "]", "\n", "print", "(", "'masked_out.shape:'", ",", "masked_out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "embedded_entity", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "torch", ".", "mean", "(", "masked_out", ",", "dim", "=", "1", ",", "keepdim", "=", "False", ")", ")", ")", "\n", "\n", "print", "(", "'embedded_entity:'", ",", "embedded_entity", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_entity.shape:'", ",", "embedded_entity", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "entity_embeddings", ",", "embedded_entity", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.Entity.__init__": [[347, 407], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["    ", "def", "__init__", "(", "self", ",", "unit_type", "=", "1", ",", "\n", "unit_attributes", "=", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "alliance", "=", "0", ",", "\n", "health", "=", "10", ",", "shield", "=", "20", ",", "energy", "=", "50", ",", "\n", "cargo_space_taken", "=", "0", ",", "cargo_space_max", "=", "0", ",", "build_progress", "=", "0", ",", "\n", "current_health_ratio", "=", "0.4", ",", "current_shield_ratio", "=", "0.5", ",", "current_energy_ratio", "=", "0.7", ",", "\n", "health_max", "=", "100", ",", "shield_max", "=", "50", ",", "energy_max", "=", "40", ",", "\n", "display_type", "=", "1", ",", "x", "=", "123", ",", "y", "=", "218", ",", "is_cloaked", "=", "3", ",", "is_powered", "=", "True", ",", "is_hallucination", "=", "False", ",", "is_active", "=", "True", ",", "\n", "is_on_screen", "=", "True", ",", "is_in_cargo", "=", "False", ",", "current_minerals", "=", "1000", ",", "current_vespene", "=", "1500", ",", "mined_minerals", "=", "500", ",", "\n", "mined_vespene", "=", "300", ",", "assigned_harvesters", "=", "8", ",", "ideal_harvesters", "=", "14", ",", "weapon_cooldown", "=", "5.0", ",", "orders", "=", "[", "0", ",", "1", ",", "3", ",", "0", "]", ",", "\n", "attack_upgrade_level", "=", "2", ",", "armor_upgrade_level", "=", "1", ",", "shield_upgrade_level", "=", "0", ",", "is_selected", "=", "True", ",", "is_targeted", "=", "False", ",", "\n", "order_length", "=", "4", ",", "order_id_0", "=", "1", ",", "order_id_1", "=", "0", ",", "order_id_2", "=", "3", ",", "order_id_3", "=", "2", ",", "order_progress_0", "=", "50", ",", "\n", "order_progress_1", "=", "95", ",", "buff_id_0", "=", "12", ",", "buff_id_1", "=", "8", ",", "addon_unit_type", "=", "4", ",", "tag", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "unit_type", "=", "unit_type", "\n", "self", ".", "unit_attributes", "=", "unit_attributes", "\n", "self", ".", "alliance", "=", "alliance", "\n", "self", ".", "health", "=", "health", "\n", "self", ".", "shield", "=", "shield", "\n", "self", ".", "energy", "=", "energy", "\n", "self", ".", "cargo_space_taken", "=", "cargo_space_taken", "\n", "self", ".", "cargo_space_max", "=", "cargo_space_max", "\n", "self", ".", "build_progress", "=", "build_progress", "\n", "self", ".", "current_health_ratio", "=", "current_health_ratio", "\n", "self", ".", "current_shield_ratio", "=", "current_shield_ratio", "\n", "self", ".", "current_energy_ratio", "=", "current_energy_ratio", "\n", "self", ".", "health_max", "=", "health_max", "\n", "self", ".", "shield_max", "=", "shield_max", "\n", "self", ".", "energy_max", "=", "energy_max", "\n", "self", ".", "display_type", "=", "display_type", "\n", "self", ".", "x", "=", "x", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "is_cloaked", "=", "is_cloaked", "\n", "self", ".", "is_powered", "=", "is_powered", "\n", "self", ".", "is_hallucination", "=", "is_hallucination", "\n", "self", ".", "is_active", "=", "is_active", "\n", "self", ".", "is_on_screen", "=", "is_on_screen", "\n", "self", ".", "is_in_cargo", "=", "is_in_cargo", "\n", "self", ".", "current_minerals", "=", "current_minerals", "\n", "self", ".", "current_vespene", "=", "current_vespene", "\n", "self", ".", "mined_minerals", "=", "mined_minerals", "\n", "self", ".", "mined_vespene", "=", "mined_vespene", "\n", "self", ".", "assigned_harvesters", "=", "assigned_harvesters", "\n", "self", ".", "ideal_harvesters", "=", "ideal_harvesters", "\n", "self", ".", "weapon_cooldown", "=", "weapon_cooldown", "\n", "self", ".", "attack_upgrade_level", "=", "attack_upgrade_level", "\n", "self", ".", "armor_upgrade_level", "=", "armor_upgrade_level", "\n", "self", ".", "shield_upgrade_level", "=", "shield_upgrade_level", "\n", "self", ".", "is_selected", "=", "is_selected", "\n", "self", ".", "is_targeted", "=", "is_targeted", "\n", "self", ".", "order_length", "=", "order_length", "\n", "self", ".", "order_id_1", "=", "order_id_0", "\n", "self", ".", "order_id_2", "=", "order_id_1", "\n", "self", ".", "order_id_3", "=", "order_id_2", "\n", "self", ".", "order_id_4", "=", "order_id_3", "\n", "self", ".", "order_progress_1", "=", "order_progress_0", "\n", "self", ".", "order_progress_2", "=", "order_progress_1", "\n", "self", ".", "buff_id_1", "=", "buff_id_0", "\n", "self", ".", "buff_id_2", "=", "buff_id_1", "\n", "self", ".", "addon_unit_type", "=", "addon_unit_type", "\n", "self", ".", "tag", "=", "tag", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.Entity.__str__": [[408, 410], ["str", "str", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'unit_type: '", "+", "str", "(", "self", ".", "unit_type", ")", "+", "', alliance: '", "+", "str", "(", "self", ".", "alliance", ")", "+", "', health: '", "+", "str", "(", "self", ".", "health", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.dec2bin": [[23, 27], ["x.unsqueeze().bitwise_and().ne().float", "torch.arange().to", "torch.arange().to", "torch.arange().to", "x.unsqueeze().bitwise_and().ne", "torch.arange", "torch.arange", "torch.arange", "x.unsqueeze().bitwise_and", "x.unsqueeze"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["def", "dec2bin", "(", "x", ",", "bits", ")", ":", "\n", "# mask = 2 ** torch.arange(bits).to(x.device, x.dtype)", "\n", "    ", "mask", "=", "2", "**", "torch", ".", "arange", "(", "bits", "-", "1", ",", "-", "1", ",", "-", "1", ")", ".", "to", "(", "x", ".", "device", ",", "x", ".", "dtype", ")", "\n", "return", "x", ".", "unsqueeze", "(", "-", "1", ")", ".", "bitwise_and", "(", "mask", ")", ".", "ne", "(", "0", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.bin2dec": [[29, 32], ["torch.sum", "torch.sum", "torch.sum", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "bin2dec", "(", "b", ",", "bits", ")", ":", "\n", "    ", "mask", "=", "2", "**", "torch", ".", "arange", "(", "bits", "-", "1", ",", "-", "1", ",", "-", "1", ")", ".", "to", "(", "b", ".", "device", ",", "b", ".", "dtype", ")", "\n", "return", "torch", ".", "sum", "(", "mask", "*", "b", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.entity_encoder.test": [[412, 443], ["print", "entity_encoder.Entity", "entity_encoder.Entity", "e_list.append", "e_list.append", "entity_encoder.EntityEncoder", "entity_encoder.EntityEncoder.preprocess", "entities_tensor.unsqueeze.unsqueeze", "entity_encoder.EntityEncoder.forward", "torch.tensor", "torch.tensor", "torch.tensor", "print", "print", "entities_tensor.unsqueeze.detach().clone", "torch.cat", "torch.cat", "torch.cat", "print", "print", "print", "print", "numpy.unpackbits", "numpy.array", "entities_tensor.unsqueeze.detach"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "print", "(", "torch", ".", "tensor", "(", "np", ".", "unpackbits", "(", "np", ".", "array", "(", "[", "25", "]", ",", "np", ".", "uint8", ")", ")", ")", ")", "\n", "batch_size", "=", "2", "\n", "\n", "e_list", "=", "[", "]", "\n", "e1", "=", "Entity", "(", "115", ",", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "0", ",", "100", ",", "60", ",", "50", ",", "4", ",", "8", ",", "95", ",", "0.2", ",", "0.0", ",", "0.0", ",", "140", ",", "60", ",", "100", ",", "\n", "1", ",", "123", ",", "218", ",", "3", ",", "True", ",", "False", ",", "True", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "3.0", ",", "[", "2", ",", "3", "]", ",", "2", ",", "1", ",", "0", ",", "True", ",", "False", ")", "\n", "e2", "=", "Entity", "(", "1908", ",", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "2", ",", "1500", ",", "0", ",", "200", ",", "0", ",", "4", ",", "15", ",", "0.5", ",", "0.8", ",", "0.5", ",", "1500", ",", "0", ",", "250", ",", "\n", "2", ",", "69", ",", "7", ",", "3", ",", "True", ",", "False", ",", "False", ",", "True", ",", "False", ",", "0", ",", "0", ",", "0", ",", "0", ",", "10", ",", "16", ",", "0.0", ",", "[", "1", "]", ",", "1", ",", "1", ",", "0", ",", "False", ",", "False", ")", "\n", "e_list", ".", "append", "(", "e1", ")", "\n", "e_list", ".", "append", "(", "e2", ")", "\n", "\n", "encoder", "=", "EntityEncoder", "(", ")", "\n", "entities_tensor", "=", "encoder", ".", "preprocess", "(", "e_list", ")", "\n", "print", "(", "'entities_tensor:'", ",", "entities_tensor", ")", "if", "debug", "else", "None", "\n", "print", "(", "'entities_tensor.shape:'", ",", "entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# entities_tensor (dim = 2): entities_size x embeding_size", "\n", "\n", "entities_tensor", "=", "entities_tensor", ".", "unsqueeze", "(", "0", ")", "\n", "if", "batch_size", "==", "2", ":", "\n", "        ", "entities_tensor_copy", "=", "entities_tensor", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "batch_entities_tensor", "=", "torch", ".", "cat", "(", "[", "entities_tensor", ",", "entities_tensor_copy", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "print", "(", "'batch_entities_tensor.shape:'", ",", "batch_entities_tensor", ".", "shape", ")", "if", "debug", "else", "None", "\n", "entity_embeddings", ",", "embedded_entity", "=", "encoder", ".", "forward", "(", "batch_entities_tensor", ")", "\n", "\n", "print", "(", "'entity_embeddings.shape:'", ",", "entity_embeddings", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "'embedded_entity.shape:'", ",", "embedded_entity", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "debug", ":", "\n", "        ", "print", "(", "\"This is a test!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.baseline.Baseline.__init__": [[32, 71], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.lib.alphastar_transformer.Transformer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "alphastarmini.core.arch.spatial_encoder.ResBlock1D", "range"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "baseline_type", "=", "'winloss'", ",", "\n", "n_statistics", "=", "10", ",", "\n", "baseline_input", "=", "AHP", ".", "winloss_baseline_input_size", ",", "\n", "n_upgrades", "=", "SFS", ".", "upgrades", ",", "\n", "n_units_buildings", "=", "SFS", ".", "unit_counts_bow", ",", "\n", "n_effects", "=", "SFS", ".", "effects", ",", "n_upgrade", "=", "SFS", ".", "upgrade", ",", "\n", "n_resblocks", "=", "AHP", ".", "n_resblocks", ",", "\n", "original_32", "=", "AHP", ".", "original_32", ",", "\n", "original_64", "=", "AHP", ".", "original_64", ",", "\n", "original_128", "=", "AHP", ".", "original_128", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "baseline_type", "=", "baseline_type", "\n", "if", "baseline_type", "==", "'build_order'", ":", "\n", "            ", "baseline_input", "=", "AHP", ".", "build_order_baseline_input_size", "\n", "", "elif", "baseline_type", "==", "'built_units'", ":", "\n", "            ", "baseline_input", "=", "AHP", ".", "built_units_baseline_input_size", "\n", "", "elif", "baseline_type", "==", "'upgrades'", ":", "\n", "            ", "baseline_input", "=", "AHP", ".", "upgrades_baseline_input_size", "\n", "", "elif", "baseline_type", "==", "'effects'", ":", "\n", "            ", "baseline_input", "=", "AHP", ".", "effects_baseline_input_size", "\n", "\n", "", "self", ".", "statistics_fc", "=", "nn", ".", "Linear", "(", "n_statistics", ",", "original_64", ")", "# with relu", "\n", "self", ".", "upgrades_fc", "=", "nn", ".", "Linear", "(", "n_upgrades", ",", "original_128", ")", "# with relu", "\n", "self", ".", "unit_counts_bow_fc", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "original_64", ")", "# A bag-of-words unit count from `entity_list`, with relu", "\n", "self", ".", "units_buildings_fc", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "effects_fc", "=", "nn", ".", "Linear", "(", "n_effects", ",", "original_32", ")", "# with relu, also goto scalar_context", "\n", "self", ".", "upgrade_fc", "=", "nn", ".", "Linear", "(", "n_upgrade", ",", "original_32", ")", "# with relu, also goto scalar_context. What is the difference with upgrades_fc?", "\n", "self", ".", "before_beginning_build_order", "=", "nn", ".", "Linear", "(", "n_units_buildings", ",", "16", ")", "# without relu", "\n", "self", ".", "beginning_build_order_transformer", "=", "Transformer", "(", "d_model", "=", "16", ",", "d_inner", "=", "32", ",", "\n", "n_layers", "=", "3", ",", "n_head", "=", "2", ",", "d_k", "=", "8", ",", "d_v", "=", "8", ",", "dropout", "=", "0.1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "embed_fc", "=", "nn", ".", "Linear", "(", "baseline_input", ",", "original_256", ")", "# with relu", "\n", "self", ".", "resblock_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ResBlock1D", "(", "inplanes", "=", "original_256", ",", "planes", "=", "original_256", ",", "seq_len", "=", "1", ")", "\n", "for", "_", "in", "range", "(", "n_resblocks", ")", "]", ")", "\n", "\n", "self", ".", "out_fc", "=", "nn", ".", "Linear", "(", "original_256", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.baseline.Baseline.preprocess": [[72, 154], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.relu", "torch.relu", "torch.relu", "embedded_scalar_list.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "embedded_scalar_list.append", "baseline.Baseline.beginning_build_order_transformer", "torch.relu.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "next", "print", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "baseline.Baseline.statistics_fc", "baseline.Baseline.statistics_fc", "baseline.Baseline.upgrades_fc", "baseline.Baseline.unit_counts_bow_fc", "torch.relu", "torch.relu", "torch.relu", "cumulative_statistics.append", "torch.relu", "torch.relu", "torch.relu", "cumulative_statistics.append", "torch.relu", "torch.relu", "torch.relu", "cumulative_statistics.append", "print", "print", "baseline.Baseline.before_beginning_build_order", "print", "print", "print", "print", "print", "print", "baseline.Baseline.parameters", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "print", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "baseline.Baseline.units_buildings_fc", "baseline.Baseline.effects_fc", "baseline.Baseline.upgrade_fc", "baseline.Baseline.relu", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "various_observations", ")", ":", "\n", "        ", "[", "agent_statistics", ",", "upgrades", ",", "unit_counts_bow", ",", "\n", "units_buildings", ",", "effects", ",", "upgrade", ",", "beginning_build_order", "]", "=", "various_observations", "\n", "\n", "# These features are all concatenated together to yield `action_type_input`, ", "\n", "# passed through a linear of size 256, then passed through 16 ResBlocks with 256 hidden units ", "\n", "# and layer normalization, passed through a ReLU, then passed through ", "\n", "# a linear with 1 hidden unit.", "\n", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "embedded_scalar_list", "=", "[", "]", "\n", "# agent_statistics: Embedded by taking log(agent_statistics + 1) and passing through a linear of size 64 and a ReLU", "\n", "the_log_statistics", "=", "torch", ".", "log", "(", "agent_statistics", "+", "1", ")", "\n", "if", "torch", ".", "isnan", "(", "the_log_statistics", ")", ".", "any", "(", ")", ":", "\n", "            ", "print", "(", "'Find NAN the_log_statistics !'", ",", "the_log_statistics", ")", "\n", "eps", "=", "1e-9", "\n", "the_log_statistics", "=", "torch", ".", "log", "(", "self", ".", "relu", "(", "agent_statistics", "+", "1", ")", "+", "eps", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "the_log_statistics", ")", ".", "any", "(", ")", ":", "\n", "                ", "print", "(", "'Find NAN the_log_statistics !'", ",", "the_log_statistics", ")", "\n", "the_log_statistics", "=", "torch", ".", "ones_like", "(", "agent_statistics", ",", "device", "=", "device", ")", "\n", "", "", "x", "=", "F", ".", "relu", "(", "self", ".", "statistics_fc", "(", "the_log_statistics", ")", ")", "\n", "embedded_scalar_list", ".", "append", "(", "x", ")", "\n", "\n", "# TODO: `cumulative_score`, as a 1D tensor of values, is processed like `agent_statistics`.", "\n", "cumulative_score", "=", "torch", ".", "ones", "(", "agent_statistics", ".", "shape", "[", "0", "]", ",", "SFS", ".", "agent_statistics", ",", "device", "=", "device", ")", "\n", "score_log_statistics", "=", "torch", ".", "log", "(", "cumulative_score", "+", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "statistics_fc", "(", "score_log_statistics", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# upgrades: The boolean vector of whether an upgrade is present is embedded through a linear of size 128 and a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "upgrades_fc", "(", "upgrades", ")", ")", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "# unit_counts_bow: A bag-of-words unit count from `entity_list`. ", "\n", "# The unit count vector is embedded by square rooting, passing through a linear layer, and passing through a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "unit_counts_bow_fc", "(", "unit_counts_bow", ")", ")", "\n", "embedded_scalar_list", ".", "append", "(", "x", ")", "\n", "\n", "# cumulative_statistics: The cumulative statistics (including units, buildings, effects, and upgrades) are preprocessed ", "\n", "# into a boolean vector of whether or not statistic is present in a human game. ", "\n", "# That vector is split into 3 sub-vectors of units/buildings, effects, and upgrades, ", "\n", "# and each subvector is passed through a linear of size 32 and a ReLU, and concatenated together.", "\n", "# The embedding is also added to `scalar_context`", "\n", "\n", "cumulative_statistics", "=", "[", "]", "# it is different in different baseline", "\n", "if", "self", ".", "baseline_type", "==", "\"winloss\"", "or", "self", ".", "baseline_type", "==", "\"build_order\"", "or", "self", ".", "baseline_type", "==", "\"built_units\"", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "units_buildings_fc", "(", "units_buildings", ")", ")", "\n", "cumulative_statistics", ".", "append", "(", "x", ")", "\n", "", "if", "self", ".", "baseline_type", "==", "\"effects\"", "or", "self", ".", "baseline_type", "==", "\"build_order\"", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "effects_fc", "(", "effects", ")", ")", "\n", "cumulative_statistics", ".", "append", "(", "x", ")", "\n", "", "if", "self", ".", "baseline_type", "==", "\"upgrades\"", "or", "self", ".", "baseline_type", "==", "\"build_order\"", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "upgrade_fc", "(", "upgrade", ")", ")", "\n", "cumulative_statistics", ".", "append", "(", "x", ")", "\n", "# embedded_scalar_list.extend(cumulative_statistics)", "\n", "\n", "# beginning_build_order: The first 20 constructed entities are converted to a 2D tensor of size ", "\n", "# [20, num_entity_types], concatenated with indices and the binary encodings ", "\n", "# (as in the Entity Encoder) of where entities were constructed (if applicable). ", "\n", "# The concatenation is passed through a transformer similar to the one in the entity encoder, ", "\n", "# but with keys, queries, and values of 8 and with a MLP hidden size of 32. ", "\n", "# The embedding is also added to `scalar_context`.", "\n", "", "print", "(", "\"beginning_build_order:\"", ",", "beginning_build_order", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"beginning_build_order.shape:\"", ",", "beginning_build_order", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "x", "=", "self", ".", "beginning_build_order_transformer", "(", "self", ".", "before_beginning_build_order", "(", "beginning_build_order", ")", ")", "\n", "print", "(", "\"x:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "SCHP", ".", "count_beginning_build_order", "*", "16", ")", "\n", "print", "(", "\"x:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# embedded_scalar_list.append(x)", "\n", "\n", "embedded_scalar", "=", "torch", ".", "cat", "(", "embedded_scalar_list", ",", "dim", "=", "1", ")", "\n", "\n", "print", "(", "\"self.baseline_type:\"", ",", "self", ".", "baseline_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"embedded_scalar.shape:\"", ",", "embedded_scalar", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "embedded_scalar", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.baseline.Baseline.forward": [[155, 187], ["baseline.Baseline.Baseline.preprocess", "baseline.Baseline.Baseline.preprocess", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "baseline.Baseline.Baseline.embed_fc", "resblock.unsqueeze", "resblock.squeeze", "torch.relu", "torch.relu", "torch.relu", "baseline.Baseline.Baseline.out_fc", "print", "print", "resblock", "print", "print", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "torch.atan", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess"], ["", "def", "forward", "(", "self", ",", "lstm_output", ",", "various_observations", ",", "opponent_observations", ")", ":", "\n", "        ", "player_scalar_out", "=", "self", ".", "preprocess", "(", "various_observations", ")", "\n", "# AlphaStar: The baseline extracts those same observations from `opponent_observations`.", "\n", "opponenet_scalar_out", "=", "self", ".", "preprocess", "(", "opponent_observations", ")", "\n", "\n", "# AlphaStar: These features are all concatenated together to yield `action_type_input`", "\n", "action_type_input", "=", "torch", ".", "cat", "(", "[", "lstm_output", ",", "player_scalar_out", "]", ",", "dim", "=", "1", ")", "\n", "print", "(", "\"action_type_input.shape:\"", ",", "action_type_input", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: passed through a linear of size 256", "\n", "x", "=", "self", ".", "embed_fc", "(", "action_type_input", ")", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: then passed through 16 ResBlocks with 256 hidden units and layer normalization,", "\n", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "\n", "for", "resblock", "in", "self", ".", "resblock_stack", ":", "\n", "            ", "x", "=", "resblock", "(", "x", ")", "\n", "", "x", "=", "x", ".", "squeeze", "(", "-", "1", ")", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: passed through a ReLU", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "\n", "# AlphaStar: then passed through a linear with 1 hidden unit.", "\n", "baseline", "=", "self", ".", "out_fc", "(", "x", ")", "\n", "print", "(", "\"baseline:\"", ",", "baseline", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: This baseline value is transformed by ((2.0 / PI) * atan((PI / 2.0) * baseline)) and is used as the baseline value", "\n", "out", "=", "(", "2.0", "/", "np", ".", "pi", ")", "*", "torch", ".", "atan", "(", "(", "np", ".", "pi", "/", "2.0", ")", "*", "baseline", ")", "\n", "print", "(", "\"out:\"", ",", "out", ")", "if", "debug", "else", "None", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.baseline.test": [[189, 224], ["baseline.Baseline", "torch.ones", "torch.ones", "torch.ones", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "scalar_list.append", "torch.ones", "torch.ones", "torch.ones", "baseline.Baseline.forward", "int", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "base_line", "=", "Baseline", "(", ")", "\n", "\n", "batch_size", "=", "2", "\n", "# dummy scalar list", "\n", "scalar_list", "=", "[", "]", "\n", "\n", "agent_statistics", "=", "torch", ".", "ones", "(", "batch_size", ",", "SFS", ".", "agent_statistics", ")", "\n", "upgrades", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrades", ")", "\n", "unit_counts_bow", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "units_buildings", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "units_buildings", ")", "\n", "effects", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "effects", ")", "\n", "upgrade", "=", "torch", ".", "randn", "(", "batch_size", ",", "SFS", ".", "upgrade", ")", "\n", "beginning_build_order", "=", "torch", ".", "randn", "(", "batch_size", ",", "SCHP", ".", "count_beginning_build_order", ",", "\n", "int", "(", "SFS", ".", "beginning_build_order", "/", "SCHP", ".", "count_beginning_build_order", ")", ")", "\n", "\n", "scalar_list", ".", "append", "(", "agent_statistics", ")", "\n", "scalar_list", ".", "append", "(", "upgrades", ")", "\n", "scalar_list", ".", "append", "(", "unit_counts_bow", ")", "\n", "scalar_list", ".", "append", "(", "units_buildings", ")", "\n", "scalar_list", ".", "append", "(", "effects", ")", "\n", "scalar_list", ".", "append", "(", "upgrade", ")", "\n", "scalar_list", ".", "append", "(", "beginning_build_order", ")", "\n", "\n", "opponenet_scalar_out", "=", "scalar_list", "\n", "\n", "lstm_output", "=", "torch", ".", "ones", "(", "batch_size", ",", "AHP", ".", "lstm_hidden_dim", ")", "\n", "\n", "out", "=", "base_line", ".", "forward", "(", "lstm_output", ",", "scalar_list", ",", "opponenet_scalar_out", ")", "\n", "\n", "print", "(", "\"out:\"", ",", "out", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"out.shape:\"", ",", "out", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "debug", ":", "\n", "        ", "print", "(", "\"This is a test!\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.__init__": [[36, 50], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "autoregressive_embedding_size", "=", "AHP", ".", "autoregressive_embedding_size", ",", "\n", "original_256", "=", "AHP", ".", "original_256", ",", "max_delay", "=", "SFS", ".", "last_delay", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "autoregressive_embedding_size", ",", "original_256", ")", "# with relu", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_256", ")", "# with relu", "\n", "self", ".", "max_delay", "=", "max_delay", "\n", "\n", "self", ".", "embed_fc", "=", "nn", ".", "Linear", "(", "original_256", ",", "max_delay", ")", "# no relu", "\n", "\n", "self", ".", "fc_3", "=", "nn", ".", "Linear", "(", "max_delay", ",", "original_256", ")", "# with relu", "\n", "self", ".", "fc_4", "=", "nn", ".", "Linear", "(", "original_256", ",", "original_256", ")", "# with relu", "\n", "self", ".", "project", "=", "nn", ".", "Linear", "(", "original_256", ",", "autoregressive_embedding_size", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.preprocess": [[51, 53], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward": [[54, 96], ["delay_head.checkNaNandInf", "torch.relu", "torch.relu", "torch.relu", "delay_head.checkNaNandInf", "torch.relu", "torch.relu", "torch.relu", "delay_head.checkNaNandInf", "delay_head.DelayHead.embed_fc", "delay_head.checkNaNandInf", "delay_head.DelayHead.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "delay_head.checkNaNandInf", "alphastarmini.lib.utils.one_hot_embedding", "delay_one_hot.squeeze.squeeze.squeeze", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "delay_head.DelayHead.project", "delay_head.DelayHead.fc_1", "print", "delay_head.DelayHead.fc_2", "print", "print", "print", "delay_head.DelayHead.fc_3", "delay_head.DelayHead.fc_4"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.one_hot_embedding"], ["", "def", "forward", "(", "self", ",", "autoregressive_embedding", ")", ":", "\n", "        ", "checkNaNandInf", "(", "autoregressive_embedding", ",", "'autoregressive_embedding'", ")", "\n", "\n", "# AlphaStar: `autoregressive_embedding` is decoded using a 2-layer (each with size 256) ", "\n", "# AlphaStar: linear network with ReLUs,", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc_1", "(", "autoregressive_embedding", ")", ")", "\n", "print", "(", "\"x.shape:\"", ",", "x", ".", "shape", ")", "if", "debug", "else", "None", "\n", "checkNaNandInf", "(", "x", ",", "'x'", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc_2", "(", "x", ")", ")", "\n", "checkNaNandInf", "(", "x", ",", "'x'", ")", "\n", "\n", "# AlphaStar: before being embedded into `delay_logits` that has size 128 (one for each ", "\n", "# AlphaStar: possible requested delay in game steps).", "\n", "# note: no temperature used here", "\n", "delay_logits", "=", "self", ".", "embed_fc", "(", "x", ")", "\n", "checkNaNandInf", "(", "delay_logits", ",", "'delay_logits'", ")", "\n", "\n", "# AlphaStar: `delay` is sampled from `delay_logits` using a multinomial, though unlike all other arguments,", "\n", "# AlphaStar: no temperature is applied to `delay_logits` before sampling.", "\n", "delay_probs", "=", "self", ".", "softmax", "(", "delay_logits", ")", "\n", "delay", "=", "torch", ".", "multinomial", "(", "delay_probs", ",", "1", ")", "\n", "checkNaNandInf", "(", "delay", ",", "'delay'", ")", "\n", "print", "(", "\"delay:\"", ",", "delay", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: Similar to `action_type`, `delay` is projected to a 1D tensor of size 1024 through ", "\n", "# AlphaStar: a 2-layer (each with size 256) linear network with ReLUs, and added to `autoregressive_embedding`", "\n", "# similar to action_type here, change it to one_hot version", "\n", "delay_one_hot", "=", "L", ".", "one_hot_embedding", "(", "delay", ",", "self", ".", "max_delay", ")", "\n", "# to make the dim of delay_one_hot as delay", "\n", "delay_one_hot", "=", "delay_one_hot", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "\"delay_one_hot:\"", ",", "delay_one_hot", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"delay_one_hot.shape:\"", ",", "delay_one_hot", ".", "shape", ")", "if", "debug", "else", "None", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "fc_3", "(", "delay_one_hot", ")", ")", "\n", "z", "=", "F", ".", "relu", "(", "self", ".", "fc_4", "(", "z", ")", ")", "\n", "t", "=", "self", ".", "project", "(", "z", ")", "\n", "# the operation may auto broadcasting, so we need a test", "\n", "y", "=", "autoregressive_embedding", "+", "t", "\n", "# make sure autoregressive_embedding has the same shape as y, prevent the auto broadcasting", "\n", "assert", "autoregressive_embedding", ".", "shape", "==", "y", ".", "shape", "\n", "autoregressive_embedding", "=", "y", "\n", "\n", "return", "delay_logits", ",", "delay", ",", "autoregressive_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.checkNaNandInf": [[20, 25], ["torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isinf().any", "torch.isinf().any", "torch.isinf().any", "print", "print", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isinf", "torch.isinf", "torch.isinf"], "function", ["None"], ["def", "checkNaNandInf", "(", "val", ",", "name", ")", ":", "\n", "    ", "if", "torch", ".", "isnan", "(", "val", ")", ".", "any", "(", ")", ":", "\n", "        ", "print", "(", "name", ",", "'Find nan:'", ",", "val", ")", "\n", "", "if", "torch", ".", "isinf", "(", "val", ")", ".", "any", "(", ")", ":", "\n", "        ", "print", "(", "name", ",", "'Find inf:'", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.test": [[98, 116], ["torch.randn", "torch.randn", "torch.randn", "delay_head.DelayHead", "delay_head.DelayHead.forward", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.delay_head.DelayHead.forward"], ["", "", "def", "test", "(", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "autoregressive_embedding", "=", "torch", ".", "randn", "(", "batch_size", ",", "AHP", ".", "autoregressive_embedding_size", ")", "\n", "delay_head", "=", "DelayHead", "(", ")", "\n", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "delay_logits", ",", "delay", ",", "autoregressive_embedding", "=", "delay_head", ".", "forward", "(", "autoregressive_embedding", ")", "\n", "\n", "print", "(", "\"delay_logits:\"", ",", "delay_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"delay_logits.shape:\"", ",", "delay_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"delay:\"", ",", "delay", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"delay.shape:\"", ",", "delay", ".", "shape", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding:\"", ",", "autoregressive_embedding", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"autoregressive_embedding.shape:\"", ",", "autoregressive_embedding", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"This is a test!\"", ")", "if", "debug", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.__init__": [[21, 28], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_players", "=", "[", "]", "\n", "self", ".", "_wins", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "_draws", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "_losses", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "_games", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "self", ".", "_decay", "=", "0.99", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff._win_rate": [[29, 35], ["None"], "methods", ["None"], ["", "def", "_win_rate", "(", "self", ",", "_home", ",", "_away", ")", ":", "\n", "        ", "if", "self", ".", "_games", "[", "_home", ",", "_away", "]", "==", "0", ":", "\n", "            ", "return", "0.5", "\n", "\n", "", "return", "(", "self", ".", "_wins", "[", "_home", ",", "_away", "]", "\n", "+", "0.5", "*", "self", ".", "_draws", "[", "_home", ",", "_away", "]", ")", "/", "self", ".", "_games", "[", "_home", ",", "_away", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.__getitem__": [[36, 49], ["isinstance", "isinstance", "numpy.array", "win_rates.reshape.reshape.reshape", "payoff.Payoff._win_rate"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff._win_rate"], ["", "def", "__getitem__", "(", "self", ",", "match", ")", ":", "\n", "        ", "home", ",", "away", "=", "match", "\n", "\n", "if", "isinstance", "(", "home", ",", "Player", ")", ":", "\n", "            ", "home", "=", "[", "home", "]", "\n", "", "if", "isinstance", "(", "away", ",", "Player", ")", ":", "\n", "            ", "away", "=", "[", "away", "]", "\n", "\n", "", "win_rates", "=", "np", ".", "array", "(", "[", "[", "self", ".", "_win_rate", "(", "h", ",", "a", ")", "for", "a", "in", "away", "]", "for", "h", "in", "home", "]", ")", "\n", "if", "win_rates", ".", "shape", "[", "0", "]", "==", "1", "or", "win_rates", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "            ", "win_rates", "=", "win_rates", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "", "return", "win_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.update": [[50, 66], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "home", ",", "away", ",", "result", ")", ":", "\n", "        ", "for", "stats", "in", "(", "self", ".", "_games", ",", "self", ".", "_wins", ",", "self", ".", "_draws", ",", "self", ".", "_losses", ")", ":", "\n", "            ", "stats", "[", "home", ",", "away", "]", "*=", "self", ".", "_decay", "\n", "stats", "[", "away", ",", "home", "]", "*=", "self", ".", "_decay", "\n", "\n", "", "self", ".", "_games", "[", "home", ",", "away", "]", "+=", "1", "\n", "self", ".", "_games", "[", "away", ",", "home", "]", "+=", "1", "\n", "if", "result", "==", "\"win\"", ":", "\n", "            ", "self", ".", "_wins", "[", "home", ",", "away", "]", "+=", "1", "\n", "self", ".", "_losses", "[", "away", ",", "home", "]", "+=", "1", "\n", "", "elif", "result", "==", "\"draw\"", ":", "\n", "            ", "self", ".", "_draws", "[", "home", ",", "away", "]", "+=", "1", "\n", "self", ".", "_draws", "[", "away", ",", "home", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "_wins", "[", "away", ",", "home", "]", "+=", "1", "\n", "self", ".", "_losses", "[", "home", ",", "away", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.add_player": [[67, 69], ["payoff.Payoff._players.append"], "methods", ["None"], ["", "", "def", "add_player", "(", "self", ",", "player", ")", ":", "\n", "        ", "self", ".", "_players", ".", "append", "(", "player", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.get_players_num": [[70, 72], ["len"], "methods", ["None"], ["", "def", "get_players_num", "(", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_players", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.payoff.Payoff.players": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "players", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_players", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.learner": [[20, 23], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "learner", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_learner", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.set_learner": [[24, 26], ["None"], "methods", ["None"], ["", "def", "set_learner", "(", "self", ",", "learner", ")", ":", "\n", "        ", "self", ".", "_learner", "=", "learner", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.actors": [[27, 30], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "actors", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_actors", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.add_actor": [[31, 33], ["player.Player._actors.append"], "methods", ["None"], ["", "def", "add_actor", "(", "self", ",", "actor", ")", ":", "\n", "        ", "self", ".", "_actors", ".", "append", "(", "actor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.get_match": [[34, 36], ["None"], "methods", ["None"], ["", "def", "get_match", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.ready_to_checkpoint": [[37, 39], ["None"], "methods", ["None"], ["", "def", "ready_to_checkpoint", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player._create_checkpoint": [[40, 43], ["player.Historical"], "methods", ["None"], ["", "def", "_create_checkpoint", "(", "self", ")", ":", "\n", "# AlphaStar\uff1a return Historical(self, self.payoff)", "\n", "        ", "return", "Historical", "(", "self", ".", "agent", ",", "self", ".", "_payoff", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.payoff": [[44, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "payoff", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_payoff", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.race": [[48, 51], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "race", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_race", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.checkpoint": [[52, 54], ["None"], "methods", ["None"], ["", "def", "checkpoint", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.setup": [[55, 57], ["player.Player.agent.setup"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup"], ["", "def", "setup", "(", "self", ",", "obs_spec", ",", "action_spec", ")", ":", "\n", "        ", "self", ".", "agent", ".", "setup", "(", "obs_spec", ",", "action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.reset": [[58, 60], ["player.Player.agent.reset"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Historical.__init__": [[64, 72], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "agent.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["    ", "def", "__init__", "(", "self", ",", "agent", ",", "payoff", ")", ":", "\n", "# AlphaStar\uff1a self._agent = Agent(agent.race, agent.get_weights())", "\n", "        ", "self", ".", "agent", "=", "AlphaStarAgent", "(", "name", "=", "\"Historical\"", ",", "race", "=", "agent", ".", "race", ",", "initial_weights", "=", "agent", ".", "get_weights", "(", ")", ")", "\n", "self", ".", "_payoff", "=", "payoff", "\n", "self", ".", "_race", "=", "agent", ".", "race", "\n", "self", ".", "_parent", "=", "agent", "\n", "self", ".", "name", "=", "\"Historical\"", "\n", "self", ".", "_actors", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Historical.parent": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "parent", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_parent", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Historical.get_match": [[77, 79], ["ValueError"], "methods", ["None"], ["", "def", "get_match", "(", "self", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Historical players should not request matches\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Historical.ready_to_checkpoint": [[80, 82], ["None"], "methods", ["None"], ["", "def", "ready_to_checkpoint", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer.__init__": [[86, 95], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "agent.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["    ", "def", "__init__", "(", "self", ",", "race", ",", "agent", ",", "payoff", ")", ":", "\n", "        ", "self", ".", "agent", "=", "AlphaStarAgent", "(", "name", "=", "\"MainPlayer\"", ",", "race", "=", "race", ",", "initial_weights", "=", "agent", ".", "get_weights", "(", ")", ")", "\n", "# actually the _payoff maintains all the players and their fight results", "\n", "# maybe this should be the league, making it more reasonable", "\n", "self", ".", "_payoff", "=", "payoff", "\n", "self", ".", "_race", "=", "agent", ".", "race", "\n", "self", ".", "_checkpoint_step", "=", "0", "\n", "self", ".", "name", "=", "\"MainPlayer\"", "\n", "self", ".", "_actors", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._pfsp_branch": [[96, 104], ["numpy.random.choice", "isinstance", "alphastarmini.core.ma.pfsp.pfsp"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.pfsp.pfsp"], ["", "def", "_pfsp_branch", "(", "self", ")", ":", "\n", "        ", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "return", "np", ".", "random", ".", "choice", "(", "\n", "historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"squared\"", ")", ")", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._selfplay_branch": [[105, 119], ["numpy.random.choice", "isinstance", "alphastarmini.core.ma.pfsp.pfsp"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.pfsp.pfsp"], ["", "def", "_selfplay_branch", "(", "self", ",", "opponent", ")", ":", "\n", "# Play self-play match", "\n", "        ", "if", "self", ".", "_payoff", "[", "self", ",", "opponent", "]", ">", "0.3", ":", "\n", "            ", "return", "opponent", ",", "False", "\n", "\n", "# If opponent is too strong, look for a checkpoint", "\n", "# as curriculum", "\n", "", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "and", "player", ".", "parent", "==", "opponent", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "return", "np", ".", "random", ".", "choice", "(", "\n", "historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"variance\"", ")", ")", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._verification_branch": [[120, 160], ["set", "player.MainPlayer._verification_branch.remove_monotonic_suffix"], "methods", ["None"], ["", "def", "_verification_branch", "(", "self", ",", "opponent", ")", ":", "\n", "# Check exploitation", "\n", "        ", "exploiters", "=", "set", "(", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "MainExploiter", ")", "\n", "]", ")", "\n", "# Q: What is the player.parent?", "\n", "# A: This is only the property of Historical", "\n", "exp_historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "and", "player", ".", "parent", "in", "exploiters", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "exp_historical", "]", "\n", "if", "len", "(", "win_rates", ")", "and", "win_rates", ".", "min", "(", ")", "<", "0.3", ":", "\n", "            ", "return", "np", ".", "random", ".", "choice", "(", "\n", "exp_historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"squared\"", ")", ")", ",", "True", "\n", "\n", "# Check forgetting", "\n", "", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "and", "player", ".", "parent", "==", "opponent", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "\n", "def", "remove_monotonic_suffix", "(", "win_rates", ",", "players", ")", ":", "\n", "            ", "if", "not", "win_rates", ":", "\n", "                ", "return", "win_rates", ",", "players", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "win_rates", ")", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "if", "win_rates", "[", "i", "-", "1", "]", "<", "win_rates", "[", "i", "]", ":", "\n", "                    ", "return", "win_rates", "[", ":", "i", "+", "1", "]", ",", "players", "[", ":", "i", "+", "1", "]", "\n", "\n", "", "", "return", "np", ".", "array", "(", "[", "]", ")", ",", "[", "]", "\n", "\n", "", "win_rates", ",", "historical", "=", "remove_monotonic_suffix", "(", "win_rates", ",", "historical", ")", "\n", "if", "len", "(", "win_rates", ")", "and", "win_rates", ".", "min", "(", ")", "<", "0.7", ":", "\n", "            ", "return", "np", ".", "random", ".", "choice", "(", "\n", "historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"squared\"", ")", ")", ",", "True", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer.get_match": [[161, 181], ["numpy.random.random", "numpy.random.choice", "player.MainPlayer._selfplay_branch", "player.MainPlayer._pfsp_branch", "player.MainPlayer._verification_branch", "isinstance"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._selfplay_branch", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._pfsp_branch", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer._verification_branch"], ["", "def", "get_match", "(", "self", ")", ":", "\n", "        ", "coin_toss", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "\n", "# Make sure you can beat the League", "\n", "if", "coin_toss", "<", "0.5", ":", "\n", "            ", "return", "self", ".", "_pfsp_branch", "(", ")", "\n", "\n", "", "main_agents", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "MainPlayer", ")", "\n", "]", "\n", "opponent", "=", "np", ".", "random", ".", "choice", "(", "main_agents", ")", "\n", "\n", "# Verify if there are some rare players we omitted", "\n", "if", "coin_toss", "<", "0.5", "+", "0.15", ":", "\n", "            ", "request", "=", "self", ".", "_verification_branch", "(", "opponent", ")", "\n", "if", "request", "is", "not", "None", ":", "\n", "                ", "return", "request", "\n", "\n", "", "", "return", "self", ".", "_selfplay_branch", "(", "opponent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer.ready_to_checkpoint": [[182, 193], ["player.MainPlayer.agent.get_steps", "isinstance", "win_rates.min"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps"], ["", "def", "ready_to_checkpoint", "(", "self", ")", ":", "\n", "        ", "steps_passed", "=", "self", ".", "agent", ".", "get_steps", "(", ")", "-", "self", ".", "_checkpoint_step", "\n", "if", "steps_passed", "<", "2e9", ":", "\n", "            ", "return", "False", "\n", "\n", "", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "return", "win_rates", ".", "min", "(", ")", ">", "0.7", "or", "steps_passed", ">", "4e9", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainPlayer.checkpoint": [[194, 197], ["player.MainPlayer.agent.get_steps", "player.MainPlayer._create_checkpoint"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player._create_checkpoint"], ["", "def", "checkpoint", "(", "self", ")", ":", "\n", "        ", "self", ".", "_checkpoint_step", "=", "self", ".", "agent", ".", "get_steps", "(", ")", "\n", "return", "self", ".", "_create_checkpoint", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainExploiter.__init__": [[201, 209], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "agent.get_weights", "agent.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["    ", "def", "__init__", "(", "self", ",", "race", ",", "agent", ",", "payoff", ")", ":", "\n", "        ", "self", ".", "agent", "=", "AlphaStarAgent", "(", "name", "=", "\"MainExploiter\"", ",", "race", "=", "race", ",", "initial_weights", "=", "agent", ".", "get_weights", "(", ")", ")", "\n", "self", ".", "_initial_weights", "=", "agent", ".", "get_weights", "(", ")", "\n", "self", ".", "_payoff", "=", "payoff", "\n", "self", ".", "_race", "=", "agent", ".", "race", "\n", "self", ".", "_checkpoint_step", "=", "0", "\n", "self", ".", "name", "=", "\"MainExploiter\"", "\n", "self", ".", "_actors", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainExploiter.get_match": [[210, 228], ["numpy.random.choice", "numpy.random.choice", "isinstance", "isinstance", "alphastarmini.core.ma.pfsp.pfsp"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.pfsp.pfsp"], ["", "def", "get_match", "(", "self", ")", ":", "\n", "        ", "main_agents", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "MainPlayer", ")", "\n", "]", "\n", "opponent", "=", "np", ".", "random", ".", "choice", "(", "main_agents", ")", "\n", "\n", "if", "self", ".", "_payoff", "[", "self", ",", "opponent", "]", ">", "0.1", ":", "\n", "            ", "return", "opponent", ",", "True", "\n", "\n", "", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "and", "player", ".", "parent", "==", "opponent", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "\n", "return", "np", ".", "random", ".", "choice", "(", "\n", "historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"variance\"", ")", ")", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainExploiter.checkpoint": [[229, 233], ["player.MainExploiter.agent.set_weights", "player.MainExploiter.agent.get_steps", "player.MainExploiter._create_checkpoint"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.set_weights", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player._create_checkpoint"], ["", "def", "checkpoint", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "set_weights", "(", "self", ".", "_initial_weights", ")", "\n", "self", ".", "_checkpoint_step", "=", "self", ".", "agent", ".", "get_steps", "(", ")", "\n", "return", "self", ".", "_create_checkpoint", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.MainExploiter.ready_to_checkpoint": [[234, 245], ["player.MainExploiter.agent.get_steps", "isinstance", "win_rates.min"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps"], ["", "def", "ready_to_checkpoint", "(", "self", ")", ":", "\n", "        ", "steps_passed", "=", "self", ".", "agent", ".", "get_steps", "(", ")", "-", "self", ".", "_checkpoint_step", "\n", "if", "steps_passed", "<", "2e9", ":", "\n", "            ", "return", "False", "\n", "\n", "", "main_agents", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "MainPlayer", ")", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "main_agents", "]", "\n", "return", "win_rates", ".", "min", "(", ")", ">", "0.7", "or", "steps_passed", ">", "4e9", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.__init__": [[249, 257], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "agent.get_weights", "agent.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["    ", "def", "__init__", "(", "self", ",", "race", ",", "agent", ",", "payoff", ")", ":", "\n", "        ", "self", ".", "agent", "=", "AlphaStarAgent", "(", "name", "=", "\"LeagueExploiter\"", ",", "race", "=", "race", ",", "initial_weights", "=", "agent", ".", "get_weights", "(", ")", ")", "\n", "self", ".", "_initial_weights", "=", "agent", ".", "get_weights", "(", ")", "\n", "self", ".", "_payoff", "=", "payoff", "\n", "self", ".", "_race", "=", "agent", ".", "race", "\n", "self", ".", "_checkpoint_step", "=", "0", "\n", "self", ".", "name", "=", "\"LeagueExploiter\"", "\n", "self", ".", "_actors", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.get_match": [[258, 267], ["numpy.random.choice", "isinstance", "alphastarmini.core.ma.pfsp.pfsp"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.pfsp.pfsp"], ["", "def", "get_match", "(", "self", ")", ":", "\n", "        ", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "return", "np", ".", "random", ".", "choice", "(", "\n", "\n", "historical", ",", "p", "=", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"linear_capped\"", ")", ")", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.checkpoint": [[268, 273], ["player.LeagueExploiter.agent.get_steps", "player.LeagueExploiter._create_checkpoint", "numpy.random.random", "player.LeagueExploiter.agent.set_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player._create_checkpoint", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.set_weights"], ["", "def", "checkpoint", "(", "self", ")", ":", "\n", "        ", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.25", ":", "\n", "            ", "self", ".", "agent", ".", "set_weights", "(", "self", ".", "_initial_weights", ")", "\n", "", "self", ".", "_checkpoint_step", "=", "self", ".", "agent", ".", "get_steps", "(", ")", "\n", "return", "self", ".", "_create_checkpoint", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.ready_to_checkpoint": [[274, 284], ["player.LeagueExploiter._agent.get_steps", "isinstance", "win_rates.min"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps"], ["", "def", "ready_to_checkpoint", "(", "self", ")", ":", "\n", "        ", "steps_passed", "=", "self", ".", "_agent", ".", "get_steps", "(", ")", "-", "self", ".", "_checkpoint_step", "\n", "if", "steps_passed", "<", "2e9", ":", "\n", "            ", "return", "False", "\n", "", "historical", "=", "[", "\n", "player", "for", "player", "in", "self", ".", "_payoff", ".", "players", "\n", "if", "isinstance", "(", "player", ",", "Historical", ")", "\n", "]", "\n", "win_rates", "=", "self", ".", "_payoff", "[", "self", ",", "historical", "]", "\n", "return", "win_rates", ".", "min", "(", ")", ">", "0.7", "or", "steps_passed", ">", "4e9", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.ma_train.league_train": [[24, 61], ["League", "alphastarmini.core.ma.coordinator.Coordinator", "range", "League.get_learning_players_num", "League.get_learning_player", "alphastarmini.core.rl.learner.Learner", "learners.append", "actors.extend", "l.start", "threads.append", "sleep", "a.start", "threads.append", "sleep", "t.join", "print", "alphastarmini.core.rl.utils.get_supervised_agent", "alphastarmini.core.rl.actor.ActorLoop", "range"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_players_num", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_supervised_agent"], ["def", "league_train", "(", ")", ":", "\n", "    ", "\"\"\"Trains the AlphaStar league.\"\"\"", "\n", "league", "=", "League", "(", "\n", "initial_agents", "=", "{", "\n", "race", ":", "get_supervised_agent", "(", "race", ")", "\n", "for", "race", "in", "[", "Race", ".", "protoss", "]", "\n", "}", ",", "\n", "main_players", "=", "1", ",", "\n", "main_exploiters", "=", "1", ",", "\n", "league_exploiters", "=", "2", ")", "\n", "\n", "coordinator", "=", "Coordinator", "(", "league", ")", "\n", "learners", "=", "[", "]", "\n", "actors", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "league", ".", "get_learning_players_num", "(", ")", ")", ":", "\n", "        ", "player", "=", "league", ".", "get_learning_player", "(", "idx", ")", "\n", "learner", "=", "Learner", "(", "player", ")", "\n", "learners", ".", "append", "(", "learner", ")", "\n", "actors", ".", "extend", "(", "[", "ActorLoop", "(", "player", ",", "coordinator", ")", "for", "_", "in", "range", "(", "1", ")", "]", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "l", "in", "learners", ":", "\n", "        ", "l", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "l", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "", "for", "a", "in", "actors", ":", "\n", "        ", "a", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "a", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "# Wait for training to finish.", "\n", "        ", "for", "t", "in", "threads", ":", "\n", "            ", "t", ".", "join", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Exception Handled in Main, Detials of the Exception:\"", ",", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.ma_train.test": [[63, 67], ["None"], "function", ["None"], ["", "", "def", "test", "(", "on_server", ")", ":", "\n", "# get all the data", "\n", "# Note: The feature here is actually feature+label", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.pfsp.pfsp": [[15, 28], ["fn", "fn.sum", "numpy.asarray", "numpy.minimum", "numpy.ones_like", "len"], "function", ["None"], ["def", "pfsp", "(", "win_rates", ",", "weighting", "=", "\"linear\"", ")", ":", "\n", "    ", "weightings", "=", "{", "\n", "\"variance\"", ":", "lambda", "x", ":", "x", "*", "(", "1", "-", "x", ")", ",", "\n", "\"linear\"", ":", "lambda", "x", ":", "1", "-", "x", ",", "\n", "\"linear_capped\"", ":", "lambda", "x", ":", "np", ".", "minimum", "(", "0.5", ",", "1", "-", "x", ")", ",", "\n", "\"squared\"", ":", "lambda", "x", ":", "(", "1", "-", "x", ")", "**", "2", ",", "\n", "}", "\n", "fn", "=", "weightings", "[", "weighting", "]", "\n", "probs", "=", "fn", "(", "np", ".", "asarray", "(", "win_rates", ")", ")", "\n", "norm", "=", "probs", ".", "sum", "(", ")", "\n", "if", "norm", "<", "1e-10", ":", "\n", "        ", "return", "np", ".", "ones_like", "(", "win_rates", ")", "/", "len", "(", "win_rates", ")", "\n", "", "return", "probs", "/", "norm", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.__init__": [[21, 50], ["alphastarmini.core.ma.payoff.Payoff", "len", "range", "range", "range", "league.League._payoff.add_player", "alphastarmini.core.ma.player.MainPlayer", "league.League._learning_players.append", "league.League._payoff.add_player", "league.League._learning_players.append", "league.League._learning_players.append", "alphastarmini.core.ma.player.MainPlayer.checkpoint", "alphastarmini.core.ma.player.MainExploiter", "alphastarmini.core.ma.player.LeagueExploiter"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.add_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.add_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.checkpoint"], ["    ", "def", "__init__", "(", "self", ",", "\n", "initial_agents", ",", "\n", "main_players", "=", "1", ",", "\n", "main_exploiters", "=", "1", ",", "\n", "league_exploiters", "=", "2", ")", ":", "\n", "        ", "self", ".", "_payoff", "=", "Payoff", "(", ")", "\n", "self", ".", "_learning_players", "=", "[", "]", "\n", "\n", "for", "race", "in", "initial_agents", ":", "\n", "            ", "for", "_", "in", "range", "(", "main_players", ")", ":", "\n", "                ", "main_player", "=", "MP", "(", "race", ",", "initial_agents", "[", "race", "]", ",", "self", ".", "_payoff", ")", "\n", "self", ".", "_learning_players", ".", "append", "(", "main_player", ")", "\n", "\n", "# add Historcal (snapshot) player", "\n", "self", ".", "_payoff", ".", "add_player", "(", "main_player", ".", "checkpoint", "(", ")", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "main_exploiters", ")", ":", "\n", "                ", "self", ".", "_learning_players", ".", "append", "(", "\n", "ME", "(", "race", ",", "initial_agents", "[", "race", "]", ",", "self", ".", "_payoff", ")", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "league_exploiters", ")", ":", "\n", "                ", "self", ".", "_learning_players", ".", "append", "(", "\n", "LE", "(", "race", ",", "initial_agents", "[", "race", "]", ",", "self", ".", "_payoff", ")", ")", "\n", "\n", "# add MP, ME, LE player", "\n", "", "", "for", "player", "in", "self", ".", "_learning_players", ":", "\n", "            ", "self", ".", "_payoff", ".", "add_player", "(", "player", ")", "\n", "\n", "", "self", ".", "_learning_players_num", "=", "len", "(", "self", ".", "_learning_players", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.update": [[51, 53], ["league.League._payoff.update"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.update"], ["", "def", "update", "(", "self", ",", "home", ",", "away", ",", "result", ")", ":", "\n", "        ", "return", "self", ".", "_payoff", ".", "update", "(", "home", ",", "away", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_player": [[54, 56], ["None"], "methods", ["None"], ["", "def", "get_learning_player", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "_learning_players", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.add_player": [[57, 59], ["league.League._payoff.add_player"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.add_player"], ["", "def", "add_player", "(", "self", ",", "player", ")", ":", "\n", "        ", "self", ".", "_payoff", ".", "add_player", "(", "player", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_players_num": [[60, 62], ["None"], "methods", ["None"], ["", "def", "get_learning_players_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_learning_players_num", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_players_num": [[63, 65], ["league.League._payoff.get_players_num"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_players_num"], ["", "def", "get_players_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_payoff", ".", "get_players_num", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.coordinator.Coordinator.__init__": [[16, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "league", ")", ":", "\n", "        ", "self", ".", "league", "=", "league", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.coordinator.Coordinator.send_outcome": [[19, 26], ["coordinator.Coordinator.league.update", "home_player.ready_to_checkpoint", "coordinator.Coordinator.league.add_player", "home_player.checkpoint"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.update", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.ready_to_checkpoint", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.add_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.LeagueExploiter.checkpoint"], ["", "def", "send_outcome", "(", "self", ",", "home_player", ",", "away_player", ",", "outcome", ")", ":", "\n", "        ", "self", ".", "league", ".", "update", "(", "home_player", ",", "away_player", ",", "outcome", ")", "\n", "\n", "if", "home_player", ".", "ready_to_checkpoint", "(", ")", ":", "\n", "# is the responsibility of the coordinator to add player in the league", "\n", "# actually it is added to to the payoff", "\n", "            ", "self", ".", "league", ".", "add_player", "(", "home_player", ".", "checkpoint", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.__init__": [[19, 35], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "entity_state", "=", "None", ",", "statistical_state", "=", "None", ",", "map_state", "=", "None", ")", ":", "\n", "        ", "super", "(", "MsState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# called enetity state in alphastar", "\n", "# tensor, shape: [batch_size, entity_size, embedding_size]", "\n", "self", ".", "entity_state", "=", "entity_state", "\n", "\n", "# called scalar state in alphastar", "\n", "# list of tensors, the reason for why this not be combined as one tensor is due to ", "\n", "# that we need do different pre-processing for different statistica", "\n", "self", ".", "statistical_state", "=", "statistical_state", "\n", "\n", "# called spatital state in alphastar", "\n", "# tensor, shape: [batch_size, channel_size, width, height]", "\n", "self", ".", "map_state", "=", "map_state", "\n", "\n", "self", ".", "_shape", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState._get_shape": [[36, 46], ["str", "str", "str"], "methods", ["None"], ["", "def", "_get_shape", "(", "self", ")", ":", "\n", "        ", "shape1", "=", "str", "(", "self", ".", "entity_state", ".", "shape", ")", "\n", "shape2", "=", "[", "\"%s\"", "%", "str", "(", "s", ".", "shape", ")", "for", "s", "in", "self", ".", "statistical_state", "]", "\n", "shape3", "=", "str", "(", "self", ".", "map_state", ".", "shape", ")", "\n", "\n", "self", ".", "shape1", "=", "'\\nentity_state: '", "+", "shape1", "+", "';'", "\n", "self", ".", "shape2", "=", "'\\nstatistical_state: '", "+", "','", ".", "join", "(", "shape2", ")", "+", "';'", "\n", "self", ".", "shape3", "=", "'\\nmap_state: '", "+", "shape3", "+", "'.'", "\n", "\n", "self", ".", "_shape", "=", "self", ".", "shape1", "+", "self", ".", "shape2", "+", "self", ".", "shape3", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.toList": [[47, 49], ["None"], "methods", ["None"], ["", "def", "toList", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "entity_state", ",", "self", ".", "statistical_state", ",", "self", ".", "map_state", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.to": [[50, 59], ["state.MsState.entity_state.to().float", "state.MsState.map_state.to().float", "print", "print", "s.to().float", "state.MsState.entity_state.to", "state.MsState.map_state.to", "s.to"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "\n", "        ", "print", "(", "'self.entity_state.device:'", ",", "self", ".", "entity_state", ".", "device", ")", "if", "debug", "else", "None", "\n", "self", ".", "entity_state", "=", "self", ".", "entity_state", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "print", "(", "'self.entity_state.device:'", ",", "self", ".", "entity_state", ".", "device", ")", "if", "debug", "else", "None", "\n", "\n", "self", ".", "statistical_state", "=", "[", "s", ".", "to", "(", "device", ")", ".", "float", "(", ")", "for", "s", "in", "self", ".", "statistical_state", "]", "\n", "\n", "self", ".", "map_state", "=", "self", ".", "map_state", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.shape": [[62, 68], ["state.MsState._get_shape"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState._get_shape"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_shape", "is", "None", ":", "\n", "            ", "self", ".", "_get_shape", "(", ")", "\n", "\n", "", "return", "self", ".", "_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.device": [[69, 72], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "entity_state", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState.__str__": [[73, 79], ["state.MsState._get_shape"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.state.MsState._get_shape"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "# \"Multi-source State\"", "\n", "        ", "if", "self", ".", "_shape", "is", "None", ":", "\n", "            ", "self", ".", "_get_shape", "(", ")", "\n", "\n", "", "return", "self", ".", "_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_train_RAS.test": [[35, 76], ["alphastarmini.core.ma.league.League", "alphastarmini.core.ma.coordinator.Coordinator", "range", "alphastarmini.core.ma.league.League.get_learning_players_num", "alphastarmini.core.ma.league.League.get_learning_player", "alphastarmini.core.rl.learner.Learner", "learners.append", "actors.extend", "l.start", "threads.append", "time.sleep", "a.start", "threads.append", "time.sleep", "t.join", "print", "alphastarmini.core.rl.utils.get_reinforcement_agent", "alphastarmini.core.rl.actor_RAS.ActorLoopRAS", "range"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_players_num", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_reinforcement_agent"], ["def", "test", "(", "on_server", "=", "False", ",", "replay_path", "=", "None", ")", ":", "\n", "# model path", "\n", "    ", "ACTOR_NUMS", "=", "P", ".", "actor_nums", "\n", "RESTORE", "=", "False", "\n", "model_name", "=", "\"rl_21-08-04_11-08-04.pkl\"", "\n", "\n", "league", "=", "League", "(", "\n", "initial_agents", "=", "{", "\n", "race", ":", "U", ".", "get_reinforcement_agent", "(", "race", ",", "restore", "=", "RESTORE", ",", "model_name", "=", "model_name", ")", "\n", "for", "race", "in", "[", "Race", ".", "protoss", "]", "\n", "}", ",", "\n", "main_players", "=", "1", ",", "\n", "main_exploiters", "=", "0", ",", "\n", "league_exploiters", "=", "0", ")", "\n", "\n", "coordinator", "=", "Coordinator", "(", "league", ")", "\n", "learners", "=", "[", "]", "\n", "actors", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "league", ".", "get_learning_players_num", "(", ")", ")", ":", "\n", "        ", "player", "=", "league", ".", "get_learning_player", "(", "idx", ")", "\n", "learner", "=", "Learner", "(", "player", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ")", "\n", "learners", ".", "append", "(", "learner", ")", "\n", "actors", ".", "extend", "(", "[", "ActorLoopRAS", "(", "player", ",", "coordinator", ",", "replay_path", "=", "replay_path", ",", "record", "=", "z", "==", "0", ")", "for", "z", "in", "range", "(", "ACTOR_NUMS", ")", "]", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "l", "in", "learners", ":", "\n", "        ", "l", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "l", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "", "for", "a", "in", "actors", ":", "\n", "        ", "a", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "a", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "# Wait for training to finish.", "\n", "        ", "for", "t", "in", "threads", ":", "\n", "            ", "t", ".", "join", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Exception Handled in Main, Detials of the Exception:\"", ",", "e", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.__init__": [[32, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ")", ":", "\n", "# agent name", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "reward", "=", "0", "\n", "self", ".", "episodes", "=", "0", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "obs_spec", "=", "None", "\n", "self", ".", "action_spec", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup": [[41, 44], ["None"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "obs_spec", ",", "action_spec", ")", ":", "\n", "        ", "self", ".", "obs_spec", "=", "obs_spec", "\n", "self", ".", "action_spec", "=", "action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.reset": [[45, 47], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "episodes", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.step": [[48, 55], ["pysc2.lib.actions.FunctionCall"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "        ", "self", ".", "steps", "+=", "1", "\n", "self", ".", "reward", "+=", "obs", ".", "reward", "\n", "\n", "func_call", "=", "actions", ".", "FunctionCall", "(", "actions", ".", "FUNCTIONS", ".", "no_op", ".", "id", ",", "[", "]", ")", "\n", "\n", "return", "func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.RandomAgent.__init__": [[60, 65], ["alphastar_agent.BaseAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "name", ",", "raw", "=", "True", ")", ":", "\n", "        ", "super", "(", "RandomAgent", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "\n", "# whether use raw actions", "\n", "self", ".", "use_raw", "=", "raw", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.RandomAgent.step": [[66, 92], ["alphastar_agent.BaseAgent.step", "pysc2.lib.actions.FunctionCall.init_with_validation", "print", "numpy.random.choice", "numpy.random.choice", "print", "print", "print", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step"], ["", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "        ", "noop_func_call", "=", "super", "(", "RandomAgent", ",", "self", ")", ".", "step", "(", "obs", ")", "\n", "\n", "print", "(", "'name:'", ",", "self", ".", "name", ")", "if", "debug", "else", "None", "\n", "\n", "observation", "=", "obs", ".", "observation", "\n", "if", "not", "self", ".", "use_raw", ":", "\n", "# print('obs.observation.available_actions:', obs.observation.available_actions)", "\n", "            ", "function_id", "=", "np", ".", "random", ".", "choice", "(", "observation", ".", "available_actions", ")", "\n", "", "else", ":", "\n", "            ", "ids", "=", "[", "f", ".", "id", "for", "f", "in", "actions", ".", "RAW_FUNCTIONS", "if", "f", ".", "avail_fn", "]", "\n", "function_id", "=", "np", ".", "random", ".", "choice", "(", "ids", ")", "\n", "\n", "", "print", "(", "'function_id:'", ",", "function_id", ")", "if", "debug", "else", "None", "\n", "args", "=", "[", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "size", ")", "for", "size", "in", "arg", ".", "sizes", "]", "\n", "for", "arg", "in", "self", ".", "action_spec", ".", "functions", "[", "function_id", "]", ".", "args", "]", "\n", "print", "(", "'args:'", ",", "args", ")", "if", "debug", "else", "None", "\n", "\n", "func_call", "=", "actions", ".", "FunctionCall", ".", "init_with_validation", "(", "function_id", ",", "args", ",", "raw", "=", "self", ".", "use_raw", ")", "\n", "print", "(", "'func_call:'", ",", "func_call", ")", "if", "debug", "else", "None", "\n", "\n", "if", "func_call", "is", "not", "None", ":", "\n", "            ", "return", "func_call", "\n", "", "else", ":", "\n", "# only return base action (no-op)", "\n", "            ", "return", "noop_func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.__init__": [[103, 119], ["alphastar_agent.RandomAgent.__init__", "alphastar_agent.AlphaStarAgent.initial_state", "alphastarmini.core.arch.agent.Agent", "alphastarmini.core.arch.agent.Agent", "alphastar_agent.AlphaStarAgent.agent_nn.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["def", "__init__", "(", "self", ",", "name", ",", "race", "=", "sc2_env", ".", "Race", ".", "protoss", ",", "initial_weights", "=", "None", ")", ":", "\n", "# AlphaStarAgent use raw actions", "\n", "        ", "super", "(", "AlphaStarAgent", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ",", "raw", "=", "True", ")", "\n", "\n", "self", ".", "race", "=", "race", "\n", "self", ".", "weights", "=", "initial_weights", "\n", "\n", "# initial the neural network agent with the initial weights", "\n", "if", "self", ".", "weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "agent_nn", "=", "Agent", "(", "self", ".", "weights", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_nn", "=", "Agent", "(", ")", "\n", "self", ".", "weights", "=", "self", ".", "agent_nn", ".", "get_weights", "(", ")", "\n", "\n", "# init lstm hidden state", "\n", "", "self", ".", "memory_state", "=", "self", ".", "initial_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state": [[120, 126], ["alphastar_agent.AlphaStarAgent.agent_nn.init_hidden_state"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.init_hidden_state"], ["", "def", "initial_state", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the hidden state of the agent for the start of an episode.\"\"\"", "\n", "# Network details elided.", "\n", "initial_state", "=", "self", ".", "agent_nn", ".", "init_hidden_state", "(", ")", "\n", "\n", "return", "initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.reset": [[127, 131], ["alphastar_agent.AlphaStarAgent.initial_state"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# init lstm hidden state", "\n", "        ", "self", ".", "episodes", "+=", "1", "\n", "self", ".", "memory_state", "=", "self", ".", "initial_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.set_weights": [[132, 135], ["alphastar_agent.AlphaStarAgent.agent_nn.set_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.set_weights"], ["", "def", "set_weights", "(", "self", ",", "weights", ")", ":", "\n", "        ", "self", ".", "weights", "=", "weights", "\n", "self", ".", "agent_nn", ".", "set_weights", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights": [[136, 142], ["alphastar_agent.AlphaStarAgent.agent_nn.get_weights"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_weights"], ["", "def", "get_weights", "(", "self", ")", ":", "\n", "#assert self.weights == self.agent_nn.get_weights()", "\n", "        ", "if", "self", ".", "agent_nn", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "agent_nn", ".", "get_weights", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_parameters": [[143, 145], ["alphastar_agent.AlphaStarAgent.agent_nn.model.parameters"], "methods", ["None"], ["", "", "def", "get_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "agent_nn", ".", "model", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.get_steps": [[146, 150], ["None"], "methods", ["None"], ["", "def", "get_steps", "(", "self", ")", ":", "\n", "        ", "\"\"\"How many agent steps the agent has been trained for.\"\"\"", "\n", "\n", "return", "self", ".", "steps", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_nn": [[151, 165], ["alphastar_agent.AlphaStarAgent.agent_nn.preprocess_state_all", "alphastar_agent.AlphaStarAgent.agent_nn.device", "alphastar_agent.AlphaStarAgent.to", "alphastar_agent.AlphaStarAgent.agent_nn.action_logits_by_state", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_all", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.device", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_logits_by_state"], ["", "def", "step_nn", "(", "self", ",", "observation", ",", "last_state", ")", ":", "\n", "        ", "\"\"\"Performs inference on the observation, given hidden state last_state.\"\"\"", "\n", "state", "=", "self", ".", "agent_nn", ".", "preprocess_state_all", "(", "observation", ")", "\n", "device", "=", "self", ".", "agent_nn", ".", "device", "(", ")", "\n", "\n", "print", "(", "\"step_nn device:\"", ",", "device", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"state:\"", ",", "state", ")", "if", "debug", "else", "None", "\n", "state", ".", "to", "(", "device", ")", "\n", "print", "(", "\"state:\"", ",", "state", ")", "if", "debug", "else", "None", "\n", "\n", "action_logits", ",", "action", ",", "hidden_state", "=", "self", ".", "agent_nn", ".", "action_logits_by_state", "(", "state", ",", "single_inference", "=", "True", ",", "\n", "hidden_state", "=", "last_state", ")", "\n", "\n", "return", "action", ",", "action_logits", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step": [[166, 186], ["alphastar_agent.RandomAgent.step", "isinstance", "alphastar_agent.AlphaStarAgent.step_nn", "print", "alphastar_agent.AlphaStarAgent.agent_nn.action_to_func_call"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_nn"], ["", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "# note here obs is actually timestep ", "\n", "        ", "rand_func_call", "=", "super", "(", "AlphaStarAgent", ",", "self", ")", ".", "step", "(", "obs", ")", "\n", "print", "(", "'name:'", ",", "self", ".", "name", ")", "if", "1", "else", "None", "\n", "\n", "# note someimes obs is timestep ", "\n", "if", "isinstance", "(", "obs", ",", "E", ".", "TimeStep", ")", ":", "\n", "            ", "obs", "=", "obs", ".", "observation", "\n", "\n", "", "action", ",", "_", ",", "self", ".", "memory_state", "=", "self", ".", "step_nn", "(", "obs", ",", "self", ".", "memory_state", ")", "\n", "\n", "if", "actions", "is", "not", "None", ":", "\n", "# we use single_inference here", "\n", "#assert len(actions) == 1", "\n", "#action = actions[0]", "\n", "            ", "func_call", "=", "self", ".", "agent_nn", ".", "action_to_func_call", "(", "action", ",", "self", ".", "action_spec", ")", "\n", "return", "func_call", "\n", "", "else", ":", "\n", "# only return random action", "\n", "            ", "return", "rand_func_call", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits": [[187, 204], ["isinstance", "alphastar_agent.AlphaStarAgent.step_nn", "alphastar_agent.AlphaStarAgent.agent_nn.action_to_func_call", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_nn"], ["", "", "def", "step_logits", "(", "self", ",", "obs", ",", "last_state", ")", ":", "\n", "        ", "print", "(", "'name:'", ",", "self", ".", "name", ")", "if", "debug", "else", "None", "\n", "\n", "# note someimes obs is timestep ", "\n", "if", "isinstance", "(", "obs", ",", "E", ".", "TimeStep", ")", ":", "\n", "            ", "obs", "=", "obs", ".", "observation", "\n", "\n", "", "action", ",", "action_logits", ",", "new_state", "=", "self", ".", "step_nn", "(", "observation", "=", "obs", ",", "last_state", "=", "last_state", ")", "\n", "\n", "print", "(", "'action:'", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_logits:'", ",", "action_logits", ")", "if", "debug", "else", "None", "\n", "\n", "func_call", ",", "units_args", "=", "self", ".", "agent_nn", ".", "action_to_func_call", "(", "action", ",", "self", ".", "action_spec", ")", "\n", "\n", "print", "(", "'func_call:'", ",", "func_call", ")", "if", "debug", "else", "None", "\n", "\n", "return", "func_call", ",", "units_args", ",", "action", ",", "action_logits", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits_RAS": [[205, 222], ["isinstance", "alphastar_agent.AlphaStarAgent.step_nn", "alphastar_agent.AlphaStarAgent.agent_nn.action_to_func_call_RAS", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_nn", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_to_func_call_RAS"], ["", "def", "step_logits_RAS", "(", "self", ",", "obs", ",", "last_state", ")", ":", "\n", "        ", "print", "(", "'name:'", ",", "self", ".", "name", ")", "if", "debug", "else", "None", "\n", "\n", "# note someimes obs is timestep ", "\n", "if", "isinstance", "(", "obs", ",", "E", ".", "TimeStep", ")", ":", "\n", "            ", "obs", "=", "obs", ".", "observation", "\n", "\n", "", "action", ",", "action_logits", ",", "new_state", "=", "self", ".", "step_nn", "(", "observation", "=", "obs", ",", "last_state", "=", "last_state", ")", "\n", "\n", "print", "(", "'action:'", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_logits:'", ",", "action_logits", ")", "if", "debug", "else", "None", "\n", "\n", "func_call", ",", "units_args", "=", "self", ".", "agent_nn", ".", "action_to_func_call_RAS", "(", "action", ",", "self", ".", "action_spec", ",", "obs", ")", "\n", "\n", "print", "(", "'func_call:'", ",", "func_call", ")", "if", "debug", "else", "None", "\n", "\n", "return", "func_call", ",", "units_args", ",", "action", ",", "action_logits", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits_HAS": [[223, 241], ["isinstance", "alphastar_agent.AlphaStarAgent.step_nn", "alphastar_agent.AlphaStarAgent.agent_nn.action_to_func_call_HAS", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_nn", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.action_to_func_call_HAS"], ["", "def", "step_logits_HAS", "(", "self", ",", "obs", ",", "last_state", ")", ":", "\n", "        ", "print", "(", "'HAS interface:'", ")", "if", "debug", "else", "None", "\n", "print", "(", "'name:'", ",", "self", ".", "name", ")", "if", "debug", "else", "None", "\n", "\n", "# note someimes obs is timestep ", "\n", "if", "isinstance", "(", "obs", ",", "E", ".", "TimeStep", ")", ":", "\n", "            ", "obs", "=", "obs", ".", "observation", "\n", "\n", "", "action", ",", "action_logits", ",", "new_state", "=", "self", ".", "step_nn", "(", "observation", "=", "obs", ",", "last_state", "=", "last_state", ")", "\n", "\n", "print", "(", "'action:'", ",", "action", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_logits:'", ",", "action_logits", ")", "if", "debug", "else", "None", "\n", "\n", "func_call", ",", "units_args", "=", "self", ".", "agent_nn", ".", "action_to_func_call_HAS", "(", "action", ",", "self", ".", "action_spec", ",", "obs", ")", "\n", "\n", "print", "(", "'func_call:'", ",", "func_call", ")", "if", "debug", "else", "None", "\n", "\n", "return", "func_call", ",", "units_args", ",", "action", ",", "action_logits", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.unroll": [[242, 336], ["enumerate", "torch.cat", "torch.cat", "alphastarmini.core.rl.state.MsState", "alphastar_agent.AlphaStarAgent.agent_nn.device", "alphastarmini.core.rl.state.MsState.to", "alphastar_agent.AlphaStarAgent.agent_nn.unroll_traj", "torch.transpose.reshape", "torch.transpose", "initial_memory_list.append", "enumerate", "enumerate", "entity_state_list.append", "statistical_state_list.append", "map_state_list.append", "torch.cat", "print", "print", "torch.cat", "torch.cat", "print", "torch.cat", "l.to", "l.to", "l.to", "print", "print", "print", "print", "alphastar_agent.AlphaStarAgent.agent_nn.preprocess_state_all", "state_traj.append", "alphastar_agent.AlphaStarAgent.agent_nn.preprocess_baseline_state", "baseline_state_traj.append", "baseline_state_op_traj.append", "zip", "zip", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.device", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.unroll_traj", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_state_all", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.arch.agent.Agent.preprocess_baseline_state"], ["", "def", "unroll", "(", "self", ",", "trajectories", ")", ":", "\n", "        ", "\"\"\"Unrolls the network over the trajectory.\n\n        The actions taken by the agent and the initial state of the unroll are\n        dictated by trajectory.\n        \"\"\"", "\n", "\n", "# trajectories shape: list of trajectory", "\n", "policy_logits", "=", "None", "\n", "baselines", "=", "None", "\n", "\n", "initial_memory_list", "=", "[", "]", "\n", "state_traj", "=", "[", "]", "\n", "\n", "baseline_state_traj", "=", "[", "]", "\n", "baseline_state_op_traj", "=", "[", "]", "\n", "for", "i", ",", "traj", "in", "enumerate", "(", "trajectories", ")", ":", "\n", "# add the initial memory state          ", "\n", "            ", "memory_seq", "=", "traj", ".", "memory", "\n", "initial_memory", "=", "memory_seq", "[", "0", "]", "\n", "initial_memory_list", ".", "append", "(", "initial_memory", ")", "\n", "\n", "# add the state", "\n", "home_obs_seq", "=", "traj", ".", "observation", "\n", "bo_seq", "=", "traj", ".", "build_order", "\n", "for", "j", ",", "home_obs", "in", "enumerate", "(", "home_obs_seq", ")", ":", "\n", "                ", "state", "=", "self", ".", "agent_nn", ".", "preprocess_state_all", "(", "home_obs", ",", "build_order", "=", "bo_seq", "[", "j", "]", ")", "\n", "state_traj", ".", "append", "(", "state", ")", "\n", "\n", "", "away_obs_seq", "=", "traj", ".", "opponent_observation", "\n", "for", "j", ",", "away_obs", "in", "enumerate", "(", "away_obs_seq", ")", ":", "\n", "                ", "state", ",", "op_state", "=", "self", ".", "agent_nn", ".", "preprocess_baseline_state", "(", "home_obs_seq", "[", "j", "]", ",", "away_obs", ",", "build_order", "=", "bo_seq", "[", "j", "]", ")", "\n", "baseline_state_traj", ".", "append", "(", "state", ")", "\n", "baseline_state_op_traj", ".", "append", "(", "op_state", ")", "\n", "\n", "", "", "entity_state_list", "=", "[", "]", "\n", "statistical_state_list", "=", "[", "]", "\n", "map_state_list", "=", "[", "]", "\n", "for", "s", "in", "state_traj", ":", "\n", "            ", "entity_state_list", ".", "append", "(", "s", ".", "entity_state", ")", "\n", "statistical_state_list", ".", "append", "(", "s", ".", "statistical_state", ")", "\n", "map_state_list", ".", "append", "(", "s", ".", "map_state", ")", "\n", "\n", "", "entity_state_all", "=", "torch", ".", "cat", "(", "entity_state_list", ",", "dim", "=", "0", ")", "\n", "statistical_state_all", "=", "[", "torch", ".", "cat", "(", "statis", ",", "dim", "=", "0", ")", "for", "statis", "in", "zip", "(", "*", "statistical_state_list", ")", "]", "\n", "map_state_all", "=", "torch", ".", "cat", "(", "map_state_list", ",", "dim", "=", "0", ")", "\n", "\n", "state_all", "=", "MsState", "(", "entity_state", "=", "entity_state_all", ",", "statistical_state", "=", "statistical_state_all", ",", "map_state", "=", "map_state_all", ")", "\n", "\n", "device", "=", "self", ".", "agent_nn", ".", "device", "(", ")", "\n", "print", "(", "\"unroll device:\"", ",", "device", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"initial_memory.shape:\"", ",", "initial_memory_list", "[", "0", "]", "[", "0", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "# note the bacth size is in the second dim of hidden state", "\n", "initial_memory_state", "=", "[", "torch", ".", "cat", "(", "l", ",", "dim", "=", "1", ")", "for", "l", "in", "zip", "(", "*", "initial_memory_list", ")", "]", "\n", "\n", "baseline_state_all", "=", "[", "torch", ".", "cat", "(", "statis", ",", "dim", "=", "0", ")", "for", "statis", "in", "zip", "(", "*", "baseline_state_traj", ")", "]", "\n", "print", "(", "\"baseline_state_all.shape:\"", ",", "baseline_state_all", "[", "0", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "baseline_state_op_all", "=", "[", "torch", ".", "cat", "(", "statis", ",", "dim", "=", "0", ")", "for", "statis", "in", "zip", "(", "*", "baseline_state_op_traj", ")", "]", "\n", "\n", "# change to device", "\n", "state_all", ".", "to", "(", "device", ")", "# note: MsStata.to(device) in place operation", "\n", "initial_memory_state", "=", "[", "l", ".", "to", "(", "device", ")", "for", "l", "in", "initial_memory_state", "]", "\n", "baseline_state_all", "=", "[", "l", ".", "to", "(", "device", ")", "for", "l", "in", "baseline_state_all", "]", "\n", "baseline_state_op_all", "=", "[", "l", ".", "to", "(", "device", ")", "for", "l", "in", "baseline_state_op_all", "]", "\n", "\n", "# shape [batch_seq_size, embedding_size]", "\n", "baseline_list", ",", "policy_logits", "=", "self", ".", "agent_nn", ".", "unroll_traj", "(", "state_all", "=", "state_all", ",", "\n", "initial_state", "=", "initial_memory_state", ",", "\n", "baseline_state", "=", "baseline_state_all", ",", "\n", "baseline_opponent_state", "=", "baseline_state_op_all", ")", "\n", "winloss_baseline", "=", "baseline_list", "[", "0", "]", "\n", "print", "(", "\"winloss_baseline:\"", ",", "winloss_baseline", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"winloss_baseline.shape:\"", ",", "winloss_baseline", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# calculate the baselines", "\n", "# note that shape is [T, B]", "\n", "seq_size", "=", "AHP", ".", "sequence_length", "\n", "batch_size", "=", "AHP", ".", "batch_size", "\n", "size", "=", "(", "seq_size", ",", "batch_size", ")", "\n", "\n", "# shape [batch_size x seq_size x 1]", "\n", "winloss_baseline", "=", "winloss_baseline", ".", "reshape", "(", "AHP", ".", "batch_size", ",", "AHP", ".", "sequence_length", ")", "\n", "# shape [batch_size x seq_size]", "\n", "# winloss_baseline = winloss_baseline.squeeze(-1)", "\n", "# shape [seq_size x batch_size]", "\n", "winloss_baseline", "=", "torch", ".", "transpose", "(", "winloss_baseline", ",", "0", ",", "1", ")", "\n", "\n", "print", "(", "\"winloss_baseline:\"", ",", "winloss_baseline", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"winloss_baseline.shape:\"", ",", "winloss_baseline", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "baseline_list", "[", "0", "]", "=", "winloss_baseline", "\n", "\n", "return", "policy_logits", ",", "baseline_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.log_prob": [[79, 92], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.squeeze", "torch.squeeze"], "function", ["None"], ["def", "log_prob", "(", "actions", ",", "logits", ",", "reduction", "=", "\"none\"", ")", ":", "\n", "    ", "\"\"\"Returns the log probability of taking an action given the logits.\"\"\"", "\n", "# Equivalent to tf.sparse_softmax_cross_entropy_with_logits.", "\n", "\n", "loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "reduction", ")", "\n", "\n", "# logits: shape [BATCH_SIZE, CLASS_SIZE]", "\n", "# actions: shape [BATCH_SIZE]", "\n", "neg_log_prob", "=", "loss", "(", "logits", ",", "torch", ".", "squeeze", "(", "actions", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "log_prob", "=", "-", "neg_log_prob", "\n", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.is_sampled": [[94, 97], ["None"], "function", ["None"], ["", "def", "is_sampled", "(", "z", ")", ":", "\n", "    ", "\"\"\"Takes a tensor of zs. Returns a mask indicating which z's are sampled.\"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by": [[99, 123], ["None"], "function", ["None"], ["", "def", "filter_by", "(", "action_fields", ",", "target", ")", ":", "\n", "    ", "\"\"\"Returns the subset of `target` corresponding to `action_fields`.\n\n    Autoregressive actions are composed of many logits.  We often want to select a\n    subset of these logits.\n\n    Args:\n      action_fields: One of 'action_type', 'delay', or 'arguments'.\n      target: A ArgsActionLogits tensor.\n    Returns:\n      A tensor\n    \"\"\"", "\n", "if", "action_fields", "==", "'action_type'", ":", "\n", "        ", "return", "target", ".", "action_type", "\n", "", "elif", "action_fields", "==", "'delay'", ":", "\n", "        ", "return", "target", ".", "delay", "\n", "", "elif", "action_fields", "==", "'queue'", ":", "\n", "        ", "return", "target", ".", "queue", "\n", "", "elif", "action_fields", "==", "'units'", ":", "\n", "        ", "return", "target", ".", "units", "\n", "", "elif", "action_fields", "==", "'target_unit'", ":", "\n", "        ", "return", "target", ".", "target_unit", "\n", "", "elif", "action_fields", "==", "'target_location'", ":", "\n", "        ", "return", "target", ".", "target_location", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_lists": [[125, 139], ["torch.cat", "torch.cat", "getattr"], "function", ["None"], ["", "", "def", "filter_by_for_lists", "(", "action_fields", ",", "target_list", ")", ":", "\n", "    ", "\"\"\"Returns the subset of `target` corresponding to `action_fields`.\n\n    Autoregressive actions are composed of many logits.  We often want to select a\n    subset of these logits.\n\n    Args:\n      action_fields: One of 'action_type', 'delay', or 'arguments'.\n      target: A list of tensors corresponding to the SC2 action spec. [T x B x S]\n    Returns:\n      A tensor corresponding to a subset of `target`, with only the tensors relevant\n      to `action_fields`.\n    \"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "getattr", "(", "b", ",", "action_fields", ")", "for", "a", "in", "target_list", "for", "b", "in", "a", "]", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_masks": [[141, 161], ["index_list.index", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "filter_by_for_masks", "(", "action_fields", ",", "target_mask", ")", ":", "\n", "    ", "\"\"\"Returns the subset of `mask` corresponding to `action_fields`.\n\n    Autoregressive actions are composed of many logits.  We often want to select a\n    subset of these logits.\n\n    Args:\n      action_fields: One of 'action_type', 'delay', or 'arguments'.\n      target_mask: A list of tensors corresponding to the masks. [T x B x 1]\n    Returns:\n      A tensor corresponding to a subset of `target`, with only the tensors relevant\n      to `action_fields`.\n    \"\"\"", "\n", "index_list", "=", "[", "'action_type'", ",", "'delay'", ",", "'queue'", ",", "'units'", ",", "'target_unit'", ",", "'target_location'", "]", "\n", "index", "=", "index_list", ".", "index", "(", "action_fields", ")", "\n", "\n", "mask", "=", "torch", ".", "tensor", "(", "target_mask", ",", "device", "=", "device", ")", "\n", "mask", "=", "mask", "[", ":", ",", ":", ",", "index", "]", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_over_actions": [[163, 179], ["sum", "zip", "rl_loss.policy_gradient_loss", "rl_loss.policy_gradient_loss"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.policy_gradient_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.policy_gradient_loss"], ["", "def", "compute_over_actions", "(", "f", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Runs f over all elements in the lists composing *args.\n\n    Autoregressive actions are composed of many logits. We run losses functions\n    over all sets of logits.\n    \"\"\"", "\n", "\n", "'''\n    # show the middle results\n    for a in zip(*args):\n        print(\"a:\", a)\n        r = f(*a)\n        print(\"r:\", r)\n    '''", "\n", "\n", "return", "sum", "(", "f", "(", "*", "a", ")", "for", "a", "in", "zip", "(", "*", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.mergeArgsActionLogits": [[181, 187], ["alphastarmini.core.rl.action.ArgsActionLogits", "i.toList", "torch.cat", "torch.cat", "t.reshape", "zip"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.toList"], ["", "def", "mergeArgsActionLogits", "(", "list_args_action_logits", ")", ":", "\n", "    ", "l", "=", "[", "i", ".", "toList", "(", ")", "for", "i", "in", "list_args_action_logits", "]", "\n", "a", "=", "[", "torch", ".", "cat", "(", "z", ",", "dim", "=", "0", ")", "for", "z", "in", "zip", "(", "*", "l", ")", "]", "\n", "b", "=", "[", "t", ".", "reshape", "(", "t", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "for", "t", "in", "a", "]", "\n", "\n", "return", "ArgsActionLogits", "(", "*", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.entropy": [[189, 204], ["torch.Softmax", "torch.LogSoftmax", "nn.Softmax.", "nn.LogSoftmax.", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "entropy", "(", "policy_logits", ",", "masks", ")", ":", "\n", "# policy_logits shape: [seq_batch_size, channel_size]", "\n", "# masks shape: [seq_batch_size, 1]", "\n", "\n", "    ", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "policy", "=", "softmax", "(", "policy_logits", ")", "\n", "log_policy", "=", "logsoftmax", "(", "policy_logits", ")", "\n", "\n", "ent", "=", "torch", ".", "sum", "(", "-", "policy", "*", "log_policy", "*", "masks", ",", "axis", "=", "-", "1", ")", "# Aggregate over actions.", "\n", "# Normalize by actions available.", "\n", "normalized_entropy", "=", "ent", "/", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "policy_logits", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ")", "\n", "\n", "return", "normalized_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.entropy_loss": [[206, 223], ["torch.Softmax", "torch.LogSoftmax", "nn.Softmax.", "nn.LogSoftmax.", "torch.mean", "torch.mean", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "entropy_loss", "(", "policy_logits", ")", ":", "\n", "    ", "\"\"\"Computes the entropy loss for a set of logits.\n\n    Args:\n      policy_logits: namedtuple of the logits for each policy argument.\n        Each shape is [..., N_i].\n    Returns:\n      Per-example entropy loss, as an array of shape policy_logits.shape[:-1].\n    \"\"\"", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "policy", "=", "softmax", "(", "policy_logits", ".", "action_type", ")", "\n", "log_policy", "=", "logsoftmax", "(", "policy_logits", ".", "action_type", ")", "\n", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "-", "policy", "*", "log_policy", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.entropy_loss_for_all_arguments": [[225, 295], ["torch.tensor", "torch.tensor", "torch.mean", "torch.mean", "getattr", "logits.reshape.reshape", "logits.reshape.transpose", "logits.reshape.reshape", "index_list.index", "torch.cat.reshape", "rl_loss.entropy", "entropy_list.append", "torch.cat", "torch.cat", "print", "print", "logits.reshape.squeeze", "print", "print", "print", "print", "logits.reshape.reshape", "logits.reshape.reshape", "print", "torch.cat", "torch.cat", "print", "print", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.entropy"], ["", "def", "entropy_loss_for_all_arguments", "(", "policy_logits", ",", "masks", ")", ":", "\n", "    ", "\"\"\"Computes the entropy loss for a set of logits.\n\n    Args:\n      policy_logits: namedtuple of the logits for each policy argument.\n        Each shape is [..., N_i].\n      masks: The masks. Each shape is policy_logits.shape[:-1].\n    Returns:\n      Per-example entropy loss, as an array of shape policy_logits.shape[:-1].\n    \"\"\"", "\n", "\n", "index_list", "=", "[", "'action_type'", ",", "'delay'", ",", "'queue'", ",", "'units'", ",", "'target_unit'", ",", "'target_location'", "]", "\n", "masks", "=", "torch", ".", "tensor", "(", "masks", ",", "device", "=", "device", ")", "\n", "\n", "entropy_list", "=", "[", "]", "\n", "for", "x", "in", "index_list", ":", "\n", "        ", "if", "x", "==", "\"delay\"", ":", "\n", "            ", "continue", "\n", "", "if", "x", "==", "\"queue\"", ":", "\n", "            ", "continue", "\n", "", "if", "x", "==", "\"target_unit\"", ":", "\n", "            ", "continue", "\n", "", "if", "(", "not", "P", ".", "use_raw_action", ")", "and", "x", "==", "\"units\"", ":", "\n", "            ", "continue", "\n", "\n", "", "logits", "=", "getattr", "(", "policy_logits", ",", "x", ")", "\n", "\n", "print", "(", "\"x name:\"", ",", "x", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "x", "==", "\"target_unit\"", ":", "\n", "# remove the axis 2", "\n", "            ", "logits", "=", "logits", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n", "", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "logits", "=", "logits", ".", "reshape", "(", "AHP", ".", "batch_size", ",", "AHP", ".", "sequence_length", ",", "*", "tuple", "(", "logits", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "logits", "=", "logits", ".", "transpose", "(", "0", ",", "1", ")", "\n", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# shape to be [seq_batch_size, channel_size]", "\n", "logits", "=", "logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "*", "AHP", ".", "batch_size", ",", "*", "tuple", "(", "logits", ".", "shape", "[", "2", ":", "]", ")", ")", "\n", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "x", "==", "\"units\"", ":", "\n", "            ", "logits", "=", "logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "*", "AHP", ".", "batch_size", "*", "AHP", ".", "max_selected", ",", "AHP", ".", "max_entities", ")", "\n", "", "if", "x", "==", "\"target_location\"", ":", "\n", "            ", "logits", "=", "logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "*", "AHP", ".", "batch_size", ",", "SCHP", ".", "world_size", "*", "SCHP", ".", "world_size", ")", "\n", "", "print", "(", "\"logits.shape:\"", ",", "logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "i", "=", "index_list", ".", "index", "(", "x", ")", "\n", "\n", "# shape to be [seq_size, batch_size, 1]", "\n", "mask", "=", "masks", "[", ":", ",", ":", ",", "i", "]", "\n", "\n", "# shape to be [seq_batch_size, 1]", "\n", "mask", "=", "mask", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "if", "x", "==", "\"units\"", ":", "\n", "            ", "mask", "=", "[", "mask", "]", "*", "AHP", ".", "max_selected", "\n", "mask", "=", "torch", ".", "cat", "(", "mask", ",", "dim", "=", "0", ")", "\n", "", "print", "(", "\"mask.shape:\"", ",", "mask", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "entropy_item", "=", "entropy", "(", "logits", ",", "mask", ")", "\n", "\n", "print", "(", "\"entropy_item:\"", ",", "entropy_item", ")", "if", "debug", "else", "None", "\n", "\n", "entropy_list", ".", "append", "(", "entropy_item", ")", "\n", "\n", "", "return", "torch", ".", "mean", "(", "torch", ".", "cat", "(", "entropy_list", ",", "axis", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.kl": [[297, 305], ["torch.Softmax", "torch.LogSoftmax", "nn.LogSoftmax.", "nn.LogSoftmax.", "nn.Softmax."], "function", ["None"], ["", "def", "kl", "(", "student_logits", ",", "teacher_logits", ",", "mask", ")", ":", "\n", "    ", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "s_logprobs", "=", "logsoftmax", "(", "student_logits", ")", "\n", "t_logprobs", "=", "logsoftmax", "(", "teacher_logits", ")", "\n", "teacher_probs", "=", "softmax", "(", "teacher_logits", ")", "\n", "return", "teacher_probs", "*", "(", "t_logprobs", "-", "s_logprobs", ")", "*", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.human_policy_kl_loss": [[307, 323], ["rl_loss.kl", "torch.mean", "torch.mean"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.kl"], ["", "def", "human_policy_kl_loss", "(", "student_logits", ",", "teacher_logits", ",", "action_type_kl_cost", ")", ":", "\n", "    ", "\"\"\"Computes the KL loss to the human policy.\n\n    Args:\n      trajectories: The trajectories.\n      kl_cost: A float; the weighting to apply to the KL cost to the human policy.\n      action_type_kl_cost: Additional cost applied to action_types for\n        conditioned policies.\n    Returns:\n      Per-example entropy loss, as an array of shape policy_logits.shape[:-1].\n    \"\"\"", "\n", "# student_logits: list of ArgsActionLogits", "\n", "action_type_loss", "=", "kl", "(", "student_logits", ",", "teacher_logits", ",", "1", ")", "\n", "kl_loss", "=", "action_type_kl_cost", "*", "torch", ".", "mean", "(", "action_type_loss", ")", "\n", "\n", "return", "kl_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss._reverse_seq": [[325, 338], ["torch.flip", "torch.flip"], "function", ["None"], ["", "def", "_reverse_seq", "(", "sequence", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "    ", "\"\"\"Reverse sequence along dim 0.\n    Args:\n      sequence: Tensor of shape [T, B, ...].\n      sequence_lengths: (optional) tensor of shape [B]. If `None`, only reverse\n        along dim 0.\n    Returns:\n      Tensor of same shape as sequence with dim 0 reversed up to sequence_lengths.\n    \"\"\"", "\n", "if", "sequence_lengths", "is", "None", ":", "\n", "        ", "return", "torch", ".", "flip", "(", "sequence", ",", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.scan_discounted_sum": [[340, 450], ["torch.cat", "torch.cat", "torch.transpose", "torch.transpose", "rl_loss.scan_discounted_sum.scan"], "function", ["None"], ["", "", "def", "scan_discounted_sum", "(", "sequence", ",", "decay", ",", "initial_value", ",", "reverse", "=", "False", ",", "\n", "sequence_lengths", "=", "None", ",", "back_prop", "=", "True", ",", "\n", "name", "=", "\"scan_discounted_sum\"", ")", ":", "\n", "    ", "\"\"\"Evaluates a cumulative discounted sum along dimension 0.\n      ```python\n      if reverse = False:\n        result[1] = sequence[1] + decay[1] * initial_value\n        result[k] = sequence[k] + decay[k] * result[k - 1]\n      if reverse = True:\n        result[last] = sequence[last] + decay[last] * initial_value\n        result[k] = sequence[k] + decay[k] * result[k + 1]\n      ```\n    Respective dimensions T, B and ... have to be the same for all input tensors.\n    T: temporal dimension of the sequence; B: batch dimension of the sequence.\n      if sequence_lengths is set then x1 and x2 below are equivalent:\n      ```python\n      x1 = zero_pad_to_length(\n        scan_discounted_sum(\n            sequence[:length], decays[:length], **kwargs), length=T)\n      x2 = scan_discounted_sum(sequence, decays,\n                               sequence_lengths=[length], **kwargs)\n      ```\n    Args:\n      sequence: Tensor of shape `[T, B, ...]` containing values to be summed.\n      decay: Tensor of shape `[T, B, ...]` containing decays/discounts.\n      initial_value: Tensor of shape `[B, ...]` containing initial value.\n      reverse: Whether to process the sum in a reverse order.\n      sequence_lengths: Tensor of shape `[B]` containing sequence lengths to be\n        (reversed and then) summed.\n      back_prop: Whether to backpropagate.\n      name: Sets the name_scope for this op.\n    Returns:\n      Cumulative sum with discount. Same shape and type as `sequence`.\n    \"\"\"", "\n", "# Note this can be implemented in terms of cumprod and cumsum,", "\n", "# approximately as (ignoring boundary issues and initial_value):", "\n", "#", "\n", "# cumsum(decay_prods * sequence) / decay_prods", "\n", "# where decay_prods = reverse_cumprod(decay)", "\n", "#", "\n", "# One reason this hasn't been done is that multiplying then dividing again by", "\n", "# products of decays isn't ideal numerically, in particular if any of the", "\n", "# decays are zero it results in NaNs.", "\n", "if", "sequence_lengths", "is", "not", "None", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "elems", "=", "[", "sequence", ",", "decay", "]", "\n", "\n", "print", "(", "\"initial_value\"", ",", "initial_value", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"initial_value.shape\"", ",", "initial_value", ")", "if", "debug", "else", "None", "\n", "\n", "if", "reverse", ":", "\n", "        ", "elems", "=", "[", "_reverse_seq", "(", "s", ",", "sequence_lengths", ")", "for", "s", "in", "elems", "]", "\n", "\n", "", "print", "(", "\"sequence\"", ",", "elems", "[", "0", "]", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"sequence.shape\"", ",", "elems", "[", "0", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"decay\"", ",", "elems", "[", "1", "]", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"decay.shape\"", ",", "elems", "[", "1", "]", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "elems", "=", "[", "s", ".", "unsqueeze", "(", "0", ")", "for", "s", "in", "elems", "]", "\n", "\n", "print", "(", "\"elems\"", ",", "elems", ")", "if", "debug", "else", "None", "\n", "\n", "elems", "=", "torch", ".", "cat", "(", "elems", ",", "dim", "=", "0", ")", "\n", "print", "(", "\"elems\"", ",", "elems", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"elems.shape\"", ",", "elems", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "elems", "=", "torch", ".", "transpose", "(", "elems", ",", "0", ",", "1", ")", "\n", "print", "(", "\"elems\"", ",", "elems", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"elems.shape\"", ",", "elems", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# we change it to a pytorch version", "\n", "def", "scan", "(", "foo", ",", "x", ",", "initial_value", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "a_", "=", "initial_value", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "print", "(", "\"a_\"", ",", "a_", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"a_.shape\"", ",", "a_", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "res", ".", "append", "(", "foo", "(", "a_", ",", "x", "[", "0", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "print", "(", "\"res\"", ",", "res", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"len(x)\"", ",", "len", "(", "x", ")", ")", "if", "debug", "else", "None", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "x", ")", ")", ":", "\n", "            ", "print", "(", "\"i\"", ",", "i", ")", "if", "debug", "else", "None", "\n", "res", ".", "append", "(", "foo", "(", "a_", ",", "x", "[", "i", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "print", "(", "\"res\"", ",", "res", ")", "if", "debug", "else", "None", "\n", "\n", "a_", "=", "foo", "(", "a_", ",", "x", "[", "i", "]", ")", "\n", "print", "(", "\"a_\"", ",", "a_", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"a_.shape\"", ",", "a_", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "", "return", "torch", ".", "cat", "(", "res", ")", "\n", "\n", "# summed = tf.scan(lambda a, x: x[0] + x[1] * a,", "\n", "#                 elems,", "\n", "#                 initializer=tf.convert_to_tensor(initial_value),", "\n", "#                 parallel_iterations=1,", "\n", "#                 back_prop=back_prop)    ", "\n", "", "summed", "=", "scan", "(", "lambda", "a", ",", "x", ":", "x", "[", "0", "]", "+", "x", "[", "1", "]", "*", "a", ",", "elems", ",", "initial_value", "=", "initial_value", ")", "\n", "\n", "print", "(", "\"summed\"", ",", "summed", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"summed.shape\"", ",", "summed", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "reverse", ":", "\n", "        ", "summed", "=", "_reverse_seq", "(", "summed", ",", "sequence_lengths", ")", "\n", "\n", "", "print", "(", "\"summed\"", ",", "summed", ")", "if", "debug", "else", "None", "\n", "\n", "return", "summed", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.multistep_forward_view": [[452, 543], ["sequence.float.float", "rl_loss.scan_discounted_sum", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.scan_discounted_sum"], ["", "def", "multistep_forward_view", "(", "rewards", ",", "pcontinues", ",", "state_values", ",", "lambda_", ",", "\n", "back_prop", "=", "True", ",", "sequence_lengths", "=", "None", ",", "\n", "name", "=", "\"multistep_forward_view_op\"", ")", ":", "\n", "    ", "\"\"\"Evaluates complex backups (forward view of eligibility traces).\n      ```python\n      result[t] = rewards[t] +\n          pcontinues[t]*(lambda_[t]*result[t+1] + (1-lambda_[t])*state_values[t])\n      result[last] = rewards[last] + pcontinues[last]*state_values[last]\n      ```\n      This operation evaluates multistep returns where lambda_ parameter controls\n      mixing between full returns and boostrapping. It is users responsibility\n      to provide state_values. Depending on how state_values are evaluated this\n      function can evaluate targets for Q(lambda), Sarsa(lambda) or some other\n      multistep boostrapping algorithm.\n      More information about a forward view is given here:\n      Please note that instead of evaluating traces and then explicitly summing\n      them we instead evaluate mixed returns in the reverse temporal order\n      by using the recurrent relationship given above.\n      The parameter lambda_ can either be a constant value (e.g for Peng's\n      Q(lambda) and Sarsa(_lambda)) or alternatively it can be a tensor containing\n      arbitrary values (Watkins' Q(lambda), Munos' Retrace, etc).\n      The result of evaluating this recurrence relation is a weighted sum of\n      n-step returns, as depicted in the diagram below. One strategy to prove this\n      equivalence notes that many of the terms in adjacent n-step returns\n      \"telescope\", or cancel out, when the returns are summed.\n      Below L3 is lambda at time step 3 (important: this diagram is 1-indexed, not\n      0-indexed like Python). If lambda is scalar then L1=L2=...=Ln.\n      g1,...,gn are discounts.\n      ```\n      Weights:  (1-L1)        (1-L2)*l1      (1-L3)*l1*l2  ...  L1*L2*...*L{n-1}\n      Returns:    |r1*(g1)+     |r1*(g1)+      |r1*(g1)+          |r1*(g1)+\n                v1*(g1)         |r2*(g1*g2)+   |r2*(g1*g2)+       |r2*(g1*g2)+\n                              v2*(g1*g2)       |r3*(g1*g2*g3)+    |r3*(g1*g2*g3)+\n                                             v3*(g1*g2*g3)               ...\n                                                                  |rn*(g1*...*gn)+\n                                                                vn*(g1*...*gn)\n      ```\n    Args:\n      rewards: Tensor of shape `[T, B]` containing rewards.\n      pcontinues: Tensor of shape `[T, B]` containing discounts.\n      state_values: Tensor of shape `[T, B]` containing state values.\n      lambda_: Mixing parameter lambda.\n          The parameter can either be a scalar or a Tensor of shape `[T, B]`\n          if mixing is a function of state.\n      back_prop: Whether to backpropagate.\n      sequence_lengths: Tensor of shape `[B]` containing sequence lengths to be\n        (reversed and then) summed, same as in `scan_discounted_sum`.\n      name: Sets the name_scope for this op.\n    Returns:\n        Tensor of shape `[T, B]` containing multistep returns.\n    \"\"\"", "\n", "\n", "# Regroup:", "\n", "#   result[t] = (rewards[t] + pcontinues[t]*(1-lambda_)*state_values[t]) +", "\n", "#               pcontinues[t]*lambda_*result[t + 1]", "\n", "# Define:", "\n", "#   sequence[t] = rewards[t] + pcontinues[t]*(1-lambda_)*state_values[t]", "\n", "#   discount[t] = pcontinues[t]*lambda_", "\n", "# Substitute:", "\n", "#   result[t] = sequence[t] + discount[t]*result[t + 1]", "\n", "# Boundary condition:", "\n", "#   result[last] = rewards[last] + pcontinues[last]*state_values[last]", "\n", "# Add and subtract the same quantity at BC:", "\n", "#   state_values[last] =", "\n", "#       lambda_*state_values[last] + (1-lambda_)*state_values[last]", "\n", "# This makes:", "\n", "#   result[last] =", "\n", "#       (rewards[last] + pcontinues[last]*(1-lambda_)*state_values[last]) +", "\n", "#       pcontinues[last]*lambda_*state_values[last]", "\n", "# Substitute in definitions for sequence and discount:", "\n", "#   result[last] = sequence[last] + discount[last]*state_values[last]", "\n", "# Define:", "\n", "#   initial_value=state_values[last]", "\n", "# We get the following recurrent relationship:", "\n", "#   result[last] = sequence[last] + decay[last]*initial_value", "\n", "#   result[k] = sequence[k] + decay[k] * result[k + 1]", "\n", "# This matches the form of scan_discounted_sum:", "\n", "#   result = scan_sum_with_discount(sequence, discount,", "\n", "#                                   initial_value = state_values[last])", "\n", "sequence", "=", "rewards", "+", "pcontinues", "*", "state_values", "*", "(", "1", "-", "lambda_", ")", "\n", "print", "(", "\"sequence\"", ",", "sequence", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"sequence.shape\"", ",", "sequence", ".", "shape", ")", "if", "debug", "else", "None", "\n", "sequence", "=", "sequence", ".", "float", "(", ")", "\n", "\n", "discount", "=", "pcontinues", "*", "lambda_", "\n", "print", "(", "\"discount\"", ",", "discount", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"discount.shape\"", ",", "discount", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "scan_discounted_sum", "(", "sequence", ",", "discount", ",", "state_values", "[", "-", "1", "]", ",", "\n", "reverse", "=", "True", ",", "sequence_lengths", "=", "sequence_lengths", ",", "\n", "back_prop", "=", "back_prop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.lambda_returns": [[545, 565], ["rl_loss.multistep_forward_view"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.multistep_forward_view"], ["", "def", "lambda_returns", "(", "values_tp1", ",", "rewards", ",", "discounts", ",", "lambdas", "=", "0.8", ")", ":", "\n", "    ", "\"\"\"Computes lambda returns.\n\n    Refer to the following for a similar function:\n    \"\"\"", "\n", "\n", "# we only implment the lambda return version in AlphaStar when lambdas=0.8", "\n", "# assert lambdas != 1", "\n", "\n", "# assert v_tp1 = torch.concat([values[1:, :], torch.unsqueeze(bootstrap_value, 0)], axis=0)", "\n", "# `back_prop=False` prevents gradients flowing into values and", "\n", "# bootstrap_value, which is what you want when using the bootstrapped", "\n", "# lambda-returns in an update as targets for values.", "\n", "return", "multistep_forward_view", "(", "\n", "rewards", ",", "\n", "discounts", ",", "\n", "values_tp1", ",", "\n", "lambdas", ",", "\n", "back_prop", "=", "False", ",", "\n", "name", "=", "\"0.8_lambda_returns\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.generalized_lambda_returns": [[567, 641], ["rl_loss.scan_discounted_sum", "torch.concat", "torch.concat", "rl_loss.multistep_forward_view", "torch.unsqueeze", "torch.unsqueeze"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.scan_discounted_sum", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.multistep_forward_view"], ["", "def", "generalized_lambda_returns", "(", "rewards", ",", "\n", "pcontinues", ",", "\n", "values", ",", "\n", "bootstrap_value", ",", "\n", "lambda_", "=", "1", ",", "\n", "name", "=", "\"generalized_lambda_returns\"", ")", ":", "\n", "    ", "\"\"\"\n    Computes lambda-returns along a batch of (chunks of) trajectories.\n    For lambda=1 these will be multistep returns looking ahead from each\n    state to the end of the chunk, where bootstrap_value is used. If you pass an\n    entire trajectory and zeros for bootstrap_value, this is just the Monte-Carlo\n    return / TD(1) target.\n    For lambda=0 these are one-step TD(0) targets.\n    For inbetween values of lambda these are lambda-returns / TD(lambda) targets,\n    except that traces are always cut off at the end of the chunk, since we can't\n    see returns beyond then. If you pass an entire trajectory with zeros for\n    bootstrap_value though, then they're plain TD(lambda) targets.\n    lambda can also be a tensor of values in [0, 1], determining the mix of\n    bootstrapping vs further accumulation of multistep returns at each timestep.\n    This can be used to implement Retrace and other algorithms. See\n    `sequence_ops.multistep_forward_view` for more info on this. Another way to\n    think about the end-of-chunk cutoff is that lambda is always effectively zero\n    on the timestep after the end of the chunk, since at the end of the chunk we\n    rely entirely on bootstrapping and can't accumulate returns looking further\n    into the future.\n    The sequences in the tensors should be aligned such that an agent in a state\n    with value `V` transitions into another state with value `V'`, receiving\n    reward `r` and pcontinue `p`. Then `V`, `r` and `p` are all at the same index\n    `i` in the corresponding tensors. `V'` is at index `i+1`, or in the\n    `bootstrap_value` tensor if `i == T`.\n    Subtracting `values` from these lambda-returns will yield estimates of the\n    advantage function which can be used for both the policy gradient loss and\n    the baseline value function loss in A3C / GAE.\n    Args:\n      rewards: 2-D Tensor with shape `[T, B]`.\n      pcontinues: 2-D Tensor with shape `[T, B]`.\n      values: 2-D Tensor containing estimates of the state values for timesteps\n        0 to `T-1`. Shape `[T, B]`.\n      bootstrap_value: 1-D Tensor containing an estimate of the value of the\n        final state at time `T`, used for bootstrapping the target n-step\n        returns. Shape `[B]`.\n      lambda_: an optional scalar or 2-D Tensor with shape `[T, B]`.\n      name: Customises the name_scope for this op.\n    Returns:\n      2-D Tensor with shape `[T, B]`\n    \"\"\"", "\n", "\n", "# values.get_shape().assert_has_rank(2)", "\n", "# rewards.get_shape().assert_has_rank(2)", "\n", "# pcontinues.get_shape().assert_has_rank(2)", "\n", "# bootstrap_value.get_shape().assert_has_rank(1)", "\n", "\n", "if", "lambda_", "==", "1", ":", "\n", "# This is actually equivalent to the branch below, just an optimisation", "\n", "# to avoid unnecessary work in this case:", "\n", "        ", "return", "scan_discounted_sum", "(", "\n", "rewards", ",", "\n", "pcontinues", ",", "\n", "initial_value", "=", "bootstrap_value", ",", "\n", "reverse", "=", "True", ",", "\n", "back_prop", "=", "False", ",", "\n", "name", "=", "\"multistep_returns\"", ")", "\n", "", "else", ":", "\n", "        ", "v_tp1", "=", "torch", ".", "concat", "(", "[", "values", "[", "1", ":", ",", ":", "]", ",", "torch", ".", "unsqueeze", "(", "bootstrap_value", ",", "0", ")", "]", ",", "axis", "=", "0", ")", "\n", "# `back_prop=False` prevents gradients flowing into values and", "\n", "# bootstrap_value, which is what you want when using the bootstrapped", "\n", "# lambda-returns in an update as targets for values.", "\n", "return", "multistep_forward_view", "(", "\n", "rewards", ",", "\n", "pcontinues", ",", "\n", "v_tp1", ",", "\n", "lambda_", ",", "\n", "back_prop", "=", "False", ",", "\n", "name", "=", "\"generalized_lambda_returns\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_advantages": [[646, 655], ["rl_loss.vtrace_from_importance_weights"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_from_importance_weights"], ["def", "vtrace_advantages", "(", "clipped_rhos", ",", "rewards", ",", "discounts", ",", "values", ",", "bootstrap_value", ")", ":", "\n", "    ", "\"\"\"Computes v-trace return advantages.\n\n    Refer to the following for a similar function:\n    see below function \"vtrace_from_importance_weights\"\n    \"\"\"", "\n", "return", "vtrace_from_importance_weights", "(", "rhos", "=", "clipped_rhos", ",", "discounts", "=", "discounts", ",", "\n", "rewards", "=", "rewards", ",", "values", "=", "values", ",", "\n", "bootstrap_value", "=", "bootstrap_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_from_importance_weights": [[657, 820], ["torch.clamp", "torch.clamp", "torch.cat", "torch.cat", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.zeros_like", "torch.zeros_like", "rl_loss.scan_discounted_sum.scan"], "function", ["None"], ["", "def", "vtrace_from_importance_weights", "(", "\n", "rhos", ",", "discounts", ",", "rewards", ",", "values", ",", "bootstrap_value", ",", "\n", "clip_rho_threshold", "=", "1.0", ",", "clip_pg_rho_threshold", "=", "1.0", ",", "\n", "name", "=", "'vtrace_from_importance_weights'", ")", ":", "\n", "    ", "r\"\"\"\n    V-trace from log importance weights.\n    Calculates V-trace actor critic targets as described in\n    \"IMPALA: Scalable Distributed Deep-RL with\n    Importance Weighted Actor-Learner Architectures\"\n    by Espeholt, Soyer, Munos et al.\n    In the notation used throughout documentation and comments, T refers to the\n    time dimension ranging from 0 to T-1. B refers to the batch size and\n    NUM_ACTIONS refers to the number of actions. This code also supports the\n    case where all tensors have the same number of additional dimensions, e.g.,\n    `rewards` is `[T, B, C]`, `values` is `[T, B, C]`, `bootstrap_value`\n    is `[B, C]`.\n    Args:\n      log_rhos: A float32 tensor of shape `[T, B, NUM_ACTIONS]` representing the\n        log importance sampling weights, i.e.\n        log(target_policy(a) / behaviour_policy(a)). V-trace performs operations\n        on rhos in log-space for numerical stability.\n        # note: in mAS we change it to rhos instead of log_rhos\n      discounts: A float32 tensor of shape `[T, B]` with discounts encountered\n        when following the behaviour policy.\n      rewards: A float32 tensor of shape `[T, B]` containing rewards generated by\n        following the behaviour policy.\n      values: A float32 tensor of shape `[T, B]` with the value function estimates\n        wrt. the target policy.\n      bootstrap_value: A float32 of shape `[B]` with the value function estimate\n        at time T.\n      clip_rho_threshold: A scalar float32 tensor with the clipping threshold for\n        importance weights (rho) when calculating the baseline targets (vs).\n        rho^bar in the paper. If None, no clipping is applied.\n      clip_pg_rho_threshold: A scalar float32 tensor with the clipping threshold\n        on rho_s in \\rho_s \\delta log \\pi(a|x) (r + \\gamma v_{s+1} - V(x_s)). If\n        None, no clipping is applied.\n      name: The name scope that all V-trace operations will be created in.\n    Returns:\n      A VTraceReturns namedtuple (vs, pg_advantages) where:\n        vs: A float32 tensor of shape `[T, B]`. Can be used as target to\n          train a baseline (V(x_t) - vs_t)^2.\n        pg_advantages: A float32 tensor of shape `[T, B]`. Can be used as the\n          advantage in the calculation of policy gradients.\n    \"\"\"", "\n", "\n", "#rhos = torch.tensor(rhos, dtype=torch.float32)", "\n", "#discounts = torch.tensor(discounts, dtype=torch.float32)", "\n", "#rewards = torch.tensor(rewards, dtype=torch.float32)", "\n", "#values = torch.tensor(values, dtype=torch.float32)", "\n", "#bootstrap_value = torch.tensor(bootstrap_value, dtype=torch.float32)", "\n", "\n", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "        ", "clip_rho_threshold", "=", "torch", ".", "tensor", "(", "clip_rho_threshold", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "        ", "clip_pg_rho_threshold", "=", "torch", ".", "tensor", "(", "clip_pg_rho_threshold", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "\n", "# Make sure tensor ranks are consistent.", "\n", "# ", "\n", "", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "        ", "clipped_rhos", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "clip_rho_threshold", ")", "\n", "", "else", ":", "\n", "        ", "clipped_rhos", "=", "rhos", "\n", "\n", "", "cs", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "1.", ")", "\n", "# Append bootstrapped value to get [v1, ..., v_t+1]", "\n", "values_t_plus_1", "=", "torch", ".", "cat", "(", "\n", "[", "values", "[", "1", ":", "]", ",", "bootstrap_value", ".", "unsqueeze", "(", "0", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "print", "(", "\"rhos:\"", ",", "rhos", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"rhos.shape:\"", ",", "rhos", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"rewards:\"", ",", "rewards", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"rewards.shape:\"", ",", "rewards", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "\"bootstrap_value:\"", ",", "bootstrap_value", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"bootstrap_value.shape:\"", ",", "bootstrap_value", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "deltas", "=", "clipped_rhos", "*", "(", "rewards", "+", "discounts", "*", "values_t_plus_1", "-", "values", ")", "\n", "\n", "print", "(", "\"deltas:\"", ",", "deltas", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"deltas.shape:\"", ",", "deltas", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# Note that all sequences are reversed, computation starts from the back.", "\n", "'''\n    Note this code is wrong, we should use zip to concat\n    sequences = (\n        torch.flip(discounts, dims=[0]),\n        torch.flip(cs, dims=[0]),\n        torch.flip(deltas, dims=[0]),\n    )\n    '''", "\n", "\n", "flip_discounts", "=", "torch", ".", "flip", "(", "discounts", ",", "dims", "=", "[", "0", "]", ")", "\n", "flip_cs", "=", "torch", ".", "flip", "(", "cs", ",", "dims", "=", "[", "0", "]", ")", "\n", "flip_deltas", "=", "torch", ".", "flip", "(", "deltas", ",", "dims", "=", "[", "0", "]", ")", "\n", "\n", "sequences", "=", "[", "item", "for", "item", "in", "zip", "(", "flip_discounts", ",", "flip_cs", ",", "flip_deltas", ")", "]", "\n", "\n", "# V-trace vs are calculated through a ", "\n", "# scan from the back to the beginning", "\n", "# of the given trajectory.", "\n", "\n", "def", "scanfunc", "(", "acc", ",", "sequence_item", ")", ":", "\n", "        ", "print", "(", "\"sequence_item\"", ",", "sequence_item", ")", "if", "debug", "else", "None", "\n", "discount_t", ",", "c_t", ",", "delta_t", "=", "sequence_item", "\n", "return", "delta_t", "+", "discount_t", "*", "c_t", "*", "acc", "\n", "\n", "", "initial_values", "=", "torch", ".", "zeros_like", "(", "bootstrap_value", ",", "device", "=", "device", ")", "\n", "\n", "# our implemented scan function for pytorch", "\n", "def", "scan", "(", "foo", ",", "x", ",", "initial_value", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "a_", "=", "initial_value", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "print", "(", "\"a_\"", ",", "a_", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"a_.shape\"", ",", "a_", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "res", ".", "append", "(", "foo", "(", "a_", ",", "x", "[", "0", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "print", "(", "\"res\"", ",", "res", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"len(x)\"", ",", "len", "(", "x", ")", ")", "if", "debug", "else", "None", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "x", ")", ")", ":", "\n", "            ", "print", "(", "\"i\"", ",", "i", ")", "if", "debug", "else", "None", "\n", "res", ".", "append", "(", "foo", "(", "a_", ",", "x", "[", "i", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "print", "(", "\"res\"", ",", "res", ")", "if", "debug", "else", "None", "\n", "\n", "a_", "=", "foo", "(", "a_", ",", "x", "[", "i", "]", ")", "\n", "print", "(", "\"a_\"", ",", "a_", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"a_.shape\"", ",", "a_", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "", "return", "torch", ".", "cat", "(", "res", ")", "\n", "\n", "", "vs_minus_v_xs", "=", "scan", "(", "foo", "=", "scanfunc", ",", "x", "=", "sequences", ",", "initial_value", "=", "initial_values", ")", "\n", "\n", "'''\n    # the original tensorflow code\n    vs_minus_v_xs = tf.scan(\n        fn=scanfunc,\n        elems=sequences,\n        initializer=initial_values,\n        parallel_iterations=1,\n        back_prop=False)\n        '''", "\n", "\n", "# Reverse the results back to original order.", "\n", "vs_minus_v_xs", "=", "torch", ".", "flip", "(", "vs_minus_v_xs", ",", "dims", "=", "[", "0", "]", ")", "\n", "\n", "# Add V(x_s) to get v_s.", "\n", "vs", "=", "torch", ".", "add", "(", "vs_minus_v_xs", ",", "values", ")", "\n", "\n", "# Advantage for policy gradient.", "\n", "vs_t_plus_1", "=", "torch", ".", "cat", "(", "[", "vs", "[", "1", ":", "]", ",", "bootstrap_value", ".", "unsqueeze", "(", "0", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "        ", "clipped_pg_rhos", "=", "torch", ".", "clamp", "(", "rhos", ",", "max", "=", "clip_pg_rho_threshold", ")", "\n", "", "else", ":", "\n", "        ", "clipped_pg_rhos", "=", "rhos", "\n", "\n", "", "pg_advantages", "=", "(", "clipped_pg_rhos", "*", "(", "rewards", "+", "discounts", "*", "vs_t_plus_1", "-", "values", ")", ")", "\n", "\n", "# Make sure no gradients backpropagated through the returned values.", "\n", "return", "VTraceReturns", "(", "vs", "=", "vs", ".", "detach", "(", ")", ",", "pg_advantages", "=", "pg_advantages", ".", "detach", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.td_lambda_loss": [[822, 841], ["torch.tensor", "torch.tensor", "rl_loss.lambda_returns", "returns.detach.detach", "numpy.array", "print", "print", "print", "torch.mean", "torch.mean", "torch.square", "torch.square"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.lambda_returns"], ["", "def", "td_lambda_loss", "(", "baselines", ",", "rewards", ",", "trajectories", ")", ":", "\n", "    ", "discounts", "=", "~", "np", ".", "array", "(", "trajectories", ".", "is_final", "[", ":", "-", "1", "]", ")", "\n", "discounts", "=", "torch", ".", "tensor", "(", "discounts", ",", "device", "=", "device", ")", "\n", "\n", "baselines", "=", "baselines", "\n", "rewards", "=", "rewards", "[", "1", ":", "]", "\n", "\n", "# The baseline is then updated using TDLambda, with relative weighting 10.0 and lambda 0.8.", "\n", "returns", "=", "lambda_returns", "(", "baselines", "[", "1", ":", "]", ",", "rewards", ",", "discounts", ",", "lambdas", "=", "0.8", ")", "\n", "# returns = stop_gradient(returns)", "\n", "print", "(", "\"returns:\"", ",", "returns", ")", "if", "debug", "else", "None", "\n", "returns", "=", "returns", ".", "detach", "(", ")", "\n", "print", "(", "\"returns:\"", ",", "returns", ")", "if", "debug", "else", "None", "\n", "\n", "result", "=", "returns", "-", "baselines", "[", ":", "-", "1", "]", "\n", "print", "(", "\"result:\"", ",", "result", ")", "if", "debug", "else", "None", "\n", "\n", "# change to pytorch version", "\n", "return", "0.5", "*", "torch", ".", "mean", "(", "torch", ".", "square", "(", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.policy_gradient_loss": [[843, 865], ["rl_loss.log_prob", "advantages.clone().detach.clone().detach", "print", "print", "print", "print", "print", "print", "advantages.clone().detach.clone"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.log_prob"], ["", "def", "policy_gradient_loss", "(", "logits", ",", "actions", ",", "advantages", ",", "mask", ")", ":", "\n", "    ", "\"\"\"Helper function for computing policy gradient loss for UPGO and v-trace.\"\"\"", "\n", "# logits: shape [BATCH_SIZE, CLASS_SIZE]", "\n", "# actions: shape [BATCH_SIZE]", "\n", "# advantages: shape [BATCH_SIZE]", "\n", "# mask: shape [BATCH_SIZE]", "\n", "action_log_prob", "=", "log_prob", "(", "actions", ",", "logits", ",", "reduction", "=", "\"none\"", ")", "\n", "print", "(", "\"action_log_prob:\"", ",", "action_log_prob", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"action_log_prob.shape:\"", ",", "action_log_prob", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# advantages = stop_gradient(advantages)", "\n", "advantages", "=", "advantages", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "print", "(", "\"advantages:\"", ",", "advantages", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"advantages.shape:\"", ",", "advantages", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "results", "=", "mask", "*", "advantages", "*", "action_log_prob", "\n", "print", "(", "\"results:\"", ",", "results", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"results.shape:\"", ",", "results", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "loss", "=", "-", "results", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_unclipped_logrho": [[867, 873], ["rl_loss.log_prob", "rl_loss.log_prob"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.log_prob", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.log_prob"], ["", "def", "compute_unclipped_logrho", "(", "behavior_logits", ",", "target_logits", ",", "actions", ")", ":", "\n", "    ", "\"\"\"Helper function for compute_importance_weights.\"\"\"", "\n", "target_log_prob", "=", "log_prob", "(", "actions", ",", "target_logits", ",", "reduction", "=", "\"none\"", ")", "\n", "behavior_log_prob", "=", "log_prob", "(", "actions", ",", "behavior_logits", ",", "reduction", "=", "\"none\"", ")", "\n", "\n", "return", "target_log_prob", "-", "behavior_log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_importance_weights": [[875, 883], ["rl_loss.compute_unclipped_logrho", "torch.clamp", "torch.clamp", "print", "print", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_unclipped_logrho"], ["", "def", "compute_importance_weights", "(", "behavior_logits", ",", "target_logits", ",", "actions", ")", ":", "\n", "    ", "\"\"\"Computes clipped importance weights.\"\"\"", "\n", "logrho", "=", "compute_unclipped_logrho", "(", "behavior_logits", ",", "target_logits", ",", "actions", ")", "\n", "print", "(", "\"logrho:\"", ",", "logrho", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"logrho.shape:\"", ",", "logrho", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# change to pytorch version", "\n", "return", "torch", ".", "clamp", "(", "torch", ".", "exp", "(", "logrho", ")", ",", "max", "=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_pg_loss": [[885, 1021], ["alphastarmini.core.rl.utils.Trajectory", "rl_loss.filter_by", "tuple", "split_target_logits.reshape.reshape", "torch.transpose", "torch.transpose", "split_target_logits.reshape.reshape", "rl_loss.filter_by_for_lists", "rl_loss.filter_by_for_lists", "rl_loss.compute_importance_weights", "torch.mean.reshape", "torch.tensor", "torch.tensor", "rl_loss.vtrace_advantages", "rl_loss.filter_by_for_masks", "rl_loss.compute_over_actions", "print", "print", "print", "print", "list", "print", "print", "print", "print", "print", "print", "print", "print", "target_logits.reshape.reshape", "behavior_logits.reshape.reshape", "actions.reshape.reshape", "target_logits.reshape.reshape", "behavior_logits.reshape.reshape", "torch.zeros", "torch.zeros", "enumerate", "torch.mean.reshape", "torch.mean", "torch.mean", "print", "print", "numpy.array", "print", "print", "print", "target_logits.reshape.reshape", "actions.reshape.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_logits.reshape.reshape", "actions.reshape.reshape", "torch.mean.reshape", "torch.mean", "torch.mean", "print", "print", "tuple", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_lists", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_lists", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_importance_weights", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_advantages", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_masks", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_over_actions"], ["", "def", "vtrace_pg_loss", "(", "target_logits", ",", "baselines", ",", "rewards", ",", "trajectories", ",", "\n", "action_fields", ")", ":", "\n", "    ", "\"\"\"Computes v-trace policy gradient loss. Helper for split_vtrace_pg_loss.\"\"\"", "\n", "# Remove last timestep from trajectories and baselines.", "\n", "debug", "=", "False", "\n", "\n", "print", "(", "\"action_fields\"", ",", "action_fields", ")", "if", "debug", "else", "None", "\n", "\n", "trajectories", "=", "Trajectory", "(", "*", "tuple", "(", "item", "[", ":", "-", "1", "]", "for", "item", "in", "trajectories", ")", ")", "\n", "print", "(", "\"trajectories.reward\"", ",", "trajectories", ".", "reward", ")", "if", "debug", "else", "None", "\n", "\n", "rewards", "=", "rewards", "[", ":", "-", "1", "]", "\n", "values", "=", "baselines", "[", ":", "-", "1", "]", "\n", "\n", "# Filter for only the relevant actions/logits/masks.", "\n", "\n", "target_logits", "=", "filter_by", "(", "action_fields", ",", "target_logits", ")", "\n", "print", "(", "\"target_logits\"", ",", "target_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_logits.shape\"", ",", "target_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# shape: [batch_seq_size x action_size]", "\n", "split_target_logits", "=", "target_logits", "\n", "action_size", "=", "tuple", "(", "list", "(", "target_logits", ".", "shape", "[", "1", ":", "]", ")", ")", "# from the 3rd dim, it is action dim, may be [S] or [C, S] or [H, W]", "\n", "\n", "# shape: [batch_size x seq_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", ".", "reshape", "(", "AHP", ".", "batch_size", ",", "AHP", ".", "sequence_length", ",", "*", "action_size", ")", "\n", "# shape: [seq_size x batch_size x action_size]", "\n", "split_target_logits", "=", "torch", ".", "transpose", "(", "split_target_logits", ",", "0", ",", "1", ")", "\n", "# shape: [new_seq_size x batch_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", "[", ":", "-", "1", "]", "\n", "# shape: [seq_batch_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", ".", "reshape", "(", "-", "1", ",", "*", "action_size", ")", "\n", "print", "(", "\"split_target_logits\"", ",", "split_target_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"split_target_logits.shape\"", ",", "split_target_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "target_logits", "=", "split_target_logits", "\n", "print", "(", "\"target_logits\"", ",", "target_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"target_logits.shape\"", ",", "target_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "behavior_logits", "=", "filter_by_for_lists", "(", "action_fields", ",", "trajectories", ".", "behavior_logits", ")", "\n", "print", "(", "\"behavior_logits\"", ",", "behavior_logits", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"behavior_logits.shape\"", ",", "behavior_logits", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "actions", "=", "filter_by_for_lists", "(", "action_fields", ",", "trajectories", ".", "action", ")", "\n", "print", "(", "\"actions\"", ",", "actions", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"actions.shape\"", ",", "actions", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "if", "action_fields", "==", "'units'", "or", "action_fields", "==", "'target_unit'", ":", "\n", "        ", "seqbatch_unit_shape", "=", "target_logits", ".", "shape", "[", "0", ":", "2", "]", "\n", "target_logits", "=", "target_logits", ".", "reshape", "(", "-", "1", ",", "target_logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "behavior_logits", "=", "behavior_logits", ".", "reshape", "(", "-", "1", ",", "behavior_logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "-", "1", ",", "actions", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "action_fields", "==", "'target_location'", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "target_logits", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "behavior_logits", "=", "behavior_logits", ".", "reshape", "(", "behavior_logits", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "actions_2", "=", "torch", ".", "zeros", "(", "behavior_logits", ".", "shape", "[", "0", "]", ",", "1", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "print", "(", "\"actions_2.shape\"", ",", "actions_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "for", "i", ",", "pos", "in", "enumerate", "(", "actions", ")", ":", "\n", "# note: for pos, the first index is x, the seconde index is y", "\n", "# however, for the matrix, the first index is y (row), and the second index is x (col)", "\n", "            ", "x", "=", "pos", "[", "0", "]", "\n", "assert", "x", ">=", "0", "\n", "assert", "x", "<", "SCHP", ".", "world_size", "\n", "y", "=", "pos", "[", "1", "]", "\n", "assert", "y", ">=", "0", "\n", "assert", "y", "<", "SCHP", ".", "world_size", "\n", "index", "=", "SCHP", ".", "world_size", "*", "y", "+", "x", "\n", "actions_2", "[", "i", "]", "[", "0", "]", "=", "index", "\n", "\n", "", "actions", "=", "actions_2", "\n", "print", "(", "\"actions_2.shape\"", ",", "actions_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# Compute and return the v-trace policy gradient loss for the relevant subset of logits.", "\n", "", "clipped_rhos", "=", "compute_importance_weights", "(", "behavior_logits", ",", "target_logits", ",", "actions", ")", "\n", "\n", "if", "action_fields", "==", "'units'", "or", "action_fields", "==", "'target_unit'", ":", "\n", "        ", "clipped_rhos", "=", "clipped_rhos", ".", "reshape", "(", "seqbatch_unit_shape", ",", "-", "1", ")", "\n", "clipped_rhos", "=", "torch", ".", "mean", "(", "clipped_rhos", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# To make the clipped_rhos shape to be [T-1, B]", "\n", "", "clipped_rhos", "=", "clipped_rhos", ".", "reshape", "(", "rewards", ".", "shape", ")", "\n", "print", "(", "\"clipped_rhos\"", ",", "clipped_rhos", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"clipped_rhos.shape\"", ",", "clipped_rhos", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "discounts", "=", "~", "np", ".", "array", "(", "trajectories", ".", "is_final", ")", "\n", "discounts", "=", "torch", ".", "tensor", "(", "discounts", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "\n", "# we implement the vtrace_advantages", "\n", "# vtrace_advantages(clipped_rhos, rewards, discounts, values, bootstrap_value):", "\n", "\n", "weighted_advantage", "=", "vtrace_advantages", "(", "clipped_rhos", ",", "rewards", ",", "\n", "discounts", ",", "values", ",", "\n", "baselines", "[", "-", "1", "]", ")", "\n", "\n", "print", "(", "\"trajectories.masks\"", ",", "trajectories", ".", "masks", ")", "if", "debug", "else", "None", "\n", "\n", "masks", "=", "filter_by_for_masks", "(", "action_fields", ",", "trajectories", ".", "masks", ")", "\n", "print", "(", "\"filtered masks\"", ",", "masks", ")", "if", "debug", "else", "None", "\n", "\n", "# AlphaStar: weighted_advantage = [weighted_advantage] * len(target_logits)", "\n", "# mAS: the weighted_advantage is already been unfolded, so we don't need the line", "\n", "# we need the pg_advantages of the VTrace_returns, which is in ths index of 1", "\n", "weighted_advantage", "=", "weighted_advantage", "[", "1", "]", "\n", "print", "(", "\"weighted_advantage\"", ",", "weighted_advantage", ")", "if", "debug", "else", "None", "\n", "\n", "# here we should reshape the target_logits and actions back to [T-1, B, C] size for computing policy gradient", "\n", "if", "action_fields", "==", "'units'", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", "*", "AHP", ".", "max_selected", ",", "-", "1", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", "*", "AHP", ".", "max_selected", ",", "-", "1", ")", "\n", "\n", "weighted_advantage", "=", "torch", ".", "cat", "(", "[", "weighted_advantage", "]", "*", "AHP", ".", "max_selected", ",", "dim", "=", "1", ")", "\n", "masks", "=", "torch", ".", "cat", "(", "[", "masks", "]", "*", "AHP", ".", "max_selected", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", ",", "-", "1", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "result", "=", "compute_over_actions", "(", "policy_gradient_loss", ",", "target_logits", ",", "\n", "actions", ",", "weighted_advantage", ",", "masks", ")", "\n", "\n", "if", "action_fields", "==", "'units'", ":", "\n", "        ", "result", "=", "result", ".", "reshape", "(", "-", "1", ",", "AHP", ".", "max_selected", ")", "\n", "result", "=", "torch", ".", "mean", "(", "result", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "print", "(", "\"result\"", ",", "result", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"result.shape\"", ",", "result", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# note: in mAS, we should make the result not beyond 0", "\n", "# return 0.5 * torch.mean(torch.square(result))", "\n", "\n", "debug", "=", "False", "\n", "\n", "# note: we change back to use only result ", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.split_vtrace_pg_loss": [[1023, 1064], ["print", "rl_loss.vtrace_pg_loss", "print", "rl_loss.vtrace_pg_loss", "loss.sum", "rl_loss.vtrace_pg_loss", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_pg_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_pg_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.vtrace_pg_loss"], ["", "def", "split_vtrace_pg_loss", "(", "target_logits", ",", "baselines", ",", "rewards", ",", "trajectories", ")", ":", "\n", "    ", "\"\"\"Computes the split v-trace policy gradient loss.\n\n    We compute the policy loss (and therefore update, via autodiff) separately for\n    the action_type, delay, and arguments. Each of these component losses are\n    weighted equally.\n\n    Paper description:\n      When applying V-trace to the policy in large action spaces, \n      the off-policy corrections truncate the trace early; \n      to mitigate this problem, we assume independence between the action type, \n      delay, and all other arguments, and so update the components \n      of the policy separately.\n    \"\"\"", "\n", "\n", "# The action_type argument, delay, and all other arguments are separately updated ", "\n", "# using a separate (\"split\") VTrace Actor-Critic losses. ", "\n", "# The weighting of these updates will be considered 1.0.", "\n", "\n", "loss", "=", "0.", "\n", "print", "(", "'split_vtrace_pg_loss'", ",", "split_vtrace_pg_loss", ")", "\n", "\n", "action_type_loss", "=", "vtrace_pg_loss", "(", "target_logits", ",", "baselines", ",", "rewards", ",", "trajectories", ",", "'action_type'", ")", "\n", "print", "(", "'action_type_loss'", ",", "action_type_loss", ")", "\n", "loss", "+=", "action_type_loss", "\n", "\n", "#loss += vtrace_pg_loss(target_logits, baselines, rewards, trajectories, 'delay')", "\n", "\n", "# note: here we use queue, units, target_unit and target_location to replace the single arguments", "\n", "# loss += vtrace_pg_loss(target_logits, baselines, rewards, trajectories, 'arguments')", "\n", "#loss += vtrace_pg_loss(target_logits, baselines, rewards, trajectories, 'queue')", "\n", "\n", "if", "P", ".", "use_raw_action", ":", "\n", "        ", "units_loss", "=", "vtrace_pg_loss", "(", "target_logits", ",", "baselines", ",", "rewards", ",", "trajectories", ",", "'units'", ")", "\n", "print", "(", "'units_loss'", ",", "units_loss", ")", "\n", "loss", "+=", "units_loss", "\n", "\n", "#loss += vtrace_pg_loss(target_logits, baselines, rewards, trajectories, 'target_unit')", "\n", "", "loss", "+=", "vtrace_pg_loss", "(", "target_logits", ",", "baselines", ",", "rewards", ",", "trajectories", ",", "'target_location'", ")", "\n", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_returns": [[1066, 1103], ["torch.cat", "torch.cat", "torch.cat.float", "torch.cat", "torch.cat", "rl_loss.lambda_returns", "print", "print", "print", "print", "print", "print", "print", "print", "bootstrap.unsqueeze", "torch.ones_like", "torch.ones_like"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.lambda_returns"], ["", "def", "upgo_returns", "(", "values", ",", "rewards", ",", "discounts", ",", "bootstrap", ")", ":", "\n", "    ", "\"\"\"Computes the UPGO return targets.\n\n    Args:\n      values: Estimated state values. Shape [T, B].\n      rewards: Rewards received moving to the next state. Shape [T, B].\n      discounts: If the step is NOT final. Shape [T, B].\n      bootstrap: Bootstrap values. Shape [B].\n    Returns:\n      UPGO return targets. Shape [T, B].\n    \"\"\"", "\n", "print", "(", "\"rewards\"", ",", "rewards", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"discounts\"", ",", "discounts", ")", "if", "debug", "else", "None", "\n", "\n", "# we change it to pytorch version", "\n", "# next_values = np.concatenate((values[1:], np.expand_dims(bootstrap, axis=0)), axis=0)", "\n", "next_values", "=", "torch", ".", "cat", "(", "[", "values", "[", "1", ":", "]", ",", "bootstrap", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "print", "(", "\"next_values\"", ",", "next_values", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"next_values.shape\"", ",", "next_values", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# Upgo can be viewed as a lambda return! The trace continues (i.e. lambda =", "\n", "# 1.0) if r_t + V_tp1 > V_t.", "\n", "lambdas", "=", "(", "rewards", "+", "discounts", "*", "next_values", ")", ">=", "values", "\n", "print", "(", "\"lambdas\"", ",", "lambdas", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"lambdas.shape\"", ",", "lambdas", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# change the bool tensor to float tensor", "\n", "lambdas", "=", "lambdas", ".", "float", "(", ")", "\n", "\n", "# Shift lambdas left one slot, such that V_t matches indices with lambda_tp1.", "\n", "# lambdas = np.concatenate((lambdas[1:], np.ones_like(lambdas[-1:])), axis=0)", "\n", "lambdas", "=", "torch", ".", "cat", "(", "[", "lambdas", "[", "1", ":", "]", ",", "torch", ".", "ones_like", "(", "lambdas", "[", "-", "1", ":", "]", ",", "device", "=", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "print", "(", "\"lambdas\"", ",", "lambdas", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"lambdas.shape\"", ",", "lambdas", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "lambda_returns", "(", "next_values", ",", "rewards", ",", "discounts", ",", "lambdas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.split_upgo_loss": [[1105, 1140], ["alphastarmini.core.rl.utils.Trajectory", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "rl_loss.upgo_returns", "rl_loss.sum_upgo_loss", "print", "print", "print", "numpy.array", "print", "print", "tuple", "numpy.array"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_returns", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.sum_upgo_loss"], ["", "def", "split_upgo_loss", "(", "target_logits", ",", "baselines", ",", "trajectories", ")", ":", "\n", "    ", "\"\"\"Computes split UPGO policy gradient loss.\n\n    See split_vtrace_pg_loss docstring for details on split updates.\n    See Methods for details on UPGO.\n    \"\"\"", "\n", "# Remove last timestep from trajectories and baselines.", "\n", "trajectories", "=", "Trajectory", "(", "*", "tuple", "(", "t", "[", ":", "-", "1", "]", "for", "t", "in", "trajectories", ")", ")", "\n", "print", "(", "\"trajectories.reward\"", ",", "trajectories", ".", "reward", ")", "if", "debug", "else", "None", "\n", "\n", "values", "=", "baselines", "[", ":", "-", "1", "]", "\n", "# shape: list of [seq_size x batch_size]", "\n", "print", "(", "\"values\"", ",", "values", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"values.shape\"", ",", "values", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# we change it to pytorch version", "\n", "# returns = upgo_returns(values.detach().numpy(), np.array(trajectories.reward), ~np.array(trajectories.is_final), ", "\n", "# baselines[-1].detach().numpy())", "\n", "reward_tensor", "=", "torch", ".", "tensor", "(", "np", ".", "array", "(", "trajectories", ".", "reward", ")", ",", "device", "=", "device", ")", "\n", "discounts", "=", "torch", ".", "tensor", "(", "~", "np", ".", "array", "(", "trajectories", ".", "is_final", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "\n", "returns", "=", "upgo_returns", "(", "values", ",", "reward_tensor", ",", "discounts", ",", "baselines", "[", "-", "1", "]", ")", "\n", "\n", "# shape: list of [seq_size x batch_size]", "\n", "print", "(", "\"returns\"", ",", "returns", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"returns.shape\"", ",", "returns", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# Compute the UPGO loss for each action subset.", "\n", "# action_type, delay, and other arguments are also similarly separately ", "\n", "# updated using UPGO, in the same way as the VTrace Actor-Critic loss, ", "\n", "# with relative weight 1.0.", "\n", "# We make upgo also contains all the arguments", "\n", "loss", "=", "sum_upgo_loss", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.sum_upgo_loss": [[1142, 1156], ["rl_loss.upgo_loss_like_vtrace", "rl_loss.upgo_loss_like_vtrace", "loss.sum", "rl_loss.upgo_loss_like_vtrace"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_loss_like_vtrace", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_loss_like_vtrace", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_loss_like_vtrace"], ["", "def", "sum_upgo_loss", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ")", ":", "\n", "    ", "loss", "=", "0.", "\n", "loss", "+=", "upgo_loss_like_vtrace", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ",", "'action_type'", ")", "\n", "#loss += upgo_loss_like_vtrace(target_logits, values, trajectories, returns, 'delay')", "\n", "\n", "#loss += upgo_loss_like_vtrace(target_logits, values, trajectories, returns, 'queue')", "\n", "\n", "if", "P", ".", "use_raw_action", ":", "\n", "        ", "loss", "+=", "upgo_loss_like_vtrace", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ",", "'units'", ")", "\n", "\n", "#loss += upgo_loss_like_vtrace(target_logits, values, trajectories, returns, 'target_unit')", "\n", "", "loss", "+=", "upgo_loss_like_vtrace", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ",", "'target_location'", ")", "\n", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.upgo_loss_like_vtrace": [[1158, 1247], ["rl_loss.filter_by", "tuple", "split_target_logits.reshape.reshape", "torch.transpose", "torch.transpose", "split_target_logits.reshape.reshape", "rl_loss.filter_by_for_lists", "rl_loss.filter_by_for_lists", "rl_loss.compute_importance_weights", "torch.mean.reshape", "rl_loss.filter_by_for_masks", "rl_loss.compute_over_actions", "print", "list", "target_logits.reshape.reshape", "behavior_logits.reshape.reshape", "actions.reshape.reshape", "target_logits.reshape.reshape", "behavior_logits.reshape.reshape", "torch.zeros", "torch.zeros", "enumerate", "torch.mean.reshape", "torch.mean", "torch.mean", "print", "target_logits.reshape.reshape", "actions.reshape.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_logits.reshape.reshape", "actions.reshape.reshape", "torch.mean.reshape", "torch.mean", "torch.mean", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_lists", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_lists", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_importance_weights", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.filter_by_for_masks", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.compute_over_actions"], ["", "def", "upgo_loss_like_vtrace", "(", "target_logits", ",", "values", ",", "trajectories", ",", "returns", ",", "action_fields", ")", ":", "\n", "    ", "print", "(", "\"action_fields\"", ",", "action_fields", ")", "if", "debug", "else", "None", "\n", "\n", "# Filter for only the relevant actions/logits/masks.", "\n", "target_logits", "=", "filter_by", "(", "action_fields", ",", "target_logits", ")", "\n", "\n", "# shape: [batch_seq_size x action_size]", "\n", "split_target_logits", "=", "target_logits", "\n", "action_size", "=", "tuple", "(", "list", "(", "target_logits", ".", "shape", "[", "1", ":", "]", ")", ")", "# from the 3rd dim, it is action dim, may be [S] or [C, S] or [H, W]", "\n", "\n", "# shape: [batch_size x seq_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", ".", "reshape", "(", "AHP", ".", "batch_size", ",", "AHP", ".", "sequence_length", ",", "*", "action_size", ")", "\n", "# shape: [seq_size x batch_size x action_size]", "\n", "split_target_logits", "=", "torch", ".", "transpose", "(", "split_target_logits", ",", "0", ",", "1", ")", "\n", "# shape: [new_seq_size x batch_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", "[", ":", "-", "1", "]", "\n", "# shape: [seq_batch_size x action_size]", "\n", "split_target_logits", "=", "split_target_logits", ".", "reshape", "(", "-", "1", ",", "*", "action_size", ")", "\n", "\n", "target_logits", "=", "split_target_logits", "\n", "\n", "behavior_logits", "=", "filter_by_for_lists", "(", "action_fields", ",", "trajectories", ".", "behavior_logits", ")", "\n", "\n", "actions", "=", "filter_by_for_lists", "(", "action_fields", ",", "trajectories", ".", "action", ")", "\n", "\n", "if", "action_fields", "==", "'units'", "or", "action_fields", "==", "'target_unit'", ":", "\n", "        ", "seqbatch_unit_shape", "=", "target_logits", ".", "shape", "[", "0", ":", "2", "]", "\n", "target_logits", "=", "target_logits", ".", "reshape", "(", "-", "1", ",", "target_logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "behavior_logits", "=", "behavior_logits", ".", "reshape", "(", "-", "1", ",", "behavior_logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "-", "1", ",", "actions", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "action_fields", "==", "'target_location'", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "target_logits", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "behavior_logits", "=", "behavior_logits", ".", "reshape", "(", "behavior_logits", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "actions_2", "=", "torch", ".", "zeros", "(", "behavior_logits", ".", "shape", "[", "0", "]", ",", "1", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "device", ")", "\n", "\n", "for", "i", ",", "pos", "in", "enumerate", "(", "actions", ")", ":", "\n", "# note: for pos, the first index is x, the seconde index is y", "\n", "# however, for the matrix, the first index is y (row), and the second index is x (col)", "\n", "            ", "x", "=", "pos", "[", "0", "]", "\n", "assert", "x", ">=", "0", "\n", "assert", "x", "<", "SCHP", ".", "world_size", "\n", "y", "=", "pos", "[", "1", "]", "\n", "assert", "y", ">=", "0", "\n", "assert", "y", "<", "SCHP", ".", "world_size", "\n", "index", "=", "SCHP", ".", "world_size", "*", "y", "+", "x", "\n", "actions_2", "[", "i", "]", "[", "0", "]", "=", "index", "\n", "\n", "", "actions", "=", "actions_2", "\n", "print", "(", "\"actions_2.shape\"", ",", "actions_2", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "", "clipped_rhos", "=", "compute_importance_weights", "(", "behavior_logits", ",", "\n", "target_logits", ",", "\n", "actions", ")", "\n", "\n", "if", "action_fields", "==", "'units'", "or", "action_fields", "==", "'target_unit'", ":", "\n", "        ", "clipped_rhos", "=", "clipped_rhos", ".", "reshape", "(", "seqbatch_unit_shape", ",", "-", "1", ")", "\n", "clipped_rhos", "=", "torch", ".", "mean", "(", "clipped_rhos", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# To make the clipped_rhos shape to be [T-1, B]", "\n", "", "clipped_rhos", "=", "clipped_rhos", ".", "reshape", "(", "values", ".", "shape", ")", "\n", "weighted_advantage", "=", "(", "returns", "-", "values", ")", "*", "clipped_rhos", "\n", "print", "(", "\"weighted_advantage\"", ",", "weighted_advantage", ")", "if", "debug", "else", "None", "\n", "\n", "masks", "=", "filter_by_for_masks", "(", "action_fields", ",", "trajectories", ".", "masks", ")", "\n", "\n", "# here we should reshape the target_logits and actions back to [T-1, B, C] size for computing policy gradient", "\n", "if", "action_fields", "==", "'units'", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", "*", "AHP", ".", "max_selected", ",", "-", "1", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", "*", "AHP", ".", "max_selected", ",", "-", "1", ")", "\n", "\n", "weighted_advantage", "=", "torch", ".", "cat", "(", "[", "weighted_advantage", "]", "*", "AHP", ".", "max_selected", ",", "dim", "=", "1", ")", "\n", "masks", "=", "torch", ".", "cat", "(", "[", "masks", "]", "*", "AHP", ".", "max_selected", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "target_logits", "=", "target_logits", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", ",", "-", "1", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "AHP", ".", "sequence_length", "-", "1", ",", "AHP", ".", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "result", "=", "compute_over_actions", "(", "policy_gradient_loss", ",", "target_logits", ",", "\n", "actions", ",", "weighted_advantage", ",", "masks", ")", "\n", "\n", "if", "action_fields", "==", "'units'", ":", "\n", "        ", "result", "=", "result", ".", "reshape", "(", "-", "1", ",", "AHP", ".", "max_selected", ")", "\n", "result", "=", "torch", ".", "mean", "(", "result", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "print", "(", "\"result\"", ",", "result", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"result.shape\"", ",", "result", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.get_baseline_hyperparameters": [[1249, 1279], ["None"], "function", ["None"], ["", "def", "get_baseline_hyperparameters", "(", ")", ":", "\n", "# Accroding to detailed_architecture.txt, baselines contains the following 5 items:", "\n", "# Winloss Baseline;", "\n", "# Build Order Baseline;", "\n", "# Built Units Baseline;", "\n", "# Upgrades Baseline;", "\n", "# Effects Baseline.", "\n", "# Thus BASELINE_COSTS_AND_REWARDS also have 5 entry", "\n", "    ", "winloss_baseline_costs", "=", "(", "1.0", ",", "10.0", ",", "\"winloss_baseline\"", ")", "\n", "\n", "# AlphaStar: The updates are computed similar to Winloss, except without UPGO, applied using Build Order baseline, and ", "\n", "# with relative weightings 4.0 for the policy and 1.0 for the baseline.", "\n", "build_order_baseline_costs", "=", "(", "4.0", ",", "1.0", ",", "\"build_order_baseline\"", ")", "\n", "\n", "# AlphaStar: The updates are computed similar to Winloss, except without UPGO, applied using Built Units baseline, ", "\n", "# and with relative weightings 6.0 for the policy and 1.0 for the baseline.", "\n", "built_units_baseline_costs", "=", "(", "6.0", ",", "1.0", ",", "\"built_units_baseline\"", ")", "\n", "\n", "# AlphaStar: The updates are computed similar to Winloss, except without UpGO, applied using Upgrades baseline, and ", "\n", "# with relative weightings 6.0 for the policy and 1.0 for the baseline.", "\n", "upgrades_baseline_costs", "=", "(", "6.0", ",", "1.0", ",", "\"upgrades_baseline\"", ")", "\n", "\n", "# AlphaStar: The updates are computed similar to Winloss, except without UPGO, applied using Effects baseline, and ", "\n", "# with relative weightings 6.0 for the policy and 1.0 for the baseline.", "\n", "effects_baseline_costs", "=", "(", "6.0", ",", "1.0", ",", "\"effects_baseline\"", ")", "\n", "\n", "BASELINE_COSTS_AND_REWARDS", "=", "[", "winloss_baseline_costs", ",", "build_order_baseline_costs", ",", "built_units_baseline_costs", ",", "\n", "upgrades_baseline_costs", ",", "effects_baseline_costs", "]", "\n", "\n", "return", "BASELINE_COSTS_AND_REWARDS", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.loss_function": [[1281, 1334], ["agent.unroll", "alphastarmini.core.rl.utils.stack_namedtuple", "alphastarmini.core.rl.utils.namedtuple_zip", "torch.tensor", "torch.tensor", "rl_loss.td_lambda_loss", "rl_loss.split_vtrace_pg_loss", "rl_loss.split_upgo_loss", "print", "print", "print", "print", "print", "print", "print", "print", "rl_loss.entropy_loss_for_all_arguments", "torch.mean", "torch.mean", "torch.std", "torch.std"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.unroll", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.stack_namedtuple", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.namedtuple_zip", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.td_lambda_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.split_vtrace_pg_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.split_upgo_loss", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.entropy_loss_for_all_arguments"], ["", "def", "loss_function", "(", "agent", ",", "trajectories", ")", ":", "\n", "    ", "\"\"\"Computes the loss of trajectories given weights.\"\"\"", "\n", "# All ALL_CAPS variables are constants.", "\n", "\n", "# QUESTIOM: The trajectories already have behavior_logits, why is the need", "\n", "# to calculate the target_logits?", "\n", "# trajectories shape: list of trajectory", "\n", "# target_logits: ArgsActionLogits", "\n", "target_logits", ",", "baselines", "=", "agent", ".", "unroll", "(", "trajectories", ")", "\n", "\n", "trajectories", "=", "U", ".", "stack_namedtuple", "(", "trajectories", ")", "\n", "trajectories", "=", "U", ".", "namedtuple_zip", "(", "trajectories", ")", "\n", "\n", "loss_actor_critic", "=", "0.", "\n", "if", "True", ":", "\n", "        ", "rewards", "=", "torch", ".", "tensor", "(", "trajectories", ".", "reward", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "print", "(", "\"trajectories.reward\"", ",", "rewards", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"trajectories.reward.shape\"", ",", "rewards", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "# use normalize", "\n", "if", "False", ":", "\n", "            ", "scale_dim", "=", "1", "\n", "rewards", "=", "(", "rewards", "-", "torch", ".", "mean", "(", "rewards", ",", "dim", "=", "scale_dim", ",", "keepdim", "=", "True", ")", ")", "/", "(", "torch", ".", "std", "(", "rewards", ",", "dim", "=", "scale_dim", ",", "keepdim", "=", "True", ")", "+", "1e-9", ")", "\n", "\n", "", "print", "(", "\"trajectories.reward\"", ",", "rewards", ")", "if", "debug", "else", "None", "\n", "print", "(", "\"trajectories.reward.shape\"", ",", "rewards", ".", "shape", ")", "if", "debug", "else", "None", "\n", "\n", "lambda_loss", "=", "td_lambda_loss", "(", "baselines", "[", "0", "]", ",", "rewards", ",", "trajectories", ")", "\n", "print", "(", "\"lambda_loss:\"", ",", "lambda_loss", ")", "if", "1", "else", "None", "\n", "loss_actor_critic", "+=", "(", "10.", "*", "lambda_loss", ")", "\n", "\n", "# we add the split_vtrace_pg_loss", "\n", "pg_loss", "=", "split_vtrace_pg_loss", "(", "target_logits", ",", "baselines", "[", "0", "]", ",", "rewards", ",", "trajectories", ")", "\n", "print", "(", "\"pg_loss:\"", ",", "pg_loss", ")", "if", "1", "else", "None", "\n", "loss_actor_critic", "+=", "(", "1.0", "*", "pg_loss", ")", "\n", "\n", "", "UPGO_WEIGHT", "=", "1.0", "\n", "loss_upgo", "=", "UPGO_WEIGHT", "*", "split_upgo_loss", "(", "target_logits", ",", "baselines", "[", "0", "]", ",", "trajectories", ")", "\n", "print", "(", "\"loss_upgo:\"", ",", "loss_upgo", ")", "if", "debug", "else", "None", "\n", "\n", "# note: we want to maximize the entropy", "\n", "# so we gradient descent the -entropy", "\n", "# Original AlphaStar pseudocode is wrong", "\n", "# AlphaStar: loss_ent = entropy_loss(trajectories.behavior_logits, trajectories.masks)", "\n", "loss_ent", "=", "3", "*", "(", "-", "entropy_loss_for_all_arguments", "(", "target_logits", ",", "trajectories", ".", "masks", ")", ")", "\n", "print", "(", "\"loss_ent:\"", ",", "loss_ent", ")", "if", "1", "else", "None", "\n", "\n", "#loss_all = target_logits.action_type.sum()", "\n", "loss_all", "=", "loss_actor_critic", "+", "loss_ent", "# + loss_upgo", "\n", "\n", "loss_list", "=", "[", "lambda_loss", ",", "pg_loss", ",", "loss_upgo", ",", "loss_ent", "]", "\n", "\n", "return", "loss_all", ",", "loss_list", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.__init__": [[26, 51], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "action_type", "=", "0", ",", "delay", "=", "SCHP", ".", "sc2_default_delay", ",", "queue", "=", "0", ",", "\n", "units", "=", "None", ",", "target_unit", "=", "None", ",", "\n", "target_location", "=", "None", ",", "use_tag", "=", "False", ")", ":", "\n", "        ", "super", "(", "ArgsAction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_type", "=", "action_type", "\n", "self", ".", "delay", "=", "delay", "\n", "self", ".", "queue", "=", "queue", "\n", "self", ".", "use_tag", "=", "use_tag", "\n", "\n", "self", ".", "units", "=", "units", "\n", "self", ".", "target_unit", "=", "target_unit", "\n", "\n", "self", ".", "target_location", "=", "target_location", "\n", "\n", "self", ".", "max_actions", "=", "LS", ".", "action_type_encoding", "\n", "self", ".", "max_delay", "=", "LS", ".", "delay_encoding", "\n", "self", ".", "max_queue", "=", "LS", ".", "queue_encoding", "\n", "\n", "self", ".", "max_units", "=", "AHP", ".", "max_entities", "\n", "self", ".", "max_selected", "=", "AHP", ".", "max_selected", "\n", "self", ".", "output_map_size", "=", "SCHP", ".", "world_size", "\n", "\n", "# not used", "\n", "self", ".", "max_target_unit", "=", "1", "\n", "self", ".", "max_target_location", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toTenser": [[52, 99], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "action.ArgsAction", "enumerate"], "methods", ["None"], ["", "def", "toTenser", "(", "self", ")", ":", "\n", "# for numpy or int object to tensor", "\n", "# note, this is used in the one element case", "\n", "        ", "action_type_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "action_type", "is", "not", "None", ":", "\n", "            ", "action_type_encoding", "[", "0", ",", "0", "]", "=", "self", ".", "action_type", "\n", "\n", "", "delay_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "delay", "is", "not", "None", ":", "\n", "            ", "delay_encoding", "[", "0", ",", "0", "]", "=", "self", ".", "delay", "\n", "\n", "", "queue_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "queue", "is", "not", "None", ":", "\n", "            ", "queue_encoding", "[", "0", ",", "0", "]", "=", "self", ".", "queue", "\n", "\n", "", "select_units_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "max_selected", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "units", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "u", "in", "enumerate", "(", "self", ".", "units", ")", ":", "\n", "                ", "if", "i", ">=", "self", ".", "max_selected", ":", "\n", "                    ", "break", "\n", "# ensure the unit index not beyond the max entities we considered", "\n", "", "if", "u", ">=", "self", ".", "max_units", ":", "\n", "                    ", "u", "=", "0", "\n", "", "select_units_encoding", "[", "0", ",", "i", ",", "0", "]", "=", "u", "\n", "\n", "", "", "target_unit_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "target_unit", "is", "not", "None", ":", "\n", "# ensure the target unit index not beyond the max entities we considered", "\n", "            ", "u", "=", "self", ".", "target_unit", "\n", "if", "u", ">=", "self", ".", "max_units", ":", "\n", "                ", "u", "=", "0", "\n", "", "target_unit_encoding", "[", "0", ",", "0", ",", "0", "]", "=", "u", "\n", "\n", "", "target_location_encoding", "=", "torch", ".", "zeros", "(", "1", ",", "2", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "target_location", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "target_location", "[", "0", "]", "\n", "y", "=", "self", ".", "target_location", "[", "1", "]", "\n", "# ensure the position not beyond the map size", "\n", "if", "x", ">=", "self", ".", "output_map_size", ":", "\n", "                ", "x", "=", "0", "\n", "", "if", "y", ">=", "self", ".", "output_map_size", ":", "\n", "                ", "y", "=", "0", "\n", "", "target_location_encoding", "[", "0", ",", "0", "]", "=", "y", "# note: the row index (0-index) is the y-axis", "\n", "target_location_encoding", "[", "0", ",", "1", "]", "=", "x", "# note: the col index (1-index) is the x-axis", "\n", "\n", "", "return", "ArgsAction", "(", "action_type_encoding", ",", "delay_encoding", ",", "queue_encoding", ",", "select_units_encoding", ",", "\n", "target_unit_encoding", ",", "target_location_encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toLogits": [[100, 134], ["alphastarmini.lib.utils.to_one_hot().squeeze", "alphastarmini.lib.utils.to_one_hot().squeeze", "alphastarmini.lib.utils.to_one_hot().squeeze", "alphastarmini.lib.utils.to_one_hot().squeeze", "alphastarmini.lib.utils.to_one_hot().squeeze", "torch.zeros", "enumerate", "action.ArgsActionLogits", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot", "alphastarmini.lib.utils.to_one_hot"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.to_one_hot"], ["", "def", "toLogits", "(", "self", ",", "tag_list", "=", "None", ")", ":", "\n", "# for tensor action to tensor action with one-hot embedding", "\n", "        ", "batch_size", "=", "self", ".", "action_type", ".", "shape", "[", "0", "]", "\n", "\n", "action_type_encoding", "=", "L", ".", "to_one_hot", "(", "self", ".", "action_type", ",", "self", ".", "max_actions", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "'self.action_type:'", ",", "self", ".", "action_type", ")", "if", "debug", "else", "None", "\n", "print", "(", "'action_type_encoding:'", ",", "action_type_encoding", ")", "if", "debug", "else", "None", "\n", "\n", "delay_encoding", "=", "L", ".", "to_one_hot", "(", "self", ".", "delay", ",", "self", ".", "max_delay", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "'self.delay:'", ",", "self", ".", "delay", ")", "if", "debug", "else", "None", "\n", "print", "(", "'delay_encoding:'", ",", "delay_encoding", ")", "if", "debug", "else", "None", "\n", "\n", "queue_encoding", "=", "L", ".", "to_one_hot", "(", "self", ".", "queue", ",", "self", ".", "max_queue", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "'self.queue:'", ",", "self", ".", "queue", ")", "if", "debug", "else", "None", "\n", "print", "(", "'queue_encoding:'", ",", "queue_encoding", ")", "if", "debug", "else", "None", "\n", "\n", "print", "(", "'self.units_index:'", ",", "self", ".", "units", ")", "if", "debug", "else", "None", "\n", "select_units_encoding", "=", "L", ".", "to_one_hot", "(", "self", ".", "units", ",", "self", ".", "max_units", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "'select_units_encoding:'", ",", "select_units_encoding", ")", "if", "debug", "else", "None", "\n", "\n", "target_unit_encoding", "=", "L", ".", "to_one_hot", "(", "self", ".", "target_unit", ",", "self", ".", "max_units", ")", ".", "squeeze", "(", "-", "2", ")", "\n", "print", "(", "'self.target_unit_index:'", ",", "self", ".", "target_unit", ")", "if", "debug", "else", "None", "\n", "print", "(", "'target_unit_encoding:'", ",", "target_unit_encoding", ")", "if", "debug", "else", "None", "\n", "\n", "target_location_encoding", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "output_map_size", ",", "self", ".", "output_map_size", ")", "\n", "for", "i", ",", "z", "in", "enumerate", "(", "self", ".", "target_location", ")", ":", "\n", "            ", "(", "x", ",", "y", ")", "=", "z", "\n", "target_row_col", "=", "(", "y", ",", "x", ")", "\n", "target_location_encoding", "[", "i", ",", "y", ",", "x", "]", "=", "1", "\n", "\n", "", "print", "(", "'self.target_location:'", ",", "self", ".", "target_location", ")", "if", "debug", "else", "None", "\n", "print", "(", "'target_location_encoding:'", ",", "target_location_encoding", ")", "if", "debug", "else", "None", "\n", "return", "ArgsActionLogits", "(", "action_type_encoding", ",", "delay_encoding", ",", "queue_encoding", ",", "select_units_encoding", ",", "\n", "target_unit_encoding", ",", "target_location_encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.toList": [[135, 138], ["None"], "methods", ["None"], ["", "def", "toList", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "action_type", ",", "self", ".", "delay", ",", "self", ".", "queue", ",", "self", ".", "units", ",", "\n", "self", ".", "target_unit", ",", "self", ".", "target_location", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.get_shape": [[139, 146], ["None"], "methods", ["None"], ["", "def", "get_shape", "(", "self", ")", ":", "\n", "        ", "result", "=", "\"\"\"action_type:%s, delay:%s, queue:%s, units:%s, \n        target_unit:%s, target_location:%s\"\"\"", "%", "(", "self", ".", "action_type", ".", "shape", ",", "\n", "self", ".", "delay", ".", "shape", ",", "self", ".", "queue", ".", "shape", ",", "self", ".", "units", ".", "shape", ",", "\n", "self", ".", "target_unit", ".", "shape", ",", "\n", "self", ".", "target_location", ".", "shape", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsAction.__str__": [[147, 154], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "result", "=", "\"\"\"action_type:%s, delay:%s, queue:%s, units:%s, \n        target_unit:%s, target_location:%s\"\"\"", "%", "(", "self", ".", "action_type", ",", "\n", "self", ".", "delay", ",", "self", ".", "queue", ",", "self", ".", "units", ",", "\n", "self", ".", "target_unit", ",", "\n", "self", ".", "target_location", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.__init__": [[161, 181], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__"], ["def", "__init__", "(", "self", ",", "action_type", ",", "delay", ",", "queue", ",", "units", ",", "\n", "target_unit", ",", "target_location", ")", ":", "\n", "        ", "super", "(", "ArgsActionLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_type", "=", "action_type", "\n", "self", ".", "delay", "=", "delay", "\n", "self", ".", "queue", "=", "queue", "\n", "self", ".", "units", "=", "units", "\n", "self", ".", "target_unit", "=", "target_unit", "\n", "self", ".", "target_location", "=", "target_location", "\n", "\n", "self", ".", "max_actions", "=", "LS", ".", "action_type_encoding", "\n", "self", ".", "max_delay", "=", "LS", ".", "delay_encoding", "\n", "self", ".", "max_queue", "=", "LS", ".", "queue_encoding", "\n", "\n", "self", ".", "max_units", "=", "AHP", ".", "max_entities", "\n", "self", ".", "output_map_size", "=", "SCHP", ".", "world_size", "\n", "\n", "# not used", "\n", "self", ".", "max_target_unit", "=", "1", "\n", "self", ".", "max_target_location", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.toList": [[182, 185], ["None"], "methods", ["None"], ["", "def", "toList", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "action_type", ",", "self", ".", "delay", ",", "self", ".", "queue", ",", "self", ".", "units", ",", "\n", "self", ".", "target_unit", ",", "self", ".", "target_location", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.__str__": [[186, 198], ["str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "shape1", "=", "str", "(", "self", ".", "action_type", ".", "shape", ")", "\n", "shape2", "=", "str", "(", "self", ".", "delay", ".", "shape", ")", "\n", "shape3", "=", "str", "(", "self", ".", "queue", ".", "shape", ")", "\n", "shape4", "=", "str", "(", "self", ".", "units", ".", "shape", ")", "if", "self", ".", "units", "is", "not", "None", "else", "\"None\"", "\n", "shape5", "=", "str", "(", "self", ".", "target_unit", ".", "shape", ")", "if", "self", ".", "target_unit", "is", "not", "None", "else", "\"None\"", "\n", "shape6", "=", "str", "(", "self", ".", "target_location", ".", "shape", ")", "if", "self", ".", "target_location", "is", "not", "None", "else", "\"None\"", "\n", "\n", "return", "\"%s %s %s %s %s %s\"", "%", "(", "shape1", ",", "shape2", ",", "\n", "shape3", ",", "\n", "shape4", ",", "\n", "shape5", ",", "shape6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to": [[199, 208], ["action.ArgsActionLogits.action_type.to().float", "action.ArgsActionLogits.delay.to().float", "action.ArgsActionLogits.queue.to().float", "action.ArgsActionLogits.units.to().float", "action.ArgsActionLogits.target_unit.to().float", "action.ArgsActionLogits.target_location.to().float", "print", "print", "action.ArgsActionLogits.action_type.to", "action.ArgsActionLogits.delay.to", "action.ArgsActionLogits.queue.to", "action.ArgsActionLogits.units.to", "action.ArgsActionLogits.target_unit.to", "action.ArgsActionLogits.target_location.to"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "print", "(", "'self.action_type.device:'", ",", "self", ".", "action_type", ".", "device", ")", "if", "debug", "else", "None", "\n", "self", ".", "action_type", "=", "self", ".", "action_type", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "print", "(", "'self.action_type.device:'", ",", "self", ".", "action_type", ".", "device", ")", "if", "debug", "else", "None", "\n", "self", ".", "delay", "=", "self", ".", "delay", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "queue", "=", "self", ".", "queue", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "units", "=", "self", ".", "units", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "target_unit", "=", "self", ".", "target_unit", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "target_location", "=", "self", ".", "target_location", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.device": [[209, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "action_type", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.test": [[214, 217], ["None"], "function", ["None"], ["", "", "def", "test", "(", ")", ":", "\n", "# refer to arch_model.py for test", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_train_HAS.test": [[35, 76], ["alphastarmini.core.ma.league.League", "alphastarmini.core.ma.coordinator.Coordinator", "range", "alphastarmini.core.ma.league.League.get_learning_players_num", "alphastarmini.core.ma.league.League.get_learning_player", "alphastarmini.core.rl.learner.Learner", "learners.append", "actors.extend", "l.start", "threads.append", "time.sleep", "a.start", "threads.append", "time.sleep", "t.join", "print", "alphastarmini.core.rl.utils.get_reinforcement_agent", "alphastarmini.core.rl.actor_HAS.ActorLoopHAS", "range"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_players_num", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_reinforcement_agent"], ["def", "test", "(", "on_server", "=", "False", ",", "replay_path", "=", "None", ")", ":", "\n", "# model path", "\n", "    ", "ACTOR_NUMS", "=", "P", ".", "actor_nums", "\n", "RESTORE", "=", "False", "\n", "model_name", "=", "\"rl_21-08-04_11-08-04.pkl\"", "\n", "\n", "league", "=", "League", "(", "\n", "initial_agents", "=", "{", "\n", "race", ":", "U", ".", "get_reinforcement_agent", "(", "race", ",", "restore", "=", "RESTORE", ",", "model_name", "=", "model_name", ")", "\n", "for", "race", "in", "[", "Race", ".", "protoss", "]", "\n", "}", ",", "\n", "main_players", "=", "1", ",", "\n", "main_exploiters", "=", "0", ",", "\n", "league_exploiters", "=", "0", ")", "\n", "\n", "coordinator", "=", "Coordinator", "(", "league", ")", "\n", "learners", "=", "[", "]", "\n", "actors", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "league", ".", "get_learning_players_num", "(", ")", ")", ":", "\n", "        ", "player", "=", "league", ".", "get_learning_player", "(", "idx", ")", "\n", "learner", "=", "Learner", "(", "player", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ")", "\n", "learners", ".", "append", "(", "learner", ")", "\n", "actors", ".", "extend", "(", "[", "ActorLoopHAS", "(", "player", ",", "coordinator", ",", "replay_path", "=", "replay_path", ")", "for", "_", "in", "range", "(", "ACTOR_NUMS", ")", "]", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "for", "l", "in", "learners", ":", "\n", "        ", "l", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "l", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "", "for", "a", "in", "actors", ":", "\n", "        ", "a", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "a", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "# Wait for training to finish.", "\n", "        ", "for", "t", "in", "threads", ":", "\n", "            ", "t", ".", "join", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Exception Handled in Main, Detials of the Exception:\"", ",", "e", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.__init__": [[61, 94], ["actor_RAS.ActorLoopRAS.player.add_actor", "threading.Thread", "datetime.datetime.datetime.now", "tensorboardX.SummaryWriter", "actor_RAS.ActorLoopRAS.player.agent.agent_nn.to", "datetime.datetime.now.strftime"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.add_actor", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["def", "__init__", "(", "self", ",", "player", ",", "coordinator", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ",", "\n", "max_time_per_one_opponent", "=", "60", "*", "60", "*", "2", ",", "\n", "max_frames_per_episode", "=", "22.4", "*", "60", "*", "15", ",", "max_frames", "=", "22.4", "*", "60", "*", "60", "*", "24", ",", "\n", "max_episodes", "=", "MAX_EPISODES", ",", "use_replay_expert_reward", "=", "True", ",", "\n", "replay_path", "=", "\"data/Replays/filtered_replays_1/\"", ",", "replay_version", "=", "'3.16.1'", ",", "\n", "record", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "player", "=", "player", "\n", "self", ".", "player", ".", "add_actor", "(", "self", ")", "\n", "if", "ON_GPU", ":", "\n", "            ", "self", ".", "player", ".", "agent", ".", "agent_nn", ".", "to", "(", "DEVICE", ")", "\n", "\n", "# below code is not used because we only can create the env when we know the opponnet information (e.g., race)", "\n", "# AlphaStar: self.environment = SC2Environment()", "\n", "\n", "", "self", ".", "coordinator", "=", "coordinator", "\n", "self", ".", "max_time_for_training", "=", "max_time_for_training", "\n", "self", ".", "max_time_per_one_opponent", "=", "max_time_per_one_opponent", "\n", "self", ".", "max_frames_per_episode", "=", "max_frames_per_episode", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "max_episodes", "=", "max_episodes", "\n", "\n", "self", ".", "thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "run", ",", "args", "=", "(", ")", ")", "\n", "self", ".", "thread", ".", "daemon", "=", "True", "# Daemonize thread", "\n", "\n", "self", ".", "is_running", "=", "True", "\n", "self", ".", "is_start", "=", "False", "\n", "\n", "now", "=", "datetime", ".", "now", "(", ")", "\n", "summary_path", "=", "\"./log/\"", "+", "now", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "+", "\"_reward/\"", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "summary_path", ")", "\n", "self", ".", "batch_iter", "=", "0", "\n", "self", ".", "record", "=", "record", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.start": [[95, 98], ["actor_RAS.ActorLoopRAS.thread.start"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "is_start", "=", "True", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_func": [[99, 203], ["actor_RAS.ActorLoopRAS.player.agent.step_logits_RAS", "our_unit_list.extend", "probe_list.sort", "our_unit_list.extend", "random.randint", "env._features[].transform_action", "env._features[].transform_action.HasField", "alphastarmini.core.rl.utils.get_mask_raw", "print", "len", "len", "print", "raw_act.HasField", "print", "print", "len", "len", "uc.HasField", "nexus_list.append", "probe_list.append", "len", "idle_probe_list.append", "print", "mineral_unit_list.append"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits_RAS", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_mask_raw"], ["", "def", "get_func", "(", "self", ",", "env", ",", "home_obs", ",", "player_memory", ",", "action_spec", ")", ":", "\n", "# run_loop: actions = [agent.step(timestep) for agent, timestep in zip(agents, timesteps)]", "\n", "        ", "player_step", "=", "self", ".", "player", ".", "agent", ".", "step_logits_RAS", "(", "home_obs", ",", "player_memory", ")", "\n", "function_call", ",", "select_units", ",", "player_action", ",", "player_logits", ",", "player_new_memory", "=", "player_step", "\n", "print", "(", "\"function:\"", ",", "function_call", ".", "function", ")", "if", "debug", "else", "None", "\n", "\n", "obs", "=", "home_obs", ".", "observation", "\n", "raw_units", "=", "obs", "[", "\"raw_units\"", "]", "\n", "\n", "our_unit_list", "=", "[", "]", "\n", "mineral_unit_list", "=", "[", "]", "\n", "nexus_list", "=", "[", "]", "\n", "probe_list", "=", "[", "]", "\n", "idle_probe_list", "=", "[", "]", "\n", "for", "u", "in", "raw_units", ":", "\n", "# only include the units we have", "\n", "            ", "if", "u", ".", "alliance", "==", "1", ":", "\n", "# our_unit_list.append(u)", "\n", "                ", "if", "u", ".", "unit_type", "==", "59", ":", "\n", "                    ", "nexus_list", ".", "append", "(", "u", ")", "\n", "", "if", "u", ".", "unit_type", "==", "84", ":", "\n", "                    ", "probe_list", ".", "append", "(", "u", ")", "\n", "if", "u", ".", "order_length", "==", "0", ":", "\n", "                        ", "idle_probe_list", ".", "append", "(", "u", ")", "\n", "# include the units of Neutral   ", "\n", "", "", "", "if", "u", ".", "alliance", "==", "3", ":", "\n", "                ", "if", "u", ".", "display_type", "==", "1", ":", "\n", "                    ", "if", "u", ".", "x", "<", "40", "and", "u", ".", "y", "<", "50", ":", "\n", "                        ", "if", "u", ".", "mineral_contents", ">", "0", ":", "\n", "                            ", "mineral_unit_list", ".", "append", "(", "u", ")", "\n", "\n", "", "", "", "", "", "our_unit_list", ".", "extend", "(", "nexus_list", ")", "\n", "\n", "def", "myFunc", "(", "e", ")", ":", "\n", "            ", "return", "e", ".", "tag", "\n", "", "probe_list", ".", "sort", "(", "reverse", "=", "False", ",", "key", "=", "myFunc", ")", "\n", "our_unit_list", ".", "extend", "(", "probe_list", ")", "\n", "\n", "random_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "our_unit_list", ")", "-", "1", ")", "\n", "if", "len", "(", "select_units", ")", ">", "0", ":", "\n", "            ", "predict_index", "=", "select_units", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "predict_index", "=", "-", "1", "\n", "\n", "", "if", "len", "(", "mineral_unit_list", ")", ">", "0", ":", "\n", "            ", "max_mineral_contents", "=", "mineral_unit_list", "[", "0", "]", ".", "mineral_contents", "\n", "max_mineral_tag", "=", "mineral_unit_list", "[", "0", "]", ".", "tag", "\n", "\n", "for", "u", "in", "mineral_unit_list", ":", "\n", "                ", "if", "u", ".", "mineral_contents", ">", "max_mineral_contents", ":", "\n", "                    ", "max_mineral_contents", "=", "u", ".", "mineral_contents", "\n", "max_mineral_tag", "=", "u", ".", "tag", "\n", "\n", "", "", "", "if", "predict_index", ">=", "len", "(", "our_unit_list", ")", "or", "predict_index", "<", "0", ":", "\n", "            ", "unit_index", "=", "random_index", "\n", "", "else", ":", "\n", "            ", "unit_index", "=", "predict_index", "\n", "\n", "", "the_tag", "=", "our_unit_list", "[", "unit_index", "]", ".", "tag", "\n", "\n", "# we change pysc2 action to sc2 action, for replace the unit tag", "\n", "sc2_action", "=", "env", ".", "_features", "[", "0", "]", ".", "transform_action", "(", "obs", ",", "function_call", ")", "\n", "print", "(", "\"sc2_action before transformed:\"", ",", "sc2_action", ")", "if", "debug", "else", "None", "\n", "\n", "# if len(nexus_list) > 0:", "\n", "#     nexus_tag = nexus_list[0].tag", "\n", "#     print(\"nexus_tag\", nexus_tag) if debug else None", "\n", "#     if function_call.function == 64:", "\n", "#         the_tag = nexus_tag", "\n", "\n", "# if len(idle_probe_list) > 0:", "\n", "#     idle_probe_tag = idle_probe_list[0].tag", "\n", "#     print(\"idle_probe_tag\", idle_probe_tag) if debug else None", "\n", "#     if function_call.function == 35:", "\n", "#         the_tag = idle_probe_tag", "\n", "# elif len(probe_list) > 0:", "\n", "#     probe_tag = probe_list[0].tag", "\n", "#     print(\"probe_tag\", probe_tag) if debug else None", "\n", "#     if function_call.function == 35:", "\n", "#         the_tag = probe_tag", "\n", "\n", "if", "sc2_action", ".", "HasField", "(", "\"action_raw\"", ")", ":", "\n", "            ", "raw_act", "=", "sc2_action", ".", "action_raw", "\n", "if", "raw_act", ".", "HasField", "(", "\"unit_command\"", ")", ":", "\n", "                ", "uc", "=", "raw_act", ".", "unit_command", "\n", "# to judge a repteated field whether has ", "\n", "# use the following way", "\n", "if", "len", "(", "uc", ".", "unit_tags", ")", "!=", "0", ":", "\n", "# can not assign, must use unit_tags[:]=[xx tag]", "\n", "                    ", "print", "(", "\"the_tag\"", ",", "the_tag", ")", "if", "debug", "else", "None", "\n", "uc", ".", "unit_tags", "[", ":", "]", "=", "[", "the_tag", "]", "\n", "# we use fixed target unit tag only for Harvest_Gather_unit action", "\n", "", "if", "uc", ".", "HasField", "(", "\"target_unit_tag\"", ")", ":", "\n", "                    ", "uc", ".", "target_unit_tag", "=", "max_mineral_tag", "\n", "\n", "", "", "", "print", "(", "\"sc2_action after transformed:\"", ",", "sc2_action", ")", "if", "debug", "else", "None", "\n", "\n", "env_actions", "=", "[", "sc2_action", "]", "\n", "\n", "player_action_spec", "=", "action_spec", "[", "0", "]", "\n", "action_masks", "=", "U", ".", "get_mask_raw", "(", "player_action", ",", "player_action_spec", ")", "\n", "print", "(", "'player_action'", ",", "player_action", ",", "'action_masks'", ",", "action_masks", ")", "if", "debug", "else", "None", "\n", "\n", "return", "env_actions", ",", "player_action", ",", "player_logits", ",", "action_masks", ",", "player_new_memory", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_reward": [[204, 223], ["float", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "get_reward", "(", "self", ",", "home_obs", ",", "home_next_obs", ")", ":", "\n", "        ", "r1", "=", "0", "# home_obs.observation.score_cumulative.collection_rate_minerals  # total_value_units", "\n", "r2", "=", "home_obs", ".", "observation", ".", "player", ".", "food_workers", "# food_cap  # food_workers  # minerals                   ", "\n", "r", "=", "r2", "\n", "print", "(", "\"r\"", ",", "r", ")", "if", "debug", "else", "None", "\n", "\n", "# .minerals  # food_workers", "\n", "next_r1", "=", "0", "# home_next_obs.observation.score_cumulative.collection_rate_minerals  # total_value_units", "\n", "next_r2", "=", "home_next_obs", ".", "observation", ".", "player", ".", "food_workers", "\n", "next_r", "=", "next_r2", "\n", "print", "(", "\"next_r\"", ",", "next_r", ")", "if", "debug", "else", "None", "\n", "\n", "diff", "=", "next_r", "-", "r", "\n", "print", "(", "\"diff\"", ",", "diff", ")", "if", "debug", "else", "None", "\n", "\n", "# we use the change of minerals as reward ", "\n", "reward", "=", "float", "(", "diff", ")", "# home_next_obs.reward", "\n", "print", "(", "\"reward: \"", ",", "reward", ")", "if", "debug", "else", "None", "\n", "return", "reward", ",", "next_r", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.run": [[225, 435], ["time.time.time", "print", "time.time.strftime", "print", "print", "time.time.localtime", "time.time.time", "actor_RAS.ActorLoopRAS.create_env_one_player", "env.observation_spec", "env.action_spec", "zip", "time.time.time", "print", "traceback.format_exc", "agent.setup", "print", "time.time.strftime", "print", "env.reset", "home_obs.last", "actor_RAS.ActorLoopRAS.player.agent.initial_state", "time.time.time", "print", "time.time.localtime", "time.time.time", "a.reset", "time.time.strftime", "env.step", "home_next_obs.last", "print", "time.time.localtime", "actor_RAS.ActorLoopRAS.get_func", "pysc2.lib.actions.FunctionCall.init_with_validation", "tuple", "len", "alphastarmini.core.rl.utils.stack_namedtuple", "print", "print", "print", "actor_RAS.ActorLoopRAS.get_func", "actor_RAS.ActorLoopRAS.get_reward", "alphastarmini.core.rl.utils.Trajectory", "trajectory.append", "results.append", "actor_RAS.ActorLoopRAS.get_reward", "alphastarmini.core.rl.utils.Trajectory", "trajectory.append", "print", "actor_RAS.ActorLoopRAS.writer.add_scalar", "print", "print", "open", "f.write", "h.detach", "actor_RAS.ActorLoopRAS.player.learner.send_trajectory", "print", "print", "print", "str"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.create_env_one_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_func", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.stack_namedtuple", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_func", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_reward", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.get_reward", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.send_trajectory"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "is_running", "=", "True", "\n", "\"\"\"A run loop to have agents and an environment interact.\"\"\"", "\n", "total_frames", "=", "0", "\n", "total_episodes", "=", "0", "\n", "results", "=", "[", "]", "\n", "\n", "start_time", "=", "time", "(", ")", "\n", "print", "(", "\"start_time before training:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_for_training", ":", "\n", "                ", "agents", "=", "[", "self", ".", "player", "]", "\n", "\n", "with", "self", ".", "create_env_one_player", "(", "self", ".", "player", ")", "as", "env", ":", "\n", "\n", "# set the obs and action spec", "\n", "                    ", "observation_spec", "=", "env", ".", "observation_spec", "(", ")", "\n", "action_spec", "=", "env", ".", "action_spec", "(", ")", "\n", "\n", "for", "agent", ",", "obs_spec", ",", "act_spec", "in", "zip", "(", "agents", ",", "observation_spec", ",", "action_spec", ")", ":", "\n", "                        ", "agent", ".", "setup", "(", "obs_spec", ",", "act_spec", ")", "\n", "\n", "", "print", "(", "'player:'", ",", "self", ".", "player", ")", "if", "debug", "else", "None", "\n", "\n", "trajectory", "=", "[", "]", "\n", "start_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_time before reset:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "# one opponent match (may include several games) defaultly lasts for no more than 2 hour", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_per_one_opponent", ":", "\n", "\n", "# Note: the pysc2 environment don't return z", "\n", "\n", "# AlphaStar: home_observation, away_observation, is_final, z = env.reset()", "\n", "                        ", "total_episodes", "+=", "1", "\n", "print", "(", "\"total_episodes:\"", ",", "total_episodes", ")", "\n", "\n", "timesteps", "=", "env", ".", "reset", "(", ")", "\n", "for", "a", "in", "agents", ":", "\n", "                            ", "a", ".", "reset", "(", ")", "\n", "\n", "", "[", "home_obs", "]", "=", "timesteps", "\n", "is_final", "=", "home_obs", ".", "last", "(", ")", "\n", "\n", "player_memory", "=", "self", ".", "player", ".", "agent", ".", "initial_state", "(", ")", "\n", "\n", "episode_frames", "=", "0", "\n", "\n", "# default outcome is 0 (means draw)", "\n", "outcome", "=", "0", "\n", "\n", "# in one episode (game)", "\n", "start_episode_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_episode_time before is_final:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_episode_time", ")", ")", ")", "\n", "\n", "interval", "=", "INTERVAL", "\n", "agent_last_obs", "=", "None", "\n", "while", "not", "is_final", ":", "\n", "                            ", "total_frames", "+=", "1", "\n", "episode_frames", "+=", "1", "\n", "\n", "if", "episode_frames", "%", "interval", "==", "0", ":", "\n", "                                ", "agent_obs", "=", "home_obs", "\n", "func_result", "=", "self", ".", "get_func", "(", "env", ",", "home_obs", ",", "player_memory", ",", "action_spec", ")", "\n", "env_actions", ",", "player_action", ",", "player_logits", ",", "action_masks", ",", "player_new_memory", "=", "func_result", "\n", "", "else", ":", "\n", "                                ", "func_noop", "=", "A", ".", "FunctionCall", ".", "init_with_validation", "(", "function", "=", "0", ",", "arguments", "=", "[", "]", ",", "raw", "=", "True", ")", "\n", "env_actions", "=", "[", "func_noop", "]", "\n", "\n", "", "timesteps", "=", "env", ".", "step", "(", "env_actions", ")", "\n", "[", "home_next_obs", "]", "=", "timesteps", "\n", "\n", "game_loop", "=", "home_obs", ".", "observation", ".", "game_loop", "[", "0", "]", "\n", "is_final", "=", "home_next_obs", ".", "last", "(", ")", "\n", "\n", "if", "episode_frames", "%", "interval", "==", "0", ":", "\n", "                                ", "if", "agent_last_obs", "is", "not", "None", ":", "\n", "\n", "                                    ", "reward", ",", "next_r", "=", "self", ".", "get_reward", "(", "agent_last_obs", ",", "agent_obs", ")", "\n", "\n", "rl_reward", "=", "reward", "\n", "\n", "traj_step", "=", "Trajectory", "(", "\n", "observation", "=", "home_obs", ".", "observation", ",", "\n", "opponent_observation", "=", "home_obs", ".", "observation", ",", "\n", "memory", "=", "player_memory", ",", "\n", "z", "=", "None", ",", "\n", "masks", "=", "action_masks", ",", "\n", "action", "=", "player_action", ",", "\n", "behavior_logits", "=", "player_logits", ",", "\n", "teacher_logits", "=", "None", ",", "\n", "is_final", "=", "is_final", ",", "\n", "reward", "=", "rl_reward", ",", "\n", "build_order", "=", "[", "]", ",", "\n", "z_build_order", "=", "[", "]", ",", "# we change it to the sampled build order", "\n", "unit_counts", "=", "[", "]", ",", "\n", "z_unit_counts", "=", "[", "]", ",", "# we change it to the sampled unit counts", "\n", "game_loop", "=", "game_loop", ",", "\n", ")", "\n", "trajectory", ".", "append", "(", "traj_step", ")", "\n", "\n", "", "player_memory", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "player_new_memory", ")", "\n", "\n", "", "home_obs", "=", "home_next_obs", "\n", "\n", "if", "episode_frames", "%", "interval", "==", "0", ":", "\n", "                                ", "agent_last_obs", "=", "agent_obs", "\n", "\n", "# if is_final:", "\n", "#     final_return = next_r", "\n", "#     print(\"final_return: \", final_return) if 1 else None", "\n", "\n", "#     self.writer.add_scalar('Return', final_return, self.batch_iter)", "\n", "#     self.batch_iter += 1", "\n", "\n", "#     print(\"Return: {:.6f}.\".format(final_return)) if debug else None", "\n", "#     results.append(final_return)", "\n", "\n", "", "if", "len", "(", "trajectory", ")", ">=", "AHP", ".", "sequence_length", ":", "\n", "                                ", "trajectories", "=", "U", ".", "stack_namedtuple", "(", "trajectory", ")", "\n", "\n", "if", "self", ".", "player", ".", "learner", "is", "not", "None", ":", "\n", "                                    ", "if", "self", ".", "player", ".", "learner", ".", "is_running", ":", "\n", "                                        ", "print", "(", "\"Learner send_trajectory!\"", ")", "if", "debug", "else", "None", "\n", "self", ".", "player", ".", "learner", ".", "send_trajectory", "(", "trajectories", ")", "\n", "trajectory", "=", "[", "]", "\n", "", "else", ":", "\n", "                                        ", "print", "(", "\"Learner stops!\"", ")", "\n", "\n", "print", "(", "\"Actor also stops!\"", ")", "\n", "return", "\n", "\n", "# use max_frames to end the loop", "\n", "# whether to stop the run", "\n", "", "", "", "if", "self", ".", "max_frames", "and", "total_frames", ">=", "self", ".", "max_frames", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames, return!\"", ")", "\n", "return", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "if", "self", ".", "max_frames_per_episode", "and", "episode_frames", ">=", "self", ".", "max_frames_per_episode", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames_per_episode, break!\"", ")", "\n", "break", "\n", "\n", "", "", "if", "is_final", ":", "\n", "                            ", "print", "(", "'append the last!'", ")", "if", "1", "else", "None", "\n", "\n", "if", "agent_last_obs", "is", "not", "None", "and", "agent_obs", "is", "not", "None", ":", "\n", "                                ", "agent_obs", "=", "home_obs", "\n", "\n", "func_result", "=", "self", ".", "get_func", "(", "env", ",", "home_obs", ",", "player_memory", ",", "action_spec", ")", "\n", "env_actions", ",", "player_action", ",", "player_logits", ",", "action_masks", ",", "player_new_memory", "=", "func_result", "\n", "\n", "# units = player_logits.units.reshape(-1).detach().clone()", "\n", "# units_probs = torch.nn.functional.softmax(units)", "\n", "# print('units_probs:', units_probs)", "\n", "# self.writer.add_histogram('Probs/units_probs', units_probs, self.batch_iter, bins='fd')", "\n", "\n", "reward", ",", "r", "=", "self", ".", "get_reward", "(", "agent_last_obs", ",", "agent_obs", ")", "\n", "\n", "rl_reward", "=", "reward", "\n", "\n", "traj_step", "=", "Trajectory", "(", "\n", "observation", "=", "home_obs", ".", "observation", ",", "\n", "opponent_observation", "=", "home_obs", ".", "observation", ",", "\n", "memory", "=", "player_memory", ",", "\n", "z", "=", "None", ",", "\n", "masks", "=", "action_masks", ",", "\n", "action", "=", "player_action", ",", "\n", "behavior_logits", "=", "player_logits", ",", "\n", "teacher_logits", "=", "None", ",", "\n", "is_final", "=", "is_final", ",", "\n", "reward", "=", "rl_reward", ",", "\n", "build_order", "=", "[", "]", ",", "\n", "z_build_order", "=", "[", "]", ",", "# we change it to the sampled build order", "\n", "unit_counts", "=", "[", "]", ",", "\n", "z_unit_counts", "=", "[", "]", ",", "# we change it to the sampled unit counts", "\n", "game_loop", "=", "game_loop", ",", "\n", ")", "\n", "trajectory", ".", "append", "(", "traj_step", ")", "\n", "\n", "final_return", "=", "next_r", "\n", "print", "(", "\"final_return: \"", ",", "final_return", ")", "if", "1", "else", "None", "\n", "\n", "if", "self", ".", "record", ":", "\n", "                                    ", "self", ".", "writer", ".", "add_scalar", "(", "'Return'", ",", "final_return", ",", "self", ".", "batch_iter", ")", "\n", "self", ".", "batch_iter", "+=", "1", "\n", "\n", "", "print", "(", "\"Return: {:.6f}.\"", ".", "format", "(", "final_return", ")", ")", "if", "debug", "else", "None", "\n", "results", ".", "append", "(", "final_return", ")", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "", "if", "self", ".", "max_episodes", "and", "total_episodes", ">=", "self", ".", "max_episodes", ":", "\n", "                            ", "print", "(", "\"Beyond the max_episodes, return!\"", ")", "\n", "\n", "if", "self", ".", "record", ":", "\n", "                                ", "print", "(", "\"results: \"", ",", "results", ")", "if", "1", "else", "None", "\n", "with", "open", "(", "\"results.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                                    ", "f", ".", "write", "(", "\", \"", ".", "join", "(", "str", "(", "item", ")", "for", "item", "in", "results", ")", ")", "\n", "\n", "", "", "return", "\n", "\n", "# close the replays", "\n", "\n", "", "", "", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"ActorLoop.run() Exception cause return, Detials of the Exception:\"", ",", "e", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "self", ".", "is_running", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_RAS.ActorLoopRAS.create_env_one_player": [[437, 464], ["pysc2.env.sc2_env.AgentInterfaceFormat", "print", "print", "print", "pysc2.env.sc2_env.Bot", "pysc2.env.sc2_env.SC2Env", "alphastarmini.lib.hyper_parameters.AlphaStar_Raw_Interface_Format_Params._asdict", "pysc2.env.sc2_env.Agent"], "methods", ["None"], ["", "", "def", "create_env_one_player", "(", "self", ",", "player", ",", "game_steps_per_episode", "=", "GAME_STEPS_PER_EPISODE", ",", "\n", "step_mul", "=", "STEP_MUL", ",", "version", "=", "None", ",", "\n", "# the map should be the same as in the expert replay", "\n", "map_name", "=", "\"AbyssalReef\"", ",", "random_seed", "=", "1", ")", ":", "\n", "\n", "        ", "player_aif", "=", "AgentInterfaceFormat", "(", "**", "ARIFP", ".", "_asdict", "(", ")", ")", "\n", "agent_interface_format", "=", "[", "player_aif", "]", "\n", "\n", "# create env", "\n", "print", "(", "'map name:'", ",", "map_name", ")", "\n", "print", "(", "'player.name:'", ",", "player", ".", "name", ")", "\n", "print", "(", "'player.race:'", ",", "player", ".", "race", ")", "\n", "\n", "sc2_computer", "=", "Bot", "(", "[", "Race", ".", "terran", "]", ",", "\n", "Difficulty", ".", "very_easy", ",", "\n", "[", "BotBuild", ".", "random", "]", ")", "\n", "\n", "env", "=", "SC2Env", "(", "map_name", "=", "map_name", ",", "\n", "players", "=", "[", "Agent", "(", "player", ".", "race", ",", "player", ".", "name", ")", ",", "\n", "sc2_computer", "]", ",", "\n", "step_mul", "=", "step_mul", ",", "\n", "game_steps_per_episode", "=", "game_steps_per_episode", ",", "\n", "agent_interface_format", "=", "agent_interface_format", ",", "\n", "version", "=", "version", ",", "\n", "random_seed", "=", "random_seed", ")", "\n", "\n", "return", "env", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_run_loop.run_loop": [[15, 81], ["time.time", "env.observation_spec", "env.action_spec", "zip", "agent.setup", "print", "env.reset", "time.time", "a.reset", "timesteps[].last", "env.step", "agent.step", "zip"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step"], ["def", "run_loop", "(", "agents", ",", "env", ",", "max_frames", "=", "0", ",", "max_episodes", "=", "0", ")", ":", "\n", "    ", "\"\"\"A run loop to have agents and an environment interact.\"\"\"", "\n", "total_frames", "=", "0", "\n", "total_episodes", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# max frames for one episode", "\n", "# e.g., we don't want a game lasts for more than one hour", "\n", "# note that one second equal to 22.4 frames in real time mode", "\n", "max_frames_for_one_episode", "=", "0", "# 60 * 60 * 22.4", "\n", "\n", "# set the obs and action spec", "\n", "observation_spec", "=", "env", ".", "observation_spec", "(", ")", "\n", "action_spec", "=", "env", ".", "action_spec", "(", ")", "\n", "\n", "for", "agent", ",", "obs_spec", ",", "act_spec", "in", "zip", "(", "agents", ",", "observation_spec", ",", "action_spec", ")", ":", "\n", "        ", "agent", ".", "setup", "(", "obs_spec", ",", "act_spec", ")", "\n", "\n", "", "try", ":", "\n", "# if max_episodes=0, we run the game forever", "\n", "        ", "while", "not", "max_episodes", "or", "total_episodes", "<", "max_episodes", ":", "\n", "            ", "total_episodes", "+=", "1", "\n", "\n", "# reset the environment", "\n", "# timesteps are actually obs, each for the each agent", "\n", "timesteps", "=", "env", ".", "reset", "(", ")", "\n", "\n", "# also reset the agents", "\n", "for", "a", "in", "agents", ":", "\n", "                ", "a", ".", "reset", "(", ")", "\n", "\n", "", "game_frames", "=", "0", "\n", "while", "True", ":", "\n", "                ", "total_frames", "+=", "1", "\n", "game_frames", "+=", "1", "\n", "\n", "# for each agent and each timestep, the agent.step(timestep) function", "\n", "# actually map the timestep(obs) to action", "\n", "# due to we have two agents, each timestep maps to each action for each agent", "\n", "# the actions combined as a list to pass to the env", "\n", "# env.step(actions) will calculate the next timesteps, each for different agent", "\n", "actions", "=", "[", "agent", ".", "step", "(", "timestep", ")", "for", "agent", ",", "timestep", "in", "zip", "(", "agents", ",", "timesteps", ")", "]", "\n", "\n", "# if max_frames=0, we run the game forever", "\n", "# thus, we can use max_frames or max_episodes to control how long we want the agent run", "\n", "if", "max_frames", "and", "total_frames", ">=", "max_frames", ":", "\n", "                    ", "return", "\n", "\n", "# if the game ends, the episode ends", "\n", "", "if", "timesteps", "[", "0", "]", ".", "last", "(", ")", ":", "\n", "                    ", "break", "\n", "\n", "# if beyond the max_frames_for_one_episode, this episode ends", "\n", "", "if", "max_frames_for_one_episode", "and", "game_frames", ">=", "max_frames_for_one_episode", ":", "\n", "                    ", "break", "\n", "\n", "# else, get the next timesteps, each for different agent", "\n", "", "timesteps", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "\n", "\n", "", "finally", ":", "\n", "        ", "elapsed_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "\"Took %.3f seconds for %s steps: %.3f fps\"", "%", "(", "\n", "elapsed_time", ",", "total_frames", ",", "total_frames", "/", "elapsed_time", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_HAS.ActorLoopHAS.__init__": [[58, 89], ["actor_HAS.ActorLoopHAS.player.add_actor", "threading.Thread", "datetime.datetime.datetime.now", "tensorboardX.SummaryWriter", "actor_HAS.ActorLoopHAS.player.agent.agent_nn.to", "datetime.datetime.now.strftime"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.add_actor", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.to"], ["def", "__init__", "(", "self", ",", "player", ",", "coordinator", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ",", "\n", "max_time_per_one_opponent", "=", "60", "*", "60", "*", "2", ",", "\n", "max_frames_per_episode", "=", "22.4", "*", "60", "*", "15", ",", "max_frames", "=", "22.4", "*", "60", "*", "60", "*", "24", ",", "\n", "max_episodes", "=", "MAX_EPISODES", ",", "use_replay_expert_reward", "=", "True", ",", "\n", "replay_path", "=", "\"data/Replays/filtered_replays_1/\"", ",", "replay_version", "=", "'3.16.1'", ")", ":", "\n", "\n", "        ", "self", ".", "player", "=", "player", "\n", "self", ".", "player", ".", "add_actor", "(", "self", ")", "\n", "if", "ON_GPU", ":", "\n", "            ", "self", ".", "player", ".", "agent", ".", "agent_nn", ".", "to", "(", "DEVICE", ")", "\n", "\n", "# below code is not used because we only can create the env when we know the opponnet information (e.g., race)", "\n", "# AlphaStar: self.environment = SC2Environment()", "\n", "\n", "", "self", ".", "coordinator", "=", "coordinator", "\n", "self", ".", "max_time_for_training", "=", "max_time_for_training", "\n", "self", ".", "max_time_per_one_opponent", "=", "max_time_per_one_opponent", "\n", "self", ".", "max_frames_per_episode", "=", "max_frames_per_episode", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "max_episodes", "=", "max_episodes", "\n", "\n", "self", ".", "thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "run", ",", "args", "=", "(", ")", ")", "\n", "self", ".", "thread", ".", "daemon", "=", "True", "# Daemonize thread", "\n", "\n", "self", ".", "is_running", "=", "True", "\n", "self", ".", "is_start", "=", "False", "\n", "\n", "now", "=", "datetime", ".", "now", "(", ")", "\n", "summary_path", "=", "\"./log/\"", "+", "now", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "+", "\"_reward/\"", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "summary_path", ")", "\n", "self", ".", "batch_iter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_HAS.ActorLoopHAS.start": [[90, 93], ["actor_HAS.ActorLoopHAS.thread.start"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "is_start", "=", "True", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_HAS.ActorLoopHAS.run": [[95, 271], ["time.time.time", "print", "time.time.strftime", "print", "print", "time.time.localtime", "time.time.time", "actor_HAS.ActorLoopHAS.create_env_one_player", "env.observation_spec", "env.action_spec", "zip", "time.time.time", "print", "traceback.format_exc", "agent.setup", "print", "time.time.strftime", "print", "env.reset", "home_obs.last", "actor_HAS.ActorLoopHAS.player.agent.initial_state", "time.time.time", "print", "time.time.localtime", "time.time.time", "a.reset", "time.time.strftime", "actor_HAS.ActorLoopHAS.player.agent.step_logits_HAS", "alphastarmini.core.rl.utils.get_mask_human", "env.step", "home_next_obs.last", "alphastarmini.core.rl.utils.Trajectory", "trajectory.append", "tuple", "print", "time.time.localtime", "print", "print", "print", "print", "actor_HAS.ActorLoopHAS.writer.add_scalar", "print", "results.append", "len", "alphastarmini.core.rl.utils.stack_namedtuple", "print", "print", "print", "open", "f.write", "h.detach", "print", "print", "actor_HAS.ActorLoopHAS.player.learner.send_trajectory", "print", "print", "str"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.create_env_one_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits_HAS", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_mask_human", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.stack_namedtuple", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.send_trajectory"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "is_running", "=", "True", "\n", "\"\"\"A run loop to have agents and an environment interact.\"\"\"", "\n", "total_frames", "=", "0", "\n", "total_episodes", "=", "0", "\n", "results", "=", "[", "]", "\n", "\n", "start_time", "=", "time", "(", ")", "\n", "print", "(", "\"start_time before training:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_for_training", ":", "\n", "                ", "agents", "=", "[", "self", ".", "player", "]", "\n", "\n", "with", "self", ".", "create_env_one_player", "(", "self", ".", "player", ")", "as", "env", ":", "\n", "\n", "# set the obs and action spec", "\n", "                    ", "observation_spec", "=", "env", ".", "observation_spec", "(", ")", "\n", "action_spec", "=", "env", ".", "action_spec", "(", ")", "\n", "\n", "for", "agent", ",", "obs_spec", ",", "act_spec", "in", "zip", "(", "agents", ",", "observation_spec", ",", "action_spec", ")", ":", "\n", "                        ", "agent", ".", "setup", "(", "obs_spec", ",", "act_spec", ")", "\n", "\n", "", "print", "(", "'player:'", ",", "self", ".", "player", ")", "if", "debug", "else", "None", "\n", "\n", "trajectory", "=", "[", "]", "\n", "start_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_time before reset:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "# one opponent match (may include several games) defaultly lasts for no more than 2 hour", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_per_one_opponent", ":", "\n", "\n", "# Note: the pysc2 environment don't return z", "\n", "\n", "# AlphaStar: home_observation, away_observation, is_final, z = env.reset()", "\n", "                        ", "total_episodes", "+=", "1", "\n", "print", "(", "\"total_episodes:\"", ",", "total_episodes", ")", "\n", "\n", "timesteps", "=", "env", ".", "reset", "(", ")", "\n", "for", "a", "in", "agents", ":", "\n", "                            ", "a", ".", "reset", "(", ")", "\n", "\n", "", "[", "home_obs", "]", "=", "timesteps", "\n", "is_final", "=", "home_obs", ".", "last", "(", ")", "\n", "\n", "player_memory", "=", "self", ".", "player", ".", "agent", ".", "initial_state", "(", ")", "\n", "\n", "episode_frames", "=", "0", "\n", "\n", "# default outcome is 0 (means draw)", "\n", "outcome", "=", "0", "\n", "\n", "# in one episode (game)", "\n", "start_episode_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_episode_time before is_final:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_episode_time", ")", ")", ")", "\n", "\n", "while", "not", "is_final", ":", "\n", "                            ", "total_frames", "+=", "1", "\n", "episode_frames", "+=", "1", "\n", "\n", "# run_loop: actions = [agent.step(timestep) for agent, timestep in zip(agents, timesteps)]", "\n", "player_step", "=", "self", ".", "player", ".", "agent", ".", "step_logits_HAS", "(", "home_obs", ",", "player_memory", ")", "\n", "function_call", ",", "select_units", ",", "player_action", ",", "player_logits", ",", "player_new_memory", "=", "player_step", "\n", "print", "(", "\"function_call:\"", ",", "function_call", ")", "if", "1", "else", "None", "\n", "\n", "env_actions", "=", "[", "function_call", "]", "\n", "\n", "player_action_spec", "=", "action_spec", "[", "0", "]", "\n", "action_masks", "=", "U", ".", "get_mask_human", "(", "player_action", ",", "player_action_spec", ")", "\n", "z", "=", "None", "\n", "\n", "timesteps", "=", "env", ".", "step", "(", "env_actions", ")", "\n", "[", "home_next_obs", "]", "=", "timesteps", "\n", "\n", "# print the observation of the agent", "\n", "# print(\"home_obs.observation:\", home_obs.observation)", "\n", "\n", "game_loop", "=", "home_obs", ".", "observation", ".", "game_loop", "[", "0", "]", "\n", "print", "(", "\"game_loop\"", ",", "game_loop", ")", "if", "debug", "else", "None", "\n", "\n", "'''\n                            minerals = home_obs.observation.player.minerals\n                            next_minerals = home_next_obs.observation.player.minerals\n                            diff_minerals = next_minerals - minerals\n                            print(\"diff_minerals\", diff_minerals) if debug else None\n                            '''", "\n", "\n", "is_final", "=", "home_next_obs", ".", "last", "(", ")", "\n", "\n", "food_workers", "=", "home_obs", ".", "observation", ".", "player", ".", "food_workers", "\n", "next_food_workers", "=", "home_next_obs", ".", "observation", ".", "player", ".", "food_workers", "\n", "diff_food_workers", "=", "next_food_workers", "-", "food_workers", "\n", "print", "(", "\"diff_food_workers\"", ",", "diff_food_workers", ")", "if", "debug", "else", "None", "\n", "\n", "# we use the change of minerals as reward ", "\n", "reward", "=", "diff_food_workers", "# home_next_obs.reward", "\n", "print", "(", "\"reward: \"", ",", "reward", ")", "if", "debug", "else", "None", "\n", "\n", "# note, original AlphaStar pseudo-code has some mistakes, we modified ", "\n", "# them here", "\n", "traj_step", "=", "Trajectory", "(", "\n", "observation", "=", "home_obs", ".", "observation", ",", "\n", "opponent_observation", "=", "home_obs", ".", "observation", ",", "\n", "memory", "=", "player_memory", ",", "\n", "z", "=", "z", ",", "\n", "masks", "=", "action_masks", ",", "\n", "action", "=", "player_action", ",", "\n", "behavior_logits", "=", "player_logits", ",", "\n", "teacher_logits", "=", "None", ",", "\n", "is_final", "=", "is_final", ",", "\n", "reward", "=", "reward", ",", "\n", "build_order", "=", "[", "]", ",", "\n", "z_build_order", "=", "[", "]", ",", "# we change it to the sampled build order", "\n", "unit_counts", "=", "[", "]", ",", "\n", "z_unit_counts", "=", "[", "]", ",", "# we change it to the sampled unit counts", "\n", "game_loop", "=", "game_loop", ",", "\n", ")", "\n", "trajectory", ".", "append", "(", "traj_step", ")", "\n", "\n", "player_memory", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "player_new_memory", ")", "\n", "\n", "home_obs", "=", "home_next_obs", "\n", "\n", "if", "is_final", ":", "\n", "                                ", "final_return", "=", "home_next_obs", ".", "observation", ".", "player", ".", "food_workers", "\n", "print", "(", "\"final_return: \"", ",", "final_return", ")", "if", "1", "else", "None", "\n", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Return'", ",", "final_return", ",", "self", ".", "batch_iter", ")", "\n", "self", ".", "batch_iter", "+=", "1", "\n", "\n", "print", "(", "\"Return: {:.6f}.\"", ".", "format", "(", "final_return", ")", ")", "\n", "results", ".", "append", "(", "final_return", ")", "\n", "\n", "", "if", "len", "(", "trajectory", ")", ">=", "AHP", ".", "sequence_length", ":", "\n", "                                ", "trajectories", "=", "U", ".", "stack_namedtuple", "(", "trajectory", ")", "\n", "\n", "if", "self", ".", "player", ".", "learner", "is", "not", "None", ":", "\n", "                                    ", "if", "self", ".", "player", ".", "learner", ".", "is_running", ":", "\n", "                                        ", "print", "(", "\"Learner send_trajectory!\"", ")", "\n", "self", ".", "player", ".", "learner", ".", "send_trajectory", "(", "trajectories", ")", "\n", "trajectory", "=", "[", "]", "\n", "", "else", ":", "\n", "                                        ", "print", "(", "\"Learner stops!\"", ")", "\n", "\n", "print", "(", "\"Actor also stops!\"", ")", "\n", "return", "\n", "\n", "# use max_frames to end the loop", "\n", "# whether to stop the run", "\n", "", "", "", "if", "self", ".", "max_frames", "and", "total_frames", ">=", "self", ".", "max_frames", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames, return!\"", ")", "\n", "return", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "if", "self", ".", "max_frames_per_episode", "and", "episode_frames", ">=", "self", ".", "max_frames_per_episode", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames_per_episode, break!\"", ")", "\n", "break", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "", "if", "self", ".", "max_episodes", "and", "total_episodes", ">=", "self", ".", "max_episodes", ":", "\n", "                            ", "print", "(", "\"Beyond the max_episodes, return!\"", ")", "\n", "print", "(", "\"results: \"", ",", "results", ")", "if", "1", "else", "None", "\n", "\n", "with", "open", "(", "\"minerals.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                                ", "f", ".", "write", "(", "\", \"", ".", "join", "(", "str", "(", "item", ")", "for", "item", "in", "results", ")", ")", "\n", "\n", "", "return", "\n", "\n", "# close the replays", "\n", "\n", "", "", "", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"ActorLoop.run() Exception cause return, Detials of the Exception:\"", ",", "e", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "self", ".", "is_running", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.actor_HAS.ActorLoopHAS.create_env_one_player": [[273, 300], ["pysc2.env.sc2_env.AgentInterfaceFormat", "print", "print", "print", "pysc2.env.sc2_env.Bot", "pysc2.env.sc2_env.SC2Env", "alphastarmini.lib.hyper_parameters.AlphaStar_Human_Interface_Format_Params._asdict", "pysc2.env.sc2_env.Agent"], "methods", ["None"], ["", "", "def", "create_env_one_player", "(", "self", ",", "player", ",", "game_steps_per_episode", "=", "GAME_STEPS_PER_EPISODE", ",", "\n", "step_mul", "=", "STEP_MUL", ",", "version", "=", "None", ",", "\n", "# the map should be the same as in the expert replay", "\n", "map_name", "=", "\"AbyssalReef\"", ",", "random_seed", "=", "1", ")", ":", "\n", "\n", "        ", "player_aif", "=", "AgentInterfaceFormat", "(", "**", "AHIFP", ".", "_asdict", "(", ")", ")", "\n", "agent_interface_format", "=", "[", "player_aif", "]", "\n", "\n", "# create env", "\n", "print", "(", "'map name:'", ",", "map_name", ")", "\n", "print", "(", "'player.name:'", ",", "player", ".", "name", ")", "\n", "print", "(", "'player.race:'", ",", "player", ".", "race", ")", "\n", "\n", "sc2_computer", "=", "Bot", "(", "[", "Race", ".", "terran", "]", ",", "\n", "Difficulty", ".", "very_easy", ",", "\n", "[", "BotBuild", ".", "random", "]", ")", "\n", "\n", "env", "=", "SC2Env", "(", "map_name", "=", "map_name", ",", "\n", "players", "=", "[", "Agent", "(", "player", ".", "race", ",", "player", ".", "name", ")", ",", "\n", "sc2_computer", "]", ",", "\n", "step_mul", "=", "step_mul", ",", "\n", "game_steps_per_episode", "=", "game_steps_per_episode", ",", "\n", "agent_interface_format", "=", "agent_interface_format", ",", "\n", "version", "=", "version", ",", "\n", "random_seed", "=", "random_seed", ")", "\n", "\n", "return", "env", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_supervised_agent": [[45, 54], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "alphastarmini.lib.utils.load_latest_model"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.load_latest_model"], ["            ", "pass", "# Wrong race.", "\n", "\n", "\n", "", "", "", "def", "get_unit_tpye_index", "(", "unit_type_name", ",", "race", ")", ":", "\n", "    ", "begin_index", "=", "0", "\n", "if", "race", "==", "Neutral", ":", "\n", "        ", "begin_index", "=", "0", "\n", "", "elif", "race", "==", "Protoss", ":", "\n", "        ", "begin_index", "=", "len", "(", "Neutral", ")", "\n", "", "elif", "race", "==", "Terran", ":", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_reinforcement_agent": [[56, 75], ["alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "os.path.join", "print", "alphastarmini.lib.utils.load_latest_model", "torch.cuda.is_available", "torch.load", "torch.load", "torch.device"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.load_latest_model", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.action.ArgsActionLogits.device"], ["", "elif", "race", "==", "Zerg", ":", "\n", "        ", "begin_index", "=", "len", "(", "Neutral", ")", "+", "len", "(", "Protoss", ")", "+", "len", "(", "Terran", ")", "\n", "\n", "", "for", "i", ",", "e", "in", "enumerate", "(", "list", "(", "race", ")", ")", ":", "\n", "        ", "if", "e", "==", "unit_type_name", ":", "\n", "            ", "return", "i", "+", "begin_index", "\n", "", "", "return", "-", "1", "\n", "\n", "\n", "", "def", "unpackbits_for_largenumber", "(", "x", ",", "num_bits", ")", ":", "\n", "    ", "if", "np", ".", "issubdtype", "(", "x", ".", "dtype", ",", "np", ".", "floating", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"numpy data type needs to be int-like\"", ")", "\n", "", "xshape", "=", "list", "(", "x", ".", "shape", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "mask", "=", "2", "**", "np", ".", "arange", "(", "num_bits", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "reshape", "(", "[", "1", ",", "num_bits", "]", ")", "\n", "return", "(", "x", "&", "mask", ")", ".", "astype", "(", "bool", ")", ".", "astype", "(", "int", ")", ".", "reshape", "(", "xshape", "+", "[", "num_bits", "]", ")", "\n", "\n", "\n", "", "def", "calculate_unit_counts_bow", "(", "obs", ")", ":", "\n", "    ", "unit_counts", "=", "obs", "[", "\"unit_counts\"", "]", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.namedtuple_one_list": [[77, 90], ["Trajectory._make", "list", "print", "print", "itertools.chain", "zip", "traceback.format_exc"], "function", ["None"], ["unit_counts_bow", "=", "torch", ".", "zeros", "(", "1", ",", "SFS", ".", "unit_counts_bow", ")", "\n", "for", "u_c", "in", "unit_counts", ":", "\n", "        ", "unit_type", "=", "u_c", "[", "0", "]", "\n", "unit_count", "=", "u_c", "[", "1", "]", "\n", "assert", "unit_type", ">=", "0", "\n", "# the unit_count can not be negetive number", "\n", "assert", "unit_count", ">=", "0", "\n", "\n", "# the unit_type should not be more than the SFS.unit_counts_bow", "\n", "# if it is, make it to be 0 now. (0 means nothing now)", "\n", "# the most impact one is ShieldBattery = 1910        ", "\n", "# find a better way to do it: transform it to unit_type_index!", "\n", "unit_type_index", "=", "unit_tpye_to_unit_type_index", "(", "unit_type", ")", "\n", "if", "unit_type_index", ">=", "SFS", ".", "unit_counts_bow", ":", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.stack_namedtuple": [[92, 105], ["list", "Trajectory._make", "zip", "print", "print", "traceback.format_exc"], "function", ["None"], ["\n", "", "unit_counts_bow", "[", "0", ",", "unit_type", "]", "=", "unit_count", "\n", "", "return", "unit_counts_bow", "\n", "\n", "\n", "", "def", "calculate_build_order", "(", "previous_bo", ",", "obs", ",", "next_obs", ")", ":", "\n", "# calculate the build order", "\n", "    ", "ucb", "=", "calculate_unit_counts_bow", "(", "obs", ")", "\n", "next_ucb", "=", "calculate_unit_counts_bow", "(", "next_obs", ")", "\n", "diff", "=", "next_ucb", "-", "ucb", "\n", "\n", "# the probe, drone, and SCV are not counted in build order", "\n", "worker_type_list", "=", "[", "84", ",", "104", ",", "45", "]", "\n", "# the pylon, drone, and supplypot are not counted in build order", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.namedtuple_zip": [[107, 119], ["Trajectory._make", "list", "print", "print", "zip", "traceback.format_exc"], "function", ["None"], ["diff", "[", "0", ",", "worker_type_list", "]", "=", "0", "\n", "diff", "[", "0", ",", "supply_type_list", "]", "=", "0", "\n", "\n", "diff_count", "=", "torch", ".", "sum", "(", "diff", ")", ".", "item", "(", ")", "\n", "print", "(", "\"diff between unit_counts_bow\"", ",", "diff_count", ")", "if", "debug", "else", "None", "\n", "if", "diff_count", "==", "1.0", ":", "\n", "        ", "diff_numpy", "=", "diff", ".", "numpy", "(", ")", "\n", "index_list", "=", "np", ".", "where", "(", "diff_numpy", ">=", "1.0", ")", "\n", "print", "(", "\"index_list:\"", ",", "index_list", ")", "if", "debug", "else", "None", "\n", "index", "=", "index_list", "[", "1", "]", "[", "0", "]", "\n", "if", "index", "not", "in", "worker_type_list", "and", "index", "not", "in", "supply_type_list", ":", "\n", "            ", "previous_bo", ".", "append", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_mask_raw": [[121, 142], ["alphastarmini.lib.utils.action_type_index_map_raw", "action.action_type.item", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_raw"], ["\n", "\n", "", "def", "load_latest_model", "(", "model_type", ",", "path", ")", ":", "\n", "    ", "models", "=", "list", "(", "filter", "(", "lambda", "x", ":", "model_type", "in", "x", ",", "os", ".", "listdir", "(", "path", ")", ")", ")", "\n", "if", "len", "(", "models", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"No models are found!\"", ")", "\n", "return", "None", "\n", "\n", "", "models", ".", "sort", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "models", "[", "-", "1", "]", ")", "\n", "print", "(", "\"load model from {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "\n", "return", "model", "\n", "\n", "\n", "", "def", "load_the_model", "(", "model_path", ")", ":", "\n", "    ", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "return", "model", "\n", "\n", "\n", "", "def", "show_map_data_test", "(", "obs", ",", "map_width", "=", "128", ",", "show_original", "=", "True", ",", "show_resacel", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_mask_human": [[144, 163], ["alphastarmini.lib.utils.action_type_index_map_human", "action.action_type.item", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.lib.utils.action_type_index_map_human"], ["small_map_width", "=", "32", "\n", "\n", "resize_type", "=", "np", ".", "uint8", "\n", "save_type", "=", "np", ".", "float16", "\n", "\n", "# note, in pysc2-1.2, obs[\"feature_minimap\"][\"height_map\"] can be shown straight,", "\n", "# however, in pysc-3.0, that can not be show straight, must be transformed to numpy arrary firstly;", "\n", "height_map", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"height_map\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "height_map", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "visibility_map", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"visibility_map\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "visibility_map", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "creep", "=", "np", ".", "array", "(", "obs", "[", "\"feature_minimap\"", "]", "[", "\"creep\"", "]", ")", "\n", "if", "show_original", ":", "\n", "        ", "imgplot", "=", "plt", ".", "imshow", "(", "creep", ")", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.__init__": [[41, 73], ["learner.Learner.player.set_learner", "torch.optim.Adam", "threading.Thread", "datetime.datetime.datetime.now", "tensorboardX.SummaryWriter", "learner.Learner.get_parameters", "datetime.datetime.now.strftime"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.set_learner", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.get_parameters"], ["def", "__init__", "(", "self", ",", "player", ",", "max_time_for_training", "=", "60", "*", "3", ")", ":", "\n", "        ", "self", ".", "player", "=", "player", "\n", "self", ".", "player", ".", "set_learner", "(", "self", ")", "\n", "\n", "self", ".", "trajectories", "=", "[", "]", "\n", "\n", "# AlphaStar code", "\n", "#self.optimizer = AdamOptimizer(learning_rate=3e-5, beta1=0, beta2=0.99, epsilon=1e-5)", "\n", "\n", "# PyTorch code", "\n", "self", ".", "optimizer", "=", "Adam", "(", "self", ".", "get_parameters", "(", ")", ",", "\n", "lr", "=", "THP", ".", "learning_rate", ",", "betas", "=", "(", "THP", ".", "beta1", ",", "THP", ".", "beta2", ")", ",", "\n", "eps", "=", "THP", ".", "epsilon", ",", "weight_decay", "=", "THP", ".", "weight_decay", ")", "\n", "\n", "self", ".", "thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "run", ",", "args", "=", "(", ")", ")", "\n", "self", ".", "thread", ".", "daemon", "=", "True", "# Daemonize thread", "\n", "\n", "self", ".", "max_time_for_training", "=", "max_time_for_training", "\n", "self", ".", "is_running", "=", "False", "\n", "\n", "now", "=", "datetime", ".", "now", "(", ")", "\n", "summary_path", "=", "\"./log/\"", "+", "now", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "+", "\"/\"", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "summary_path", ")", "\n", "\n", "self", ".", "batch_iter", "=", "0", "\n", "\n", "self", ".", "use_random_shuffle", "=", "False", "\n", "\n", "if", "self", ".", "use_random_shuffle", ":", "\n", "            ", "self", ".", "replay_buffer_weight", "=", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "replay_buffer_weight", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.get_parameters": [[74, 76], ["learner.Learner.player.agent.get_parameters"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.get_parameters"], ["", "", "def", "get_parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "player", ".", "agent", ".", "get_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.send_trajectory": [[77, 79], ["learner.Learner.trajectories.append"], "methods", ["None"], ["", "def", "send_trajectory", "(", "self", ",", "trajectory", ")", ":", "\n", "        ", "self", ".", "trajectories", ".", "append", "(", "trajectory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.update_parameters": [[80, 178], ["agent.agent_nn.model.train", "learner.Learner.optimizer.zero_grad", "alphastarmini.core.rl.rl_loss.loss_function", "print", "writer.add_scalar", "loss_all.backward", "learner.Learner.optimizer.step", "torch.save", "random.shuffle", "print", "print", "loss_all.item", "print", "writer.add_scalar", "print", "writer.add_scalar", "print", "writer.add_scalar", "print", "writer.add_scalar", "print", "loss_all.item", "lambda_loss.item", "pg_loss.item", "loss_upgo.item", "loss_ent.item", "lambda_loss.item", "pg_loss.item", "loss_upgo.item", "loss_ent.item"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.transformer.Optim.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.rl_loss.loss_function", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step"], ["", "def", "update_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "use_random_shuffle", ":", "\n", "# random shuffle the list", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "trajectories", ")", "\n", "\n", "", "trajectories", "=", "self", ".", "trajectories", "[", ":", "AHP", ".", "batch_size", "]", "\n", "self", ".", "trajectories", "=", "self", ".", "trajectories", "[", "AHP", ".", "batch_size", ":", "]", "\n", "\n", "agent", "=", "self", ".", "player", ".", "agent", "\n", "\n", "print", "(", "\"begin backward\"", ")", "if", "debug", "else", "None", "\n", "\n", "# a error: cudnn RNN backward can only be called in training mode", "\n", "agent", ".", "agent_nn", ".", "model", ".", "train", "(", ")", "\n", "#torch.backends.cudnn.enabled = False", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss_all", ",", "loss_list", "=", "loss_function", "(", "agent", ",", "trajectories", ")", "\n", "print", "(", "\"loss_all:\"", ",", "loss_all", ")", "if", "1", "else", "None", "\n", "\n", "writer", "=", "self", ".", "writer", "\n", "batch_iter", "=", "self", ".", "batch_iter", "\n", "print", "(", "\"One batch loss_all: {:.6f}.\"", ".", "format", "(", "loss_all", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/loss_all'", ",", "loss_all", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "if", "True", ":", "\n", "            ", "[", "lambda_loss", ",", "pg_loss", ",", "loss_upgo", ",", "loss_ent", "]", "=", "loss_list", "\n", "\n", "print", "(", "\"One batch lambda_loss: {:.6f}.\"", ".", "format", "(", "lambda_loss", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/lambda_loss'", ",", "lambda_loss", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch pg_loss: {:.6f}.\"", ".", "format", "(", "pg_loss", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/pg_loss'", ",", "pg_loss", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch loss_upgo: {:.6f}.\"", ".", "format", "(", "loss_upgo", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/loss_upgo'", ",", "loss_upgo", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "print", "(", "\"One batch loss_ent: {:.6f}.\"", ".", "format", "(", "loss_ent", ".", "item", "(", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "'OneBatch/loss_ent'", ",", "loss_ent", ".", "item", "(", ")", ",", "batch_iter", ")", "\n", "\n", "", "loss_all", ".", "backward", "(", ")", "\n", "\n", "# print('selected_units_head.conv_1.weight.grad', agent.agent_nn.model.selected_units_head.conv_1.weight.grad) if 0 else None", "\n", "# print('selected_units_head.conv_1.weight.grad.shape', agent.agent_nn.model.selected_units_head.conv_1.weight.grad.shape) if 1 else None", "\n", "# print('selected_units_head.conv_1.weight.grad.mean', agent.agent_nn.model.selected_units_head.conv_1.weight.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.conv_1.weight.grad.std', agent.agent_nn.model.selected_units_head.conv_1.weight.grad.std()) if 1 else None", "\n", "\n", "# print('selected_units_head.fc_1.weight.grad', agent.agent_nn.model.selected_units_head.fc_1.weight.grad) if 1 else None", "\n", "# print('selected_units_head.fc_1.weight.grad.shape', agent.agent_nn.model.selected_units_head.fc_1.weight.grad.shape) if 1 else None", "\n", "# print('selected_units_head.fc_1.weight.grad.mean', agent.agent_nn.model.selected_units_head.fc_1.weight.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.fc_1.weight.grad.std', agent.agent_nn.model.selected_units_head.fc_1.weight.grad.std()) if 1 else None", "\n", "\n", "# print('selected_units_head.func_embed.weight.grad', agent.agent_nn.model.selected_units_head.func_embed.weight.grad) if 1 else None", "\n", "# print('selected_units_head.func_embed.weight.grad.shape', agent.agent_nn.model.selected_units_head.func_embed.weight.grad.shape) if 1 else None", "\n", "# print('selected_units_head.func_embed.weight.grad.mean', agent.agent_nn.model.selected_units_head.func_embed.weight.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.func_embed.weight.grad.std', agent.agent_nn.model.selected_units_head.func_embed.weight.grad.std()) if 1 else None", "\n", "\n", "# print('selected_units_head.fc_2.weight.grad', agent.agent_nn.model.selected_units_head.fc_2.weight.grad) if 0 else None", "\n", "# print('selected_units_head.fc_2.weight.grad.shape', agent.agent_nn.model.selected_units_head.fc_2.weight.grad.shape) if 1 else None", "\n", "# print('selected_units_head.fc_2.weight.grad.mean', agent.agent_nn.model.selected_units_head.fc_2.weight.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.fc_2.weight.grad.std', agent.agent_nn.model.selected_units_head.fc_2.weight.grad.std()) if 1 else None", "\n", "\n", "# print('selected_units_head.fc_3.weight.grad', agent.agent_nn.model.selected_units_head.fc_3.weight.grad) if 0 else None", "\n", "# print('selected_units_head.fc_3.weight.grad.shape', agent.agent_nn.model.selected_units_head.fc_3.weight.grad.shape) if 1 else None", "\n", "# print('selected_units_head.fc_3.weight.grad.mean', agent.agent_nn.model.selected_units_head.fc_3.weight.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.fc_3.weight.grad.std', agent.agent_nn.model.selected_units_head.fc_3.weight.grad.std()) if 1 else None", "\n", "\n", "# print('selected_units_head.small_lstm.weight_ih_l0.grad', agent.agent_nn.model.selected_units_head.small_lstm.weight_ih_l0.grad) if 1 else None", "\n", "# print('selected_units_head.small_lstm.weight_ih_l0.grad.shape', agent.agent_nn.model.selected_units_head.small_lstm.weight_ih_l0.grad.shape) if 1 else None", "\n", "# print('selected_units_head.small_lstm.weight_ih_l0.grad.mean', agent.agent_nn.model.selected_units_head.small_lstm.weight_ih_l0.grad.mean()) if 1 else None", "\n", "# print('selected_units_head.small_lstm.weight_ih_l0.grad.std', agent.agent_nn.model.selected_units_head.small_lstm.weight_ih_l0.grad.std()) if 1 else None", "\n", "\n", "# print('action_type_head.glu_1.fc_2.weight.grad', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad) if 0 else None", "\n", "# print('action_type_head.glu_1.fc_2.weight.grad.shape', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad.shape) if 1 else None", "\n", "# print('action_type_head.glu_1.fc_2.weight.grad.mean', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad.mean()) if 1 else None", "\n", "# print('action_type_head.glu_1.fc_2.weight.grad.std', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad.std()) if 1 else None", "\n", "\n", "# if self.batch_iter % 10 == 0:", "\n", "#     writer.add_histogram('units/tensor', agent.agent_nn.model.selected_units_head.fc_3.weight.grad, batch_iter)", "\n", "#     writer.add_scalar('units/mean', agent.agent_nn.model.selected_units_head.fc_3.weight.grad.mean(), batch_iter)", "\n", "#     writer.add_scalar('units/std', agent.agent_nn.model.selected_units_head.fc_3.weight.grad.std(), batch_iter)", "\n", "\n", "#     writer.add_histogram('action/tensor', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad, batch_iter)", "\n", "#     writer.add_scalar('action/mean', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad.mean(), batch_iter)", "\n", "#     writer.add_scalar('action/std', agent.agent_nn.model.action_type_head.glu_1.fc_2.weight.grad.std(), batch_iter)", "\n", "\n", "#print(\"stop\", stop)", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "print", "(", "\"end backward\"", ")", "if", "debug", "else", "None", "\n", "\n", "torch", ".", "save", "(", "agent", ".", "agent_nn", ".", "model", ",", "SAVE_PATH", "+", "\"\"", "+", "\".pkl\"", ")", "\n", "\n", "agent", ".", "steps", "+=", "AHP", ".", "batch_size", "*", "AHP", ".", "sequence_length", "# num_steps(trajectories)", "\n", "\n", "self", ".", "batch_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.start": [[181, 183], ["learner.Learner.thread.start"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.run": [[185, 227], ["time.time.time", "print", "time.time.time", "len", "print", "time.time.sleep", "print", "print", "print", "print", "len", "len", "print", "learner.Learner.update_parameters", "traceback.format_exc"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.update_parameters"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "start_time", "=", "time", "(", ")", "\n", "self", ".", "is_running", "=", "True", "\n", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_for_training", ":", "\n", "                ", "try", ":", "\n", "# if at least one actor is running, the learner would not stop", "\n", "                    ", "actor_is_running", "=", "False", "\n", "if", "len", "(", "self", ".", "player", ".", "actors", ")", "==", "0", ":", "\n", "                        ", "actor_is_running", "=", "True", "\n", "\n", "", "for", "actor", "in", "self", ".", "player", ".", "actors", ":", "\n", "                        ", "if", "actor", ".", "is_start", ":", "\n", "                            ", "actor_is_running", "=", "actor_is_running", "|", "actor", ".", "is_running", "\n", "", "else", ":", "\n", "                            ", "actor_is_running", "=", "actor_is_running", "|", "1", "\n", "\n", "", "", "if", "actor_is_running", ":", "\n", "                        ", "print", "(", "'learner trajectories size:'", ",", "len", "(", "self", ".", "trajectories", ")", ")", "\n", "\n", "if", "len", "(", "self", ".", "trajectories", ")", ">=", "self", ".", "replay_buffer_weight", "*", "AHP", ".", "batch_size", ":", "\n", "                            ", "print", "(", "\"learner begin to update parameters\"", ")", "\n", "self", ".", "update_parameters", "(", ")", "\n", "\n", "", "sleep", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"Actor stops!\"", ")", "\n", "\n", "print", "(", "\"Learner also stops!\"", ")", "\n", "return", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "\"Learner.run() Exception cause break, Detials of the Exception:\"", ",", "e", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "break", "\n", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Learner.run() Exception cause return, Detials of the Exception:\"", ",", "e", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "self", ".", "is_running", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.test": [[229, 231], ["None"], "function", ["None"], ["", "", "", "def", "test", "(", "on_server", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str": [[29, 32], ["chr", "int"], "function", ["None"], ["def", "list2str", "(", "l", ")", ":", "\n", "# note: the maximus accept number for chr() is 1114111, else raise a ValueError", "\n", "    ", "return", "''", ".", "join", "(", "[", "chr", "(", "int", "(", "i", ")", ")", "for", "i", "in", "l", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.reward_by_build_order": [[34, 50], ["pseudo_reward.list2str", "pseudo_reward.list2str", "Levenshtein.distance", "pseudo_reward.time_decay_scale", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.time_decay_scale"], ["", "def", "reward_by_build_order", "(", "bo", ",", "z_bo", ",", "gl", "=", "0", ")", ":", "\n", "    ", "str1", "=", "list2str", "(", "bo", ")", "\n", "str2", "=", "list2str", "(", "z_bo", ")", "\n", "\n", "dist", "=", "Levenshtein", ".", "distance", "(", "str1", ",", "str2", ")", "\n", "print", "(", "'dist:'", ",", "dist", ")", "if", "debug", "else", "None", "\n", "\n", "# the cost is the squared distance between the ", "\n", "# true built entity and the agent's entity", "\n", "reward", "=", "-", "dist", "*", "dist", "\n", "print", "(", "'reward:'", ",", "reward", ")", "if", "debug", "else", "None", "\n", "\n", "scale", "=", "time_decay_scale", "(", "game_loop", "=", "gl", ")", "\n", "# note, build_order seems not to use time decay scale", "\n", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.reward_by_unit_counts": [[52, 67], ["pseudo_reward.list2str", "pseudo_reward.list2str", "Levenshtein.hamming", "pseudo_reward.time_decay_scale", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.time_decay_scale"], ["", "def", "reward_by_unit_counts", "(", "ucb", ",", "z_ucb", ",", "gl", "=", "0", ")", ":", "\n", "    ", "str1", "=", "list2str", "(", "ucb", ")", "\n", "str2", "=", "list2str", "(", "z_ucb", ")", "\n", "\n", "dist", "=", "Levenshtein", ".", "hamming", "(", "str1", ",", "str2", ")", "\n", "print", "(", "'dist:'", ",", "dist", ")", "if", "debug", "else", "None", "\n", "\n", "reward", "=", "-", "dist", "\n", "print", "(", "'reward:'", ",", "reward", ")", "if", "debug", "else", "None", "\n", "\n", "scale", "=", "time_decay_scale", "(", "game_loop", "=", "gl", ")", "\n", "print", "(", "'scale:'", ",", "scale", ")", "if", "debug", "else", "None", "\n", "\n", "# hamming distance use time decay scale", "\n", "return", "reward", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.time_decay_scale": [[69, 83], ["int", "int"], "function", ["None"], ["", "def", "time_decay_scale", "(", "game_loop", ")", ":", "\n", "\n", "    ", "time_seconds", "=", "int", "(", "game_loop", "/", "22.4", ")", "\n", "time_minutes", "=", "int", "(", "time_seconds", "/", "60", ")", "\n", "\n", "scale", "=", "1.", "\n", "if", "time_minutes", ">", "24", ":", "\n", "        ", "scale", "=", "0.", "\n", "", "elif", "time_minutes", ">", "16", ":", "\n", "        ", "scale", "=", "0.25", "\n", "", "elif", "time_minutes", ">", "8", ":", "\n", "        ", "scale", "=", "0.5", "\n", "\n", "", "return", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.test": [[85, 122], ["pseudo_reward.list2str", "pseudo_reward.list2str", "print", "pseudo_reward.list2str", "pseudo_reward.list2str", "print", "print", "Levenshtein.distance", "Levenshtein.hamming"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.pseudo_reward.list2str"], ["", "def", "test", "(", ")", ":", "\n", "    ", "levenshtein", "=", "ED", ".", "levenshtein_recur", "\n", "hammingDist", "=", "ED", ".", "hammingDist", "\n", "\n", "Start", "=", "0", "\n", "Stop", "=", "SCHP", ".", "max_unit_type", "\n", "\n", "print", "(", "\"Stop is :\"", ",", "Stop", ")", "if", "debug", "else", "None", "\n", "\n", "limit", "=", "5", "\n", "\n", "l_1", "=", "[", "]", "\n", "l_2", "=", "[", "]", "\n", "\n", "# random", "\n", "#[l_1.append(random.randrange(Start, Stop)) for i in range(limit)]", "\n", "#[l_2.append(random.randrange(Start, Stop)) for i in range(limit)]", "\n", "\n", "# specfic", "\n", "l_1", "=", "[", "13", ",", "23", ",", "45", ",", "1114111", "]", "\n", "l_2", "=", "[", "13", ",", "45", ",", "1114110", "]", "\n", "\n", "s_1", "=", "list2str", "(", "l_1", ")", "\n", "s_2", "=", "list2str", "(", "l_2", ")", "\n", "\n", "print", "(", "\"edit distance between 'l_1', 'l_2'\"", ",", "Levenshtein", ".", "distance", "(", "s_1", ",", "s_2", ")", ")", "\n", "\n", "# note: hamming distance need the two lists have equal length", "\n", "l_1", "=", "[", "13", ",", "23", ",", "45", ",", "1114111", "]", "\n", "l_2", "=", "[", "13", ",", "21", ",", "45", ",", "1114110", "]", "\n", "\n", "s_1", "=", "list2str", "(", "l_1", ")", "\n", "s_2", "=", "list2str", "(", "l_2", ")", "\n", "\n", "print", "(", "\"hamming distance between 'l_1', 'l_2'\"", ",", "Levenshtein", ".", "hamming", "(", "s_1", ",", "s_2", ")", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.__init__": [[57, 83], ["against_computer.ActorLoopVersusComputer.player.add_actor", "alphastarmini.core.rl.utils.get_supervised_agent", "threading.Thread"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.player.Player.add_actor", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_supervised_agent"], ["def", "__init__", "(", "self", ",", "player", ",", "coordinator", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ",", "\n", "max_time_per_one_opponent", "=", "60", "*", "60", "*", "4", ",", "\n", "max_frames_per_episode", "=", "22.4", "*", "60", "*", "15", ",", "max_frames", "=", "22.4", "*", "60", "*", "60", "*", "24", ",", "\n", "max_episodes", "=", "MAX_EPISODES", ",", "is_training", "=", "IS_TRAINING", ")", ":", "\n", "\n", "        ", "self", ".", "player", "=", "player", "\n", "self", ".", "player", ".", "add_actor", "(", "self", ")", "\n", "\n", "# below code is not used because we only can create the env when we know the opponnet information (e.g., race)", "\n", "# AlphaStar: self.environment = SC2Environment()", "\n", "\n", "self", ".", "teacher", "=", "get_supervised_agent", "(", "player", ".", "race", ",", "model_type", "=", "\"sl\"", ")", "\n", "\n", "self", ".", "coordinator", "=", "coordinator", "\n", "self", ".", "max_time_for_training", "=", "max_time_for_training", "\n", "self", ".", "max_time_per_one_opponent", "=", "max_time_per_one_opponent", "\n", "self", ".", "max_frames_per_episode", "=", "max_frames_per_episode", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "self", ".", "max_episodes", "=", "max_episodes", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "self", ".", "thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "run", ",", "args", "=", "(", ")", ")", "\n", "\n", "self", ".", "thread", ".", "daemon", "=", "True", "# Daemonize thread", "\n", "self", ".", "is_running", "=", "True", "\n", "self", ".", "is_start", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start": [[84, 87], ["against_computer.ActorLoopVersusComputer.thread.start"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "is_start", "=", "True", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.run": [[89, 240], ["time.time.time", "print", "time.time.strftime", "print", "print", "time.time.localtime", "time.time.time", "against_computer.ActorLoopVersusComputer.create_env_one_player", "env.observation_spec", "env.action_spec", "zip", "time.time.time", "print", "traceback.format_exc", "agent.setup", "print", "print", "time.time.strftime", "print", "env.reset", "home_obs.last", "against_computer.ActorLoopVersusComputer.player.agent.initial_state", "against_computer.ActorLoopVersusComputer.teacher.initial_state", "time.time.time", "print", "time.time.localtime", "time.time.time", "a.reset", "time.time.strftime", "against_computer.ActorLoopVersusComputer.player.agent.step_logits", "alphastarmini.core.rl.utils.get_mask", "env.step", "home_next_obs.last", "alphastarmini.core.rl.utils.Trajectory", "trajectory.append", "tuple", "print", "time.time.localtime", "print", "print", "len", "alphastarmini.core.rl.utils.stack_namedtuple", "print", "print", "print", "print", "h.detach", "print", "print", "print", "against_computer.ActorLoopVersusComputer.player.learner.send_trajectory", "sum", "print"], "methods", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.create_env_one_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.BaseAgent.setup", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.initial_state", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.alphastar_agent.AlphaStarAgent.step_logits", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.stack_namedtuple", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.learner.Learner.send_trajectory"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "is_running", "=", "True", "\n", "\"\"\"A run loop to have agents and an environment interact.\"\"\"", "\n", "total_frames", "=", "0", "\n", "total_episodes", "=", "0", "\n", "\n", "results", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "\n", "start_time", "=", "time", "(", ")", "\n", "print", "(", "\"start_time before training:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "# use max_episodes to end the loop", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_for_training", ":", "\n", "                ", "agents", "=", "[", "self", ".", "player", "]", "\n", "\n", "with", "self", ".", "create_env_one_player", "(", "self", ".", "player", ")", "as", "env", ":", "\n", "\n", "# set the obs and action spec", "\n", "                    ", "observation_spec", "=", "env", ".", "observation_spec", "(", ")", "\n", "action_spec", "=", "env", ".", "action_spec", "(", ")", "\n", "\n", "for", "agent", ",", "obs_spec", ",", "act_spec", "in", "zip", "(", "agents", ",", "observation_spec", ",", "action_spec", ")", ":", "\n", "                        ", "agent", ".", "setup", "(", "obs_spec", ",", "act_spec", ")", "\n", "\n", "", "print", "(", "'player:'", ",", "self", ".", "player", ")", "if", "debug", "else", "None", "\n", "print", "(", "'opponent:'", ",", "\"Computer bot\"", ")", "if", "debug", "else", "None", "\n", "\n", "trajectory", "=", "[", "]", "\n", "start_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_time before reset:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_time", ")", ")", ")", "\n", "\n", "# one opponent match (may include several games) defaultly lasts for no more than 2 hour", "\n", "while", "time", "(", ")", "-", "start_time", "<", "self", ".", "max_time_per_one_opponent", ":", "\n", "\n", "# Note: the pysc2 environment don't return z", "\n", "# AlphaStar: home_observation, away_observation, is_final, z = env.reset()", "\n", "                        ", "total_episodes", "+=", "1", "\n", "print", "(", "\"total_episodes:\"", ",", "total_episodes", ")", "\n", "\n", "timesteps", "=", "env", ".", "reset", "(", ")", "\n", "for", "a", "in", "agents", ":", "\n", "                            ", "a", ".", "reset", "(", ")", "\n", "\n", "", "[", "home_obs", "]", "=", "timesteps", "\n", "is_final", "=", "home_obs", ".", "last", "(", ")", "\n", "\n", "player_memory", "=", "self", ".", "player", ".", "agent", ".", "initial_state", "(", ")", "\n", "teacher_memory", "=", "self", ".", "teacher", ".", "initial_state", "(", ")", "\n", "\n", "episode_frames", "=", "0", "\n", "# default outcome is 0 (means draw)", "\n", "outcome", "=", "0", "\n", "\n", "# in one episode (game)", "\n", "# ", "\n", "start_episode_time", "=", "time", "(", ")", "# in seconds.", "\n", "print", "(", "\"start_episode_time before is_final:\"", ",", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ",", "localtime", "(", "start_episode_time", ")", ")", ")", "\n", "\n", "while", "not", "is_final", ":", "\n", "                            ", "total_frames", "+=", "1", "\n", "episode_frames", "+=", "1", "\n", "\n", "# run_loop: actions = [agent.step(timestep) for agent, timestep in zip(agents, timesteps)]", "\n", "player_step", "=", "self", ".", "player", ".", "agent", ".", "step_logits", "(", "home_obs", ",", "player_memory", ")", "\n", "player_function_call", ",", "player_action", ",", "player_logits", ",", "player_new_memory", "=", "player_step", "\n", "\n", "print", "(", "\"player_function_call:\"", ",", "player_function_call", ")", "if", "0", "else", "None", "\n", "\n", "teacher_logits", "=", "player_logits", "\n", "\n", "env_actions", "=", "[", "player_function_call", "]", "\n", "\n", "player_action_spec", "=", "action_spec", "[", "0", "]", "\n", "action_masks", "=", "U", ".", "get_mask", "(", "player_action", ",", "player_action_spec", ")", "\n", "z", "=", "None", "\n", "\n", "timesteps", "=", "env", ".", "step", "(", "env_actions", ")", "\n", "[", "home_next_obs", "]", "=", "timesteps", "\n", "reward", "=", "home_next_obs", ".", "reward", "\n", "print", "(", "\"reward: \"", ",", "reward", ")", "if", "0", "else", "None", "\n", "\n", "is_final", "=", "home_next_obs", ".", "last", "(", ")", "\n", "\n", "# note, original AlphaStar pseudo-code has some mistakes, we modified ", "\n", "# them here", "\n", "traj_step", "=", "Trajectory", "(", "\n", "observation", "=", "home_obs", ".", "observation", ",", "\n", "opponent_observation", "=", "home_obs", ".", "observation", ",", "\n", "memory", "=", "player_memory", ",", "\n", "z", "=", "z", ",", "\n", "masks", "=", "action_masks", ",", "\n", "action", "=", "player_action", ",", "\n", "behavior_logits", "=", "player_logits", ",", "\n", "teacher_logits", "=", "teacher_logits", ",", "\n", "is_final", "=", "is_final", ",", "\n", "reward", "=", "reward", ",", "\n", ")", "\n", "trajectory", ".", "append", "(", "traj_step", ")", "\n", "\n", "player_memory", "=", "tuple", "(", "h", ".", "detach", "(", ")", "for", "h", "in", "player_new_memory", ")", "\n", "\n", "home_obs", "=", "home_next_obs", "\n", "\n", "if", "is_final", ":", "\n", "                                ", "outcome", "=", "reward", "\n", "print", "(", "\"outcome: \"", ",", "outcome", ")", "if", "1", "else", "None", "\n", "results", "[", "outcome", "+", "1", "]", "+=", "1", "\n", "\n", "", "if", "len", "(", "trajectory", ")", ">=", "AHP", ".", "sequence_length", ":", "\n", "                                ", "trajectories", "=", "U", ".", "stack_namedtuple", "(", "trajectory", ")", "\n", "\n", "if", "self", ".", "player", ".", "learner", "is", "not", "None", ":", "\n", "                                    ", "if", "self", ".", "player", ".", "learner", ".", "is_running", ":", "\n", "                                        ", "if", "self", ".", "is_training", ":", "\n", "                                            ", "print", "(", "\"Learner send_trajectory!\"", ")", "if", "debug", "else", "None", "\n", "\n", "self", ".", "player", ".", "learner", ".", "send_trajectory", "(", "trajectories", ")", "\n", "trajectory", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                                        ", "print", "(", "\"Learner stops!\"", ")", "\n", "\n", "print", "(", "\"Actor also stops!\"", ")", "\n", "return", "\n", "\n", "# use max_frames to end the loop", "\n", "# whether to stop the run", "\n", "", "", "", "if", "self", ".", "max_frames", "and", "total_frames", ">=", "self", ".", "max_frames", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames, return!\"", ")", "\n", "return", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "if", "self", ".", "max_frames_per_episode", "and", "episode_frames", ">=", "self", ".", "max_frames_per_episode", ":", "\n", "                                ", "print", "(", "\"Beyond the max_frames_per_episode, break!\"", ")", "\n", "break", "\n", "\n", "#self.coordinator.send_outcome(self.player, self.opponent, outcome)", "\n", "\n", "# use max_frames_per_episode to end the episode", "\n", "", "", "if", "self", ".", "max_episodes", "and", "total_episodes", ">=", "self", ".", "max_episodes", ":", "\n", "                            ", "print", "(", "\"Beyond the max_episodes, return!\"", ")", "\n", "print", "(", "\"results: \"", ",", "results", ")", "if", "1", "else", "None", "\n", "print", "(", "\"win rate: \"", ",", "results", "[", "2", "]", "/", "(", "1e-8", "+", "sum", "(", "results", ")", ")", ")", "if", "1", "else", "None", "\n", "return", "\n", "\n", "", "", "", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"ActorLoop.run() Exception cause return, Detials of the Exception:\"", ",", "e", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "self", ".", "is_running", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.create_env_one_player": [[242, 268], ["pysc2.env.sc2_env.AgentInterfaceFormat", "print", "print", "print", "pysc2.env.sc2_env.Bot", "pysc2.env.sc2_env.SC2Env", "alphastarmini.lib.hyper_parameters.AlphaStar_Raw_Interface_Format_Params._asdict", "pysc2.env.sc2_env.Agent"], "methods", ["None"], ["", "", "def", "create_env_one_player", "(", "self", ",", "player", ",", "game_steps_per_episode", "=", "GAME_STEPS_PER_EPISODE", ",", "\n", "step_mul", "=", "STEP_MUL", ",", "version", "=", "None", ",", "\n", "map_name", "=", "\"Simple64\"", ",", "random_seed", "=", "1", ")", ":", "\n", "\n", "        ", "player_aif", "=", "AgentInterfaceFormat", "(", "**", "ARIFP", ".", "_asdict", "(", ")", ")", "\n", "agent_interface_format", "=", "[", "player_aif", "]", "\n", "\n", "# create env", "\n", "print", "(", "'map name:'", ",", "map_name", ")", "\n", "print", "(", "'player.name:'", ",", "player", ".", "name", ")", "\n", "print", "(", "'player.race:'", ",", "player", ".", "race", ")", "\n", "\n", "sc2_computer", "=", "Bot", "(", "[", "Race", ".", "terran", "]", ",", "\n", "Difficulty", ".", "very_hard", ",", "\n", "[", "BotBuild", ".", "random", "]", ")", "\n", "\n", "env", "=", "SC2Env", "(", "map_name", "=", "map_name", ",", "\n", "players", "=", "[", "Agent", "(", "player", ".", "race", ",", "player", ".", "name", ")", ",", "\n", "sc2_computer", "]", ",", "\n", "step_mul", "=", "step_mul", ",", "\n", "game_steps_per_episode", "=", "game_steps_per_episode", ",", "\n", "agent_interface_format", "=", "agent_interface_format", ",", "\n", "version", "=", "version", ",", "\n", "random_seed", "=", "random_seed", ")", "\n", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.test": [[270, 308], ["alphastarmini.core.ma.league.League", "alphastarmini.core.ma.coordinator.Coordinator", "range", "alphastarmini.core.ma.league.League.get_learning_players_num", "alphastarmini.core.ma.league.League.get_learning_player", "alphastarmini.core.rl.learner.Learner", "learners.append", "actors.extend", "l.start", "threads.append", "time.sleep", "a.start", "threads.append", "time.sleep", "t.join", "print", "alphastarmini.core.rl.utils.get_supervised_agent", "against_computer.ActorLoopVersusComputer", "range"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_players_num", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.ma.league.League.get_learning_player", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start", "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.utils.get_supervised_agent"], ["", "", "def", "test", "(", "on_server", "=", "False", ")", ":", "\n", "    ", "league", "=", "League", "(", "\n", "initial_agents", "=", "{", "\n", "race", ":", "get_supervised_agent", "(", "race", ",", "model_type", "=", "\"rl\"", ")", "\n", "for", "race", "in", "[", "Race", ".", "protoss", "]", "\n", "}", ",", "\n", "main_players", "=", "MAIN_PLAYER_NUMS", ",", "\n", "main_exploiters", "=", "0", ",", "\n", "league_exploiters", "=", "0", ")", "\n", "\n", "coordinator", "=", "Coordinator", "(", "league", ")", "\n", "learners", "=", "[", "]", "\n", "actors", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "league", ".", "get_learning_players_num", "(", ")", ")", ":", "\n", "        ", "player", "=", "league", ".", "get_learning_player", "(", "idx", ")", "\n", "learner", "=", "Learner", "(", "player", ",", "max_time_for_training", "=", "60", "*", "60", "*", "24", ")", "\n", "learners", ".", "append", "(", "learner", ")", "\n", "actors", ".", "extend", "(", "[", "ActorLoopVersusComputer", "(", "player", ",", "coordinator", ")", "for", "_", "in", "range", "(", "ACTOR_NUMS", ")", "]", ")", "\n", "\n", "", "threads", "=", "[", "]", "\n", "\n", "for", "l", "in", "learners", ":", "\n", "        ", "l", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "l", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "\n", "", "for", "a", "in", "actors", ":", "\n", "        ", "a", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "a", ".", "thread", ")", "\n", "sleep", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "# Wait for training to finish.", "\n", "        ", "for", "t", "in", "threads", ":", "\n", "            ", "t", ".", "join", "(", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Exception Handled in Main, Detials of the Exception:\"", ",", "e", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.__init__": [[38, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "settings", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.step": [[41, 43], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "home_action", ",", "away_action", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.SC2Environment.reset": [[44, 46], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.get_env_outcome": [[50, 59], ["pysc2.env.sc2_env.possible_results.get"], "function", ["None"], ["", "", "def", "get_env_outcome", "(", "timestep", ")", ":", "\n", "    ", "outcome", "=", "0", "\n", "o", "=", "timestep", ".", "raw_observation", "\n", "player_id", "=", "o", ".", "observation", ".", "player_common", ".", "player_id", "\n", "for", "r", "in", "o", ".", "player_result", ":", "\n", "        ", "if", "r", ".", "player_id", "==", "player_id", ":", "\n", "            ", "outcome", "=", "sc2_env", ".", "possible_results", ".", "get", "(", "r", ".", "result", ",", "default", "=", "0", ")", "\n", "", "", "frames", "=", "o", ".", "observation", ".", "game_loop", "\n", "return", "outcome", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.test_multi_player_env": [[61, 83], ["pysc2.env.sc2_env.SC2Env", "alphastarmini.core.rl.env_run_loop.run_loop", "alphastarmini.core.rl.alphastar_agent.AlphaStarAgent", "pysc2.env.sc2_env.Agent", "pysc2.env.sc2_env.Agent"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_run_loop.run_loop"], ["", "def", "test_multi_player_env", "(", "agent_interface_format", ")", ":", "\n", "    ", "steps", "=", "10000", "\n", "step_mul", "=", "1", "\n", "players", "=", "2", "\n", "agent_names", "=", "[", "\"Protoss\"", ",", "\"Terran\"", "]", "\n", "\n", "# create env", "\n", "with", "sc2_env", ".", "SC2Env", "(", "\n", "map_name", "=", "\"Simple64\"", ",", "\n", "players", "=", "[", "sc2_env", ".", "Agent", "(", "sc2_env", ".", "Race", ".", "protoss", ",", "agent_names", "[", "0", "]", ")", ",", "\n", "sc2_env", ".", "Agent", "(", "sc2_env", ".", "Race", ".", "terran", ",", "agent_names", "[", "1", "]", ")", "]", ",", "\n", "step_mul", "=", "step_mul", ",", "\n", "game_steps_per_episode", "=", "steps", "*", "step_mul", "//", "2", ",", "\n", "agent_interface_format", "=", "agent_interface_format", ",", "\n", "version", "=", "None", ",", "\n", "random_seed", "=", "1", ")", "as", "env", ":", "\n", "# begin env", "\n", "\n", "#agents = [RandomAgent(x) for x in agent_names]", "\n", "        ", "agents", "=", "[", "AlphaStarAgent", "(", "x", ")", "for", "x", "in", "agent_names", "]", "\n", "\n", "run_loop", "(", "agents", ",", "env", ",", "steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.random_agent_test": [[85, 93], ["pysc2.env.sc2_env.AgentInterfaceFormat", "pysc2.env.sc2_env.AgentInterfaceFormat", "env_utils.test_multi_player_env", "alphastarmini.lib.hyper_parameters.AlphaStar_Raw_Interface_Format_Params._asdict", "alphastarmini.lib.hyper_parameters.AlphaStar_Raw_Interface_Format_Params._asdict"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.test_multi_player_env"], ["", "", "def", "random_agent_test", "(", ")", ":", "\n", "\n", "    ", "aif_1", "=", "sc2_env", ".", "AgentInterfaceFormat", "(", "**", "ARIFP", ".", "_asdict", "(", ")", ")", "\n", "aif_2", "=", "sc2_env", ".", "AgentInterfaceFormat", "(", "**", "ARIFP", ".", "_asdict", "(", ")", ")", "\n", "\n", "aif", "=", "[", "aif_1", ",", "aif_2", "]", "\n", "\n", "test_multi_player_env", "(", "aif", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.run_thread_test": [[96, 111], ["pysc2.run_configs.get", "s2clientprotocol.sc2api_pb2.InterfaceOptions", "pysc2.lib.point.Point", "pysc2.lib.point.Point", "point.Point.assign_to", "point.Point.assign_to", "run_configs.get.start", "s2clientprotocol.sc2api_pb2.SpatialCameraSetup"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.against_computer.ActorLoopVersusComputer.start"], ["", "def", "run_thread_test", "(", ")", ":", "\n", "    ", "run_config", "=", "run_configs", ".", "get", "(", "version", "=", "\"3.16.1\"", ")", "\n", "\n", "camera_width", "=", "24", "\n", "interface", "=", "sc_pb", ".", "InterfaceOptions", "(", "\n", "raw", "=", "True", ",", "score", "=", "True", ",", "\n", "feature_layer", "=", "sc_pb", ".", "SpatialCameraSetup", "(", "width", "=", "camera_width", ")", ")", "\n", "\n", "screen_resolution", "=", "point", ".", "Point", "(", "32", ",", "32", ")", "\n", "minimap_resolution", "=", "point", ".", "Point", "(", "32", ",", "32", ")", "\n", "screen_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "resolution", ")", "\n", "minimap_resolution", ".", "assign_to", "(", "interface", ".", "feature_layer", ".", "minimap_resolution", ")", "\n", "\n", "with", "run_config", ".", "start", "(", "full_screen", "=", "False", ")", "as", "controller", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.test": [[113, 115], ["env_utils.random_agent_test"], "function", ["home.repos.pwc.inspect_result.liuruoze_Raw-vs-Human-in-AlphaStar.rl.env_utils.random_agent_test"], ["", "", "def", "test", "(", "on_server", "=", "False", ")", ":", "\n", "    ", "random_agent_test", "(", ")", "\n", "", ""]]}