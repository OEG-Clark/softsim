{"home.repos.pwc.inspect_result.hendrycks_ethics.None.probe.load_model": [[6, 16], ["transformers.AutoConfig.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "torch.nn.DataParallel.load_state_dict", "torch.load", "torch.nn.DataParallel.cuda", "torch.nn.DataParallel", "range"], "function", ["None"], ["def", "load_model", "(", "model", ",", "ngpus", ",", "load_path", ")", ":", "\n", "    ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model", ",", "num_labels", "=", "1", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model", ",", "config", "=", "config", ")", "\n", "\n", "# Use strict=False since the provided models were originally trained with an earlier version of Huggingface", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "load_path", ")", ",", "strict", "=", "False", ")", "\n", "if", "args", ".", "ngpus", ">", "0", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "i", "for", "i", "in", "range", "(", "ngpus", ")", "]", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.probe.get_ids_mask": [[17, 29], ["numpy.array", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "amasks.append", "numpy.pad", "float", "len"], "function", ["None"], ["", "def", "get_ids_mask", "(", "sentences", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "tokenized", "=", "[", "tokenizer", ".", "tokenize", "(", "s", ")", "for", "s", "in", "sentences", "]", "\n", "tokenized", "=", "[", "t", "[", ":", "(", "max_length", "-", "1", ")", "]", "+", "[", "'SEP'", "]", "for", "t", "in", "tokenized", "]", "\n", "\n", "ids", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "t", ")", "for", "t", "in", "tokenized", "]", "\n", "ids", "=", "np", ".", "array", "(", "[", "np", ".", "pad", "(", "i", ",", "(", "0", ",", "max_length", "-", "len", "(", "i", ")", ")", ",", "\n", "mode", "=", "'constant'", ")", "for", "i", "in", "ids", "]", ")", "\n", "amasks", "=", "[", "]", "\n", "for", "seq", "in", "ids", ":", "\n", "        ", "seq_mask", "=", "[", "float", "(", "i", ">", "0", ")", "for", "i", "in", "seq", "]", "\n", "amasks", ".", "append", "(", "seq_mask", ")", "\n", "", "return", "ids", ",", "amasks", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.probe.load_process_sentences": [[30, 37], ["transformers.AutoTokenizer.from_pretrained", "probe.get_ids_mask", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.get_ids_mask"], ["", "def", "load_process_sentences", "(", "model", ",", "sentences", ",", "max_length", "=", "512", ")", ":", "\n", "    ", "sentences", "=", "[", "\"[CLS] \"", "+", "s", "for", "s", "in", "sentences", "]", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model", ")", "\n", "ids", ",", "amasks", "=", "get_ids_mask", "(", "sentences", ",", "tokenizer", ",", "max_length", ")", "\n", "inputs", "=", "torch", ".", "tensor", "(", "ids", ")", "\n", "masks", "=", "torch", ".", "tensor", "(", "amasks", ")", "\n", "return", "inputs", ",", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.probe.main": [[38, 53], ["probe.load_model", "load_model.eval", "input", "probe.load_process_sentences", "torch.no_grad", "print", "print", "load_model.", "torch.sigmoid().squeeze().detach().cpu().numpy", "output.item", "torch.sigmoid().squeeze().detach().cpu", "torch.sigmoid().squeeze().detach", "torch.sigmoid().squeeze", "torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.probe.load_process_sentences"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "load_path", "=", "\"{}_{}.pt\"", ".", "format", "(", "args", ".", "data", ",", "args", ".", "model", ")", "\n", "model", "=", "load_model", "(", "args", ".", "model", ",", "args", ".", "ngpus", ",", "load_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "sentence", "=", "input", "(", "\"Input: \"", ")", "\n", "input_ids", ",", "input_mask", "=", "load_process_sentences", "(", "args", ".", "model", ",", "[", "sentence", "]", ",", "args", ".", "max_length", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "input_ids", ",", "attention_mask", "=", "input_mask", ")", "[", "0", "]", "\n", "", "if", "args", ".", "data", "==", "\"cm\"", ":", "# commonsense morality", "\n", "            ", "prob", "=", "torch", ".", "sigmoid", "(", "output", ")", ".", "squeeze", "(", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "print", "(", "\"Is 'clearly wrong according to ordinary morality in usual circumstances' confidence: {:.3f}\"", ".", "format", "(", "prob", ")", ")", "\n", "", "else", ":", "# utilitarianism", "\n", "            ", "print", "(", "\"Utility Value: {:.3f}\"", ".", "format", "(", "output", ".", "item", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.get_tokenizer": [[9, 12], ["transformers.AutoTokenizer.from_pretrained"], "function", ["None"], ["def", "get_tokenizer", "(", "model", ")", ":", "\n", "    ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.get_ids_mask": [[13, 26], ["numpy.array", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "amasks.append", "numpy.pad", "float", "len"], "function", ["None"], ["", "def", "get_ids_mask", "(", "sentences", ",", "tokenizer", ",", "max_length", ")", ":", "\n", "    ", "tokenized", "=", "[", "tokenizer", ".", "tokenize", "(", "s", ")", "for", "s", "in", "sentences", "]", "\n", "tokenized", "=", "[", "t", "[", ":", "(", "max_length", "-", "1", ")", "]", "+", "[", "'SEP'", "]", "for", "t", "in", "tokenized", "]", "\n", "\n", "ids", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "t", ")", "for", "t", "in", "tokenized", "]", "\n", "ids", "=", "np", ".", "array", "(", "[", "np", ".", "pad", "(", "i", ",", "(", "0", ",", "max_length", "-", "len", "(", "i", ")", ")", ",", "\n", "mode", "=", "'constant'", ")", "for", "i", "in", "ids", "]", ")", "\n", "\n", "amasks", "=", "[", "]", "\n", "for", "seq", "in", "ids", ":", "\n", "        ", "seq_mask", "=", "[", "float", "(", "i", ">", "0", ")", "for", "i", "in", "seq", "]", "\n", "amasks", ".", "append", "(", "seq_mask", ")", "\n", "", "return", "ids", ",", "amasks", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model": [[27, 52], ["transformers.AutoModelForSequenceClassification.from_pretrained", "torch.nn.DataParallel.cuda", "torch.nn.DataParallel", "print", "transformers.AdamW", "transformers.AutoConfig.from_pretrained", "transformers.AutoConfig.from_pretrained", "torch.nn.DataParallel.load_state_dict", "torch.load", "range", "torch.nn.DataParallel.named_parameters", "torch.nn.DataParallel.named_parameters", "any", "any"], "function", ["None"], ["", "def", "load_model", "(", "args", ",", "load_path", "=", "None", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "if", "cache_dir", "is", "not", "None", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "model", ",", "num_labels", "=", "1", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "model", ",", "num_labels", "=", "1", ")", "\n", "", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "model", ",", "config", "=", "config", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "load_path", ")", ")", "\n", "\n", "", "model", ".", "cuda", "(", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "i", "for", "i", "in", "range", "(", "args", ".", "ngpus", ")", "]", ")", "\n", "\n", "print", "(", "'\\nPretrained model \"{}\" loaded'", ".", "format", "(", "args", ".", "model", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "1e-8", ")", "\n", "\n", "return", "model", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.split_data": [[53, 65], ["numpy.arange", "numpy.ones().astype", "numpy.zeros().astype", "torch.utils.data.Subset", "torch.utils.data.Subset", "len", "numpy.ones", "numpy.zeros", "len", "len", "len", "len"], "function", ["None"], ["", "def", "split_data", "(", "split", ",", "data", ",", "nsplits", "=", "5", ")", ":", "\n", "    ", "all_idxs", "=", "np", ".", "arange", "(", "len", "(", "data", ")", ")", "\n", "train_mask", "=", "np", ".", "ones", "(", "len", "(", "data", ")", ")", ".", "astype", "(", "bool", ")", "\n", "test_mask", "=", "np", ".", "zeros", "(", "len", "(", "data", ")", ")", ".", "astype", "(", "bool", ")", "\n", "start", ",", "end", "=", "(", "len", "(", "data", ")", "//", "nsplits", ")", "*", "split", ",", "(", "len", "(", "data", ")", "//", "nsplits", ")", "*", "(", "split", "+", "1", ")", "\n", "train_mask", "[", "start", ":", "end", "]", "=", "False", "\n", "test_mask", "[", "start", ":", "end", "]", "=", "True", "\n", "train_idxs", "=", "all_idxs", "[", "train_mask", "]", "\n", "test_idxs", "=", "all_idxs", "[", "test_mask", "]", "\n", "train_data", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "data", ",", "train_idxs", ")", "\n", "test_data", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "data", ",", "test_idxs", ")", "\n", "return", "train_data", ",", "test_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_cm_sentences": [[66, 82], ["os.path.join", "pandas.read_csv", "os.path.join", "pandas.read_csv", "range", "range", "range", "range", "split.split"], "function", ["None"], ["", "def", "load_cm_sentences", "(", "data_dir", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "if", "\"long\"", "in", "split", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"cm_{}.csv\"", ".", "format", "(", "split", ".", "split", "(", "\"long_\"", ")", "[", "1", "]", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "df", "=", "df", "[", "df", "[", "\"is_short\"", "]", "==", "False", "]", "\n", "", "else", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"cm_{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "\n", "", "if", "split", "==", "\"ambig\"", ":", "\n", "        ", "labels", "=", "[", "-", "1", "for", "_", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "sentences", "=", "[", "df", ".", "iloc", "[", "i", ",", "0", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "        ", "labels", "=", "[", "df", ".", "iloc", "[", "i", ",", "0", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "sentences", "=", "[", "df", ".", "iloc", "[", "i", ",", "1", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_justice_sentences": [[83, 89], ["os.path.join", "pandas.read_csv", "range", "range"], "function", ["None"], ["", "def", "load_justice_sentences", "(", "data_dir", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"justice_{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "labels", "=", "[", "df", ".", "iloc", "[", "i", ",", "0", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "sentences", "=", "[", "df", ".", "iloc", "[", "i", ",", "1", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_virtue_sentences": [[90, 96], ["os.path.join", "pandas.read_csv", "range", "range"], "function", ["None"], ["", "def", "load_virtue_sentences", "(", "data_dir", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"virtue_{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "labels", "=", "[", "df", ".", "iloc", "[", "i", ",", "0", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "sentences", "=", "[", "df", ".", "iloc", "[", "i", ",", "1", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_deontology_sentences": [[97, 105], ["os.path.join", "pandas.read_csv", "range", "range", "range", "zip"], "function", ["None"], ["", "def", "load_deontology_sentences", "(", "data_dir", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"deontology_{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "labels", "=", "[", "df", ".", "iloc", "[", "i", ",", "0", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "scenarios", "=", "[", "df", ".", "iloc", "[", "i", ",", "1", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "excuses", "=", "[", "df", ".", "iloc", "[", "i", ",", "2", "]", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", "]", "\n", "sentences", "=", "[", "sc", "+", "\" [SEP] \"", "+", "exc", "for", "(", "sc", ",", "exc", ")", "in", "zip", "(", "scenarios", ",", "excuses", ")", "]", "\n", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_util_sentences": [[106, 115], ["os.path.join", "pandas.read_csv", "range", "sentences.append", "sentences.append", "range", "len"], "function", ["None"], ["", "def", "load_util_sentences", "(", "data_dir", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"util_{}.csv\"", ".", "format", "(", "split", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "path", ",", "header", "=", "None", ")", "\n", "sentences", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "df", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "sentences", ".", "append", "(", "df", ".", "iloc", "[", "i", ",", "0", "]", ")", "\n", "sentences", ".", "append", "(", "df", ".", "iloc", "[", "i", ",", "1", "]", ")", "\n", "", "labels", "=", "[", "-", "1", "for", "_", "in", "range", "(", "len", "(", "sentences", ")", ")", "]", "\n", "return", "sentences", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data": [[116, 140], ["load_fn", "utils.get_tokenizer", "utils.get_ids_mask", "torch.utils.data.TensorDataset", "numpy.mean", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "range", "len", "numpy.mean", "range", "range"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.get_tokenizer", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.get_ids_mask"], ["", "def", "load_process_data", "(", "args", ",", "data_dir", ",", "dataset", ",", "split", "=", "\"train\"", ")", ":", "\n", "    ", "load_fn", "=", "{", "\"cm\"", ":", "load_cm_sentences", ",", "\"deontology\"", ":", "load_deontology_sentences", ",", "\"justice\"", ":", "load_justice_sentences", ",", "\n", "\"virtue\"", ":", "load_virtue_sentences", ",", "\"util\"", ":", "load_util_sentences", "}", "[", "dataset", "]", "\n", "sentences", ",", "labels", "=", "load_fn", "(", "data_dir", ",", "split", "=", "split", ")", "\n", "sentences", "=", "[", "\"[CLS] \"", "+", "s", "for", "s", "in", "sentences", "]", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "model", ")", "\n", "ids", ",", "amasks", "=", "get_ids_mask", "(", "sentences", ",", "tokenizer", ",", "args", ".", "max_length", ")", "\n", "within_bounds", "=", "[", "ids", "[", "i", ",", "-", "1", "]", "==", "0", "for", "i", "in", "range", "(", "len", "(", "ids", ")", ")", "]", "\n", "if", "np", ".", "mean", "(", "within_bounds", ")", "<", "1", ":", "\n", "        ", "print", "(", "\"{} fraction of examples within context window ({} tokens): {:.3f}\"", ".", "format", "(", "split", ",", "args", ".", "max_length", ",", "np", ".", "mean", "(", "within_bounds", ")", ")", ")", "\n", "", "inputs", ",", "labels", ",", "masks", "=", "torch", ".", "tensor", "(", "ids", ")", ",", "torch", ".", "tensor", "(", "labels", ")", ",", "torch", ".", "tensor", "(", "amasks", ")", "\n", "\n", "if", "\"util\"", "in", "dataset", ":", "\n", "        ", "even_mask", "=", "[", "i", "for", "i", "in", "range", "(", "inputs", ".", "shape", "[", "0", "]", ")", "if", "i", "%", "2", "==", "0", "]", "\n", "odd_mask", "=", "[", "i", "for", "i", "in", "range", "(", "inputs", ".", "shape", "[", "0", "]", ")", "if", "i", "%", "2", "==", "1", "]", "\n", "even_inputs", ",", "odd_inputs", "=", "inputs", "[", "even_mask", "]", ",", "inputs", "[", "odd_mask", "]", "\n", "even_labels", ",", "odd_labels", "=", "labels", "[", "even_mask", "]", ",", "labels", "[", "odd_mask", "]", "\n", "even_masks", ",", "odd_masks", "=", "masks", "[", "even_mask", "]", ",", "masks", "[", "odd_mask", "]", "\n", "inputs", "=", "torch", ".", "stack", "(", "[", "even_inputs", ",", "odd_inputs", "]", ",", "axis", "=", "1", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "even_labels", ",", "odd_labels", "]", ",", "axis", "=", "1", ")", "\n", "masks", "=", "torch", ".", "stack", "(", "[", "even_masks", ",", "odd_masks", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "data", "=", "TensorDataset", "(", "inputs", ",", "masks", ",", "labels", ")", "\n", "return", "data", "\n", "", ""]], "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.main": [[11, 69], ["os.path.abspath", "range", "open", "f.write", "load_model", "load_process_data", "load_process_data", "load_process_data", "load_process_data", "load_process_data", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "test_hard_accs.append", "test_accs.append", "tune.get_probs", "tune.get_probs", "numpy.maximum", "numpy.maximum", "numpy.zeros", "numpy.ones", "sklearn.metrics.roc_auc_score", "print", "aucs.append", "numpy.max", "numpy.max", "numpy.max", "len", "len", "len", "print", "tune.train", "print", "tune.evaluate", "print", "tune.evaluate", "numpy.concatenate", "numpy.concatenate", "print", "torch.save", "open", "f.write", "model.module.state_dict"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.get_probs", "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.get_probs", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "test_hard_accs", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "aucs", "=", "[", "]", "\n", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", "\n", "for", "run", "in", "range", "(", "args", ".", "nruns", ")", ":", "\n", "        ", "model", ",", "optimizer", "=", "load_model", "(", "args", ")", "\n", "\n", "# data for ambiguous detection auroc", "\n", "long_test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"long_test\"", ")", "\n", "ambig_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"ambig\"", ")", "\n", "\n", "# data for normal training + etestuation", "\n", "train_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"train\"", ")", "\n", "test_hard_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test_hard\"", ")", "\n", "test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test\"", ")", "\n", "print", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_hard_data", ")", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "test_hard_dataloader", "=", "DataLoader", "(", "test_hard_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "ambig_dataloader", "=", "DataLoader", "(", "ambig_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "long_test_dataloader", "=", "DataLoader", "(", "long_test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "nepochs", "+", "1", ")", ":", "\n", "            ", "print", "(", ")", "\n", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ")", "\n", "print", "(", "'\\ntest hard set:'", ")", "\n", "test_hard_acc", "=", "evaluate", "(", "model", ",", "test_hard_dataloader", ")", "\n", "print", "(", "'\\ntest set:'", ")", "\n", "test_acc", "=", "evaluate", "(", "model", ",", "test_dataloader", ")", "\n", "\n", "", "test_hard_accs", ".", "append", "(", "test_hard_acc", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "probs", "=", "get_probs", "(", "model", ",", "ambig_dataloader", ")", "\n", "test_probs", "=", "get_probs", "(", "model", ",", "long_test_dataloader", ")", "\n", "\n", "# now see how well we can distinguish between these ", "\n", "max_probs", "=", "np", ".", "maximum", "(", "probs", ",", "1", "-", "probs", ")", "\n", "max_test_probs", "=", "np", ".", "maximum", "(", "test_probs", ",", "1", "-", "test_probs", ")", "\n", "y", "=", "np", ".", "zeros", "(", "probs", ".", "shape", "[", "0", "]", ")", "\n", "test_y", "=", "np", ".", "ones", "(", "test_probs", ".", "shape", "[", "0", "]", ")", "\n", "all_y", ",", "all_probs", "=", "np", ".", "concatenate", "(", "[", "y", ",", "test_y", "]", ")", ",", "np", ".", "concatenate", "(", "[", "max_probs", ",", "max_test_probs", "]", ")", "\n", "auc", "=", "roc_auc_score", "(", "all_y", ",", "all_probs", ")", "\n", "print", "(", "\"AUC: {:.3f}\"", ".", "format", "(", "auc", ")", ")", "\n", "aucs", ".", "append", "(", "auc", ")", "\n", "\n", "if", "args", ".", "save", ":", "\n", "            ", "save_path", "=", "\"cm_{}_{}_{}_{}.pkl\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "learning_rate", ",", "args", ".", "batch_size", ",", "args", ".", "nepochs", ")", "\n", "print", "(", "\"SAVING to\"", ",", "save_path", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Run {} test hard acc: {:.3f} test acc: {:.3f} auc: {:.3f}\\n\"", ".", "format", "(", "run", ",", "test_hard_acc", ",", "test_acc", ",", "auc", ")", ")", "\n", "\n", "", "", "return", "np", ".", "max", "(", "test_hard_accs", ")", ",", "np", ".", "max", "(", "test_accs", ")", ",", "np", ".", "max", "(", "aucs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.train": [[70, 104], ["model.train", "torch.nn.BCEWithLogitsLoss", "enumerate", "tuple", "optimizer.zero_grad", "[].squeeze", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "optimizer.step", "b_labels.float", "print", "t.cuda", "model", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train"], ["", "def", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ",", "log_interval", "=", "10", ")", ":", "\n", "# Set model to training mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# Loop over each batch from the training set", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Copy data to GPU if needed", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "\n", "# Unpack the inputs from our dataloader", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "# Zero gradient buffers", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Forward pass", "\n", "output", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ".", "float", "(", ")", ")", "\n", "\n", "# Backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Update weights", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "log_interval", "==", "0", "and", "step", ">", "0", "and", "args", ".", "verbose", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "step", "*", "len", "(", "b_input_ids", ")", ",", "\n", "len", "(", "train_dataloader", ".", "dataset", ")", ",", "\n", "100.", "*", "step", "/", "len", "(", "train_dataloader", ")", ",", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.evaluate": [[106, 127], ["model.eval", "print", "tuple", "logits.squeeze().detach().cpu().numpy", "b_labels.detach().cpu().numpy.detach().cpu().numpy", "torch.no_grad", "t.cuda", "model", "logits.squeeze().detach().cpu", "b_labels.detach().cpu().numpy.detach().cpu", "logits.squeeze().detach", "b_labels.detach().cpu().numpy.detach", "logits.squeeze"], "function", ["None"], ["", "", "", "def", "evaluate", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "cor", "=", "0", "\n", "total", "=", "0", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", "\n", "", "output", "=", "logits", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "predictions", "=", "(", "output", ">", "0", ")", ".", "astype", "(", "int", ")", "\n", "\n", "b_labels", "=", "b_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cor", "+=", "(", "predictions", "==", "b_labels", ")", ".", "sum", "(", ")", "\n", "total", "+=", "b_labels", ".", "shape", "[", "0", "]", "\n", "\n", "", "acc", "=", "cor", "/", "total", "\n", "print", "(", "'Accuracy: {:.4f}'", ".", "format", "(", "acc", ")", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.commonsense.tune.get_probs": [[128, 148], ["model.eval", "numpy.concatenate", "tuple", "torch.sigmoid().squeeze().detach().cpu().numpy", "torch.no_grad", "all_probs.append", "t.cuda", "model", "torch.sigmoid().squeeze().detach().cpu", "torch.sigmoid().squeeze().detach", "torch.sigmoid().squeeze", "torch.sigmoid"], "function", ["None"], ["", "def", "get_probs", "(", "model", ",", "dataloader", ",", "no_labels", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "all_probs", "=", "[", "]", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "if", "not", "no_labels", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "", "else", ":", "\n", "            ", "b_input_ids", ",", "b_input_mask", "=", "batch", "# no labels", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", "\n", "\n", "", "probs", "=", "torch", ".", "sigmoid", "(", "logits", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "probs", ".", "size", ">", "1", ":", "\n", "            ", "all_probs", ".", "append", "(", "probs", ")", "\n", "\n", "", "", "probs", "=", "np", ".", "concatenate", "(", "all_probs", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.justice.tune.main": [[10, 53], ["os.path.abspath", "range", "open", "f.write", "load_model", "load_process_data", "load_process_data", "load_process_data", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "test_hard_accs.append", "test_accs.append", "test_hard_ems.append", "test_ems.append", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "len", "len", "len", "print", "tune.train", "print", "tune.evaluate", "print", "tune.evaluate", "print", "torch.save", "open", "f.write", "model.module.state_dict"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate"], ["\n", "def", "main", "(", "args", ")", ":", "\n", "    ", "test_hard_accs", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "aucs", "=", "[", "]", "\n", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", "\n", "for", "run", "in", "range", "(", "args", ".", "nruns", ")", ":", "\n", "        ", "model", ",", "optimizer", "=", "load_model", "(", "args", ")", "\n", "\n", "# data for ambiguous detection auroc", "\n", "long_test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"long_test\"", ")", "\n", "ambig_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"ambig\"", ")", "\n", "\n", "# data for normal training + etestuation", "\n", "train_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"train\"", ")", "\n", "test_hard_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test_hard\"", ")", "\n", "test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test\"", ")", "\n", "print", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_hard_data", ")", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "test_hard_dataloader", "=", "DataLoader", "(", "test_hard_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "ambig_dataloader", "=", "DataLoader", "(", "ambig_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "long_test_dataloader", "=", "DataLoader", "(", "long_test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "nepochs", "+", "1", ")", ":", "\n", "            ", "print", "(", ")", "\n", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ")", "\n", "print", "(", "'\\ntest hard set:'", ")", "\n", "test_hard_acc", "=", "evaluate", "(", "model", ",", "test_hard_dataloader", ")", "\n", "print", "(", "'\\ntest set:'", ")", "\n", "test_acc", "=", "evaluate", "(", "model", ",", "test_dataloader", ")", "\n", "\n", "", "test_hard_accs", ".", "append", "(", "test_hard_acc", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "probs", "=", "get_probs", "(", "model", ",", "ambig_dataloader", ")", "\n", "test_probs", "=", "get_probs", "(", "model", ",", "long_test_dataloader", ")", "\n", "\n", "# now see how well we can distinguish between these ", "\n", "max_probs", "=", "np", ".", "maximum", "(", "probs", ",", "1", "-", "probs", ")", "\n", "max_test_probs", "=", "np", ".", "maximum", "(", "test_probs", ",", "1", "-", "test_probs", ")", "\n", "y", "=", "np", ".", "zeros", "(", "probs", ".", "shape", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.justice.tune.train": [[54, 86], ["torch.nn.BCEWithLogitsLoss", "enumerate", "tuple", "optimizer.zero_grad", "[].squeeze", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "optimizer.step", "b_labels.float", "print", "t.cuda", "model", "len", "len", "len"], "function", ["None"], ["test_y", "=", "np", ".", "ones", "(", "test_probs", ".", "shape", "[", "0", "]", ")", "\n", "all_y", ",", "all_probs", "=", "np", ".", "concatenate", "(", "[", "y", ",", "test_y", "]", ")", ",", "np", ".", "concatenate", "(", "[", "max_probs", ",", "max_test_probs", "]", ")", "\n", "auc", "=", "roc_auc_score", "(", "all_y", ",", "all_probs", ")", "\n", "print", "(", "\"AUC: {:.3f}\"", ".", "format", "(", "auc", ")", ")", "\n", "aucs", ".", "append", "(", "auc", ")", "\n", "\n", "if", "args", ".", "save", ":", "\n", "            ", "save_path", "=", "\"cm_{}_{}_{}_{}.pkl\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "learning_rate", ",", "args", ".", "batch_size", ",", "args", ".", "nepochs", ")", "\n", "print", "(", "\"SAVING to\"", ",", "save_path", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Run {} test hard acc: {:.3f} test acc: {:.3f} auc: {:.3f}\\n\"", ".", "format", "(", "run", ",", "test_hard_acc", ",", "test_acc", ",", "auc", ")", ")", "\n", "\n", "", "", "return", "np", ".", "max", "(", "test_hard_accs", ")", ",", "np", ".", "max", "(", "test_accs", ")", ",", "np", ".", "max", "(", "aucs", ")", "\n", "\n", "", "def", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ",", "log_interval", "=", "10", ")", ":", "\n", "# Set model to training mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# Loop over each batch from the training set", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Copy data to GPU if needed", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "\n", "# Unpack the inputs from our dataloader", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "# Zero gradient buffers", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.justice.tune.evaluate": [[88, 110], ["model.eval", "numpy.mean", "numpy.mean", "print", "tuple", "logits.squeeze().detach().cpu().numpy", "b_labels.detach().cpu().numpy.detach().cpu().numpy", "list", "torch.no_grad", "int", "range", "range", "t.cuda", "model", "logits.squeeze().detach().cpu", "b_labels.detach().cpu().numpy.detach().cpu", "int", "len", "int", "int", "len", "logits.squeeze().detach", "b_labels.detach().cpu().numpy.detach", "logits.squeeze"], "function", ["None"], ["# Forward pass", "\n", "output", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ".", "float", "(", ")", ")", "\n", "\n", "# Backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Update weights", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "log_interval", "==", "0", "and", "step", ">", "0", "and", "args", ".", "verbose", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "step", "*", "len", "(", "b_input_ids", ")", ",", "\n", "len", "(", "train_dataloader", ".", "dataset", ")", ",", "\n", "100.", "*", "step", "/", "len", "(", "train_dataloader", ")", ",", "loss", ")", ")", "\n", "\n", "\n", "", "", "", "def", "evaluate", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "cor", "=", "0", "\n", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.deontology.tune.main": [[10, 53], ["os.path.abspath", "range", "open", "f.write", "load_model", "load_process_data", "load_process_data", "load_process_data", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "test_hard_accs.append", "test_accs.append", "test_hard_ems.append", "test_ems.append", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "len", "len", "len", "print", "tune.train", "print", "tune.evaluate", "print", "tune.evaluate", "print", "torch.save", "open", "f.write", "model.module.state_dict"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate"], ["\n", "def", "main", "(", "args", ")", ":", "\n", "    ", "test_hard_accs", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "aucs", "=", "[", "]", "\n", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", "\n", "for", "run", "in", "range", "(", "args", ".", "nruns", ")", ":", "\n", "        ", "model", ",", "optimizer", "=", "load_model", "(", "args", ")", "\n", "\n", "# data for ambiguous detection auroc", "\n", "long_test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"long_test\"", ")", "\n", "ambig_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"ambig\"", ")", "\n", "\n", "# data for normal training + etestuation", "\n", "train_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"train\"", ")", "\n", "test_hard_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test_hard\"", ")", "\n", "test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test\"", ")", "\n", "print", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_hard_data", ")", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "test_hard_dataloader", "=", "DataLoader", "(", "test_hard_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "ambig_dataloader", "=", "DataLoader", "(", "ambig_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "long_test_dataloader", "=", "DataLoader", "(", "long_test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "nepochs", "+", "1", ")", ":", "\n", "            ", "print", "(", ")", "\n", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ")", "\n", "print", "(", "'\\ntest hard set:'", ")", "\n", "test_hard_acc", "=", "evaluate", "(", "model", ",", "test_hard_dataloader", ")", "\n", "print", "(", "'\\ntest set:'", ")", "\n", "test_acc", "=", "evaluate", "(", "model", ",", "test_dataloader", ")", "\n", "\n", "", "test_hard_accs", ".", "append", "(", "test_hard_acc", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "probs", "=", "get_probs", "(", "model", ",", "ambig_dataloader", ")", "\n", "test_probs", "=", "get_probs", "(", "model", ",", "long_test_dataloader", ")", "\n", "\n", "# now see how well we can distinguish between these ", "\n", "max_probs", "=", "np", ".", "maximum", "(", "probs", ",", "1", "-", "probs", ")", "\n", "max_test_probs", "=", "np", ".", "maximum", "(", "test_probs", ",", "1", "-", "test_probs", ")", "\n", "y", "=", "np", ".", "zeros", "(", "probs", ".", "shape", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.deontology.tune.train": [[54, 86], ["torch.nn.BCEWithLogitsLoss", "enumerate", "tuple", "optimizer.zero_grad", "[].squeeze", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "optimizer.step", "b_labels.float", "print", "t.cuda", "model", "len", "len", "len"], "function", ["None"], ["test_y", "=", "np", ".", "ones", "(", "test_probs", ".", "shape", "[", "0", "]", ")", "\n", "all_y", ",", "all_probs", "=", "np", ".", "concatenate", "(", "[", "y", ",", "test_y", "]", ")", ",", "np", ".", "concatenate", "(", "[", "max_probs", ",", "max_test_probs", "]", ")", "\n", "auc", "=", "roc_auc_score", "(", "all_y", ",", "all_probs", ")", "\n", "print", "(", "\"AUC: {:.3f}\"", ".", "format", "(", "auc", ")", ")", "\n", "aucs", ".", "append", "(", "auc", ")", "\n", "\n", "if", "args", ".", "save", ":", "\n", "            ", "save_path", "=", "\"cm_{}_{}_{}_{}.pkl\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "learning_rate", ",", "args", ".", "batch_size", ",", "args", ".", "nepochs", ")", "\n", "print", "(", "\"SAVING to\"", ",", "save_path", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Run {} test hard acc: {:.3f} test acc: {:.3f} auc: {:.3f}\\n\"", ".", "format", "(", "run", ",", "test_hard_acc", ",", "test_acc", ",", "auc", ")", ")", "\n", "\n", "", "", "return", "np", ".", "max", "(", "test_hard_accs", ")", ",", "np", ".", "max", "(", "test_accs", ")", ",", "np", ".", "max", "(", "aucs", ")", "\n", "\n", "", "def", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ",", "log_interval", "=", "10", ")", ":", "\n", "# Set model to training mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# Loop over each batch from the training set", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Copy data to GPU if needed", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "\n", "# Unpack the inputs from our dataloader", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "# Zero gradient buffers", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.deontology.tune.evaluate": [[88, 110], ["model.eval", "numpy.mean", "numpy.mean", "print", "tuple", "logits.squeeze().detach().cpu().numpy", "b_labels.detach().cpu().numpy.detach().cpu().numpy", "list", "torch.no_grad", "int", "range", "range", "t.cuda", "model", "logits.squeeze().detach().cpu", "b_labels.detach().cpu().numpy.detach().cpu", "int", "len", "int", "int", "len", "logits.squeeze().detach", "b_labels.detach().cpu().numpy.detach", "logits.squeeze"], "function", ["None"], ["# Forward pass", "\n", "output", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ".", "float", "(", ")", ")", "\n", "\n", "# Backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Update weights", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "log_interval", "==", "0", "and", "step", ">", "0", "and", "args", ".", "verbose", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "step", "*", "len", "(", "b_input_ids", ")", ",", "\n", "len", "(", "train_dataloader", ".", "dataset", ")", ",", "\n", "100.", "*", "step", "/", "len", "(", "train_dataloader", ")", ",", "loss", ")", ")", "\n", "\n", "\n", "", "", "", "def", "evaluate", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "cor", "=", "0", "\n", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.virtue.tune.main": [[10, 58], ["os.path.abspath", "range", "open", "f.write", "load_model", "load_process_data", "load_process_data", "load_process_data", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "test_hard_accs.append", "test_accs.append", "test_hard_ems.append", "test_ems.append", "test_hard_accs.append", "test_accs.append", "open", "f.write", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "len", "len", "len", "print", "tune.train", "print", "tune.evaluate", "print", "tune.evaluate", "print", "torch.save", "open", "f.write", "model.module.state_dict", "numpy.max", "numpy.max", "numpy.max", "numpy.max"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate"], ["\n", "def", "main", "(", "args", ")", ":", "\n", "    ", "test_hard_accs", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "aucs", "=", "[", "]", "\n", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", "\n", "for", "run", "in", "range", "(", "args", ".", "nruns", ")", ":", "\n", "        ", "model", ",", "optimizer", "=", "load_model", "(", "args", ")", "\n", "\n", "# data for ambiguous detection auroc", "\n", "long_test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"long_test\"", ")", "\n", "ambig_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"ambig\"", ")", "\n", "\n", "# data for normal training + etestuation", "\n", "train_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"train\"", ")", "\n", "test_hard_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test_hard\"", ")", "\n", "test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test\"", ")", "\n", "print", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_hard_data", ")", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "test_hard_dataloader", "=", "DataLoader", "(", "test_hard_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "ambig_dataloader", "=", "DataLoader", "(", "ambig_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "long_test_dataloader", "=", "DataLoader", "(", "long_test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "nepochs", "+", "1", ")", ":", "\n", "            ", "print", "(", ")", "\n", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ")", "\n", "print", "(", "'\\ntest hard set:'", ")", "\n", "test_hard_acc", "=", "evaluate", "(", "model", ",", "test_hard_dataloader", ")", "\n", "print", "(", "'\\ntest set:'", ")", "\n", "test_acc", "=", "evaluate", "(", "model", ",", "test_dataloader", ")", "\n", "\n", "", "test_hard_accs", ".", "append", "(", "test_hard_acc", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "probs", "=", "get_probs", "(", "model", ",", "ambig_dataloader", ")", "\n", "test_probs", "=", "get_probs", "(", "model", ",", "long_test_dataloader", ")", "\n", "\n", "# now see how well we can distinguish between these ", "\n", "max_probs", "=", "np", ".", "maximum", "(", "probs", ",", "1", "-", "probs", ")", "\n", "max_test_probs", "=", "np", ".", "maximum", "(", "test_probs", ",", "1", "-", "test_probs", ")", "\n", "y", "=", "np", ".", "zeros", "(", "probs", ".", "shape", "[", "0", "]", ")", "\n", "test_y", "=", "np", ".", "ones", "(", "test_probs", ".", "shape", "[", "0", "]", ")", "\n", "all_y", ",", "all_probs", "=", "np", ".", "concatenate", "(", "[", "y", ",", "test_y", "]", ")", ",", "np", ".", "concatenate", "(", "[", "max_probs", ",", "max_test_probs", "]", ")", "\n", "auc", "=", "roc_auc_score", "(", "all_y", ",", "all_probs", ")", "\n", "print", "(", "\"AUC: {:.3f}\"", ".", "format", "(", "auc", ")", ")", "\n", "aucs", ".", "append", "(", "auc", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.virtue.tune.train": [[59, 91], ["torch.nn.BCEWithLogitsLoss", "enumerate", "tuple", "optimizer.zero_grad", "[].squeeze", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "optimizer.step", "b_labels.float", "print", "t.cuda", "model", "len", "len", "len"], "function", ["None"], ["\n", "if", "args", ".", "save", ":", "\n", "            ", "save_path", "=", "\"cm_{}_{}_{}_{}.pkl\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "learning_rate", ",", "args", ".", "batch_size", ",", "args", ".", "nepochs", ")", "\n", "print", "(", "\"SAVING to\"", ",", "save_path", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Run {} test hard acc: {:.3f} test acc: {:.3f} auc: {:.3f}\\n\"", ".", "format", "(", "run", ",", "test_hard_acc", ",", "test_acc", ",", "auc", ")", ")", "\n", "\n", "", "", "return", "np", ".", "max", "(", "test_hard_accs", ")", ",", "np", ".", "max", "(", "test_accs", ")", ",", "np", ".", "max", "(", "aucs", ")", "\n", "\n", "", "def", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ",", "log_interval", "=", "10", ")", ":", "\n", "# Set model to training mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# Loop over each batch from the training set", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Copy data to GPU if needed", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "\n", "# Unpack the inputs from our dataloader", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "# Zero gradient buffers", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Forward pass", "\n", "output", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ".", "float", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.virtue.tune.evaluate": [[93, 115], ["model.eval", "numpy.mean", "numpy.mean", "print", "tuple", "logits.squeeze().detach().cpu().numpy", "b_labels.detach().cpu().numpy.detach().cpu().numpy", "list", "torch.no_grad", "int", "range", "range", "t.cuda", "model", "logits.squeeze().detach().cpu", "b_labels.detach().cpu().numpy.detach().cpu", "int", "len", "int", "len", "logits.squeeze().detach", "b_labels.detach().cpu().numpy.detach", "int", "int", "logits.squeeze"], "function", ["None"], ["# Backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Update weights", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "log_interval", "==", "0", "and", "step", ">", "0", "and", "args", ".", "verbose", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "step", "*", "len", "(", "b_input_ids", ")", ",", "\n", "len", "(", "train_dataloader", ".", "dataset", ")", ",", "\n", "100.", "*", "step", "/", "len", "(", "train_dataloader", ")", ",", "loss", ")", ")", "\n", "\n", "\n", "", "", "", "def", "evaluate", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "cor", "=", "0", "\n", "total", "=", "0", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.main": [[10, 50], ["os.path.abspath", "range", "open", "f.write", "load_model", "load_process_data", "load_process_data", "load_process_data", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "test_hard_accs.append", "test_accs.append", "numpy.max", "numpy.max", "print", "tune.train", "print", "tune.evaluate", "print", "tune.evaluate", "open", "f.write", "f.write", "open", "f.write", "print", "torch.save", "model.module.state_dict"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_model", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.None.utils.load_process_data", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate"], ["\n", "def", "main", "(", "args", ")", ":", "\n", "    ", "test_hard_accs", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "aucs", "=", "[", "]", "\n", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", "\n", "for", "run", "in", "range", "(", "args", ".", "nruns", ")", ":", "\n", "        ", "model", ",", "optimizer", "=", "load_model", "(", "args", ")", "\n", "\n", "# data for ambiguous detection auroc", "\n", "long_test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"long_test\"", ")", "\n", "ambig_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"ambig\"", ")", "\n", "\n", "# data for normal training + etestuation", "\n", "train_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"train\"", ")", "\n", "test_hard_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test_hard\"", ")", "\n", "test_data", "=", "load_process_data", "(", "args", ",", "data_dir", ",", "\"cm\"", ",", "\"test\"", ")", "\n", "print", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_hard_data", ")", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "test_hard_dataloader", "=", "DataLoader", "(", "test_hard_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "ambig_dataloader", "=", "DataLoader", "(", "ambig_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "long_test_dataloader", "=", "DataLoader", "(", "long_test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "nepochs", "+", "1", ")", ":", "\n", "            ", "print", "(", ")", "\n", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ")", "\n", "print", "(", "'\\ntest hard set:'", ")", "\n", "test_hard_acc", "=", "evaluate", "(", "model", ",", "test_hard_dataloader", ")", "\n", "print", "(", "'\\ntest set:'", ")", "\n", "test_acc", "=", "evaluate", "(", "model", ",", "test_dataloader", ")", "\n", "\n", "", "test_hard_accs", ".", "append", "(", "test_hard_acc", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "probs", "=", "get_probs", "(", "model", ",", "ambig_dataloader", ")", "\n", "test_probs", "=", "get_probs", "(", "model", ",", "long_test_dataloader", ")", "\n", "\n", "# now see how well we can distinguish between these ", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.flatten": [[51, 54], ["torch.cat"], "function", ["None"], ["max_probs", "=", "np", ".", "maximum", "(", "probs", ",", "1", "-", "probs", ")", "\n", "max_test_probs", "=", "np", ".", "maximum", "(", "test_probs", ",", "1", "-", "test_probs", ")", "\n", "y", "=", "np", ".", "zeros", "(", "probs", ".", "shape", "[", "0", "]", ")", "\n", "test_y", "=", "np", ".", "ones", "(", "test_probs", ".", "shape", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.unflatten": [[55, 58], ["torch.stack"], "function", ["None"], ["all_y", ",", "all_probs", "=", "np", ".", "concatenate", "(", "[", "y", ",", "test_y", "]", ")", ",", "np", ".", "concatenate", "(", "[", "max_probs", ",", "max_test_probs", "]", ")", "\n", "auc", "=", "roc_auc_score", "(", "all_y", ",", "all_probs", ")", "\n", "print", "(", "\"AUC: {:.3f}\"", ".", "format", "(", "auc", ")", ")", "\n", "aucs", ".", "append", "(", "auc", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train": [[59, 96], ["model.train", "torch.nn.BCEWithLogitsLoss", "len", "enumerate", "tuple", "tune.flatten", "tune.flatten", "optimizer.zero_grad", "tune.unflatten", "torch.nn.BCEWithLogitsLoss.", "criterion.backward", "optimizer.step", "model", "diffs.squeeze", "torch.ones().cuda", "print", "t.cuda", "torch.ones"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.train", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.flatten", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.flatten", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.unflatten"], ["\n", "if", "args", ".", "save", ":", "\n", "            ", "save_path", "=", "\"cm_{}_{}_{}_{}.pkl\"", ".", "format", "(", "args", ".", "model", ",", "args", ".", "learning_rate", ",", "args", ".", "batch_size", ",", "args", ".", "nepochs", ")", "\n", "print", "(", "\"SAVING to\"", ",", "save_path", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "with", "open", "(", "\"runs.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"Run {} test hard acc: {:.3f} test acc: {:.3f} auc: {:.3f}\\n\"", ".", "format", "(", "run", ",", "test_hard_acc", ",", "test_acc", ",", "auc", ")", ")", "\n", "\n", "", "", "return", "np", ".", "max", "(", "test_hard_accs", ")", ",", "np", ".", "max", "(", "test_accs", ")", ",", "np", ".", "max", "(", "aucs", ")", "\n", "\n", "", "def", "train", "(", "model", ",", "optimizer", ",", "train_dataloader", ",", "epoch", ",", "log_interval", "=", "10", ")", ":", "\n", "# Set model to training mode", "\n", "    ", "model", ".", "train", "(", ")", "\n", "\n", "criterion", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# Loop over each batch from the training set", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "\n", "# Copy data to GPU if needed", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "\n", "# Unpack the inputs from our dataloader", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "# Zero gradient buffers", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Forward pass", "\n", "output", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "b_labels", ".", "float", "(", ")", ")", "\n", "\n", "# Backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Update weights", "\n"]], "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.evaluate": [[97, 125], ["model.eval", "enumerate", "numpy.concatenate", "numpy.mean", "print", "tuple", "tune.flatten", "tune.flatten", "np.concatenate.append", "torch.no_grad", "tune.unflatten", "diffs.squeeze().detach().cpu().numpy.squeeze().detach().cpu().numpy", "t.cuda", "model", "diffs.squeeze().detach().cpu().numpy.squeeze().detach().cpu", "diffs.squeeze().detach().cpu().numpy.squeeze().detach", "diffs.squeeze().detach().cpu().numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.flatten", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.flatten", "home.repos.pwc.inspect_result.hendrycks_ethics.utilitarianism.tune.unflatten"], ["optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "log_interval", "==", "0", "and", "step", ">", "0", "and", "args", ".", "verbose", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "step", "*", "len", "(", "b_input_ids", ")", ",", "\n", "len", "(", "train_dataloader", ".", "dataset", ")", ",", "\n", "100.", "*", "step", "/", "len", "(", "train_dataloader", ")", ",", "loss", ")", ")", "\n", "\n", "\n", "", "", "", "def", "evaluate", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "cor", "=", "0", "\n", "total", "=", "0", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "cuda", "(", ")", "for", "t", "in", "batch", ")", "\n", "b_input_ids", ",", "b_input_mask", ",", "b_labels", "=", "batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "model", "(", "b_input_ids", ",", "attention_mask", "=", "b_input_mask", ")", "[", "0", "]", "\n", "", "output", "=", "logits", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "predictions", "=", "(", "output", ">", "0", ")", ".", "astype", "(", "int", ")", "\n", "\n", "b_labels", "=", "b_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cor", "+=", "(", "predictions", "==", "b_labels", ")", ".", "sum", "(", ")", "\n", "total", "+=", "b_labels", ".", "shape", "[", "0", "]", "\n", "\n", "", "acc", "=", "cor", "/", "total", "\n", "print", "(", "'Accuracy: {:.4f}'", ".", "format", "(", "acc", ")", ")", "\n"]]}