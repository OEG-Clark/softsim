{"home.repos.pwc.inspect_result.chz816_tas.None.taas_finetune_trainer.handle_metrics": [[147, 161], ["logger.info", "sorted", "utils.save_json", "metrics.keys", "logger.info", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json"], ["", "def", "handle_metrics", "(", "split", ",", "metrics", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"\n    Log and save metrics\n\n    Args:\n    - split: one of train, val, test\n    - metrics: metrics dict\n    - output_dir: where to save the metrics\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "f\"***** {split} metrics *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "metrics", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"  {key} = {metrics[key]}\"", ")", "\n", "", "save_json", "(", "metrics", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{split}_results.json\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_finetune_trainer.main": [[163, 378], ["transformers.HfArgumentParser", "utils.check_output_dir", "transformers.trainer_utils.is_main_process", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "utils.use_task_specific_params", "logger.info", "topic_models.preprocessing.WhiteSpacePreprocessing", "topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "sorted", "topic_models.preprocessing.WhiteSpacePreprocessing", "topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "topic_models.preprocessing.WhiteSpacePreprocessing", "topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "topic_models.data_preparation.TopicModelDataPreparation", "topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "taas_seq2seq_trainer.Seq2SeqTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "getattr", "model.TAASForConditionalGeneration.from_pretrained", "model.TAASForConditionalGeneration.from_pretrained", "isinstance", "utils.freeze_embeds", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "line.strip", "line.strip", "line.strip", "utils.TAASSeq2SeqDataset", "utils.TAASSeq2SeqDataset", "utils.TAASSeq2SeqDataset", "utils.build_compute_metrics_fn", "logger.info", "taas_seq2seq_trainer.Seq2SeqTrainer.save_model", "taas_seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "len", "hasattr", "setattr", "TAASForConditionalGeneration.from_pretrained.get_encoder", "TAASForConditionalGeneration.from_pretrained.get_encoder", "TAASForConditionalGeneration.from_pretrained.get_decoder", "TAASForConditionalGeneration.from_pretrained.get_decoder", "open().readlines", "open().readlines", "open().readlines", "utils.TAASSeq2SeqDataCollator", "len", "taas_seq2seq_trainer.Seq2SeqTrainer.train", "taas_seq2seq_trainer.Seq2SeqTrainer.train", "taas_finetune_trainer.handle_metrics", "all_metrics.update", "taas_seq2seq_trainer.Seq2SeqTrainer.state.save_to_json", "AutoTokenizer.from_pretrained.save_pretrained", "os.path.abspath", "getattr", "os.path.join", "open", "open", "open", "os.path.isdir", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.check_output_dir", "home.repos.pwc.inspect_result.chz816_tas.None.utils.use_task_specific_params", "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_embeds", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.build_compute_metrics_fn", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.handle_metrics"], ["", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "check_output_dir", "(", "training_args", ")", "\n", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Set seed", "\n", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "extra_model_params", "=", "(", "\"encoder_layerdrop\"", ",", "\"decoder_layerdrop\"", ",", "\"dropout\"", ",", "\"attention_dropout\"", ")", "\n", "for", "p", "in", "extra_model_params", ":", "\n", "        ", "if", "getattr", "(", "training_args", ",", "p", ",", "None", ")", ":", "\n", "            ", "assert", "hasattr", "(", "config", ",", "p", ")", ",", "f\"({config.__class__.__name__}) doesn't have a `{p}` attribute\"", "\n", "setattr", "(", "config", ",", "p", ",", "getattr", "(", "training_args", ",", "p", ")", ")", "\n", "\n", "# get tokenizer", "\n", "", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "if", "not", "model_args", ".", "load_checkpoint", ":", "\n", "        ", "model", "=", "TAASForConditionalGeneration", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "topic_num", "=", "model_args", ".", "topic_num", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "TAASForConditionalGeneration", ".", "from_pretrained", "(", "model_args", ".", "load_checkpoint_path", ",", "\n", "topic_num", "=", "model_args", ".", "topic_num", ",", "\n", "model_type", "=", "model_args", ".", "topic_model_type", ")", "\n", "\n", "# use task specific params", "\n", "", "use_task_specific_params", "(", "model", ",", "data_args", ".", "task", ")", "\n", "\n", "# set num_beams for evaluation", "\n", "if", "data_args", ".", "eval_beams", "is", "None", ":", "\n", "        ", "data_args", ".", "eval_beams", "=", "model", ".", "config", ".", "num_beams", "\n", "\n", "# set decoder_start_token_id for MBart", "\n", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "        ", "assert", "(", "\n", "data_args", ".", "tgt_lang", "is", "not", "None", "and", "data_args", ".", "src_lang", "is", "not", "None", "\n", ")", ",", "\"mBart requires --tgt_lang and --src_lang\"", "\n", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "tgt_lang", "]", "\n", "\n", "", "if", "model_args", ".", "freeze_embeds", ":", "\n", "        ", "freeze_embeds", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Freeze the word embedding\"", ")", "\n", "# freeze encoder", "\n", "", "if", "model_args", ".", "freeze_encoder", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_encoder", "(", ")", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_encoder", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Freeze the encoder\"", ")", "\n", "# freeze decoder", "\n", "", "if", "model_args", ".", "freeze_decoder", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_decoder", "(", ")", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_decoder", "(", ")", ")", "\n", "logger", ".", "info", "(", "f\"Freeze the decoder\"", ")", "\n", "\n", "# preprocess for the topic modeling", "\n", "", "logger", ".", "info", "(", "\"Preprocess the documents for topic modeling\"", ")", "\n", "# load the input documents for training", "\n", "train_documents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "\n", "open", "(", "f\"{data_args.data_dir}/train.source\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", "\n", "# load the input documents for validation", "\n", "val_documents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "f\"{data_args.data_dir}/val.source\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", "\n", "# load the input documents for testing set", "\n", "test_documents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "f\"{data_args.data_dir}/test.source\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", "\n", "\n", "# load the vocabulary - we use the training set", "\n", "sp", "=", "WhiteSpacePreprocessing", "(", "train_documents", ",", "\"english\"", ")", "\n", "preprocessed_documents_for_bow_training", ",", "topic_vocab", "=", "sp", ".", "preprocess", "(", ")", "\n", "# sort the topic_vocab", "\n", "topic_vocab", "=", "sorted", "(", "topic_vocab", ")", "\n", "# for validation set", "\n", "sp", "=", "WhiteSpacePreprocessing", "(", "val_documents", ",", "\"english\"", ")", "\n", "# use the pre-defined topic_vocab, which is learned from the training set", "\n", "preprocessed_documents_for_bow_val", ",", "val_topic_vocab", "=", "sp", ".", "preprocess", "(", "vocabulary", "=", "topic_vocab", ")", "\n", "# for testing set", "\n", "sp", "=", "WhiteSpacePreprocessing", "(", "test_documents", ",", "\"english\"", ")", "\n", "# use the pre-defined topic_vocab, which is learned from the training set", "\n", "preprocessed_documents_for_bow_test", ",", "test_topic_vocab", "=", "sp", ".", "preprocess", "(", "vocabulary", "=", "topic_vocab", ")", "\n", "qt", "=", "TopicModelDataPreparation", "(", "topic_vocab", ")", "\n", "# get bow representation for training", "\n", "bow_dataset_train", "=", "qt", ".", "create_training_set", "(", "preprocessed_documents_for_bow_training", ")", "\n", "# get bow representation for validation", "\n", "bow_dataset_val", "=", "qt", ".", "create_training_set", "(", "preprocessed_documents_for_bow_val", ")", "\n", "# get bow representation for testing", "\n", "bow_dataset_test", "=", "qt", ".", "create_training_set", "(", "preprocessed_documents_for_bow_test", ")", "\n", "# get the mapping between id and selected word", "\n", "id2token", "=", "bow_dataset_train", ".", "idx2token", "\n", "\n", "# Get datasets", "\n", "train_dataset", "=", "(", "\n", "TAASSeq2SeqDataset", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"train\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_train", ",", "\n", "bow_representation", "=", "bow_dataset_train", ".", "X", ",", "\n", "max_target_length", "=", "data_args", ".", "max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_train", "\n", "else", "None", "\n", ")", "\n", "eval_dataset", "=", "(", "\n", "TAASSeq2SeqDataset", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"val\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_val", ",", "\n", "bow_representation", "=", "bow_dataset_val", ".", "X", ",", "\n", "max_target_length", "=", "data_args", ".", "val_max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_eval", "or", "training_args", ".", "evaluation_strategy", "!=", "EvaluationStrategy", ".", "NO", "\n", "else", "None", "\n", ")", "\n", "test_dataset", "=", "(", "\n", "TAASSeq2SeqDataset", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"test\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_val", ",", "\n", "bow_representation", "=", "bow_dataset_test", ".", "X", ",", "\n", "max_target_length", "=", "data_args", ".", "val_max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_eval", "or", "training_args", ".", "evaluation_strategy", "!=", "EvaluationStrategy", ".", "NO", "\n", "else", "None", "\n", ")", "\n", "\n", "# Initialize our Trainer", "\n", "compute_metrics_fn", "=", "(", "\n", "build_compute_metrics_fn", "(", "data_args", ".", "task", ",", "tokenizer", ")", "if", "training_args", ".", "predict_with_generate", "else", "None", "\n", ")", "\n", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "eval_dataset", "=", "eval_dataset", ",", "\n", "data_collator", "=", "TAASSeq2SeqDataCollator", "(", "tokenizer", ",", "data_args", ",", "training_args", ".", "tpu_num_cores", ")", ",", "\n", "compute_metrics", "=", "compute_metrics_fn", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "topic_num", "=", "model_args", ".", "topic_num", ",", "\n", "alpha", "=", "model_args", ".", "loss_alpha", ",", "\n", "beta", "=", "model_args", ".", "loss_beta", ",", "\n", "id2token", "=", "id2token", ",", "\n", "topic_vocab", "=", "topic_vocab", ",", "\n", "topic_vocab_size", "=", "len", "(", "topic_vocab", ")", ",", "\n", ")", "\n", "\n", "all_metrics", "=", "{", "}", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Train ***\"", ")", "\n", "\n", "if", "not", "model_args", ".", "continue_trainer", ":", "\n", "            ", "train_result", "=", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "model_name_or_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "else", "None", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_result", "=", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "continue_trainer_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "continue_trainer_path", ")", "else", "None", "\n", ")", "\n", "\n", "", "metrics", "=", "train_result", ".", "metrics", "\n", "metrics", "[", "\"train_n_objs\"", "]", "=", "data_args", ".", "n_train", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# this also saves the tokenizer", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "handle_metrics", "(", "\"train\"", ",", "metrics", ",", "training_args", ".", "output_dir", ")", "\n", "all_metrics", ".", "update", "(", "metrics", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "\n", "", "", "return", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.run_seq2seq.DataTrainingArguments.__post_init__": [[179, 192], ["ValueError", "ValueError", "run_seq2seq.DataTrainingArguments.task.startswith", "run_seq2seq.DataTrainingArguments.task.startswith", "run_seq2seq.DataTrainingArguments.train_file.split", "run_seq2seq.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", "]", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", "]", ",", "\"`validation_file` should be a csv or a json file.\"", "\n", "", "", "if", "not", "self", ".", "task", ".", "startswith", "(", "\"summarization\"", ")", "and", "not", "self", ".", "task", ".", "startswith", "(", "\"translation\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"`task` should be summarization, summarization_{dataset}, translation or translation_{xx}_to_{yy}.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.run_seq2seq.main": [[201, 491], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "data_args.task.startswith", "data_args.task.startswith", "datasets.load_metric", "transformers.Seq2SeqTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.exists", "os.listdir", "ValueError", "transformers.utils.logging.set_verbosity_info", "datasets.load_dataset", "datasets.load_dataset", "isinstance", "ValueError", "summarization_name_mapping.get", "re.match", "data_args.task.startswith", "AutoTokenizer.from_pretrained.", "train_dataset.select.map", "eval_dataset.select.map", "transformers.DataCollatorForSeq2Seq", "data_args.task.startswith", "isinstance", "AutoTokenizer.from_pretrained.batch_decode", "AutoTokenizer.from_pretrained.batch_decode", "datasets.load_metric.compute", "numpy.mean", "transformers.Seq2SeqTrainer.train", "transformers.Seq2SeqTrainer.save_model", "os.path.join", "transformers.Seq2SeqTrainer.is_world_process_zero", "logger.info", "transformers.Seq2SeqTrainer.evaluate", "os.path.join", "transformers.Seq2SeqTrainer.is_world_process_zero", "len", "bool", "AutoTokenizer.from_pretrained.as_target_tokenizer", "AutoTokenizer.from_pretrained.", "train_dataset.select.select", "eval_dataset.select.select", "numpy.where", "pred.strip", "label.strip", "numpy.count_nonzero", "transformers.Seq2SeqTrainer.state.save_to_json", "os.path.abspath", "transformers.trainer_utils.is_main_process", "data_args.train_file.split", "data_args.validation_file.split", "data_args.source_lang.split", "re.match.groups", "data_args.target_lang.split", "re.match.groups", "range", "range", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "bool", "metric.compute.items", "os.path.isdir", "trainer.train.metrics.items", "logger.info", "writer.write", "trainer.evaluate.items", "logger.info", "writer.write"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty.\"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files in the summarization task, this script will use the first column for the full texts and the", "\n", "# second column for the summaries (unless you specify column names for this with the `text_column` and", "\n", "# `summary_column` arguments).", "\n", "# For translation, only JSON files are supported, with one field named \"translation\" containing two keys for the", "\n", "# source and target languages (unless you adapt what follows).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "extension", "=", "data_args", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Set decoder_start_token_id", "\n", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "        ", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "target_lang", "]", "\n", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Make sure that `config.decoder_start_token_id` is correctly defined\"", ")", "\n", "\n", "# Preprocessing the datasets.", "\n", "# We need to tokenize inputs and targets.", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "\n", "# For translation we set the codes of our source and target languages (only useful for mBART, the others will", "\n", "# ignore those attributes).", "\n", "", "if", "data_args", ".", "task", ".", "startswith", "(", "\"translation\"", ")", ":", "\n", "        ", "if", "data_args", ".", "source_lang", "is", "not", "None", ":", "\n", "            ", "tokenizer", ".", "src_lang", "=", "data_args", ".", "source_lang", "\n", "", "if", "data_args", ".", "target_lang", "is", "not", "None", ":", "\n", "            ", "tokenizer", ".", "tgt_lang", "=", "data_args", ".", "target_lang", "\n", "\n", "# To serialize preprocess_function below, each of those four variables needs to be defined (even if we won't use", "\n", "# them all).", "\n", "", "", "source_lang", ",", "target_lang", ",", "text_column", ",", "summary_column", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "if", "data_args", ".", "task", ".", "startswith", "(", "\"summarization\"", ")", ":", "\n", "# Get the column names for input/target.", "\n", "        ", "dataset_columns", "=", "summarization_name_mapping", ".", "get", "(", "data_args", ".", "dataset_name", ",", "None", ")", "\n", "if", "data_args", ".", "text_column", "is", "None", ":", "\n", "            ", "text_column", "=", "dataset_columns", "[", "0", "]", "if", "dataset_columns", "is", "not", "None", "else", "column_names", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "text_column", "=", "data_args", ".", "text_column", "\n", "", "if", "data_args", ".", "summary_column", "is", "None", ":", "\n", "            ", "summary_column", "=", "dataset_columns", "[", "1", "]", "if", "dataset_columns", "is", "not", "None", "else", "column_names", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "summary_column", "=", "data_args", ".", "summary_column", "\n", "", "", "else", ":", "\n", "# Get the language codes for input/target.", "\n", "        ", "lang_search", "=", "re", ".", "match", "(", "\"translation_([a-z]+)_to_([a-z]+)\"", ",", "data_args", ".", "task", ")", "\n", "if", "data_args", ".", "source_lang", "is", "not", "None", ":", "\n", "            ", "source_lang", "=", "data_args", ".", "source_lang", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "lang_search", "is", "not", "None", "\n", ")", ",", "\"Provide a source language via --source_lang or rename your task 'translation_xx_to_yy'.\"", "\n", "source_lang", "=", "lang_search", ".", "groups", "(", ")", "[", "0", "]", "\n", "\n", "", "if", "data_args", ".", "target_lang", "is", "not", "None", ":", "\n", "            ", "target_lang", "=", "data_args", ".", "target_lang", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "(", "\n", "lang_search", "is", "not", "None", "\n", ")", ",", "\"Provide a target language via --target_lang or rename your task 'translation_xx_to_yy'.\"", "\n", "target_lang", "=", "lang_search", ".", "groups", "(", ")", "[", "1", "]", "\n", "\n", "# Temporarily set max_target_length for training.", "\n", "", "", "max_target_length", "=", "data_args", ".", "max_target_length", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "        ", "if", "data_args", ".", "task", ".", "startswith", "(", "\"translation\"", ")", ":", "\n", "            ", "inputs", "=", "[", "ex", "[", "source_lang", "]", "for", "ex", "in", "examples", "[", "\"translation\"", "]", "]", "\n", "targets", "=", "[", "ex", "[", "target_lang", "]", "for", "ex", "in", "examples", "[", "\"translation\"", "]", "]", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "examples", "[", "text_column", "]", "\n", "targets", "=", "examples", "[", "summary_column", "]", "\n", "", "model_inputs", "=", "tokenizer", "(", "inputs", ",", "max_length", "=", "data_args", ".", "max_source_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# Setup the tokenizer for targets", "\n", "with", "tokenizer", ".", "as_target_tokenizer", "(", ")", ":", "\n", "            ", "labels", "=", "tokenizer", "(", "targets", ",", "max_length", "=", "max_target_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore", "\n", "# padding in the loss.", "\n", "", "if", "padding", "==", "\"max_length\"", "and", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "            ", "labels", "[", "\"input_ids\"", "]", "=", "[", "\n", "[", "(", "l", "if", "l", "!=", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "l", "in", "label", "]", "for", "label", "in", "labels", "[", "\"input_ids\"", "]", "\n", "]", "\n", "\n", "", "model_inputs", "[", "\"labels\"", "]", "=", "labels", "[", "\"input_ids\"", "]", "\n", "return", "model_inputs", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "", "train_dataset", "=", "train_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "max_target_length", "=", "data_args", ".", "val_max_target_length", "\n", "eval_dataset", "=", "datasets", "[", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_val_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_val_samples", ")", ")", "\n", "", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "", "label_pad_token_id", "=", "-", "100", "if", "data_args", ".", "ignore_pad_token_for_loss", "else", "tokenizer", ".", "pad_token_id", "\n", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "DataCollatorForSeq2Seq", "(", "tokenizer", ",", "label_pad_token_id", "=", "label_pad_token_id", ")", "\n", "\n", "# Metric", "\n", "", "metric_name", "=", "\"rouge\"", "if", "data_args", ".", "task", ".", "startswith", "(", "\"summarization\"", ")", "else", "\"sacrebleu\"", "\n", "metric", "=", "load_metric", "(", "metric_name", ")", "\n", "\n", "def", "compute_metrics", "(", "eval_preds", ")", ":", "\n", "        ", "preds", ",", "labels", "=", "eval_preds", "\n", "if", "isinstance", "(", "preds", ",", "tuple", ")", ":", "\n", "            ", "preds", "=", "preds", "[", "0", "]", "\n", "", "decoded_preds", "=", "tokenizer", ".", "batch_decode", "(", "preds", ",", "skip_special_tokens", "=", "True", ")", "\n", "if", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "# Replace -100 in the labels as we can't decode them.", "\n", "            ", "labels", "=", "np", ".", "where", "(", "labels", "!=", "-", "100", ",", "labels", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "", "decoded_labels", "=", "tokenizer", ".", "batch_decode", "(", "labels", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "# Some simple post-processing", "\n", "decoded_preds", "=", "[", "pred", ".", "strip", "(", ")", "for", "pred", "in", "decoded_preds", "]", "\n", "decoded_labels", "=", "[", "label", ".", "strip", "(", ")", "for", "label", "in", "decoded_labels", "]", "\n", "if", "metric_name", "==", "\"sacrebleu\"", ":", "\n", "            ", "decoded_labels", "=", "[", "[", "label", "]", "for", "label", "in", "decoded_labels", "]", "\n", "\n", "", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "decoded_preds", ",", "references", "=", "decoded_labels", ")", "\n", "\n", "# Extract a few results from ROUGE", "\n", "if", "metric_name", "==", "\"rouge\"", ":", "\n", "            ", "result", "=", "{", "key", ":", "value", ".", "mid", ".", "fmeasure", "*", "100", "for", "key", ",", "value", "in", "result", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "result", "=", "{", "\"bleu\"", ":", "result", "[", "\"score\"", "]", "}", "\n", "\n", "", "prediction_lens", "=", "[", "np", ".", "count_nonzero", "(", "pred", "!=", "tokenizer", ".", "pad_token_id", ")", "for", "pred", "in", "preds", "]", "\n", "result", "[", "\"gen_len\"", "]", "=", "np", ".", "mean", "(", "prediction_lens", ")", "\n", "\n", "return", "result", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "if", "training_args", ".", "predict_with_generate", "else", "None", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "train_result", "=", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "model_name_or_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "else", "None", "\n", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "results", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_seq2seq.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.run_seq2seq._mp_fn": [[493, 496], ["run_seq2seq.main"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.extract_rouge_mid_statistics": [[36, 42], ["dct.items", "round", "getattr"], "function", ["None"], ["def", "extract_rouge_mid_statistics", "(", "dct", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "k1", ",", "v1", "in", "dct", ".", "items", "(", ")", ":", "\n", "        ", "mid", "=", "v1", ".", "mid", "\n", "new_dict", "[", "k1", "]", "=", "{", "stat", ":", "round", "(", "getattr", "(", "mid", ",", "stat", ")", ",", "2", ")", "for", "stat", "in", "[", "\"precision\"", ",", "\"recall\"", ",", "\"fmeasure\"", "]", "}", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.calculate_rouge": [[44, 73], ["rouge_score.rouge_scorer.RougeScorer", "rouge_score.scoring.BootstrapAggregator", "zip", "rouge_scorer.RougeScorer.score", "scoring.BootstrapAggregator.add_scores", "scoring.BootstrapAggregator.aggregate", "sentence_splitter.add_newline_to_end_of_each_sentence", "sentence_splitter.add_newline_to_end_of_each_sentence", "robustness.extract_rouge_mid_statistics", "round", "aggregator.aggregate.items"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.chz816_tas.None.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.chz816_tas.None.utils.extract_rouge_mid_statistics"], ["", "def", "calculate_rouge", "(", "\n", "pred_lns", ",", "\n", "tgt_lns", ",", "\n", "use_stemmer", "=", "True", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ",", "\n", "return_precision_and_recall", "=", "False", ",", "\n", "bootstrap_aggregation", "=", "True", ",", "\n", "newline_sep", "=", "True", ",", "\n", ")", ":", "\n", "    ", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "rouge_keys", ",", "use_stemmer", "=", "use_stemmer", ")", "\n", "aggregator", "=", "scoring", ".", "BootstrapAggregator", "(", ")", "\n", "for", "pred", ",", "tgt", "in", "zip", "(", "tgt_lns", ",", "pred_lns", ")", ":", "\n", "# rougeLsum expects \"\\n\" separated sentences within a summary", "\n", "        ", "if", "newline_sep", ":", "\n", "            ", "pred", "=", "add_newline_to_end_of_each_sentence", "(", "pred", ")", "\n", "tgt", "=", "add_newline_to_end_of_each_sentence", "(", "tgt", ")", "\n", "", "scores", "=", "scorer", ".", "score", "(", "pred", ",", "tgt", ")", "\n", "aggregator", ".", "add_scores", "(", "scores", ")", "\n", "# print(f\"aggregator._scores: {aggregator._scores}\")", "\n", "\n", "", "if", "bootstrap_aggregation", ":", "\n", "        ", "result", "=", "aggregator", ".", "aggregate", "(", ")", "\n", "if", "return_precision_and_recall", ":", "\n", "            ", "return", "extract_rouge_mid_statistics", "(", "result", ")", "# here we return dict", "\n", "", "else", ":", "\n", "            ", "return", "{", "k", ":", "round", "(", "v", ".", "mid", ".", "fmeasure", "*", "100", ",", "2", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "aggregator", ".", "_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.length": [[75, 109], ["range", "pandas.DataFrame", "pd.DataFrame.sort_values", "range", "range", "robustness.calculate_rouge", "print", "robustness.calculate_rouge", "print", "print", "print", "len", "result.append", "int", "shortest_article.append", "shortest_summary.append", "shortest_target.append", "len", "longest_article.append", "longest_summary.append", "longest_target.append", "int", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge"], ["", "", "def", "length", "(", "preds", ",", "articles", ",", "targets", ",", "percentile", "=", "0.1", ")", ":", "\n", "    ", "\"\"\"\n    Create slices based on the length of the source document\n    :return:\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "        ", "pred", "=", "preds", "[", "i", "]", "\n", "article", "=", "articles", "[", "i", "]", "\n", "target", "=", "targets", "[", "i", "]", "\n", "result", ".", "append", "(", "{", "'article'", ":", "article", ",", "'pred'", ":", "pred", ",", "'target'", ":", "target", ",", "'length'", ":", "len", "(", "article", ")", "}", ")", "\n", "# sort the dataset based on length - ascending", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "result", ")", "\n", "df", ".", "sort_values", "(", "by", "=", "[", "'length'", "]", ",", "ascending", "=", "True", ",", "ignore_index", "=", "True", ",", "inplace", "=", "True", ")", "\n", "# create the subpopulations based on percentile", "\n", "shortest_article", ",", "longest_article", ",", "shortest_summary", ",", "longest_summary", ",", "shortest_target", ",", "longest_target", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "percentile", ")", ")", ":", "\n", "        ", "shortest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "shortest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "shortest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "(", "1", "-", "percentile", ")", ")", "+", "1", ",", "len", "(", "df", ")", ")", ":", "\n", "        ", "longest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "longest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "longest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "\n", "# calculate the performance - ROUGE score", "\n", "", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "shortest_summary", ",", "tgt_lns", "=", "shortest_target", ")", "\n", "print", "(", "f\"Result for Shortest: {metrics}\"", ")", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "longest_summary", ",", "tgt_lns", "=", "longest_target", ")", "\n", "print", "(", "f\"Result for Longest: {metrics}\"", ")", "\n", "# calculate the total number of observations in two slices", "\n", "print", "(", "f\"There are {len(shortest_article)} observations in Shortest Articles\"", ")", "\n", "print", "(", "f\"There are {len(longest_article)} observations in Longest Articles\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.abstractiveness": [[111, 160], ["print", "range", "pandas.DataFrame", "pd.DataFrame.sort_values", "range", "range", "robustness.calculate_rouge", "print", "robustness.calculate_rouge", "print", "print", "print", "len", "robustness.calculate_rouge", "result.append", "int", "shortest_article.append", "shortest_summary.append", "shortest_target.append", "int", "len", "longest_article.append", "longest_summary.append", "longest_target.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge"], ["", "def", "abstractiveness", "(", "preds", ",", "articles", ",", "targets", ",", "rouge_key", "=", "'rouge1'", ",", "percentile", "=", "0.1", ")", ":", "\n", "    ", "\"\"\"\n    The degree to which the reference summary is abstractive versus extractive,\n    based on the proportion of n-grams in the reference summary that are not in the article.\n\n    abstractiveess(A,S) = 1-rouge_precision(A,S)\n\n    rouge_key: can be the value of [\"rouge1\", \"rouge2\", \"rougeL\"], default value is 'rouge1'\n    :return:\n    \"\"\"", "\n", "print", "(", "f\"Evaluate the robustness through abstractiveness with {rouge_key}\"", ")", "\n", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "articles", ")", ")", ":", "\n", "        ", "article", "=", "articles", "[", "i", "]", "\n", "pred", "=", "preds", "[", "i", "]", "\n", "target", "=", "targets", "[", "i", "]", "\n", "# rouge_precision equals the proportion of n-grams in the reference summary that are also in the article", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "[", "target", "]", ",", "tgt_lns", "=", "[", "article", "]", ",", "rouge_keys", "=", "[", "rouge_key", "]", ",", "\n", "return_precision_and_recall", "=", "True", ")", "\n", "result", ".", "append", "(", "{", "'article'", ":", "article", ",", "'pred'", ":", "pred", ",", "'target'", ":", "target", ",", "\n", "'abstractiveness'", ":", "1", "-", "metrics", "[", "rouge_key", "]", "[", "'precision'", "]", "}", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "result", ")", "\n", "df", ".", "sort_values", "(", "by", "=", "[", "'abstractiveness'", "]", ",", "ascending", "=", "True", ",", "inplace", "=", "True", ",", "ignore_index", "=", "True", ")", "\n", "\n", "shortest_article", ",", "longest_article", ",", "shortest_summary", ",", "longest_summary", ",", "shortest_target", ",", "longest_target", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "percentile", ")", ")", ":", "\n", "        ", "shortest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "shortest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "shortest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "(", "1", "-", "percentile", ")", ")", ",", "len", "(", "df", ")", ")", ":", "\n", "        ", "longest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "longest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "longest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "\n", "# for BART", "\n", "\n", "", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "shortest_summary", ",", "tgt_lns", "=", "shortest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Least Abstractive: {metrics}\"", ")", "\n", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "longest_summary", ",", "tgt_lns", "=", "longest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Most Abstractive: {metrics}\"", ")", "\n", "\n", "# calculate the total number of observations in two slices", "\n", "print", "(", "f\"There are {len(shortest_article)} observations in Least Abstractive\"", ")", "\n", "print", "(", "f\"There are {len(longest_article)} observations in Most Abstractive\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.distillation": [[162, 211], ["print", "range", "pandas.DataFrame", "pd.DataFrame.sort_values", "range", "range", "robustness.calculate_rouge", "print", "robustness.calculate_rouge", "print", "print", "print", "len", "robustness.calculate_rouge", "result.append", "int", "shortest_article.append", "shortest_summary.append", "shortest_target.append", "int", "len", "longest_article.append", "longest_summary.append", "longest_target.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge"], ["", "def", "distillation", "(", "preds", ",", "articles", ",", "targets", ",", "rouge_key", "=", "'rouge1'", ",", "percentile", "=", "0.1", ")", ":", "\n", "    ", "\"\"\"\n    The degree to which the reference summary is distilled from a larger quantity of content,\n    based on the proportion of n-grams in the article that do not appear in the reference summary.\n\n    distillation(A,S) = 1-rouge_recall(A,S)\n    :return:\n    \"\"\"", "\n", "print", "(", "f\"Evaluate the robustness through distillation with {rouge_key}\"", ")", "\n", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "articles", ")", ")", ":", "\n", "        ", "article", "=", "articles", "[", "i", "]", "\n", "pred", "=", "preds", "[", "i", "]", "\n", "target", "=", "targets", "[", "i", "]", "\n", "# rouge_precision equals the proportion of n-grams in the reference summary that are also in the article", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "[", "target", "]", ",", "tgt_lns", "=", "[", "article", "]", ",", "rouge_keys", "=", "[", "rouge_key", "]", ",", "\n", "return_precision_and_recall", "=", "True", ")", "\n", "result", ".", "append", "(", "\n", "{", "'article'", ":", "article", ",", "'pred'", ":", "pred", ",", "'target'", ":", "target", ",", "\n", "'distill'", ":", "1", "-", "metrics", "[", "rouge_key", "]", "[", "'recall'", "]", "}", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "result", ")", "\n", "df", ".", "sort_values", "(", "by", "=", "[", "'distill'", "]", ",", "ascending", "=", "True", ",", "inplace", "=", "True", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# create the subpopulations based on percentile", "\n", "shortest_article", ",", "longest_article", ",", "shortest_summary", ",", "longest_summary", ",", "shortest_target", ",", "longest_target", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "percentile", ")", ")", ":", "\n", "        ", "shortest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "shortest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "shortest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "(", "1", "-", "percentile", ")", ")", ",", "len", "(", "df", ")", ")", ":", "\n", "        ", "longest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "longest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "longest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "\n", "# for BART", "\n", "\n", "", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "shortest_summary", ",", "tgt_lns", "=", "shortest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Least Distilled: {metrics}\"", ")", "\n", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "longest_summary", ",", "tgt_lns", "=", "longest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Most Distilled: {metrics}\"", ")", "\n", "\n", "# calculate the total number of observations in two slices", "\n", "print", "(", "f\"There are {len(shortest_article)} observations in Least Abstractive\"", ")", "\n", "print", "(", "f\"There are {len(longest_article)} observations in Most Abstractive\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.robustness.position": [[213, 259], ["print", "range", "pandas.DataFrame", "pd.DataFrame.sort_values", "range", "range", "robustness.calculate_rouge", "print", "robustness.calculate_rouge", "print", "print", "print", "len", "nltk.tokenize.sent_tokenize", "range", "result.append", "int", "shortest_article.append", "shortest_summary.append", "shortest_target.append", "int", "len", "longest_article.append", "longest_summary.append", "longest_target.append", "len", "robustness.calculate_rouge", "sent_sim.append", "sent_sim.index", "len", "len", "len", "len", "max"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge"], ["", "def", "position", "(", "preds", ",", "articles", ",", "targets", ",", "rouge_key", "=", "'rouge1'", ",", "percentile", "=", "0.1", ")", ":", "\n", "    ", "print", "(", "f\"Evaluate the robustness through position with {rouge_key}\"", ")", "\n", "result", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "articles", ")", ")", ":", "\n", "# input document", "\n", "        ", "article", "=", "articles", "[", "i", "]", "\n", "# prediction; generated summary", "\n", "pred", "=", "preds", "[", "i", "]", "\n", "# target summary", "\n", "target", "=", "targets", "[", "i", "]", "\n", "# find the position of the best matched summary in the document", "\n", "sentences", "=", "tokenize", ".", "sent_tokenize", "(", "article", ")", "\n", "sent_sim", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "sentences", ")", ")", ":", "\n", "            ", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "[", "sentences", "[", "j", "]", "]", ",", "tgt_lns", "=", "[", "target", "]", ",", "rouge_keys", "=", "[", "rouge_key", "]", ",", "\n", "return_precision_and_recall", "=", "True", ")", "\n", "sent_sim", ".", "append", "(", "metrics", "[", "rouge_key", "]", "[", "'fmeasure'", "]", ")", "\n", "# record the best-matched sentence (index is from 0)", "\n", "", "result", ".", "append", "(", "\n", "{", "'article'", ":", "article", ",", "'pred'", ":", "pred", ",", "'target'", ":", "target", ",", "'best-matched'", ":", "sent_sim", ".", "index", "(", "max", "(", "sent_sim", ")", ")", "}", ")", "\n", "# average", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "result", ")", "\n", "df", ".", "sort_values", "(", "by", "=", "[", "'best-matched'", "]", ",", "ascending", "=", "True", ",", "inplace", "=", "True", ",", "ignore_index", "=", "True", ")", "\n", "\n", "shortest_article", ",", "longest_article", ",", "shortest_summary", ",", "longest_summary", ",", "shortest_target", ",", "longest_target", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "percentile", ")", ")", ":", "\n", "        ", "shortest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "shortest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "shortest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "len", "(", "df", ")", "*", "(", "1", "-", "percentile", ")", ")", ",", "len", "(", "df", ")", ")", ":", "\n", "        ", "longest_article", ".", "append", "(", "df", "[", "'article'", "]", "[", "i", "]", ")", "\n", "longest_summary", ".", "append", "(", "df", "[", "'pred'", "]", "[", "i", "]", ")", "\n", "longest_target", ".", "append", "(", "df", "[", "'target'", "]", "[", "i", "]", ")", "\n", "# evaluate the performance - ROUGE", "\n", "", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "shortest_summary", ",", "tgt_lns", "=", "shortest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Earliest Position: {metrics}\"", ")", "\n", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", "=", "longest_summary", ",", "tgt_lns", "=", "longest_target", ",", "\n", "rouge_keys", "=", "[", "\"rouge1\"", ",", "\"rouge2\"", ",", "\"rougeL\"", "]", ")", "\n", "print", "(", "f\"Result for Latest Position: {metrics}\"", ")", "\n", "\n", "# calculate the total number of observations in two slices", "\n", "print", "(", "f\"There are {len(shortest_article)} observations in Earliest Position\"", ")", "\n", "print", "(", "f\"There are {len(longest_article)} observations in Latest Position\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.convert_model_to_fp16.convert": [[23, 33], ["torch.load", "tqdm.tqdm", "torch.save", "torch.load.items", "v.half", "isinstance", "TypeError"], "function", ["None"], ["def", "convert", "(", "src_path", ":", "str", ",", "map_location", ":", "str", "=", "\"cpu\"", ",", "save_path", ":", "Union", "[", "str", ",", "None", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"Convert a pytorch_model.bin or model.pt file to torch.float16 for faster downloads, less disk space.\"\"\"", "\n", "state_dict", "=", "torch", ".", "load", "(", "src_path", ",", "map_location", "=", "map_location", ")", "\n", "for", "k", ",", "v", "in", "tqdm", "(", "state_dict", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"FP16 conversion only works on paths that are saved state dicts, like pytorch_model.bin\"", ")", "\n", "", "state_dict", "[", "k", "]", "=", "v", ".", "half", "(", ")", "\n", "", "if", "save_path", "is", "None", ":", "# overwrite src_path", "\n", "        ", "save_path", "=", "src_path", "\n", "", "torch", ".", "save", "(", "state_dict", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.eval_data_dir": [[42, 149], ["str", "torch.distributed.init_process_group", "pathlib.Path", "pathlib.Path.joinpath", "torch.cuda.set_device", "utils.use_task_specific_params", "generate_kwargs.pop", "transformers.AutoTokenizer.from_pretrained", "topic_models.preprocessing.WhiteSpacePreprocessing", "topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "topic_models.data_preparation.TopicModelDataPreparation", "topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "utils.TAASSeq2SeqDataset", "utils.TAASSeq2SeqDataset.make_sortish_sampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "utils.save_json", "transformers.AutoModelForSeq2SeqLM.from_pretrained().cuda", "len", "model.TAASForConditionalGeneration.from_pretrained().cuda", "line.strip", "line.strip", "TAASForConditionalGeneration.from_pretrained().cuda.generate", "AutoTokenizer.from_pretrained.batch_decode", "enumerate", "getattr", "open().readlines", "open().readlines", "utils.chunks", "results.append", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "line.strip", "model.TAASForConditionalGeneration.from_pretrained", "batch[].to", "batch[].to", "batch[].to", "dict", "open().readlines", "open", "open", "ids[].item", "open"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.use_task_specific_params", "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.preprocess", "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.create_training_set", "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_sortish_sampler", "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.generate", "home.repos.pwc.inspect_result.chz816_tas.None.utils.chunks"], ["def", "eval_data_dir", "(", "\n", "data_dir", ",", "\n", "save_dir", ":", "str", ",", "\n", "model_name", ":", "str", ",", "\n", "bs", ":", "int", "=", "8", ",", "\n", "max_source_length", ":", "int", "=", "1024", ",", "\n", "type_path", "=", "\"test\"", ",", "\n", "n_obs", "=", "None", ",", "\n", "fp16", "=", "False", ",", "\n", "task", "=", "\"summarization\"", ",", "\n", "local_rank", "=", "None", ",", "\n", "num_return_sequences", "=", "1", ",", "\n", "dataset_kwargs", ":", "Dict", "=", "None", ",", "\n", "prefix", "=", "\"\"", ",", "\n", "use_checkpoint", "=", "False", ",", "\n", "checkpoint_path", "=", "None", ",", "\n", "**", "generate_kwargs", ",", "\n", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"Run evaluation on part of the data for one gpu and save to {save_dir}/rank_{rank}_output.json\"\"\"", "\n", "model_name", "=", "str", "(", "model_name", ")", "\n", "assert", "local_rank", "is", "not", "None", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ",", "rank", "=", "local_rank", ")", "\n", "\n", "save_dir", "=", "Path", "(", "save_dir", ")", "\n", "save_path", "=", "save_dir", ".", "joinpath", "(", "f\"rank_{local_rank}_output.json\"", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "\n", "# load the model", "\n", "if", "not", "use_checkpoint", ":", "\n", "        ", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "model_name", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "# get the number of topics", "\n", "        ", "topic_num", "=", "len", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "f\"{checkpoint_path}/topics.txt\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", ")", "\n", "model", "=", "TAASForConditionalGeneration", ".", "from_pretrained", "(", "checkpoint_path", ",", "topic_num", "=", "topic_num", ")", ".", "cuda", "(", ")", "\n", "\n", "# update config with task specific params", "\n", "", "use_task_specific_params", "(", "model", ",", "task", ")", "\n", "num_beams", "=", "generate_kwargs", ".", "pop", "(", "\"num_beams\"", ",", "model", ".", "config", ".", "num_beams", ")", "\n", "if", "num_return_sequences", ">", "num_beams", ":", "\n", "        ", "num_beams", "=", "num_return_sequences", "\n", "\n", "# load the tokenizer", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "\"./cache\"", ")", "\n", "\n", "if", "max_source_length", "is", "None", ":", "\n", "        ", "max_source_length", "=", "tokenizer", ".", "model_max_length", "\n", "", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "prefix", "or", "getattr", "(", "model", ".", "config", ",", "\"prefix\"", ",", "\"\"", ")", "or", "\"\"", "\n", "\n", "# load the data", "\n", "\n", "# prepare for topic modeling", "\n", "\n", "# load the vocab for topic modeling", "\n", "", "topic_vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "f\"{checkpoint_path}/topic-vocab.txt\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", "\n", "\n", "# load the input documents for testing set", "\n", "test_documents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "f\"{data_dir}/test.source\"", ",", "encoding", "=", "\"utf-8\"", ")", ".", "readlines", "(", ")", "]", "\n", "\n", "# for testing set", "\n", "sp", "=", "WhiteSpacePreprocessing", "(", "test_documents", ",", "\"english\"", ")", "\n", "# use the pre-defined topic_vocab, which is learned from the training set", "\n", "preprocessed_documents_for_bow_test", ",", "test_topic_vocab", "=", "sp", ".", "preprocess", "(", "vocabulary", "=", "topic_vocab", ")", "\n", "\n", "qt", "=", "TopicModelDataPreparation", "(", "topic_vocab", ")", "\n", "bow_dataset", "=", "qt", ".", "create_training_set", "(", "preprocessed_documents_for_bow_test", ")", "\n", "# get the mapping between id and selected word", "\n", "id2token", "=", "bow_dataset", ".", "idx2token", "\n", "\n", "# get the dataset", "\n", "ds", "=", "TAASSeq2SeqDataset", "(", "\n", "tokenizer", ",", "\n", "data_dir", ",", "\n", "max_source_length", ",", "\n", "max_target_length", "=", "1024", ",", "\n", "type_path", "=", "type_path", ",", "\n", "n_obs", "=", "n_obs", ",", "\n", "prefix", "=", "prefix", ",", "\n", "bow_representation", "=", "bow_dataset", ".", "X", ",", "\n", "**", "dataset_kwargs", ",", "\n", ")", "\n", "# sampler", "\n", "sampler", "=", "ds", ".", "make_sortish_sampler", "(", "bs", ",", "distributed", "=", "True", ",", "add_extra_examples", "=", "False", ",", "shuffle", "=", "True", ")", "\n", "# dataloader", "\n", "data_loader", "=", "DataLoader", "(", "ds", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_size", "=", "bs", ",", "\n", "collate_fn", "=", "ds", ".", "collate_fn", ")", "\n", "# generate the results", "\n", "results", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "        ", "summaries", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "to", "(", "model", ".", "device", ")", ",", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "to", "(", "model", ".", "device", ")", ",", "\n", "num_return_sequences", "=", "num_return_sequences", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "bow", "=", "batch", "[", "\"bow\"", "]", ".", "to", "(", "model", ".", "device", ")", ",", "\n", "**", "generate_kwargs", ",", "\n", ")", "\n", "preds", "=", "tokenizer", ".", "batch_decode", "(", "summaries", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "ids", "=", "batch", "[", "\"ids\"", "]", "\n", "if", "num_return_sequences", ">", "1", ":", "\n", "            ", "preds", "=", "chunks", "(", "preds", ",", "num_return_sequences", ")", "# batch size chunks, each of size num_return_seq", "\n", "", "for", "i", ",", "pred", "in", "enumerate", "(", "preds", ")", ":", "\n", "            ", "results", ".", "append", "(", "dict", "(", "pred", "=", "pred", ",", "id", "=", "ids", "[", "i", "]", ".", "item", "(", ")", ")", ")", "\n", "", "", "save_json", "(", "results", ",", "save_path", ")", "\n", "return", "results", ",", "sampler", ".", "num_replicas", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.run_generate": [[151, 262], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "time.time", "argparse.ArgumentParser.parse_known_args", "utils.parse_numeric_n_bool_cl_kwargs", "pathlib.Path", "pathlib.Path().mkdir", "list", "pathlib.Path().mkdir", "taas_eval.eval_data_dir", "print", "pathlib.Path.glob", "ValueError", "pathlib.Path", "pathlib.Path.mkdir", "taas_eval.gather_results_from_each_node", "taas_eval.combine_partial_results", "pathlib.Path().joinpath", "score_fn", "len", "round", "pathlib.Path.joinpath", "utils.save_json", "print", "utils.write_txt_file", "pathlib.Path", "pathlib.Path", "pathlib.Path.joinpath", "print", "utils.save_json", "time.time", "pathlib.Path.joinpath", "utils.write_txt_file", "shutil.rmtree", "pathlib.Path", "x.rstrip", "len", "pathlib.Path.joinpath", "open().readlines", "open"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.parse_numeric_n_bool_cl_kwargs", "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.eval_data_dir", "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.gather_results_from_each_node", "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.combine_partial_results", "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json", "home.repos.pwc.inspect_result.chz816_tas.None.utils.write_txt_file", "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json", "home.repos.pwc.inspect_result.chz816_tas.None.utils.write_txt_file"], ["", "def", "run_generate", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "epilog", "=", "\"Unspecified args like --num_beams=2 --decoder_start_token_id=4 are passed to model.generate\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "str", ",", "help", "=", "\"like cnn_dm/test.source\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"like facebook/bart-large-cnn,t5-base, etc.\"", ",", "\n", "default", "=", "\"sshleifer/distilbart-xsum-12-3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "help", "=", "\"where to save\"", ",", "default", "=", "\"tmp_gen\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_source_length\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--type_path\"", ",", "type", "=", "str", ",", "default", "=", "\"test\"", ",", "help", "=", "\"which subset to evaluate typically train/val/test\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "type", "=", "str", ",", "default", "=", "\"summarization\"", ",", "help", "=", "\"used for task_specific_params + metrics\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bs\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "required", "=", "False", ",", "help", "=", "\"batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "required", "=", "False", ",", "help", "=", "\"should be passed by distributed.launch\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_obs\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "\"How many observations. Defaults to all.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_return_sequences\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "required", "=", "False", ",", "help", "=", "\"How many sequences to return\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sync_timeout\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "600", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"How long should master process wait for other processes to finish.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--src_lang\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt_lang\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--prefix\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "\"will be added to the begininng of src examples\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_checkpoint\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_path\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "required", "=", "False", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "args", ",", "rest", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "generate_kwargs", "=", "parse_numeric_n_bool_cl_kwargs", "(", "rest", ")", "\n", "if", "generate_kwargs", "and", "args", ".", "local_rank", "<=", "0", ":", "\n", "        ", "print", "(", "f\"parsed the following generate kwargs: {generate_kwargs}\"", ")", "\n", "", "json_save_dir", "=", "Path", "(", "args", ".", "save_dir", "+", "\"_tmp\"", ")", "\n", "Path", "(", "json_save_dir", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "# this handles locking.", "\n", "intermediate_files", "=", "list", "(", "json_save_dir", ".", "glob", "(", "\"rank_*.json\"", ")", ")", "\n", "if", "intermediate_files", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Found files at {json_save_dir} please move or remove them.\"", ")", "\n", "# In theory, a node could finish and save before another node hits this. If this happens, we can address later.", "\n", "", "dataset_kwargs", "=", "{", "}", "\n", "if", "args", ".", "src_lang", "is", "not", "None", ":", "\n", "        ", "dataset_kwargs", "[", "\"src_lang\"", "]", "=", "args", ".", "src_lang", "\n", "", "if", "args", ".", "tgt_lang", "is", "not", "None", ":", "\n", "        ", "dataset_kwargs", "[", "\"tgt_lang\"", "]", "=", "args", ".", "tgt_lang", "\n", "\n", "", "Path", "(", "args", ".", "save_dir", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "results", ",", "num_replicas", "=", "eval_data_dir", "(", "\n", "args", ".", "data_dir", ",", "\n", "json_save_dir", ",", "\n", "args", ".", "model_name", ",", "\n", "type_path", "=", "args", ".", "type_path", ",", "\n", "bs", "=", "args", ".", "bs", ",", "\n", "fp16", "=", "args", ".", "fp16", ",", "\n", "task", "=", "args", ".", "task", ",", "\n", "local_rank", "=", "args", ".", "local_rank", ",", "\n", "n_obs", "=", "args", ".", "n_obs", ",", "\n", "max_source_length", "=", "args", ".", "max_source_length", ",", "\n", "num_return_sequences", "=", "args", ".", "num_return_sequences", ",", "\n", "prefix", "=", "args", ".", "prefix", ",", "\n", "dataset_kwargs", "=", "dataset_kwargs", ",", "\n", "use_checkpoint", "=", "args", ".", "use_checkpoint", ",", "\n", "checkpoint_path", "=", "args", ".", "checkpoint_path", ",", "\n", "**", "generate_kwargs", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "<=", "0", ":", "\n", "        ", "save_dir", "=", "Path", "(", "args", ".", "save_dir", ")", "\n", "save_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "partial_results", "=", "gather_results_from_each_node", "(", "num_replicas", ",", "json_save_dir", ",", "args", ".", "sync_timeout", ")", "\n", "preds", "=", "combine_partial_results", "(", "partial_results", ")", "\n", "if", "args", ".", "num_return_sequences", ">", "1", ":", "\n", "            ", "save_path", "=", "save_dir", ".", "joinpath", "(", "\"pseudolabel_results.json\"", ")", "\n", "print", "(", "f\"Saving aggregated results at {save_path}, intermediate in {json_save_dir}/\"", ")", "\n", "save_json", "(", "preds", ",", "save_path", ")", "\n", "return", "\n", "", "tgt_file", "=", "Path", "(", "args", ".", "data_dir", ")", ".", "joinpath", "(", "args", ".", "type_path", "+", "\".target\"", ")", "\n", "labels", "=", "[", "x", ".", "rstrip", "(", ")", "for", "x", "in", "open", "(", "tgt_file", ",", "encoding", "=", "'utf8'", ")", ".", "readlines", "(", ")", "]", "[", ":", "len", "(", "preds", ")", "]", "\n", "\n", "# Calculate metrics, save metrics,  and save _generations.txt", "\n", "calc_bleu", "=", "\"translation\"", "in", "args", ".", "task", "\n", "score_fn", "=", "calculate_bleu", "if", "calc_bleu", "else", "calculate_rouge", "\n", "metric_name", "=", "\"bleu\"", "if", "calc_bleu", "else", "\"rouge\"", "\n", "metrics", ":", "Dict", "=", "score_fn", "(", "preds", ",", "labels", ")", "\n", "metrics", "[", "\"n_obs\"", "]", "=", "len", "(", "preds", ")", "\n", "runtime", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "metrics", "[", "\"seconds_per_sample\"", "]", "=", "round", "(", "runtime", "/", "metrics", "[", "\"n_obs\"", "]", ",", "4", ")", "\n", "metrics", "[", "\"n_gpus\"", "]", "=", "num_replicas", "\n", "metrics_save_path", "=", "save_dir", ".", "joinpath", "(", "f\"{args.type_path}_{metric_name}.json\"", ")", "\n", "save_json", "(", "metrics", ",", "metrics_save_path", ",", "indent", "=", "None", ")", "\n", "print", "(", "metrics", ")", "\n", "write_txt_file", "(", "preds", ",", "save_dir", ".", "joinpath", "(", "f\"{args.type_path}_generations.txt\"", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "write_txt_file", "(", "labels", ",", "save_dir", ".", "joinpath", "(", "f\"{args.type_path}.target\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "json_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.combine_partial_results": [[264, 272], ["list", "list.extend", "sorted"], "function", ["None"], ["", "", "", "def", "combine_partial_results", "(", "partial_results", ")", "->", "List", ":", "\n", "    ", "\"\"\"Concatenate partial results into one file, then sort it by id.\"\"\"", "\n", "records", "=", "[", "]", "\n", "for", "partial_result", "in", "partial_results", ":", "\n", "        ", "records", ".", "extend", "(", "partial_result", ")", "\n", "", "records", "=", "list", "(", "sorted", "(", "records", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", ")", "\n", "preds", "=", "[", "x", "[", "\"pred\"", "]", "for", "x", "in", "records", "]", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_eval.gather_results_from_each_node": [[274, 291], ["time.time", "logger.info", "list", "TimeoutError", "time.time", "save_dir.glob", "len", "utils.lmap"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap"], ["", "def", "gather_results_from_each_node", "(", "num_replicas", ",", "save_dir", ",", "timeout", ")", "->", "List", "[", "Dict", "[", "str", ",", "List", "]", "]", ":", "\n", "# WAIT FOR lots of .json files", "\n", "    ", "start_wait", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"waiting for all nodes to finish\"", ")", "\n", "json_data", "=", "None", "\n", "while", "(", "time", ".", "time", "(", ")", "-", "start_wait", ")", "<", "timeout", ":", "\n", "        ", "json_files", "=", "list", "(", "save_dir", ".", "glob", "(", "\"rank_*.json\"", ")", ")", "\n", "if", "len", "(", "json_files", ")", "<", "num_replicas", ":", "\n", "            ", "continue", "\n", "", "try", ":", "\n", "# make sure all json files are fully saved", "\n", "            ", "json_data", "=", "lmap", "(", "load_json", ",", "json_files", ")", "\n", "return", "json_data", "\n", "", "except", "JSONDecodeError", ":", "\n", "            ", "continue", "\n", "", "", "else", ":", "\n", "        ", "raise", "TimeoutError", "(", "\"Rank 0 gave up on waiting for other processes\"", ")", "\n", "# Unreachable", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.__init__": [[72, 112], ["transformers.Trainer.__init__", "isinstance", "isinstance", "logger.warn", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "topic_num", ",", "alpha", "=", "0", ",", "beta", "=", "1", ",", "topic_vocab_size", "=", "2000", ",", "topic_vocab", "=", "None", ",", "config", "=", "None", ",", "\n", "data_args", "=", "None", ",", "id2token", "=", "None", ",", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "config", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "\n", "self", ".", "model", ",", "PreTrainedModel", "\n", ")", ",", "f\"If no `config` is passed the model to be trained has to be of type `PreTrainedModel`, but is {self.model.__class__}\"", "\n", "self", ".", "config", "=", "self", ".", "model", ".", "config", "\n", "", "else", ":", "\n", "            ", "self", ".", "config", "=", "config", "\n", "\n", "", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "vocab_size", "=", "self", ".", "config", ".", "tgt_vocab_size", "if", "isinstance", "(", "self", ".", "config", ",", "FSMTConfig", ")", "else", "self", ".", "config", ".", "vocab_size", "\n", "self", ".", "topic_num", "=", "topic_num", "\n", "self", ".", "loss_alpha", "=", "alpha", "\n", "self", ".", "loss_beta", "=", "beta", "\n", "self", ".", "topic_vocab_size", "=", "topic_vocab_size", "\n", "self", ".", "id2token", "=", "id2token", "\n", "self", ".", "topic_word", "=", "None", "\n", "self", ".", "topic_vocab", "=", "topic_vocab", "\n", "\n", "if", "self", ".", "args", ".", "label_smoothing", "!=", "0", "or", "(", "self", ".", "data_args", "is", "not", "None", "and", "self", ".", "data_args", ".", "ignore_pad_token_for_loss", ")", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"Make sure that `config.pad_token_id` is correcly defined when ignoring `pad_token` for loss calculation or doing label smoothing.\"", "\n", "\n", "", "if", "self", ".", "config", ".", "pad_token_id", "is", "None", "and", "self", ".", "config", ".", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The `config.pad_token_id` is `None`. Using `config.eos_token_id` = {self.config.eos_token_id} for padding..\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "label_smoothing", "==", "0", ":", "\n", "            ", "self", ".", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "self", ".", "config", ".", "pad_token_id", ")", "\n", "", "else", ":", "\n", "# dynamically import label_smoothed_nll_loss", "\n", "            ", "from", "utils", "import", "label_smoothed_nll_loss", "\n", "\n", "self", ".", "loss_fn", "=", "label_smoothed_nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.create_optimizer_and_scheduler": [[113, 156], ["taas_seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler", "logger.warn", "OSS", "optimizer_cls", "taas_seq2seq_trainer.Seq2SeqTrainer.model.named_parameters", "taas_seq2seq_trainer.Seq2SeqTrainer.model.named_parameters", "any", "any"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler"], ["", "", "def", "create_optimizer_and_scheduler", "(", "self", ",", "num_training_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Setup the optimizer and the learning rate scheduler.\n\n        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n        Trainer's init through :obj:`optimizers`, or subclass and override this method in a subclass.\n        \"\"\"", "\n", "if", "self", ".", "optimizer", "is", "None", ":", "\n", "            ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer_cls", "=", "Adafactor", "if", "self", ".", "args", ".", "adafactor", "else", "AdamW", "\n", "if", "self", ".", "args", ".", "adafactor", ":", "\n", "                ", "optimizer_cls", "=", "Adafactor", "\n", "optimizer_kwargs", "=", "{", "\"scale_parameter\"", ":", "False", ",", "\"relative_step\"", ":", "False", "}", "\n", "", "else", ":", "\n", "                ", "optimizer_cls", "=", "AdamW", "\n", "optimizer_kwargs", "=", "{", "\n", "\"betas\"", ":", "(", "self", ".", "args", ".", "adam_beta1", ",", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "\"eps\"", ":", "self", ".", "args", ".", "adam_epsilon", ",", "\n", "}", "\n", "", "optimizer_kwargs", "[", "\"lr\"", "]", "=", "self", ".", "args", ".", "learning_rate", "\n", "if", "self", ".", "sharded_dpp", ":", "\n", "                ", "self", ".", "optimizer", "=", "OSS", "(", "\n", "params", "=", "optimizer_grouped_parameters", ",", "\n", "optim", "=", "optimizer_cls", ",", "\n", "**", "optimizer_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer", "=", "optimizer_cls", "(", "optimizer_grouped_parameters", ",", "**", "optimizer_kwargs", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "self", ".", "_get_lr_scheduler", "(", "num_training_steps", ")", "\n", "", "else", ":", "# ignoring --lr_scheduler", "\n", "            ", "logger", ".", "warn", "(", "\"scheduler is passed to `Seq2SeqTrainer`, `--lr_scheduler` arg is ignored.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler": [[157, 168], ["schedule_func", "schedule_func", "schedule_func"], "methods", ["None"], ["", "", "def", "_get_lr_scheduler", "(", "self", ",", "num_training_steps", ")", ":", "\n", "        ", "schedule_func", "=", "arg_to_scheduler", "[", "self", ".", "args", ".", "lr_scheduler", "]", "\n", "if", "self", ".", "args", ".", "lr_scheduler", "==", "\"constant\"", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "self", ".", "optimizer", ")", "\n", "", "elif", "self", ".", "args", ".", "lr_scheduler", "==", "\"constant_w_warmup\"", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ")", "\n", "", "else", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_training_steps", "\n", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._get_train_sampler": [[169, 185], ["isinstance", "transformers.file_utils.is_torch_tpu_available", "transformers.trainer_pt_utils.get_tpu_sampler", "taas_seq2seq_trainer.Seq2SeqTrainer.train_dataset.make_sortish_sampler", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_sortish_sampler"], ["", "def", "_get_train_sampler", "(", "self", ")", "->", "Optional", "[", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "Sampler", "]", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "train_dataset", ",", "torch", ".", "utils", ".", "data", ".", "IterableDataset", ")", ":", "\n", "            ", "return", "None", "\n", "", "elif", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "return", "get_tpu_sampler", "(", "self", ".", "train_dataset", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "sortish_sampler", ":", "\n", "                ", "self", ".", "train_dataset", ".", "make_sortish_sampler", "(", "\n", "self", ".", "args", ".", "per_device_train_batch_size", ",", "\n", "distributed", "=", "(", "self", ".", "args", ".", "parallel_mode", "==", "ParallelMode", ".", "DISTRIBUTED", ")", ",", "\n", ")", "\n", "\n", "", "return", "(", "\n", "RandomSampler", "(", "self", ".", "train_dataset", ")", "\n", "if", "self", ".", "args", ".", "local_rank", "==", "-", "1", "\n", "else", "DistributedSampler", "(", "self", ".", "train_dataset", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._compute_loss": [[187, 202], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "taas_seq2seq_trainer.Seq2SeqTrainer.loss_fn", "taas_seq2seq_trainer.Seq2SeqTrainer.loss_fn", "model", "model", "logits.view", "labels.view", "model"], "methods", ["None"], ["", "", "def", "_compute_loss", "(", "self", ",", "model", ",", "inputs", ",", "labels", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "label_smoothing", "==", "0", ":", "\n", "            ", "if", "self", ".", "data_args", "is", "not", "None", "and", "self", ".", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "# force training to ignore pad token", "\n", "                ", "logits", "=", "model", "(", "**", "inputs", ",", "use_cache", "=", "False", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "shape", "[", "-", "1", "]", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "# compute usual loss via models", "\n", "                ", "loss", ",", "logits", "=", "model", "(", "**", "inputs", ",", "labels", "=", "labels", ",", "use_cache", "=", "False", ")", "[", ":", "2", "]", "\n", "", "", "else", ":", "\n", "# compute label smoothed loss", "\n", "            ", "logits", "=", "model", "(", "**", "inputs", ",", "use_cache", "=", "False", ")", "[", "0", "]", "\n", "lprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", ",", "_", "=", "self", ".", "loss_fn", "(", "lprobs", ",", "labels", ",", "self", ".", "args", ".", "label_smoothing", ",", "ignore_index", "=", "self", ".", "config", ".", "pad_token_id", ")", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.compute_loss": [[203, 207], ["inputs.pop", "taas_seq2seq_trainer.Seq2SeqTrainer._compute_loss"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._compute_loss"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "labels", "=", "inputs", ".", "pop", "(", "\"labels\"", ")", "\n", "loss", ",", "_", "=", "self", ".", "_compute_loss", "(", "model", ",", "inputs", ",", "labels", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.prediction_step": [[208, 290], ["all", "taas_seq2seq_trainer.Seq2SeqTrainer._prepare_inputs", "transformers.trainer_pt_utils.nested_detach", "hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "len", "transformers.trainer_pt_utils.nested_detach", "getattr", "model", "isinstance", "isinstance", "tuple", "len", "taas_seq2seq_trainer.Seq2SeqTrainer.get", "autocast", "model", "taas_seq2seq_trainer.Seq2SeqTrainer.label_smoother().mean().detach", "tuple", "tuple", "taas_seq2seq_trainer.Seq2SeqTrainer.get", "taas_seq2seq_trainer.Seq2SeqTrainer.label_smoother().mean", "outputs.items", "outputs.items", "taas_seq2seq_trainer.Seq2SeqTrainer.label_smoother", "isinstance"], "methods", ["None"], ["", "def", "prediction_step", "(", "\n", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ",", "\n", "prediction_loss_only", ":", "bool", ",", "\n", "ignore_keys", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Optional", "[", "float", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Perform an evaluation step on :obj:`model` using obj:`inputs`.\n\n        Subclass and override to inject custom behavior.\n\n        Args:\n            model (:obj:`nn.Module`):\n                The model to evaluate.\n            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n                The inputs and targets of the model.\n\n                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n            prediction_loss_only (:obj:`bool`):\n                Whether or not to return the loss only.\n\n        Return:\n            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n            A tuple with the loss, logits and labels (each being optional).\n        \"\"\"", "\n", "has_labels", "=", "all", "(", "inputs", ".", "get", "(", "k", ")", "is", "not", "None", "for", "k", "in", "self", ".", "label_names", ")", "\n", "\n", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "if", "ignore_keys", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "model", ",", "\"config\"", ")", ":", "\n", "                ", "ignore_keys", "=", "getattr", "(", "self", ".", "model", ".", "config", ",", "\"keys_to_ignore_at_inference\"", ",", "[", "]", ")", "\n", "", "else", ":", "\n", "                ", "ignore_keys", "=", "[", "]", "\n", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "use_amp", ":", "\n", "                ", "with", "autocast", "(", ")", ":", "\n", "                    ", "outputs", ",", "loss_topic_modeling", ",", "self", ".", "topic_word", "=", "model", "(", "**", "inputs", ")", "\n", "", "", "else", ":", "\n", "                ", "outputs", ",", "loss_topic_modeling", ",", "self", ".", "topic_word", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "if", "has_labels", ":", "\n", "                ", "if", "self", ".", "label_smoother", "is", "not", "None", "and", "\"labels\"", "in", "inputs", ":", "\n", "                    ", "loss", "=", "self", ".", "label_smoother", "(", "outputs", ",", "inputs", "[", "\"labels\"", "]", ")", ".", "mean", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "(", "outputs", "[", "\"loss\"", "]", "if", "isinstance", "(", "outputs", ",", "dict", ")", "else", "outputs", "[", "0", "]", ")", ".", "mean", "(", ")", ".", "detach", "(", ")", "\n", "", "if", "isinstance", "(", "outputs", ",", "dict", ")", ":", "\n", "                    ", "logits", "=", "tuple", "(", "v", "for", "k", ",", "v", "in", "outputs", ".", "items", "(", ")", "if", "k", "not", "in", "ignore_keys", "+", "[", "\"loss\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "outputs", "[", "1", ":", "]", "\n", "", "", "else", ":", "\n", "                ", "loss", "=", "None", "\n", "if", "isinstance", "(", "outputs", ",", "dict", ")", ":", "\n", "                    ", "logits", "=", "tuple", "(", "v", "for", "k", ",", "v", "in", "outputs", ".", "items", "(", ")", "if", "k", "not", "in", "ignore_keys", ")", "\n", "", "else", ":", "\n", "                    ", "logits", "=", "outputs", "\n", "\n", "", "", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "                ", "self", ".", "_past", "=", "outputs", "[", "self", ".", "args", ".", "past_index", "if", "has_labels", "else", "self", ".", "args", ".", "past_index", "-", "1", "]", "\n", "\n", "# if beta=0, we use the loss from topic modeling", "\n", "# if self.loss_beta == 0:", "\n", "#     loss = loss_topic_modeling", "\n", "", "", "loss", "=", "self", ".", "loss_alpha", "*", "loss_topic_modeling", "+", "self", ".", "loss_beta", "*", "loss", "\n", "\n", "if", "prediction_loss_only", ":", "\n", "            ", "return", "(", "loss", ",", "None", ",", "None", ")", "\n", "\n", "", "logits", "=", "nested_detach", "(", "logits", ")", "\n", "if", "len", "(", "logits", ")", "==", "1", ":", "\n", "            ", "logits", "=", "logits", "[", "0", "]", "\n", "\n", "", "if", "has_labels", ":", "\n", "            ", "labels", "=", "nested_detach", "(", "tuple", "(", "inputs", ".", "get", "(", "name", ")", "for", "name", "in", "self", ".", "label_names", ")", ")", "\n", "if", "len", "(", "labels", ")", "==", "1", ":", "\n", "                ", "labels", "=", "labels", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "labels", "=", "None", "\n", "\n", "", "return", "(", "loss", ",", "logits", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len": [[291, 305], ["ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "_pad_tensors_to_max_len", "(", "self", ",", "tensor", ",", "max_length", ")", ":", "\n", "# If PAD token is not defined at least EOS token has to be defined", "\n", "        ", "pad_token_id", "=", "self", ".", "config", ".", "pad_token_id", "if", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "\n", "if", "pad_token_id", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Make sure that either `config.pad_token_id` or `config.eos_token_id` is defined if tensor has to be padded to `max_length`={max_length}\"", "\n", ")", "\n", "\n", "", "padded_tensor", "=", "pad_token_id", "*", "torch", ".", "ones", "(", "\n", "(", "tensor", ".", "shape", "[", "0", "]", ",", "max_length", ")", ",", "dtype", "=", "tensor", ".", "dtype", ",", "device", "=", "tensor", ".", "device", "\n", ")", "\n", "padded_tensor", "[", ":", ",", ":", "tensor", ".", "shape", "[", "-", "1", "]", "]", "=", "tensor", "\n", "return", "padded_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._save_checkpoint": [[306, 362], ["hasattr", "os.path.join", "taas_seq2seq_trainer.Seq2SeqTrainer.store_flos", "taas_seq2seq_trainer.Seq2SeqTrainer.save_model", "os.path.isdir", "taas_seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "taas_seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "taas_seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "taas_seq2seq_trainer.Seq2SeqTrainer.save_topic", "taas_seq2seq_trainer.Seq2SeqTrainer.save_topic_vocab", "torch.save", "torch.save", "torch.save", "torch.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "taas_seq2seq_trainer.Seq2SeqTrainer.state.save_to_json", "taas_seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints", "taas_seq2seq_trainer.Seq2SeqTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "torch.save", "torch.save", "torch.save", "torch.save", "metric_to_check.startswith", "operator", "os.path.join", "numpy.round", "taas_seq2seq_trainer.Seq2SeqTrainer.lr_scheduler.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.save_topic", "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.save_topic_vocab", "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints"], ["", "def", "_save_checkpoint", "(", "self", ",", "model", ",", "trial", ",", "metrics", "=", "None", ")", ":", "\n", "# In all cases (even distributed/parallel), self.model is always a reference", "\n", "# to the model we want to save.", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "            ", "assert", "model", ".", "module", "is", "self", ".", "model", ",", "f\"Module {model.module} should be a reference to self.model\"", "\n", "", "else", ":", "\n", "            ", "assert", "model", "is", "self", ".", "model", ",", "f\"Model {model} should be a reference to self.model\"", "\n", "\n", "# Save model checkpoint", "\n", "", "checkpoint_folder", "=", "f\"val_avg_loss-{'%.4f' % np.round(metrics['eval_loss'], 4)}-step-{self.state.global_step}\"", "\n", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "checkpoint_folder", ")", "\n", "\n", "self", ".", "store_flos", "(", ")", "\n", "# save the checkpoint", "\n", "self", ".", "save_model", "(", "output_dir", ")", "\n", "\n", "# save the topic", "\n", "if", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "# todo: hard code k", "\n", "            ", "self", ".", "save_topic", "(", "output_dir", ",", "vocab_size", "=", "self", ".", "vocab_size", ",", "k", "=", "10", ")", "\n", "\n", "# save topic_vocab", "\n", "self", ".", "save_topic_vocab", "(", "output_dir", ")", "\n", "\n", "# Save optimizer and scheduler", "\n", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                ", "torch", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "\n", "# Determine the new best metric / best model checkpoint", "\n", "", "if", "metrics", "is", "not", "None", "and", "self", ".", "args", ".", "metric_for_best_model", "is", "not", "None", ":", "\n", "            ", "metric_to_check", "=", "self", ".", "args", ".", "metric_for_best_model", "\n", "if", "not", "metric_to_check", ".", "startswith", "(", "\"eval_\"", ")", ":", "\n", "                ", "metric_to_check", "=", "f\"eval_{metric_to_check}\"", "\n", "", "metric_value", "=", "metrics", "[", "metric_to_check", "]", "\n", "\n", "operator", "=", "np", ".", "greater", "if", "self", ".", "args", ".", "greater_is_better", "else", "np", ".", "less", "\n", "if", "(", "\n", "self", ".", "state", ".", "best_metric", "is", "None", "\n", "or", "self", ".", "state", ".", "best_model_checkpoint", "is", "None", "\n", "or", "operator", "(", "metric_value", ",", "self", ".", "state", ".", "best_metric", ")", "\n", ")", ":", "\n", "                ", "self", ".", "state", ".", "best_metric", "=", "metric_value", "\n", "self", ".", "state", ".", "best_model_checkpoint", "=", "output_dir", "\n", "\n", "# Save the Trainer state", "\n", "", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "self", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Maybe delete some older checkpoints.", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "self", ".", "_rotate_checkpoints", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints": [[363, 372], ["str", "float", "pathlib.Path().glob", "re.search().group", "sorted", "checkpoints_sorted.items", "pathlib.Path", "re.search"], "methods", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "self", ",", "checkpoint_prefix", "=", "\"val_avg_loss\"", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "glob_checkpoints", "=", "[", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "self", ".", "args", ".", "output_dir", ")", ".", "glob", "(", "f\"{checkpoint_prefix}-*\"", ")", "]", "\n", "# get the loss based on its name", "\n", "checkpoints_sorted", "=", "{", "}", "\n", "for", "checkpoint", "in", "glob_checkpoints", ":", "\n", "            ", "checkpoints_sorted", "[", "checkpoint", "]", "=", "float", "(", "re", ".", "search", "(", "f'{checkpoint_prefix}-(.+?)-'", ",", "checkpoint", ")", ".", "group", "(", "1", ")", ")", "\n", "# sort the dictionary based on the value - loss", "\n", "", "checkpoints_sorted_name", "=", "[", "k", "for", "k", ",", "v", "in", "sorted", "(", "checkpoints_sorted", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ")", "]", "\n", "return", "checkpoints_sorted_name", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints": [[373, 387], ["taas_seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints", "len", "logger.info", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "args", ".", "save_total_limit", "is", "None", "or", "self", ".", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "            ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "self", ".", "_sorted_checkpoints", "(", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "self", ".", "args", ".", "save_total_limit", ":", "\n", "            ", "return", "\n", "", "saved_checkpoints", "=", "checkpoints_sorted", "[", ":", "self", ".", "args", ".", "save_total_limit", "]", "\n", "\n", "for", "checkpoint", "in", "checkpoints_sorted", ":", "\n", "            ", "if", "checkpoint", "not", "in", "saved_checkpoints", ":", "\n", "                ", "logger", ".", "info", "(", "\"Deleting checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.training_step": [[388, 435], ["model.train", "taas_seq2seq_trainer.Seq2SeqTrainer._prepare_inputs", "taas_seq2seq_trainer.Seq2SeqTrainer.detach", "taas_seq2seq_trainer.Seq2SeqTrainer.training_compute_loss", "taas_seq2seq_trainer.Seq2SeqTrainer.mean", "taas_seq2seq_trainer.Seq2SeqTrainer.scaler.scale().backward", "autocast", "taas_seq2seq_trainer.Seq2SeqTrainer.training_compute_loss", "taas_seq2seq_trainer.Seq2SeqTrainer.scaler.scale", "amp.scale_loss", "scaled_loss.backward", "taas_seq2seq_trainer.Seq2SeqTrainer.model_wrapped.module.backward", "taas_seq2seq_trainer.Seq2SeqTrainer.backward"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.training_compute_loss", "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.training_compute_loss"], ["", "", "", "def", "training_step", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Perform a training step on a batch of inputs.\n\n        Subclass and override to inject custom behavior.\n\n        Args:\n            model (:obj:`nn.Module`):\n                The model to train.\n            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n                The inputs and targets of the model.\n\n                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n\n        Return:\n            :obj:`torch.Tensor`: The tensor with training loss on this batch.\n        \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "# here inputs contains the last hidden states from the encoder", "\n", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "\n", "if", "self", ".", "use_amp", ":", "\n", "            ", "with", "autocast", "(", ")", ":", "\n", "                ", "loss", "=", "self", ".", "training_compute_loss", "(", "model", ",", "inputs", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "training_compute_loss", "(", "model", ",", "inputs", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "if", "self", ".", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "self", ".", "use_amp", ":", "\n", "            ", "self", ".", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "elif", "self", ".", "use_apex", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "elif", "self", ".", "deepspeed", ":", "\n", "# calling on DS engine (model_wrapped == DDP(Deepspeed(PretrainedModule)))", "\n", "            ", "self", ".", "model_wrapped", ".", "module", ".", "backward", "(", "loss", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "return", "loss", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.training_compute_loss": [[436, 455], ["model", "isinstance"], "methods", ["None"], ["", "def", "training_compute_loss", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n\n        Subclass and override for custom behavior.\n        \"\"\"", "\n", "outputs", ",", "loss_topic_modeling", ",", "self", ".", "topic_word", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "# Save past state if it exists", "\n", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "            ", "self", ".", "_past", "=", "outputs", "[", "self", ".", "args", ".", "past_index", "]", "\n", "\n", "# loss from language modeling", "\n", "", "loss_lm", "=", "outputs", "[", "\"loss\"", "]", "if", "isinstance", "(", "outputs", ",", "dict", ")", "else", "outputs", "[", "0", "]", "\n", "\n", "# final loss: alpha * topic modeling + beta * lm", "\n", "loss", "=", "self", ".", "loss_alpha", "*", "loss_topic_modeling", "+", "self", ".", "loss_beta", "*", "loss_lm", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.get_topic_lists": [[456, 470], ["torch.topk", "torch.topk", "torch.topk", "torch.topk", "topics.append", "idxs.cpu().numpy().tolist", "idxs.cpu().numpy", "idxs.cpu"], "methods", ["None"], ["", "def", "get_topic_lists", "(", "self", ",", "vocab_size", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Retrieve the lists of topic words.\n\n        :param k: (int) number of words to return per topic, default 10.\n        \"\"\"", "\n", "assert", "k", "<=", "vocab_size", ",", "\"k must be <= input size.\"", "\n", "component_dists", "=", "self", ".", "topic_word", "\n", "topics", "=", "[", "]", "\n", "for", "row", "in", "component_dists", ":", "\n", "            ", "_", ",", "idxs", "=", "torch", ".", "topk", "(", "row", ",", "k", ")", "\n", "component_words", "=", "[", "self", ".", "id2token", "[", "idx", "]", "for", "idx", "in", "idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "]", "\n", "topics", ".", "append", "(", "component_words", ")", "\n", "", "return", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.save_topic": [[471, 483], ["taas_seq2seq_trainer.Seq2SeqTrainer.get_topic_lists", "open", "enumerate", "f.write"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.get_topic_lists"], ["", "def", "save_topic", "(", "self", ",", "output_dir", ",", "vocab_size", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Save the topic to topics.txt\n        :param output_dir: save path\n        :param vocab_size: size of the vocabulary used for topic modeling\n        :param k: for each topic, we find the most relevant k words\n        :return:\n        \"\"\"", "\n", "topics", "=", "self", ".", "get_topic_lists", "(", "vocab_size", "=", "vocab_size", ",", "k", "=", "k", ")", "\n", "with", "open", "(", "f\"{output_dir}/topics.txt\"", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "topic", "in", "enumerate", "(", "topics", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"Topic {i + 1}: {topic}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.taas_seq2seq_trainer.Seq2SeqTrainer.save_topic_vocab": [[484, 491], ["open", "f.write"], "methods", ["None"], ["", "", "", "def", "save_topic_vocab", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "\"\"\"\n        Save the pre-defined vocab for topic modeling\n        \"\"\"", "\n", "with", "open", "(", "f\"{output_dir}/topic-vocab.txt\"", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "for", "word", "in", "self", ".", "topic_vocab", ":", "\n", "                ", "f", ".", "write", "(", "f\"{word}\\n\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer.__init__": [[60, 91], ["transformers.Trainer.__init__", "isinstance", "isinstance", "logger.warn", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", "=", "None", ",", "data_args", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "config", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "\n", "self", ".", "model", ",", "PreTrainedModel", "\n", ")", ",", "f\"If no `config` is passed the model to be trained has to be of type `PreTrainedModel`, but is {self.model.__class__}\"", "\n", "self", ".", "config", "=", "self", ".", "model", ".", "config", "\n", "", "else", ":", "\n", "            ", "self", ".", "config", "=", "config", "\n", "\n", "", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "vocab_size", "=", "self", ".", "config", ".", "tgt_vocab_size", "if", "isinstance", "(", "self", ".", "config", ",", "FSMTConfig", ")", "else", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "self", ".", "args", ".", "label_smoothing", "!=", "0", "or", "(", "self", ".", "data_args", "is", "not", "None", "and", "self", ".", "data_args", ".", "ignore_pad_token_for_loss", ")", ":", "\n", "            ", "assert", "(", "\n", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"Make sure that `config.pad_token_id` is correcly defined when ignoring `pad_token` for loss calculation or doing label smoothing.\"", "\n", "\n", "", "if", "self", ".", "config", ".", "pad_token_id", "is", "None", "and", "self", ".", "config", ".", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The `config.pad_token_id` is `None`. Using `config.eos_token_id` = {self.config.eos_token_id} for padding..\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "label_smoothing", "==", "0", ":", "\n", "            ", "self", ".", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "self", ".", "config", ".", "pad_token_id", ")", "\n", "", "else", ":", "\n", "# dynamically import label_smoothed_nll_loss", "\n", "            ", "from", "utils", "import", "label_smoothed_nll_loss", "\n", "\n", "self", ".", "loss_fn", "=", "label_smoothed_nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer.create_optimizer_and_scheduler": [[92, 135], ["seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler", "logger.warn", "OSS", "optimizer_cls", "seq2seq_trainer.Seq2SeqTrainer.model.named_parameters", "seq2seq_trainer.Seq2SeqTrainer.model.named_parameters", "any", "any"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler"], ["", "", "def", "create_optimizer_and_scheduler", "(", "self", ",", "num_training_steps", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Setup the optimizer and the learning rate scheduler.\n\n        We provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\n        Trainer's init through :obj:`optimizers`, or subclass and override this method in a subclass.\n        \"\"\"", "\n", "if", "self", ".", "optimizer", "is", "None", ":", "\n", "            ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer_cls", "=", "Adafactor", "if", "self", ".", "args", ".", "adafactor", "else", "AdamW", "\n", "if", "self", ".", "args", ".", "adafactor", ":", "\n", "                ", "optimizer_cls", "=", "Adafactor", "\n", "optimizer_kwargs", "=", "{", "\"scale_parameter\"", ":", "False", ",", "\"relative_step\"", ":", "False", "}", "\n", "", "else", ":", "\n", "                ", "optimizer_cls", "=", "AdamW", "\n", "optimizer_kwargs", "=", "{", "\n", "\"betas\"", ":", "(", "self", ".", "args", ".", "adam_beta1", ",", "self", ".", "args", ".", "adam_beta2", ")", ",", "\n", "\"eps\"", ":", "self", ".", "args", ".", "adam_epsilon", ",", "\n", "}", "\n", "", "optimizer_kwargs", "[", "\"lr\"", "]", "=", "self", ".", "args", ".", "learning_rate", "\n", "if", "self", ".", "sharded_dpp", ":", "\n", "                ", "self", ".", "optimizer", "=", "OSS", "(", "\n", "params", "=", "optimizer_grouped_parameters", ",", "\n", "optim", "=", "optimizer_cls", ",", "\n", "**", "optimizer_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer", "=", "optimizer_cls", "(", "optimizer_grouped_parameters", ",", "**", "optimizer_kwargs", ")", "\n", "\n", "", "", "if", "self", ".", "lr_scheduler", "is", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", "=", "self", ".", "_get_lr_scheduler", "(", "num_training_steps", ")", "\n", "", "else", ":", "# ignoring --lr_scheduler", "\n", "            ", "logger", ".", "warn", "(", "\"scheduler is passed to `Seq2SeqTrainer`, `--lr_scheduler` arg is ignored.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._get_lr_scheduler": [[136, 147], ["schedule_func", "schedule_func", "schedule_func"], "methods", ["None"], ["", "", "def", "_get_lr_scheduler", "(", "self", ",", "num_training_steps", ")", ":", "\n", "        ", "schedule_func", "=", "arg_to_scheduler", "[", "self", ".", "args", ".", "lr_scheduler", "]", "\n", "if", "self", ".", "args", ".", "lr_scheduler", "==", "\"constant\"", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "self", ".", "optimizer", ")", "\n", "", "elif", "self", ".", "args", ".", "lr_scheduler", "==", "\"constant_w_warmup\"", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ")", "\n", "", "else", ":", "\n", "            ", "scheduler", "=", "schedule_func", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_training_steps", "\n", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._get_train_sampler": [[148, 164], ["isinstance", "transformers.file_utils.is_torch_tpu_available", "transformers.trainer_pt_utils.get_tpu_sampler", "seq2seq_trainer.Seq2SeqTrainer.train_dataset.make_sortish_sampler", "torch.utils.data.RandomSampler", "torch.utils.data.DistributedSampler"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_sortish_sampler"], ["", "def", "_get_train_sampler", "(", "self", ")", "->", "Optional", "[", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "Sampler", "]", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "train_dataset", ",", "torch", ".", "utils", ".", "data", ".", "IterableDataset", ")", ":", "\n", "            ", "return", "None", "\n", "", "elif", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "return", "get_tpu_sampler", "(", "self", ".", "train_dataset", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "sortish_sampler", ":", "\n", "                ", "self", ".", "train_dataset", ".", "make_sortish_sampler", "(", "\n", "self", ".", "args", ".", "per_device_train_batch_size", ",", "\n", "distributed", "=", "(", "self", ".", "args", ".", "parallel_mode", "==", "ParallelMode", ".", "DISTRIBUTED", ")", ",", "\n", ")", "\n", "\n", "", "return", "(", "\n", "RandomSampler", "(", "self", ".", "train_dataset", ")", "\n", "if", "self", ".", "args", ".", "local_rank", "==", "-", "1", "\n", "else", "DistributedSampler", "(", "self", ".", "train_dataset", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._compute_loss": [[166, 181], ["torch.nn.functional.log_softmax", "seq2seq_trainer.Seq2SeqTrainer.loss_fn", "seq2seq_trainer.Seq2SeqTrainer.loss_fn", "model", "model", "logits.view", "labels.view", "model"], "methods", ["None"], ["", "", "def", "_compute_loss", "(", "self", ",", "model", ",", "inputs", ",", "labels", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "label_smoothing", "==", "0", ":", "\n", "            ", "if", "self", ".", "data_args", "is", "not", "None", "and", "self", ".", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "# force training to ignore pad token", "\n", "                ", "logits", "=", "model", "(", "**", "inputs", ",", "use_cache", "=", "False", ")", "[", "0", "]", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "shape", "[", "-", "1", "]", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "# compute usual loss via models", "\n", "                ", "loss", ",", "logits", "=", "model", "(", "**", "inputs", ",", "labels", "=", "labels", ",", "use_cache", "=", "False", ")", "[", ":", "2", "]", "\n", "", "", "else", ":", "\n", "# compute label smoothed loss", "\n", "            ", "logits", "=", "model", "(", "**", "inputs", ",", "use_cache", "=", "False", ")", "[", "0", "]", "\n", "lprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", ",", "_", "=", "self", ".", "loss_fn", "(", "lprobs", ",", "labels", ",", "self", ".", "args", ".", "label_smoothing", ",", "ignore_index", "=", "self", ".", "config", ".", "pad_token_id", ")", "\n", "", "return", "loss", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer.compute_loss": [[182, 186], ["inputs.pop", "seq2seq_trainer.Seq2SeqTrainer._compute_loss"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._compute_loss"], ["", "def", "compute_loss", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "labels", "=", "inputs", ".", "pop", "(", "\"labels\"", ")", "\n", "loss", ",", "_", "=", "self", ".", "_compute_loss", "(", "model", ",", "inputs", ",", "labels", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer.prediction_step": [[187, 248], ["seq2seq_trainer.Seq2SeqTrainer._prepare_inputs", "seq2seq_trainer.Seq2SeqTrainer.pop", "loss.mean().detach.mean().detach.mean().detach", "seq2seq_trainer.Seq2SeqTrainer.model.generate", "torch.no_grad", "seq2seq_trainer.Seq2SeqTrainer._compute_loss", "seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len", "seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len", "loss.mean().detach.mean().detach.mean"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.generate", "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._compute_loss", "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len", "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len"], ["", "def", "prediction_step", "(", "\n", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "inputs", ":", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ",", "\n", "prediction_loss_only", ":", "bool", ",", "\n", "ignore_keys", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Optional", "[", "float", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Optional", "[", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Perform an evaluation step on :obj:`model` using obj:`inputs`.\n\n        Subclass and override to inject custom behavior.\n\n        Args:\n            model (:obj:`nn.Module`):\n                The model to evaluate.\n            inputs (:obj:`Dict[str, Union[torch.Tensor, Any]]`):\n                The inputs and targets of the model.\n\n                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n                argument :obj:`labels`. Check your model's documentation for all accepted arguments.\n            prediction_loss_only (:obj:`bool`):\n                Whether or not to return the loss only.\n\n        Return:\n            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n            A tuple with the loss, logits and labels (each being optional).\n        \"\"\"", "\n", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "\n", "gen_kwargs", "=", "{", "\n", "\"max_length\"", ":", "self", ".", "data_args", ".", "val_max_target_length", "\n", "if", "self", ".", "data_args", "is", "not", "None", "\n", "else", "self", ".", "config", ".", "max_length", ",", "\n", "\"num_beams\"", ":", "self", ".", "data_args", ".", "eval_beams", "if", "self", ".", "data_args", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", ",", "\n", "}", "\n", "\n", "if", "self", ".", "args", ".", "predict_with_generate", "and", "not", "self", ".", "args", ".", "prediction_loss_only", ":", "\n", "            ", "generated_tokens", "=", "self", ".", "model", ".", "generate", "(", "\n", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "**", "gen_kwargs", ",", "\n", ")", "\n", "# in case the batch is shorter than max length, the output should be padded", "\n", "if", "generated_tokens", ".", "shape", "[", "-", "1", "]", "<", "gen_kwargs", "[", "\"max_length\"", "]", ":", "\n", "                ", "generated_tokens", "=", "self", ".", "_pad_tensors_to_max_len", "(", "generated_tokens", ",", "gen_kwargs", "[", "\"max_length\"", "]", ")", "\n", "\n", "", "", "labels", "=", "inputs", ".", "pop", "(", "\"labels\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# compute loss on predict data", "\n", "            ", "loss", ",", "logits", "=", "self", ".", "_compute_loss", "(", "model", ",", "inputs", ",", "labels", ")", "\n", "\n", "", "loss", "=", "loss", ".", "mean", "(", ")", ".", "detach", "(", ")", "\n", "if", "self", ".", "args", ".", "prediction_loss_only", ":", "\n", "            ", "return", "(", "loss", ",", "None", ",", "None", ")", "\n", "\n", "", "logits", "=", "generated_tokens", "if", "self", ".", "args", ".", "predict_with_generate", "else", "logits", "\n", "\n", "if", "labels", ".", "shape", "[", "-", "1", "]", "<", "gen_kwargs", "[", "\"max_length\"", "]", ":", "\n", "            ", "labels", "=", "self", ".", "_pad_tensors_to_max_len", "(", "labels", ",", "gen_kwargs", "[", "\"max_length\"", "]", ")", "\n", "\n", "", "return", "(", "loss", ",", "logits", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._pad_tensors_to_max_len": [[249, 263], ["ValueError", "torch.ones"], "methods", ["None"], ["", "def", "_pad_tensors_to_max_len", "(", "self", ",", "tensor", ",", "max_length", ")", ":", "\n", "# If PAD token is not defined at least EOS token has to be defined", "\n", "        ", "pad_token_id", "=", "self", ".", "config", ".", "pad_token_id", "if", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "\n", "if", "pad_token_id", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Make sure that either `config.pad_token_id` or `config.eos_token_id` is defined if tensor has to be padded to `max_length`={max_length}\"", "\n", ")", "\n", "\n", "", "padded_tensor", "=", "pad_token_id", "*", "torch", ".", "ones", "(", "\n", "(", "tensor", ".", "shape", "[", "0", "]", ",", "max_length", ")", ",", "dtype", "=", "tensor", ".", "dtype", ",", "device", "=", "tensor", ".", "device", "\n", ")", "\n", "padded_tensor", "[", ":", ",", ":", "tensor", ".", "shape", "[", "-", "1", "]", "]", "=", "tensor", "\n", "return", "padded_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._save_checkpoint": [[264, 311], ["hasattr", "os.path.join", "seq2seq_trainer.Seq2SeqTrainer.store_flos", "seq2seq_trainer.Seq2SeqTrainer.save_model", "seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "seq2seq_trainer.Seq2SeqTrainer.is_world_process_zero", "torch.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "seq2seq_trainer.Seq2SeqTrainer.state.save_to_json", "seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints", "seq2seq_trainer.Seq2SeqTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "torch.save", "metric_to_check.startswith", "operator", "os.path.join", "numpy.round", "seq2seq_trainer.Seq2SeqTrainer.lr_scheduler.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints"], ["", "def", "_save_checkpoint", "(", "self", ",", "model", ",", "trial", ",", "metrics", "=", "None", ")", ":", "\n", "# In all cases (even distributed/parallel), self.model is always a reference", "\n", "# to the model we want to save.", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "            ", "assert", "model", ".", "module", "is", "self", ".", "model", ",", "f\"Module {model.module} should be a reference to self.model\"", "\n", "", "else", ":", "\n", "            ", "assert", "model", "is", "self", ".", "model", ",", "f\"Model {model} should be a reference to self.model\"", "\n", "\n", "# Save model checkpoint", "\n", "", "checkpoint_folder", "=", "f\"val_avg_loss-{'%.4f' % np.round(metrics['eval_loss'], 4)}-step-{self.state.global_step}\"", "\n", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "checkpoint_folder", ")", "\n", "\n", "self", ".", "store_flos", "(", ")", "\n", "self", ".", "save_model", "(", "output_dir", ")", "\n", "\n", "# Save optimizer and scheduler", "\n", "\n", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                ", "torch", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "\n", "# Determine the new best metric / best model checkpoint", "\n", "", "if", "metrics", "is", "not", "None", "and", "self", ".", "args", ".", "metric_for_best_model", "is", "not", "None", ":", "\n", "            ", "metric_to_check", "=", "self", ".", "args", ".", "metric_for_best_model", "\n", "if", "not", "metric_to_check", ".", "startswith", "(", "\"eval_\"", ")", ":", "\n", "                ", "metric_to_check", "=", "f\"eval_{metric_to_check}\"", "\n", "", "metric_value", "=", "metrics", "[", "metric_to_check", "]", "\n", "\n", "operator", "=", "np", ".", "greater", "if", "self", ".", "args", ".", "greater_is_better", "else", "np", ".", "less", "\n", "if", "(", "\n", "self", ".", "state", ".", "best_metric", "is", "None", "\n", "or", "self", ".", "state", ".", "best_model_checkpoint", "is", "None", "\n", "or", "operator", "(", "metric_value", ",", "self", ".", "state", ".", "best_metric", ")", "\n", ")", ":", "\n", "                ", "self", ".", "state", ".", "best_metric", "=", "metric_value", "\n", "self", ".", "state", ".", "best_model_checkpoint", "=", "output_dir", "\n", "\n", "# Save the Trainer state", "\n", "", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "self", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Maybe delete some older checkpoints.", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "self", ".", "_rotate_checkpoints", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints": [[313, 317], ["sorted", "str", "pathlib.Path().glob", "pathlib.Path"], "methods", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "self", ",", "checkpoint_prefix", "=", "\"val_avg_loss\"", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "glob_checkpoints", "=", "[", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "self", ".", "args", ".", "output_dir", ")", ".", "glob", "(", "f\"{checkpoint_prefix}-*\"", ")", "]", "\n", "checkpoints_sorted", "=", "sorted", "(", "glob_checkpoints", ")", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._rotate_checkpoints": [[318, 332], ["seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints", "len", "logger.info", "shutil.rmtree"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.seq2seq_trainer.Seq2SeqTrainer._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "args", ".", "save_total_limit", "is", "None", "or", "self", ".", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "            ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "self", ".", "_sorted_checkpoints", "(", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "self", ".", "args", ".", "save_total_limit", ":", "\n", "            ", "return", "\n", "", "saved_checkpoints", "=", "checkpoints_sorted", "[", ":", "self", ".", "args", ".", "save_total_limit", "]", "\n", "\n", "for", "checkpoint", "in", "checkpoints_sorted", ":", "\n", "            ", "if", "checkpoint", "not", "in", "saved_checkpoints", ":", "\n", "                ", "logger", ".", "info", "(", "\"Deleting checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.__init__": [[231, 241], ["transformers.models.bart.modeling_bart.BartPretrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformers.models.bart.modeling_bart.BartEncoder", "transformers.models.bart.modeling_bart.BartDecoder", "model.TAASModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "padding_idx", ",", "vocab_size", "=", "config", ".", "pad_token_id", ",", "config", ".", "vocab_size", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "config", ".", "d_model", ",", "padding_idx", ")", "\n", "# we use BartEncoder and BartDecoder", "\n", "self", ".", "encoder", "=", "BartEncoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "self", ".", "decoder", "=", "BartDecoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.get_input_embeddings": [[242, 244], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.set_input_embeddings": [[245, 249], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "shared", "=", "value", "\n", "self", ".", "encoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "self", ".", "decoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.get_encoder": [[250, 252], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.get_decoder": [[253, 255], ["None"], "methods", ["None"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASModel.forward": [[256, 337], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.add_code_sample_docstrings", "model.TAASModel.decoder", "transformers.modeling_outputs.Seq2SeqModelOutput", "model.shift_tokens_right", "model.TAASModel.encoder", "transformers.modeling_outputs.BaseModelOutput", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.shift_tokens_right"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "\"facebook/bart-large\"", ",", "\n", "output_type", "=", "Seq2SeqModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "\n", "# different to other models, Bart automatically creates decoder_input_ids from", "\n", "# input_ids if no decoder_input_ids are provided", "\n", "        ", "if", "decoder_input_ids", "is", "None", "and", "decoder_inputs_embeds", "is", "None", ":", "\n", "            ", "decoder_input_ids", "=", "shift_tokens_right", "(", "\n", "input_ids", ",", "self", ".", "config", ".", "pad_token_id", ",", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# encoder outputs", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True", "\n", "", "elif", "return_dict", "and", "not", "isinstance", "(", "encoder_outputs", ",", "BaseModelOutput", ")", ":", "\n", "            ", "encoder_outputs", "=", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "hidden_states", "=", "encoder_outputs", "[", "1", "]", "if", "len", "(", "encoder_outputs", ")", ">", "1", "else", "None", ",", "\n", "attentions", "=", "encoder_outputs", "[", "2", "]", "if", "len", "(", "encoder_outputs", ")", ">", "2", "else", "None", ",", "\n", ")", "\n", "\n", "# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)", "\n", "", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "attention_mask", "=", "decoder_attention_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", ",", "\n", "encoder_attention_mask", "=", "attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n", "", "return", "Seq2SeqModelOutput", "(", "\n", "last_hidden_state", "=", "decoder_outputs", ".", "last_hidden_state", ",", "\n", "past_key_values", "=", "decoder_outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "decoder_outputs", ".", "hidden_states", ",", "\n", "decoder_attentions", "=", "decoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "decoder_outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "encoder_outputs", ".", "last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "encoder_attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.__init__": [[352, 371], ["transformers.models.bart.modeling_bart.BartPretrainedModel.__init__", "model.TAASModel", "model.TAASForConditionalGeneration.register_buffer", "torch.nn.Linear", "torch.nn.Linear", "topic_models.networks.decoding_network.DecoderNetwork", "torch.nn.Linear", "torch.nn.Linear", "model.TAASForConditionalGeneration.init_weights", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "topic_num", "=", "1024", ",", "vocab_size", "=", "2000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model", "=", "TAASModel", "(", "config", ")", "\n", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "torch", ".", "zeros", "(", "(", "1", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ")", ")", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ",", "bias", "=", "False", ")", "\n", "\n", "# initial topic model", "\n", "self", ".", "topic_num", "=", "topic_num", "\n", "# todo: confirm the vocab_size for topic modeling", "\n", "self", ".", "topic_model", "=", "DecoderNetwork", "(", "vocab_size", "=", "vocab_size", ",", "bert_size", "=", "config", ".", "d_model", ",", "\n", "infnet", "=", "\"zeroshot\"", ",", "num_topics", "=", "self", ".", "topic_num", ",", "model_type", "=", "'prodLDA'", ",", "\n", "hidden_sizes", "=", "(", "100", ",", "100", ")", ",", "activation", "=", "'softplus'", ",", "\n", "dropout", "=", "self", ".", "config", ".", "dropout", ",", "learn_priors", "=", "True", ")", "\n", "# transfer the topic modeling vocab to vocab size", "\n", "self", ".", "tm_head", "=", "nn", ".", "Linear", "(", "vocab_size", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ",", "bias", "=", "False", ")", "\n", "# for model analysis: use an additional NN to transfer dimension", "\n", "# self.dimhead = nn.Linear(config.d_model, self.topic_num, bias=False)", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder": [[372, 374], ["model.TAASForConditionalGeneration.model.get_encoder"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_encoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder": [[375, 377], ["model.TAASForConditionalGeneration.model.get_decoder"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder"], ["", "def", "get_decoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "get_decoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.resize_token_embeddings": [[378, 382], ["super().resize_token_embeddings", "model.TAASForConditionalGeneration._resize_final_logits_bias"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._resize_final_logits_bias"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", ":", "int", ")", "->", "nn", ".", "Embedding", ":", "\n", "        ", "new_embeddings", "=", "super", "(", ")", ".", "resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "self", ".", "_resize_final_logits_bias", "(", "new_num_tokens", ")", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._resize_final_logits_bias": [[383, 391], ["model.TAASForConditionalGeneration.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_resize_final_logits_bias", "(", "self", ",", "new_num_tokens", ":", "int", ")", "->", "None", ":", "\n", "        ", "old_num_tokens", "=", "self", ".", "final_logits_bias", ".", "shape", "[", "-", "1", "]", "\n", "if", "new_num_tokens", "<=", "old_num_tokens", ":", "\n", "            ", "new_bias", "=", "self", ".", "final_logits_bias", "[", ":", ",", ":", "new_num_tokens", "]", "\n", "", "else", ":", "\n", "            ", "extra_bias", "=", "torch", ".", "zeros", "(", "(", "1", ",", "new_num_tokens", "-", "old_num_tokens", ")", ",", "device", "=", "self", ".", "final_logits_bias", ".", "device", ")", "\n", "new_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "final_logits_bias", ",", "extra_bias", "]", ",", "dim", "=", "1", ")", "\n", "", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "new_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_output_embeddings": [[392, 394], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.set_output_embeddings": [[395, 397], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "lm_head", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.forward": [[398, 499], ["transformers.file_utils.add_start_docstrings_to_model_forward", "transformers.file_utils.replace_return_docstrings", "transformers.file_utils.add_end_docstrings", "model.TAASForConditionalGeneration.model", "bow.reshape.reshape.reshape", "model.TAASForConditionalGeneration.topic_model", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "topic_models.loss.topic_modeling_loss", "transformers.modeling_outputs.Seq2SeqLMOutput", "model.shift_tokens_right", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "model.TAASForConditionalGeneration.lm_head", "lm_logits.view", "labels.view", "bow.reshape.reshape.size", "word_dists.size", "model.TAASForConditionalGeneration.lm_head", "model.TAASForConditionalGeneration.tm_head"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.topic_models.loss.topic_modeling_loss", "home.repos.pwc.inspect_result.chz816_tas.None.model.shift_tokens_right"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "Seq2SeqLMOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "@", "add_end_docstrings", "(", "BART_GENERATION_EXAMPLE", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "decoder_inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "topic_guided", "=", "True", ",", "\n", "bow", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the masked language modeling loss. Indices should either be in ``[0, ...,\n            config.vocab_size]`` or -100 (see ``input_ids`` docstring). Tokens with indices set to ``-100`` are ignored\n            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``.\n\n        Returns:\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "decoder_input_ids", "is", "None", ":", "\n", "                ", "decoder_input_ids", "=", "shift_tokens_right", "(", "\n", "labels", ",", "self", ".", "config", ".", "pad_token_id", ",", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "", "", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "decoder_inputs_embeds", "=", "decoder_inputs_embeds", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "# topic attention", "\n", "bow", "=", "bow", ".", "reshape", "(", "bow", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# perform topic modeling - use \"[CLS]\" as the representation", "\n", "prior_mean", ",", "prior_variance", ",", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "word_dists", ",", "h", "=", "self", ".", "topic_model", "(", "\n", "bow", ",", "outputs", ".", "encoder_last_hidden_state", "[", ":", ":", ",", "0", "]", ")", "\n", "\n", "# outputs[0]: if the last hidden state from the decoder_outputs; size: torch.Size([bs, #(summary), d_model])", "\n", "# self.lm_head = nn.Linear(config.d_model, self.model.shared.num_embeddings, bias=False)", "\n", "# self.lm_head(outputs[0]): torch.Size([bs, #(summary), #(vocab)])", "\n", "# self.topic_model.topic_word: torch.Size([1024, 2000])", "\n", "# lm_logits.size(): torch.Size([16, 38, 50264]) => batch size * #(summary) * len(vocab)", "\n", "# theta = self.topic_model.get_theta(bow, outputs.encoder_last_hidden_state[::, 0])", "\n", "\n", "if", "topic_guided", ":", "\n", "#     lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias + torch.matmul(self.dimhead(outputs[0]), self.tm_head(", "\n", "#         self.topic_model.topic_word))", "\n", "            ", "lm_logits", "=", "self", ".", "lm_head", "(", "outputs", "[", "0", "]", ")", "+", "self", ".", "final_logits_bias", "+", "torch", ".", "matmul", "(", "outputs", "[", "0", "]", ",", "self", ".", "tm_head", "(", "\n", "self", ".", "topic_model", ".", "topic_word", ")", ")", "\n", "", "else", ":", "\n", "            ", "lm_logits", "=", "self", ".", "lm_head", "(", "outputs", "[", "0", "]", ")", "+", "self", ".", "final_logits_bias", "\n", "\n", "", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "# loss for topic modeling", "\n", "", "if", "bow", ".", "size", "(", ")", "[", "0", "]", "<", "word_dists", ".", "size", "(", ")", "[", "0", "]", ":", "\n", "            ", "loss_topic_modeling", "=", "0", "\n", "", "else", ":", "\n", "            ", "loss_topic_modeling", "=", "topic_modeling_loss", "(", "bow", ",", "self", ".", "topic_num", ",", "word_dists", ",", "prior_mean", ",", "prior_variance", ",", "\n", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ")", "\n", "\n", "", "return", "Seq2SeqLMOutput", "(", "\n", "loss", "=", "masked_lm_loss", ",", "\n", "logits", "=", "lm_logits", ",", "\n", "past_key_values", "=", "outputs", ".", "past_key_values", ",", "\n", "decoder_hidden_states", "=", "outputs", ".", "decoder_hidden_states", ",", "\n", "decoder_attentions", "=", "outputs", ".", "decoder_attentions", ",", "\n", "cross_attentions", "=", "outputs", ".", "cross_attentions", ",", "\n", "encoder_last_hidden_state", "=", "outputs", ".", "encoder_last_hidden_state", ",", "\n", "encoder_hidden_states", "=", "outputs", ".", "encoder_hidden_states", ",", "\n", "encoder_attentions", "=", "outputs", ".", "encoder_attentions", ",", "\n", ")", ",", "loss_topic_modeling", ",", "self", ".", "topic_model", ".", "topic_word", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.prepare_inputs_for_generation": [[500, 513], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "decoder_input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "use_cache", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# cut decoder_input_ids if past is used", "\n", "        ", "if", "past", "is", "not", "None", ":", "\n", "            ", "decoder_input_ids", "=", "decoder_input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "None", ",", "# encoder_outputs is defined. input_ids not needed", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"past_key_values\"", ":", "past", ",", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "# change this to avoid caching (presumably for debugging)", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.adjust_logits_during_generation": [[515, 521], ["model.TAASForConditionalGeneration._force_token_id_to_be_generated", "model.TAASForConditionalGeneration._force_token_id_to_be_generated"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._force_token_id_to_be_generated", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._force_token_id_to_be_generated"], ["", "def", "adjust_logits_during_generation", "(", "self", ",", "logits", ",", "cur_len", ",", "max_length", ")", ":", "\n", "        ", "if", "cur_len", "==", "1", "and", "self", ".", "config", ".", "force_bos_token_to_be_generated", ":", "\n", "            ", "self", ".", "_force_token_id_to_be_generated", "(", "logits", ",", "self", ".", "config", ".", "bos_token_id", ")", "\n", "", "elif", "cur_len", "==", "max_length", "-", "1", "and", "self", ".", "config", ".", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "self", ".", "_force_token_id_to_be_generated", "(", "logits", ",", "self", ".", "config", ".", "eos_token_id", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._force_token_id_to_be_generated": [[522, 526], ["float", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_force_token_id_to_be_generated", "(", "scores", ",", "token_id", ")", "->", "None", ":", "\n", "        ", "\"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0 (logprob=-float(\"inf\"))\"\"\"", "\n", "scores", "[", ":", ",", "[", "x", "for", "x", "in", "range", "(", "scores", ".", "shape", "[", "1", "]", ")", "if", "x", "!=", "token_id", "]", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._reorder_cache": [[527, 536], ["tuple", "past_state.index_select"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reorder_cache", "(", "past", ",", "beam_idx", ")", ":", "\n", "        ", "reordered_past", "=", "(", ")", "\n", "for", "layer_past", "in", "past", ":", "\n", "# cached cross_attention states don't have to be reordered -> they are always the same", "\n", "            ", "reordered_past", "+=", "(", "\n", "tuple", "(", "past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", "for", "past_state", "in", "layer_past", "[", ":", "2", "]", ")", "+", "layer_past", "[", "2", ":", "]", ",", "\n", ")", "\n", "", "return", "reordered_past", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.generate": [[537, 795], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.TAASForConditionalGeneration._get_logits_processor", "transformers.BeamSearchScorer", "model.TAASForConditionalGeneration._expand_inputs_for_generation", "model.TAASForConditionalGeneration.beam_search", "model.TAASForConditionalGeneration._prepare_input_ids_for_generation", "model.TAASForConditionalGeneration.get", "model.TAASForConditionalGeneration._prepare_attention_mask_for_generation", "logger.warning", "model.TAASForConditionalGeneration._prepare_encoder_decoder_kwargs_for_generation", "logger.warning", "ValueError", "model.TAASForConditionalGeneration.pop", "model.TAASForConditionalGeneration._prepare_decoder_input_ids_for_generation"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.beam_search"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "min_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "do_sample", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "early_stopping", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_beams", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "temperature", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "top_k", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "top_p", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "repetition_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "bad_words_ids", ":", "Optional", "[", "Iterable", "[", "int", "]", "]", "=", "None", ",", "\n", "bos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pad_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "length_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "no_repeat_ngram_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_return_sequences", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "decoder_start_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_cache", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_beam_groups", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "diversity_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "prefix_allowed_tokens_fn", ":", "Optional", "[", "Callable", "[", "[", "int", ",", "torch", ".", "Tensor", "]", ",", "List", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "output_attentions", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "output_hidden_states", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "output_scores", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "return_dict_in_generate", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "bow", "=", "None", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "->", "Union", "[", "GreedySearchOutput", ",", "SampleOutput", ",", "BeamSearchOutput", ",", "BeamSampleOutput", ",", "torch", ".", "LongTensor", "]", ":", "\n", "        ", "r\"\"\"\n        Generates sequences for models with a language modeling head. The method currently supports greedy decoding,\n        multinomial sampling, beam-search decoding, and beam-search multinomial sampling.\n\n        Apart from :obj:`input_ids` and :obj:`attention_mask`, all the arguments below will default to the value of the\n        attribute of the same name inside the :class:`~transformers.PretrainedConfig` of the model. The default values\n        indicated are the default values of those config.\n\n        Most of these parameters are explained in more detail in `this blog post\n        <https://huggingface.co/blog/how-to-generate>`__.\n\n        Parameters:\n\n            input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                The sequence used as a prompt for the generation. If :obj:`None` the method initializes it as an empty\n                :obj:`torch.LongTensor` of shape :obj:`(1,)`.\n            max_length (:obj:`int`, `optional`, defaults to 20):\n                The maximum length of the sequence to be generated.\n            min_length (:obj:`int`, `optional`, defaults to 10):\n                The minimum length of the sequence to be generated.\n            do_sample (:obj:`bool`, `optional`, defaults to :obj:`False`):\n                Whether or not to use sampling ; use greedy decoding otherwise.\n            early_stopping (:obj:`bool`, `optional`, defaults to :obj:`False`):\n                Whether to stop the beam search when at least ``num_beams`` sentences are finished per batch or not.\n            num_beams (:obj:`int`, `optional`, defaults to 1):\n                Number of beams for beam search. 1 means no beam search.\n            temperature (:obj:`float`, `optional`, defaults tp 1.0):\n                The value used to module the next token probabilities.\n            top_k (:obj:`int`, `optional`, defaults to 50):\n                The number of highest probability vocabulary tokens to keep for top-k-filtering.\n            top_p (:obj:`float`, `optional`, defaults to 1.0):\n                If set to float < 1, only the most probable tokens with probabilities that add up to :obj:`top_p` or\n                higher are kept for generation.\n            repetition_penalty (:obj:`float`, `optional`, defaults to 1.0):\n                The parameter for repetition penalty. 1.0 means no penalty. See `this paper\n                <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details.\n            pad_token_id (:obj:`int`, `optional`):\n                The id of the `padding` token.\n            bos_token_id (:obj:`int`, `optional`):\n                The id of the `beginning-of-sequence` token.\n            eos_token_id (:obj:`int`, `optional`):\n                The id of the `end-of-sequence` token.\n            length_penalty (:obj:`float`, `optional`, defaults to 1.0):\n                Exponential penalty to the length. 1.0 means no penalty. Set to values < 1.0 in order to encourage the\n                model to generate shorter sequences, to a value > 1.0 in order to encourage the model to produce longer\n                sequences.\n            no_repeat_ngram_size (:obj:`int`, `optional`, defaults to 0):\n                If set to int > 0, all ngrams of that size can only occur once.\n            bad_words_ids(:obj:`List[List[int]]`, `optional`):\n                List of token ids that are not allowed to be generated. In order to get the tokens of the words that\n                should not appear in the generated text, use :obj:`tokenizer(bad_word,\n                add_prefix_space=True).input_ids`.\n            num_return_sequences(:obj:`int`, `optional`, defaults to 1):\n                The number of independently computed returned sequences for each element in the batch.\n            attention_mask (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Mask to avoid performing attention on padding token indices. Mask values are in ``[0, 1]``, 1 for\n                tokens that are not masked, and 0 for masked tokens. If not provided, will default to a tensor the same\n                shape as :obj:`input_ids` that masks the pad token. `What are attention masks?\n                <../glossary.html#attention-mask>`__\n            decoder_start_token_id (:obj:`int`, `optional`):\n                If an encoder-decoder model starts decoding with a different token than `bos`, the id of that token.\n            use_cache: (:obj:`bool`, `optional`, defaults to :obj:`True`):\n                Whether or not the model should use the past last key/values attentions (if applicable to the model) to\n                speed up decoding.\n            num_beam_groups (:obj:`int`, `optional`, defaults to 1):\n                Number of groups to divide :obj:`num_beams` into in order to ensure diversity among different groups of\n                beams. `this paper <https://arxiv.org/pdf/1610.02424.pdf>`__ for more details.\n            diversity_penalty (:obj:`float`, `optional`, defaults to 0.0):\n                This value is subtracted from a beam's score if it generates a token same as any beam from other group\n                at a particular time. Note that :obj:`diversity_penalty` is only effective if ``group beam search`` is\n                enabled.\n            prefix_allowed_tokens_fn: (:obj:`Callable[[int, torch.Tensor], List[int]]`, `optional`):\n                If provided, this function constraints the beam search to allowed tokens only at each step. If not\n                provided no constraint is applied. This function takes 2 arguments :obj:`inputs_ids` and the batch ID\n                :obj:`batch_id`. It has to return a list with the allowed tokens for the next generation step\n                conditioned on the previously generated tokens :obj:`inputs_ids` and the batch ID :obj:`batch_id`. This\n                argument is useful for constrained generation conditioned on the prefix, as described in\n                `Autoregressive Entity Retrieval <https://arxiv.org/abs/2010.00904>`__.\n            output_attentions (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more details.\n            output_hidden_states (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return trhe hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more details.\n            output_scores (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return the prediction scores. See ``scores`` under returned tensors for more details.\n            return_dict_in_generate (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n\n            model_kwargs:\n                Additional model specific kwargs will be forwarded to the :obj:`forward` function of the model. If the\n                model is an encoder-decoder model, encoder specific kwargs should not be prefixed and decoder specific\n                kwargs should be prefixed with `decoder_`.\n\n        Return:\n            :class:`~transformers.file_utils.ModelOutput` or :obj:`torch.LongTensor`: A\n            :class:`~transformers.file_utils.ModelOutput` (if ``return_dict_in_generate=True`` or when\n            ``config.return_dict_in_generate=True``) or a :obj:`torch.FloatTensor`.\n\n                If the model is `not` an encoder-decoder model (``model.config.is_encoder_decoder=False``), the\n                possible :class:`~transformers.file_utils.ModelOutput` types are:\n\n                    - :class:`~transformers.generation_utils.GreedySearchDecoderOnlyOutput`,\n                    - :class:`~transformers.generation_utils.SampleDecoderOnlyOutput`,\n                    - :class:`~transformers.generation_utils.BeamSearchDecoderOnlyOutput`,\n                    - :class:`~transformers.generation_utils.BeamSampleDecoderOnlyOutput`\n\n                If the model is an encoder-decoder model (``model.config.is_encoder_decoder=True``), the possible\n                :class:`~transformers.file_utils.ModelOutput` types are:\n\n                    - :class:`~transformers.generation_utils.GreedySearchEncoderDecoderOutput`,\n                    - :class:`~transformers.generation_utils.SampleEncoderDecoderOutput`,\n                    - :class:`~transformers.generation_utils.BeamSearchEncoderDecoderOutput`,\n                    - :class:`~transformers.generation_utils.BeamSampleEncoderDecoderOutput`\n        \"\"\"", "\n", "\n", "# set init values", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "num_beam_groups", "=", "num_beam_groups", "if", "num_beam_groups", "is", "not", "None", "else", "self", ".", "config", ".", "num_beam_groups", "\n", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "eos_token_id", "=", "eos_token_id", "if", "eos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "\n", "output_scores", "=", "output_scores", "if", "output_scores", "is", "not", "None", "else", "self", ".", "config", ".", "output_scores", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict_in_generate", "=", "(", "\n", "return_dict_in_generate", "if", "return_dict_in_generate", "is", "not", "None", "else", "self", ".", "config", ".", "return_dict_in_generate", "\n", ")", "\n", "\n", "model_kwargs", "[", "\"output_attentions\"", "]", "=", "output_attentions", "\n", "model_kwargs", "[", "\"output_hidden_states\"", "]", "=", "output_hidden_states", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "# init `input_ids` with bos_token_id", "\n", "            ", "input_ids", "=", "self", ".", "_prepare_input_ids_for_generation", "(", "bos_token_id", ")", "\n", "\n", "", "if", "model_kwargs", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "is", "None", ":", "\n", "# init `attention_mask` depending on `pad_token_id`", "\n", "            ", "model_kwargs", "[", "\"attention_mask\"", "]", "=", "self", ".", "_prepare_attention_mask_for_generation", "(", "\n", "input_ids", ",", "pad_token_id", ",", "eos_token_id", "\n", ")", "\n", "\n", "# special case if pad_token_id is not defined", "\n", "", "if", "pad_token_id", "is", "None", "and", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Setting `pad_token_id` to `eos_token_id`:{eos_token_id} for open-end generation.\"", ")", "\n", "pad_token_id", "=", "eos_token_id", "\n", "\n", "# generate the outputs using the model", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "# add encoder_outputs to model_kwargs", "\n", "            ", "model_kwargs", "=", "self", ".", "_prepare_encoder_decoder_kwargs_for_generation", "(", "input_ids", ",", "model_kwargs", ")", "\n", "\n", "# set input_ids as decoder_input_ids", "\n", "if", "\"decoder_input_ids\"", "in", "model_kwargs", ":", "\n", "                ", "input_ids", "=", "model_kwargs", ".", "pop", "(", "\"decoder_input_ids\"", ")", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "self", ".", "_prepare_decoder_input_ids_for_generation", "(", "\n", "input_ids", ",", "decoder_start_token_id", "=", "decoder_start_token_id", ",", "bos_token_id", "=", "bos_token_id", "\n", ")", "\n", "\n", "", "", "if", "input_ids", ".", "shape", "[", "-", "1", "]", ">=", "max_length", ":", "\n", "            ", "input_ids_string", "=", "\"decoder_input_ids\"", "if", "self", ".", "config", ".", "is_encoder_decoder", "else", "\"input_ids\"", "\n", "logger", ".", "warning", "(", "\n", "f\"Input length of {input_ids_string} is {input_ids.shape[-1]}, but ``max_length`` is set to {max_length}.\"", "\n", "\"This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\"", "\n", ")", "\n", "\n", "# determine generation mode - use beam search directly for this model", "\n", "\n", "# set model_kwargs", "\n", "", "model_kwargs", "[", "\"use_cache\"", "]", "=", "use_cache", "\n", "\n", "# get distribution pre_processing samplers", "\n", "logits_processor", "=", "self", ".", "_get_logits_processor", "(", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "min_length", "=", "min_length", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "prefix_allowed_tokens_fn", "=", "prefix_allowed_tokens_fn", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "num_beam_groups", "=", "num_beam_groups", ",", "\n", "diversity_penalty", "=", "diversity_penalty", ",", "\n", ")", "\n", "\n", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "early_stopping", "=", "early_stopping", "if", "early_stopping", "is", "not", "None", "else", "self", ".", "config", ".", "early_stopping", "\n", "\n", "if", "num_return_sequences", ">", "num_beams", ":", "\n", "            ", "raise", "ValueError", "(", "\"`num_return_sequences` has to be smaller or equal to `num_beams`.\"", ")", "\n", "\n", "", "beam_scorer", "=", "BeamSearchScorer", "(", "\n", "batch_size", "=", "batch_size", ",", "\n", "max_length", "=", "max_length", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "length_penalty", "=", "length_penalty", ",", "\n", "do_early_stopping", "=", "early_stopping", ",", "\n", "num_beam_hyps_to_keep", "=", "num_return_sequences", ",", "\n", ")", "\n", "# interleave with `num_beams`", "\n", "input_ids", ",", "model_kwargs", "=", "self", ".", "_expand_inputs_for_generation", "(", "\n", "input_ids", ",", "expand_size", "=", "num_beams", ",", "is_encoder_decoder", "=", "self", ".", "config", ".", "is_encoder_decoder", ",", "**", "model_kwargs", "\n", ")", "\n", "return", "self", ".", "beam_search", "(", "\n", "input_ids", ",", "\n", "beam_scorer", ",", "\n", "logits_processor", "=", "logits_processor", ",", "\n", "max_length", "=", "max_length", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "output_scores", "=", "output_scores", ",", "\n", "return_dict_in_generate", "=", "return_dict_in_generate", ",", "\n", "bow", "=", "bow", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.beam_search": [[797, 1000], ["len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.view.view.view", "beam_scorer.finalize", "transformers.LogitsProcessorList", "model.TAASForConditionalGeneration.prepare_inputs_for_generation", "model.TAASForConditionalGeneration.", "model.TAASForConditionalGeneration.adjust_logits_during_generation", "torch.log_softmax", "torch.log_softmax", "logits_processor", "next_token_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "beam_scorer.process", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.TAASForConditionalGeneration._update_model_kwargs_for_generation", "model_kwargs[].get", "model_kwargs[].get", "beam_scores[].expand_as", "model.TAASForConditionalGeneration._reorder_cache", "transformers.generation_utils.BeamSearchEncoderDecoderOutput", "transformers.generation_utils.BeamSearchDecoderOnlyOutput", "beam_next_tokens.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.adjust_logits_during_generation", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration._reorder_cache"], ["", "def", "beam_search", "(", "\n", "self", ",", "\n", "input_ids", ":", "torch", ".", "LongTensor", ",", "\n", "beam_scorer", ":", "BeamScorer", ",", "\n", "logits_processor", ":", "Optional", "[", "LogitsProcessorList", "]", "=", "None", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pad_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "output_attentions", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "output_hidden_states", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "output_scores", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "return_dict_in_generate", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "bow", "=", "None", ",", "\n", "**", "model_kwargs", ",", "\n", ")", "->", "Union", "[", "BeamSearchOutput", ",", "torch", ".", "LongTensor", "]", ":", "\n", "        ", "r\"\"\"\n        Generates sequences for models with a language modeling head using beam search decoding.\n\n        Parameters:\n\n            input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                The sequence used as a prompt for the generation. If :obj:`None` the method initializes it as an empty\n                :obj:`torch.LongTensor` of shape :obj:`(1,)`.\n            beam_scorer (:obj:`BeamScorer`):\n                An derived instance of :class:`~transformers.BeamScorer` that defines how beam hypotheses are\n                constructed, stored and sorted during generation. For more information, the documentation of\n                :class:`~transformers.BeamScorer` should be read.\n            logits_processor (:obj:`LogitsProcessorList`, `optional`):\n                An instance of :class:`~transformers.LogitsProcessorList`. List of instances of class derived from\n                :class:`~transformers.LogitsProcessor` used to modify the prediction scores of the language modeling\n                head applied at each generation step.\n            max_length (:obj:`int`, `optional`, defaults to 20):\n                The maximum length of the sequence to be generated.\n            pad_token_id (:obj:`int`, `optional`):\n                The id of the `padding` token.\n            eos_token_id (:obj:`int`, `optional`):\n                The id of the `end-of-sequence` token.\n            output_attentions (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more details.\n            output_hidden_states (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return trhe hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more details.\n            output_scores (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return the prediction scores. See ``scores`` under returned tensors for more details.\n            return_dict_in_generate (:obj:`bool`, `optional`, defaults to `False`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n            model_kwargs:\n                Additional model specific kwargs will be forwarded to the :obj:`forward` function of the model. If\n                model is an encoder-decoder model the kwargs should include :obj:`encoder_outputs`.\n\n        Return:\n            :class:`~transformers.generation_utilsBeamSearchDecoderOnlyOutput`,\n            :class:`~transformers.generation_utils.BeamSearchEncoderDecoderOutput` or obj:`torch.LongTensor`: A\n            :obj:`torch.LongTensor` containing the generated tokens (default behaviour) or a\n            :class:`~transformers.generation_utils.BeamSearchDecoderOnlyOutput` if\n            ``model.config.is_encoder_decoder=False`` and ``return_dict_in_generate=True`` or a\n            :class:`~transformers.generation_utils.BeamSearchEncoderDecoderOutput` if\n            ``model.config.is_encoder_decoder=True``.\n        \"\"\"", "\n", "\n", "# init values", "\n", "logits_processor", "=", "logits_processor", "if", "logits_processor", "is", "not", "None", "else", "LogitsProcessorList", "(", ")", "\n", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_id", "=", "eos_token_id", "if", "eos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "output_scores", "=", "output_scores", "if", "output_scores", "is", "not", "None", "else", "self", ".", "config", ".", "output_scores", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict_in_generate", "=", "(", "\n", "return_dict_in_generate", "if", "return_dict_in_generate", "is", "not", "None", "else", "self", ".", "config", ".", "return_dict_in_generate", "\n", ")", "\n", "\n", "# init attention / hidden states / scores tuples", "\n", "scores", "=", "(", ")", "if", "(", "return_dict_in_generate", "and", "output_scores", ")", "else", "None", "\n", "decoder_attentions", "=", "(", ")", "if", "(", "return_dict_in_generate", "and", "output_attentions", ")", "else", "None", "\n", "decoder_hidden_states", "=", "(", ")", "if", "(", "return_dict_in_generate", "and", "output_hidden_states", ")", "else", "None", "\n", "\n", "# if model is an encoder-decoder, retrieve encoder attention weights and hidden states", "\n", "if", "return_dict_in_generate", "and", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "            ", "encoder_attentions", "=", "model_kwargs", "[", "\"encoder_outputs\"", "]", ".", "get", "(", "\"attentions\"", ")", "if", "output_attentions", "else", "None", "\n", "encoder_hidden_states", "=", "(", "\n", "model_kwargs", "[", "\"encoder_outputs\"", "]", ".", "get", "(", "\"hidden_states\"", ")", "if", "output_hidden_states", "else", "None", "\n", ")", "\n", "\n", "", "batch_size", "=", "len", "(", "beam_scorer", ".", "_beam_hyps", ")", "\n", "num_beams", "=", "beam_scorer", ".", "num_beams", "\n", "\n", "batch_beam_size", ",", "cur_len", "=", "input_ids", ".", "shape", "\n", "\n", "assert", "(", "\n", "num_beams", "*", "batch_size", "==", "batch_beam_size", "\n", ")", ",", "\"Batch dimension of `input_ids` should be {num_beams * batch_size}, but is {batch_beam_size}.\"", "\n", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "(", "batch_size", "*", "num_beams", ",", ")", ")", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "**", "model_kwargs", ")", "\n", "\n", "# feed the inputs into \"TAASForConditionalGeneration\"", "\n", "outputs", ",", "loss_topic_modeling", ",", "topic_word", "=", "self", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "bow", "=", "bow", ",", "\n", ")", "\n", "# next_token_logits.size(): batch size * len(vocab)", "\n", "next_token_logits", "=", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "# adjust tokens for Bart, *e.g.*", "\n", "next_token_logits", "=", "self", ".", "adjust_logits_during_generation", "(", "\n", "next_token_logits", ",", "cur_len", "=", "cur_len", ",", "max_length", "=", "max_length", "\n", ")", "\n", "\n", "next_token_scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "next_token_scores", "=", "logits_processor", "(", "input_ids", ",", "next_token_scores", ")", "\n", "next_token_scores", "=", "next_token_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "next_token_scores", ")", "\n", "\n", "# Store scores, attentions and hidden_states when required", "\n", "if", "return_dict_in_generate", ":", "\n", "                ", "if", "output_scores", ":", "\n", "                    ", "scores", "+=", "(", "next_token_scores", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "                    ", "decoder_attentions", "+=", "(", "\n", "(", "outputs", ".", "decoder_attentions", ",", ")", "if", "self", ".", "config", ".", "is_encoder_decoder", "else", "(", "outputs", ".", "attentions", ",", ")", "\n", ")", "\n", "\n", "", "if", "output_hidden_states", ":", "\n", "                    ", "decoder_hidden_states", "+=", "(", "\n", "(", "outputs", ".", "decoder_hidden_states", ",", ")", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", "\n", "else", "(", "outputs", ".", "hidden_states", ",", ")", "\n", ")", "\n", "\n", "# reshape for beam search", "\n", "", "", "vocab_size", "=", "next_token_scores", ".", "shape", "[", "-", "1", "]", "\n", "next_token_scores", "=", "next_token_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "\n", "\n", "next_token_scores", ",", "next_tokens", "=", "torch", ".", "topk", "(", "\n", "next_token_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", "\n", ")", "\n", "\n", "next_indices", "=", "next_tokens", "//", "vocab_size", "\n", "next_tokens", "=", "next_tokens", "%", "vocab_size", "\n", "\n", "# stateless", "\n", "beam_outputs", "=", "beam_scorer", ".", "process", "(", "\n", "input_ids", ",", "\n", "next_token_scores", ",", "\n", "next_tokens", ",", "\n", "next_indices", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", ")", "\n", "beam_scores", "=", "beam_outputs", "[", "\"next_beam_scores\"", "]", "\n", "beam_next_tokens", "=", "beam_outputs", "[", "\"next_beam_tokens\"", "]", "\n", "beam_idx", "=", "beam_outputs", "[", "\"next_beam_indices\"", "]", "\n", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", "[", "beam_idx", ",", ":", "]", ",", "beam_next_tokens", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "model_kwargs", "=", "self", ".", "_update_model_kwargs_for_generation", "(", "\n", "outputs", ",", "model_kwargs", ",", "is_encoder_decoder", "=", "self", ".", "config", ".", "is_encoder_decoder", "\n", ")", "\n", "if", "model_kwargs", "[", "\"past\"", "]", "is", "not", "None", ":", "\n", "                ", "model_kwargs", "[", "\"past\"", "]", "=", "self", ".", "_reorder_cache", "(", "model_kwargs", "[", "\"past\"", "]", ",", "beam_idx", ")", "\n", "\n", "", "if", "beam_scorer", ".", "is_done", ":", "\n", "                ", "break", "\n", "\n", "", "", "sequence_outputs", "=", "beam_scorer", ".", "finalize", "(", "\n", "input_ids", ",", "beam_scores", ",", "next_tokens", ",", "next_indices", ",", "pad_token_id", "=", "pad_token_id", ",", "eos_token_id", "=", "eos_token_id", "\n", ")", "\n", "\n", "if", "return_dict_in_generate", ":", "\n", "            ", "if", "not", "output_scores", ":", "\n", "                ", "sequence_outputs", "[", "\"sequence_scores\"", "]", "=", "None", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "                ", "return", "BeamSearchEncoderDecoderOutput", "(", "\n", "sequences", "=", "sequence_outputs", "[", "\"sequences\"", "]", ",", "\n", "sequences_scores", "=", "sequence_outputs", "[", "\"sequence_scores\"", "]", ",", "\n", "scores", "=", "scores", ",", "\n", "encoder_attentions", "=", "encoder_attentions", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "decoder_attentions", "=", "decoder_attentions", ",", "\n", "decoder_hidden_states", "=", "decoder_hidden_states", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "return", "BeamSearchDecoderOnlyOutput", "(", "\n", "sequences", "=", "sequence_outputs", "[", "\"sequences\"", "]", ",", "\n", "sequences_scores", "=", "sequence_outputs", "[", "\"sequence_scores\"", "]", ",", "\n", "scores", "=", "scores", ",", "\n", "attentions", "=", "decoder_attentions", ",", "\n", "hidden_states", "=", "decoder_hidden_states", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "sequence_outputs", "[", "\"sequences\"", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.None.model.shift_tokens_right": [[56, 69], ["input_ids.new_zeros", "input_ids[].clone", "input_ids.new_zeros.masked_fill_"], "function", ["None"], ["def", "shift_tokens_right", "(", "input_ids", ":", "torch", ".", "Tensor", ",", "pad_token_id", ":", "int", ",", "decoder_start_token_id", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Shift input ids one token to the right.\n    \"\"\"", "\n", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", ":", ",", "1", ":", "]", "=", "input_ids", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", ":", ",", "0", "]", "=", "decoder_start_token_id", "\n", "\n", "assert", "pad_token_id", "is", "not", "None", ",", "\"self.model.config.pad_token_id has to be defined.\"", "\n", "# replace possible -100 values in labels by `pad_token_id`", "\n", "shifted_input_ids", ".", "masked_fill_", "(", "shifted_input_ids", "==", "-", "100", ",", "pad_token_id", ")", "\n", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model._make_causal_mask": [[71, 84], ["torch.full", "torch.full", "torch.arange", "torch.arange", "torch.cat.masked_fill_", "torch.cat.to", "mask[].expand", "float", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat.size", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "_make_causal_mask", "(", "input_ids_shape", ":", "torch", ".", "Size", ",", "dtype", ":", "torch", ".", "dtype", ",", "past_key_values_length", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Make causal mask used for bi-directional self-attention.\n    \"\"\"", "\n", "bsz", ",", "tgt_len", "=", "input_ids_shape", "\n", "mask", "=", "torch", ".", "full", "(", "(", "tgt_len", ",", "tgt_len", ")", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "mask_cond", "=", "torch", ".", "arange", "(", "mask", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", ".", "masked_fill_", "(", "mask_cond", "<", "(", "mask_cond", "+", "1", ")", ".", "view", "(", "mask", ".", "size", "(", "-", "1", ")", ",", "1", ")", ",", "0", ")", "\n", "mask", "=", "mask", ".", "to", "(", "dtype", ")", "\n", "\n", "if", "past_key_values_length", ">", "0", ":", "\n", "        ", "mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "tgt_len", ",", "past_key_values_length", ",", "dtype", "=", "dtype", ")", ",", "mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "mask", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "tgt_len", ",", "tgt_len", "+", "past_key_values_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.model._expand_mask": [[86, 98], ["mask.size", "mask[].expand().to", "inverted_mask.masked_fill", "inverted_mask.bool", "mask[].expand", "torch.finfo", "torch.finfo"], "function", ["None"], ["", "def", "_expand_mask", "(", "mask", ":", "torch", ".", "Tensor", ",", "dtype", ":", "torch", ".", "dtype", ",", "tgt_len", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Expands attention_mask from `[bsz, seq_len]` to `[bsz, 1, tgt_seq_len, src_seq_len]`.\n    \"\"\"", "\n", "bsz", ",", "src_len", "=", "mask", ".", "size", "(", ")", "\n", "tgt_len", "=", "tgt_len", "if", "tgt_len", "is", "not", "None", "else", "src_len", "\n", "\n", "expanded_mask", "=", "mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", ".", "expand", "(", "bsz", ",", "1", ",", "tgt_len", ",", "src_len", ")", ".", "to", "(", "dtype", ")", "\n", "\n", "inverted_mask", "=", "1.0", "-", "expanded_mask", "\n", "\n", "return", "inverted_mask", ".", "masked_fill", "(", "inverted_mask", ".", "bool", "(", ")", ",", "torch", ".", "finfo", "(", "dtype", ")", ".", "min", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.sentence_splitter.add_newline_to_end_of_each_sentence": [[31, 36], ["re.sub", "nltk.sent_tokenize"], "function", ["None"], ["", "", "def", "add_newline_to_end_of_each_sentence", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"This was added to get rougeLsum scores matching published rougeL scores for BART and PEGASUS.\"\"\"", "\n", "re", ".", "sub", "(", "\"<n>\"", ",", "\"\"", ",", "x", ")", "# remove pegasus newline char", "\n", "assert", "NLTK_AVAILABLE", ",", "\"nltk must be installed to separate newlines between sentences. (pip install nltk)\"", "\n", "return", "\"\\n\"", ".", "join", "(", "nltk", ".", "sent_tokenize", "(", "x", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.handle_metrics": [[141, 155], ["logger.info", "sorted", "utils.save_json", "metrics.keys", "logger.info", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json"], ["", "def", "handle_metrics", "(", "split", ",", "metrics", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"\n    Log and save metrics\n\n    Args:\n    - split: one of train, val, test\n    - metrics: metrics dict\n    - output_dir: where to save the metrics\n    \"\"\"", "\n", "\n", "logger", ".", "info", "(", "f\"***** {split} metrics *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "metrics", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "f\"  {key} = {metrics[key]}\"", ")", "\n", "", "save_json", "(", "metrics", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{split}_results.json\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.main": [[157, 394], ["transformers.HfArgumentParser", "utils.check_output_dir", "logging.basicConfig", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "utils.use_task_specific_params", "transformers.Seq2SeqTrainer", "transformers.Seq2SeqTrainer.is_world_process_zero", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "bool", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "getattr", "isinstance", "utils.freeze_embeds", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "utils.freeze_params", "utils.assert_all_frozen", "logger.info", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder().init_weights", "logger.info", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder().init_weights", "logger.info", "dataset_class", "dataset_class", "dataset_class", "utils.build_compute_metrics_fn", "logger.info", "transformers.Seq2SeqTrainer.train", "transformers.Seq2SeqTrainer.save_model", "transformers.Seq2SeqTrainer.is_world_process_zero", "logger.info", "transformers.Seq2SeqTrainer.evaluate", "round", "transformers.Seq2SeqTrainer.is_world_process_zero", "logger.info", "transformers.Seq2SeqTrainer.predict", "transformers.Seq2SeqTrainer.is_world_process_zero", "utils.save_json", "len", "hasattr", "setattr", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder", "utils.Seq2SeqDataCollator", "finetune_trainer.handle_metrics", "all_metrics.update", "transformers.Seq2SeqTrainer.state.save_to_json", "AutoTokenizer.from_pretrained.save_pretrained", "finetune_trainer.handle_metrics", "all_metrics.update", "round", "finetune_trainer.handle_metrics", "all_metrics.update", "os.path.join", "os.path.abspath", "getattr", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder", "os.path.join", "AutoTokenizer.from_pretrained.batch_decode", "utils.lmap", "utils.write_txt_file", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder", "AutoModelForSeq2SeqLM.from_pretrained.get_encoder", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder", "AutoModelForSeq2SeqLM.from_pretrained.get_decoder", "os.path.isdir", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.check_output_dir", "home.repos.pwc.inspect_result.chz816_tas.None.utils.use_task_specific_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_embeds", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen", "home.repos.pwc.inspect_result.chz816_tas.None.utils.build_compute_metrics_fn", "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.handle_metrics", "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.handle_metrics", "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.handle_metrics", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap", "home.repos.pwc.inspect_result.chz816_tas.None.utils.write_txt_file", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder", "home.repos.pwc.inspect_result.chz816_tas.None.model.TAASForConditionalGeneration.get_decoder"], ["", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "check_output_dir", "(", "training_args", ")", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "parallel_mode", "==", "ParallelMode", ".", "DISTRIBUTED", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "extra_model_params", "=", "(", "\"encoder_layerdrop\"", ",", "\"decoder_layerdrop\"", ",", "\"dropout\"", ",", "\"attention_dropout\"", ")", "\n", "for", "p", "in", "extra_model_params", ":", "\n", "        ", "if", "getattr", "(", "training_args", ",", "p", ",", "None", ")", ":", "\n", "            ", "assert", "hasattr", "(", "config", ",", "p", ")", ",", "f\"({config.__class__.__name__}) doesn't have a `{p}` attribute\"", "\n", "setattr", "(", "config", ",", "p", ",", "getattr", "(", "training_args", ",", "p", ")", ")", "\n", "\n", "", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "# use task specific params", "\n", "use_task_specific_params", "(", "model", ",", "data_args", ".", "task", ")", "\n", "\n", "# set num_beams for evaluation", "\n", "if", "data_args", ".", "eval_beams", "is", "None", ":", "\n", "        ", "data_args", ".", "eval_beams", "=", "model", ".", "config", ".", "num_beams", "\n", "\n", "# set decoder_start_token_id for MBart", "\n", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "        ", "assert", "(", "\n", "data_args", ".", "tgt_lang", "is", "not", "None", "and", "data_args", ".", "src_lang", "is", "not", "None", "\n", ")", ",", "\"mBart requires --tgt_lang and --src_lang\"", "\n", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "tgt_lang", "]", "\n", "\n", "", "if", "model_args", ".", "freeze_embeds", ":", "\n", "        ", "freeze_embeds", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Freeze the word embedding\"", ")", "\n", "# freeze encoder", "\n", "", "if", "model_args", ".", "freeze_encoder", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_encoder", "(", ")", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_encoder", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Freeze the encoder\"", ")", "\n", "# freeze decoder", "\n", "", "if", "model_args", ".", "freeze_decoder", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_decoder", "(", ")", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_decoder", "(", ")", ")", "\n", "logger", ".", "info", "(", "f\"Freeze the decoder\"", ")", "\n", "# freeze some layers of the encoder", "\n", "", "if", "model_args", ".", "freeze_encoder_layer", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_encoder", "(", ")", ".", "layers", "[", ":", "model_args", ".", "freeze_encoder_layer", "]", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_encoder", "(", ")", ".", "layers", "[", ":", "model_args", ".", "freeze_encoder_layer", "]", ")", "\n", "logger", ".", "info", "(", "f\"Freeze the first {model_args.freeze_encoder_layer} layer(s) in the encoder\"", ")", "\n", "# freeze some layers of the decoder", "\n", "", "if", "model_args", ".", "freeze_decoder_layer", ":", "\n", "        ", "freeze_params", "(", "model", ".", "get_decoder", "(", ")", ".", "layers", "[", ":", "model_args", ".", "freeze_decoder_layer", "]", ")", "\n", "assert_all_frozen", "(", "model", ".", "get_decoder", "(", ")", ".", "layers", "[", ":", "model_args", ".", "freeze_decoder_layer", "]", ")", "\n", "logger", ".", "info", "(", "f\"Freeze the first {model_args.freeze_decoder_layer} layer(s) in the decoder\"", ")", "\n", "# reset the encoder", "\n", "", "if", "model_args", ".", "reset_encoder", ":", "\n", "        ", "model", ".", "get_encoder", "(", ")", ".", "init_weights", "(", ")", "\n", "logger", ".", "info", "(", "f\"Reset the encoder\"", ")", "\n", "# reset the decoder", "\n", "", "if", "model_args", ".", "reset_decoder", ":", "\n", "        ", "model", ".", "get_decoder", "(", ")", ".", "init_weights", "(", ")", "\n", "logger", ".", "info", "(", "f\"Reset the decoder\"", ")", "\n", "\n", "", "dataset_class", "=", "Seq2SeqDataset", "\n", "\n", "# Get datasets", "\n", "train_dataset", "=", "(", "\n", "dataset_class", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"train\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_train", ",", "\n", "max_target_length", "=", "data_args", ".", "max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_train", "\n", "else", "None", "\n", ")", "\n", "eval_dataset", "=", "(", "\n", "dataset_class", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"val\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_val", ",", "\n", "max_target_length", "=", "data_args", ".", "val_max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_eval", "or", "training_args", ".", "evaluation_strategy", "!=", "EvaluationStrategy", ".", "NO", "\n", "else", "None", "\n", ")", "\n", "test_dataset", "=", "(", "\n", "dataset_class", "(", "\n", "tokenizer", ",", "\n", "type_path", "=", "\"test\"", ",", "\n", "data_dir", "=", "data_args", ".", "data_dir", ",", "\n", "n_obs", "=", "data_args", ".", "n_test", ",", "\n", "max_target_length", "=", "data_args", ".", "test_max_target_length", ",", "\n", "max_source_length", "=", "data_args", ".", "max_source_length", ",", "\n", "prefix", "=", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "if", "training_args", ".", "do_predict", "\n", "else", "None", "\n", ")", "\n", "\n", "# Initialize our Trainer", "\n", "compute_metrics_fn", "=", "(", "\n", "build_compute_metrics_fn", "(", "data_args", ".", "task", ",", "tokenizer", ")", "if", "training_args", ".", "predict_with_generate", "else", "None", "\n", ")", "\n", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "eval_dataset", "=", "eval_dataset", ",", "\n", "data_collator", "=", "Seq2SeqDataCollator", "(", "tokenizer", ",", "data_args", ",", "training_args", ".", "tpu_num_cores", ")", ",", "\n", "compute_metrics", "=", "compute_metrics_fn", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", ")", "\n", "\n", "all_metrics", "=", "{", "}", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Train ***\"", ")", "\n", "\n", "train_result", "=", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "model_name_or_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "else", "None", "\n", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "metrics", "[", "\"train_n_objs\"", "]", "=", "data_args", ".", "n_train", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# this also saves the tokenizer", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "handle_metrics", "(", "\"train\"", ",", "metrics", ",", "training_args", ".", "output_dir", ")", "\n", "all_metrics", ".", "update", "(", "metrics", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# For convenience, we also re-save the tokenizer to the same directory,", "\n", "# so that you can share your model easily on huggingface.co/models =)", "\n", "tokenizer", ".", "save_pretrained", "(", "training_args", ".", "output_dir", ")", "\n", "\n", "# Evaluation", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "metrics", "=", "trainer", ".", "evaluate", "(", "\n", "metric_key_prefix", "=", "\"val\"", ",", "max_length", "=", "data_args", ".", "val_max_target_length", ",", "num_beams", "=", "data_args", ".", "eval_beams", "\n", ")", "\n", "metrics", "[", "\"val_n_objs\"", "]", "=", "data_args", ".", "n_val", "\n", "metrics", "[", "\"val_loss\"", "]", "=", "round", "(", "metrics", "[", "\"val_loss\"", "]", ",", "4", ")", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "handle_metrics", "(", "\"val\"", ",", "metrics", ",", "training_args", ".", "output_dir", ")", "\n", "all_metrics", ".", "update", "(", "metrics", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "test_output", "=", "trainer", ".", "predict", "(", "\n", "test_dataset", "=", "test_dataset", ",", "\n", "metric_key_prefix", "=", "\"test\"", ",", "\n", "max_length", "=", "data_args", ".", "val_max_target_length", ",", "\n", "num_beams", "=", "data_args", ".", "eval_beams", ",", "\n", ")", "\n", "metrics", "=", "test_output", ".", "metrics", "\n", "metrics", "[", "\"test_n_objs\"", "]", "=", "data_args", ".", "n_test", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "metrics", "[", "\"test_loss\"", "]", "=", "round", "(", "metrics", "[", "\"test_loss\"", "]", ",", "4", ")", "\n", "handle_metrics", "(", "\"test\"", ",", "metrics", ",", "training_args", ".", "output_dir", ")", "\n", "all_metrics", ".", "update", "(", "metrics", ")", "\n", "\n", "if", "training_args", ".", "predict_with_generate", ":", "\n", "                ", "test_preds", "=", "tokenizer", ".", "batch_decode", "(", "\n", "test_output", ".", "predictions", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "test_preds", "=", "lmap", "(", "str", ".", "strip", ",", "test_preds", ")", "\n", "write_txt_file", "(", "test_preds", ",", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"test_generations.txt\"", ")", ")", "\n", "\n", "", "", "", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "        ", "save_json", "(", "all_metrics", ",", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"all_results.json\"", ")", ")", "\n", "\n", "", "return", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer._mp_fn": [[396, 399], ["finetune_trainer.main"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.finetune_trainer.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.__init__": [[121, 156], ["torch.utils.data.Dataset.__init__", "pathlib.Path().joinpath", "pathlib.Path().joinpath", "pathlib.Path().joinpath", "os.path.exists", "dataset_kwargs.update", "utils.pickle_load", "utils.AbstractSeq2SeqDataset.get_char_lens", "min", "pathlib.Path", "pathlib.Path", "pathlib.Path", "isinstance"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__", "home.repos.pwc.inspect_result.chz816_tas.None.utils.pickle_load", "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.get_char_lens"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "data_dir", ",", "\n", "max_source_length", ",", "\n", "max_target_length", ",", "\n", "type_path", "=", "\"train\"", ",", "\n", "n_obs", "=", "None", ",", "\n", "bow_representation", "=", "None", ",", "\n", "prefix", "=", "\"\"", ",", "\n", "**", "dataset_kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".source\"", ")", "\n", "self", ".", "tgt_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".target\"", ")", "\n", "self", ".", "len_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".len\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "len_file", ")", ":", "\n", "            ", "self", ".", "src_lens", "=", "pickle_load", "(", "self", ".", "len_file", ")", "\n", "self", ".", "used_char_len", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "src_lens", "=", "self", ".", "get_char_lens", "(", "self", ".", "src_file", ")", "\n", "self", ".", "used_char_len", "=", "True", "\n", "", "self", ".", "max_source_length", "=", "max_source_length", "\n", "self", ".", "max_target_length", "=", "max_target_length", "\n", "assert", "min", "(", "self", ".", "src_lens", ")", ">", "0", ",", "f\"found empty line in {self.src_file}\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "prefix", "=", "prefix", "if", "prefix", "is", "not", "None", "else", "\"\"", "\n", "\n", "if", "n_obs", "is", "not", "None", ":", "\n", "            ", "self", ".", "src_lens", "=", "self", ".", "src_lens", "[", ":", "n_obs", "]", "\n", "", "self", ".", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "dataset_kwargs", "=", "dataset_kwargs", "\n", "dataset_kwargs", ".", "update", "(", "{", "\"add_prefix_space\"", ":", "True", "}", "if", "isinstance", "(", "self", ".", "tokenizer", ",", "BartTokenizer", ")", "else", "{", "}", ")", "\n", "\n", "self", ".", "bow_representation", "=", "bow_representation", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.__len__": [[157, 159], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "src_lens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.get_char_lens": [[160, 163], ["len", "pathlib.Path().open().readlines", "pathlib.Path().open", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_char_lens", "(", "data_file", ")", ":", "\n", "        ", "return", "[", "len", "(", "x", ")", "for", "x", "in", "Path", "(", "data_file", ")", ".", "open", "(", "encoding", "=", "'utf8'", ")", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.tgt_lens": [[164, 168], ["utils.AbstractSeq2SeqDataset.get_char_lens"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.get_char_lens"], ["", "@", "cached_property", "\n", "def", "tgt_lens", "(", "self", ")", ":", "\n", "        ", "\"\"\"Length in characters of target documents\"\"\"", "\n", "return", "self", ".", "get_char_lens", "(", "self", ".", "tgt_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_sortish_sampler": [[169, 174], ["utils.DistributedSortishSampler", "utils.SortishSampler"], "methods", ["None"], ["", "def", "make_sortish_sampler", "(", "self", ",", "batch_size", ",", "distributed", "=", "False", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "distributed", ":", "\n", "            ", "return", "DistributedSortishSampler", "(", "self", ",", "batch_size", ",", "shuffle", "=", "shuffle", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "SortishSampler", "(", "self", ".", "src_lens", ",", "batch_size", ",", "shuffle", "=", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_dynamic_sampler": [[175, 199], ["list", "batch_by_size", "numpy.argmax", "utils.AbstractSeq2SeqDataset.make_sortish_sampler", "min", "numpy.random.permutation", "max", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.make_sortish_sampler"], ["", "", "def", "make_dynamic_sampler", "(", "self", ",", "max_tokens_per_batch", "=", "1024", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "FAIRSEQ_AVAILABLE", ",", "\"Dynamic batch size requires `pip install fairseq`\"", "\n", "assert", "not", "self", ".", "used_char_len", ",", "\"You must call  python make_len_file.py before calling make_dynamic_sampler\"", "\n", "sorted_indices", "=", "list", "(", "self", ".", "make_sortish_sampler", "(", "1024", ",", "shuffle", "=", "False", ")", ")", "\n", "\n", "def", "num_tokens_in_example", "(", "i", ")", ":", "\n", "            ", "return", "min", "(", "self", ".", "src_lens", "[", "i", "]", ",", "self", ".", "max_target_length", ")", "\n", "\n", "# call fairseq cython function", "\n", "", "batch_sampler", ":", "List", "[", "List", "[", "int", "]", "]", "=", "batch_by_size", "(", "\n", "sorted_indices", ",", "\n", "num_tokens_fn", "=", "num_tokens_in_example", ",", "\n", "max_tokens", "=", "max_tokens_per_batch", ",", "\n", "required_batch_size_multiple", "=", "64", ",", "\n", ")", "\n", "shuffled_batches", "=", "[", "batch_sampler", "[", "i", "]", "for", "i", "in", "np", ".", "random", ".", "permutation", "(", "range", "(", "len", "(", "batch_sampler", ")", ")", ")", "]", "\n", "# move the largest batch to the front to OOM quickly (uses an approximation for padding)", "\n", "approximate_toks_per_batch", "=", "[", "max", "(", "self", ".", "src_lens", "[", "i", "]", "for", "i", "in", "batch", ")", "*", "len", "(", "batch", ")", "for", "batch", "in", "shuffled_batches", "]", "\n", "largest_batch_idx", "=", "np", ".", "argmax", "(", "approximate_toks_per_batch", ")", "\n", "shuffled_batches", "[", "0", "]", ",", "shuffled_batches", "[", "largest_batch_idx", "]", "=", "(", "\n", "shuffled_batches", "[", "largest_batch_idx", "]", ",", "\n", "shuffled_batches", "[", "0", "]", ",", "\n", ")", "\n", "return", "shuffled_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.__getitem__": [[200, 202], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.AbstractSeq2SeqDataset.collate_fn": [[203, 205], ["NotImplementedError"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.LegacySeq2SeqDataset.__getitem__": [[208, 225], ["linecache.getline().rstrip", "utils.LegacySeq2SeqDataset.encode_line", "utils.LegacySeq2SeqDataset.encode_line", "source_inputs[].squeeze", "target_inputs[].squeeze", "source_inputs[].squeeze", "linecache.getline().rstrip", "linecache.getline", "linecache.getline", "str", "str"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.LegacySeq2SeqDataset.encode_line", "home.repos.pwc.inspect_result.chz816_tas.None.utils.LegacySeq2SeqDataset.encode_line"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Call tokenizer on src and tgt_lines\"\"\"", "\n", "index", "=", "index", "+", "1", "# linecache starts at 1", "\n", "source_line", "=", "self", ".", "prefix", "+", "linecache", ".", "getline", "(", "str", "(", "self", ".", "src_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "tgt_line", "=", "linecache", ".", "getline", "(", "str", "(", "self", ".", "tgt_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "assert", "source_line", ",", "f\"empty source line for index {index}\"", "\n", "assert", "tgt_line", ",", "f\"empty tgt line for index {index}\"", "\n", "source_inputs", "=", "self", ".", "encode_line", "(", "self", ".", "tokenizer", ",", "source_line", ",", "self", ".", "max_source_length", ")", "\n", "target_inputs", "=", "self", ".", "encode_line", "(", "self", ".", "tokenizer", ",", "tgt_line", ",", "self", ".", "max_target_length", ")", "\n", "\n", "source_ids", "=", "source_inputs", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "target_ids", "=", "target_inputs", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "src_mask", "=", "source_inputs", "[", "\"attention_mask\"", "]", ".", "squeeze", "(", ")", "\n", "return", "{", "\n", "\"input_ids\"", ":", "source_ids", ",", "\n", "\"attention_mask\"", ":", "src_mask", ",", "\n", "\"labels\"", ":", "target_ids", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.LegacySeq2SeqDataset.encode_line": [[227, 236], ["tokenizer"], "methods", ["None"], ["", "def", "encode_line", "(", "self", ",", "tokenizer", ",", "line", ",", "max_length", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ":", "\n", "        ", "\"\"\"Only used by LegacyDataset\"\"\"", "\n", "return", "tokenizer", "(", "\n", "[", "line", "]", ",", "\n", "max_length", "=", "max_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "pad_to_max_length", "else", "None", ",", "\n", "truncation", "=", "True", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.LegacySeq2SeqDataset.collate_fn": [[238, 251], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.trim_batch", "utils.trim_batch"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch", "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "input_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"input_ids\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "masks", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"attention_mask\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "target_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"labels\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "pad_token_id", "=", "self", ".", "pad_token_id", "\n", "y", "=", "trim_batch", "(", "target_ids", ",", "pad_token_id", ")", "\n", "source_ids", ",", "source_mask", "=", "trim_batch", "(", "input_ids", ",", "pad_token_id", ",", "attention_mask", "=", "masks", ")", "\n", "batch", "=", "{", "\n", "\"input_ids\"", ":", "source_ids", ",", "\n", "\"attention_mask\"", ":", "source_mask", ",", "\n", "\"labels\"", ":", "y", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataset.__getitem__": [[256, 263], ["linecache.getline().rstrip", "linecache.getline().rstrip", "linecache.getline", "linecache.getline", "str", "str"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "        ", "index", "=", "index", "+", "1", "# linecache starts at 1", "\n", "source_line", "=", "self", ".", "prefix", "+", "linecache", ".", "getline", "(", "str", "(", "self", ".", "src_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "tgt_line", "=", "linecache", ".", "getline", "(", "str", "(", "self", ".", "tgt_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "assert", "source_line", ",", "f\"empty source line for index {index}\"", "\n", "assert", "tgt_line", ",", "f\"empty tgt line for index {index}\"", "\n", "return", "{", "\"tgt_texts\"", ":", "tgt_line", ",", "\"src_texts\"", ":", "source_line", ",", "\"id\"", ":", "index", "-", "1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataset.collate_fn": [[264, 276], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.Seq2SeqDataset.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Call prepare_seq2seq_batch.\"\"\"", "\n", "batch_encoding", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "max_target_length", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", ".", "data", "\n", "batch_encoding", "[", "\"ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "x", "[", "\"id\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "return", "batch_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.TAASSeq2SeqDataset.__getitem__": [[281, 292], ["linecache.getline().rstrip", "linecache.getline().rstrip", "type", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "linecache.getline", "utils.TAASSeq2SeqDataset.bow_representation[].todense", "linecache.getline", "str", "str"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "        ", "index", "=", "index", "+", "1", "# linecache starts at 1", "\n", "source_line", "=", "self", ".", "prefix", "+", "linecache", ".", "getline", "(", "str", "(", "self", ".", "src_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "tgt_line", "=", "linecache", ".", "getline", "(", "str", "(", "self", ".", "tgt_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "if", "type", "(", "self", ".", "bow_representation", "[", "index", "-", "1", "]", ")", "==", "scipy", ".", "sparse", ".", "csr", ".", "csr_matrix", ":", "\n", "            ", "bow", "=", "torch", ".", "FloatTensor", "(", "self", ".", "bow_representation", "[", "index", "-", "1", "]", ".", "todense", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "bow", "=", "torch", ".", "FloatTensor", "(", "self", ".", "bow_representation", "[", "index", "-", "1", "]", ")", "\n", "", "assert", "source_line", ",", "f\"empty source line for index {index}\"", "\n", "assert", "tgt_line", ",", "f\"empty tgt line for index {index}\"", "\n", "return", "{", "\"tgt_texts\"", ":", "tgt_line", ",", "\"src_texts\"", ":", "source_line", ",", "\"id\"", ":", "index", "-", "1", ",", "\"bow\"", ":", "bow", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.TAASSeq2SeqDataset.collate_fn": [[293, 306], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.TAASSeq2SeqDataset.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Call prepare_seq2seq_batch.\"\"\"", "\n", "batch_encoding", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "max_target_length", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", ".", "data", "\n", "batch_encoding", "[", "\"ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "x", "[", "\"id\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "batch_encoding", "[", "\"bow\"", "]", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"bow\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "return", "batch_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.TAASSeq2SeqDataCollator.__init__": [[309, 322], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "data_args", ",", "tpu_num_cores", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", "\n", "assert", "(", "\n", "self", ".", "pad_token_id", "is", "not", "None", "\n", ")", ",", "f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "tpu_num_cores", "=", "tpu_num_cores", "\n", "self", ".", "dataset_kwargs", "=", "{", "\"add_prefix_space\"", ":", "True", "}", "if", "isinstance", "(", "tokenizer", ",", "BartTokenizer", ")", "else", "{", "}", "\n", "if", "data_args", ".", "src_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"src_lang\"", "]", "=", "data_args", ".", "src_lang", "\n", "", "if", "data_args", ".", "tgt_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"tgt_lang\"", "]", "=", "data_args", ".", "tgt_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.TAASSeq2SeqDataCollator.__call__": [[323, 348], ["hasattr", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.TAASSeq2SeqDataCollator._encode", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.trim_batch", "utils.trim_batch"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator._encode", "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch", "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch"], ["", "", "def", "__call__", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"prepare_seq2seq_batch\"", ")", ":", "\n", "            ", "bow", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"bow\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "batch", "=", "self", ".", "_encode", "(", "batch", ")", "\n", "input_ids", ",", "attention_mask", ",", "labels", "=", "(", "\n", "batch", "[", "\"input_ids\"", "]", ",", "\n", "batch", "[", "\"attention_mask\"", "]", ",", "\n", "batch", "[", "\"labels\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"input_ids\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "attention_mask", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"attention_mask\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"labels\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "bow", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"bow\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "\n", "labels", "=", "trim_batch", "(", "labels", ",", "self", ".", "pad_token_id", ")", "\n", "input_ids", ",", "attention_mask", "=", "trim_batch", "(", "input_ids", ",", "self", ".", "pad_token_id", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "\"bow\"", ":", "bow", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.TAASSeq2SeqDataCollator._encode": [[349, 360], ["utils.TAASSeq2SeqDataCollator.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "batch_encoding", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "data_args", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "data_args", ".", "max_target_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "self", ".", "tpu_num_cores", "is", "not", "None", "else", "\"longest\"", ",", "# TPU hack", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n", "return", "batch_encoding", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator.__init__": [[363, 376], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "data_args", ",", "tpu_num_cores", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", "\n", "assert", "(", "\n", "self", ".", "pad_token_id", "is", "not", "None", "\n", ")", ",", "f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "tpu_num_cores", "=", "tpu_num_cores", "\n", "self", ".", "dataset_kwargs", "=", "{", "\"add_prefix_space\"", ":", "True", "}", "if", "isinstance", "(", "tokenizer", ",", "BartTokenizer", ")", "else", "{", "}", "\n", "if", "data_args", ".", "src_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"src_lang\"", "]", "=", "data_args", ".", "src_lang", "\n", "", "if", "data_args", ".", "tgt_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"tgt_lang\"", "]", "=", "data_args", ".", "tgt_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator.__call__": [[377, 399], ["hasattr", "utils.Seq2SeqDataCollator._encode", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.trim_batch", "utils.trim_batch"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator._encode", "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch", "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch"], ["", "", "def", "__call__", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"prepare_seq2seq_batch\"", ")", ":", "\n", "            ", "batch", "=", "self", ".", "_encode", "(", "batch", ")", "\n", "input_ids", ",", "attention_mask", ",", "labels", "=", "(", "\n", "batch", "[", "\"input_ids\"", "]", ",", "\n", "batch", "[", "\"attention_mask\"", "]", ",", "\n", "batch", "[", "\"labels\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"input_ids\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "attention_mask", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"attention_mask\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"labels\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "\n", "labels", "=", "trim_batch", "(", "labels", ",", "self", ".", "pad_token_id", ")", "\n", "input_ids", ",", "attention_mask", "=", "trim_batch", "(", "input_ids", ",", "self", ".", "pad_token_id", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator._shift_right_t5": [[400, 406], ["input_ids.new_zeros", "input_ids[].clone"], "methods", ["None"], ["", "def", "_shift_right_t5", "(", "self", ",", "input_ids", ")", ":", "\n", "# shift inputs to the right", "\n", "        ", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", "...", ",", "1", ":", "]", "=", "input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", "...", ",", "0", "]", "=", "self", ".", "pad_token_id", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.Seq2SeqDataCollator._encode": [[407, 418], ["utils.Seq2SeqDataCollator.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "batch_encoding", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "data_args", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "data_args", ".", "max_target_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "self", ".", "tpu_num_cores", "is", "not", "None", "else", "\"longest\"", ",", "# TPU hack", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n", "return", "batch_encoding", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.SortishSampler.__init__": [[423, 425], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "data", ",", "self", ".", "bs", ",", "self", ".", "shuffle", "=", "data", ",", "batch_size", ",", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.SortishSampler.__len__": [[426, 428], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.SortishSampler.__iter__": [[429, 431], ["iter", "utils.sortish_sampler_indices"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.sortish_sampler_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "sortish_sampler_indices", "(", "self", ".", "data", ",", "self", ".", "bs", ",", "shuffle", "=", "self", ".", "shuffle", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.DistributedSortishSampler.__init__": [[457, 479], ["torch.get_world_size", "torch.get_world_size", "torch.get_rank", "torch.get_rank", "int", "len", "len", "torch.is_available", "torch.is_available", "RuntimeError", "torch.is_available", "torch.is_available", "RuntimeError", "math.ceil", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "add_extra_examples", "=", "True", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "num_replicas", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "num_replicas", "=", "dist", ".", "get_world_size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "epoch", "=", "0", "\n", "if", "add_extra_examples", ":", "\n", "            ", "self", ".", "num_samples", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "*", "1.0", "/", "self", ".", "num_replicas", ")", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "", "else", ":", "\n", "            ", "self", ".", "total_size", "=", "len", "(", "dataset", ")", "\n", "self", ".", "num_samples", "=", "len", "(", "self", ".", "available_indices", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "add_extra_examples", "=", "add_extra_examples", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.DistributedSortishSampler.__iter__": [[480, 489], ["torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "utils.sortish_sampler_indices", "iter", "len"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.sortish_sampler_indices"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterable", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "\n", "sortish_data", "=", "[", "self", ".", "dataset", ".", "src_lens", "[", "i", "]", "for", "i", "in", "self", ".", "available_indices", "]", "\n", "sortish_indices", "=", "sortish_sampler_indices", "(", "sortish_data", ",", "self", ".", "batch_size", ",", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "indices", "=", "[", "self", ".", "available_indices", "[", "i", "]", "for", "i", "in", "sortish_indices", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.DistributedSortishSampler.available_indices": [[490, 499], ["list", "range", "len", "len", "len"], "methods", ["None"], ["", "@", "cached_property", "\n", "def", "available_indices", "(", "self", ")", "->", "np", ".", "array", ":", "\n", "        ", "indices", "=", "list", "(", "range", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "# add extra samples to make it evenly divisible", "\n", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "# subsample", "\n", "available_indices", "=", "indices", "[", "self", ".", "rank", ":", "self", ".", "total_size", ":", "self", ".", "num_replicas", "]", "\n", "return", "available_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.DistributedSortishSampler.__len__": [[500, 502], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.DistributedSortishSampler.set_epoch": [[503, 505], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.label_smoothed_nll_loss": [[47, 66], ["nll_loss.squeeze.sum", "smooth_loss.squeeze.sum", "target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.eq", "nll_loss.squeeze.masked_fill_", "smooth_loss.squeeze.masked_fill_", "nll_loss.squeeze.squeeze", "smooth_loss.squeeze.squeeze", "lprobs.size", "lprobs.dim"], "function", ["None"], ["", "def", "label_smoothed_nll_loss", "(", "lprobs", ",", "target", ",", "epsilon", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "    ", "\"\"\"From fairseq\"\"\"", "\n", "if", "target", ".", "dim", "(", ")", "==", "lprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "target", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "nll_loss", "=", "-", "lprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ")", "\n", "smooth_loss", "=", "-", "lprobs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "pad_mask", "=", "target", ".", "eq", "(", "ignore_index", ")", "\n", "nll_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "smooth_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "nll_loss", "=", "nll_loss", ".", "sum", "(", ")", "# mean()? Scared to break other math.", "\n", "smooth_loss", "=", "smooth_loss", ".", "sum", "(", ")", "\n", "eps_i", "=", "epsilon", "/", "lprobs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.0", "-", "epsilon", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap": [[68, 71], ["list", "map"], "function", ["None"], ["", "def", "lmap", "(", "f", ":", "Callable", ",", "x", ":", "Iterable", ")", "->", "List", ":", "\n", "    ", "\"\"\"list(map(f, x))\"\"\"", "\n", "return", "list", "(", "map", "(", "f", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_bleu": [[73, 76], ["round", "sacrebleu.corpus_bleu"], "function", ["None"], ["", "def", "calculate_bleu", "(", "output_lns", ",", "refs_lns", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "    ", "\"\"\"Uses sacrebleu's corpus_bleu implementation.\"\"\"", "\n", "return", "{", "\"bleu\"", ":", "round", "(", "corpus_bleu", "(", "output_lns", ",", "[", "refs_lns", "]", ",", "**", "kwargs", ")", ".", "score", ",", "4", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.build_compute_metrics_fn": [[78, 105], ["numpy.count_nonzero", "tokenizer.batch_decode", "tokenizer.batch_decode", "utils.lmap", "utils.lmap", "utils.build_compute_metrics_fn.decode_pred"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap", "home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap"], ["", "def", "build_compute_metrics_fn", "(", "task_name", ":", "str", ",", "tokenizer", ":", "PreTrainedTokenizer", ")", "->", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", ":", "\n", "    ", "def", "non_pad_len", "(", "tokens", ":", "np", ".", "ndarray", ")", "->", "int", ":", "\n", "        ", "return", "np", ".", "count_nonzero", "(", "tokens", "!=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "def", "decode_pred", "(", "pred", ":", "EvalPrediction", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "pred_str", "=", "tokenizer", ".", "batch_decode", "(", "pred", ".", "predictions", ",", "skip_special_tokens", "=", "True", ")", "\n", "label_str", "=", "tokenizer", ".", "batch_decode", "(", "pred", ".", "label_ids", ",", "skip_special_tokens", "=", "True", ")", "\n", "pred_str", "=", "lmap", "(", "str", ".", "strip", ",", "pred_str", ")", "\n", "label_str", "=", "lmap", "(", "str", ".", "strip", ",", "label_str", ")", "\n", "return", "pred_str", ",", "label_str", "\n", "\n", "", "def", "summarization_metrics", "(", "pred", ":", "EvalPrediction", ")", "->", "Dict", ":", "\n", "        ", "pred_str", ",", "label_str", "=", "decode_pred", "(", "pred", ")", "\n", "rouge", ":", "Dict", "=", "calculate_rouge", "(", "pred_str", ",", "label_str", ")", "\n", "summ_len", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "lmap", "(", "non_pad_len", ",", "pred", ".", "predictions", ")", ")", ",", "1", ")", "\n", "rouge", ".", "update", "(", "{", "\"gen_len\"", ":", "summ_len", "}", ")", "\n", "return", "rouge", "\n", "\n", "", "def", "translation_metrics", "(", "pred", ":", "EvalPrediction", ")", "->", "Dict", ":", "\n", "        ", "pred_str", ",", "label_str", "=", "decode_pred", "(", "pred", ")", "\n", "bleu", ":", "Dict", "=", "calculate_bleu", "(", "pred_str", ",", "label_str", ")", "\n", "gen_len", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "lmap", "(", "non_pad_len", ",", "pred", ".", "predictions", ")", ")", ",", "1", ")", "\n", "bleu", ".", "update", "(", "{", "\"gen_len\"", ":", "gen_len", "}", ")", "\n", "return", "bleu", "\n", "\n", "", "compute_metrics_fn", "=", "summarization_metrics", "if", "\"summarization\"", "in", "task_name", "else", "translation_metrics", "\n", "return", "compute_metrics_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.trim_batch": [[107, 118], ["input_ids.ne().any", "input_ids.ne"], "function", ["None"], ["", "def", "trim_batch", "(", "\n", "input_ids", ",", "\n", "pad_token_id", ",", "\n", "attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Remove columns that are populated exclusively by pad_token_id\"\"\"", "\n", "keep_column_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "any", "(", "dim", "=", "0", ")", "\n", "if", "attention_mask", "is", "None", ":", "\n", "        ", "return", "input_ids", "[", ":", ",", "keep_column_mask", "]", "\n", "", "else", ":", "\n", "        ", "return", "(", "input_ids", "[", ":", ",", "keep_column_mask", "]", ",", "attention_mask", "[", ":", ",", "keep_column_mask", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.sortish_sampler_indices": [[433, 452], ["numpy.random.permutation", "numpy.concatenate", "numpy.argmax", "numpy.concatenate", "numpy.argsort", "len", "numpy.concatenate", "numpy.array", "range", "sorted", "range", "utils.sortish_sampler_indices.key_fn"], "function", ["None"], ["", "", "def", "sortish_sampler_indices", "(", "data", ":", "List", ",", "bs", ":", "int", ",", "shuffle", "=", "True", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"Go through the text data by order of src length with a bit of randomness. From fastai repo.\"", "\n", "if", "not", "shuffle", ":", "\n", "        ", "return", "np", ".", "argsort", "(", "np", ".", "array", "(", "data", ")", "*", "-", "1", ")", "\n", "\n", "", "def", "key_fn", "(", "i", ")", ":", "\n", "        ", "return", "data", "[", "i", "]", "\n", "\n", "", "idxs", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "data", ")", ")", "\n", "sz", "=", "bs", "*", "50", "\n", "ck_idx", "=", "[", "idxs", "[", "i", ":", "i", "+", "sz", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "idxs", ")", ",", "sz", ")", "]", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "[", "sorted", "(", "s", ",", "key", "=", "key_fn", ",", "reverse", "=", "True", ")", "for", "s", "in", "ck_idx", "]", ")", "\n", "sz", "=", "bs", "\n", "ck_idx", "=", "[", "sort_idx", "[", "i", ":", "i", "+", "sz", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sort_idx", ")", ",", "sz", ")", "]", "\n", "max_ck", "=", "np", ".", "argmax", "(", "[", "key_fn", "(", "ck", "[", "0", "]", ")", "for", "ck", "in", "ck_idx", "]", ")", "# find the chunk with the largest key,", "\n", "ck_idx", "[", "0", "]", ",", "ck_idx", "[", "max_ck", "]", "=", "ck_idx", "[", "max_ck", "]", ",", "ck_idx", "[", "0", "]", "# then make sure it goes first.", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "np", ".", "random", ".", "permutation", "(", "ck_idx", "[", "1", ":", "]", ")", ")", "if", "len", "(", "ck_idx", ")", ">", "1", "else", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "(", "ck_idx", "[", "0", "]", ",", "sort_idx", ")", ")", "\n", "return", "sort_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.use_task_specific_params": [[510, 519], ["task_specific_params.get", "logger.info", "logger.info", "model.config.update"], "function", ["None"], ["def", "use_task_specific_params", "(", "model", ",", "task", ")", ":", "\n", "    ", "\"\"\"Update config with summarization specific params.\"\"\"", "\n", "task_specific_params", "=", "model", ".", "config", ".", "task_specific_params", "\n", "\n", "if", "task_specific_params", "is", "not", "None", ":", "\n", "        ", "pars", "=", "task_specific_params", ".", "get", "(", "task", ",", "{", "}", ")", "\n", "logger", ".", "info", "(", "f\"setting model.config to task specific params for {task}:\\n {pars}\"", ")", "\n", "logger", ".", "info", "(", "\"note: command line args may override some of these\"", ")", "\n", "model", ".", "config", ".", "update", "(", "pars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.pickle_load": [[521, 525], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "pickle_load", "(", "path", ")", ":", "\n", "    ", "\"\"\"pickle.load(path)\"\"\"", "\n", "with", "open", "(", "path", ",", "\"rb\"", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.pickle_save": [[527, 531], ["open", "pickle.dump"], "function", ["None"], ["", "", "def", "pickle_save", "(", "obj", ",", "path", ")", ":", "\n", "    ", "\"\"\"pickle.dump(obj, path)\"\"\"", "\n", "with", "open", "(", "path", ",", "\"wb\"", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "dump", "(", "obj", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.flatten_list": [[533, 535], ["itertools.chain.from_iterable"], "function", ["None"], ["", "", "def", "flatten_list", "(", "summary_ids", ":", "List", "[", "List", "]", ")", ":", "\n", "    ", "return", "[", "x", "for", "x", "in", "itertools", ".", "chain", ".", "from_iterable", "(", "summary_ids", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json": [[537, 540], ["open", "json.dump"], "function", ["None"], ["", "def", "save_json", "(", "content", ",", "path", ",", "indent", "=", "4", ",", "**", "json_dump_kwargs", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "content", ",", "f", ",", "indent", "=", "indent", ",", "sort_keys", "=", "True", ",", "**", "json_dump_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.load_json": [[542, 545], ["open", "json.load"], "function", ["None"], ["", "", "def", "load_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.extract_rouge_mid_statistics": [[550, 556], ["dct.items", "round", "getattr"], "function", ["None"], ["def", "extract_rouge_mid_statistics", "(", "dct", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "k1", ",", "v1", "in", "dct", ".", "items", "(", ")", ":", "\n", "        ", "mid", "=", "v1", ".", "mid", "\n", "new_dict", "[", "k1", "]", "=", "{", "stat", ":", "round", "(", "getattr", "(", "mid", ",", "stat", ")", ",", "2", ")", "for", "stat", "in", "[", "\"precision\"", ",", "\"recall\"", ",", "\"fmeasure\"", "]", "}", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge": [[558, 604], ["rouge_score.rouge_scorer.RougeScorer", "rouge_score.scoring.BootstrapAggregator", "zip", "rouge_scorer.RougeScorer.score", "scoring.BootstrapAggregator.add_scores", "scoring.BootstrapAggregator.aggregate", "sentence_splitter.add_newline_to_end_of_each_sentence", "sentence_splitter.add_newline_to_end_of_each_sentence", "utils.extract_rouge_mid_statistics", "round", "aggregator.aggregate.items"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.chz816_tas.None.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.chz816_tas.None.utils.extract_rouge_mid_statistics"], ["", "def", "calculate_rouge", "(", "\n", "pred_lns", ":", "List", "[", "str", "]", ",", "\n", "tgt_lns", ":", "List", "[", "str", "]", ",", "\n", "use_stemmer", "=", "True", ",", "\n", "rouge_keys", "=", "ROUGE_KEYS", ",", "\n", "return_precision_and_recall", "=", "False", ",", "\n", "bootstrap_aggregation", "=", "True", ",", "\n", "newline_sep", "=", "True", ",", "\n", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"Calculate rouge using rouge_scorer package.\n\n    Args:\n        pred_lns: list of summaries generated by model\n        tgt_lns: list of groundtruth summaries (e.g. contents of val.target)\n        use_stemmer:  Bool indicating whether Porter stemmer should be used to\n        strip word suffixes to improve matching.\n        rouge_keys:  which metrics to compute, defaults to rouge1, rouge2, rougeL, rougeLsum\n        return_precision_and_recall: (False) whether to also return precision and recall.\n        bootstrap_aggregation: whether to do the typical bootstrap resampling of scores. Defaults to True, if False\n            this function returns a collections.defaultdict[metric: list of values for each observation for each subscore]``\n        newline_sep:(default=True) whether to add newline between sentences. This is essential for calculation rougeL\n        on multi sentence summaries (CNN/DM dataset).\n\n    Returns:\n         Dict[score: value] if aggregate else defaultdict(list) keyed by rouge_keys\n\n    \"\"\"", "\n", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "rouge_keys", ",", "use_stemmer", "=", "use_stemmer", ")", "\n", "aggregator", "=", "scoring", ".", "BootstrapAggregator", "(", ")", "\n", "for", "pred", ",", "tgt", "in", "zip", "(", "tgt_lns", ",", "pred_lns", ")", ":", "\n", "# rougeLsum expects \"\\n\" separated sentences within a summary", "\n", "        ", "if", "newline_sep", ":", "\n", "            ", "pred", "=", "add_newline_to_end_of_each_sentence", "(", "pred", ")", "\n", "tgt", "=", "add_newline_to_end_of_each_sentence", "(", "tgt", ")", "\n", "", "scores", "=", "scorer", ".", "score", "(", "pred", ",", "tgt", ")", "\n", "aggregator", ".", "add_scores", "(", "scores", ")", "\n", "\n", "", "if", "bootstrap_aggregation", ":", "\n", "        ", "result", "=", "aggregator", ".", "aggregate", "(", ")", "\n", "if", "return_precision_and_recall", ":", "\n", "            ", "return", "extract_rouge_mid_statistics", "(", "result", ")", "# here we return dict", "\n", "", "else", ":", "\n", "            ", "return", "{", "k", ":", "round", "(", "v", ".", "mid", ".", "fmeasure", "*", "100", ",", "2", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "aggregator", ".", "_scores", "# here we return defaultdict(list)", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params": [[609, 613], ["model.parameters"], "function", ["None"], ["", "", "def", "freeze_params", "(", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Set requires_grad=False for each of model.parameters()\"\"\"", "\n", "for", "par", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "par", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_embeds": [[615, 632], ["utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params", "home.repos.pwc.inspect_result.chz816_tas.None.utils.freeze_params"], ["", "", "def", "freeze_embeds", "(", "model", ")", ":", "\n", "    ", "\"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"", "\n", "model_type", "=", "model", ".", "config", ".", "model_type", "\n", "\n", "if", "model_type", "==", "\"t5\"", ":", "\n", "        ", "freeze_params", "(", "model", ".", "shared", ")", "\n", "for", "d", "in", "[", "model", ".", "encoder", ",", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "", "", "elif", "model_type", "==", "\"fsmt\"", ":", "\n", "        ", "for", "d", "in", "[", "model", ".", "model", ".", "encoder", ",", "model", ".", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_positions", ")", "\n", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "", "", "else", ":", "\n", "        ", "freeze_params", "(", "model", ".", "model", ".", "shared", ")", "\n", "for", "d", "in", "[", "model", ".", "model", ".", "encoder", ",", "model", ".", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_positions", ")", "\n", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.grad_status": [[634, 636], ["model.parameters"], "function", ["None"], ["", "", "", "def", "grad_status", "(", "model", ":", "nn", ".", "Module", ")", "->", "Iterable", ":", "\n", "    ", "return", "(", "par", ".", "requires_grad", "for", "par", "in", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.any_requires_grad": [[638, 640], ["any", "utils.grad_status"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.grad_status"], ["", "def", "any_requires_grad", "(", "model", ":", "nn", ".", "Module", ")", "->", "bool", ":", "\n", "    ", "return", "any", "(", "grad_status", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_all_frozen": [[642, 647], ["list", "sum", "len", "utils.grad_status", "utils.lmap", "any"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.grad_status", "home.repos.pwc.inspect_result.chz816_tas.None.utils.lmap"], ["", "def", "assert_all_frozen", "(", "model", ")", ":", "\n", "    ", "model_grads", ":", "List", "[", "bool", "]", "=", "list", "(", "grad_status", "(", "model", ")", ")", "\n", "n_require_grad", "=", "sum", "(", "lmap", "(", "int", ",", "model_grads", ")", ")", "\n", "npars", "=", "len", "(", "model_grads", ")", "\n", "assert", "not", "any", "(", "model_grads", ")", ",", "f\"{n_require_grad / npars:.1%} of {npars} weights require grad\"", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.assert_not_all_frozen": [[649, 653], ["list", "len", "any", "utils.grad_status"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.grad_status"], ["", "def", "assert_not_all_frozen", "(", "model", ")", ":", "\n", "    ", "model_grads", ":", "List", "[", "bool", "]", "=", "list", "(", "grad_status", "(", "model", ")", ")", "\n", "npars", "=", "len", "(", "model_grads", ")", "\n", "assert", "any", "(", "model_grads", ")", ",", "f\"none of {npars} weights require grad\"", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.parse_numeric_n_bool_cl_kwargs": [[655, 678], ["range", "len", "unparsed_args[].startswith", "len", "unparsed_args[].lower", "unparsed_args[].lower", "int", "float"], "function", ["None"], ["", "def", "parse_numeric_n_bool_cl_kwargs", "(", "unparsed_args", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "float", ",", "bool", "]", "]", ":", "\n", "    ", "\"\"\"\n    Parse an argv list of unspecified command line args to a dict.\n    Assumes all values are either numeric or boolean in the form of true/false.\n    \"\"\"", "\n", "result", "=", "{", "}", "\n", "assert", "len", "(", "unparsed_args", ")", "%", "2", "==", "0", ",", "f\"got odd number of unparsed args: {unparsed_args}\"", "\n", "num_pairs", "=", "len", "(", "unparsed_args", ")", "//", "2", "\n", "for", "pair_num", "in", "range", "(", "num_pairs", ")", ":", "\n", "        ", "i", "=", "2", "*", "pair_num", "\n", "assert", "unparsed_args", "[", "i", "]", ".", "startswith", "(", "\"--\"", ")", "\n", "if", "unparsed_args", "[", "i", "+", "1", "]", ".", "lower", "(", ")", "==", "\"true\"", ":", "\n", "            ", "value", "=", "True", "\n", "", "elif", "unparsed_args", "[", "i", "+", "1", "]", ".", "lower", "(", ")", "==", "\"false\"", ":", "\n", "            ", "value", "=", "False", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "value", "=", "int", "(", "unparsed_args", "[", "i", "+", "1", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "value", "=", "float", "(", "unparsed_args", "[", "i", "+", "1", "]", ")", "# this can raise another informative ValueError", "\n", "\n", "", "", "result", "[", "unparsed_args", "[", "i", "]", "[", "2", ":", "]", "]", "=", "value", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.write_txt_file": [[680, 685], ["pathlib.Path().open", "Path().open.write", "Path().open.flush", "pathlib.Path"], "function", ["None"], ["", "def", "write_txt_file", "(", "ordered_tgt", ",", "path", ")", ":", "\n", "    ", "f", "=", "Path", "(", "path", ")", ".", "open", "(", "\"w\"", ",", "encoding", "=", "'utf8'", ")", "\n", "for", "ln", "in", "ordered_tgt", ":", "\n", "        ", "f", ".", "write", "(", "ln", "+", "\"\\n\"", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.chunks": [[687, 691], ["range", "len"], "function", ["None"], ["", "", "def", "chunks", "(", "lst", ",", "n", ")", ":", "\n", "    ", "\"\"\"Yield successive n-sized chunks from lst.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "lst", ")", ",", "n", ")", ":", "\n", "        ", "yield", "lst", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.utils.check_output_dir": [[693, 712], ["os.path.exists", "ValueError", "len", "os.listdir", "len", "os.listdir"], "function", ["None"], ["", "", "def", "check_output_dir", "(", "args", ",", "expected_items", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Checks whether to bail out if output_dir already exists and has more than expected_items in it\n\n    `args`: needs to have the following attributes of `args`:\n      - output_dir\n      - do_train\n      - overwrite_output_dir\n\n    `expected_items`: normally 0 (default) - i.e. empty dir, but in some cases a few files are expected (e.g. recovery from OOM)\n    \"\"\"", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "len", "(", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", ")", ">", "expected_items", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and \"", "\n", "f\"has {len(os.listdir(args.output_dir))} items in it (expected {expected_items} items). \"", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.rouge_cli.calculate_rouge_path": [[20, 28], ["utils.calculate_rouge", "x.strip", "utils.save_json", "open().readlines", "x.strip", "len", "open().readlines", "open", "open"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.utils.calculate_rouge", "home.repos.pwc.inspect_result.chz816_tas.None.utils.save_json"], ["def", "calculate_rouge_path", "(", "pred_path", ",", "tgt_path", ",", "save_path", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Kwargs will be passed to calculate_rouge\"\"\"", "\n", "pred_lns", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "open", "(", "pred_path", ")", ".", "readlines", "(", ")", "]", "\n", "tgt_lns", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "open", "(", "tgt_path", ")", ".", "readlines", "(", ")", "]", "[", ":", "len", "(", "pred_lns", ")", "]", "\n", "metrics", "=", "calculate_rouge", "(", "pred_lns", ",", "tgt_lns", ",", "**", "kwargs", ")", "\n", "if", "save_path", "is", "not", "None", ":", "\n", "        ", "save_json", "(", "metrics", ",", "save_path", ",", "indent", "=", "None", ")", "\n", "", "return", "metrics", "# these print nicely", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm._is_digit": [[30, 35], ["ch.isdigit"], "function", ["None"], ["def", "_is_digit", "(", "w", ")", ":", "\n", "    ", "for", "ch", "in", "w", ":", "\n", "        ", "if", "not", "(", "ch", ".", "isdigit", "(", ")", "or", "ch", "==", "','", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.fix_tokenization": [[37, 119], ["text.split", "text.replace", "len", "output_tokens.append", "output_tokens.append", "output_tokens[].endswith", "output_tokens.append", "len", "output_tokens.append", "len", "len", "output_tokens.append", "output_tokens.append", "output_tokens.append", "postprocess_cnndm._is_digit", "postprocess_cnndm._is_digit", "len", "len", "output_tokens[].isdigit", "input_tokens[].isdigit", "len", "len", "output_tokens[].isupper", "input_tokens[].isupper", "len", "len", "len", "len", "len", "len", "input_tokens[].isupper", "output_tokens.append", "output_tokens.append", "len", "output_tokens.append", "len", "len", "output_tokens.append", "len"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm._is_digit", "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm._is_digit"], ["", "def", "fix_tokenization", "(", "text", ")", ":", "\n", "    ", "input_tokens", "=", "text", ".", "split", "(", ")", "\n", "output_tokens", "=", "[", "]", "\n", "has_left_quote", "=", "False", "\n", "has_left_single_quote", "=", "False", "\n", "\n", "i", "=", "0", "\n", "prev_dash", "=", "False", "\n", "while", "i", "<", "len", "(", "input_tokens", ")", ":", "\n", "        ", "tok", "=", "input_tokens", "[", "i", "]", "\n", "flag_prev_dash", "=", "False", "\n", "if", "tok", "==", "\"\\\"\"", ":", "\n", "            ", "if", "has_left_quote", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"''\"", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"``\"", ")", "\n", "", "has_left_quote", "=", "not", "has_left_quote", "\n", "i", "+=", "1", "\n", "", "elif", "tok", "==", "\"'\"", "and", "len", "(", "output_tokens", ")", ">", "0", "and", "output_tokens", "[", "-", "1", "]", ".", "endswith", "(", "\"n\"", ")", "and", "i", "<", "len", "(", "input_tokens", ")", "-", "1", "and", "input_tokens", "[", "i", "+", "1", "]", "==", "\"t\"", ":", "\n", "            ", "output_tokens", "[", "-", "1", "]", "=", "output_tokens", "[", "-", "1", "]", "[", ":", "-", "1", "]", "\n", "output_tokens", ".", "append", "(", "\"n't\"", ")", "\n", "i", "+=", "2", "\n", "", "elif", "tok", "==", "\"'\"", "and", "i", "<", "len", "(", "input_tokens", ")", "-", "1", "and", "input_tokens", "[", "i", "+", "1", "]", "in", "(", "\"s\"", ",", "\"d\"", ",", "\"ll\"", ")", ":", "\n", "            ", "output_tokens", ".", "append", "(", "\"'\"", "+", "input_tokens", "[", "i", "+", "1", "]", ")", "\n", "i", "+=", "2", "\n", "", "elif", "tok", "==", "\"'\"", ":", "\n", "            ", "if", "has_left_single_quote", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"'\"", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"`\"", ")", "\n", "", "has_left_single_quote", "=", "not", "has_left_single_quote", "\n", "i", "+=", "1", "\n", "", "elif", "tok", "==", "\".\"", "and", "i", "<", "len", "(", "input_tokens", ")", "-", "2", "and", "input_tokens", "[", "i", "+", "1", "]", "==", "\".\"", "and", "input_tokens", "[", "i", "+", "2", "]", "==", "\".\"", ":", "\n", "            ", "output_tokens", ".", "append", "(", "\"...\"", ")", "\n", "i", "+=", "3", "\n", "", "elif", "tok", "==", "\",\"", "and", "len", "(", "output_tokens", ")", ">", "0", "and", "_is_digit", "(", "output_tokens", "[", "-", "1", "]", ")", "and", "i", "<", "len", "(", "\n", "input_tokens", ")", "-", "1", "and", "_is_digit", "(", "input_tokens", "[", "i", "+", "1", "]", ")", ":", "\n", "# $ 3 , 000 -> $ 3,000", "\n", "            ", "output_tokens", "[", "-", "1", "]", "+=", "','", "+", "input_tokens", "[", "i", "+", "1", "]", "\n", "i", "+=", "2", "\n", "", "elif", "tok", "==", "\".\"", "and", "len", "(", "output_tokens", ")", ">", "0", "and", "output_tokens", "[", "-", "1", "]", ".", "isdigit", "(", ")", "and", "i", "<", "len", "(", "input_tokens", ")", "-", "1", "and", "input_tokens", "[", "i", "+", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "# 3 . 03 -> $ 3.03", "\n", "            ", "output_tokens", "[", "-", "1", "]", "+=", "'.'", "+", "input_tokens", "[", "i", "+", "1", "]", "\n", "i", "+=", "2", "\n", "", "elif", "tok", "==", "\".\"", "and", "len", "(", "output_tokens", ")", ">", "0", "and", "len", "(", "output_tokens", "[", "-", "1", "]", ")", "==", "1", "and", "output_tokens", "[", "\n", "-", "1", "]", ".", "isupper", "(", ")", "and", "i", "<", "len", "(", "input_tokens", ")", "-", "2", "and", "len", "(", "input_tokens", "[", "i", "+", "1", "]", ")", "==", "1", "and", "input_tokens", "[", "\n", "i", "+", "1", "]", ".", "isupper", "(", ")", "and", "input_tokens", "[", "i", "+", "2", "]", "==", "'.'", ":", "\n", "# U . N . -> U.N.", "\n", "            ", "k", "=", "i", "+", "3", "\n", "while", "k", "+", "2", "<", "len", "(", "input_tokens", ")", ":", "\n", "                ", "if", "len", "(", "input_tokens", "[", "k", "+", "1", "]", ")", "==", "1", "and", "input_tokens", "[", "k", "+", "1", "]", ".", "isupper", "(", ")", "and", "input_tokens", "[", "k", "+", "2", "]", "==", "'.'", ":", "\n", "                    ", "k", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "output_tokens", "[", "-", "1", "]", "+=", "''", ".", "join", "(", "input_tokens", "[", "i", ":", "k", "]", ")", "\n", "i", "+=", "2", "\n", "", "elif", "tok", "==", "\"-\"", ":", "\n", "            ", "if", "i", "<", "len", "(", "input_tokens", ")", "-", "1", "and", "input_tokens", "[", "i", "+", "1", "]", "==", "\"-\"", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"--\"", ")", "\n", "i", "+=", "2", "\n", "", "elif", "i", "==", "len", "(", "input_tokens", ")", "-", "1", "or", "i", "==", "0", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"-\"", ")", "\n", "i", "+=", "1", "\n", "", "elif", "output_tokens", "[", "-", "1", "]", "not", "in", "string", ".", "punctuation", "and", "input_tokens", "[", "i", "+", "1", "]", "[", "0", "]", "not", "in", "string", ".", "punctuation", ":", "\n", "                ", "output_tokens", "[", "-", "1", "]", "+=", "\"-\"", "\n", "i", "+=", "1", "\n", "flag_prev_dash", "=", "True", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "append", "(", "\"-\"", ")", "\n", "i", "+=", "1", "\n", "", "", "elif", "prev_dash", "and", "len", "(", "output_tokens", ")", ">", "0", "and", "tok", "[", "0", "]", "not", "in", "string", ".", "punctuation", ":", "\n", "            ", "output_tokens", "[", "-", "1", "]", "+=", "tok", "\n", "i", "+=", "1", "\n", "", "else", ":", "\n", "            ", "output_tokens", ".", "append", "(", "tok", ")", "\n", "i", "+=", "1", "\n", "", "prev_dash", "=", "flag_prev_dash", "\n", "", "text", "=", "' '", ".", "join", "(", "[", "x", "for", "x", "in", "output_tokens", "]", ")", "\n", "fine_text", "=", "text", ".", "replace", "(", "' ##'", ",", "''", ")", "\n", "return", "fine_text", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.remove_duplicate": [[121, 131], ["set", "enumerate", "l.lower().split", "set", "r_list.append", "l.lower", "len", "len"], "function", ["None"], ["", "def", "remove_duplicate", "(", "l_list", ",", "duplicate_rate", ")", ":", "\n", "    ", "tk_list", "=", "[", "l", ".", "lower", "(", ")", ".", "split", "(", ")", "for", "l", "in", "l_list", "]", "\n", "r_list", "=", "[", "]", "\n", "history_set", "=", "set", "(", ")", "\n", "for", "i", ",", "w_list", "in", "enumerate", "(", "tk_list", ")", ":", "\n", "        ", "w_set", "=", "set", "(", "w_list", ")", "\n", "if", "len", "(", "w_set", "&", "history_set", ")", "/", "len", "(", "w_set", ")", "<=", "duplicate_rate", ":", "\n", "            ", "r_list", ".", "append", "(", "l_list", "[", "i", "]", ")", "\n", "", "history_set", "|=", "w_set", "\n", "", "return", "r_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.rouge": [[133, 168], ["tempfile.mkdtemp", "len", "time.strftime", "os.path.join", "len", "len", "time.localtime", "os.path.isdir", "os.mkdir", "os.mkdir", "os.mkdir", "range", "bs_pyrouge.Rouge155", "bs_pyrouge.Rouge155.convert_and_evaluate", "print", "bs_pyrouge.Rouge155.output_to_dict", "os.path.isdir", "shutil.rmtree", "len", "open", "f.write", "open", "f.write"], "function", ["None"], ["", "def", "rouge", "(", "cand", ",", "ref", ")", ":", "\n", "    ", "temp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "candidates", "=", "cand", "\n", "references", "=", "ref", "\n", "assert", "len", "(", "candidates", ")", "==", "len", "(", "references", ")", "\n", "\n", "cnt", "=", "len", "(", "candidates", ")", "\n", "current_time", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ",", "\"rouge-tmp-{}\"", ".", "format", "(", "current_time", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/candidate\"", ")", "\n", "os", ".", "mkdir", "(", "tmp_dir", "+", "\"/reference\"", ")", "\n", "", "try", ":", "\n", "        ", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "            ", "if", "len", "(", "references", "[", "i", "]", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/candidate/cand.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "candidates", "[", "i", "]", ")", "\n", "", "with", "open", "(", "tmp_dir", "+", "\"/reference/ref.{}.txt\"", ".", "format", "(", "i", ")", ",", "\"w\"", ",", "\n", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "references", "[", "i", "]", ")", "\n", "", "", "r", "=", "Rouge155", "(", "temp_dir", "=", "temp_dir", ")", "\n", "r", ".", "model_dir", "=", "tmp_dir", "+", "\"/reference/\"", "\n", "r", ".", "system_dir", "=", "tmp_dir", "+", "\"/candidate/\"", "\n", "r", ".", "model_filename_pattern", "=", "'ref.#ID#.txt'", "\n", "r", ".", "system_filename_pattern", "=", "r'cand.(\\d+).txt'", "\n", "rouge_results", "=", "r", ".", "convert_and_evaluate", "(", ")", "\n", "print", "(", "rouge_results", ")", "\n", "results_dict", "=", "r", ".", "output_to_dict", "(", "rouge_results", ")", "\n", "", "finally", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "tmp_dir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.rouge_results_to_str": [[170, 178], ["None"], "function", ["None"], ["", "def", "rouge_results_to_str", "(", "results_dict", ")", ":", "\n", "    ", "return", "\">> ROUGE-F(1/2/l): {:.2f}/{:.2f}/{:.2f}\\nROUGE-R(1/2/3/l): {:.2f}/{:.2f}/{:.2f}\\n\"", ".", "format", "(", "\n", "results_dict", "[", "\"rouge_1_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_l_f_score\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_1_recall\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_2_recall\"", "]", "*", "100", ",", "\n", "results_dict", "[", "\"rouge_l_recall\"", "]", "*", "100", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.count_tokens": [[181, 189], ["counter.keys"], "function", ["None"], ["", "def", "count_tokens", "(", "tokens", ")", ":", "\n", "    ", "counter", "=", "{", "}", "\n", "for", "t", "in", "tokens", ":", "\n", "        ", "if", "t", "in", "counter", ".", "keys", "(", ")", ":", "\n", "            ", "counter", "[", "t", "]", "+=", "1", "\n", "", "else", ":", "\n", "            ", "counter", "[", "t", "]", "=", "1", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.get_f1": [[191, 205], ["text_a.lower().split", "text_b.lower().split", "postprocess_cnndm.count_tokens", "postprocess_cnndm.count_tokens", "count_tokens.keys", "len", "len", "text_a.lower", "text_b.lower", "len", "len", "count_tokens.keys", "min", "len", "len"], "function", ["home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.count_tokens", "home.repos.pwc.inspect_result.chz816_tas.None.postprocess_cnndm.count_tokens"], ["", "def", "get_f1", "(", "text_a", ",", "text_b", ")", ":", "\n", "    ", "tokens_a", "=", "text_a", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "tokens_b", "=", "text_b", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens_a", ")", "==", "0", "or", "len", "(", "tokens_b", ")", "==", "0", ":", "\n", "        ", "return", "1", "if", "len", "(", "tokens_a", ")", "==", "len", "(", "tokens_b", ")", "else", "0", "\n", "", "set_a", "=", "count_tokens", "(", "tokens_a", ")", "\n", "set_b", "=", "count_tokens", "(", "tokens_b", ")", "\n", "match", "=", "0", "\n", "for", "token", "in", "set_a", ".", "keys", "(", ")", ":", "\n", "        ", "if", "token", "in", "set_b", ".", "keys", "(", ")", ":", "\n", "            ", "match", "+=", "min", "(", "set_a", "[", "token", "]", ",", "set_b", "[", "token", "]", ")", "\n", "", "", "p", "=", "match", "/", "len", "(", "tokens_a", ")", "\n", "r", "=", "match", "/", "len", "(", "tokens_b", ")", "\n", "return", "2.0", "*", "p", "*", "r", "/", "(", "p", "+", "r", "+", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.__init__": [[19, 23], ["sklearn.feature_extraction.text.CountVectorizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "id2token", "=", "{", "}", "\n", "self", ".", "vectorizer", "=", "CountVectorizer", "(", "vocabulary", "=", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.TopicModelDataPreparation.create_training_set": [[24, 30], ["data_preparation.TopicModelDataPreparation.vectorizer.fit_transform", "topic_models.tm_dataset.CTMDataset", "zip", "range", "len"], "methods", ["None"], ["", "def", "create_training_set", "(", "self", ",", "text_for_bow", ")", ":", "\n", "        ", "train_bow_embeddings", "=", "self", ".", "vectorizer", ".", "fit_transform", "(", "text_for_bow", ")", "\n", "# self.vocab = self.vectorizer.get_feature_names()", "\n", "self", ".", "id2token", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "self", ".", "vocab", ")", ")", ",", "self", ".", "vocab", ")", "}", "\n", "\n", "return", "CTMDataset", "(", "train_bow_embeddings", ",", "self", ".", "id2token", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.data_preparation.get_bag_of_words": [[7, 16], ["scipy.sparse.csr_matrix", "numpy.bincount", "x[].astype", "numpy.sum", "numpy.array", "numpy.array"], "function", ["None"], ["def", "get_bag_of_words", "(", "data", ",", "min_length", ")", ":", "\n", "    ", "\"\"\"\n    Creates the bag of words\n    \"\"\"", "\n", "vect", "=", "[", "np", ".", "bincount", "(", "x", "[", "x", "!=", "np", ".", "array", "(", "None", ")", "]", ".", "astype", "(", "'int'", ")", ",", "minlength", "=", "min_length", ")", "\n", "for", "x", "in", "data", "if", "np", ".", "sum", "(", "x", "[", "x", "!=", "np", ".", "array", "(", "None", ")", "]", ")", "!=", "0", "]", "\n", "\n", "vect", "=", "scipy", ".", "sparse", ".", "csr_matrix", "(", "vect", ")", "\n", "return", "vect", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.tm_dataset.CTMDataset.__init__": [[9, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "X", ",", "idx2token", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            X : array-like, shape=(n_samples, n_features)\n                Document word matrix.\n        \"\"\"", "\n", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "idx2token", "=", "idx2token", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.tm_dataset.CTMDataset.__len__": [[19, 22], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return length of dataset.\"\"\"", "\n", "return", "self", ".", "X", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.tm_dataset.CTMDataset.__getitem__": [[23, 31], ["type", "torch.FloatTensor", "torch.FloatTensor", "tm_dataset.CTMDataset.X[].todense"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"Return sample from dataset at index i.\"\"\"", "\n", "if", "type", "(", "self", ".", "X", "[", "i", "]", ")", "==", "scipy", ".", "sparse", ".", "csr", ".", "csr_matrix", ":", "\n", "            ", "X", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X", "[", "i", "]", ".", "todense", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "X", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X", "[", "i", "]", ")", "\n", "\n", "", "return", "{", "'X'", ":", "X", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.loss.topic_modeling_loss": [[8, 28], ["torch.sum", "torch.sum", "loss.mean", "prior_variance.log().sum", "posterior_log_variance.sum", "torch.sum", "prior_variance.log", "torch.log"], "function", ["None"], ["def", "topic_modeling_loss", "(", "inputs", ",", "topic_num", ",", "word_dists", ",", "prior_mean", ",", "prior_variance", ",", "\n", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ")", ":", "\n", "# KL term", "\n", "# var division term", "\n", "    ", "var_division", "=", "torch", ".", "sum", "(", "posterior_variance", "/", "prior_variance", ",", "dim", "=", "1", ")", "\n", "# diff means term", "\n", "diff_means", "=", "prior_mean", "-", "posterior_mean", "\n", "diff_term", "=", "torch", ".", "sum", "(", "(", "diff_means", "*", "diff_means", ")", "/", "prior_variance", ",", "dim", "=", "1", ")", "\n", "# logvar det division term", "\n", "logvar_det_division", "=", "prior_variance", ".", "log", "(", ")", ".", "sum", "(", ")", "-", "posterior_log_variance", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# combine terms", "\n", "KL", "=", "0.5", "*", "(", "var_division", "+", "diff_term", "-", "topic_num", "+", "logvar_det_division", ")", "\n", "\n", "# Reconstruction term", "\n", "RL", "=", "-", "torch", ".", "sum", "(", "inputs", "*", "torch", ".", "log", "(", "word_dists", "+", "1e-10", ")", ",", "dim", "=", "1", ")", "\n", "\n", "loss", "=", "KL", "+", "RL", "\n", "\n", "# the losses are averaged across observations for each minibatch", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.__init__": [[16, 26], ["set", "nltk.corpus.stopwords.words"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "documents", ",", "stopwords_language", "=", "\"english\"", ",", "vocabulary_size", "=", "2000", ")", ":", "\n", "        ", "\"\"\"\n\n        :param documents: list of strings\n        :param stopwords_language: string of the language of the stopwords (see nltk stopwords)\n        :param vocabulary_size: the number of most frequent words to include in the documents. Infrequent words will be discarded from the list of preprocessed documents\n        \"\"\"", "\n", "self", ".", "documents", "=", "documents", "\n", "self", ".", "stopwords", "=", "set", "(", "stop_words", ".", "words", "(", "stopwords_language", ")", ")", "\n", "self", ".", "vocabulary_size", "=", "vocabulary_size", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.topic_models.preprocessing.WhiteSpacePreprocessing.preprocess": [[27, 62], ["enumerate", "doc.lower", "doc.translate", "sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.CountVectorizer.fit_transform", "set", "list", "str.maketrans", "sklearn.feature_extraction.text.CountVectorizer.get_feature_names", "len", "preprocessed_docs.append", "preprocessed_docs.append", "open", "f.write", "len", "doc.split", "len", "w.isdigit"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "vocabulary", "=", "None", ",", "save", "=", "False", ",", "save_path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Note that if after filtering some documents do not contain words we remove them. That is why we return also the\n        list of unpreprocessed documents.\n\n        :return: preprocessed documents, unpreprocessed documents and the vocabulary list\n        \"\"\"", "\n", "preprocessed_docs_tmp", "=", "self", ".", "documents", "\n", "preprocessed_docs_tmp", "=", "[", "doc", ".", "lower", "(", ")", "for", "doc", "in", "preprocessed_docs_tmp", "]", "\n", "# remove the punctuation", "\n", "preprocessed_docs_tmp", "=", "[", "doc", ".", "translate", "(", "str", ".", "maketrans", "(", "string", ".", "punctuation", ",", "' '", "*", "len", "(", "string", ".", "punctuation", ")", ")", ")", "for", "doc", "\n", "in", "preprocessed_docs_tmp", "]", "\n", "\n", "if", "vocabulary", "is", "None", ":", "\n", "# learn the vocabulary", "\n", "            ", "vectorizer", "=", "CountVectorizer", "(", "max_features", "=", "self", ".", "vocabulary_size", ",", "token_pattern", "=", "r'\\b[a-zA-Z]{2,}\\b'", ")", "\n", "vectorizer", ".", "fit_transform", "(", "preprocessed_docs_tmp", ")", "\n", "vocabulary", "=", "set", "(", "vectorizer", ".", "get_feature_names", "(", ")", ")", "\n", "\n", "", "preprocessed_docs", "=", "[", "]", "\n", "for", "i", ",", "doc", "in", "enumerate", "(", "preprocessed_docs_tmp", ")", ":", "\n", "            ", "processed_doc", "=", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "doc", ".", "split", "(", ")", "if", "len", "(", "\n", "w", ")", ">", "0", "and", "w", "not", "in", "self", ".", "stopwords", "and", "not", "w", ".", "isdigit", "(", ")", "and", "w", "in", "vocabulary", "]", ")", "\n", "if", "len", "(", "processed_doc", ")", ">", "0", ":", "\n", "                ", "preprocessed_docs", ".", "append", "(", "processed_doc", ")", "\n", "", "else", ":", "\n", "                ", "preprocessed_docs", ".", "append", "(", "preprocessed_docs", "[", "-", "1", "]", ")", "\n", "\n", "# save the preprocessed_docs", "\n", "", "", "if", "save", "and", "save_path", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "save_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "preprocessed_docs", ":", "\n", "                    ", "f", ".", "write", "(", "f\"{line}\\n\"", ")", "\n", "\n", "", "", "", "return", "preprocessed_docs", ",", "list", "(", "vocabulary", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.__init__": [[17, 84], ["torch.nn.Module.__init__", "isinstance", "isinstance", "torch.tensor", "torch.cuda.is_available", "torch.tensor", "torch.cuda.is_available", "torch.Tensor", "torch.cuda.is_available", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "isinstance", "topic_models.networks.inference_network.ContextualInferenceNetwork", "decoding_network.DecoderNetwork.prior_mean.cuda", "torch.nn.Parameter", "decoding_network.DecoderNetwork.prior_variance.cuda", "torch.nn.Parameter", "decoding_network.DecoderNetwork.topic_word.cuda", "topic_models.networks.inference_network.CombinedInferenceNetwork", "Exception"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "bert_size", ",", "infnet", ",", "num_topics", ",", "model_type", "=", "'prodLDA'", ",", "\n", "hidden_sizes", "=", "(", "100", ",", "100", ")", ",", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ",", "\n", "learn_priors", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            vocab_size : int, dimension of input\n            num_topics : int, number of topic components, (default 10)\n            model_type : string, 'prodLDA' or 'LDA' (default 'prodLDA')\n            hidden_sizes : tuple, length = n_layers, (default (100, 100))\n            activation : string, 'softplus', 'relu', (default 'softplus')\n            learn_priors : bool, make priors learnable parameter\n        \"\"\"", "\n", "super", "(", "DecoderNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "vocab_size", ",", "int", ")", ",", "\"vocab_size must by type int.\"", "\n", "assert", "isinstance", "(", "num_topics", ",", "int", ")", "and", "num_topics", ">", "0", ",", "\"num_topics must be type int > 0.\"", "\n", "assert", "model_type", "in", "[", "'prodLDA'", ",", "'LDA'", "]", ",", "\"model type must be 'prodLDA' or 'LDA'\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "num_topics", "=", "num_topics", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "learn_priors", "=", "learn_priors", "\n", "\n", "if", "infnet", "==", "\"zeroshot\"", ":", "\n", "            ", "self", ".", "inf_net", "=", "ContextualInferenceNetwork", "(", "vocab_size", ",", "bert_size", ",", "num_topics", ",", "hidden_sizes", ",", "activation", ")", "\n", "", "elif", "infnet", "==", "\"combined\"", ":", "\n", "            ", "self", ".", "inf_net", "=", "CombinedInferenceNetwork", "(", "vocab_size", ",", "bert_size", ",", "num_topics", ",", "hidden_sizes", ",", "activation", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Missing infnet parameter, options are zeroshot and combined'", ")", "\n", "\n", "# init prior parameters", "\n", "# \\mu_1k = log \\alpha_k + 1/K \\sum_i log \\alpha_i;", "\n", "# \\alpha = 1 \\forall \\alpha", "\n", "", "topic_prior_mean", "=", "0.0", "\n", "self", ".", "prior_mean", "=", "torch", ".", "tensor", "(", "[", "topic_prior_mean", "]", "*", "num_topics", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "prior_mean", "=", "self", ".", "prior_mean", ".", "cuda", "(", ")", "\n", "", "if", "self", ".", "learn_priors", ":", "\n", "            ", "self", ".", "prior_mean", "=", "nn", ".", "Parameter", "(", "self", ".", "prior_mean", ")", "\n", "\n", "# \\Sigma_1kk = 1 / \\alpha_k (1 - 2/K) + 1/K^2 \\sum_i 1 / \\alpha_k;", "\n", "# \\alpha = 1 \\forall \\alpha", "\n", "", "topic_prior_variance", "=", "1.", "-", "(", "1.", "/", "self", ".", "num_topics", ")", "\n", "self", ".", "prior_variance", "=", "torch", ".", "tensor", "(", "\n", "[", "topic_prior_variance", "]", "*", "num_topics", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "prior_variance", "=", "self", ".", "prior_variance", ".", "cuda", "(", ")", "\n", "", "if", "self", ".", "learn_priors", ":", "\n", "            ", "self", ".", "prior_variance", "=", "nn", ".", "Parameter", "(", "self", ".", "prior_variance", ")", "\n", "\n", "", "self", ".", "topic_word", "=", "torch", ".", "Tensor", "(", "num_topics", ",", "vocab_size", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "topic_word", "=", "self", ".", "topic_word", ".", "cuda", "(", ")", "\n", "", "self", ".", "topic_word", "=", "nn", ".", "Parameter", "(", "self", ".", "topic_word", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "topic_word", ")", "\n", "\n", "self", ".", "topic_word_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "vocab_size", ",", "affine", "=", "False", ")", "\n", "\n", "# dropout on h", "\n", "self", ".", "drop_h", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.reparameterize": [[85, 91], ["torch.exp", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "reparameterize", "(", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"Reparameterize the h distribution.\"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.forward": [[92, 115], ["decoding_network.DecoderNetwork.inf_net", "torch.exp", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.drop_h", "decoding_network.DecoderNetwork.reparameterize", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.topic_word_batchnorm", "torch.nn.functional.softmax", "torch.matmul", "torch.matmul", "decoding_network.DecoderNetwork.topic_word_batchnorm"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.reparameterize"], ["", "def", "forward", "(", "self", ",", "x", ",", "latent_representation", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        - word_dist: batch_size x vocab_size\n        \"\"\"", "\n", "# batch_size x num_topics", "\n", "posterior_mu", ",", "posterior_log_sigma", "=", "self", ".", "inf_net", "(", "x", ",", "latent_representation", ")", "\n", "posterior_sigma", "=", "torch", ".", "exp", "(", "posterior_log_sigma", ")", "\n", "\n", "# generate samples from h - h.size: batch_size * num_topics", "\n", "h", "=", "F", ".", "softmax", "(", "self", ".", "reparameterize", "(", "posterior_mu", ",", "posterior_log_sigma", ")", ",", "dim", "=", "1", ")", "\n", "h", "=", "self", ".", "drop_h", "(", "h", ")", "\n", "\n", "# prodLDA vs LDA", "\n", "if", "self", ".", "model_type", "==", "'prodLDA'", ":", "\n", "# in: batch_size x vocab_size x num_topics", "\n", "            ", "word_dist", "=", "F", ".", "softmax", "(", "self", ".", "topic_word_batchnorm", "(", "torch", ".", "matmul", "(", "h", ",", "self", ".", "topic_word", ")", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "model_type", "==", "'LDA'", ":", "\n", "# simplex constrain on topic_word", "\n", "            ", "self", ".", "topic_word", "=", "F", ".", "softmax", "(", "self", ".", "topic_word_batchnorm", "(", "self", ".", "topic_word", ")", ",", "dim", "=", "1", ")", "\n", "word_dist", "=", "torch", ".", "matmul", "(", "h", ",", "self", ".", "topic_word", ")", "\n", "\n", "", "return", "self", ".", "prior_mean", ",", "self", ".", "prior_variance", ",", "posterior_mu", ",", "posterior_sigma", ",", "posterior_log_sigma", ",", "word_dist", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.get_theta": [[116, 126], ["torch.no_grad", "decoding_network.DecoderNetwork.inf_net", "torch.exp", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.reparameterize"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.decoding_network.DecoderNetwork.reparameterize"], ["", "def", "get_theta", "(", "self", ",", "x", ",", "latent_representation", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# batch_size x n_components", "\n", "            ", "posterior_mu", ",", "posterior_log_sigma", "=", "self", ".", "inf_net", "(", "x", ",", "latent_representation", ")", "\n", "posterior_sigma", "=", "torch", ".", "exp", "(", "posterior_log_sigma", ")", "\n", "\n", "# generate samples from theta", "\n", "theta", "=", "F", ".", "softmax", "(", "self", ".", "reparameterize", "(", "posterior_mu", ",", "posterior_log_sigma", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "theta", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.ContextualInferenceNetwork.__init__": [[18, 61], ["torch.nn.Module.__init__", "isinstance", "isinstance", "isinstance", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Softplus", "collections.OrderedDict", "torch.nn.ReLU", "torch.nn.Sequential", "enumerate", "torch.nn.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "latent_representation_size", ",", "output_size", ",", "hidden_sizes", ",", "\n", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            vocab_size : int, dimension of input\n            output_size : int, dimension of output\n            hidden_sizes : tuple, length = n_layers\n            activation : string, 'softplus' or 'relu', default 'softplus'\n            dropout : float, default 0.2, default 0.2\n        \"\"\"", "\n", "super", "(", "ContextualInferenceNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "vocab_size", ",", "int", ")", ",", "\"vocab_size must by type int.\"", "\n", "assert", "isinstance", "(", "output_size", ",", "int", ")", ",", "\"output_size must be type int.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "if", "activation", "==", "'softplus'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "vocab_size", "+", "vocab_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "self", ".", "adapt", "=", "nn", ".", "Linear", "(", "latent_representation_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "\n", "self", ".", "hiddens", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'l_{}'", ".", "format", "(", "i", ")", ",", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "h_in", ",", "h_out", ")", ",", "self", ".", "activation", ")", ")", "\n", "for", "i", ",", "(", "h_in", ",", "h_out", ")", "in", "enumerate", "(", "zip", "(", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", "[", "1", ":", "]", ")", ")", "]", ")", ")", "\n", "\n", "self", ".", "f_mu", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_mu_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "f_sigma", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_sigma_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "dropout_enc", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.ContextualInferenceNetwork.forward": [[62, 73], ["inference_network.ContextualInferenceNetwork.adapt", "inference_network.ContextualInferenceNetwork.activation", "inference_network.ContextualInferenceNetwork.hiddens", "inference_network.ContextualInferenceNetwork.dropout_enc", "inference_network.ContextualInferenceNetwork.f_mu_batchnorm", "inference_network.ContextualInferenceNetwork.f_sigma_batchnorm", "inference_network.ContextualInferenceNetwork.f_mu", "inference_network.ContextualInferenceNetwork.f_sigma"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "latent_representation", ")", ":", "\n", "        ", "\"\"\"Generate mu and sigma - Inference Network\"\"\"", "\n", "latent_representation", "=", "self", ".", "adapt", "(", "latent_representation", ")", "\n", "\n", "x", "=", "self", ".", "activation", "(", "latent_representation", ")", "\n", "x", "=", "self", ".", "hiddens", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_enc", "(", "x", ")", "\n", "mu", "=", "self", ".", "f_mu_batchnorm", "(", "self", ".", "f_mu", "(", "x", ")", ")", "\n", "log_sigma", "=", "self", ".", "f_sigma_batchnorm", "(", "self", ".", "f_sigma", "(", "x", ")", ")", "\n", "\n", "return", "mu", ",", "log_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__": [[81, 127], ["torch.nn.Module.__init__", "isinstance", "isinstance", "isinstance", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Softplus", "collections.OrderedDict", "torch.nn.ReLU", "torch.nn.Sequential", "enumerate", "torch.nn.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "latent_representation_size", ",", "output_size", ",", "hidden_sizes", ",", "\n", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            vocab_size : int, dimension of input\n            output_size : int, dimension of output\n            hidden_sizes : tuple, length = n_layers\n            activation : string, 'softplus' or 'relu', default 'softplus'\n            dropout : float, default 0.2, default 0.2\n        \"\"\"", "\n", "super", "(", "CombinedInferenceNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "vocab_size", ",", "int", ")", ",", "\"vocab_size must by type int.\"", "\n", "assert", "isinstance", "(", "output_size", ",", "int", ")", ",", "\"output_size must be type int.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "if", "activation", "==", "'softplus'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "vocab_size", "+", "vocab_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "self", ".", "adapt", "=", "nn", ".", "Linear", "(", "latent_representation_size", ",", "vocab_size", ")", "\n", "self", ".", "bert_layer", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "0", "]", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "\n", "self", ".", "hiddens", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'l_{}'", ".", "format", "(", "i", ")", ",", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "h_in", ",", "h_out", ")", ",", "self", ".", "activation", ")", ")", "\n", "for", "i", ",", "(", "h_in", ",", "h_out", ")", "in", "enumerate", "(", "zip", "(", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", "[", "1", ":", "]", ")", ")", "]", ")", ")", "\n", "\n", "self", ".", "f_mu", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_mu_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "f_sigma", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_sigma_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "dropout_enc", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chz816_tas.networks.inference_network.CombinedInferenceNetwork.forward": [[128, 141], ["inference_network.CombinedInferenceNetwork.adapt", "torch.cat", "inference_network.CombinedInferenceNetwork.input_layer", "inference_network.CombinedInferenceNetwork.activation", "inference_network.CombinedInferenceNetwork.hiddens", "inference_network.CombinedInferenceNetwork.dropout_enc", "inference_network.CombinedInferenceNetwork.f_mu_batchnorm", "inference_network.CombinedInferenceNetwork.f_sigma_batchnorm", "inference_network.CombinedInferenceNetwork.f_mu", "inference_network.CombinedInferenceNetwork.f_sigma"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "latent_representation", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "latent_representation", "=", "self", ".", "adapt", "(", "latent_representation", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "latent_representation", ")", ",", "1", ")", "\n", "x", "=", "self", ".", "input_layer", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "hiddens", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_enc", "(", "x", ")", "\n", "mu", "=", "self", ".", "f_mu_batchnorm", "(", "self", ".", "f_mu", "(", "x", ")", ")", "\n", "log_sigma", "=", "self", ".", "f_sigma_batchnorm", "(", "self", ".", "f_sigma", "(", "x", ")", ")", "\n", "\n", "return", "mu", ",", "log_sigma", "\n", "", "", ""]]}