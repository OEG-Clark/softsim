{"home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.MulLayer.__init__": [[40, 44], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN_onlyrecurrent.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.MulLayer.get_output_for": [[45, 47], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.MulLayer.get_output_shape_for": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__": [[58, 134], ["lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.MergeLayer.__init__", "isinstance", "incomings.append", "incomings.append", "len", "ValueError", "len", "ValueError", "ValueError", "IndRNN_onlyrecurrent.onlyRecurrentLayer.add_param", "len", "len", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["def", "__init__", "(", "self", ",", "incoming", ",", "input_to_hidden", ",", "hidden_to_hidden", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# This layer inherits from a MergeLayer, because it can have three", "\n", "# inputs - the layer input, the mask and the initial hidden state.  We", "\n", "# will just provide the layer input as incomings, unless a mask input", "\n", "# or initial hidden state was provided.", "\n", "        ", "incomings", "=", "[", "incoming", "]", "\n", "self", ".", "mask_incoming_index", "=", "-", "1", "\n", "self", ".", "hid_init_incoming_index", "=", "-", "1", "\n", "if", "mask_input", "is", "not", "None", ":", "\n", "            ", "incomings", ".", "append", "(", "mask_input", ")", "\n", "self", ".", "mask_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "incomings", ".", "append", "(", "hid_init", ")", "\n", "self", ".", "hid_init_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "\n", "", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "__init__", "(", "incomings", ",", "**", "kwargs", ")", "\n", "\n", "input_to_hidden_in_layers", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "input_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "input_to_hidden_in_layers", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`input_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "input_to_hidden_in_layers", ")", ")", ")", "\n", "\n", "", "hidden_to_hidden_in_lyrs", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "hidden_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "hidden_to_hidden_in_lyrs", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`hidden_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "hidden_to_hidden_in_lyrs", ")", ")", ")", "\n", "", "hidden_to_hidden_in_layer", "=", "hidden_to_hidden_in_lyrs", "[", "0", "]", "\n", "\n", "self", ".", "input_to_hidden", "=", "input_to_hidden", "\n", "self", ".", "hidden_to_hidden", "=", "hidden_to_hidden", "\n", "self", ".", "learn_init", "=", "learn_init", "\n", "self", ".", "backwards", "=", "backwards", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "grad_clipping", "=", "grad_clipping", "\n", "self", ".", "unroll_scan", "=", "unroll_scan", "\n", "self", ".", "precompute_input", "=", "precompute_input", "\n", "self", ".", "only_return_final", "=", "only_return_final", "\n", "\n", "\n", "if", "unroll_scan", "and", "gradient_steps", "!=", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Gradient steps must be -1 when unroll_scan is true.\"", ")", "\n", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "\n", "if", "nonlinearity", "is", "None", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearities", ".", "identity", "\n", "", "else", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "\n", "# Initialize hidden state", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "self", ".", "hid_init", "=", "hid_init", "\n", "", "else", ":", "\n", "            ", "self", ".", "hid_init", "=", "self", ".", "add_param", "(", "\n", "hid_init", ",", "(", "1", ",", ")", "+", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ",", "\n", "name", "=", "\"hid_init\"", ",", "trainable", "=", "learn_init", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params": [[135, 142], ["super().get_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params"], ["", "", "def", "get_params", "(", "self", ",", "**", "tags", ")", ":", "\n", "# Get all parameters from this layer, the master layer", "\n", "        ", "params", "=", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "get_params", "(", "**", "tags", ")", "\n", "# Combine with all parameters from the child layers", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "input_to_hidden", ",", "**", "tags", ")", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ",", "**", "tags", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_shape_for": [[143, 155], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shapes", ")", ":", "\n", "# The shape of the input to this layer will be the first element", "\n", "# of input_shapes, whether or not a mask input is being used.", "\n", "        ", "input_shape", "=", "input_shapes", "[", "0", "]", "\n", "# When only_return_final is true, the second (sequence step) dimension", "\n", "# will be flattened", "\n", "if", "self", ".", "only_return_final", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", "\n", "# Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "\n", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for": [[156, 251], ["lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "IndRNN_onlyrecurrent.onlyRecurrentLayer.nonlinearity", "IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for.step"], "methods", ["None"], ["", "", "def", "get_output_for", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Retrieve the layer input", "\n", "        ", "input", "=", "inputs", "[", "0", "]", "\n", "# Retrieve the mask when it is supplied", "\n", "mask", "=", "None", "\n", "hid_init", "=", "None", "\n", "if", "self", ".", "mask_incoming_index", ">", "0", ":", "\n", "            ", "mask", "=", "inputs", "[", "self", ".", "mask_incoming_index", "]", "\n", "", "if", "self", ".", "hid_init_incoming_index", ">", "0", ":", "\n", "            ", "hid_init", "=", "inputs", "[", "self", ".", "hid_init_incoming_index", "]", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, n_features)", "\n", "# but scan requires the iterable dimension to be first", "\n", "# So, we need to dimshuffle to (n_time_steps, n_batch, n_features)", "\n", "#input = input.dimshuffle(1, 0, *range(2, input.ndim))", "\n", "", "seq_len", ",", "num_batch", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "# We will always pass the hidden-to-hidden layer params to step", "\n", "non_seqs", "=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ")", "\n", "\n", "# Create single recurrent computation step function", "\n", "def", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Compute the hidden-to-hidden activation", "\n", "            ", "hid_pre", "=", "helper", ".", "get_output", "(", "\n", "self", ".", "hidden_to_hidden", ",", "hid_previous", ",", "**", "kwargs", ")", "\n", "\n", "hid_pre", "+=", "input_n", "\n", "\n", "# Clip gradients", "\n", "if", "self", ".", "grad_clipping", ":", "\n", "                ", "hid_pre", "=", "theano", ".", "gradient", ".", "grad_clip", "(", "\n", "hid_pre", ",", "-", "self", ".", "grad_clipping", ",", "self", ".", "grad_clipping", ")", "\n", "\n", "", "return", "self", ".", "nonlinearity", "(", "hid_pre", ")", "\n", "\n", "", "def", "step_masked", "(", "input_n", ",", "mask_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Skip over any input with mask 0 by copying the previous", "\n", "# hidden state; proceed normally for any input with mask 1.", "\n", "            ", "hid", "=", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", "\n", "hid_out", "=", "T", ".", "switch", "(", "mask_n", ",", "hid", ",", "hid_previous", ")", "\n", "return", "[", "hid_out", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "dimshuffle", "(", "1", ",", "0", ",", "'x'", ")", "\n", "sequences", "=", "[", "input", ",", "mask", "]", "\n", "step_fun", "=", "step_masked", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "input", "\n", "step_fun", "=", "step", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "hid_init", ",", "Layer", ")", ":", "\n", "# The code below simply repeats self.hid_init num_batch times in", "\n", "# its first dimension.  Turns out using a dot product and a", "\n", "# dimshuffle is faster than T.repeat.", "\n", "            ", "dot_dims", "=", "(", "list", "(", "range", "(", "1", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", ")", ")", "+", "\n", "[", "0", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", "]", ")", "\n", "hid_init", "=", "T", ".", "dot", "(", "T", ".", "ones", "(", "(", "num_batch", ",", "1", ")", ")", ",", "\n", "self", ".", "hid_init", ".", "dimshuffle", "(", "dot_dims", ")", ")", "\n", "\n", "", "if", "self", ".", "unroll_scan", ":", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "            ", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "# Explicitly unroll the recurrence instead of using scan", "\n", "hid_out", "=", "unroll_scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "n_steps", "=", "input_shape", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# Scan op iterates over first dimension of input and repeatedly", "\n", "# applies the step function", "\n", "            ", "hid_out", "=", "theano", ".", "scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "truncate_gradient", "=", "self", ".", "gradient_steps", ",", "\n", "strict", "=", "True", ")", "[", "0", "]", "\n", "\n", "# When it is requested that we only return the final sequence step,", "\n", "# we need to slice it out immediately after scan is applied", "\n", "", "if", "self", ".", "only_return_final", ":", "\n", "            ", "hid_out", "=", "hid_out", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "# dimshuffle back to (n_batch, n_time_steps, n_features))", "\n", "#hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))", "\n", "\n", "# if scan is backward reverse the output", "\n", "            ", "if", "self", ".", "backwards", ":", "\n", "                ", "hid_out", "=", "hid_out", "[", ":", ":", "-", "1", ",", ":", "]", "\n", "\n", "", "", "return", "hid_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.None.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__": [[255, 320], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "IndRNN_onlyrecurrent.MulLayer", "IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "#W_in_to_hid=init.Uniform(),", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "#b=init.Constant(0.),", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "InputLayer", "(", "input_shape", ")", "\n", "\n", "#         in_to_hid = DenseLayer(InputLayer((None,) + input_shape[2:]),", "\n", "#                                num_units, W=W_in_to_hid, b=b,", "\n", "#                                nonlinearity=None,", "\n", "#                                name=basename + 'input_to_hidden',", "\n", "#                                **layer_kwargs)        ", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "#self.W_in_to_hid = in_to_hid.W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "#self.b = in_to_hid.b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer_onlyrecurrent", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.adding.build_rnn_network": [[63, 75], ["lasagne.layers.InputLayer", "lasagne.layers.DenseLayer", "print", "rnnmodel", "lasagne.layers.get_output_shape", "rnnmodel", "lasagne.layers.Gate", "rnnmodel", "lasagne.init.Normal", "lasagne.init.Constant", "numpy.identity", "lasagne.init.Normal"], "function", ["None"], ["def", "build_rnn_network", "(", "rnnmodel", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "feature_size", ")", ")", "\n", "if", "rnnmodel", "==", "LSTMLayer", ":", "\n", "      ", "net", "[", "'rnn'", "]", "=", "rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "forgetgate", "=", "lasagne", ".", "layers", ".", "Gate", "(", "b", "=", "lasagne", ".", "init", ".", "Constant", "(", "1.", ")", ")", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "", "elif", "act", "==", "rectify", ":", "\n", "      ", "net", "[", "'rnn'", "]", "=", "rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "W_hid_to_hid", "=", "lambda", "shape", ":", "np", ".", "identity", "(", "hidden_units", ",", "dtype", "=", "np", ".", "float32", ")", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "", "elif", "act", "==", "tanh", ":", "\n", "      ", "net", "[", "'rnn'", "]", "=", "rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "None", ")", "\n", "print", "(", "lasagne", ".", "layers", ".", "get_output_shape", "(", "net", "[", "'out'", "]", ")", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.adding.build_indrnn_network": [[78, 89], ["lasagne.layers.InputLayer", "lasagne.layers.DenseLayer", "res_rnnmodel", "res_rnnmodel", "res_rnnmodel", "res_rnnmodel", "lasagne.init.Normal", "lasagne.init.Uniform", "lasagne.init.Normal", "lasagne.init.Uniform", "lasagne.init.Normal", "lasagne.init.Uniform", "lasagne.init.Normal", "lasagne.init.Uniform"], "function", ["None"], ["", "def", "build_indrnn_network", "(", "res_rnnmodel", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "feature_size", ")", ")", "\n", "if", "act", "==", "rectify", ":", "\n", "      ", "net", "[", "'rnn0'", "]", "=", "res_rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "nonlinearity", "=", "act", ",", "W_hid_to_hid", "=", "lasagne", ".", "init", ".", "Uniform", "(", "range", "=", "(", "0", ",", "U_bound", ")", ")", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "net", "[", "'rnn'", "]", "=", "res_rnnmodel", "(", "net", "[", "'rnn0'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "nonlinearity", "=", "act", ",", "W_hid_to_hid", "=", "lasagne", ".", "init", ".", "Uniform", "(", "range", "=", "(", "U_lowbound", ",", "U_bound", ")", ")", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "", "elif", "act", "==", "tanh", ":", "\n", "      ", "net", "[", "'rnn0'", "]", "=", "res_rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "nonlinearity", "=", "act", ",", "W_hid_to_hid", "=", "lasagne", ".", "init", ".", "Uniform", "(", "range", "=", "(", "U_bound", ")", ")", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "net", "[", "'rnn'", "]", "=", "res_rnnmodel", "(", "net", "[", "'rnn0'", "]", ",", "hidden_units", ",", "W_in_to_hid", "=", "lasagne", ".", "init", ".", "Normal", "(", "args", ".", "in2hidW", ")", ",", "nonlinearity", "=", "act", ",", "W_hid_to_hid", "=", "lasagne", ".", "init", ".", "Uniform", "(", "range", "=", "(", "U_bound", ")", ")", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "None", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.adding.adding.generate_data": [[91, 114], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "range", "numpy.reshape", "numpy.transpose", "numpy.zeros", "numpy.random.uniform", "numpy.random.randint", "int", "int"], "function", ["None"], ["", "def", "generate_data", "(", "time_steps", ",", "n_data", ")", ":", "\n", "    ", "x", "=", "np", ".", "asarray", "(", "np", ".", "zeros", "(", "(", "time_steps", ",", "int", "(", "n_data", ")", ",", "2", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "x", "[", ":", ",", ":", ",", "0", "]", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.", ",", "\n", "high", "=", "1.", ",", "\n", "size", "=", "(", "time_steps", ",", "n_data", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "\n", "\n", "inds", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "randint", "(", "time_steps", "//", "2", ",", "size", "=", "(", "n_data", ",", "2", ")", ")", ")", "\n", "inds", "[", ":", ",", "1", "]", "+=", "time_steps", "//", "2", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "n_data", ")", ")", ":", "\n", "        ", "x", "[", "inds", "[", "i", ",", "0", "]", ",", "i", ",", "1", "]", "=", "1.0", "\n", "x", "[", "inds", "[", "i", ",", "1", "]", ",", "i", ",", "1", "]", "=", "1.0", "\n", "\n", "", "y", "=", "(", "x", "[", ":", ",", ":", ",", "0", "]", "*", "x", "[", ":", ",", ":", ",", "1", "]", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "y", "=", "np", ".", "reshape", "(", "y", ",", "(", "n_data", ",", "1", ")", ")", "\n", "x", "=", "np", ".", "transpose", "(", "x", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.batch_thread.__init__": [[77, 83], ["numpy.arange", "numpy.random.shuffle", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "indices", "=", "np", ".", "arange", "(", "len", "(", "y_train", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.batch_thread.__call__": [[83, 96], ["numpy.zeros", "numpy.zeros", "range", "len", "numpy.random.shuffle"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_train", ".", "shape", "[", "1", "]", ",", "X_train", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_size_", ")", ":", "\n", "      ", "batch_data_", "[", "i", ",", ":", ",", ":", "]", "=", "X_train", "[", "self", ".", "indices", "[", "self", ".", "idx", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", "i", "]", "=", "y_train", "[", "self", ".", "indices", "[", "self", ".", "idx", "]", "]", "\n", "self", ".", "idx", "+=", "1", "\n", "if", "self", ".", "idx", "==", "len", "(", "self", ".", "indices", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "\n", "", "", "self", ".", "result", "[", "'data'", "]", "=", "batch_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.DataHandler.__init__": [[100, 113], ["numpy.zeros", "numpy.zeros", "Data_gen_permute.batch_thread", "Data_gen_permute.DataHandler.dispatch_worker", "Data_gen_permute.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "batch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.DataHandler.get_batch": [[115, 125], ["Data_gen_permute.DataHandler.dispatch_worker", "Data_gen_permute.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.DataHandler.dispatch_worker": [[127, 131], ["threading.Thread", "Data_gen_permute.DataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.DataHandler.join_worker": [[132, 136], ["Data_gen_permute.DataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.DataHandler.GetDatasetSize": [[137, 139], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "Aug_Y_train", ")", "//", "(", "2", "*", "self", ".", "batch_size_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testbatch_thread.__init__": [[144, 150], ["numpy.arange", "numpy.random.shuffle", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "indices", "=", "np", ".", "arange", "(", "len", "(", "y_test", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testbatch_thread.__call__": [[150, 170], ["numpy.zeros", "numpy.zeros", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_test", ".", "shape", "[", "1", "]", ",", "X_test", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "self", ".", "idx", "+", "self", ".", "batch_size_", ">", "len", "(", "y_test", ")", ":", "\n", "      ", "batch_data_", "[", ":", "len", "(", "y_test", ")", "-", "self", ".", "idx", "]", "=", "X_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "len", "(", "y_test", ")", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", ":", "len", "(", "y_test", ")", "-", "self", ".", "idx", "]", "=", "y_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "len", "(", "y_test", ")", "]", "]", "\n", "needed", "=", "self", ".", "batch_size_", "-", "(", "len", "(", "y_test", ")", "-", "self", ".", "idx", ")", "\n", "batch_data_", "[", "len", "(", "y_test", ")", "-", "self", ".", "idx", ":", "]", "=", "X_test", "[", "self", ".", "indices", "[", "0", ":", "needed", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", "len", "(", "y_test", ")", "-", "self", ".", "idx", ":", "]", "=", "y_test", "[", "self", ".", "indices", "[", "0", ":", "needed", "]", "]", "\n", "self", ".", "idx", "=", "needed", "\n", "", "else", ":", "\n", "      ", "batch_data_", "=", "X_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "=", "y_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "]", "\n", "self", ".", "idx", "+=", "self", ".", "batch_size_", "\n", "\n", "", "self", ".", "result", "[", "'data'", "]", "=", "batch_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "batch_label_", "\n", "\n", "if", "self", ".", "idx", "==", "len", "(", "y_test", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testDataHandler.__init__": [[174, 187], ["numpy.zeros", "numpy.zeros", "Data_gen_permute.testbatch_thread", "Data_gen_permute.testDataHandler.dispatch_worker", "Data_gen_permute.testDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_test", ".", "shape", "[", "1", "]", ",", "X_test", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "testbatch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testDataHandler.get_batch": [[189, 199], ["Data_gen_permute.testDataHandler.dispatch_worker", "Data_gen_permute.testDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testDataHandler.dispatch_worker": [[201, 205], ["threading.Thread", "Data_gen_permute.testDataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testDataHandler.join_worker": [[206, 210], ["Data_gen_permute.testDataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "", "def", "GetDatasetSize", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.testDataHandler.GetDatasetSize": [[210, 212], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "y_test", ")", "//", "self", ".", "batch_size_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestbatch_thread.__init__": [[222, 226], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestbatch_thread.__call__": [[226, 241], ["numpy.zeros", "numpy.zeros", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "temp_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "temp_data_", "[", ":", ":", "2", ",", ":", ",", ":", ",", ":", "]", "=", "pre_X_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", ",", ":", ",", ":", ",", ":", "]", "\n", "temp_label_", "[", ":", ":", "2", "]", "=", "y_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "\n", "\n", "temp_data_", "[", "1", ":", ":", "2", ",", ":", ",", ":", ",", ":", "]", "=", "pre_X_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "temp_label_", "[", "1", ":", ":", "2", "]", "=", "y_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "\n", "\n", "self", ".", "result", "[", "'data'", "]", "=", "temp_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "temp_label_", "\n", "self", ".", "idx", "+=", "self", ".", "batch_size_", "\n", "if", "self", ".", "idx", "==", "len", "(", "y_test", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestDataHandler.__init__": [[245, 258], ["numpy.zeros", "numpy.zeros", "Data_gen_permute.finaltestbatch_thread", "Data_gen_permute.finaltestDataHandler.dispatch_worker", "Data_gen_permute.finaltestDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "finaltestbatch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestDataHandler.get_batch": [[260, 270], ["Data_gen_permute.finaltestDataHandler.dispatch_worker", "Data_gen_permute.finaltestDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestDataHandler.dispatch_worker": [[272, 276], ["threading.Thread", "Data_gen_permute.finaltestDataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestDataHandler.join_worker": [[277, 281], ["Data_gen_permute.finaltestDataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "", "def", "GetDatasetSize", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.finaltestDataHandler.GetDatasetSize": [[281, 283], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "y_test", ")", "//", "self", ".", "batch_size_", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen_permute.load_dataset": [[7, 52], ["Data_gen_permute.load_dataset.load_mnist_images"], "function", ["None"], ["def", "load_dataset", "(", ")", ":", "\n", "# We first define a download function, supporting both Python 2 and 3.", "\n", "    ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "        ", "from", "urllib", "import", "urlretrieve", "\n", "", "else", ":", "\n", "        ", "from", "urllib", ".", "request", "import", "urlretrieve", "\n", "\n", "", "def", "download", "(", "filename", ",", "source", "=", "'http://yann.lecun.com/exdb/mnist/'", ")", ":", "\n", "        ", "print", "(", "\"Downloading %s\"", "%", "filename", ")", "\n", "urlretrieve", "(", "source", "+", "filename", ",", "filename", ")", "\n", "\n", "# We then define functions for loading MNIST images and labels.", "\n", "# For convenience, they also download the requested files if needed.", "\n", "", "import", "gzip", "\n", "\n", "def", "load_mnist_images", "(", "filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "download", "(", "filename", ")", "\n", "# Read the inputs in Yann LeCun's binary format.", "\n", "", "with", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "# The inputs are vectors now, we reshape them to monochrome 2D images,", "\n", "# following the shape convention: (examples, channels, rows, columns)", "\n", "", "data", "=", "data", ".", "reshape", "(", "-", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "# The inputs come as bytes, we convert them to float32 in range [0,1].", "\n", "# (Actually to range [0, 255/256], for compatibility to the version", "\n", "# provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)", "\n", "return", "data", "/", "np", ".", "float32", "(", "256", ")", "\n", "\n", "", "def", "load_mnist_labels", "(", "filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "download", "(", "filename", ")", "\n", "# Read the labels in Yann LeCun's binary format.", "\n", "", "with", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "8", ")", "\n", "# The labels are vectors of integers now, that's exactly what we want.", "\n", "", "return", "data", "\n", "\n", "# We can now download and read the training and test set images and labels.", "\n", "", "X_train", "=", "load_mnist_images", "(", "'train-images-idx3-ubyte.gz'", ")", "\n", "y_train", "=", "load_mnist_labels", "(", "'train-labels-idx1-ubyte.gz'", ")", "\n", "X_test", "=", "load_mnist_images", "(", "'t10k-images-idx3-ubyte.gz'", ")", "\n", "y_test", "=", "load_mnist_labels", "(", "'t10k-labels-idx1-ubyte.gz'", ")", "\n", "\n", "return", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.batch_thread.__init__": [[66, 72], ["numpy.arange", "numpy.random.shuffle", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "indices", "=", "np", ".", "arange", "(", "len", "(", "y_train", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.batch_thread.__call__": [[72, 85], ["numpy.zeros", "numpy.zeros", "range", "len", "numpy.random.shuffle"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_train", ".", "shape", "[", "1", "]", ",", "X_train", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batch_size_", ")", ":", "\n", "      ", "batch_data_", "[", "i", ",", ":", ",", ":", "]", "=", "X_train", "[", "self", ".", "indices", "[", "self", ".", "idx", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", "i", "]", "=", "y_train", "[", "self", ".", "indices", "[", "self", ".", "idx", "]", "]", "\n", "self", ".", "idx", "+=", "1", "\n", "if", "self", ".", "idx", "==", "len", "(", "self", ".", "indices", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "\n", "", "", "self", ".", "result", "[", "'data'", "]", "=", "batch_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.DataHandler.__init__": [[89, 102], ["numpy.zeros", "numpy.zeros", "Data_gen.batch_thread", "Data_gen.DataHandler.dispatch_worker", "Data_gen.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "batch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.DataHandler.get_batch": [[104, 114], ["Data_gen.DataHandler.dispatch_worker", "Data_gen.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.DataHandler.dispatch_worker": [[116, 120], ["threading.Thread", "Data_gen.DataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.DataHandler.join_worker": [[121, 125], ["Data_gen.DataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.DataHandler.GetDatasetSize": [[126, 128], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "Aug_Y_train", ")", "//", "(", "2", "*", "self", ".", "batch_size_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testbatch_thread.__init__": [[133, 139], ["numpy.arange", "numpy.random.shuffle", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "indices", "=", "np", ".", "arange", "(", "len", "(", "y_test", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "indices", ")", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testbatch_thread.__call__": [[139, 159], ["numpy.zeros", "numpy.zeros", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_test", ".", "shape", "[", "1", "]", ",", "X_test", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "self", ".", "idx", "+", "self", ".", "batch_size_", ">", "len", "(", "y_test", ")", ":", "\n", "      ", "batch_data_", "[", ":", "len", "(", "y_test", ")", "-", "self", ".", "idx", "]", "=", "X_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "len", "(", "y_test", ")", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", ":", "len", "(", "y_test", ")", "-", "self", ".", "idx", "]", "=", "y_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "len", "(", "y_test", ")", "]", "]", "\n", "needed", "=", "self", ".", "batch_size_", "-", "(", "len", "(", "y_test", ")", "-", "self", ".", "idx", ")", "\n", "batch_data_", "[", "len", "(", "y_test", ")", "-", "self", ".", "idx", ":", "]", "=", "X_test", "[", "self", ".", "indices", "[", "0", ":", "needed", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "[", "len", "(", "y_test", ")", "-", "self", ".", "idx", ":", "]", "=", "y_test", "[", "self", ".", "indices", "[", "0", ":", "needed", "]", "]", "\n", "self", ".", "idx", "=", "needed", "\n", "", "else", ":", "\n", "      ", "batch_data_", "=", "X_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", ",", ":", ",", ":", "]", "\n", "batch_label_", "=", "y_test", "[", "self", ".", "indices", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "]", "\n", "self", ".", "idx", "+=", "self", ".", "batch_size_", "\n", "\n", "", "self", ".", "result", "[", "'data'", "]", "=", "batch_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "batch_label_", "\n", "\n", "if", "self", ".", "idx", "==", "len", "(", "y_test", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testDataHandler.__init__": [[163, 176], ["numpy.zeros", "numpy.zeros", "Data_gen.testbatch_thread", "Data_gen.testDataHandler.dispatch_worker", "Data_gen.testDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ",", "X_test", ".", "shape", "[", "1", "]", ",", "X_test", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "testbatch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testDataHandler.get_batch": [[178, 188], ["Data_gen.testDataHandler.dispatch_worker", "Data_gen.testDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testDataHandler.dispatch_worker": [[190, 194], ["threading.Thread", "Data_gen.testDataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testDataHandler.join_worker": [[195, 199], ["Data_gen.testDataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "", "def", "GetDatasetSize", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.testDataHandler.GetDatasetSize": [[199, 201], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "y_test", ")", "//", "self", ".", "batch_size_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestbatch_thread.__init__": [[211, 215], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "idx", "=", "0", "\n", "", "def", "__call__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestbatch_thread.__call__": [[215, 230], ["numpy.zeros", "numpy.zeros", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "temp_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "temp_data_", "[", ":", ":", "2", ",", ":", ",", ":", ",", ":", "]", "=", "pre_X_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", ",", ":", ",", ":", ",", ":", "]", "\n", "temp_label_", "[", ":", ":", "2", "]", "=", "y_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "\n", "\n", "temp_data_", "[", "1", ":", ":", "2", ",", ":", ",", ":", ",", ":", "]", "=", "pre_X_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "temp_label_", "[", "1", ":", ":", "2", "]", "=", "y_test", "[", "self", ".", "idx", ":", "self", ".", "idx", "+", "self", ".", "batch_size_", "]", "\n", "\n", "self", ".", "result", "[", "'data'", "]", "=", "temp_data_", "\n", "self", ".", "result", "[", "'label'", "]", "=", "temp_label_", "\n", "self", ".", "idx", "+=", "self", ".", "batch_size_", "\n", "if", "self", ".", "idx", "==", "len", "(", "y_test", ")", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestDataHandler.__init__": [[234, 247], ["numpy.zeros", "numpy.zeros", "Data_gen.finaltestbatch_thread", "Data_gen.finaltestDataHandler.dispatch_worker", "Data_gen.finaltestDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "# batch size            ", "\n", "\n", "self", ".", "batch_data_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ",", "3", ",", "32", ",", "32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "batch_label_", "=", "np", ".", "zeros", "(", "(", "self", ".", "batch_size_", "*", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "self", ".", "batch_advancer", "=", "finaltestbatch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ")", "\n", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestDataHandler.get_batch": [[249, 259], ["Data_gen.finaltestDataHandler.dispatch_worker", "Data_gen.finaltestDataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "get_batch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestDataHandler.dispatch_worker": [[261, 265], ["threading.Thread", "Data_gen.finaltestDataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestDataHandler.join_worker": [[266, 270], ["Data_gen.finaltestDataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "", "def", "GetDatasetSize", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.finaltestDataHandler.GetDatasetSize": [[270, 272], ["len"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "y_test", ")", "//", "self", ".", "batch_size_", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.Data_gen.load_dataset": [[7, 52], ["Data_gen.load_dataset.load_mnist_images"], "function", ["None"], ["def", "load_dataset", "(", ")", ":", "\n", "# We first define a download function, supporting both Python 2 and 3.", "\n", "    ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "        ", "from", "urllib", "import", "urlretrieve", "\n", "", "else", ":", "\n", "        ", "from", "urllib", ".", "request", "import", "urlretrieve", "\n", "\n", "", "def", "download", "(", "filename", ",", "source", "=", "'http://yann.lecun.com/exdb/mnist/'", ")", ":", "\n", "        ", "print", "(", "\"Downloading %s\"", "%", "filename", ")", "\n", "urlretrieve", "(", "source", "+", "filename", ",", "filename", ")", "\n", "\n", "# We then define functions for loading MNIST images and labels.", "\n", "# For convenience, they also download the requested files if needed.", "\n", "", "import", "gzip", "\n", "\n", "def", "load_mnist_images", "(", "filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "download", "(", "filename", ")", "\n", "# Read the inputs in Yann LeCun's binary format.", "\n", "", "with", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "16", ")", "\n", "# The inputs are vectors now, we reshape them to monochrome 2D images,", "\n", "# following the shape convention: (examples, channels, rows, columns)", "\n", "", "data", "=", "data", ".", "reshape", "(", "-", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "# The inputs come as bytes, we convert them to float32 in range [0,1].", "\n", "# (Actually to range [0, 255/256], for compatibility to the version", "\n", "# provided at http://deeplearning.net/data/mnist/mnist.pkl.gz.)", "\n", "return", "data", "/", "np", ".", "float32", "(", "256", ")", "\n", "\n", "", "def", "load_mnist_labels", "(", "filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "download", "(", "filename", ")", "\n", "# Read the labels in Yann LeCun's binary format.", "\n", "", "with", "gzip", ".", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "np", ".", "uint8", ",", "offset", "=", "8", ")", "\n", "# The labels are vectors of integers now, that's exactly what we want.", "\n", "", "return", "data", "\n", "\n", "# We can now download and read the training and test set images and labels.", "\n", "", "X_train", "=", "load_mnist_images", "(", "'train-images-idx3-ubyte.gz'", ")", "\n", "y_train", "=", "load_mnist_labels", "(", "'train-labels-idx1-ubyte.gz'", ")", "\n", "X_test", "=", "load_mnist_images", "(", "'t10k-images-idx3-ubyte.gz'", ")", "\n", "y_test", "=", "load_mnist_labels", "(", "'t10k-labels-idx1-ubyte.gz'", ")", "\n", "\n", "return", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.pixelmnist.build_lstm_network": [[62, 68], ["lasagne.layers.InputLayer", "rnnmodel", "lasagne.layers.DenseLayer", "lasagne.layers.Gate", "lasagne.init.Constant"], "function", ["None"], ["def", "build_lstm_network", "(", "rnnmodel", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "feature_size", ")", ")", "\n", "net", "[", "'rnn'", "]", "=", "rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "forgetgate", "=", "lasagne", ".", "layers", ".", "Gate", "(", "b", "=", "lasagne", ".", "init", ".", "Constant", "(", "1.", ")", ")", ",", "peepholes", "=", "False", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "\n", "return", "net", "\n", "", "def", "build_rnn_network", "(", "rnnmodel", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.pixelmnist.build_rnn_network": [[68, 74], ["lasagne.layers.InputLayer", "rnnmodel", "lasagne.layers.DenseLayer", "lasagne.init.Normal", "numpy.identity"], "function", ["None"], ["", "def", "build_rnn_network", "(", "rnnmodel", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "feature_size", ")", ")", "\n", "net", "[", "'rnn'", "]", "=", "rnnmodel", "(", "net", "[", "'input'", "]", ",", "hidden_units", ",", "nonlinearity", "=", "act", ",", "W_in_to_hid", "=", "Normal", "(", "args", ".", "ini", ")", ",", "W_hid_to_hid", "=", "lambda", "shape", ":", "np", ".", "identity", "(", "hidden_units", ",", "dtype", "=", "np", ".", "float32", ")", ",", "only_return_final", "=", "True", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.pixelmnist.build_res_rnn_network": [[81, 106], ["lasagne.layers.InputLayer", "lasagne.layers.DimshuffleLayer", "range", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "rnnmodel", "lasagne.layers.BatchNormLayer", "lasagne.layers.BatchNormLayer", "lasagne.layers.SliceLayer", "lasagne.init.Uniform", "lasagne.init.Uniform", "lasagne.init.Uniform"], "function", ["None"], ["", "def", "build_res_rnn_network", "(", "rnnmodel", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "feature_size", ")", ")", "\n", "net", "[", "'rnn0'", "]", "=", "DimshuffleLayer", "(", "net", "[", "'input'", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "for", "l", "in", "range", "(", "1", ",", "num_layers", "+", "1", ")", ":", "\n", "      ", "hidini", "=", "0", "\n", "if", "l", "==", "num_layers", ":", "\n", "        ", "hidini", "=", "U_lowbound", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "hidden_units", ",", "W", "=", "ini_W", ",", "b", "=", "Uniform", "(", "range", "=", "(", "0", ",", "args", ".", "ini_b", ")", ")", ",", "nonlinearity", "=", "None", ")", "#W=Uniform(ini_rernn_in_to_hid),         #", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "\n", "net", "[", "'rnn%d'", "%", "l", "]", "=", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "\n", "if", "not", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNormLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ",", "beta", "=", "Uniform", "(", "range", "=", "(", "0", ",", "args", ".", "ini_b", ")", ")", ")", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "rnnmodel", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "hidden_units", ",", "W_hid_to_hid", "=", "Uniform", "(", "range", "=", "(", "hidini", ",", "U_bound", ")", ")", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "False", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "if", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNormLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "", "if", "l", "==", "num_layers", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "num_layers", "]", "=", "lasagne", ".", "layers", ".", "SliceLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "indices", "=", "-", "1", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.MulLayer.__init__": [[40, 44], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN_onlyrecurrent.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.MulLayer.get_output_for": [[45, 47], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.MulLayer.get_output_shape_for": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__": [[58, 134], ["lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.MergeLayer.__init__", "isinstance", "incomings.append", "incomings.append", "len", "ValueError", "len", "ValueError", "ValueError", "IndRNN_onlyrecurrent.onlyRecurrentLayer.add_param", "len", "len", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["def", "__init__", "(", "self", ",", "incoming", ",", "input_to_hidden", ",", "hidden_to_hidden", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# This layer inherits from a MergeLayer, because it can have three", "\n", "# inputs - the layer input, the mask and the initial hidden state.  We", "\n", "# will just provide the layer input as incomings, unless a mask input", "\n", "# or initial hidden state was provided.", "\n", "        ", "incomings", "=", "[", "incoming", "]", "\n", "self", ".", "mask_incoming_index", "=", "-", "1", "\n", "self", ".", "hid_init_incoming_index", "=", "-", "1", "\n", "if", "mask_input", "is", "not", "None", ":", "\n", "            ", "incomings", ".", "append", "(", "mask_input", ")", "\n", "self", ".", "mask_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "incomings", ".", "append", "(", "hid_init", ")", "\n", "self", ".", "hid_init_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "\n", "", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "__init__", "(", "incomings", ",", "**", "kwargs", ")", "\n", "\n", "input_to_hidden_in_layers", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "input_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "input_to_hidden_in_layers", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`input_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "input_to_hidden_in_layers", ")", ")", ")", "\n", "\n", "", "hidden_to_hidden_in_lyrs", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "hidden_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "hidden_to_hidden_in_lyrs", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`hidden_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "hidden_to_hidden_in_lyrs", ")", ")", ")", "\n", "", "hidden_to_hidden_in_layer", "=", "hidden_to_hidden_in_lyrs", "[", "0", "]", "\n", "\n", "self", ".", "input_to_hidden", "=", "input_to_hidden", "\n", "self", ".", "hidden_to_hidden", "=", "hidden_to_hidden", "\n", "self", ".", "learn_init", "=", "learn_init", "\n", "self", ".", "backwards", "=", "backwards", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "grad_clipping", "=", "grad_clipping", "\n", "self", ".", "unroll_scan", "=", "unroll_scan", "\n", "self", ".", "precompute_input", "=", "precompute_input", "\n", "self", ".", "only_return_final", "=", "only_return_final", "\n", "\n", "\n", "if", "unroll_scan", "and", "gradient_steps", "!=", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Gradient steps must be -1 when unroll_scan is true.\"", ")", "\n", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "\n", "if", "nonlinearity", "is", "None", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearities", ".", "identity", "\n", "", "else", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "\n", "# Initialize hidden state", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "self", ".", "hid_init", "=", "hid_init", "\n", "", "else", ":", "\n", "            ", "self", ".", "hid_init", "=", "self", ".", "add_param", "(", "\n", "hid_init", ",", "(", "1", ",", ")", "+", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ",", "\n", "name", "=", "\"hid_init\"", ",", "trainable", "=", "learn_init", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params": [[135, 142], ["super().get_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params"], ["", "", "def", "get_params", "(", "self", ",", "**", "tags", ")", ":", "\n", "# Get all parameters from this layer, the master layer", "\n", "        ", "params", "=", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "get_params", "(", "**", "tags", ")", "\n", "# Combine with all parameters from the child layers", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "input_to_hidden", ",", "**", "tags", ")", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ",", "**", "tags", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_shape_for": [[143, 155], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shapes", ")", ":", "\n", "# The shape of the input to this layer will be the first element", "\n", "# of input_shapes, whether or not a mask input is being used.", "\n", "        ", "input_shape", "=", "input_shapes", "[", "0", "]", "\n", "# When only_return_final is true, the second (sequence step) dimension", "\n", "# will be flattened", "\n", "if", "self", ".", "only_return_final", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", "\n", "# Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "\n", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for": [[156, 251], ["lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "IndRNN_onlyrecurrent.onlyRecurrentLayer.nonlinearity", "IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for.step"], "methods", ["None"], ["", "", "def", "get_output_for", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Retrieve the layer input", "\n", "        ", "input", "=", "inputs", "[", "0", "]", "\n", "# Retrieve the mask when it is supplied", "\n", "mask", "=", "None", "\n", "hid_init", "=", "None", "\n", "if", "self", ".", "mask_incoming_index", ">", "0", ":", "\n", "            ", "mask", "=", "inputs", "[", "self", ".", "mask_incoming_index", "]", "\n", "", "if", "self", ".", "hid_init_incoming_index", ">", "0", ":", "\n", "            ", "hid_init", "=", "inputs", "[", "self", ".", "hid_init_incoming_index", "]", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, n_features)", "\n", "# but scan requires the iterable dimension to be first", "\n", "# So, we need to dimshuffle to (n_time_steps, n_batch, n_features)", "\n", "#input = input.dimshuffle(1, 0, *range(2, input.ndim))", "\n", "", "seq_len", ",", "num_batch", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "# We will always pass the hidden-to-hidden layer params to step", "\n", "non_seqs", "=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ")", "\n", "\n", "# Create single recurrent computation step function", "\n", "def", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Compute the hidden-to-hidden activation", "\n", "            ", "hid_pre", "=", "helper", ".", "get_output", "(", "\n", "self", ".", "hidden_to_hidden", ",", "hid_previous", ",", "**", "kwargs", ")", "\n", "\n", "hid_pre", "+=", "input_n", "\n", "\n", "# Clip gradients", "\n", "if", "self", ".", "grad_clipping", ":", "\n", "                ", "hid_pre", "=", "theano", ".", "gradient", ".", "grad_clip", "(", "\n", "hid_pre", ",", "-", "self", ".", "grad_clipping", ",", "self", ".", "grad_clipping", ")", "\n", "\n", "", "return", "self", ".", "nonlinearity", "(", "hid_pre", ")", "\n", "\n", "", "def", "step_masked", "(", "input_n", ",", "mask_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Skip over any input with mask 0 by copying the previous", "\n", "# hidden state; proceed normally for any input with mask 1.", "\n", "            ", "hid", "=", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", "\n", "hid_out", "=", "T", ".", "switch", "(", "mask_n", ",", "hid", ",", "hid_previous", ")", "\n", "return", "[", "hid_out", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "dimshuffle", "(", "1", ",", "0", ",", "'x'", ")", "\n", "sequences", "=", "[", "input", ",", "mask", "]", "\n", "step_fun", "=", "step_masked", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "input", "\n", "step_fun", "=", "step", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "hid_init", ",", "Layer", ")", ":", "\n", "# The code below simply repeats self.hid_init num_batch times in", "\n", "# its first dimension.  Turns out using a dot product and a", "\n", "# dimshuffle is faster than T.repeat.", "\n", "            ", "dot_dims", "=", "(", "list", "(", "range", "(", "1", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", ")", ")", "+", "\n", "[", "0", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", "]", ")", "\n", "hid_init", "=", "T", ".", "dot", "(", "T", ".", "ones", "(", "(", "num_batch", ",", "1", ")", ")", ",", "\n", "self", ".", "hid_init", ".", "dimshuffle", "(", "dot_dims", ")", ")", "\n", "\n", "", "if", "self", ".", "unroll_scan", ":", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "            ", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "# Explicitly unroll the recurrence instead of using scan", "\n", "hid_out", "=", "unroll_scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "n_steps", "=", "input_shape", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# Scan op iterates over first dimension of input and repeatedly", "\n", "# applies the step function", "\n", "            ", "hid_out", "=", "theano", ".", "scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "truncate_gradient", "=", "self", ".", "gradient_steps", ",", "\n", "strict", "=", "True", ")", "[", "0", "]", "\n", "\n", "# When it is requested that we only return the final sequence step,", "\n", "# we need to slice it out immediately after scan is applied", "\n", "", "if", "self", ".", "only_return_final", ":", "\n", "            ", "hid_out", "=", "hid_out", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "# dimshuffle back to (n_batch, n_time_steps, n_features))", "\n", "#hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))", "\n", "\n", "# if scan is backward reverse the output", "\n", "            ", "if", "self", ".", "backwards", ":", "\n", "                ", "hid_out", "=", "hid_out", "[", ":", ":", "-", "1", ",", ":", "]", "\n", "\n", "", "", "return", "hid_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.mnist.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__": [[255, 320], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "IndRNN_onlyrecurrent.MulLayer", "IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "#W_in_to_hid=init.Uniform(),", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "#b=init.Constant(0.),", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "InputLayer", "(", "input_shape", ")", "\n", "\n", "#         in_to_hid = DenseLayer(InputLayer((None,) + input_shape[2:]),", "\n", "#                                num_units, W=W_in_to_hid, b=b,", "\n", "#                                nonlinearity=None,", "\n", "#                                name=basename + 'input_to_hidden',", "\n", "#                                **layer_kwargs)        ", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "#self.W_in_to_hid = in_to_hid.W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "#self.b = in_to_hid.b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer_onlyrecurrent", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.bn_eachstep_withdrop_timefirst.BatchNormLayer.__init__": [[10, 57], ["lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.layers.Layer.__init__", "any", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "isinstance", "len", "ValueError", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "len", "lasagne.layers.DropoutLayer", "lasagne.layers.DropoutLayer", "tuple", "enumerate", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "axes", "=", "'auto'", ",", "droprate", "=", "0.2", ",", "epsilon", "=", "1e-4", ",", "alpha", "=", "0.1", ",", "sparsity", "=", "1.0", ",", "\n", "beta", "=", "init", ".", "Constant", "(", "0", ")", ",", "gamma", "=", "init", ".", "Constant", "(", "1", ")", ",", "\n", "mean", "=", "init", ".", "Constant", "(", "0", ")", ",", "inv_std", "=", "init", ".", "Constant", "(", "1", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BatchNormLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "\n", "if", "axes", "==", "'auto'", ":", "\n", "# default: normalize over all but the second axis", "\n", "            ", "axes", "=", "(", "0", ",", ")", "+", "tuple", "(", "range", "(", "2", ",", "len", "(", "self", ".", "input_shape", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "axes", ",", "int", ")", ":", "\n", "            ", "axes", "=", "(", "axes", ",", ")", "\n", "", "self", ".", "axes", "=", "axes", "\n", "if", "len", "(", "axes", ")", "==", "1", ":", "\n", "          ", "self", ".", "mean_axes", "=", "self", ".", "axes", "\n", "", "else", ":", "\n", "          ", "self", ".", "mean_axes", "=", "(", "axes", "[", "1", "]", ",", ")", "\n", "\n", "", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "# create parameters, ignoring all dimensions in axes", "\n", "shape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "axes", "]", "\n", "meanshape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "mean_axes", "]", "\n", "if", "any", "(", "size", "is", "None", "for", "size", "in", "shape", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"BatchNormLayer needs specified input sizes for \"", "\n", "\"all axes not normalized over.\"", ")", "\n", "", "if", "beta", "is", "None", ":", "\n", "            ", "self", ".", "beta", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "self", ".", "add_param", "(", "beta", ",", "shape", ",", "'beta'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "False", ")", "\n", "", "if", "gamma", "is", "None", ":", "\n", "            ", "self", ".", "gamma", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma", "=", "self", ".", "add_param", "(", "gamma", ",", "shape", ",", "'gamma'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "True", ")", "\n", "", "self", ".", "mean", "=", "self", ".", "add_param", "(", "mean", ",", "meanshape", ",", "'mean'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "self", ".", "inv_std", "=", "self", ".", "add_param", "(", "inv_std", ",", "meanshape", ",", "'inv_std'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "#print('here',len(self.input_shape))", "\n", "self", ".", "sparsity", "=", "sparsity", "\n", "if", "len", "(", "self", ".", "input_shape", ")", "==", "3", ":", "\n", "          ", "self", ".", "dropout", "=", "DropoutLayer", "(", "(", "self", ".", "input_shape", "[", "0", "]", ",", "self", ".", "input_shape", "[", "1", "]", ",", "self", ".", "input_shape", "[", "2", "]", ")", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", "1", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "          ", "self", ".", "dropout", "=", "DropoutLayer", "(", "(", "self", ".", "input_shape", "[", "0", "]", ",", "self", ".", "input_shape", "[", "1", "]", ")", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.bn_eachstep_withdrop_timefirst.BatchNormLayer.get_output_for": [[58, 124], ["iter", "iter", "mean.dimshuffle.dimshuffle.dimshuffle", "inv_std.dimshuffle.dimshuffle.dimshuffle", "bn_eachstep_withdrop_timefirst.BatchNormLayer.dropout.get_output_for", "bn_eachstep_withdrop_timefirst.BatchNormLayer.mean", "theano.inv", "theano.inv", "theano.inv", "theano.inv", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "range", "bn_eachstep_withdrop_timefirst.BatchNormLayer.beta.dimshuffle", "bn_eachstep_withdrop_timefirst.BatchNormLayer.gamma.dimshuffle", "range", "theano.sqrt", "theano.sqrt", "bn_eachstep_withdrop_timefirst.BatchNormLayer.mean", "theano.sqrt", "theano.sqrt", "next", "range", "next", "range", "len", "len", "bn_eachstep_withdrop_timefirst.BatchNormLayer.var", "bn_eachstep_withdrop_timefirst.BatchNormLayer.var", "theano.sqr", "theano.sqr"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for"], ["", "", "def", "get_output_for", "(", "self", ",", "input", ",", "deterministic", "=", "False", ",", "\n", "batch_norm_use_averages", "=", "None", ",", "\n", "batch_norm_update_averages", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "sparsity", "==", "1", ":", "\n", "          ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "", "else", ":", "\n", "          ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "*", "(", "1.0", "/", "self", ".", "sparsity", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "*", "(", "1.0", "/", "self", ".", "sparsity", ")", "-", "(", "1", "-", "self", ".", "sparsity", ")", "*", "T", ".", "sqr", "(", "input_mean", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "\n", "# Decide whether to use the stored averages or mini-batch statistics", "\n", "", "if", "batch_norm_use_averages", "is", "None", ":", "\n", "            ", "batch_norm_use_averages", "=", "deterministic", "\n", "", "use_averages", "=", "batch_norm_use_averages", "\n", "\n", "if", "use_averages", ":", "\n", "            ", "mean", "=", "self", ".", "mean", "\n", "inv_std", "=", "self", ".", "inv_std", "\n", "", "else", ":", "\n", "            ", "mean", "=", "input_mean", "\n", "inv_std", "=", "input_inv_std", "\n", "\n", "# Decide whether to update the stored averages", "\n", "", "if", "batch_norm_update_averages", "is", "None", ":", "\n", "            ", "batch_norm_update_averages", "=", "not", "deterministic", "\n", "", "update_averages", "=", "batch_norm_update_averages", "\n", "\n", "if", "update_averages", ":", "\n", "# Trick: To update the stored statistics, we create memory-aliased", "\n", "# clones of the stored statistics:", "\n", "            ", "running_mean", "=", "theano", ".", "clone", "(", "self", ".", "mean", ",", "share_inputs", "=", "False", ")", "\n", "running_inv_std", "=", "theano", ".", "clone", "(", "self", ".", "inv_std", ",", "share_inputs", "=", "False", ")", "\n", "# set a default update for them:", "\n", "running_mean", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "running_mean", "+", "\n", "self", ".", "alpha", "*", "input_mean", ")", "\n", "running_inv_std", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "\n", "running_inv_std", "+", "\n", "self", ".", "alpha", "*", "input_inv_std", ")", "\n", "# and make sure they end up in the graph without participating in", "\n", "# the computation (this way their default_update will be collected", "\n", "# and applied, but the computation will be optimized away):", "\n", "mean", "+=", "0", "*", "running_mean", "\n", "inv_std", "+=", "0", "*", "running_inv_std", "\n", "\n", "# prepare dimshuffle pattern inserting broadcastable axes as needed", "\n", "", "param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "axes", ")", ")", ")", "\n", "pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "axes", "\n", "else", "next", "(", "param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "\n", "# apply dimshuffle pattern to all parameters", "\n", "beta", "=", "0", "if", "self", ".", "beta", "is", "None", "else", "self", ".", "beta", ".", "dimshuffle", "(", "pattern", ")", "\n", "gamma", "=", "1", "if", "self", ".", "gamma", "is", "None", "else", "self", ".", "gamma", ".", "dimshuffle", "(", "pattern", ")", "\n", "\n", "mean_param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "mean_axes", ")", ")", ")", "\n", "mean_pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "mean_axes", "\n", "else", "next", "(", "mean_param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "mean", "=", "mean", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "inv_std", "=", "inv_std", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "\n", "input", "=", "self", ".", "dropout", ".", "get_output_for", "(", "input", ",", "deterministic", "=", "deterministic", ")", "\n", "\n", "# normalize", "\n", "normalized", "=", "(", "input", "-", "mean", ")", "*", "(", "gamma", "*", "inv_std", ")", "+", "beta", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.__init__": [[16, 57], ["lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.layers.Layer.__init__", "any", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "isinstance", "len", "ValueError", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "tuple", "enumerate", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "axes", "=", "'auto'", ",", "epsilon", "=", "1e-4", ",", "alpha", "=", "0.1", ",", "\n", "beta", "=", "init", ".", "Constant", "(", "0", ")", ",", "gamma", "=", "init", ".", "Constant", "(", "1", ")", ",", "\n", "mean", "=", "init", ".", "Constant", "(", "0", ")", ",", "inv_std", "=", "init", ".", "Constant", "(", "1", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BatchNorm_step_timefirst_Layer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "\n", "if", "axes", "==", "'auto'", ":", "\n", "# default: normalize over all but the second axis", "\n", "            ", "axes", "=", "(", "0", ",", ")", "+", "tuple", "(", "range", "(", "2", ",", "len", "(", "self", ".", "input_shape", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "axes", ",", "int", ")", ":", "\n", "            ", "axes", "=", "(", "axes", ",", ")", "\n", "", "self", ".", "axes", "=", "axes", "\n", "if", "len", "(", "axes", ")", "==", "1", ":", "\n", "          ", "self", ".", "mean_axes", "=", "self", ".", "axes", "\n", "", "else", ":", "\n", "          ", "self", ".", "mean_axes", "=", "(", "axes", "[", "1", "]", ",", ")", "\n", "\n", "", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "# create parameters, ignoring all dimensions in axes", "\n", "shape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "axes", "]", "\n", "meanshape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "mean_axes", "]", "\n", "if", "any", "(", "size", "is", "None", "for", "size", "in", "shape", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"BatchNormLayer needs specified input sizes for \"", "\n", "\"all axes not normalized over.\"", ")", "\n", "", "if", "beta", "is", "None", ":", "\n", "            ", "self", ".", "beta", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "self", ".", "add_param", "(", "beta", ",", "shape", ",", "'beta'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "False", ")", "\n", "", "if", "gamma", "is", "None", ":", "\n", "            ", "self", ".", "gamma", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma", "=", "self", ".", "add_param", "(", "gamma", ",", "shape", ",", "'gamma'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "True", ")", "\n", "", "self", ".", "mean", "=", "self", ".", "add_param", "(", "mean", ",", "meanshape", ",", "'mean'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "self", ".", "inv_std", "=", "self", ".", "add_param", "(", "inv_std", ",", "meanshape", ",", "'inv_std'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.get_output_for": [[58, 118], ["input.mean", "theano.inv", "theano.inv", "iter", "iter", "mean.dimshuffle.dimshuffle.dimshuffle", "inv_std.dimshuffle.dimshuffle.dimshuffle", "theano.sqrt", "theano.sqrt", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "range", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.beta.dimshuffle", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.gamma.dimshuffle", "range", "next", "range", "next", "range", "input.var", "len", "len"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "deterministic", "=", "False", ",", "\n", "batch_norm_use_averages", "=", "None", ",", "\n", "batch_norm_update_averages", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "\n", "# Decide whether to use the stored averages or mini-batch statistics", "\n", "if", "batch_norm_use_averages", "is", "None", ":", "\n", "            ", "batch_norm_use_averages", "=", "deterministic", "\n", "", "use_averages", "=", "batch_norm_use_averages", "\n", "\n", "if", "use_averages", ":", "\n", "            ", "mean", "=", "self", ".", "mean", "\n", "inv_std", "=", "self", ".", "inv_std", "\n", "", "else", ":", "\n", "            ", "mean", "=", "input_mean", "\n", "inv_std", "=", "input_inv_std", "\n", "\n", "# Decide whether to update the stored averages", "\n", "", "if", "batch_norm_update_averages", "is", "None", ":", "\n", "            ", "batch_norm_update_averages", "=", "not", "deterministic", "\n", "", "update_averages", "=", "batch_norm_update_averages", "\n", "\n", "if", "update_averages", ":", "\n", "# Trick: To update the stored statistics, we create memory-aliased", "\n", "# clones of the stored statistics:", "\n", "            ", "running_mean", "=", "theano", ".", "clone", "(", "self", ".", "mean", ",", "share_inputs", "=", "False", ")", "\n", "running_inv_std", "=", "theano", ".", "clone", "(", "self", ".", "inv_std", ",", "share_inputs", "=", "False", ")", "\n", "# set a default update for them:", "\n", "running_mean", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "running_mean", "+", "\n", "self", ".", "alpha", "*", "input_mean", ")", "\n", "running_inv_std", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "\n", "running_inv_std", "+", "\n", "self", ".", "alpha", "*", "input_inv_std", ")", "\n", "# and make sure they end up in the graph without participating in", "\n", "# the computation (this way their default_update will be collected", "\n", "# and applied, but the computation will be optimized away):", "\n", "mean", "+=", "0", "*", "running_mean", "\n", "inv_std", "+=", "0", "*", "running_inv_std", "\n", "\n", "# prepare dimshuffle pattern inserting broadcastable axes as needed", "\n", "", "param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "axes", ")", ")", ")", "\n", "pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "axes", "\n", "else", "next", "(", "param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "\n", "# apply dimshuffle pattern to all parameters", "\n", "beta", "=", "0", "if", "self", ".", "beta", "is", "None", "else", "self", ".", "beta", ".", "dimshuffle", "(", "pattern", ")", "\n", "gamma", "=", "1", "if", "self", ".", "gamma", "is", "None", "else", "self", ".", "gamma", ".", "dimshuffle", "(", "pattern", ")", "\n", "\n", "mean_param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "mean_axes", ")", ")", ")", "\n", "mean_pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "mean_axes", "\n", "else", "next", "(", "mean_param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "mean", "=", "mean", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "inv_std", "=", "inv_std", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "\n", "# normalize", "\n", "normalized", "=", "(", "input", "-", "mean", ")", "*", "(", "gamma", "*", "inv_std", ")", "+", "beta", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.penntree_wordlevel_rernn_WT.get_raw_data": [[103, 106], ["reader.ptb_raw_data"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader.ptb_raw_data"], ["", "def", "get_raw_data", "(", "dataset", "=", "'ptb'", ",", "data_path", "=", "'data/'", ")", ":", "\n", "  ", "raw_data", "=", "ptb_raw_data", "(", "data_path", ",", "filename", "=", "name_dataset", ")", "\n", "return", "raw_data", "\n", "", "train_data", ",", "valid_data", ",", "test_data", ",", "_", "=", "get_raw_data", "(", "'ptb'", ")", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.penntree_wordlevel_rernn_WT.build_rnn_network": [[146, 200], ["lasagne.layers.InputLayer", "lasagne.layers.EmbeddingLayer", "lasagne.layers.DimshuffleLayer", "range", "lasagne.layers.DimshuffleLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DropoutLayer", "lasagne.layers.InputLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "rnnmodel", "lasagne.layers.SliceLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.init.Uniform", "lasagne.layers.ElemwiseSumLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "lasagne.layers.ConcatLayer", "lasagne.layers.DropoutLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "lasagne.init.Constant", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "print", "lasagne.layers.DropoutLayer", "lasagne.init.Constant"], "function", ["None"], ["", "def", "build_rnn_network", "(", "rnnmodel", ",", "X_sym", ",", "hid_init_sym", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "\n", "net", "[", "'input0'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ")", ",", "X_sym", ")", "\n", "net", "[", "'embed'", "]", "=", "lasagne", ".", "layers", ".", "EmbeddingLayer", "(", "net", "[", "'input0'", "]", ",", "outputclass", ",", "units", "[", "0", "]", ",", "W", "=", "Uniform", "(", "args", ".", "ini_last", ")", ")", "#,W=Uniform(0.04))#,W=lasagne.init.Uniform(inial_scale)      ", "\n", "net", "[", "'rnn0'", "]", "=", "DimshuffleLayer", "(", "net", "[", "'embed'", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "#change to (time, batch_size,hidden_units)    ", "\n", "if", "use_dropout", "and", "args", ".", "drop_embedding", ":", "\n", "      ", "net", "[", "'rnn0'", "]", "=", "lasagne", ".", "layers", ".", "DropoutLayer", "(", "net", "[", "'rnn0'", "]", ",", "p", "=", "droprate", ",", "shared_axes", "=", "taxdrop", ")", "\n", "", "for", "l", "in", "range", "(", "1", ",", "num_layers", "+", "1", ")", ":", "\n", "      ", "net", "[", "'hiddeninput%d'", "%", "l", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "units", "[", "l", "-", "1", "]", ")", ",", "hid_init_sym", "[", ":", ",", "acc_units", "[", "l", "-", "1", "]", ":", "acc_units", "[", "l", "]", "]", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "units", "[", "l", "-", "1", "]", ",", "W", "=", "ini_W", ",", "b", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ",", "nonlinearity", "=", "None", ")", "#W=Uniform(ini_rernn_in_to_hid),         #", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "\n", "if", "args", ".", "use_residual", "and", "l", ">", "args", ".", "residual_layers", "and", "(", "l", "-", "1", ")", "%", "args", ".", "residual_layers", "==", "0", ":", "# and l!=num_layers", "\n", "        ", "if", "units", "[", "l", "-", "1", "]", "!=", "units", "[", "l", "-", "1", "-", "args", ".", "residual_layers", "]", ":", "\n", "          ", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'sum%d'", "%", "(", "l", "-", "args", ".", "residual_layers", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "units", "[", "l", "-", "1", "]", ",", "W", "=", "ini_W", ",", "nonlinearity", "=", "None", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "print", "(", "'left branch'", ")", "\n", "", "else", ":", "\n", "          ", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "net", "[", "'sum%d'", "%", "(", "l", "-", "args", ".", "residual_layers", ")", "]", "\n", "", "net", "[", "'sum%d'", "%", "l", "]", "=", "ElemwiseSumLayer", "(", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "net", "[", "'sum%d'", "%", "l", "]", "=", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "net", "[", "'sum%d'", "%", "l", "]", "\n", "if", "not", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ",", "beta", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ")", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "rnnmodel", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "units", "[", "l", "-", "1", "]", ",", "hid_init", "=", "net", "[", "'hiddeninput%d'", "%", "l", "]", ",", "W_hid_to_hid", "=", "ini_U", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "False", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "\n", "net", "[", "'last_state%d'", "%", "l", "]", "=", "SliceLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "-", "1", ",", "axis", "=", "0", ")", "\n", "if", "l", "==", "1", ":", "\n", "        ", "net", "[", "'hid_out'", "]", "=", "net", "[", "'last_state%d'", "%", "l", "]", "\n", "", "else", ":", "\n", "        ", "net", "[", "'hid_out'", "]", "=", "ConcatLayer", "(", "[", "net", "[", "'hid_out'", "]", ",", "net", "[", "'last_state%d'", "%", "l", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "use_dropout", "and", "l", "%", "droplayers", "==", "0", "and", "l", "!=", "num_layers", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "lasagne", ".", "layers", ".", "DropoutLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "p", "=", "droprate", ",", "shared_axes", "=", "taxdrop", ")", "\n", "", "elif", "use_dropout", "and", "l", "%", "droplayers", "==", "0", "and", "l", "==", "num_layers", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "lasagne", ".", "layers", ".", "DropoutLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "p", "=", "args", ".", "droprate_last", ",", "shared_axes", "=", "taxdrop", ")", "\n", "\n", "", "if", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "", "", "net", "[", "'rnn%d'", "%", "num_layers", "]", "=", "DimshuffleLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "net", "[", "'reshape_rnn'", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "(", "-", "1", ",", "units", "[", "num_layers", "-", "1", "]", ")", ")", "\n", "if", "args", ".", "w_tying", ":", "\n", "      ", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'reshape_rnn'", "]", ",", "outputclass", ",", "W", "=", "net", "[", "'embed'", "]", ".", "W", ".", "T", ",", "nonlinearity", "=", "softmax", ")", "#lasagne.init.HeNormal(gain='relu'))#,W=Uniform(inial_scale)", "\n", "", "else", ":", "\n", "      ", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'reshape_rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.MulLayer.__init__": [[40, 44], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN_onlyrecurrent.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.MulLayer.get_output_for": [[45, 47], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.MulLayer.get_output_shape_for": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__": [[58, 134], ["lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.MergeLayer.__init__", "isinstance", "incomings.append", "incomings.append", "len", "ValueError", "len", "ValueError", "ValueError", "IndRNN_onlyrecurrent.onlyRecurrentLayer.add_param", "len", "len", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["def", "__init__", "(", "self", ",", "incoming", ",", "input_to_hidden", ",", "hidden_to_hidden", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# This layer inherits from a MergeLayer, because it can have three", "\n", "# inputs - the layer input, the mask and the initial hidden state.  We", "\n", "# will just provide the layer input as incomings, unless a mask input", "\n", "# or initial hidden state was provided.", "\n", "        ", "incomings", "=", "[", "incoming", "]", "\n", "self", ".", "mask_incoming_index", "=", "-", "1", "\n", "self", ".", "hid_init_incoming_index", "=", "-", "1", "\n", "if", "mask_input", "is", "not", "None", ":", "\n", "            ", "incomings", ".", "append", "(", "mask_input", ")", "\n", "self", ".", "mask_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "incomings", ".", "append", "(", "hid_init", ")", "\n", "self", ".", "hid_init_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "\n", "", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "__init__", "(", "incomings", ",", "**", "kwargs", ")", "\n", "\n", "input_to_hidden_in_layers", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "input_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "input_to_hidden_in_layers", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`input_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "input_to_hidden_in_layers", ")", ")", ")", "\n", "\n", "", "hidden_to_hidden_in_lyrs", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "hidden_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "hidden_to_hidden_in_lyrs", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`hidden_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "hidden_to_hidden_in_lyrs", ")", ")", ")", "\n", "", "hidden_to_hidden_in_layer", "=", "hidden_to_hidden_in_lyrs", "[", "0", "]", "\n", "\n", "self", ".", "input_to_hidden", "=", "input_to_hidden", "\n", "self", ".", "hidden_to_hidden", "=", "hidden_to_hidden", "\n", "self", ".", "learn_init", "=", "learn_init", "\n", "self", ".", "backwards", "=", "backwards", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "grad_clipping", "=", "grad_clipping", "\n", "self", ".", "unroll_scan", "=", "unroll_scan", "\n", "self", ".", "precompute_input", "=", "precompute_input", "\n", "self", ".", "only_return_final", "=", "only_return_final", "\n", "\n", "\n", "if", "unroll_scan", "and", "gradient_steps", "!=", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Gradient steps must be -1 when unroll_scan is true.\"", ")", "\n", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "\n", "if", "nonlinearity", "is", "None", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearities", ".", "identity", "\n", "", "else", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "\n", "# Initialize hidden state", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "self", ".", "hid_init", "=", "hid_init", "\n", "", "else", ":", "\n", "            ", "self", ".", "hid_init", "=", "self", ".", "add_param", "(", "\n", "hid_init", ",", "(", "1", ",", ")", "+", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ",", "\n", "name", "=", "\"hid_init\"", ",", "trainable", "=", "learn_init", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params": [[135, 142], ["super().get_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params"], ["", "", "def", "get_params", "(", "self", ",", "**", "tags", ")", ":", "\n", "# Get all parameters from this layer, the master layer", "\n", "        ", "params", "=", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "get_params", "(", "**", "tags", ")", "\n", "# Combine with all parameters from the child layers", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "input_to_hidden", ",", "**", "tags", ")", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ",", "**", "tags", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_shape_for": [[143, 155], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shapes", ")", ":", "\n", "# The shape of the input to this layer will be the first element", "\n", "# of input_shapes, whether or not a mask input is being used.", "\n", "        ", "input_shape", "=", "input_shapes", "[", "0", "]", "\n", "# When only_return_final is true, the second (sequence step) dimension", "\n", "# will be flattened", "\n", "if", "self", ".", "only_return_final", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", "\n", "# Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "\n", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for": [[156, 251], ["lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "IndRNN_onlyrecurrent.onlyRecurrentLayer.nonlinearity", "IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for.step"], "methods", ["None"], ["", "", "def", "get_output_for", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Retrieve the layer input", "\n", "        ", "input", "=", "inputs", "[", "0", "]", "\n", "# Retrieve the mask when it is supplied", "\n", "mask", "=", "None", "\n", "hid_init", "=", "None", "\n", "if", "self", ".", "mask_incoming_index", ">", "0", ":", "\n", "            ", "mask", "=", "inputs", "[", "self", ".", "mask_incoming_index", "]", "\n", "", "if", "self", ".", "hid_init_incoming_index", ">", "0", ":", "\n", "            ", "hid_init", "=", "inputs", "[", "self", ".", "hid_init_incoming_index", "]", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, n_features)", "\n", "# but scan requires the iterable dimension to be first", "\n", "# So, we need to dimshuffle to (n_time_steps, n_batch, n_features)", "\n", "#input = input.dimshuffle(1, 0, *range(2, input.ndim))", "\n", "", "seq_len", ",", "num_batch", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "# We will always pass the hidden-to-hidden layer params to step", "\n", "non_seqs", "=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ")", "\n", "\n", "# Create single recurrent computation step function", "\n", "def", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Compute the hidden-to-hidden activation", "\n", "            ", "hid_pre", "=", "helper", ".", "get_output", "(", "\n", "self", ".", "hidden_to_hidden", ",", "hid_previous", ",", "**", "kwargs", ")", "\n", "\n", "hid_pre", "+=", "input_n", "\n", "\n", "# Clip gradients", "\n", "if", "self", ".", "grad_clipping", ":", "\n", "                ", "hid_pre", "=", "theano", ".", "gradient", ".", "grad_clip", "(", "\n", "hid_pre", ",", "-", "self", ".", "grad_clipping", ",", "self", ".", "grad_clipping", ")", "\n", "\n", "", "return", "self", ".", "nonlinearity", "(", "hid_pre", ")", "\n", "\n", "", "def", "step_masked", "(", "input_n", ",", "mask_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Skip over any input with mask 0 by copying the previous", "\n", "# hidden state; proceed normally for any input with mask 1.", "\n", "            ", "hid", "=", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", "\n", "hid_out", "=", "T", ".", "switch", "(", "mask_n", ",", "hid", ",", "hid_previous", ")", "\n", "return", "[", "hid_out", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "dimshuffle", "(", "1", ",", "0", ",", "'x'", ")", "\n", "sequences", "=", "[", "input", ",", "mask", "]", "\n", "step_fun", "=", "step_masked", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "input", "\n", "step_fun", "=", "step", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "hid_init", ",", "Layer", ")", ":", "\n", "# The code below simply repeats self.hid_init num_batch times in", "\n", "# its first dimension.  Turns out using a dot product and a", "\n", "# dimshuffle is faster than T.repeat.", "\n", "            ", "dot_dims", "=", "(", "list", "(", "range", "(", "1", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", ")", ")", "+", "\n", "[", "0", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", "]", ")", "\n", "hid_init", "=", "T", ".", "dot", "(", "T", ".", "ones", "(", "(", "num_batch", ",", "1", ")", ")", ",", "\n", "self", ".", "hid_init", ".", "dimshuffle", "(", "dot_dims", ")", ")", "\n", "\n", "", "if", "self", ".", "unroll_scan", ":", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "            ", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "# Explicitly unroll the recurrence instead of using scan", "\n", "hid_out", "=", "unroll_scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "n_steps", "=", "input_shape", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# Scan op iterates over first dimension of input and repeatedly", "\n", "# applies the step function", "\n", "            ", "hid_out", "=", "theano", ".", "scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "truncate_gradient", "=", "self", ".", "gradient_steps", ",", "\n", "strict", "=", "True", ")", "[", "0", "]", "\n", "\n", "# When it is requested that we only return the final sequence step,", "\n", "# we need to slice it out immediately after scan is applied", "\n", "", "if", "self", ".", "only_return_final", ":", "\n", "            ", "hid_out", "=", "hid_out", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "# dimshuffle back to (n_batch, n_time_steps, n_features))", "\n", "#hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))", "\n", "\n", "# if scan is backward reverse the output", "\n", "            ", "if", "self", ".", "backwards", ":", "\n", "                ", "hid_out", "=", "hid_out", "[", ":", ":", "-", "1", ",", ":", "]", "\n", "\n", "", "", "return", "hid_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__": [[255, 320], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "IndRNN_onlyrecurrent.MulLayer", "IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "#W_in_to_hid=init.Uniform(),", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "#b=init.Constant(0.),", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "InputLayer", "(", "input_shape", ")", "\n", "\n", "#         in_to_hid = DenseLayer(InputLayer((None,) + input_shape[2:]),", "\n", "#                                num_units, W=W_in_to_hid, b=b,", "\n", "#                                nonlinearity=None,", "\n", "#                                name=basename + 'input_to_hidden',", "\n", "#                                **layer_kwargs)        ", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "#self.W_in_to_hid = in_to_hid.W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "#self.b = in_to_hid.b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer_onlyrecurrent", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader._read_symbols": [[33, 36], ["open", "f.read"], "function", ["None"], ["def", "_read_symbols", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "return", "f", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader._read_words": [[38, 41], ["open", "f.read().decode().replace().split", "f.read().decode().replace", "f.read().decode", "f.read"], "function", ["None"], ["", "", "def", "_read_words", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "return", "f", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"<eos>\"", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader._build_vocab": [[43, 53], ["reader._read_words", "collections.Counter", "sorted", "list", "dict", "collections.Counter.items", "zip", "zip", "range", "len"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_words"], ["", "", "def", "_build_vocab", "(", "filename", ")", ":", "\n", "  ", "data", "=", "_read_words", "(", "filename", ")", "\n", "\n", "counter", "=", "collections", ".", "Counter", "(", "data", ")", "\n", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "\n", "words", ",", "_", "=", "list", "(", "zip", "(", "*", "count_pairs", ")", ")", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "words", ",", "range", "(", "len", "(", "words", ")", ")", ")", ")", "\n", "\n", "return", "word_to_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader._file_to_word_ids": [[55, 58], ["reader._read_words"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_words"], ["", "def", "_file_to_word_ids", "(", "filename", ",", "word_to_id", ")", ":", "\n", "  ", "data", "=", "_read_words", "(", "filename", ")", "\n", "return", "[", "word_to_id", "[", "word", "]", "for", "word", "in", "data", "if", "word", "in", "word_to_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader.hutter_raw_data": [[60, 85], ["os.path.join", "reader._read_symbols", "numpy.fromstring", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_symbols"], ["", "def", "hutter_raw_data", "(", "data_path", "=", "None", ",", "num_test_symbols", "=", "5000000", ")", ":", "\n", "  ", "\"\"\"Load raw data from data directory \"data_path\".\n\n  The raw Hutter prize data is at:\n  http://mattmahoney.net/dc/enwik8.zip\n\n  Args:\n    data_path: string path to the directory where simple-examples.tgz has\n      been extracted.\n    num_test_symbols: number of symbols at the end that make up the test set\n\n  Returns:\n    tuple (train_data, valid_data, test_data, unique)\n    where each of the data objects can be passed to hutter_iterator.\n  \"\"\"", "\n", "\n", "data_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"enwik8\"", ")", "\n", "\n", "raw_data", "=", "_read_symbols", "(", "data_path", ")", "\n", "raw_data", "=", "np", ".", "fromstring", "(", "raw_data", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "unique", ",", "data", "=", "np", ".", "unique", "(", "raw_data", ",", "return_inverse", "=", "True", ")", "\n", "train_data", "=", "data", "[", ":", "-", "2", "*", "num_test_symbols", "]", "\n", "valid_data", "=", "data", "[", "-", "2", "*", "num_test_symbols", ":", "-", "num_test_symbols", "]", "\n", "test_data", "=", "data", "[", "-", "num_test_symbols", ":", "]", "\n", "return", "train_data", ",", "valid_data", ",", "test_data", ",", "unique", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader.ptb_raw_data": [[87, 120], ["os.path.join", "os.path.join", "os.path.join", "reader._build_vocab", "reader._file_to_word_ids", "reader._file_to_word_ids", "reader._file_to_word_ids", "len", "print"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._build_vocab", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids"], ["", "def", "ptb_raw_data", "(", "data_path", "=", "None", ",", "filename", "=", "'ptb.'", ")", ":", "\n", "  ", "\"\"\"Load PTB raw data from data directory \"data_path\".\n\n  Reads PTB text files, converts strings to integer ids,\n  and performs mini-batching of the inputs.\n\n  The PTB dataset comes from Tomas Mikolov's webpage:\n\n  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n\n  Args:\n    data_path: string path to the directory where simple-examples.tgz has\n      been extracted.\n\n  Returns:\n    tuple (train_data, valid_data, test_data, vocabulary)\n    where each of the data objects can be passed to PTBIterator.\n  \"\"\"", "\n", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'train.txt'", ")", "\n", "valid_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'valid.txt'", ")", "\n", "test_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'test.txt'", ")", "\n", "#print (train_path)", "\n", "\n", "word_to_id", "=", "_build_vocab", "(", "train_path", ")", "\n", "train_data", "=", "_file_to_word_ids", "(", "train_path", ",", "word_to_id", ")", "\n", "valid_data", "=", "_file_to_word_ids", "(", "valid_path", ",", "word_to_id", ")", "\n", "test_data", "=", "_file_to_word_ids", "(", "test_path", ",", "word_to_id", ")", "\n", "vocabulary", "=", "len", "(", "word_to_id", ")", "\n", "#   save_name='ptb_char'", "\n", "print", "(", "'voc'", ",", "vocabulary", ")", "\n", "#   np.savez(save_name, train_data, valid_data, test_data, vocabulary)", "\n", "return", "train_data", ",", "valid_data", ",", "test_data", ",", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.wordPTB.reader.data_iterator": [[122, 158], ["numpy.array", "len", "numpy.zeros", "range", "range", "ValueError"], "function", ["None"], ["", "def", "data_iterator", "(", "raw_data", ",", "batch_size", ",", "num_steps", ")", ":", "\n", "  ", "\"\"\"Iterate on the raw Hutter prize data or the raw PTB data.\n\n  This generates batch_size pointers into the given raw data, and allows\n  minibatch iteration along these pointers.\n\n  Args:\n    raw_data: one of the raw data outputs from hutter_raw_data or ptb_raw_data.\n    batch_size: int, the batch size.\n    num_steps: int, the number of unrolls.\n\n  Yields:\n    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n    The second element of the tuple is the same data time-shifted to the\n    right by one.\n\n  Raises:\n    ValueError: if batch_size or num_steps are too high.\n  \"\"\"", "\n", "raw_data", "=", "np", ".", "array", "(", "raw_data", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "data_len", "=", "len", "(", "raw_data", ")", "\n", "batch_len", "=", "data_len", "//", "batch_size", "\n", "data", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "batch_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "data", "[", "i", "]", "=", "raw_data", "[", "batch_len", "*", "i", ":", "batch_len", "*", "(", "i", "+", "1", ")", "]", "\n", "\n", "", "epoch_size", "=", "(", "batch_len", "-", "1", ")", "//", "num_steps", "\n", "\n", "if", "epoch_size", "==", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or num_steps\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "    ", "x", "=", "data", "[", ":", ",", "i", "*", "num_steps", ":", "(", "i", "+", "1", ")", "*", "num_steps", "]", "\n", "y", "=", "data", "[", ":", ",", "i", "*", "num_steps", "+", "1", ":", "(", "i", "+", "1", ")", "*", "num_steps", "+", "1", "]", "\n", "yield", "(", "x", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.opts.train_opts": [[5, 38], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "train_opts", "(", "parser", ")", ":", "\n", "  ", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "2e-4", ",", "help", "=", "'lr'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'batch_size'", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_len'", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "'num_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_units'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'--test_CV'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'use the CS test setting. If True, then use CV test setting.'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_weightdecay_nohiddenW'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--decayrate'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "1e-4", ",", "help", "=", "'lr'", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_bn_afterrnn'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "'--ini_in2hid'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "0.002", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--constrain_U'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--MAG'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "5.0", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--rotation_aug'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_fold'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--ini_b'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--end_rate'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "1e-6", ")", "\n", "\n", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_dropout'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--droprate'", ",", "type", "=", "np", ".", "float32", ",", "default", "=", "0.1", ",", "help", "=", "'lr'", ")", "\n", "parser", ".", "add_argument", "(", "'--rec_drop'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--conv_drop'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.batch_thread.__init__": [[22, 41], ["numpy.load", "numpy.load", "numpy.load", "len", "numpy.arange", "numpy.random.shuffle", "print"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ",", "seq_len", ")", ":", "#, datasets", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "idx", "=", "-", "1", "\n", "\n", "dataname", "=", "datasets", "+", "'.npy'", "\n", "labelname", "=", "datasets", "+", "'_label.npy'", "\n", "lenname", "=", "datasets", "+", "'_len.npy'", "\n", "self", ".", "data_handle", "=", "np", ".", "load", "(", "dataname", ")", "\n", "self", ".", "label_handle", "=", "np", ".", "load", "(", "labelname", ")", "\n", "self", ".", "len_handle", "=", "np", ".", "load", "(", "lenname", ")", "\n", "\n", "self", ".", "num_videos", "=", "len", "(", "self", ".", "data_handle", ")", "\n", "self", ".", "shufflevideolist", "=", "np", ".", "arange", "(", "self", ".", "num_videos", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "shufflevideolist", ")", "\n", "\n", "print", "(", "'Dataset size'", ",", "self", ".", "num_videos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.batch_thread.__call__": [[42, 89], ["range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "templabel.append", "tempindex.append", "numpy.zeros", "batch_data.append", "numpy.random.shuffle", "numpy.int32", "numpy.int32", "tuple", "numpy.random.randint", "numpy.random.randint", "min", "range", "max", "numpy.random.randint", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "###Be careful.  The appended data may change like pointer.", "\n", "    ", "templabel", "=", "[", "]", "\n", "batch_data", "=", "[", "]", "\n", "tempindex", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "batch_size_", ")", ":", "\n", "      ", "self", ".", "idx", "+=", "1", "\n", "if", "self", ".", "idx", "==", "self", ".", "num_videos", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "shufflevideolist", ")", "\n", "", "shufflevideoindex", "=", "self", ".", "shufflevideolist", "[", "self", ".", "idx", "]", "\n", "\n", "label", "=", "self", ".", "label_handle", "[", "shufflevideoindex", "]", "\n", "templabel", ".", "append", "(", "np", ".", "int32", "(", "label", ")", ")", "\n", "tempindex", ".", "append", "(", "np", ".", "int32", "(", "shufflevideoindex", ")", ")", "\n", "dataset", "=", "self", ".", "data_handle", "[", "shufflevideoindex", "]", "\n", "len_data", "=", "self", ".", "len_handle", "[", "shufflevideoindex", "]", "\n", "\n", "sample", "=", "np", ".", "zeros", "(", "tuple", "(", "(", "self", ".", "seq_len", ",", ")", "+", "self", ".", "data_handle", "[", "shufflevideoindex", "]", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "lenperseg", "=", "len_data", "//", "self", ".", "seq_len", "\n", "if", "lenperseg", "==", "1", "and", "len_data", ">", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "len_data", "-", "self", ".", "seq_len", ")", "\n", "sample", "=", "dataset", "[", "startid", ":", "startid", "+", "self", ".", "seq_len", "]", "\n", "", "elif", "len_data", "<=", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "max", "(", "self", ".", "seq_len", "-", "len_data", ",", "int", "(", "0.25", "*", "self", ".", "seq_len", ")", ")", ")", "\n", "endid", "=", "min", "(", "self", ".", "seq_len", ",", "startid", "+", "len_data", ")", "\n", "datasid", "=", "0", "\n", "dataeid", "=", "len_data", "\n", "if", "startid", "+", "len_data", ">", "self", ".", "seq_len", ":", "\n", "          ", "datasid", "=", "np", ".", "random", ".", "randint", "(", "startid", "+", "len_data", "-", "self", ".", "seq_len", ")", "\n", "dataeid", "=", "datasid", "+", "self", ".", "seq_len", "-", "startid", "\n", "", "sample", "[", "startid", ":", "endid", "]", "=", "dataset", "[", "datasid", ":", "dataeid", "]", "\n", "", "else", ":", "\n", "        ", "for", "framei", "in", "range", "(", "self", ".", "seq_len", ")", ":", "\n", "          ", "if", "framei", "==", "self", ".", "seq_len", "-", "1", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "len_data", "-", "lenperseg", "*", "(", "self", ".", "seq_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "lenperseg", ")", "\n", "", "sample", "[", "framei", "]", "=", "dataset", "[", "index", "]", "\n", "#print (index,lenperseg)  ", "\n", "\n", "", "", "batch_data", ".", "append", "(", "sample", ")", "###Be careful. It has to be different. Otherwise, the appended data will change as well.", "\n", "#print(batch_data)       ", "\n", "\n", "\n", "", "self", ".", "result", "[", "'data'", "]", "=", "np", ".", "asarray", "(", "batch_data", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "result", "[", "'label'", "]", "=", "np", ".", "asarray", "(", "templabel", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "result", "[", "'index'", "]", "=", "np", ".", "asarray", "(", "tempindex", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.batch_thread.GetDatasetSize": [[91, 93], ["None"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "num_videos", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.DataHandler.__init__": [[98, 112], ["random.seed", "data_reader_numpy_test.batch_thread", "data_reader_numpy_test.DataHandler.batch_advancer.GetDatasetSize", "data_reader_numpy_test.DataHandler.dispatch_worker", "data_reader_numpy_test.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetDatasetSize", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ",", "seq_len", ")", ":", "#, datasets", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "\n", "#self.datasets = datasets    ", "\n", "random", ".", "seed", "(", "10", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "\n", "self", ".", "batch_advancer", "=", "batch_thread", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ",", "seq_len", ")", "#, self.datasets", "\n", "\n", "self", ".", "datasetsize", "=", "self", ".", "batch_advancer", ".", "GetDatasetSize", "(", ")", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.DataHandler.GetBatch": [[114, 128], ["data_reader_numpy_test.DataHandler.dispatch_worker", "data_reader_numpy_test.DataHandler.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "GetBatch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "#     self.batch_data_=self.thread_result['data']", "\n", "#     self.batch_label_=self.thread_result['label']", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "self", ".", "batch_index_", "=", "self", ".", "thread_result", "[", "'index'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", ",", "self", ".", "batch_index_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.DataHandler.dispatch_worker": [[133, 137], ["threading.Thread", "data_reader_numpy_test.DataHandler.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.DataHandler.join_worker": [[138, 142], ["data_reader_numpy_test.DataHandler.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.DataHandler.GetDatasetSize": [[143, 145], ["None"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "datasetsize", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_test.main": [[150, 153], ["data_reader_numpy_test.DataHandler", "print"], "function", ["None"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "dh", "=", "DataHandler", "(", "10", ",", "30", ",", "'train_ntus'", ")", "#'test_ntus.h5')#'test_ntus_allwitherror.h5')#", "\n", "print", "(", "dh", ".", "GetDatasetSize", ")", "\n", "#  ", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.batch_thread_train.__init__": [[59, 65], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ",", "seq_len", ",", "use_rotation", "=", "False", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "idx", "=", "0", "\n", "self", ".", "use_rotation", "=", "use_rotation", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.batch_thread_train.__call__": [[66, 121], ["range", "numpy.asarray", "numpy.asarray", "templabel.append", "numpy.zeros", "batch_data.append", "numpy.random.shuffle", "numpy.int32", "tuple", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "min", "range", "data_reader_numpy_witheval.rotate", "max", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.rotate"], ["", "def", "__call__", "(", "self", ")", ":", "###Be careful.  The appended data may change like pointer.", "\n", "    ", "templabel", "=", "[", "]", "\n", "batch_data", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "batch_size_", ")", ":", "\n", "      ", "self", ".", "idx", "+=", "1", "\n", "if", "self", ".", "idx", "==", "train_no", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "shufflevideolist_train", ")", "\n", "", "shufflevideoindex", "=", "shufflevideolist_train", "[", "self", ".", "idx", "]", "\n", "\n", "\n", "label", "=", "label_handle", "[", "shufflevideoindex", "]", "\n", "templabel", ".", "append", "(", "np", ".", "int32", "(", "label", ")", ")", "\n", "dataset", "=", "data_handle", "[", "shufflevideoindex", "]", "\n", "len_data", "=", "len_handle", "[", "shufflevideoindex", "]", "\n", "\n", "sample", "=", "np", ".", "zeros", "(", "tuple", "(", "(", "self", ".", "seq_len", ",", ")", "+", "data_handle", "[", "shufflevideoindex", "]", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "lenperseg", "=", "len_data", "//", "self", ".", "seq_len", "\n", "if", "lenperseg", "==", "1", "and", "len_data", ">", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "len_data", "-", "self", ".", "seq_len", ")", "\n", "sample", "=", "dataset", "[", "startid", ":", "startid", "+", "self", ".", "seq_len", "]", "\n", "#print('wrong data length first')", "\n", "", "elif", "len_data", "<=", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "max", "(", "self", ".", "seq_len", "-", "len_data", ",", "int", "(", "0.25", "*", "self", ".", "seq_len", ")", ")", ")", "\n", "endid", "=", "min", "(", "self", ".", "seq_len", ",", "startid", "+", "len_data", ")", "\n", "datasid", "=", "0", "\n", "dataeid", "=", "len_data", "\n", "if", "startid", "+", "len_data", ">", "self", ".", "seq_len", ":", "\n", "          ", "datasid", "=", "np", ".", "random", ".", "randint", "(", "startid", "+", "len_data", "-", "self", ".", "seq_len", ")", "\n", "dataeid", "=", "datasid", "+", "self", ".", "seq_len", "-", "startid", "\n", "", "sample", "[", "startid", ":", "endid", "]", "=", "dataset", "[", "datasid", ":", "dataeid", "]", "\n", "", "else", ":", "\n", "        ", "for", "framei", "in", "range", "(", "self", ".", "seq_len", ")", ":", "\n", "          ", "if", "framei", "==", "self", ".", "seq_len", "-", "1", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "len_data", "-", "lenperseg", "*", "(", "self", ".", "seq_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "lenperseg", ")", "\n", "", "sample", "[", "framei", "]", "=", "dataset", "[", "index", "]", "\n", "\n", "#print(sample)", "\n", "", "", "if", "self", ".", "use_rotation", ":", "\n", "        ", "if", "np", ".", "random", ".", "randint", "(", "2", ")", ":", "\n", "          ", "s", "=", "np", ".", "random", ".", "randint", "(", "2", ")", "*", "45", "#random(1)*45", "\n", "b", "=", "np", ".", "random", ".", "randint", "(", "2", ")", "*", "45", "#random(1)*45", "\n", "#print(sample.shape)", "\n", "sample", "=", "rotate", "(", "sample", ",", "s", ",", "b", ")", "\n", "#print (index,lenperseg)  ", "\n", "#       rframei=np.random.randint(len_data)  ", "\n", "#       tmean=(dataset[rframei,0,:]+dataset[rframei,12,:]+dataset[rframei,16,:])/3", "\n", "#       sample=sample-tmean  ", "\n", "", "", "batch_data", ".", "append", "(", "sample", ")", "###Be careful. It has to be different. Otherwise, the appended data will change as well.", "\n", "#print(batch_data)       ", "\n", "\n", "", "self", ".", "result", "[", "'data'", "]", "=", "np", ".", "asarray", "(", "batch_data", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "result", "[", "'label'", "]", "=", "np", ".", "asarray", "(", "templabel", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_train.__init__": [[124, 136], ["random.seed", "data_reader_numpy_witheval.batch_thread_train", "data_reader_numpy_witheval.DataHandler_train.dispatch_worker", "data_reader_numpy_witheval.DataHandler_train.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ",", "seq_len", ",", "use_rotation", "=", "False", ")", ":", "#datasets,", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "\n", "#self.datasets = datasets    ", "\n", "random", ".", "seed", "(", "10", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "\n", "self", ".", "batch_advancer", "=", "batch_thread_train", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ",", "seq_len", ",", "use_rotation", ")", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_train.GetBatch": [[138, 148], ["data_reader_numpy_witheval.DataHandler_train.dispatch_worker", "data_reader_numpy_witheval.DataHandler_train.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "GetBatch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_train.dispatch_worker": [[149, 153], ["threading.Thread", "data_reader_numpy_witheval.DataHandler_train.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_train.join_worker": [[154, 158], ["data_reader_numpy_witheval.DataHandler_train.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_train.GetDatasetSize": [[159, 161], ["None"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "train_no", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.batch_thread_eval.__init__": [[171, 176], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "result", ",", "batch_size_", ",", "seq_len", ")", ":", "\n", "    ", "self", ".", "result", "=", "result", "\n", "self", ".", "batch_size_", "=", "batch_size_", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.batch_thread_eval.__call__": [[177, 221], ["range", "numpy.asarray", "numpy.asarray", "templabel.append", "numpy.zeros", "batch_data.append", "numpy.random.shuffle", "numpy.int32", "tuple", "numpy.random.randint", "numpy.random.randint", "min", "range", "max", "numpy.random.randint", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "###Be careful.  The appended data may change like pointer.", "\n", "    ", "templabel", "=", "[", "]", "\n", "batch_data", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "batch_size_", ")", ":", "\n", "      ", "self", ".", "idx", "+=", "1", "\n", "if", "self", ".", "idx", "==", "test_no", ":", "\n", "        ", "self", ".", "idx", "=", "0", "\n", "np", ".", "random", ".", "shuffle", "(", "shufflevideolist_test", ")", "\n", "", "shufflevideoindex", "=", "shufflevideolist_test", "[", "self", ".", "idx", "]", "\n", "\n", "\n", "label", "=", "label_handle", "[", "shufflevideoindex", "]", "\n", "templabel", ".", "append", "(", "np", ".", "int32", "(", "label", ")", ")", "\n", "dataset", "=", "data_handle", "[", "shufflevideoindex", "]", "\n", "len_data", "=", "len_handle", "[", "shufflevideoindex", "]", "\n", "\n", "sample", "=", "np", ".", "zeros", "(", "tuple", "(", "(", "self", ".", "seq_len", ",", ")", "+", "data_handle", "[", "shufflevideoindex", "]", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "lenperseg", "=", "len_data", "//", "self", ".", "seq_len", "\n", "if", "lenperseg", "==", "1", "and", "len_data", ">", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "len_data", "-", "self", ".", "seq_len", ")", "\n", "sample", "=", "dataset", "[", "startid", ":", "startid", "+", "self", ".", "seq_len", "]", "\n", "", "elif", "len_data", "<=", "self", ".", "seq_len", ":", "\n", "        ", "startid", "=", "np", ".", "random", ".", "randint", "(", "max", "(", "self", ".", "seq_len", "-", "len_data", ",", "int", "(", "0.25", "*", "self", ".", "seq_len", ")", ")", ")", "\n", "endid", "=", "min", "(", "self", ".", "seq_len", ",", "startid", "+", "len_data", ")", "\n", "datasid", "=", "0", "\n", "dataeid", "=", "len_data", "\n", "if", "startid", "+", "len_data", ">", "self", ".", "seq_len", ":", "\n", "          ", "datasid", "=", "np", ".", "random", ".", "randint", "(", "startid", "+", "len_data", "-", "self", ".", "seq_len", ")", "\n", "dataeid", "=", "datasid", "+", "self", ".", "seq_len", "-", "startid", "\n", "", "sample", "[", "startid", ":", "endid", "]", "=", "dataset", "[", "datasid", ":", "dataeid", "]", "\n", "", "else", ":", "\n", "        ", "for", "framei", "in", "range", "(", "self", ".", "seq_len", ")", ":", "\n", "          ", "if", "framei", "==", "self", ".", "seq_len", "-", "1", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "len_data", "-", "lenperseg", "*", "(", "self", ".", "seq_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "index", "=", "lenperseg", "*", "framei", "+", "np", ".", "random", ".", "randint", "(", "lenperseg", ")", "\n", "", "sample", "[", "framei", "]", "=", "dataset", "[", "index", "]", "\n", "#print (index,lenperseg)  ", "\n", "\n", "", "", "batch_data", ".", "append", "(", "sample", ")", "###Be careful. It has to be different. Otherwise, the appended data will change as well.", "\n", "#print(batch_data)       ", "\n", "\n", "", "self", ".", "result", "[", "'data'", "]", "=", "np", ".", "asarray", "(", "batch_data", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "result", "[", "'label'", "]", "=", "np", ".", "asarray", "(", "templabel", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.__init__": [[224, 236], ["random.seed", "data_reader_numpy_witheval.batch_thread_eval", "data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "data_reader_numpy_witheval.DataHandler_eval.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["  ", "def", "__init__", "(", "self", ",", "batch_size", ",", "seq_len", ")", ":", "#, datasets", "\n", "    ", "self", ".", "batch_size_", "=", "batch_size", "\n", "#self.datasets = datasets    ", "\n", "random", ".", "seed", "(", "10", ")", "\n", "\n", "self", ".", "thread_result", "=", "{", "}", "\n", "self", ".", "thread", "=", "None", "\n", "\n", "self", ".", "batch_advancer", "=", "batch_thread_eval", "(", "self", ".", "thread_result", ",", "self", ".", "batch_size_", ",", "seq_len", ")", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "self", ".", "join_worker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetBatch": [[238, 248], ["data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "data_reader_numpy_witheval.DataHandler_eval.join_worker"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker"], ["", "def", "GetBatch", "(", "self", ")", ":", "\n", "#self.batch_data_  = np.zeros((self.batch_size_, 3, self.seq_length_, 112, 112), dtype=np.float32)", "\n", "    ", "if", "self", ".", "thread", "is", "not", "None", ":", "\n", "      ", "self", ".", "join_worker", "(", ")", "\n", "\n", "", "self", ".", "batch_data_", "=", "self", ".", "thread_result", "[", "'data'", "]", "\n", "self", ".", "batch_label_", "=", "self", ".", "thread_result", "[", "'label'", "]", "\n", "\n", "self", ".", "dispatch_worker", "(", ")", "\n", "return", "self", ".", "batch_data_", ",", "self", ".", "batch_label_", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.dispatch_worker": [[249, 253], ["threading.Thread", "data_reader_numpy_witheval.DataHandler_eval.thread.start"], "methods", ["None"], ["", "def", "dispatch_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "None", "\n", "self", ".", "thread", "=", "Thread", "(", "target", "=", "self", ".", "batch_advancer", ")", "\n", "self", ".", "thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.join_worker": [[254, 258], ["data_reader_numpy_witheval.DataHandler_eval.thread.join"], "methods", ["None"], ["", "def", "join_worker", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "thread", "is", "not", "None", "\n", "self", ".", "thread", ".", "join", "(", ")", "\n", "self", ".", "thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetDatasetSize": [[259, 261], ["None"], "methods", ["None"], ["", "def", "GetDatasetSize", "(", "self", ")", ":", "\n", "    ", "return", "test_no", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.rotate": [[39, 57], ["input.reshape.reshape", "RX.reshape.reshape", "RY.reshape.reshape", "RZ.reshape.reshape", "numpy.concatenate", "output.reshape.reshape", "numpy.cos", "numpy.sin", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.cos", "numpy.sin", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.sin", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.cos"], "function", ["None"], ["def", "rotate", "(", "input", ",", "s", ",", "b", ")", ":", "\n", "  ", "shape", "=", "input", ".", "shape", "\n", "input", "=", "input", ".", "reshape", "(", "(", "-", "1", ",", "3", ")", ")", "\n", "XT", "=", "input", "[", ":", ",", "0", "]", "\n", "YT", "=", "input", "[", ":", ",", "1", "]", "\n", "ZT", "=", "input", "[", ":", ",", "2", "]", "\n", "s", "=", "s", "/", "180.0", "*", "np", ".", "pi", "\n", "b", "=", "b", "/", "180.0", "*", "np", ".", "pi", "\n", "RX", "=", "XT", "*", "np", ".", "cos", "(", "b", ")", "-", "ZT", "*", "np", ".", "sin", "(", "b", ")", "+", "ZT", "*", "np", ".", "sin", "(", "b", ")", "*", "np", ".", "cos", "(", "s", ")", "+", "YT", "*", "np", ".", "sin", "(", "b", ")", "*", "np", ".", "sin", "(", "s", ")", "-", "ZT", "*", "np", ".", "sin", "(", "b", ")", "*", "(", "np", ".", "cos", "(", "s", ")", "-", "1", ")", ";", "\n", "RY", "=", "YT", "*", "np", ".", "cos", "(", "s", ")", ";", "\n", "RZ", "=", "ZT", "*", "np", ".", "cos", "(", "b", ")", "*", "np", ".", "cos", "(", "s", ")", "-", "ZT", "*", "(", "np", ".", "cos", "(", "b", ")", "-", "1", ")", "-", "XT", "*", "np", ".", "sin", "(", "b", ")", "+", "YT", "*", "np", ".", "cos", "(", "b", ")", "*", "np", ".", "sin", "(", "s", ")", "-", "ZT", "*", "np", ".", "cos", "(", "b", ")", "*", "(", "np", ".", "cos", "(", "s", ")", "-", "1", ")", ";", "\n", "RX", "=", "RX", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "RY", "=", "RY", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "RZ", "=", "RZ", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "output", "=", "np", ".", "concatenate", "(", "[", "RX", ",", "RY", ",", "RZ", "]", ",", "axis", "=", "1", ")", "\n", "output", "=", "output", ".", "reshape", "(", "shape", ")", "\n", "#print(shape,output.shape,input.shape)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.main": [[264, 280], ["data_reader_numpy_witheval.DataHandler_train", "print", "data_reader_numpy_witheval.DataHandler_eval", "print", "data_reader_numpy_witheval.DataHandler_train.GetBatch", "data_reader_numpy_witheval.DataHandler_train.GetBatch", "data_reader_numpy_witheval.DataHandler_train.GetDatasetSize", "data_reader_numpy_witheval.DataHandler_eval.GetDatasetSize"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetBatch", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetBatch", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetDatasetSize", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.data_reader_numpy_witheval.DataHandler_eval.GetDatasetSize"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "dh", "=", "DataHandler_train", "(", "1", ",", "30", ",", "True", ")", "#'test_ntus.h5')#'test_ntus_allwitherror.h5')#", "\n", "print", "(", "dh", ".", "GetDatasetSize", "(", ")", ")", "\n", "dh_eval", "=", "DataHandler_eval", "(", "10", ",", "30", ")", "#'test_ntus.h5')#'test_ntus_allwitherror.h5')#", "\n", "print", "(", "dh_eval", ".", "GetDatasetSize", "(", ")", ")", "\n", "\n", "x", ",", "y", "=", "dh", ".", "GetBatch", "(", ")", "\n", "#   print (x.shape)", "\n", "#   print (y[0:3],x[0,0,0],x[1,0,0],x[0,1,0])", "\n", "#   x,y = dh_eval.GetBatch()", "\n", "#   #print (x[0,0],y)  ", "\n", "#   print (y,x[0,0,0])", "\n", "#   x,y = dh.GetBatch()", "\n", "#   #print (x[0,0],y)", "\n", "#   print (y,x[0,0,0])", "\n", "x", ",", "y", "=", "dh", ".", "GetBatch", "(", ")", "\n", "#print (x[0,0],y)    ", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.Indrnn_action_network.build_indrnn_network": [[47, 75], ["lasagne.layers.InputLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DimshuffleLayer", "range", "lasagne.layers.SliceLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "rnnmodel", "lasagne.layers.DropoutLayer", "lasagne.layers.BatchNormLayer", "lasagne.layers.BatchNormLayer", "lasagne.layers.DropoutLayer", "lasagne.init.Constant", "lasagne.init.Uniform", "lasagne.init.Constant"], "function", ["None"], ["", "def", "build_indrnn_network", "(", "X_sym", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "net", "[", "'input0'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ",", "indim", ",", "3", ")", ",", "X_sym", ")", "\n", "net", "[", "'input'", "]", "=", "ReshapeLayer", "(", "net", "[", "'input0'", "]", ",", "(", "batch_size", ",", "seq_len", ",", "indim", "*", "3", ")", ")", "\n", "net", "[", "'rnn0'", "]", "=", "DimshuffleLayer", "(", "net", "[", "'input'", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "for", "l", "in", "range", "(", "1", ",", "num_layers", "+", "1", ")", ":", "\n", "      ", "hidini", "=", "0", "\n", "if", "l", "==", "num_layers", ":", "\n", "        ", "hidini", "=", "U_lowbound", "\n", "", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "hidden_units", ",", "W", "=", "ini_W", ",", "b", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ",", "nonlinearity", "=", "None", ")", "#", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "if", "args", ".", "conv_drop", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DropoutLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", ")", ")", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "\n", "if", "not", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNormLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "beta", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "rnnmodel", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "hidden_units", ",", "W_hid_to_hid", "=", "Uniform", "(", "range", "=", "(", "hidini", ",", "U_bound", ")", ")", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "False", ",", "grad_clipping", "=", "gradclipvalue", ")", "\n", "\n", "if", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNormLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "", "if", "args", ".", "use_dropout", "and", "l", "%", "args", ".", "drop_layers", "==", "0", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "DropoutLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", ")", ")", "\n", "\n", "", "", "net", "[", "'rnn%d'", "%", "num_layers", "]", "=", "lasagne", ".", "layers", ".", "SliceLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "indices", "=", "-", "1", ",", "axis", "=", "0", ")", "\n", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.MulLayer.__init__": [[40, 44], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN_onlyrecurrent.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.MulLayer.get_output_for": [[45, 47], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.MulLayer.get_output_shape_for": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__": [[58, 134], ["lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.MergeLayer.__init__", "isinstance", "incomings.append", "incomings.append", "len", "ValueError", "len", "ValueError", "ValueError", "IndRNN_onlyrecurrent.onlyRecurrentLayer.add_param", "len", "len", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["def", "__init__", "(", "self", ",", "incoming", ",", "input_to_hidden", ",", "hidden_to_hidden", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# This layer inherits from a MergeLayer, because it can have three", "\n", "# inputs - the layer input, the mask and the initial hidden state.  We", "\n", "# will just provide the layer input as incomings, unless a mask input", "\n", "# or initial hidden state was provided.", "\n", "        ", "incomings", "=", "[", "incoming", "]", "\n", "self", ".", "mask_incoming_index", "=", "-", "1", "\n", "self", ".", "hid_init_incoming_index", "=", "-", "1", "\n", "if", "mask_input", "is", "not", "None", ":", "\n", "            ", "incomings", ".", "append", "(", "mask_input", ")", "\n", "self", ".", "mask_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "incomings", ".", "append", "(", "hid_init", ")", "\n", "self", ".", "hid_init_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "\n", "", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "__init__", "(", "incomings", ",", "**", "kwargs", ")", "\n", "\n", "input_to_hidden_in_layers", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "input_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "input_to_hidden_in_layers", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`input_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "input_to_hidden_in_layers", ")", ")", ")", "\n", "\n", "", "hidden_to_hidden_in_lyrs", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "hidden_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "hidden_to_hidden_in_lyrs", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`hidden_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "hidden_to_hidden_in_lyrs", ")", ")", ")", "\n", "", "hidden_to_hidden_in_layer", "=", "hidden_to_hidden_in_lyrs", "[", "0", "]", "\n", "\n", "self", ".", "input_to_hidden", "=", "input_to_hidden", "\n", "self", ".", "hidden_to_hidden", "=", "hidden_to_hidden", "\n", "self", ".", "learn_init", "=", "learn_init", "\n", "self", ".", "backwards", "=", "backwards", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "grad_clipping", "=", "grad_clipping", "\n", "self", ".", "unroll_scan", "=", "unroll_scan", "\n", "self", ".", "precompute_input", "=", "precompute_input", "\n", "self", ".", "only_return_final", "=", "only_return_final", "\n", "\n", "\n", "if", "unroll_scan", "and", "gradient_steps", "!=", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Gradient steps must be -1 when unroll_scan is true.\"", ")", "\n", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "\n", "if", "nonlinearity", "is", "None", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearities", ".", "identity", "\n", "", "else", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "\n", "# Initialize hidden state", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "self", ".", "hid_init", "=", "hid_init", "\n", "", "else", ":", "\n", "            ", "self", ".", "hid_init", "=", "self", ".", "add_param", "(", "\n", "hid_init", ",", "(", "1", ",", ")", "+", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ",", "\n", "name", "=", "\"hid_init\"", ",", "trainable", "=", "learn_init", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params": [[135, 142], ["super().get_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params"], ["", "", "def", "get_params", "(", "self", ",", "**", "tags", ")", ":", "\n", "# Get all parameters from this layer, the master layer", "\n", "        ", "params", "=", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "get_params", "(", "**", "tags", ")", "\n", "# Combine with all parameters from the child layers", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "input_to_hidden", ",", "**", "tags", ")", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ",", "**", "tags", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_shape_for": [[143, 155], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shapes", ")", ":", "\n", "# The shape of the input to this layer will be the first element", "\n", "# of input_shapes, whether or not a mask input is being used.", "\n", "        ", "input_shape", "=", "input_shapes", "[", "0", "]", "\n", "# When only_return_final is true, the second (sequence step) dimension", "\n", "# will be flattened", "\n", "if", "self", ".", "only_return_final", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", "\n", "# Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "\n", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for": [[156, 251], ["lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "IndRNN_onlyrecurrent.onlyRecurrentLayer.nonlinearity", "IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for.step"], "methods", ["None"], ["", "", "def", "get_output_for", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Retrieve the layer input", "\n", "        ", "input", "=", "inputs", "[", "0", "]", "\n", "# Retrieve the mask when it is supplied", "\n", "mask", "=", "None", "\n", "hid_init", "=", "None", "\n", "if", "self", ".", "mask_incoming_index", ">", "0", ":", "\n", "            ", "mask", "=", "inputs", "[", "self", ".", "mask_incoming_index", "]", "\n", "", "if", "self", ".", "hid_init_incoming_index", ">", "0", ":", "\n", "            ", "hid_init", "=", "inputs", "[", "self", ".", "hid_init_incoming_index", "]", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, n_features)", "\n", "# but scan requires the iterable dimension to be first", "\n", "# So, we need to dimshuffle to (n_time_steps, n_batch, n_features)", "\n", "#input = input.dimshuffle(1, 0, *range(2, input.ndim))", "\n", "", "seq_len", ",", "num_batch", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "# We will always pass the hidden-to-hidden layer params to step", "\n", "non_seqs", "=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ")", "\n", "\n", "# Create single recurrent computation step function", "\n", "def", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Compute the hidden-to-hidden activation", "\n", "            ", "hid_pre", "=", "helper", ".", "get_output", "(", "\n", "self", ".", "hidden_to_hidden", ",", "hid_previous", ",", "**", "kwargs", ")", "\n", "\n", "hid_pre", "+=", "input_n", "\n", "\n", "# Clip gradients", "\n", "if", "self", ".", "grad_clipping", ":", "\n", "                ", "hid_pre", "=", "theano", ".", "gradient", ".", "grad_clip", "(", "\n", "hid_pre", ",", "-", "self", ".", "grad_clipping", ",", "self", ".", "grad_clipping", ")", "\n", "\n", "", "return", "self", ".", "nonlinearity", "(", "hid_pre", ")", "\n", "\n", "", "def", "step_masked", "(", "input_n", ",", "mask_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Skip over any input with mask 0 by copying the previous", "\n", "# hidden state; proceed normally for any input with mask 1.", "\n", "            ", "hid", "=", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", "\n", "hid_out", "=", "T", ".", "switch", "(", "mask_n", ",", "hid", ",", "hid_previous", ")", "\n", "return", "[", "hid_out", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "dimshuffle", "(", "1", ",", "0", ",", "'x'", ")", "\n", "sequences", "=", "[", "input", ",", "mask", "]", "\n", "step_fun", "=", "step_masked", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "input", "\n", "step_fun", "=", "step", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "hid_init", ",", "Layer", ")", ":", "\n", "# The code below simply repeats self.hid_init num_batch times in", "\n", "# its first dimension.  Turns out using a dot product and a", "\n", "# dimshuffle is faster than T.repeat.", "\n", "            ", "dot_dims", "=", "(", "list", "(", "range", "(", "1", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", ")", ")", "+", "\n", "[", "0", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", "]", ")", "\n", "hid_init", "=", "T", ".", "dot", "(", "T", ".", "ones", "(", "(", "num_batch", ",", "1", ")", ")", ",", "\n", "self", ".", "hid_init", ".", "dimshuffle", "(", "dot_dims", ")", ")", "\n", "\n", "", "if", "self", ".", "unroll_scan", ":", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "            ", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "# Explicitly unroll the recurrence instead of using scan", "\n", "hid_out", "=", "unroll_scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "n_steps", "=", "input_shape", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# Scan op iterates over first dimension of input and repeatedly", "\n", "# applies the step function", "\n", "            ", "hid_out", "=", "theano", ".", "scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "truncate_gradient", "=", "self", ".", "gradient_steps", ",", "\n", "strict", "=", "True", ")", "[", "0", "]", "\n", "\n", "# When it is requested that we only return the final sequence step,", "\n", "# we need to slice it out immediately after scan is applied", "\n", "", "if", "self", ".", "only_return_final", ":", "\n", "            ", "hid_out", "=", "hid_out", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "# dimshuffle back to (n_batch, n_time_steps, n_features))", "\n", "#hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))", "\n", "\n", "# if scan is backward reverse the output", "\n", "            ", "if", "self", ".", "backwards", ":", "\n", "                ", "hid_out", "=", "hid_out", "[", ":", ":", "-", "1", ",", ":", "]", "\n", "\n", "", "", "return", "hid_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.action recognition.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__": [[255, 320], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "IndRNN_onlyrecurrent.MulLayer", "IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "#W_in_to_hid=init.Uniform(),", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "#b=init.Constant(0.),", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "InputLayer", "(", "input_shape", ")", "\n", "\n", "#         in_to_hid = DenseLayer(InputLayer((None,) + input_shape[2:]),", "\n", "#                                num_units, W=W_in_to_hid, b=b,", "\n", "#                                nonlinearity=None,", "\n", "#                                name=basename + 'input_to_hidden',", "\n", "#                                **layer_kwargs)        ", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "#self.W_in_to_hid = in_to_hid.W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "#self.b = in_to_hid.b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer_onlyrecurrent", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN.MulLayer.__init__": [[36, 40], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN.MulLayer.get_output_for": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN.MulLayer.get_output_shape_for": [[44, 46], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN.IndRNNLayer.__init__": [[50, 113], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "lasagne.layers.DenseLayer", "IndRNN.MulLayer", "lasagne.layers.CustomRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "W_in_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "b", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "DenseLayer", "(", "InputLayer", "(", "(", "None", ",", ")", "+", "input_shape", "[", "2", ":", "]", ")", ",", "\n", "num_units", ",", "W", "=", "W_in_to_hid", ",", "b", "=", "b", ",", "\n", "nonlinearity", "=", "None", ",", "\n", "name", "=", "basename", "+", "'input_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "self", ".", "W_in_to_hid", "=", "in_to_hid", ".", "W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "self", ".", "b", "=", "in_to_hid", ".", "b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.bn_eachstep_withdrop_timefirst.BatchNormLayer.__init__": [[10, 57], ["lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.layers.Layer.__init__", "any", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "isinstance", "len", "ValueError", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "bn_eachstep_withdrop_timefirst.BatchNormLayer.add_param", "len", "lasagne.layers.DropoutLayer", "lasagne.layers.DropoutLayer", "tuple", "enumerate", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "axes", "=", "'auto'", ",", "droprate", "=", "0.2", ",", "epsilon", "=", "1e-4", ",", "alpha", "=", "0.1", ",", "sparsity", "=", "1.0", ",", "\n", "beta", "=", "init", ".", "Constant", "(", "0", ")", ",", "gamma", "=", "init", ".", "Constant", "(", "1", ")", ",", "\n", "mean", "=", "init", ".", "Constant", "(", "0", ")", ",", "inv_std", "=", "init", ".", "Constant", "(", "1", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BatchNormLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "\n", "if", "axes", "==", "'auto'", ":", "\n", "# default: normalize over all but the second axis", "\n", "            ", "axes", "=", "(", "0", ",", ")", "+", "tuple", "(", "range", "(", "2", ",", "len", "(", "self", ".", "input_shape", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "axes", ",", "int", ")", ":", "\n", "            ", "axes", "=", "(", "axes", ",", ")", "\n", "", "self", ".", "axes", "=", "axes", "\n", "if", "len", "(", "axes", ")", "==", "1", ":", "\n", "          ", "self", ".", "mean_axes", "=", "self", ".", "axes", "\n", "", "else", ":", "\n", "          ", "self", ".", "mean_axes", "=", "(", "axes", "[", "1", "]", ",", ")", "\n", "\n", "", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "# create parameters, ignoring all dimensions in axes", "\n", "shape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "axes", "]", "\n", "meanshape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "mean_axes", "]", "\n", "if", "any", "(", "size", "is", "None", "for", "size", "in", "shape", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"BatchNormLayer needs specified input sizes for \"", "\n", "\"all axes not normalized over.\"", ")", "\n", "", "if", "beta", "is", "None", ":", "\n", "            ", "self", ".", "beta", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "self", ".", "add_param", "(", "beta", ",", "shape", ",", "'beta'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "False", ")", "\n", "", "if", "gamma", "is", "None", ":", "\n", "            ", "self", ".", "gamma", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma", "=", "self", ".", "add_param", "(", "gamma", ",", "shape", ",", "'gamma'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "True", ")", "\n", "", "self", ".", "mean", "=", "self", ".", "add_param", "(", "mean", ",", "meanshape", ",", "'mean'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "self", ".", "inv_std", "=", "self", ".", "add_param", "(", "inv_std", ",", "meanshape", ",", "'inv_std'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "#print('here',len(self.input_shape))", "\n", "self", ".", "sparsity", "=", "sparsity", "\n", "if", "len", "(", "self", ".", "input_shape", ")", "==", "3", ":", "\n", "          ", "self", ".", "dropout", "=", "DropoutLayer", "(", "(", "self", ".", "input_shape", "[", "0", "]", ",", "self", ".", "input_shape", "[", "1", "]", ",", "self", ".", "input_shape", "[", "2", "]", ")", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", "1", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "          ", "self", ".", "dropout", "=", "DropoutLayer", "(", "(", "self", ".", "input_shape", "[", "0", "]", ",", "self", ".", "input_shape", "[", "1", "]", ")", ",", "p", "=", "droprate", ",", "shared_axes", "=", "(", "0", ",", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.bn_eachstep_withdrop_timefirst.BatchNormLayer.get_output_for": [[58, 124], ["iter", "iter", "mean.dimshuffle.dimshuffle.dimshuffle", "inv_std.dimshuffle.dimshuffle.dimshuffle", "bn_eachstep_withdrop_timefirst.BatchNormLayer.dropout.get_output_for", "bn_eachstep_withdrop_timefirst.BatchNormLayer.mean", "theano.inv", "theano.inv", "theano.inv", "theano.inv", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "range", "bn_eachstep_withdrop_timefirst.BatchNormLayer.beta.dimshuffle", "bn_eachstep_withdrop_timefirst.BatchNormLayer.gamma.dimshuffle", "range", "theano.sqrt", "theano.sqrt", "bn_eachstep_withdrop_timefirst.BatchNormLayer.mean", "theano.sqrt", "theano.sqrt", "next", "range", "next", "range", "len", "len", "bn_eachstep_withdrop_timefirst.BatchNormLayer.var", "bn_eachstep_withdrop_timefirst.BatchNormLayer.var", "theano.sqr", "theano.sqr"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for"], ["", "", "def", "get_output_for", "(", "self", ",", "input", ",", "deterministic", "=", "False", ",", "\n", "batch_norm_use_averages", "=", "None", ",", "\n", "batch_norm_update_averages", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "sparsity", "==", "1", ":", "\n", "          ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "", "else", ":", "\n", "          ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "*", "(", "1.0", "/", "self", ".", "sparsity", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "*", "(", "1.0", "/", "self", ".", "sparsity", ")", "-", "(", "1", "-", "self", ".", "sparsity", ")", "*", "T", ".", "sqr", "(", "input_mean", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "\n", "# Decide whether to use the stored averages or mini-batch statistics", "\n", "", "if", "batch_norm_use_averages", "is", "None", ":", "\n", "            ", "batch_norm_use_averages", "=", "deterministic", "\n", "", "use_averages", "=", "batch_norm_use_averages", "\n", "\n", "if", "use_averages", ":", "\n", "            ", "mean", "=", "self", ".", "mean", "\n", "inv_std", "=", "self", ".", "inv_std", "\n", "", "else", ":", "\n", "            ", "mean", "=", "input_mean", "\n", "inv_std", "=", "input_inv_std", "\n", "\n", "# Decide whether to update the stored averages", "\n", "", "if", "batch_norm_update_averages", "is", "None", ":", "\n", "            ", "batch_norm_update_averages", "=", "not", "deterministic", "\n", "", "update_averages", "=", "batch_norm_update_averages", "\n", "\n", "if", "update_averages", ":", "\n", "# Trick: To update the stored statistics, we create memory-aliased", "\n", "# clones of the stored statistics:", "\n", "            ", "running_mean", "=", "theano", ".", "clone", "(", "self", ".", "mean", ",", "share_inputs", "=", "False", ")", "\n", "running_inv_std", "=", "theano", ".", "clone", "(", "self", ".", "inv_std", ",", "share_inputs", "=", "False", ")", "\n", "# set a default update for them:", "\n", "running_mean", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "running_mean", "+", "\n", "self", ".", "alpha", "*", "input_mean", ")", "\n", "running_inv_std", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "\n", "running_inv_std", "+", "\n", "self", ".", "alpha", "*", "input_inv_std", ")", "\n", "# and make sure they end up in the graph without participating in", "\n", "# the computation (this way their default_update will be collected", "\n", "# and applied, but the computation will be optimized away):", "\n", "mean", "+=", "0", "*", "running_mean", "\n", "inv_std", "+=", "0", "*", "running_inv_std", "\n", "\n", "# prepare dimshuffle pattern inserting broadcastable axes as needed", "\n", "", "param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "axes", ")", ")", ")", "\n", "pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "axes", "\n", "else", "next", "(", "param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "\n", "# apply dimshuffle pattern to all parameters", "\n", "beta", "=", "0", "if", "self", ".", "beta", "is", "None", "else", "self", ".", "beta", ".", "dimshuffle", "(", "pattern", ")", "\n", "gamma", "=", "1", "if", "self", ".", "gamma", "is", "None", "else", "self", ".", "gamma", ".", "dimshuffle", "(", "pattern", ")", "\n", "\n", "mean_param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "mean_axes", ")", ")", ")", "\n", "mean_pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "mean_axes", "\n", "else", "next", "(", "mean_param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "mean", "=", "mean", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "inv_std", "=", "inv_std", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "\n", "input", "=", "self", ".", "dropout", ".", "get_output_for", "(", "input", ",", "deterministic", "=", "deterministic", ")", "\n", "\n", "# normalize", "\n", "normalized", "=", "(", "input", "-", "mean", ")", "*", "(", "gamma", "*", "inv_std", ")", "+", "beta", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.__init__": [[16, 57], ["lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.init.Constant", "lasagne.layers.Layer.__init__", "any", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "isinstance", "len", "ValueError", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.add_param", "tuple", "enumerate", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "axes", "=", "'auto'", ",", "epsilon", "=", "1e-4", ",", "alpha", "=", "0.1", ",", "\n", "beta", "=", "init", ".", "Constant", "(", "0", ")", ",", "gamma", "=", "init", ".", "Constant", "(", "1", ")", ",", "\n", "mean", "=", "init", ".", "Constant", "(", "0", ")", ",", "inv_std", "=", "init", ".", "Constant", "(", "1", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BatchNorm_step_timefirst_Layer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "\n", "if", "axes", "==", "'auto'", ":", "\n", "# default: normalize over all but the second axis", "\n", "            ", "axes", "=", "(", "0", ",", ")", "+", "tuple", "(", "range", "(", "2", ",", "len", "(", "self", ".", "input_shape", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "axes", ",", "int", ")", ":", "\n", "            ", "axes", "=", "(", "axes", ",", ")", "\n", "", "self", ".", "axes", "=", "axes", "\n", "if", "len", "(", "axes", ")", "==", "1", ":", "\n", "          ", "self", ".", "mean_axes", "=", "self", ".", "axes", "\n", "", "else", ":", "\n", "          ", "self", ".", "mean_axes", "=", "(", "axes", "[", "1", "]", ",", ")", "\n", "\n", "", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "# create parameters, ignoring all dimensions in axes", "\n", "shape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "axes", "]", "\n", "meanshape", "=", "[", "size", "for", "axis", ",", "size", "in", "enumerate", "(", "self", ".", "input_shape", ")", "\n", "if", "axis", "not", "in", "self", ".", "mean_axes", "]", "\n", "if", "any", "(", "size", "is", "None", "for", "size", "in", "shape", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"BatchNormLayer needs specified input sizes for \"", "\n", "\"all axes not normalized over.\"", ")", "\n", "", "if", "beta", "is", "None", ":", "\n", "            ", "self", ".", "beta", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta", "=", "self", ".", "add_param", "(", "beta", ",", "shape", ",", "'beta'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "False", ")", "\n", "", "if", "gamma", "is", "None", ":", "\n", "            ", "self", ".", "gamma", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "gamma", "=", "self", ".", "add_param", "(", "gamma", ",", "shape", ",", "'gamma'", ",", "\n", "trainable", "=", "True", ",", "regularizable", "=", "True", ")", "\n", "", "self", ".", "mean", "=", "self", ".", "add_param", "(", "mean", ",", "meanshape", ",", "'mean'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "self", ".", "inv_std", "=", "self", ".", "add_param", "(", "inv_std", ",", "meanshape", ",", "'inv_std'", ",", "\n", "trainable", "=", "False", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.get_output_for": [[58, 118], ["input.mean", "theano.inv", "theano.inv", "iter", "iter", "mean.dimshuffle.dimshuffle.dimshuffle", "inv_std.dimshuffle.dimshuffle.dimshuffle", "theano.sqrt", "theano.sqrt", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "theano.clone", "range", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.beta.dimshuffle", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer.gamma.dimshuffle", "range", "next", "range", "next", "range", "input.var", "len", "len"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "deterministic", "=", "False", ",", "\n", "batch_norm_use_averages", "=", "None", ",", "\n", "batch_norm_update_averages", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_mean", "=", "input", ".", "mean", "(", "self", ".", "mean_axes", ")", "\n", "input_inv_std", "=", "T", ".", "inv", "(", "T", ".", "sqrt", "(", "input", ".", "var", "(", "self", ".", "mean_axes", ")", "+", "self", ".", "epsilon", ")", ")", "\n", "\n", "# Decide whether to use the stored averages or mini-batch statistics", "\n", "if", "batch_norm_use_averages", "is", "None", ":", "\n", "            ", "batch_norm_use_averages", "=", "deterministic", "\n", "", "use_averages", "=", "batch_norm_use_averages", "\n", "\n", "if", "use_averages", ":", "\n", "            ", "mean", "=", "self", ".", "mean", "\n", "inv_std", "=", "self", ".", "inv_std", "\n", "", "else", ":", "\n", "            ", "mean", "=", "input_mean", "\n", "inv_std", "=", "input_inv_std", "\n", "\n", "# Decide whether to update the stored averages", "\n", "", "if", "batch_norm_update_averages", "is", "None", ":", "\n", "            ", "batch_norm_update_averages", "=", "not", "deterministic", "\n", "", "update_averages", "=", "batch_norm_update_averages", "\n", "\n", "if", "update_averages", ":", "\n", "# Trick: To update the stored statistics, we create memory-aliased", "\n", "# clones of the stored statistics:", "\n", "            ", "running_mean", "=", "theano", ".", "clone", "(", "self", ".", "mean", ",", "share_inputs", "=", "False", ")", "\n", "running_inv_std", "=", "theano", ".", "clone", "(", "self", ".", "inv_std", ",", "share_inputs", "=", "False", ")", "\n", "# set a default update for them:", "\n", "running_mean", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "running_mean", "+", "\n", "self", ".", "alpha", "*", "input_mean", ")", "\n", "running_inv_std", ".", "default_update", "=", "(", "(", "1", "-", "self", ".", "alpha", ")", "*", "\n", "running_inv_std", "+", "\n", "self", ".", "alpha", "*", "input_inv_std", ")", "\n", "# and make sure they end up in the graph without participating in", "\n", "# the computation (this way their default_update will be collected", "\n", "# and applied, but the computation will be optimized away):", "\n", "mean", "+=", "0", "*", "running_mean", "\n", "inv_std", "+=", "0", "*", "running_inv_std", "\n", "\n", "# prepare dimshuffle pattern inserting broadcastable axes as needed", "\n", "", "param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "axes", ")", ")", ")", "\n", "pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "axes", "\n", "else", "next", "(", "param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "\n", "# apply dimshuffle pattern to all parameters", "\n", "beta", "=", "0", "if", "self", ".", "beta", "is", "None", "else", "self", ".", "beta", ".", "dimshuffle", "(", "pattern", ")", "\n", "gamma", "=", "1", "if", "self", ".", "gamma", "is", "None", "else", "self", ".", "gamma", ".", "dimshuffle", "(", "pattern", ")", "\n", "\n", "mean_param_axes", "=", "iter", "(", "range", "(", "input", ".", "ndim", "-", "len", "(", "self", ".", "mean_axes", ")", ")", ")", "\n", "mean_pattern", "=", "[", "'x'", "if", "input_axis", "in", "self", ".", "mean_axes", "\n", "else", "next", "(", "mean_param_axes", ")", "\n", "for", "input_axis", "in", "range", "(", "input", ".", "ndim", ")", "]", "\n", "mean", "=", "mean", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "inv_std", "=", "inv_std", ".", "dimshuffle", "(", "mean_pattern", ")", "\n", "\n", "# normalize", "\n", "normalized", "=", "(", "input", "-", "mean", ")", "*", "(", "gamma", "*", "inv_std", ")", "+", "beta", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.penntree_charlevel_rernn.get_raw_data": [[83, 86], ["reader.ptb_raw_data"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader.ptb_raw_data"], ["def", "get_raw_data", "(", "dataset", "=", "'ptb'", ",", "data_path", "=", "'data/'", ")", ":", "\n", "  ", "raw_data", "=", "ptb_raw_data", "(", "data_path", ",", "filename", "=", "name_dataset", ")", "\n", "return", "raw_data", "\n", "", "train_data", ",", "valid_data", ",", "test_data", ",", "_", "=", "get_raw_data", "(", "'ptb'", ")", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.penntree_charlevel_rernn.build_rnn_network": [[122, 173], ["lasagne.layers.InputLayer", "lasagne.layers.EmbeddingLayer", "lasagne.layers.DimshuffleLayer", "range", "lasagne.layers.DimshuffleLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.InputLayer", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "rnnmodel", "lasagne.layers.SliceLayer", "lasagne.layers.ElemwiseSumLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "lasagne.layers.ConcatLayer", "lasagne.layers.DropoutLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "lasagne.init.Constant", "lasagne.layers.ReshapeLayer", "lasagne.layers.DenseLayer", "lasagne.layers.ReshapeLayer", "BatchNorm_step_timefirst.BatchNorm_step_timefirst_Layer", "print", "lasagne.init.Uniform", "lasagne.init.Constant"], "function", ["None"], ["", "def", "build_rnn_network", "(", "rnnmodel", ",", "X_sym", ",", "hid_init_sym", ")", ":", "\n", "    ", "net", "=", "{", "}", "\n", "\n", "net", "[", "'input0'", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "seq_len", ")", ",", "X_sym", ")", "\n", "net", "[", "'input'", "]", "=", "lasagne", ".", "layers", ".", "EmbeddingLayer", "(", "net", "[", "'input0'", "]", ",", "outputclass", ",", "units", "[", "0", "]", ")", "#,W=lasagne.init.Uniform(inial_scale)      ", "\n", "net", "[", "'rnn0'", "]", "=", "DimshuffleLayer", "(", "net", "[", "'input'", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "#change to (time, batch_size,hidden_units)    ", "\n", "\n", "for", "l", "in", "range", "(", "1", ",", "num_layers", "+", "1", ")", ":", "\n", "      ", "net", "[", "'hiddeninput%d'", "%", "l", "]", "=", "InputLayer", "(", "(", "batch_size", ",", "units", "[", "l", "-", "1", "]", ")", ",", "hid_init_sym", "[", ":", ",", "acc_units", "[", "l", "-", "1", "]", ":", "acc_units", "[", "l", "]", "]", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "units", "[", "l", "-", "1", "]", ",", "W", "=", "ini_W", ",", "b", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ",", "nonlinearity", "=", "None", ")", "#W=Uniform(ini_rernn_in_to_hid),         #", "\n", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "\n", "if", "args", ".", "use_residual", "and", "l", ">", "args", ".", "residual_layers", "and", "(", "l", "-", "1", ")", "%", "args", ".", "residual_layers", "==", "0", ":", "# and l!=num_layers", "\n", "        ", "if", "units", "[", "l", "-", "1", "]", "!=", "units", "[", "l", "-", "1", "-", "args", ".", "residual_layers", "]", ":", "\n", "          ", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'sum%d'", "%", "(", "l", "-", "args", ".", "residual_layers", ")", "]", ",", "(", "batch_size", "*", "seq_len", ",", "-", "1", ")", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "DenseLayer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "units", "[", "l", "-", "1", "]", ",", "W", "=", "ini_W", ",", "nonlinearity", "=", "None", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "ReshapeLayer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "print", "(", "'left branch'", ")", "\n", "", "else", ":", "\n", "          ", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", "=", "net", "[", "'sum%d'", "%", "(", "l", "-", "args", ".", "residual_layers", ")", "]", "\n", "", "net", "[", "'sum%d'", "%", "l", "]", "=", "ElemwiseSumLayer", "(", "(", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", ",", "net", "[", "'leftbranch%d'", "%", "(", "l", "-", "1", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "net", "[", "'sum%d'", "%", "l", "]", "=", "net", "[", "'rnn%d'", "%", "(", "l", "-", "1", ")", "]", "\n", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "net", "[", "'sum%d'", "%", "l", "]", "\n", "if", "not", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ",", "beta", "=", "lasagne", ".", "init", ".", "Constant", "(", "args", ".", "ini_b", ")", ")", "\n", "\n", "", "ini_hid_start", "=", "0", "\n", "if", "act", "==", "tanh", ":", "\n", "        ", "ini_hid_start", "=", "-", "1", "*", "U_bound", "\n", "", "net", "[", "'rnn%d'", "%", "l", "]", "=", "rnnmodel", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "units", "[", "l", "-", "1", "]", ",", "hid_init", "=", "net", "[", "'hiddeninput%d'", "%", "l", "]", ",", "W_hid_to_hid", "=", "Uniform", "(", "range", "=", "(", "ini_hid_start", ",", "U_bound", ")", ")", ",", "nonlinearity", "=", "act", ",", "only_return_final", "=", "False", ",", "grad_clipping", "=", "args", ".", "gradclipvalue", ")", "\n", "\n", "net", "[", "'last_state%d'", "%", "l", "]", "=", "SliceLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "-", "1", ",", "axis", "=", "0", ")", "\n", "if", "l", "==", "1", ":", "\n", "        ", "net", "[", "'hid_out'", "]", "=", "net", "[", "'last_state%d'", "%", "l", "]", "\n", "", "else", ":", "\n", "        ", "net", "[", "'hid_out'", "]", "=", "ConcatLayer", "(", "[", "net", "[", "'hid_out'", "]", ",", "net", "[", "'last_state%d'", "%", "l", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "use_dropout", "and", "l", "%", "droplayers", "==", "0", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "lasagne", ".", "layers", ".", "DropoutLayer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "p", "=", "droprate", ",", "shared_axes", "=", "taxdrop", ")", "\n", "\n", "", "if", "args", ".", "use_bn_afterrnn", ":", "\n", "        ", "net", "[", "'rnn%d'", "%", "l", "]", "=", "BatchNorm_step_timefirst_Layer", "(", "net", "[", "'rnn%d'", "%", "l", "]", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "", "", "net", "[", "'rnn%d'", "%", "num_layers", "]", "=", "DimshuffleLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "net", "[", "'reshape_rnn'", "]", "=", "ReshapeLayer", "(", "net", "[", "'rnn%d'", "%", "num_layers", "]", ",", "(", "-", "1", ",", "units", "[", "num_layers", "-", "1", "]", ")", ")", "\n", "net", "[", "'out'", "]", "=", "DenseLayer", "(", "net", "[", "'reshape_rnn'", "]", ",", "outputclass", ",", "nonlinearity", "=", "softmax", ")", "#lasagne.init.HeNormal(gain='relu'))#,W=Uniform(inial_scale)", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.MulLayer.__init__": [[40, 44], ["lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "lasagne.init.Normal", "super().__init__", "IndRNN_onlyrecurrent.MulLayer.add_param"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "W", "=", "lasagne", ".", "init", ".", "Normal", "(", "0.01", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MulLayer", ",", "self", ")", ".", "__init__", "(", "incoming", ",", "**", "kwargs", ")", "\n", "num_inputs", "=", "self", ".", "input_shape", "[", "1", "]", "\n", "self", ".", "W", "=", "self", ".", "add_param", "(", "W", ",", "(", "num_inputs", ",", ")", ",", "name", "=", "'W'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.MulLayer.get_output_for": [[45, 47], ["None"], "methods", ["None"], ["", "def", "get_output_for", "(", "self", ",", "input", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.MulLayer.get_output_shape_for": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "#(input_shape[0], self.num_units)", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__": [[58, 134], ["lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.MergeLayer.__init__", "isinstance", "incomings.append", "incomings.append", "len", "ValueError", "len", "ValueError", "ValueError", "IndRNN_onlyrecurrent.onlyRecurrentLayer.add_param", "len", "len", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "lasagne.layers.helper.get_all_layers", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["def", "__init__", "(", "self", ",", "incoming", ",", "input_to_hidden", ",", "hidden_to_hidden", ",", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# This layer inherits from a MergeLayer, because it can have three", "\n", "# inputs - the layer input, the mask and the initial hidden state.  We", "\n", "# will just provide the layer input as incomings, unless a mask input", "\n", "# or initial hidden state was provided.", "\n", "        ", "incomings", "=", "[", "incoming", "]", "\n", "self", ".", "mask_incoming_index", "=", "-", "1", "\n", "self", ".", "hid_init_incoming_index", "=", "-", "1", "\n", "if", "mask_input", "is", "not", "None", ":", "\n", "            ", "incomings", ".", "append", "(", "mask_input", ")", "\n", "self", ".", "mask_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "incomings", ".", "append", "(", "hid_init", ")", "\n", "self", ".", "hid_init_incoming_index", "=", "len", "(", "incomings", ")", "-", "1", "\n", "\n", "", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "__init__", "(", "incomings", ",", "**", "kwargs", ")", "\n", "\n", "input_to_hidden_in_layers", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "input_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "input_to_hidden_in_layers", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`input_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "input_to_hidden_in_layers", ")", ")", ")", "\n", "\n", "", "hidden_to_hidden_in_lyrs", "=", "[", "layer", "for", "layer", "in", "helper", ".", "get_all_layers", "(", "hidden_to_hidden", ")", "\n", "if", "isinstance", "(", "layer", ",", "InputLayer", ")", "]", "\n", "if", "len", "(", "hidden_to_hidden_in_lyrs", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'`hidden_to_hidden` must have exactly one InputLayer, but it '", "\n", "'has {}'", ".", "format", "(", "len", "(", "hidden_to_hidden_in_lyrs", ")", ")", ")", "\n", "", "hidden_to_hidden_in_layer", "=", "hidden_to_hidden_in_lyrs", "[", "0", "]", "\n", "\n", "self", ".", "input_to_hidden", "=", "input_to_hidden", "\n", "self", ".", "hidden_to_hidden", "=", "hidden_to_hidden", "\n", "self", ".", "learn_init", "=", "learn_init", "\n", "self", ".", "backwards", "=", "backwards", "\n", "self", ".", "gradient_steps", "=", "gradient_steps", "\n", "self", ".", "grad_clipping", "=", "grad_clipping", "\n", "self", ".", "unroll_scan", "=", "unroll_scan", "\n", "self", ".", "precompute_input", "=", "precompute_input", "\n", "self", ".", "only_return_final", "=", "only_return_final", "\n", "\n", "\n", "if", "unroll_scan", "and", "gradient_steps", "!=", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Gradient steps must be -1 when unroll_scan is true.\"", ")", "\n", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "\n", "if", "nonlinearity", "is", "None", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearities", ".", "identity", "\n", "", "else", ":", "\n", "            ", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "\n", "# Initialize hidden state", "\n", "", "if", "isinstance", "(", "hid_init", ",", "Layer", ")", ":", "\n", "            ", "self", ".", "hid_init", "=", "hid_init", "\n", "", "else", ":", "\n", "            ", "self", ".", "hid_init", "=", "self", ".", "add_param", "(", "\n", "hid_init", ",", "(", "1", ",", ")", "+", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ",", "\n", "name", "=", "\"hid_init\"", ",", "trainable", "=", "learn_init", ",", "regularizable", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params": [[135, 142], ["super().get_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_params"], ["", "", "def", "get_params", "(", "self", ",", "**", "tags", ")", ":", "\n", "# Get all parameters from this layer, the master layer", "\n", "        ", "params", "=", "super", "(", "onlyRecurrentLayer", ",", "self", ")", ".", "get_params", "(", "**", "tags", ")", "\n", "# Combine with all parameters from the child layers", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "input_to_hidden", ",", "**", "tags", ")", "\n", "params", "+=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ",", "**", "tags", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_shape_for": [[143, 155], ["None"], "methods", ["None"], ["", "def", "get_output_shape_for", "(", "self", ",", "input_shapes", ")", ":", "\n", "# The shape of the input to this layer will be the first element", "\n", "# of input_shapes, whether or not a mask input is being used.", "\n", "        ", "input_shape", "=", "input_shapes", "[", "0", "]", "\n", "# When only_return_final is true, the second (sequence step) dimension", "\n", "# will be flattened", "\n", "if", "self", ".", "only_return_final", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", "\n", "# Otherwise, the shape will be (n_batch, n_steps, trailing_dims...)", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "\n", "self", ".", "hidden_to_hidden", ".", "output_shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for": [[156, 251], ["lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_all_params", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "lasagne.layers.helper.get_output", "IndRNN_onlyrecurrent.onlyRecurrentLayer.nonlinearity", "IndRNN_onlyrecurrent.onlyRecurrentLayer.get_output_for.step"], "methods", ["None"], ["", "", "def", "get_output_for", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "# Retrieve the layer input", "\n", "        ", "input", "=", "inputs", "[", "0", "]", "\n", "# Retrieve the mask when it is supplied", "\n", "mask", "=", "None", "\n", "hid_init", "=", "None", "\n", "if", "self", ".", "mask_incoming_index", ">", "0", ":", "\n", "            ", "mask", "=", "inputs", "[", "self", ".", "mask_incoming_index", "]", "\n", "", "if", "self", ".", "hid_init_incoming_index", ">", "0", ":", "\n", "            ", "hid_init", "=", "inputs", "[", "self", ".", "hid_init_incoming_index", "]", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, n_features)", "\n", "# but scan requires the iterable dimension to be first", "\n", "# So, we need to dimshuffle to (n_time_steps, n_batch, n_features)", "\n", "#input = input.dimshuffle(1, 0, *range(2, input.ndim))", "\n", "", "seq_len", ",", "num_batch", "=", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", "\n", "\n", "# We will always pass the hidden-to-hidden layer params to step", "\n", "non_seqs", "=", "helper", ".", "get_all_params", "(", "self", ".", "hidden_to_hidden", ")", "\n", "\n", "# Create single recurrent computation step function", "\n", "def", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Compute the hidden-to-hidden activation", "\n", "            ", "hid_pre", "=", "helper", ".", "get_output", "(", "\n", "self", ".", "hidden_to_hidden", ",", "hid_previous", ",", "**", "kwargs", ")", "\n", "\n", "hid_pre", "+=", "input_n", "\n", "\n", "# Clip gradients", "\n", "if", "self", ".", "grad_clipping", ":", "\n", "                ", "hid_pre", "=", "theano", ".", "gradient", ".", "grad_clip", "(", "\n", "hid_pre", ",", "-", "self", ".", "grad_clipping", ",", "self", ".", "grad_clipping", ")", "\n", "\n", "", "return", "self", ".", "nonlinearity", "(", "hid_pre", ")", "\n", "\n", "", "def", "step_masked", "(", "input_n", ",", "mask_n", ",", "hid_previous", ",", "*", "args", ")", ":", "\n", "# Skip over any input with mask 0 by copying the previous", "\n", "# hidden state; proceed normally for any input with mask 1.", "\n", "            ", "hid", "=", "step", "(", "input_n", ",", "hid_previous", ",", "*", "args", ")", "\n", "hid_out", "=", "T", ".", "switch", "(", "mask_n", ",", "hid", ",", "hid_previous", ")", "\n", "return", "[", "hid_out", "]", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "dimshuffle", "(", "1", ",", "0", ",", "'x'", ")", "\n", "sequences", "=", "[", "input", ",", "mask", "]", "\n", "step_fun", "=", "step_masked", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "input", "\n", "step_fun", "=", "step", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "hid_init", ",", "Layer", ")", ":", "\n", "# The code below simply repeats self.hid_init num_batch times in", "\n", "# its first dimension.  Turns out using a dot product and a", "\n", "# dimshuffle is faster than T.repeat.", "\n", "            ", "dot_dims", "=", "(", "list", "(", "range", "(", "1", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", ")", ")", "+", "\n", "[", "0", ",", "self", ".", "hid_init", ".", "ndim", "-", "1", "]", ")", "\n", "hid_init", "=", "T", ".", "dot", "(", "T", ".", "ones", "(", "(", "num_batch", ",", "1", ")", ")", ",", "\n", "self", ".", "hid_init", ".", "dimshuffle", "(", "dot_dims", ")", ")", "\n", "\n", "", "if", "self", ".", "unroll_scan", ":", "\n", "# Retrieve the dimensionality of the incoming layer", "\n", "            ", "input_shape", "=", "self", ".", "input_shapes", "[", "0", "]", "\n", "# Explicitly unroll the recurrence instead of using scan", "\n", "hid_out", "=", "unroll_scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "n_steps", "=", "input_shape", "[", "1", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# Scan op iterates over first dimension of input and repeatedly", "\n", "# applies the step function", "\n", "            ", "hid_out", "=", "theano", ".", "scan", "(", "\n", "fn", "=", "step_fun", ",", "\n", "sequences", "=", "sequences", ",", "\n", "go_backwards", "=", "self", ".", "backwards", ",", "\n", "outputs_info", "=", "[", "hid_init", "]", ",", "\n", "non_sequences", "=", "non_seqs", ",", "\n", "truncate_gradient", "=", "self", ".", "gradient_steps", ",", "\n", "strict", "=", "True", ")", "[", "0", "]", "\n", "\n", "# When it is requested that we only return the final sequence step,", "\n", "# we need to slice it out immediately after scan is applied", "\n", "", "if", "self", ".", "only_return_final", ":", "\n", "            ", "hid_out", "=", "hid_out", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "# dimshuffle back to (n_batch, n_time_steps, n_features))", "\n", "#hid_out = hid_out.dimshuffle(1, 0, *range(2, hid_out.ndim))", "\n", "\n", "# if scan is backward reverse the output", "\n", "            ", "if", "self", ".", "backwards", ":", "\n", "                ", "hid_out", "=", "hid_out", "[", ":", ":", "-", "1", ",", ":", "]", "\n", "\n", "", "", "return", "hid_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__": [[255, 320], ["lasagne.Uniform", "lasagne.Uniform", "lasagne.Uniform", "lasagne.Constant", "lasagne.Constant", "lasagne.Constant", "isinstance", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "IndRNN_onlyrecurrent.MulLayer", "IndRNN_onlyrecurrent.onlyRecurrentLayer.__init__", "dict", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "lasagne.layers.InputLayer", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.IndRNN_onlyrecurrent.IndRNNLayer_onlyrecurrent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "incoming", ",", "num_units", ",", "\n", "#W_in_to_hid=init.Uniform(),", "\n", "W_hid_to_hid", "=", "init", ".", "Uniform", "(", ")", ",", "\n", "#b=init.Constant(0.),", "\n", "nonlinearity", "=", "nonlinearities", ".", "rectify", ",", "\n", "hid_init", "=", "init", ".", "Constant", "(", "0.", ")", ",", "\n", "backwards", "=", "False", ",", "\n", "learn_init", "=", "False", ",", "\n", "gradient_steps", "=", "-", "1", ",", "\n", "grad_clipping", "=", "0", ",", "\n", "unroll_scan", "=", "False", ",", "\n", "precompute_input", "=", "True", ",", "\n", "mask_input", "=", "None", ",", "\n", "only_return_final", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "incoming", ",", "tuple", ")", ":", "\n", "            ", "input_shape", "=", "incoming", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "incoming", ".", "output_shape", "\n", "# Retrieve the supplied name, if it exists; otherwise use ''", "\n", "", "if", "'name'", "in", "kwargs", ":", "\n", "            ", "basename", "=", "kwargs", "[", "'name'", "]", "+", "'.'", "\n", "# Create a separate version of kwargs for the contained layers", "\n", "# which does not include 'name'", "\n", "layer_kwargs", "=", "dict", "(", "(", "key", ",", "arg", ")", "for", "key", ",", "arg", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "key", "!=", "'name'", ")", "\n", "", "else", ":", "\n", "            ", "basename", "=", "''", "\n", "layer_kwargs", "=", "kwargs", "\n", "# We will be passing the input at each time step to the dense layer,", "\n", "# so we need to remove the second dimension (the time dimension)", "\n", "", "in_to_hid", "=", "InputLayer", "(", "input_shape", ")", "\n", "\n", "#         in_to_hid = DenseLayer(InputLayer((None,) + input_shape[2:]),", "\n", "#                                num_units, W=W_in_to_hid, b=b,", "\n", "#                                nonlinearity=None,", "\n", "#                                name=basename + 'input_to_hidden',", "\n", "#                                **layer_kwargs)        ", "\n", "# The hidden-to-hidden layer expects its inputs to have num_units", "\n", "# features because it recycles the previous hidden state", "\n", "\n", "hid_to_hid", "=", "MulLayer", "(", "InputLayer", "(", "(", "None", ",", "num_units", ")", ")", ",", "\n", "W", "=", "W_hid_to_hid", ",", "\n", "name", "=", "basename", "+", "'hidden_to_hidden'", ",", "\n", "**", "layer_kwargs", ")", "\n", "#         hid_to_hid = DenseLayer(InputLayer((None, num_units)),", "\n", "#                                 num_units, W=W_hid_to_hid, b=None,", "\n", "#                                 nonlinearity=None,", "\n", "#                                 name=basename + 'hidden_to_hidden',", "\n", "#                                 **layer_kwargs)", "\n", "\n", "# Make child layer parameters intuitively accessible", "\n", "#self.W_in_to_hid = in_to_hid.W", "\n", "self", ".", "W_hid_to_hid", "=", "hid_to_hid", ".", "W", "\n", "#self.b = in_to_hid.b", "\n", "\n", "# Just use the CustomRecurrentLayer with the DenseLayers we created", "\n", "super", "(", "IndRNNLayer_onlyrecurrent", ",", "self", ")", ".", "__init__", "(", "\n", "incoming", ",", "in_to_hid", ",", "hid_to_hid", ",", "nonlinearity", "=", "nonlinearity", ",", "\n", "hid_init", "=", "hid_init", ",", "backwards", "=", "backwards", ",", "learn_init", "=", "learn_init", ",", "\n", "gradient_steps", "=", "gradient_steps", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "unroll_scan", "=", "unroll_scan", ",", "\n", "precompute_input", "=", "precompute_input", ",", "mask_input", "=", "mask_input", ",", "\n", "only_return_final", "=", "only_return_final", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_symbols": [[33, 36], ["open", "f.read"], "function", ["None"], ["def", "_read_symbols", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "return", "f", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_words": [[38, 41], ["open", "f.read().decode().replace().split", "f.read().decode().replace", "f.read().decode", "f.read"], "function", ["None"], ["", "", "def", "_read_words", "(", "filename", ")", ":", "\n", "  ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "return", "f", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"<eos>\"", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._build_vocab": [[43, 53], ["reader._read_words", "collections.Counter", "sorted", "list", "dict", "collections.Counter.items", "zip", "zip", "range", "len"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_words"], ["", "", "def", "_build_vocab", "(", "filename", ")", ":", "\n", "  ", "data", "=", "_read_words", "(", "filename", ")", "\n", "\n", "counter", "=", "collections", ".", "Counter", "(", "data", ")", "\n", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "\n", "words", ",", "_", "=", "list", "(", "zip", "(", "*", "count_pairs", ")", ")", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "words", ",", "range", "(", "len", "(", "words", ")", ")", ")", ")", "\n", "\n", "return", "word_to_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids": [[55, 58], ["reader._read_words"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_words"], ["", "def", "_file_to_word_ids", "(", "filename", ",", "word_to_id", ")", ":", "\n", "  ", "data", "=", "_read_words", "(", "filename", ")", "\n", "return", "[", "word_to_id", "[", "word", "]", "for", "word", "in", "data", "if", "word", "in", "word_to_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader.hutter_raw_data": [[60, 85], ["os.path.join", "reader._read_symbols", "numpy.fromstring", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._read_symbols"], ["", "def", "hutter_raw_data", "(", "data_path", "=", "None", ",", "num_test_symbols", "=", "5000000", ")", ":", "\n", "  ", "\"\"\"Load raw data from data directory \"data_path\".\n\n  The raw Hutter prize data is at:\n  http://mattmahoney.net/dc/enwik8.zip\n\n  Args:\n    data_path: string path to the directory where simple-examples.tgz has\n      been extracted.\n    num_test_symbols: number of symbols at the end that make up the test set\n\n  Returns:\n    tuple (train_data, valid_data, test_data, unique)\n    where each of the data objects can be passed to hutter_iterator.\n  \"\"\"", "\n", "\n", "data_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "\"enwik8\"", ")", "\n", "\n", "raw_data", "=", "_read_symbols", "(", "data_path", ")", "\n", "raw_data", "=", "np", ".", "fromstring", "(", "raw_data", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "unique", ",", "data", "=", "np", ".", "unique", "(", "raw_data", ",", "return_inverse", "=", "True", ")", "\n", "train_data", "=", "data", "[", ":", "-", "2", "*", "num_test_symbols", "]", "\n", "valid_data", "=", "data", "[", "-", "2", "*", "num_test_symbols", ":", "-", "num_test_symbols", "]", "\n", "test_data", "=", "data", "[", "-", "num_test_symbols", ":", "]", "\n", "return", "train_data", ",", "valid_data", ",", "test_data", ",", "unique", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader.ptb_raw_data": [[87, 120], ["os.path.join", "os.path.join", "os.path.join", "reader._build_vocab", "reader._file_to_word_ids", "reader._file_to_word_ids", "reader._file_to_word_ids", "len", "print"], "function", ["home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._build_vocab", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids", "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader._file_to_word_ids"], ["", "def", "ptb_raw_data", "(", "data_path", "=", "None", ",", "filename", "=", "'ptb.'", ")", ":", "\n", "  ", "\"\"\"Load PTB raw data from data directory \"data_path\".\n\n  Reads PTB text files, converts strings to integer ids,\n  and performs mini-batching of the inputs.\n\n  The PTB dataset comes from Tomas Mikolov's webpage:\n\n  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n\n  Args:\n    data_path: string path to the directory where simple-examples.tgz has\n      been extracted.\n\n  Returns:\n    tuple (train_data, valid_data, test_data, vocabulary)\n    where each of the data objects can be passed to PTBIterator.\n  \"\"\"", "\n", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'train.txt'", ")", "\n", "valid_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'valid.txt'", ")", "\n", "test_path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "filename", "+", "'test.txt'", ")", "\n", "#print (train_path)", "\n", "\n", "word_to_id", "=", "_build_vocab", "(", "train_path", ")", "\n", "train_data", "=", "_file_to_word_ids", "(", "train_path", ",", "word_to_id", ")", "\n", "valid_data", "=", "_file_to_word_ids", "(", "valid_path", ",", "word_to_id", ")", "\n", "test_data", "=", "_file_to_word_ids", "(", "test_path", ",", "word_to_id", ")", "\n", "vocabulary", "=", "len", "(", "word_to_id", ")", "\n", "#   save_name='ptb_char'", "\n", "print", "(", "'voc'", ",", "vocabulary", ")", "\n", "#   np.savez(save_name, train_data, valid_data, test_data, vocabulary)", "\n", "return", "train_data", ",", "valid_data", ",", "test_data", ",", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.Sunnydreamrain_IndRNN_Theano_Lasagne.cPTB.reader.data_iterator": [[122, 158], ["numpy.array", "len", "numpy.zeros", "range", "range", "ValueError"], "function", ["None"], ["", "def", "data_iterator", "(", "raw_data", ",", "batch_size", ",", "num_steps", ")", ":", "\n", "  ", "\"\"\"Iterate on the raw Hutter prize data or the raw PTB data.\n\n  This generates batch_size pointers into the given raw data, and allows\n  minibatch iteration along these pointers.\n\n  Args:\n    raw_data: one of the raw data outputs from hutter_raw_data or ptb_raw_data.\n    batch_size: int, the batch size.\n    num_steps: int, the number of unrolls.\n\n  Yields:\n    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n    The second element of the tuple is the same data time-shifted to the\n    right by one.\n\n  Raises:\n    ValueError: if batch_size or num_steps are too high.\n  \"\"\"", "\n", "raw_data", "=", "np", ".", "array", "(", "raw_data", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "data_len", "=", "len", "(", "raw_data", ")", "\n", "batch_len", "=", "data_len", "//", "batch_size", "\n", "data", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "batch_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "data", "[", "i", "]", "=", "raw_data", "[", "batch_len", "*", "i", ":", "batch_len", "*", "(", "i", "+", "1", ")", "]", "\n", "\n", "", "epoch_size", "=", "(", "batch_len", "-", "1", ")", "//", "num_steps", "\n", "\n", "if", "epoch_size", "==", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"epoch_size == 0, decrease batch_size or num_steps\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "epoch_size", ")", ":", "\n", "    ", "x", "=", "data", "[", ":", ",", "i", "*", "num_steps", ":", "(", "i", "+", "1", ")", "*", "num_steps", "]", "\n", "y", "=", "data", "[", ":", ",", "i", "*", "num_steps", "+", "1", ":", "(", "i", "+", "1", ")", "*", "num_steps", "+", "1", "]", "\n", "yield", "(", "x", ",", "y", ")", "\n", "\n"]]}