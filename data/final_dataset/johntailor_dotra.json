{"home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.__init__": [[53, 60], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "g12", ",", "self", ".", "g21", "=", "None", ",", "None", "\n", "self", ".", "d1", ",", "self", ".", "d2", "=", "None", ",", "None", "\n", "self", ".", "g_optimizer", ",", "self", ".", "d_optimizer", "=", "None", ",", "None", "\n", "self", ".", "num_classes", "=", "cfg", "[", "\"ds\"", "]", "[", "1", "]", "\n", "self", ".", "batch_size", "=", "cfg", "[", "\"batchSize\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.build_model": [[63, 75], ["latAEModels.G().cuda", "latAEModels.G().cuda", "latAEModels.D().cuda", "list", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "latAEModels.D().cuda", "latAEModels.D().cuda", "list", "list", "optCycEncoded.Solver.d2.parameters", "list", "list", "latAEModels.G", "latAEModels.G", "latAEModels.D", "optCycEncoded.Solver.g12.parameters", "optCycEncoded.Solver.g21.parameters", "optCycEncoded.Solver.d1.parameters", "optCycEncoded.Solver.d1cl.parameters", "latAEModels.D", "latAEModels.D"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "# \"\"\"Builds a generator and a discriminator.\"\"\"", "\n", "        ", "self", ".", "g12", "=", "G", "(", "self", ".", "cfg", ")", ".", "cuda", "(", ")", "\n", "self", ".", "g21", "=", "G", "(", "self", ".", "cfg", ")", ".", "cuda", "(", ")", "\n", "if", "self", ".", "cfg", "[", "\"d1\"", "]", ":", "self", ".", "d1", "=", "D", "(", "self", ".", "cfg", ",", "use_labels", "=", "self", ".", "cfg", "[", "\"useLab\"", "]", "in", "[", "1", ",", "2", "]", ")", ".", "cuda", "(", ")", "\n", "self", ".", "d2", "=", "D", "(", "self", ".", "cfg", ",", "use_labels", "=", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ")", ".", "cuda", "(", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "3", ":", "self", ".", "d1cl", "=", "D", "(", "self", ".", "cfg", ",", "use_labels", "=", "1", ")", ".", "cuda", "(", ")", "\n", "g_params", "=", "list", "(", "self", ".", "g12", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "g21", ".", "parameters", "(", ")", ")", "\n", "d_params", "=", "list", "(", "self", ".", "d2", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "cfg", "[", "\"d1\"", "]", ":", "d_params", "+=", "list", "(", "self", ".", "d1", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "3", ":", "d_params", "+=", "list", "(", "self", ".", "d1cl", ".", "parameters", "(", ")", ")", "\n", "self", ".", "d_optimizer", "=", "optim", ".", "Adam", "(", "d_params", ",", "self", ".", "cfg", "[", "\"DGlr\"", "]", "[", "0", "]", ",", "self", ".", "cfg", "[", "\"DGBeta12\"", "]", "[", "0", "]", ")", "\n", "self", ".", "g_optimizer", "=", "optim", ".", "Adam", "(", "g_params", ",", "self", ".", "cfg", "[", "\"DGlr\"", "]", "[", "1", "]", ",", "self", ".", "cfg", "[", "\"DGBeta12\"", "]", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.to_var": [[77, 78], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.cuda"], "methods", ["None"], ["", "def", "to_var", "(", "self", ",", "x", ")", ":", "return", "Variable", "(", "x", ".", "cuda", "(", ")", ")", "# \"\"\"Converts numpy to variable.\"\"\"", "\n", "#def to_data(self, x): return x.cpu().data.numpy() #\"\"\"Converts variable to numpy.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.reset_grad": [[79, 82], ["optCycEncoded.Solver.g_optimizer.zero_grad", "optCycEncoded.Solver.d_optimizer.zero_grad"], "methods", ["None"], ["def", "reset_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "g_optimizer", ".", "zero_grad", "(", "set_to_none", "=", "True", ")", "\n", "self", ".", "d_optimizer", ".", "zero_grad", "(", "set_to_none", "=", "True", ")", "\n", "#if self.cfg[\"useLab\"] == 3: self.d3_optimizer.zero_grad()", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.decay": [[84, 89], ["None"], "methods", ["None"], ["", "def", "decay", "(", "self", ",", "epoch", ",", "total", ")", ":", "\n", "        ", "if", "epoch", ">", "total", "*", "self", ".", "cfg", "[", "\"lrdecay\"", "]", ":", "\n", "            ", "for", "opt", "in", "[", "self", ".", "g_optimizer", ",", "self", ".", "d_optimizer", "]", ":", "\n", "                ", "for", "g", "in", "opt", ".", "param_groups", ":", "\n", "                    ", "g", "[", "'lr'", "]", "=", "0.85", "*", "g", "[", "'lr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train": [[91, 285], ["print", "optCycEncoded.Solver.build_model", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "iter", "iter", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "torch.GradScaler", "scaler.scale().backward", "scaler.step", "scaler.update", "d_adaDom_loss.item", "d_fake_loss.item", "LinCl().cuda", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "getLinCl", "recF", "recF", "torch.autocast", "torch.autocast", "torch.autocast", "optCycEncoded.Solver.reset_grad", "optCycEncoded.Solver.d2", "optCycEncoded.Solver.train.wrap"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.build_model", "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getLinCl", "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.reset_grad"], ["", "", "", "", "def", "train", "(", "self", ",", "netAEorg", ",", "netAEdom", ",", "aetr_iter", ",", "aete_iter", ",", "aemodtr_iter", ",", "modteX", ",", "modteY", ",", "cget", ",", "nd", ")", ":", "#drift_iter = iter(self.adaDom_loader)        #orgDom_iter = iter(self.orgDom_loader)", "\n", "        ", "othlo", ",", "milo", ",", "bacc", "=", "-", "1", ",", "1e99", ",", "0", "\n", "reclo", ",", "reclo2", "=", "torch", ".", "zeros", "(", "1", ")", ",", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "print", "(", "\"Train Cyc GAN\"", ")", "\n", "if", "self", ".", "cfg", "[", "\"useClLo\"", "]", ":", "\n", "            ", "from", "trainClassifiers", "import", "getLinCl", "\n", "clloss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "self", ".", "cfg", "[", "\"trainCl\"", "]", ":", "\n", "                ", "ccf", "=", "self", ".", "cfg", "[", "\"clcfg\"", "]", "\n", "from", "latAEModels", "import", "LinCl", "\n", "\n", "clDom", "=", "LinCl", "(", "self", ".", "cfg", ")", ".", "cuda", "(", ")", "\n", "loOrg", ",", "loDom", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "clr", "=", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "/", "100", "\n", "if", "self", ".", "cfg", "[", "\"trainCl\"", "]", "!=", "3", ":", "\n", "                    ", "clOrg", "=", "LinCl", "(", "self", ".", "cfg", ")", ".", "cuda", "(", ")", "\n", "optOrg", "=", "optim", ".", "SGD", "(", "clOrg", ".", "parameters", "(", ")", ",", "lr", "=", "clr", ",", "momentum", "=", "0.8", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", "/", "5", ")", "#clr / warmup[", "\n", "", "else", ":", "\n", "                    ", "linCl", ",", "lincfg", "=", "getLinCl", "(", "self", ".", "cfg", ",", "aetr_iter", ",", "aete_iter", ",", "\"None\"", ",", "cget", ",", "save", "=", "True", ",", "loadCl", "=", "True", ")", "\n", "", "optDom", "=", "optim", ".", "SGD", "(", "clDom", ".", "parameters", "(", ")", ",", "lr", "=", "clr", ",", "momentum", "=", "0.8", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", "/", "5", ")", "\n", "", "else", ":", "\n", "                 ", "linCl", ",", "lincfg", "=", "getLinCl", "(", "self", ".", "cfg", ",", "aetr_iter", ",", "aete_iter", ",", "\"None\"", ",", "cget", ",", "save", "=", "True", ",", "loadCl", "=", "True", ")", "\n", "", "", "self", ".", "build_model", "(", ")", "\n", "useLabLoss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "# loss if use_labels = True", "\n", "ax", ",", "ay", "=", "[", "]", ",", "[", "]", "\n", "tries", "=", "0", "\n", "niterEp", "=", "nd", "//", "self", ".", "cfg", "[", "\"batchSize\"", "]", "\n", "train_iters", "=", "self", ".", "cfg", "[", "\"epG\"", "]", "*", "niterEp", "+", "self", ".", "cfg", "[", "\"ntries\"", "]", "[", "0", "]", "*", "self", ".", "cfg", "[", "\"ntries\"", "]", "[", "1", "]", "# config.train_iters", "\n", "labSmo", "=", "lambda", "sh", ":", "2", "*", "(", "torch", ".", "rand", "(", "sh", ".", "shape", "[", "0", "]", ")", ".", "cuda", "(", ")", "-", "0.5", ")", "*", "self", ".", "cfg", "[", "\"labSmo\"", "]", "if", "self", ".", "cfg", "[", "\"labSmo\"", "]", ">", "0", "else", "0", "\n", "recF", "=", "torch", ".", "square", "if", "self", ".", "cfg", "[", "\"recLo\"", "]", "%", "10", "==", "2", "else", "torch", ".", "abs", "\n", "recLoFct", "=", "lambda", "x", ":", "recF", "(", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x", ")", ",", "dim", "=", "1", ")", ")", "if", "self", ".", "cfg", "[", "\"recLo\"", "]", ">=", "10", "else", "recF", "(", "x", ")", "\n", "miter", ",", "siter", "=", "iter", "(", "aetr_iter", ")", ",", "iter", "(", "aemodtr_iter", ")", "\n", "sca0", ",", "sca1", ",", "sca2", ",", "sca3", "=", "tca", ".", "GradScaler", "(", ")", ",", "tca", ".", "GradScaler", "(", ")", ",", "tca", ".", "GradScaler", "(", ")", ",", "tca", ".", "GradScaler", "(", ")", "\n", "def", "wrap", "(", "scaler", ",", "opt", ",", "lo", ")", ":", "\n", "            ", "scaler", ".", "scale", "(", "lo", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "opt", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "for", "step", "in", "range", "(", "train_iters", "+", "1", ")", ":", "# # reset data_iter for each epoch", "\n", "           ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "adaDom", ",", "s_labels", "=", "next", "(", "siter", ")", "## load adaDom and orgDom dataset", "\n", "orgDom", ",", "m_labels", "=", "next", "(", "miter", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "miter", ",", "siter", "=", "iter", "(", "aetr_iter", ")", ",", "iter", "(", "aemodtr_iter", ")", "\n", "adaDom", ",", "s_labels", "=", "next", "(", "siter", ")", "\n", "orgDom", ",", "m_labels", "=", "next", "(", "miter", ")", "\n", "self", ".", "decay", "(", "step", "//", "niterEp", ",", "self", ".", "cfg", "[", "\"epG\"", "]", ")", "\n", "\n", "", "orgDom", ",", "adaDom", "=", "orgDom", ".", "float", "(", ")", ",", "adaDom", ".", "float", "(", ")", "\n", "if", "step", "==", "0", ":", "code_org", ",", "code_dom", "=", "orgDom", ".", "clone", "(", ")", ".", "cuda", "(", ")", ",", "adaDom", ".", "clone", "(", ")", ".", "cuda", "(", ")", "#save for outputting images", "\n", "adaDom", ",", "s_labels", "=", "self", ".", "to_var", "(", "adaDom", ")", ",", "self", ".", "to_var", "(", "s_labels", ")", ".", "long", "(", ")", ".", "squeeze", "(", ")", "\n", "orgDom", ",", "m_labels", "=", "self", ".", "to_var", "(", "orgDom", ")", ",", "self", ".", "to_var", "(", "m_labels", ".", "long", "(", ")", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", ":", "orgDom_fake_labels", "=", "self", ".", "to_var", "(", "torch", ".", "Tensor", "(", "[", "self", ".", "num_classes", "]", "*", "adaDom", ".", "size", "(", "0", ")", ")", ".", "long", "(", ")", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "adaDom_fake_labels", "=", "self", ".", "to_var", "(", "torch", ".", "Tensor", "(", "[", "self", ".", "num_classes", "]", "*", "orgDom", ".", "size", "(", "0", ")", ")", ".", "long", "(", ")", ")", "\n", "\n", "# ============ train D ============#", "\n", "# train with real images", "\n", "self", ".", "reset_grad", "(", ")", "\n", "d1_loss", "=", "0", "\n", "if", "self", ".", "cfg", "[", "\"d1\"", "]", ":", "\n", "                ", "out", "=", "self", ".", "d1", "(", "orgDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "1", "or", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "d1_loss", "=", "useLabLoss", "(", "out", ",", "m_labels", ")", "\n", "else", ":", "d1_loss", "=", "torch", ".", "mean", "(", "(", "out", "-", "1", "+", "labSmo", "(", "out", ")", ")", "**", "2", ")", "\n", "", "out", "=", "self", ".", "d2", "(", "adaDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "d2_loss", "=", "useLabLoss", "(", "out", ",", "s_labels", ")", "\n", "else", ":", "d2_loss", "=", "torch", ".", "mean", "(", "(", "out", "-", "1", "+", "labSmo", "(", "out", ")", ")", "**", "2", ")", "\n", "d_orgDom_loss", ",", "d_adaDom_loss", ",", "d_real_loss", "=", "d1_loss", ",", "d2_loss", ",", "d1_loss", "+", "d2_loss", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "3", ":", "\n", "                ", "out", "=", "self", ".", "d1cl", "(", "orgDom", ")", "\n", "d_real_loss", "+=", "useLabLoss", "(", "out", ",", "m_labels", ")", "\n", "", "wrap", "(", "sca0", ",", "self", ".", "d_optimizer", ",", "d_real_loss", ")", "\n", "\n", "\n", "# train with fake images", "\n", "self", ".", "reset_grad", "(", ")", "\n", "fake_adaDom", "=", "self", ".", "g12", "(", "orgDom", ")", "\n", "out", "=", "self", ".", "d2", "(", "fake_adaDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "d2_loss", "=", "useLabLoss", "(", "out", ",", "adaDom_fake_labels", ")", "\n", "else", ":", "d2_loss", "=", "torch", ".", "mean", "(", "(", "out", "+", "labSmo", "(", "out", ")", ")", "**", "2", ")", "\n", "fake_orgDom", "=", "self", ".", "g21", "(", "adaDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"d1\"", "]", ":", "\n", "                ", "out", "=", "self", ".", "d1", "(", "fake_orgDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "1", "or", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "d1_loss", "=", "useLabLoss", "(", "out", ",", "orgDom_fake_labels", ")", "\n", "else", ":", "d1_loss", "=", "torch", ".", "mean", "(", "(", "out", "+", "labSmo", "(", "out", ")", ")", "**", "2", ")", "\n", "", "else", ":", "d1_loss", "=", "0", "\n", "d_fake_loss", "=", "d1_loss", "+", "d2_loss", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "3", ":", "\n", "                ", "out", "=", "self", ".", "d1cl", "(", "fake_orgDom", ")", "\n", "d_fake_loss", "+=", "useLabLoss", "(", "out", ",", "orgDom_fake_labels", ")", "\n", "# d_fake_loss.backward()", "\n", "# self.d_optimizer.step()", "\n", "", "wrap", "(", "sca1", ",", "self", ".", "d_optimizer", ",", "d_fake_loss", ")", "\n", "\n", "# ============ train G ============#", "\n", "# train orgDom-adaDom-orgDom cycle", "\n", "self", ".", "reset_grad", "(", ")", "\n", "fake_adaDom", "=", "self", ".", "g12", "(", "orgDom", ")", "\n", "out", "=", "self", ".", "d2", "(", "fake_adaDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "g_loss", "=", "useLabLoss", "(", "out", ",", "m_labels", ")", "\n", "else", ":", "g_loss", "=", "torch", ".", "mean", "(", "(", "out", "-", "1", ")", "**", "2", ")", "\n", "if", "self", ".", "cfg", "[", "\"useRec\"", "]", ">", "0", ":", "\n", "                ", "reconst_orgDom", "=", "self", ".", "g21", "(", "fake_adaDom", ")", "\n", "reclo", "=", "self", ".", "cfg", "[", "\"cycFac\"", "]", "[", "0", "]", "*", "self", ".", "cfg", "[", "\"useRec\"", "]", "*", "torch", ".", "mean", "(", "recLoFct", "(", "orgDom", "-", "reconst_orgDom", ")", ")", "\n", "g_loss", "+=", "reclo", "\n", "", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "3", ":", "\n", "                ", "out", "=", "self", ".", "d1cl", "(", "reconst_orgDom", ")", "\n", "g_loss", "+=", "useLabLoss", "(", "out", ",", "m_labels", ")", "\n", "", "if", "self", ".", "cfg", "[", "\"useClLo\"", "]", ":", "\n", "                ", "if", "self", ".", "cfg", "[", "\"trainCl\"", "]", ":", "\n", "                    ", "actOrg", "=", "clOrg", "(", "reconst_orgDom", ")", "# subtract loss on original maybe", "\n", "actDom", "=", "clDom", "(", "fake_adaDom", ")", "# subtract loss on original maybe", "\n", "if", "self", ".", "cfg", "[", "\"smoo\"", "]", ":", "\n", "                        ", "actOrg", "=", "actOrg", "+", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "actOrg", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "*", "self", ".", "cfg", "[", "\"smoo\"", "]", "\n", "actDom", "=", "actDom", "+", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "actDom", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "*", "self", ".", "cfg", "[", "\"smoo\"", "]", "\n", "", "li_loss", "=", "self", ".", "cfg", "[", "\"trainCl\"", "]", "*", "(", "clloss", "(", "actOrg", ",", "m_labels", ")", "+", "clloss", "(", "actDom", ",", "m_labels", ")", ")", "\n", "", "else", ":", "\n", "                    ", "acti", "=", "linCl", "(", "reconst_orgDom", ")", "# subtract loss on original maybe", "\n", "if", "self", ".", "cfg", "[", "\"smoo\"", "]", ":", "\n", "                        ", "acti", "=", "acti", "+", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "acti", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", "*", "self", ".", "cfg", "[", "\"smoo\"", "]", "\n", "", "li_loss", "=", "self", ".", "cfg", "[", "\"useClLo\"", "]", "*", "clloss", "(", "acti", ",", "m_labels", ")", "\n", "", "g_loss", "+=", "li_loss", "\n", "\n", "", "wrap", "(", "sca2", ",", "self", ".", "g_optimizer", ",", "g_loss", ")", "\n", "\n", "\n", "# train adaDom-orgDom-adaDom cycle", "\n", "self", ".", "reset_grad", "(", ")", "\n", "fake_orgDom", "=", "self", ".", "g21", "(", "adaDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"d1\"", "]", ":", "\n", "                ", "out", "=", "self", ".", "d1", "(", "fake_orgDom", ")", "\n", "if", "self", ".", "cfg", "[", "\"useLab\"", "]", "==", "2", ":", "g_loss", "=", "useLabLoss", "(", "out", ",", "s_labels", ")", "\n", "else", ":", "g_loss", "=", "torch", ".", "mean", "(", "(", "out", "-", "1", ")", "**", "2", ")", "\n", "", "else", ":", "g_loss", "=", "0", "\n", "if", "self", ".", "cfg", "[", "\"useRec\"", "]", ">", "0", ":", "\n", "                ", "reconst_adaDom", "=", "self", ".", "g12", "(", "fake_orgDom", ")", "\n", "reclo2", "=", "self", ".", "cfg", "[", "\"cycFac\"", "]", "[", "1", "]", "*", "self", ".", "cfg", "[", "\"useRec\"", "]", "*", "torch", ".", "mean", "(", "recLoFct", "(", "adaDom", "-", "reconst_adaDom", ")", ")", "\n", "g_loss", "+=", "reclo2", "\n", "\n", "", "wrap", "(", "sca3", ",", "self", ".", "g_optimizer", ",", "g_loss", ")", "\n", "\n", "if", "self", ".", "cfg", "[", "\"useClLo\"", "]", ":", "\n", "                ", "if", "self", ".", "cfg", "[", "\"trainCl\"", "]", ":", "\n", "                    ", "def", "trCl", "(", "cl", ",", "dat", ",", "lo", ",", "opt", ")", ":", "\n", "                        ", "opt", ".", "zero_grad", "(", "set_to_none", "=", "True", ")", "\n", "cl", ".", "train", "(", ")", "\n", "act", "=", "cl", "(", "dat", ")", "\n", "clo", "=", "lo", "(", "act", ",", "m_labels", ")", "\n", "clo", ".", "backward", "(", ")", "\n", "opt", ".", "step", "(", ")", "\n", "cl", ".", "eval", "(", ")", "\n", "", "if", "not", "self", ".", "cfg", "[", "\"trainOrg\"", "]", "==", "2", ":", "trCl", "(", "clOrg", ",", "reconst_orgDom", ".", "detach", "(", ")", ",", "loOrg", ",", "optOrg", ")", "\n", "if", "self", ".", "cfg", "[", "\"trainOrg\"", "]", "==", "1", ":", "trCl", "(", "clOrg", ",", "orgDom", ".", "detach", "(", ")", ",", "loOrg", ",", "optOrg", ")", "\n", "trCl", "(", "clDom", ",", "fake_adaDom", ".", "detach", "(", ")", ",", "loDom", ",", "optDom", ")", "\n", "\n", "\n", "", "", "if", "(", "step", "+", "1", ")", "%", "self", ".", "cfg", "[", "\"ntries\"", "]", "[", "0", "]", "==", "0", ":", "# print the log info self.log_step", "\n", "                ", "useLat", "=", "self", ".", "cfg", "[", "\"useLat\"", "]", "\n", "\n", "def", "getaeds", "(", "ds", ")", ":", "\n", "                    ", "ax0", ",", "ax1", ",", "ay", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "self", ".", "g12", ".", "eval", "(", ")", "\n", "for", "bx", ",", "by", "in", "ds", ":", "\n", "                       ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                        ", "cx", "=", "bx", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "fake_code_dom", "=", "self", ".", "g12", "(", "cx", ")", "\n", "if", "not", "useLat", ":", "\n", "                            ", "orgX", "=", "netAEorg", ".", "dec", "(", "cx", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "domGenX", "=", "netAEdom", ".", "dec", "(", "fake_code_dom", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "ax0", ".", "append", "(", "orgX", "if", "not", "useLat", "else", "bx", ")", "\n", "ax1", ".", "append", "(", "domGenX", "if", "not", "useLat", "else", "fake_code_dom", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ay", ".", "append", "(", "by", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "self", ".", "g12", ".", "train", "(", ")", "\n", "return", "[", "np", ".", "concatenate", "(", "cx", ",", "axis", "=", "0", ")", "for", "cx", "in", "[", "ax0", ",", "ax1", ",", "ay", "]", "]", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "(", "10", "*", "self", ".", "cfg", "[", "\"ntries\"", "]", "[", "0", "]", ")", "==", "0", ":", "\n", "                    ", "print", "(", "'Step [%d/%d], Losses: d_real: %.4f, d_OrgDom: %.4f, d_AdaDom: %.4f, '", "\n", "'d_fake: %.4f, g: %.4f, r: %.4f, r2: %.4f'", "%", "(", "step", "+", "1", ",", "train_iters", ",", "d_real_loss", ".", "item", "(", ")", ",", "d_orgDom_loss", ".", "item", "(", ")", "if", "self", ".", "cfg", "[", "\"d1\"", "]", "else", "-", "1", ",", "d_adaDom_loss", ".", "item", "(", ")", ",", "d_fake_loss", ".", "item", "(", ")", ",", "g_loss", ".", "item", "(", ")", ",", "reclo", ".", "item", "(", ")", ",", "reclo2", ".", "item", "(", ")", ")", ",", "self", ".", "cfg", "[", "\"pr\"", "]", ")", "\n", "if", "self", ".", "cfg", "[", "\"useClLo\"", "]", ":", "print", "(", "\"LinCl Loss\"", ",", "li_loss", ".", "item", "(", ")", ")", "\n", "\n", "", "clo", "=", "g_loss", ".", "item", "(", ")", "\n", "\n", "\n", "if", "(", "step", "//", "niterEp", ">=", "self", ".", "cfg", "[", "\"epG\"", "]", "and", "milo", "*", "0.85", ">", "clo", ")", ":", "\n", "                    ", "milo", "=", "clo", "\n", "tries", "+=", "1", "\n", "[", "ax0", ",", "ax1", ",", "ay", "]", "=", "getaeds", "(", "aetr_iter", ")", "\n", "[", "atex0", ",", "atex1", ",", "atey", "]", "=", "getaeds", "(", "aete_iter", ")", "\n", "if", "tries", "==", "self", ".", "cfg", "[", "\"ntries\"", "]", "[", "1", "]", ":", "break", "\n", "\n", "\n", "", "", "", "", "othlo", "=", "{", "\"DOLo\"", ":", "d_orgDom_loss", ".", "item", "(", ")", "if", "self", ".", "cfg", "[", "\"d1\"", "]", "else", "0", ",", "\"DDLo\"", ":", "d_adaDom_loss", ".", "item", "(", ")", ",", "\"DFLo\"", ":", "d_fake_loss", ".", "item", "(", ")", "}", "# \"DRLo\":d_real_loss.item(),", "\n", "return", "othlo", ",", "ax0", ",", "ax1", ",", "ay", ",", "atex0", ",", "atex1", ",", "atey", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.getTrAcc": [[22, 50], ["classifierModels.worNet().cuda", "torch.optim.SGD", "torch.GradScaler", "torch.CrossEntropyLoss", "range", "torch.CrossEntropyLoss", "max", "worNet().cuda.parameters", "trainClassifiers.getAcc", "worNet().cuda.train", "enumerate", "trainClassifiers.decay", "worNet().cuda.eval", "clAcc", "classifierModels.worNet", "print", "torch.autocast", "optim.SGD.zero_grad", "worNet().cuda.", "nn.CrossEntropyLoss.", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "tca.GradScaler.update", "clAcc", "data[].cuda", "data[].cuda", "dsy.long", "tca.GradScaler.scale", "crolo.item", "crolo.item"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getAcc", "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay"], ["def", "getTrAcc", "(", "cfg", ",", "trds", ",", "val_dataset", ")", ":", "\n", "    ", "netCl", "=", "worNet", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "ccf", "=", "cfg", "[", "\"clcfg\"", "]", "\n", "closs", ",", "teaccs", ",", "trep", ",", "loss", ",", "clr", "=", "0", ",", "[", "]", ",", "cfg", "[", "\"epC\"", "]", "//", "3", ",", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "\n", "# optimizerCl = optim.SGD(netCl.parameters(), lr=0.05, momentum=0.9, weight_decay=1e-5)  # elif ccf[\"opt\"][0] == \"A\": optimizerCl = optim.Adam(netCl.parameters(), ccf[\"opt\"][2], weight_decay=ccf[\"opt\"][3])", "\n", "warmup", "=", "(", "max", "(", "2", ",", "trep", "//", "40", ")", ",", "10", ")", "\n", "optimizerCl", "=", "optim", ".", "SGD", "(", "netCl", ".", "parameters", "(", ")", ",", "lr", "=", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "/", "warmup", "[", "1", "]", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", ")", "\n", "scaler", "=", "tca", ".", "GradScaler", "(", ")", "\n", "clAcc", "=", "lambda", "dataset", ":", "getAcc", "(", "netCl", ",", "dataset", ",", "niter", "=", "9999", ",", "cfg", "=", "cfg", ")", "\n", "crolo", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "closs", "=", "0", "\n", "for", "epoch", "in", "range", "(", "trep", ")", ":", "\n", "        ", "netCl", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "trds", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "optimizerCl", ".", "zero_grad", "(", "set_to_none", "=", "True", ")", "\n", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", "\n", "output", "=", "netCl", "(", "dsx", ")", "\n", "errD_real", "=", "crolo", "(", "output", ",", "dsy", ".", "long", "(", ")", ")", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerCl", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "closs", "=", "0.97", "*", "closs", "+", "0.03", "*", "errD_real", ".", "item", "(", ")", "if", "i", ">", "20", "else", "0.8", "*", "closs", "+", "0.2", "*", "errD_real", ".", "item", "(", ")", "\n", "", "", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ",", "warmup", ",", "trep", ")", "\n", "netCl", ".", "eval", "(", ")", "\n", "if", "epoch", "<", "2", "or", "epoch", "==", "trep", "-", "1", "or", "epoch", "%", "15", "==", "0", ":", "\n", "            ", "print", "(", "\"Train Test CL\"", ",", "\"ep\"", ",", "epoch", ",", "closs", ",", "clAcc", "(", "val_dataset", ")", ")", "\n", "", "", "return", "clAcc", "(", "val_dataset", ")", ",", "netCl", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.decay": [[18, 25], ["print", "print", "numpy.round", "numpy.round", "int"], "function", ["None"], ["def", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ",", "warmup", ",", "trep", ")", ":", "\n", "    ", "if", "epoch", "==", "warmup", "[", "0", "]", ":", "\n", "        ", "for", "p", "in", "optimizerCl", ".", "param_groups", ":", "p", "[", "'lr'", "]", "*=", "(", "warmup", "[", "1", "]", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", "else", "warmup", "[", "1", "]", "/", "3", ")", "\n", "print", "(", "\"  W\"", ",", "np", ".", "round", "(", "optimizerCl", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "5", ")", ")", "\n", "", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", "and", "(", "epoch", "+", "1", ")", "%", "int", "(", "trep", "//", "3", "+", "10", "+", "warmup", "[", "0", "]", ")", "==", "0", ":", "\n", "        ", "for", "p", "in", "optimizerCl", ".", "param_groups", ":", "p", "[", "'lr'", "]", "*=", "0.1", "\n", "print", "(", "\"  D\"", ",", "np", ".", "round", "(", "optimizerCl", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getSingleAcc": [[26, 32], ["torch.autocast", "net", "torch.max", "torch.max", "torch.max", "torch.max", "torch.eq().sum().item", "torch.eq().sum().item", "torch.eq().sum().item", "torch.eq().sum().item", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "function", ["None"], ["", "", "def", "getSingleAcc", "(", "net", ",", "dsx", ",", "labels", ",", "pool", "=", "None", ")", ":", "\n", "  ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "    ", "outputs", "=", "net", "(", "dsx", ")", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "correct", "=", "torch", ".", "eq", "(", "predicted", ",", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "correct", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getAcc": [[34, 47], ["net.eval", "float", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.autocast", "net", "dsy.size", "torch.max", "torch.max", "torch.max", "torch.max", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "data[].cuda", "data[].cuda().unsqueeze", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "data[].cuda", "dsy.squeeze().long", "dsy.squeeze"], "function", ["None"], ["", "", "def", "getAcc", "(", "net", ",", "dataset", ",", "niter", "=", "10000", ",", "cfg", "=", "None", ")", ":", "\n", "    ", "correct", ",", "total", "=", "0", ",", "0", "\n", "net", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "cit", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "outputs", "=", "net", "(", "dsx", ")", "# if useAtt:                #     errD_real = loss(output[0], dsy.long())+loss(output[1], dsy.long())                #     output=output[1] #prediction outputs                # else:", "\n", "total", "+=", "dsy", ".", "size", "(", "0", ")", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ",", "1", ")", "\n", "correct", "+=", "torch", ".", "eq", "(", "predicted", ",", "dsy", ".", "squeeze", "(", ")", ".", "long", "(", ")", ")", ".", "sum", "(", ")", "\n", "if", "cit", ">=", "niter", ":", "break", "\n", "", "", "", "return", "float", "(", "(", "correct", "*", "1.0", "/", "total", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getCorr": [[48, 61], ["net.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.concatenate", "numpy.concatenate", "torch.autocast", "net", "torch.max", "torch.max", "torch.max", "torch.max", "correct.append", "conf.append", "data[].cuda", "data[].cuda().unsqueeze", "torch.eq().detach().cpu().numpy", "torch.eq().detach().cpu().numpy", "torch.eq().detach().cpu().numpy", "torch.eq().detach().cpu().numpy", "preconf.detach().cpu().numpy", "data[].cuda", "torch.eq().detach().cpu", "torch.eq().detach().cpu", "torch.eq().detach().cpu", "torch.eq().detach().cpu", "preconf.detach().cpu", "torch.eq().detach", "torch.eq().detach", "torch.eq().detach", "torch.eq().detach", "preconf.detach", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "dsy.squeeze().long", "dsy.squeeze"], "function", ["None"], ["", "def", "getCorr", "(", "net", ",", "dataset", ")", ":", "\n", "    ", "correct", "=", "[", "]", "\n", "conf", "=", "[", "]", "\n", "net", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "cit", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "outputs", "=", "net", "(", "dsx", ")", "\n", "preconf", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ",", "1", ")", "\n", "correct", ".", "append", "(", "torch", ".", "eq", "(", "predicted", ",", "dsy", ".", "squeeze", "(", ")", ".", "long", "(", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "conf", ".", "append", "(", "preconf", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "", "return", "np", ".", "concatenate", "(", "correct", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "conf", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getCls": [[63, 75], ["net.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.concatenate", "numpy.concatenate", "torch.autocast", "net", "torch.max", "torch.max", "torch.max", "torch.max", "by.append", "bx.append", "data[].cuda", "data[].cuda().unsqueeze", "predicted.detach().cpu().numpy", "data[].cpu().numpy", "data[].cuda", "predicted.detach().cpu", "data[].cpu", "predicted.detach"], "function", ["None"], ["", "def", "getCls", "(", "net", ",", "dataset", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "bx", ",", "by", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "cit", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "outputs", "=", "net", "(", "dsx", ")", "# if useAtt:                #     errD_real = loss(output[0], dsy.long())+loss(output[1], dsy.long())                #     output=output[1] #prediction outputs                # else:", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ",", "1", ")", "\n", "by", ".", "append", "(", "predicted", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "bx", ".", "append", "(", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "", "return", "np", ".", "concatenate", "(", "bx", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "by", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.setEval": [[76, 82], ["netCl.eval", "netCl.named_modules", "isinstance", "isinstance", "isinstance"], "function", ["None"], ["", "def", "setEval", "(", "netCl", ")", ":", "\n", "        ", "netCl", ".", "eval", "(", ")", "\n", "for", "name", ",", "module", "in", "netCl", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn", ".", "Dropout", ")", ":", "module", ".", "p", "=", "0", "\n", "elif", "isinstance", "(", "module", ",", "nn", ".", "LSTM", ")", ":", "module", ".", "dropout", "=", "0", "#print(\"zero lstm drop\") #print(\"zero drop\")", "\n", "elif", "isinstance", "(", "module", ",", "nn", ".", "GRU", ")", ":", "module", ".", "dropout", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getTrans": [[84, 166], ["NETWORK().cuda", "torch.Adam", "print", "torch.GradScaler", "numpy.zeros", "range", "trainClassifiers.setEval", "torch.MSELoss", "torch.L1Loss", "max", "NETWORK().cuda.parameters", "NETWORK().cuda.train", "enumerate", "trainClassifiers.decay", "NETWORK().cuda.eval", "enumerate", "orgTransModel.eval", "cds"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.setEval", "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay"], ["", "", "def", "getTrans", "(", "cfg", ",", "train_dataset", ",", "val_dataset", ",", "dat", ",", "traname", ",", "cget", ",", "selfTra", "=", "False", ")", ":", "\n", "    ", "ccf", "=", "cfg", "[", "\"trcfg\"", "]", "\n", "NETWORK", "=", "Trans", "#if \"V\" in ccf[\"netT\"] else (res.ResNet10 if ccf[\"netT\"] == \"R10\" else res.ResNet18)", "\n", "netCl", "=", "NETWORK", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "\n", "closs", ",", "teaccs", ",", "trep", ",", "clr", ",", "telo", "=", "0", ",", "[", "]", ",", "cfg", "[", "\"epC\"", "]", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", ",", "0", "\n", "loss", "=", "nn", ".", "MSELoss", "(", ")", "if", "cfg", "[", "\"traLo\"", "]", "else", "nn", ".", "L1Loss", "(", ")", "\n", "warmup", "=", "(", "max", "(", "2", ",", "trep", "//", "40", ")", ",", "10", ")", "\n", "#if ccf[\"opt\"][0] == \"S\": optimizerCl = optim.SGD(netCl.parameters(), lr=ccf[\"opt\"][1]/warmup[1], momentum=0.8, weight_decay=ccf[\"opt\"][2])", "\n", "#elif ccf[\"opt\"][0] == \"A\": #else: \"Error opt not found\"", "\n", "optimizerCl", "=", "optim", ".", "Adam", "(", "netCl", ".", "parameters", "(", ")", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", ")", "\n", "print", "(", "\"Train Trans\"", ",", "ccf", ")", "\n", "scaler", "=", "tca", ".", "GradScaler", "(", ")", "\n", "nDom", "=", "2", "#len(cfg[\"trans\"])+1-cfg[\"nFor\"] #Last for testing", "\n", "inds", "=", "np", ".", "zeros", "(", "3", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "for", "epoch", "in", "range", "(", "trep", ")", ":", "\n", "        ", "netCl", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_dataset", ")", ":", "\n", "          ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "            ", "optimizerCl", ".", "zero_grad", "(", ")", "\n", "xdata", "=", "data", "[", ":", "-", "1", "]", "\n", "if", "cfg", "[", "\"singleIn\"", "]", ":", "\n", "                ", "inds", "[", "0", "]", "=", "np", ".", "random", ".", "choice", "(", "nDom", "-", "1", ")", "# -4 = X0, -3=X1, -2=XTe, -1=XPreTest", "\n", "inds", "[", "1", "]", "=", "inds", "[", "0", "]", "\n", "inds", "[", "2", "]", "=", "inds", "[", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "inds", "[", "0", "]", "=", "np", ".", "random", ".", "choice", "(", "nDom", "-", "2", ")", "#-4 = X0, -3=X1, -2=XTe, -1=XPreTest", "\n", "inds", "[", "1", "]", "=", "inds", "[", "0", "]", "+", "1", "\n", "if", "cfg", "[", "\"ranCh\"", "]", ":", "inds", "[", "1", "]", "+=", "np", ".", "random", ".", "choice", "(", "nDom", "-", "2", "-", "inds", "[", "0", "]", ")", "\n", "inds", "[", "2", "]", "=", "inds", "[", "1", "]", "+", "1", "\n", "", "dsx", "=", "[", "xdata", "[", "cind", "]", ".", "cuda", "(", ")", "for", "cind", "in", "inds", "]", "#dsy = data[1].cuda()", "\n", "output", "=", "netCl", "(", "dsx", "[", ":", "2", "]", ")", "\n", "errD_real", "=", "loss", "(", "output", ",", "dsx", "[", "-", "1", "]", ")", "# errD_real.backward()            # optimizerCl.step()", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerCl", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "closs", "=", "0.97", "*", "closs", "+", "0.03", "*", "errD_real", ".", "item", "(", ")", "if", "i", ">", "20", "else", "0.8", "*", "closs", "+", "0.2", "*", "errD_real", ".", "item", "(", ")", "\n", "\n", "", "", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ",", "warmup", ",", "trep", ")", "\n", "netCl", ".", "eval", "(", ")", "\n", "#if epoch%16==0: store(pre=\"Ep_\" + str(epoch)+\"_\",dirapp=\"Tmp\",output=output,xdata=xdata)", "\n", "if", "(", "epoch", "%", "2", "==", "0", "and", "epoch", "<=", "10", ")", "or", "(", "epoch", "%", "10", "==", "0", "and", "epoch", ">", "10", ")", ":", "\n", "            ", "print", "(", "epoch", ",", "np", ".", "round", "(", "np", ".", "array", "(", "[", "closs", "]", ")", ",", "5", ")", ",", "cfg", "[", "\"pr\"", "]", ")", "#teAccs[-1], clAcc(train_dataset)", "\n", "if", "np", ".", "isnan", "(", "closs", ")", ":", "\n", "                ", "print", "(", "\"Failed!!!\"", ")", "\n", "return", "None", ",", "None", ",", "None", "\n", "", "", "", "def", "getLo", "(", "ds", ",", "off", "=", "0", ")", ":", "\n", "        ", "telo", ",", "nele", "=", "0", ",", "0", "\n", "for", "i", ",", "xdata", "in", "enumerate", "(", "ds", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "ainds", "=", "[", "nDom", "-", "3", "+", "off", ",", "nDom", "-", "2", "+", "off", ",", "nDom", "-", "1", "+", "off", "]", "# Shift by one to get test", "\n", "dsx", "=", "[", "xdata", "[", "cind", "]", ".", "cuda", "(", ")", "for", "cind", "in", "ainds", "]", "\n", "output", "=", "netCl", "(", "dsx", "[", ":", "2", "]", ")", "\n", "telo", "+=", "loss", "(", "output", ",", "dsx", "[", "-", "1", "]", ")", "\n", "nele", "+=", "dsx", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "", "", "", "return", "(", "telo", "/", "nele", ")", ".", "item", "(", ")", "\n", "\n", "", "def", "transform", "(", "cfg", ",", "orgTransModel", ",", "traX", ",", "traY", ")", ":", "\n", "        ", "def", "cds", "(", "X", ",", "Y", ",", "shuffle", "=", "False", ",", "norm", "=", "True", ")", ":", "\n", "            ", "noX", "=", "imgutil", ".", "nor", "(", "X", ".", "astype", "(", "np", ".", "float32", ")", ")", "if", "norm", "else", "X", "\n", "ds", "=", "TensorDataset", "(", "torch", ".", "from_numpy", "(", "noX", ")", ",", "torch", ".", "from_numpy", "(", "Y", ")", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ds", ",", "batch_size", "=", "cfg", "[", "\"batchSize\"", "]", ",", "shuffle", "=", "shuffle", ",", "num_workers", "=", "0", ")", "\n", "\n", "", "cajx", ",", "cajy", "=", "[", "]", ",", "[", "]", "\n", "orgTransModel", ".", "eval", "(", ")", "\n", "for", "data", "in", "cds", "(", "traX", ",", "traY", ",", "shuffle", "=", "False", ")", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "# with torch.no_grad():", "\n", "                ", "dsx", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", "\n", "out1", "=", "orgTransModel", "(", "[", "None", ",", "dsx", "]", ")", "\n", "output", "=", "orgTransModel", "(", "[", "None", ",", "out1", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "cajx", ".", "append", "(", "output", ".", "clone", "(", ")", ".", "numpy", "(", ")", ")", "\n", "cajy", ".", "append", "(", "data", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "return", "cds", "(", "np", ".", "concatenate", "(", "cajx", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "cajy", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "lcfg", "=", "{", "\"trLo\"", ":", "closs", ",", "\"tetrLo\"", ":", "getLo", "(", "train_dataset", ")", ",", "\"teteLo\"", ":", "getLo", "(", "val_dataset", ")", "}", "#,\"D1AccTra\":traAcc", "\n", "setEval", "(", "netCl", ")", "\n", "return", "netCl", ",", "lcfg", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getclassifier": [[167, 208], ["print", "NETWORK().cuda", "print", "torch.GradScaler", "torch.CrossEntropyLoss", "range", "numpy.max", "trainClassifiers.setEval", "torch.CrossEntropyLoss", "max", "torch.SGD", "trainClassifiers.getAcc", "NETWORK().cuda.train", "enumerate", "trainClassifiers.decay", "NETWORK().cuda.eval", "teAccs.append", "numpy.array", "clAcc", "NETWORK", "NETWORK().cuda.parameters", "clAcc", "print", "numpy.isnan", "torch.autocast", "optim.SGD.zero_grad", "NETWORK().cuda.", "nn.CrossEntropyLoss.", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "tca.GradScaler.update", "numpy.round", "print", "data[].cuda", "data[].cuda", "dsy.long", "numpy.array", "tca.GradScaler.scale", "crolo.item", "crolo.item", "clAcc"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.setEval", "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getAcc", "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay"], ["", "def", "getclassifier", "(", "cfg", ",", "train_dataset", ",", "val_dataset", ",", "sname", ",", "getc", ",", "save", "=", "False", ",", "loadCl", "=", "True", ",", "useLat", "=", "False", ")", ":", "\n", "    ", "print", "(", "sname", ",", "\"Cl\"", ")", "\n", "ccf", "=", "cfg", "[", "\"clcfg\"", "]", "\n", "if", "useLat", ":", "NETWORK", "=", "linNet", "\n", "else", ":", "NETWORK", "=", "worNet", "#if \"V\" in ccf[\"netT\"]  else (res.ResNet10 if ccf[\"netT\"] == \"R10\" else res.ResNet18)", "\n", "netCl", "=", "NETWORK", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "\n", "closs", ",", "teaccs", ",", "trep", ",", "loss", ",", "clr", "=", "0", ",", "[", "]", ",", "cfg", "[", "\"epC\"", "]", ",", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "\n", "warmup", "=", "(", "max", "(", "2", ",", "trep", "//", "40", ")", ",", "10", ")", "\n", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", ":", "optimizerCl", "=", "optim", ".", "SGD", "(", "netCl", ".", "parameters", "(", ")", ",", "lr", "=", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "/", "warmup", "[", "1", "]", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", ")", "#elif ccf[\"opt\"][0] == \"A\": optimizerCl = optim.Adam(netCl.parameters(), ccf[\"opt\"][2], weight_decay=ccf[\"opt\"][3])", "\n", "else", ":", "\"Error opt not found\"", "\n", "print", "(", "\"Train CL\"", ",", "sname", ",", "ccf", ")", "\n", "scaler", "=", "tca", ".", "GradScaler", "(", ")", "\n", "teAccs", "=", "[", "]", "\n", "clAcc", "=", "lambda", "dataset", ":", "getAcc", "(", "netCl", ",", "dataset", ",", "niter", "=", "niter", ",", "cfg", "=", "cfg", ")", "\n", "crolo", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "for", "epoch", "in", "range", "(", "trep", ")", ":", "\n", "        ", "netCl", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_dataset", ")", ":", "\n", "          ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "            ", "optimizerCl", ".", "zero_grad", "(", ")", "\n", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", "\n", "output", "=", "netCl", "(", "dsx", ")", "\n", "errD_real", "=", "crolo", "(", "output", ",", "dsy", ".", "long", "(", ")", ")", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerCl", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "closs", "=", "0.97", "*", "closs", "+", "0.03", "*", "errD_real", ".", "item", "(", ")", "if", "i", ">", "20", "else", "0.8", "*", "closs", "+", "0.2", "*", "errD_real", ".", "item", "(", ")", "\n", "", "", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ",", "warmup", ",", "trep", ")", "\n", "netCl", ".", "eval", "(", ")", "\n", "teAccs", ".", "append", "(", "clAcc", "(", "val_dataset", ")", ")", "\n", "if", "(", "epoch", "%", "2", "==", "0", "and", "epoch", "<=", "10", ")", "or", "(", "epoch", "%", "10", "==", "0", "and", "epoch", ">", "10", ")", ":", "\n", "            ", "print", "(", "epoch", ",", "np", ".", "round", "(", "np", ".", "array", "(", "[", "closs", ",", "teAccs", "[", "-", "1", "]", ",", "clAcc", "(", "train_dataset", ")", "]", ")", ",", "5", ")", ",", "cfg", "[", "\"pr\"", "]", ")", "\n", "if", "np", ".", "isnan", "(", "closs", ")", ":", "\n", "                ", "print", "(", "\"Failed!!!\"", ")", "\n", "return", "None", ",", "None", ",", "None", "\n", "", "", "", "mteA", "=", "np", ".", "max", "(", "np", ".", "array", "(", "teAccs", ")", ")", "\n", "lcfg", "=", "{", "\"teA\"", ":", "teAccs", "[", "-", "1", "]", ",", "\"trA\"", ":", "clAcc", "(", "train_dataset", ")", ",", "\"Lo\"", ":", "closs", ",", "\"mteA\"", ":", "mteA", "}", "\n", "setEval", "(", "netCl", ")", "\n", "return", "netCl", ",", "lcfg", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getLinCl": [[210, 246], ["LinCl().cuda", "print", "torch.GradScaler", "torch.CrossEntropyLoss", "range", "trainClassifiers.setEval", "torch.CrossEntropyLoss", "max", "torch.SGD", "trainClassifiers.getAcc", "LinCl().cuda.train", "enumerate", "trainClassifiers.decay", "LinCl().cuda.eval", "teAccs.append", "clAcc", "clAcc", "LinCl", "LinCl().cuda.parameters", "clAcc", "print", "numpy.isnan", "torch.autocast", "optim.SGD.zero_grad", "LinCl().cuda.", "nn.CrossEntropyLoss.", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "tca.GradScaler.update", "numpy.round", "print", "data[].cuda", "data[].cuda", "dsy.long", "numpy.array", "tca.GradScaler.scale", "crolo.item", "crolo.item", "clAcc"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.setEval", "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getAcc", "home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay"], ["", "def", "getLinCl", "(", "cfg", ",", "train_dataset", ",", "val_dataset", ",", "sname", ",", "getc", ",", "save", "=", "True", ",", "loadCl", "=", "True", ")", ":", "\n", "    ", "ccf", "=", "cfg", "[", "\"clcfg\"", "]", "\n", "from", "aecyc", ".", "latAEModels", "import", "LinCl", "\n", "netCl", "=", "LinCl", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "closs", ",", "teaccs", ",", "trep", ",", "loss", ",", "clr", "=", "0", ",", "[", "]", ",", "cfg", "[", "\"epC\"", "]", ",", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "/", "4", "#Train just 1/2 as long", "\n", "warmup", "=", "(", "max", "(", "2", ",", "trep", "//", "40", ")", ",", "10", ")", "\n", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", ":", "optimizerCl", "=", "optim", ".", "SGD", "(", "netCl", ".", "parameters", "(", ")", ",", "lr", "=", "clr", "/", "warmup", "[", "1", "]", ",", "momentum", "=", "0.8", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", "/", "5", ")", "#elif ccf[\"opt\"][0] == \"A\": optimizerCl = optim.Adam(netCl.parameters(), ccf[\"opt\"][2], weight_decay=ccf[\"opt\"][3])", "\n", "else", ":", "\"Error opt not found\"", "\n", "print", "(", "\"Train CL\"", ",", "sname", ",", "ccf", ")", "\n", "scaler", "=", "tca", ".", "GradScaler", "(", ")", "\n", "teAccs", "=", "[", "]", "\n", "clAcc", "=", "lambda", "dataset", ":", "getAcc", "(", "netCl", ",", "dataset", ",", "niter", "=", "niter", ",", "cfg", "=", "cfg", ")", "\n", "crolo", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "for", "epoch", "in", "range", "(", "trep", ")", ":", "\n", "        ", "netCl", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_dataset", ")", ":", "\n", "          ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "            ", "optimizerCl", ".", "zero_grad", "(", ")", "\n", "dsx", ",", "dsy", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", ",", "data", "[", "1", "]", ".", "cuda", "(", ")", "\n", "output", "=", "netCl", "(", "dsx", ")", "\n", "errD_real", "=", "crolo", "(", "output", ",", "dsy", ".", "long", "(", ")", ")", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerCl", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "closs", "=", "0.97", "*", "closs", "+", "0.03", "*", "errD_real", ".", "item", "(", ")", "if", "i", ">", "20", "else", "0.8", "*", "closs", "+", "0.2", "*", "errD_real", ".", "item", "(", ")", "\n", "", "", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ",", "warmup", ",", "trep", ")", "\n", "netCl", ".", "eval", "(", ")", "\n", "teAccs", ".", "append", "(", "clAcc", "(", "val_dataset", ")", ")", "\n", "if", "(", "epoch", "%", "2", "==", "0", "and", "epoch", "<=", "10", ")", "or", "(", "epoch", "%", "10", "==", "0", "and", "epoch", ">", "10", ")", ":", "\n", "            ", "print", "(", "epoch", ",", "np", ".", "round", "(", "np", ".", "array", "(", "[", "closs", ",", "teAccs", "[", "-", "1", "]", ",", "clAcc", "(", "train_dataset", ")", "]", ")", ",", "5", ")", ",", "cfg", "[", "\"pr\"", "]", ")", "\n", "if", "np", ".", "isnan", "(", "closs", ")", ":", "\n", "                ", "print", "(", "\"Failed!!!\"", ")", "\n", "return", "None", ",", "None", ",", "None", "\n", "", "", "", "lcfg", "=", "{", "\"LiteA\"", ":", "clAcc", "(", "val_dataset", ")", ",", "\"LitrA\"", ":", "clAcc", "(", "train_dataset", ")", ",", "\"LiLo\"", ":", "closs", "}", "\n", "setEval", "(", "netCl", ")", "\n", "return", "netCl", ",", "lcfg", "", "", ""]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.nor": [[7, 8], ["numpy.mean", "numpy.std"], "function", ["None"], ["def", "nor", "(", "x", ")", ":", "return", "(", "x", "-", "np", ".", "mean", "(", "x", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", ")", "/", "(", "np", ".", "std", "(", "x", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", "+", "1e-7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.rot1": [[10, 17], ["min", "scipy.ndimage.rotate"], "function", ["None"], ["def", "rot1", "(", "img", ",", "d", ")", ":", "\n", "#co = np.min(img) #img[ 0, 0]", "\n", "    ", "co", "=", "min", "(", "img", "[", "0", ",", "0", "]", ",", "img", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "#print(np.min(img),np.max(img),np.mean(img),np.std(img),np.median(img),\"test\")", "\n", "img", "=", "ndimage", ".", "rotate", "(", "img", ",", "d", ",", "reshape", "=", "False", ",", "cval", "=", "co", ")", "\n", "#print(co, img[0, 0],bef, \"rotting\")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.zoo1": [[20, 24], ["int", "scipy.ndimage.zoom"], "function", ["None"], ["", "def", "zoo1", "(", "img", ",", "d", ")", ":", "\n", "    ", "bo", "=", "int", "(", "32", "*", "d", "-", "32", ")", "//", "2", "\n", "img", "=", "ndimage", ".", "zoom", "(", "img", ",", "d", ")", "[", "bo", ":", "32", "+", "bo", ",", "bo", ":", "32", "+", "bo", "]", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.splitMid1": [[26, 33], ["min", "numpy.concatenate"], "function", ["None"], ["", "def", "splitMid1", "(", "x", ",", "d", ")", ":", "\n", "    ", "w", "=", "x", ".", "shape", "[", "0", "]", "\n", "left", "=", "x", "[", "d", "//", "2", ":", "w", "//", "2", ",", ":", "]", "\n", "mid", "=", "x", "[", ":", "d", "]", "*", "0", "+", "min", "(", "x", "[", "0", ",", "0", "]", ",", "x", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "right", "=", "x", "[", "w", "//", "2", ":", ",", ":", "]", "\n", "x", "=", "np", ".", "concatenate", "(", "[", "left", ",", "mid", ",", "right", "]", ",", "axis", "=", "0", ")", "[", ":", "w", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.getOp": [[34, 36], ["globals"], "function", ["None"], ["", "def", "getOp", "(", "name", ")", ":", "\n", "    ", "return", "globals", "(", ")", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.applyOp": [[37, 44], ["x.astype.astype", "imgutil.getOp", "range", "imgutil.nor", "range", "getOp."], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.getOp", "home.repos.pwc.inspect_result.johntailor_dotra.None.imgutil.nor"], ["", "def", "applyOp", "(", "x", ",", "opname", ",", "para", ")", ":", "\n", "    ", "x", "=", "x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "op", "=", "getOp", "(", "opname", ")", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "x", ".", "shape", "[", "1", "]", ")", ":", "# xo=np.copy(x[i,j])", "\n", "            ", "x", "[", "i", ",", "j", "]", "=", "op", "(", "x", "[", "i", ",", "j", "]", ",", "para", ")", "\n", "", "", "return", "nor", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.main.trainOne": [[19, 148], ["int", "dutils.getFullDS", "int", "trainClassifiers.getclassifier", "main.trainOne.getAE"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.dutils.getFullDS", "home.repos.pwc.inspect_result.johntailor_dotra.None.trainClassifiers.getclassifier"], ["def", "trainOne", "(", "cfg", ")", ":", "\n", "    ", "def", "cds", "(", "X", ",", "Y", ",", "shuffle", "=", "False", ",", "norm", "=", "True", ")", ":", "\n", "        ", "noX", "=", "imgutil", ".", "nor", "(", "X", ".", "astype", "(", "np", ".", "float32", ")", ")", "if", "norm", "else", "X", "\n", "ds", "=", "TensorDataset", "(", "torch", ".", "from_numpy", "(", "noX", ")", ",", "torch", ".", "from_numpy", "(", "Y", ")", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ds", ",", "batch_size", "=", "cfg", "[", "\"batchSize\"", "]", ",", "shuffle", "=", "shuffle", ",", "num_workers", "=", "0", ")", "\n", "\n", "", "def", "cds2", "(", "X", ",", "Y", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "noX", "=", "[", "imgutil", ".", "nor", "(", "cX", ".", "astype", "(", "np", ".", "float32", ")", ")", "for", "cX", "in", "X", "]", "\n", "ds", "=", "TensorDataset", "(", "*", "[", "torch", ".", "from_numpy", "(", "cX", ")", "for", "cX", "in", "noX", "]", ",", "torch", ".", "from_numpy", "(", "Y", ")", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "ds", ",", "batch_size", "=", "cfg", "[", "\"batchSize\"", "]", ",", "shuffle", "=", "shuffle", ",", "num_workers", "=", "0", ")", "\n", "\n", "", "def", "modXY", "(", "toModteX", ",", "modteY", ")", ":", "\n", "        ", "t", "=", "cfg", "[", "\"trans\"", "]", "[", "0", "]", "\n", "modteX", "=", "applyOp", "(", "toModteX", ",", "t", "[", "0", "]", ",", "t", "[", "1", "]", ")", "\n", "return", "modteX", ",", "modteY", "\n", "\n", "", "def", "cdsMod", "(", "X", ",", "Y", ")", ":", "\n", "        ", "X", "=", "imgutil", ".", "nor", "(", "X", ")", "\n", "allX", ",", "allY", "=", "[", "X", "]", ",", "[", "Y", "]", "\n", "for", "t", "in", "cfg", "[", "\"transEv\"", "]", ":", "\n", "            ", "modtrX", ",", "Y", "=", "modXY", "(", "allX", "[", "-", "1", "]", ".", "astype", "(", "np", ".", "float32", ")", ",", "allY", "[", "-", "1", "]", ")", "\n", "allX", ".", "append", "(", "modtrX", ")", "\n", "allY", ".", "append", "(", "Y", ")", "\n", "", "return", "allX", ",", "allY", "\n", "\n", "", "def", "getAE", "(", "cfg", ",", "trX", ",", "trY", ",", "teX", ",", "teY", ",", "sname", ",", "dotrain", ",", "picname", "=", "\"\"", ")", ":", "\n", "        ", "origtr_iter", "=", "cds", "(", "trX", ",", "trY", ",", "True", ")", "\n", "origte_iter", "=", "cds", "(", "teX", ",", "teY", ",", "False", ")", "\n", "(", "aetrX", ",", "aetrY", ")", ",", "(", "aeteX", ",", "aeteY", ")", ",", "acfg", ",", "netAEorg", "=", "aut", ".", "runAE", "(", "cfg", ",", "origtr_iter", ",", "origte_iter", ",", "sname", ",", "dotrain", ",", "picname", ")", "\n", "aetr_iter", "=", "cds", "(", "aetrX", ",", "aetrY", ",", "True", ",", "False", ")", "\n", "aete_iter", "=", "cds", "(", "aeteX", ",", "aeteY", ",", "False", ",", "False", ")", "\n", "return", "aetr_iter", ",", "aete_iter", ",", "netAEorg", "\n", "\n", "\n", "\n", "", "cget", "=", "True", "\n", "#Get unmodified, raw training data and a base Classifier", "\n", "totdat", "=", "int", "(", "cfg", "[", "\"ds\"", "]", "[", "2", "]", ")", "\n", "(", "trX", ",", "trY", ")", ",", "(", "teX", ",", "teY", ")", "=", "dutils", ".", "getFullDS", "(", "cfg", ",", "totdat", ",", "None", ",", "cget", ")", "\n", "\n", "if", "cfg", "[", "\"baseZoom\"", "]", "!=", "1", ":", "\n", "        ", "print", "(", "\"Zooming data for Proposition test\"", ")", "\n", "trX", "=", "applyOp", "(", "trX", ",", "\"zoo1\"", ",", "cfg", "[", "\"baseZoom\"", "]", ")", "\n", "teX", "=", "applyOp", "(", "teX", ",", "\"zoo1\"", ",", "cfg", "[", "\"baseZoom\"", "]", ")", "\n", "\n", "", "disoff", "=", "int", "(", "totdat", "*", "cfg", "[", "\"distinctDat\"", "]", "*", "0.5", ")", "\n", "nd", "=", "totdat", "-", "disoff", "\n", "baseCl", ",", "baseClRes", "=", "trainClassifiers", ".", "getclassifier", "(", "cfg", ",", "cds", "(", "trX", ",", "trY", ",", "True", ")", ",", "cds", "(", "teX", ",", "teY", ",", "False", ")", ",", "None", ",", "getc", "=", "False", ",", "loadCl", "=", "False", ",", "save", "=", "False", ",", "useLat", "=", "False", ")", "#get base classifier (only used for reference)", "\n", "\n", "toModtrX", ",", "modtrY", "=", "np", ".", "copy", "(", "trX", "[", "disoff", ":", "nd", "+", "disoff", "]", ")", ",", "np", ".", "copy", "(", "trY", "[", "disoff", ":", "nd", "+", "disoff", "]", ")", "\n", "toModteX", ",", "modteY", "=", "np", ".", "copy", "(", "teX", ")", ",", "np", ".", "copy", "(", "teY", ")", "\n", "trX", ",", "trY", "=", "trX", "[", ":", "nd", "]", ",", "trY", "[", ":", "nd", "]", "\n", "\n", "#Get auto encoding of raw training data and domain adapted data", "\n", "aetr_iter", ",", "aete_iter", ",", "netAEorg", "=", "getAE", "(", "cfg", ",", "trX", ",", "trY", ",", "teX", ",", "teY", ",", "sname", "=", "None", ",", "dotrain", "=", "cget", ",", "picname", "=", "\"onRawOrgDomain\"", ")", "#AE with tanh => -1,1", "\n", "t", "=", "cfg", "[", "\"trans\"", "]", "[", "0", "]", "\n", "\n", "modtrX", ",", "modtrY", "=", "modXY", "(", "toModtrX", ",", "modtrY", ")", "\n", "modteX", ",", "modteY", "=", "modXY", "(", "toModteX", ",", "modteY", ")", "\n", "\n", "failed", "=", "False", "\n", "# Full DoTra: autoencode, transform on latent, learn between domains", "\n", "aemodtr_iter", ",", "aemodte_iter", ",", "netAEdom", "=", "getAE", "(", "cfg", ",", "modtrX", ",", "modtrY", ",", "modteX", ",", "modteY", ",", "sname", "=", "None", ",", "dotrain", "=", "cget", ",", "picname", "=", "\"onRawAdaDomain\"", ")", "\n", "\n", "#Get Transformer between auto encodings of raw training data and for the same data in domain-adapted space", "\n", "solver", "=", "Solver", "(", "cfg", ")", "#if cfg[\"solvSim\"]==0 else solverSimp.Solver(cfg)", "\n", "othlo", ",", "ax0", ",", "ax1", ",", "ay", ",", "atex0", ",", "atex1", ",", "atey", "=", "solver", ".", "train", "(", "netAEorg", ",", "netAEdom", ",", "aetr_iter", ",", "aete_iter", ",", "aemodtr_iter", ",", "modteX", ",", "modteY", ",", "cget", ",", "nd", ")", "#AE with tanh => -1,1", "\n", "\n", "# Get transformer from original space (not some encoding space) and domain space (not encoded)", "\n", "a2tr_iter", "=", "cds2", "(", "[", "ax0", ",", "ax1", "]", ",", "ay", ",", "shuffle", "=", "True", ")", "# Data where training data in orig space is mapped to data in domain space", "\n", "a2te_iter", "=", "cds2", "(", "[", "atex0", ",", "atex1", "]", ",", "atey", ")", "# modtrX, amodteX = cdsMod(trX), cdsMod(teX)        #eteX, eteY = amodteX[-nFor:], [teY] * nFor    # if cfg[\"doTra\"]:            #ntr=ntra+1 - nFor            #origtr_iter = cds2(amodtrX,np.copy(trY), True)  # Array is copied due to type cast to float32 in cds2            #origte_iter = cds2(amodteX, np.copy(teY), False)", "\n", "loadtrans", "=", "cget", "\n", "orgTransModel", ",", "cyccfg", ",", "loaded", "=", "trainClassifiers", ".", "getTrans", "(", "cfg", ",", "a2tr_iter", ",", "a2te_iter", ",", "(", "(", "ax0", ",", "ay", ")", ",", "(", "atex0", ",", "atey", ")", ")", ",", "None", ",", "loadtrans", ",", "selfTra", "=", "False", ")", "\n", "\n", "\n", "\n", "#Get labeled domain data, by  applying transformer multiple times on source data", "\n", "nFor", "=", "len", "(", "cfg", "[", "\"transEv\"", "]", ")", "#   nFor = ntra# if nFor <= 0:        print(\"nothing to forecast\", ntra, cfg[\"transEv\"]) return", "\n", "atrX", "=", "[", "ax0", "]", "\n", "atrY", "=", "[", "ay", "]", "\n", "for", "i", "in", "range", "(", "nFor", ")", ":", "\n", "        ", "cajx", ",", "cajy", "=", "[", "]", ",", "[", "]", "\n", "orgTransModel", ".", "eval", "(", ")", "\n", "cdataset", "=", "cds", "(", "atrX", "[", "-", "1", "]", ",", "atrY", "[", "-", "1", "]", ",", "shuffle", "=", "False", ",", "norm", "=", "cfg", "[", "\"evNorm\"", "]", ")", "# citer=cds2([atrX[-2],atrX[-1]],atrY[-1])", "\n", "for", "data", "in", "cdataset", ":", "\n", "            ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "dsx", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", "\n", "if", "not", "cfg", "[", "\"dirCyc\"", "]", ":", "dsx", "=", "[", "None", ",", "dsx", "]", "\n", "output", "=", "orgTransModel", "(", "dsx", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "cajx", ".", "append", "(", "output", ".", "clone", "(", ")", ".", "numpy", "(", ")", ")", "\n", "cajy", ".", "append", "(", "data", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "atrX", ".", "append", "(", "np", ".", "concatenate", "(", "cajx", ",", "axis", "=", "0", ")", ")", "\n", "atrY", ".", "append", "(", "np", ".", "concatenate", "(", "cajy", ",", "axis", "=", "0", ")", ")", "\n", "", "etrX", ",", "etrY", "=", "atrX", "[", "-", "nFor", ":", "]", ",", "atrY", "[", "-", "nFor", ":", "]", "#print(\"nfo\", nFor, len(atrX))    # imgutil.makeAndStore2(atrX[-3][:64],atrX[-2][:64],atrX[-1][:64], cfg[\"bFolder\"] + \"samples/\", \"FORCAST\"+str(cfg[\"bid\"]) + fs(cfg) + \".png\")", "\n", "\n", "if", "not", "failed", ":", "\n", "#Get domain datasets used for prediction", "\n", "        ", "amodteX", ",", "amodteY", "=", "cdsMod", "(", "teX", ",", "teY", ")", "\n", "eteX", ",", "eteY", "=", "amodteX", "[", "-", "nFor", ":", "]", ",", "amodteY", "[", "-", "nFor", ":", "]", "\n", "\n", "def", "evalCl", "(", "ltrX", ",", "ltrY", ",", "lteX", ",", "lteY", ",", "domid", ")", ":", "\n", "            ", "def", "cods", "(", "lX", ",", "lY", ",", "shuffle", "=", "False", ")", ":", "\n", "                ", "trX", ",", "trY", "=", "np", ".", "concatenate", "(", "lX", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "lY", ",", "axis", "=", "0", ")", "# trY=np.concatenate([np.ones(aj[0].shape[0],dtype=np.int)*j for j in range(len(aj))])", "\n", "trX", ",", "trY", "=", "sklearn", ".", "utils", ".", "shuffle", "(", "trX", ",", "trY", ")", "\n", "trit", "=", "cds", "(", "trX", ",", "trY", ",", "shuffle", ")", "\n", "return", "trit", "\n", "", "trit", "=", "cods", "(", "ltrX", ",", "ltrY", ",", "True", ")", "\n", "teit", "=", "cods", "(", "lteX", ",", "lteY", ",", "False", ")", "\n", "netCl", ",", "clcfg", "=", "trainClassifiers", ".", "getclassifier", "(", "cfg", ",", "trit", ",", "teit", ",", "None", ",", "getc", "=", "False", ",", "save", "=", "False", ",", "loadCl", "=", "False", ")", "\n", "return", "clcfg", "\n", "\n", "#Train classifier using labeled data being transformed and apply it to generated test data", "\n", "", "vals", "=", "np", ".", "arange", "(", "nFor", ")", "\n", "for", "j", "in", "reversed", "(", "vals", ")", ":", "\n", "                ", "clcfg", "=", "evalCl", "(", "[", "etrX", "[", "j", "]", "]", ",", "[", "etrY", "[", "j", "]", "]", ",", "[", "eteX", "[", "j", "]", "]", ",", "[", "eteY", "[", "j", "]", "]", ",", "j", ")", "\n", "#print(\"eval\",j,nFor,np.sum(etrX[j]),clcfg,cyccfg)", "\n", "cyccfg", "[", "\"ptrA\"", "+", "str", "(", "j", ")", "]", "=", "clcfg", "[", "\"trA\"", "]", "\n", "cyccfg", "[", "\"pteA\"", "+", "str", "(", "j", ")", "]", "=", "clcfg", "[", "\"teA\"", "]", "\n", "cyccfg", "[", "\"mteA\"", "+", "str", "(", "j", ")", "]", "=", "clcfg", "[", "\"mteA\"", "]", "\n", "\n", "", "", "cyccfg", "=", "{", "**", "cyccfg", ",", "**", "othlo", ",", "**", "baseClRes", "}", "\n", "cfg", "[", "\"result\"", "]", "=", "[", "cyccfg", "]", "\n", "print", "(", "\"\\n\\nBench:\"", ",", "cfg", "[", "\"trans\"", "]", ")", "\n", "print", "(", "\"Result\"", ")", "\n", "res", "=", "cfg", "[", "\"result\"", "]", "[", "0", "]", "\n", "print", "(", "\"All metrics\"", ",", "res", ")", "\n", "print", "(", "\"Accs (Source, target 0,..,2)\"", ",", "np", ".", "round", "(", "[", "res", "[", "\"teA\"", "]", "]", "+", "[", "res", "[", "\"pteA\"", "+", "str", "(", "i", ")", "]", "for", "i", "in", "range", "(", "3", ")", "]", ",", "3", ")", ")", "\n", "print", "(", "\"MaxAccs\"", ",", "np", ".", "round", "(", "[", "res", "[", "\"teA\"", "]", "]", "+", "[", "res", "[", "\"mteA\"", "+", "str", "(", "i", ")", "]", "for", "i", "in", "range", "(", "3", ")", "]", ",", "3", ")", ")", "\n", "print", "(", "\"\\n\\n\\n\\n\"", ")", "\n", "#print(\"\\n\\n\\n\\nFOR Accuracy: check pteA. (=Accuracy after last epoch) and mteA.(=max Accuracy accross all epochs) in results below\")", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.BasicBlock.__init__": [[21, 33], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.BasicBlock.forward": [[35, 41], ["torch.relu", "torch.relu", "torch.relu", "doTraModel.BasicBlock.bn2", "doTraModel.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "doTraModel.BasicBlock.bn1", "doTraModel.BasicBlock.conv2", "doTraModel.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.__init__": [[44, 75], ["torch.Module.__init__", "int", "doTraModel.deconv", "doTraModel.deconv", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv", "doTraModel.BasicBlock", "doTraModel.BasicBlock", "doTraModel.conv", "doTraModel.conv", "doTraModel.BasicBlock", "torch.Identity", "torch.Identity", "torch.Identity", "doTraModel.conv", "torch.Identity", "torch.Identity", "torch.Identity", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.deconv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.deconv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "Trans", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "conv_dim", "=", "int", "(", "cfg", "[", "\"convdim\"", "]", "*", "cfg", "[", "\"netSi\"", "]", ")", "\n", "self", ".", "leak", "=", "cfg", "[", "\"tleak\"", "]", "\n", "# encoding blocks", "\n", "self", ".", "in1", "=", "cfg", "[", "\"singleIn\"", "]", "\n", "self", ".", "sym", "=", "cfg", "[", "\"sym\"", "]", "\n", "insym", "=", "cfg", "[", "\"imCh\"", "]", "*", "(", "1", "+", "2", "*", "int", "(", "cfg", "[", "\"sym\"", "]", "==", "1", ")", "+", "int", "(", "cfg", "[", "\"sym\"", "]", "==", "2", ")", "+", "3", "*", "int", "(", "cfg", "[", "\"sym\"", "]", "==", "3", ")", ")", "\n", "if", "self", ".", "in1", ":", "\n", "            ", "self", ".", "conv1", "=", "conv", "(", "insym", ",", "conv_dim", ",", "4", ")", "\n", "self", ".", "conv2", "=", "conv", "(", "conv_dim", ",", "conv_dim", "*", "2", ",", "4", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conca", "=", "cfg", "[", "\"conca\"", "]", "\n", "co", "=", "self", ".", "conca", "\n", "self", ".", "conv1", "=", "conv", "(", "insym", "*", "(", "co", "+", "1", ")", ",", "conv_dim", "//", "(", "2", "-", "co", ")", ",", "4", ")", "\n", "self", ".", "conv2", "=", "conv", "(", "conv_dim", "//", "(", "2", "-", "co", ")", ",", "conv_dim", "*", "2", "//", "(", "2", "-", "co", ")", ",", "4", ")", "\n", "\n", "# residual blocks", "\n", "", "if", "cfg", "[", "\"resB\"", "]", ":", "\n", "            ", "self", ".", "conv3", "=", "BasicBlock", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ")", "\n", "self", ".", "conv3a", "=", "BasicBlock", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ",", "3", ")", "if", "cfg", "[", "\"nExLay\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "conv4", "=", "BasicBlock", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv3", "=", "conv", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "conv3a", "=", "conv", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ",", "3", ",", "1", ",", "1", ")", "if", "cfg", "[", "\"nExLay\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "conv4", "=", "conv", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "2", ",", "3", ",", "1", ",", "1", ")", "\n", "\n", "# decoding blocks", "\n", "", "self", ".", "deconv1", "=", "deconv", "(", "conv_dim", "*", "2", ",", "conv_dim", ",", "4", ")", "\n", "self", ".", "deconv2", "=", "deconv", "(", "conv_dim", ",", "cfg", "[", "\"imCh\"", "]", ",", "4", ",", "bn", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.geto": [[76, 80], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "doTraModel.Trans.conv1", "doTraModel.Trans.conv2"], "methods", ["None"], ["", "def", "geto", "(", "self", ",", "inx", ")", ":", "\n", "        ", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv1", "(", "inx", ")", ",", "self", ".", "leak", ")", "# (?, 64, 16, 16)", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv2", "(", "out", ")", ",", "self", ".", "leak", ")", "# (?, 128, 8, 8)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.forward": [[81, 105], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.tanh", "torch.tanh", "torch.tanh", "doTraModel.Trans.geto", "doTraModel.Trans.conv3", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "doTraModel.Trans.conv4", "doTraModel.Trans.deconv1", "doTraModel.Trans.deconv2", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doTraModel.Trans.geto", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doTraModel.Trans.conv3a", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doTraModel.Trans.geto", "doTraModel.Trans.geto", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "torch.flip"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.geto", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.geto", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.geto", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.Trans.geto"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", ",", "x2", "=", "x", "\n", "if", "self", ".", "in1", ":", "\n", "            ", "if", "self", ".", "sym", ":", "\n", "                ", "xsym", "=", "torch", ".", "flip", "(", "x2", ",", "dims", "=", "(", "-", "1", ",", ")", ")", "\n", "if", "self", ".", "sym", "==", "1", ":", "x2", "=", "torch", ".", "cat", "(", "[", "x2", ",", "xsym", ",", "torch", ".", "flip", "(", "x2", ",", "dims", "=", "(", "-", "2", ",", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "sym", "==", "2", ":", "x2", "=", "torch", ".", "cat", "(", "[", "x2", ",", "torch", ".", "flip", "(", "xsym", ",", "dims", "=", "(", "-", "2", ",", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "sym", "==", "3", ":", "x2", "=", "torch", ".", "cat", "(", "[", "x2", ",", "xsym", ",", "torch", ".", "flip", "(", "x2", ",", "dims", "=", "(", "-", "2", ",", ")", ")", ",", "torch", ".", "flip", "(", "xsym", ",", "dims", "=", "(", "-", "2", ",", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "out", "=", "self", ".", "geto", "(", "x2", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "sym", ">", "0", ":", "print", "(", "\"must flip etc for each input - not implemented see above how to do it\"", ")", "\n", "if", "self", ".", "conca", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "[", "x1", ",", "x2", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "geto", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "cat", "(", "[", "self", ".", "geto", "(", "x1", ")", ",", "self", ".", "geto", "(", "x2", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv3", "(", "out", ")", ",", "self", ".", "leak", ")", "# ( \" )", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv3a", "(", "out", ")", ",", "self", ".", "leak", ")", "if", "self", ".", "cfg", "[", "\"nExLay\"", "]", "else", "out", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv4", "(", "out", ")", ",", "self", ".", "leak", ")", "# ( \" )", "\n", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "deconv1", "(", "out", ")", ",", "self", ".", "leak", ")", "# (?, 64, 16, 16)", "\n", "out", "=", "F", ".", "tanh", "(", "self", ".", "deconv2", "(", "out", ")", ")", "# (?, 3, 32, 32)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.D1.__init__": [[110, 117], ["torch.Module.__init__", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv"], ["def", "__init__", "(", "self", ",", "conv_dim", "=", "64", ",", "use_labels", "=", "False", ")", ":", "\n", "        ", "super", "(", "D1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv", "(", "1", ",", "conv_dim", ",", "4", ",", "bn", "=", "False", ")", "\n", "self", ".", "conv2", "=", "conv", "(", "conv_dim", ",", "conv_dim", "*", "2", ",", "4", ")", "\n", "self", ".", "conv3", "=", "conv", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "4", ",", "4", ")", "\n", "n_out", "=", "11", "if", "use_labels", "else", "1", "\n", "self", ".", "fc", "=", "conv", "(", "conv_dim", "*", "4", ",", "n_out", ",", "4", ",", "1", ",", "0", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.D1.forward": [[118, 124], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "doTraModel.D1.fc().squeeze", "doTraModel.D1.conv1", "doTraModel.D1.conv2", "doTraModel.D1.conv3", "doTraModel.D1.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv1", "(", "x", ")", ",", "0.05", ")", "# (?, 64, 16, 16)", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv2", "(", "out", ")", ",", "0.05", ")", "# (?, 128, 8, 8)", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv3", "(", "out", ")", ",", "0.05", ")", "# (?, 256, 4, 4)", "\n", "out", "=", "self", ".", "fc", "(", "out", ")", ".", "squeeze", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.D2.__init__": [[127, 134], ["torch.Module.__init__", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv", "doTraModel.conv"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv", "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv"], ["def", "__init__", "(", "self", ",", "conv_dim", "=", "64", ",", "use_labels", "=", "False", ")", ":", "\n", "        ", "super", "(", "D2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv", "(", "1", ",", "conv_dim", ",", "4", ",", "bn", "=", "False", ")", "\n", "self", ".", "conv2", "=", "conv", "(", "conv_dim", ",", "conv_dim", "*", "2", ",", "4", ")", "\n", "self", ".", "conv3", "=", "conv", "(", "conv_dim", "*", "2", ",", "conv_dim", "*", "4", ",", "4", ")", "\n", "n_out", "=", "11", "if", "use_labels", "else", "1", "\n", "self", ".", "fc", "=", "conv", "(", "conv_dim", "*", "4", ",", "n_out", ",", "4", ",", "1", ",", "0", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.D2.forward": [[135, 141], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "doTraModel.D2.fc().squeeze", "doTraModel.D2.conv1", "doTraModel.D2.conv2", "doTraModel.D2.conv3", "doTraModel.D2.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv1", "(", "x", ")", ",", "0.05", ")", "# (?, 64, 16, 16)", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv2", "(", "out", ")", ",", "0.05", ")", "# (?, 128, 8, 8)", "\n", "out", "=", "F", ".", "leaky_relu", "(", "self", ".", "conv3", "(", "out", ")", ",", "0.05", ")", "# (?, 256, 4, 4)", "\n", "out", "=", "self", ".", "fc", "(", "out", ")", ".", "squeeze", "(", ")", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.deconv": [[8, 12], ["torch.Sequential", "torch.ConvTranspose2d", "layers.append", "torch.BatchNorm2d"], "function", ["None"], ["def", "deconv", "(", "c_in", ",", "c_out", ",", "k_size", ",", "stride", "=", "2", ",", "pad", "=", "1", ",", "bn", "=", "True", ")", ":", "#\"\"\"Custom deconvolutional layer for simplicity.\"\"\"", "\n", "    ", "layers", "=", "[", "nn", ".", "ConvTranspose2d", "(", "c_in", ",", "c_out", ",", "k_size", ",", "stride", ",", "pad", ",", "bias", "=", "not", "bn", ")", "]", "\n", "if", "bn", ":", "layers", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "c_out", ")", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.doTraModel.conv": [[13, 17], ["torch.Sequential", "torch.Conv2d", "layers.append", "torch.BatchNorm2d"], "function", ["None"], ["", "def", "conv", "(", "c_in", ",", "c_out", ",", "k_size", ",", "stride", "=", "2", ",", "pad", "=", "1", ",", "bn", "=", "True", ")", ":", "#\"\"\"Custom convolutional layer for simplicity.\"\"\"", "\n", "    ", "layers", "=", "[", "nn", ".", "Conv2d", "(", "c_in", ",", "c_out", ",", "k_size", ",", "stride", ",", "pad", ",", "bias", "=", "not", "bn", ")", "]", "\n", "if", "bn", ":", "layers", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "c_out", ")", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.dutils.getnorm": [[11, 14], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "numpy.array().reshape", "numpy.array().reshape", "numpy.array", "numpy.array"], "function", ["None"], ["def", "getnorm", "(", "dname", ")", ":", "\n", "    ", "if", "dname", "==", "\"MNIST\"", ":", "\n", "        ", "return", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "(", "0.1307", ")", ",", "np", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ".", "cuda", "(", ")", ",", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "(", "0.3081", ")", ",", "np", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ".", "cuda", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.dutils.getFullDS": [[16, 54], ["torchvision.Compose", "dutils.getnorm", "os.makedirs", "dutils.getFullDS.loadStore"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.dutils.getnorm"], ["", "", "def", "getFullDS", "(", "cfg", ",", "ntrain", ",", "sname", ",", "cget", ")", ":", "\n", "    ", "dname", "=", "cfg", "[", "\"ds\"", "]", "[", "0", "]", "\n", "trans", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", "]", ")", "\n", "if", "dname", "==", "\"MNIST\"", ":", "\n", "        ", "cdat", "=", "torchvision", ".", "datasets", ".", "MNIST", "\n", "cfg", "[", "\"imCh\"", "]", "=", "1", "\n", "", "down", "=", "True", "\n", "cpa", "=", "\".\"", "\n", "fname", "=", "\"Mnist\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fname", "+", "\"teX\"", ")", "or", "cget", ":", "\n", "       ", "os", ".", "makedirs", "(", "cpa", ",", "exist_ok", "=", "True", ")", "\n", "def", "loadStore", "(", "isTrain", ",", "ndat", ")", ":", "\n", "            ", "trainset", "=", "cdat", "(", "root", "=", "\".\"", ",", "train", "=", "isTrain", ",", "download", "=", "down", ",", "transform", "=", "trans", ")", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "ndat", ",", "num_workers", "=", "0", ")", "# cfg[\"batchSize\"]", "\n", "ds", "=", "next", "(", "iter", "(", "train_dataset", ")", ")", "\n", "X", ",", "y", "=", "ds", "[", "0", "]", ".", "clone", "(", ")", ".", "numpy", "(", ")", ",", "ds", "[", "1", "]", ".", "clone", "(", ")", ".", "numpy", "(", ")", "\n", "print", "(", "\"Data stats\"", ",", "dname", ",", "X", ".", "shape", ",", "np", ".", "mean", "(", "X", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ")", ",", "np", ".", "std", "(", "X", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ")", ")", "\n", "if", "(", "dname", "==", "\"MNIST\"", "or", "dname", "==", "\"Fash\"", ")", "and", "cfg", "[", "\"imSi\"", "]", "!=", "28", ":", "\n", "                ", "X", "=", "[", "ndimage", ".", "zoom", "(", "X", "[", "i", ",", "0", "]", ",", "cfg", "[", "\"imSi\"", "]", "/", "28", ")", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", "]", "\n", "X", "=", "np", ".", "stack", "(", "X", ",", "axis", "=", "0", ")", "\n", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "1", ")", "\n", "", "ds", "=", "[", "X", ",", "y", "]", "\n", "ds", "=", "sklearn", ".", "utils", ".", "shuffle", "(", "*", "ds", ")", "# , random_state=cfg[\"seed\"])", "\n", "t", "=", "np", ".", "float16", "\n", "preamb", "=", "\"tr\"", "if", "isTrain", "else", "\"te\"", "\n", "with", "open", "(", "fname", "+", "preamb", "+", "\"X\"", ",", "\"wb\"", ")", "as", "f", ":", "np", ".", "save", "(", "f", ",", "ds", "[", "0", "]", ".", "astype", "(", "t", ")", ",", "allow_pickle", "=", "True", ")", "\n", "with", "open", "(", "fname", "+", "preamb", "+", "\"Y\"", ",", "\"wb\"", ")", "as", "f", ":", "np", ".", "save", "(", "f", ",", "ds", "[", "1", "]", ".", "astype", "(", "np", ".", "int16", ")", ",", "allow_pickle", "=", "True", ")", "\n", "#return trainset", "\n", "", "loadStore", "(", "True", ",", "ntrain", ")", "\n", "loadStore", "(", "False", ",", "ntrain", ")", "\n", "", "lo", "=", "lambda", "na", ":", "np", ".", "load", "(", "open", "(", "fname", "+", "na", ",", "\"rb\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "trX", ",", "trY", "=", "lo", "(", "\"trX\"", ")", ",", "lo", "(", "\"trY\"", ")", "\n", "teX", ",", "teY", "=", "lo", "(", "\"teX\"", ")", ",", "lo", "(", "\"teY\"", ")", "\n", "\n", "norm", "=", "getnorm", "(", "dname", ")", "\n", "trX", "=", "(", "trX", "-", "norm", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "/", "norm", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "teX", "=", "(", "teX", "-", "norm", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "/", "norm", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "(", "trX", ",", "trY", ")", ",", "(", "teX", ",", "teY", ")", "#, None,norm", "\n", "", ""]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.G.__init__": [[19, 29], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "numpy.array", "latAEModels.lin", "len", "len"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.lin"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "lw", "=", "cfg", "[", "\"aez\"", "]", "*", "np", ".", "array", "(", "[", "1", "]", "+", "cfg", "[", "\"glay\"", "]", "+", "[", "1", "]", ")", "\n", "self", ".", "laleak", "=", "cfg", "[", "\"laLeak\"", "]", "\n", "\n", "lins", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "lw", ")", "-", "1", ")", ":", "\n", "            ", "dobn", "=", "cfg", "[", "\"gben\"", "]", "and", "not", "(", "cfg", "[", "\"gben\"", "]", "==", "2", "and", "(", "j", "+", "1", "==", "len", "(", "lw", ")", "-", "1", ")", ")", "\n", "lins", "+=", "lin", "(", "lw", "[", "j", "]", ",", "lw", "[", "j", "+", "1", "]", ",", "dobn", ",", "cfg", "[", "\"gdrop\"", "]", "[", "j", "]", ")", "\n", "", "self", ".", "lays", "=", "nn", ".", "Sequential", "(", "*", "lins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.G.forward": [[30, 37], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "lays", "[", ":", "-", "1", "]", ":", "\n", "            ", "x", "=", "F", ".", "leaky_relu", "(", "l", "(", "x", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "lays", "[", "-", "1", "]", "(", "x", ")", "\n", "if", "self", ".", "laleak", ":", "x", "=", "F", ".", "leaky_relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.D.__init__": [[39, 50], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "numpy.array", "latAEModels.lin", "len", "len"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.lin"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "use_labels", "=", "False", ")", ":", "\n", "        ", "super", "(", "D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_out", "=", "11", "if", "use_labels", "else", "1", "\n", "lw", "=", "cfg", "[", "\"aez\"", "]", "*", "np", ".", "array", "(", "[", "1", "]", "+", "cfg", "[", "\"dlay\"", "]", "+", "[", "1", "]", ")", "\n", "lw", "[", "-", "1", "]", "=", "n_out", "\n", "lins", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "lw", ")", "-", "1", ")", ":", "\n", "            ", "dobn", "=", "cfg", "[", "\"dben\"", "]", "and", "not", "(", "cfg", "[", "\"dben\"", "]", "==", "2", "and", "(", "j", "+", "1", "==", "len", "(", "lw", ")", "-", "1", ")", ")", "\n", "lins", "+=", "lin", "(", "lw", "[", "j", "]", ",", "lw", "[", "j", "+", "1", "]", ",", "dobn", ",", "cfg", "[", "\"ddrop\"", "]", "[", "j", "]", ")", "\n", "\n", "", "self", ".", "lays", "=", "nn", ".", "Sequential", "(", "*", "lins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.D.forward": [[51, 56], ["torch.leaky_relu", "torch.leaky_relu", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "lays", "[", ":", "-", "1", "]", ":", "\n", "            ", "x", "=", "F", ".", "leaky_relu", "(", "l", "(", "x", ")", ")", "\n", "", "x", "=", "self", ".", "lays", "[", "-", "1", "]", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.LinCl.__init__": [[59, 68], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "latAEModels.lin", "list", "len", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.lin"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "LinCl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "lw", "=", "[", "cfg", "[", "\"aez\"", "]", "]", "+", "list", "(", "cfg", "[", "\"aez\"", "]", "*", "np", ".", "array", "(", "cfg", "[", "\"cllay\"", "]", ")", ")", "+", "[", "cfg", "[", "\"ds\"", "]", "[", "1", "]", "]", "\n", "\n", "lins", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "lw", ")", "-", "1", ")", ":", "\n", "            ", "dobn", "=", "cfg", "[", "\"clben\"", "]", "and", "not", "(", "cfg", "[", "\"clben\"", "]", "==", "2", "and", "(", "j", "+", "1", "==", "len", "(", "lw", ")", "-", "1", ")", ")", "\n", "lins", "+=", "lin", "(", "lw", "[", "j", "]", ",", "lw", "[", "j", "+", "1", "]", ",", "dobn", ",", "cfg", "[", "\"cldrop\"", "]", "[", "j", "]", ")", "\n", "", "self", ".", "lays", "=", "nn", ".", "Sequential", "(", "*", "lins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.LinCl.forward": [[69, 74], ["torch.leaky_relu", "torch.leaky_relu", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "lays", "[", ":", "-", "1", "]", ":", "\n", "            ", "x", "=", "F", ".", "leaky_relu", "(", "l", "(", "x", ")", ")", "\n", "", "x", "=", "self", ".", "lays", "[", "-", "1", "]", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.latAEModels.lin": [[11, 17], ["layers.append", "layers.append", "torch.Linear", "layers.append", "torch.Dropout", "torch.BatchNorm1d"], "function", ["None"], ["def", "lin", "(", "c_in", ",", "c_out", ",", "bn", "=", "True", ",", "dr", "=", "False", ")", ":", "# \"\"\"Custom convolutional layer for simplicity.\"\"\"", "\n", "    ", "layers", "=", "[", "]", "\n", "if", "dr", ">", "0", ":", "layers", ".", "append", "(", "nn", ".", "Dropout", "(", "dr", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "c_in", ",", "c_out", ",", "bias", "=", "not", "bn", ")", ")", "\n", "if", "bn", ":", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "c_out", ")", ")", "\n", "return", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AEDisc.__init__": [[19, 35], ["torch.nn.Module.__init__", "int", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_size", "=", "(", "1", ",", "32", ",", "32", ")", ")", ":", "\n", "            ", "super", "(", "AEDisc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "output_size", "=", "1", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "channel_mult", "=", "int", "(", "64", "*", "cfg", "[", "\"netSi\"", "]", ")", "\n", "bn", "=", "lambda", "x", ":", "nn", ".", "BatchNorm2d", "(", "x", ")", "if", "cfg", "[", "\"aeganbn\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "bn1d", "=", "lambda", "x", ":", "nn", ".", "BatchNorm1d", "(", "x", ")", "if", "cfg", "[", "\"aeganbn\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "slope", "=", "0.2", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "=", "input_size", "[", "0", "]", ",", "out_channels", "=", "self", ".", "channel_mult", "*", "1", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "1", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "1", ",", "self", ".", "channel_mult", "*", "2", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "2", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "2", ",", "self", ".", "channel_mult", "*", "4", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "4", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "4", ",", "self", ".", "channel_mult", "*", "8", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "8", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "8", ",", "self", ".", "channel_mult", "*", "8", ",", "3", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "8", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", "]", ")", "\n", "# self.flat_fts = self.get_flat_fts(self.conv)", "\n", "self", ".", "nin", "=", "self", ".", "channel_mult", "*", "8", "\n", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "nin", ",", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AEDisc.forward": [[36, 41], ["enumerate", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "AEModels.AEDisc.linear", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "il", ",", "l", "in", "enumerate", "(", "self", ".", "conv", ")", ":", "\n", "            ", "x", "=", "l", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "# x.view(-1, self.flat_fts)", "\n", "return", "self", ".", "linear", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.CNN_Encoder.__init__": [[45, 61], ["torch.nn.Module.__init__", "int", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "bn1d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "int"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_size", "=", "(", "1", ",", "32", ",", "32", ")", ")", ":", "\n", "        ", "super", "(", "CNN_Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "output_size", "=", "cfg", "[", "\"aez\"", "]", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "channel_mult", "=", "int", "(", "64", "*", "(", "cfg", "[", "\"netSi\"", "]", "+", "0.25", "*", "int", "(", "\"F\"", "in", "cfg", "[", "\"ds\"", "]", "[", "0", "]", ")", ")", ")", "\n", "bn", "=", "lambda", "x", ":", "nn", ".", "BatchNorm2d", "(", "x", ")", "if", "cfg", "[", "\"aebn\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "bn1d", "=", "lambda", "x", ":", "nn", ".", "BatchNorm1d", "(", "x", ")", "if", "cfg", "[", "\"aebn\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "slope", "=", "0.05", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "=", "input_size", "[", "0", "]", ",", "out_channels", "=", "self", ".", "channel_mult", "*", "1", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "1", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "1", ",", "self", ".", "channel_mult", "*", "2", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "2", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "2", ",", "self", ".", "channel_mult", "*", "4", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "4", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "4", ",", "self", ".", "channel_mult", "*", "8", ",", "4", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "8", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "channel_mult", "*", "8", ",", "self", ".", "channel_mult", "*", "8", ",", "3", ",", "2", ",", "1", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "8", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ",", "inplace", "=", "True", ")", "]", ")", "\n", "#self.flat_fts = self.get_flat_fts(self.conv)", "\n", "self", ".", "nin", "=", "self", ".", "channel_mult", "*", "8", "\n", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "nin", ",", "output_size", ")", ",", "bn1d", "(", "output_size", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.CNN_Encoder.forward": [[63, 68], ["enumerate", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "AEModels.CNN_Encoder.linear", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "il", ",", "l", "in", "enumerate", "(", "self", ".", "conv", ")", ":", "\n", "            ", "x", "=", "l", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "#x.view(-1, self.flat_fts)", "\n", "return", "self", ".", "linear", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.CNN_Decoder.__init__": [[70, 83], ["torch.nn.Module.__init__", "int", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "bn", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "int"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "CNN_Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "cfg", "[", "\"aez\"", "]", "#cfg[\"aecfg\"][\"esize\"]", "\n", "self", ".", "channel_mult", "=", "int", "(", "64", "*", "(", "cfg", "[", "\"netSi\"", "]", "+", "0.25", "*", "int", "(", "\"F\"", "in", "cfg", "[", "\"ds\"", "]", "[", "0", "]", ")", ")", ")", "\n", "self", ".", "fc_output_dim", "=", "self", ".", "channel_mult", "*", "16", "#self.input_dim#int(64*cfg[\"aecfg\"][\"netSi\"]) #cfg[\"aecfg\"][\"esize\"]#128#256", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "fc_output_dim", ")", ",", "nn", ".", "BatchNorm1d", "(", "self", ".", "fc_output_dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "bn", "=", "lambda", "x", ":", "nn", ".", "BatchNorm2d", "(", "x", ")", "if", "cfg", "[", "\"aebn\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "slope", "=", "0.05", "\n", "self", ".", "deconv", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "ConvTranspose2d", "(", "self", ".", "fc_output_dim", ",", "self", ".", "channel_mult", "*", "8", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "8", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "channel_mult", "*", "8", ",", "self", ".", "channel_mult", "*", "4", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "4", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "channel_mult", "*", "4", ",", "self", ".", "channel_mult", "*", "2", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "2", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "channel_mult", "*", "2", ",", "self", ".", "channel_mult", "*", "1", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "bn", "(", "self", ".", "channel_mult", "*", "1", ")", ",", "nn", ".", "LeakyReLU", "(", "slope", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "self", ".", "channel_mult", "*", "1", ",", "cfg", "[", "\"imCh\"", "]", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.CNN_Decoder.forward": [[84, 89], ["AEModels.CNN_Decoder.fc", "l.view", "torch.nn.functional.tanh", "torch.nn.functional.tanh", "torch.nn.functional.tanh", "torch.nn.functional.tanh", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "fc_output_dim", ",", "1", ",", "1", ")", "\n", "for", "l", "in", "self", ".", "deconv", ":", "x", "=", "l", "(", "x", ")", "\n", "return", "F", ".", "tanh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.__init__": [[91, 95], ["torch.nn.Module.__init__", "AEModels.CNN_Encoder", "AEModels.CNN_Decoder"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "AENetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "CNN_Encoder", "(", "cfg", ",", "input_size", "=", "(", "cfg", "[", "\"imCh\"", "]", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "decoder", "=", "CNN_Decoder", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.enc": [[96, 97], ["AEModels.AENetwork.encoder"], "methods", ["None"], ["", "def", "enc", "(", "self", ",", "x", ")", ":", "return", "self", ".", "encoder", "(", "x", ")", "\n", "def", "dec", "(", "self", ",", "z", ")", ":", "return", "self", ".", "decoder", "(", "z", ")", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.dec": [[97, 98], ["AEModels.AENetwork.decoder"], "methods", ["None"], ["def", "dec", "(", "self", ",", "z", ")", ":", "return", "self", ".", "decoder", "(", "z", ")", "\n", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.forward": [[98, 101], ["AEModels.AENetwork.enc", "AEModels.AENetwork.dec"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.enc", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.AENetwork.dec"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "enc", "(", "x", ")", "#.view(-1, 784))", "\n", "return", "self", ".", "dec", "(", "z", ")", ",", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDat": [[102, 116], ["netAE.eval", "torch.autocast", "numpy.concatenate", "numpy.concatenate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.mean", "numpy.std", "data[].cuda", "netAE", "aencx.append", "aency.append", "tosave.detach().cpu().numpy", "numpy.copy", "data[].cpu().numpy", "tosave.detach().cpu", "data[].cpu", "tosave.detach"], "function", ["None"], ["", "", "def", "getAEDat", "(", "netAE", ",", "dataset", ",", "encoded", "=", "True", ")", ":", "\n", "    ", "netAE", ".", "eval", "(", ")", "\n", "aencx", "=", "[", "]", "\n", "aency", "=", "[", "]", "\n", "def", "nor", "(", "x", ")", ":", "return", "(", "x", "-", "np", ".", "mean", "(", "x", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", ")", "/", "(", "np", ".", "std", "(", "x", ",", "axis", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdims", "=", "True", ")", "+", "1e-7", ")", "\n", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "          ", "for", "i", ",", "data", "in", "enumerate", "(", "dataset", ")", ":", "\n", "             ", "x", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", "\n", "selfx", ",", "code", "=", "netAE", "(", "x", ")", "\n", "tosave", "=", "code", "if", "encoded", "else", "selfx", "\n", "aencx", ".", "append", "(", "tosave", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "aency", ".", "append", "(", "np", ".", "copy", "(", "data", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "", "", "return", "np", ".", "concatenate", "(", "aencx", ",", "axis", "=", "0", ")", ",", "np", ".", "concatenate", "(", "aency", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDatIter": [[117, 123], ["AEModels.getAEDat", "cds", "AEModels.getAEDat", "cds"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDat", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDat"], ["", "def", "getAEDatIter", "(", "netAE", ",", "trdata", ",", "tedata", ",", "encoded", "=", "True", ",", "cds", "=", "None", ")", ":", "\n", "    ", "aetrX", ",", "aetrY", "=", "getAEDat", "(", "netAE", ",", "trdata", ",", "encoded", "=", "encoded", ")", "\n", "aetr_iter", "=", "cds", "(", "aetrX", ",", "aetrY", ",", "True", ",", "False", ")", "\n", "aeteX", ",", "aeteY", "=", "getAEDat", "(", "netAE", ",", "tedata", ",", "encoded", "=", "encoded", ")", "\n", "aete_iter", "=", "cds", "(", "aeteX", ",", "aeteY", ",", "False", ",", "False", ")", "\n", "return", "aetr_iter", ",", "aete_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.runAE": [[125, 131], ["getM", "AEModels.getAEDat", "AEModels.getAEDat"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDat", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEDat"], ["", "def", "runAE", "(", "cfg", ",", "dataset", ",", "tedataset", ",", "sname", ",", "cget", ",", "picname", ")", ":", "\n", "    ", "getM", "=", "getAEModel", "\n", "netAE", ",", "acfg", "=", "getM", "(", "cfg", ",", "dataset", ",", "sname", ",", "cget", ",", "picname", ")", "\n", "trds", ",", "teds", "=", "getAEDat", "(", "netAE", ",", "dataset", ")", ",", "getAEDat", "(", "netAE", ",", "tedataset", ")", "\n", "#imgutil.makeAndStore(trds[:64], trds[:64], cfg[\"bFolder\"] + \"samples/\", \"AE\" + picname + fs(cfg) + \".png\")", "\n", "return", "trds", ",", "teds", ",", "acfg", ",", "netAE", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay": [[132, 136], ["print", "numpy.round"], "function", ["None"], ["", "def", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ")", ":", "\n", "    ", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", "and", "(", "epoch", "+", "1", ")", "%", "(", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "//", "3", "+", "ccf", "[", "\"opt\"", "]", "[", "1", "]", "//", "10", "+", "2", ")", "==", "0", ":", "\n", "        ", "for", "p", "in", "optimizerCl", ".", "param_groups", ":", "p", "[", "'lr'", "]", "*=", "0.1", "\n", "print", "(", "\"  D\"", ",", "np", ".", "round", "(", "optimizerCl", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.getAEModel": [[137, 209], ["AENetwork().cuda", "print", "torch.GradScaler", "range", "AENetwork().cuda.eval", "AEDisc().cuda", "torch.Adam", "torch.Adam", "torch.nn.BCEWithLogitsLoss", "torch.SGD", "torch.nn.MSELoss", "AENetwork().cuda.train", "enumerate", "AEModels.decay", "AENetwork().cuda.eval", "AEModels.AENetwork", "AEDisc().cuda.parameters", "AENetwork().cuda.parameters", "AENetwork().cuda.parameters", "torch.Adam", "print", "numpy.isnan", "AEModels.AEDisc", "AENetwork().cuda.parameters", "torch.autocast", "optim.Adam.zero_grad", "data[].cuda", "AENetwork().cuda.", "loss", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "tca.GradScaler.update", "ulo", "numpy.round", "print", "t.item", "t.item", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "AEDisc().cuda.zero_grad", "data[].cuda.size", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "AEDisc().cuda.view", "nn.BCEWithLogitsLoss.", "tca.GradScaler.scale().backward", "torch.full().cuda.fill_", "AEDisc().cuda.view", "nn.BCEWithLogitsLoss.", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "optim.Adam.zero_grad", "torch.full().cuda.fill_", "AENetwork().cuda.", "AEDisc().cuda.view", "nn.BCEWithLogitsLoss.", "tca.GradScaler.scale().backward", "tca.GradScaler.step", "tca.GradScaler.update", "ulo", "ulo", "ulo", "numpy.array", "tca.GradScaler.scale", "torch.full", "torch.full", "torch.full", "torch.full", "AEDisc().cuda.", "tca.GradScaler.scale", "AEDisc().cuda.", "tca.GradScaler.scale", "AEDisc().cuda.", "tca.GradScaler.scale", "outAE.detach"], "function", ["home.repos.pwc.inspect_result.johntailor_dotra.None.optCycEncoded.Solver.train", "home.repos.pwc.inspect_result.johntailor_dotra.None.AEModels.decay"], ["", "", "def", "getAEModel", "(", "cfg", ",", "train_dataset", ",", "sname", ",", "cget", ",", "picname", "=", "\"\"", ")", ":", "#Co,val_datasetMa,resFolder", "\n", "    ", "ccf", "=", "cfg", "[", "\"aecfg\"", "]", "\n", "netAE", "=", "AENetwork", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "if", "cfg", "[", "\"aeGAN\"", "]", "[", "0", "]", ":", "\n", "        ", "netD", "=", "AEDisc", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "optimizerD", "=", "optim", ".", "Adam", "(", "netD", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", "[", "\"aeGAN\"", "]", "[", "1", "]", "[", "\"lr\"", "]", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "optimizerG", "=", "optim", ".", "Adam", "(", "netAE", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", "[", "\"aeGAN\"", "]", "[", "1", "]", "[", "\"lr\"", "]", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "real_label", ",", "fake_label", "=", "1.", ",", "0.", "\n", "gloss", ",", "drloss", ",", "dfloss", "=", "0", ",", "0", ",", "0", "\n", "\n", "", "if", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"S\"", ":", "optimizerCl", "=", "optim", ".", "SGD", "(", "netAE", ".", "parameters", "(", ")", ",", "lr", "=", "ccf", "[", "\"opt\"", "]", "[", "1", "]", ",", "momentum", "=", "0.8", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", ")", "\n", "elif", "ccf", "[", "\"opt\"", "]", "[", "0", "]", "==", "\"A\"", ":", "optimizerCl", "=", "optim", ".", "Adam", "(", "netAE", ".", "parameters", "(", ")", ",", "ccf", "[", "\"opt\"", "]", "[", "1", "]", ",", "weight_decay", "=", "ccf", "[", "\"opt\"", "]", "[", "2", "]", ")", "\n", "else", ":", "\"Error opt not found\"", "\n", "closs", ",", "trep", ",", "loss", "=", "0", ",", "cfg", "[", "\"epA\"", "]", ",", "nn", ".", "MSELoss", "(", ")", "#nn.CrossEntropyLoss()", "\n", "print", "(", "\"Train AE\"", ")", "\n", "scaler", "=", "tca", ".", "GradScaler", "(", ")", "\n", "ulo", "=", "lambda", "x", ",", "t", ",", "e", ":", "0.97", "*", "x", "+", "0.03", "*", "t", ".", "item", "(", ")", "if", "e", ">", "1", "else", "0.85", "*", "x", "+", "0.15", "*", "t", ".", "item", "(", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "for", "epoch", "in", "range", "(", "trep", ")", ":", "\n", "            ", "netAE", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_dataset", ")", ":", "\n", "               ", "with", "tca", ".", "autocast", "(", ")", ":", "\n", "                ", "optimizerCl", ".", "zero_grad", "(", ")", "\n", "x", "=", "data", "[", "0", "]", ".", "cuda", "(", ")", "\n", "outAE", ",", "lo", "=", "netAE", "(", "x", ")", "\n", "errD_real", "=", "loss", "(", "torch", ".", "flatten", "(", "outAE", ",", "1", ")", ",", "torch", ".", "flatten", "(", "x", ",", "1", ")", ")", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerCl", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "if", "cfg", "[", "\"aeGAN\"", "]", "[", "0", "]", ":", "\n", "## Train with all-real batch", "\n", "                    ", "netD", ".", "zero_grad", "(", ")", "\n", "b_size", "=", "x", ".", "size", "(", "0", ")", "\n", "label", "=", "torch", ".", "full", "(", "(", "b_size", ",", ")", ",", "real_label", ",", "dtype", "=", "torch", ".", "float", ")", ".", "cuda", "(", ")", "\n", "outreal", "=", "netD", "(", "x", ")", ".", "view", "(", "-", "1", ")", "\n", "errD_real", "=", "criterion", "(", "outreal", ",", "label", ")", "\n", "scaler", ".", "scale", "(", "errD_real", ")", ".", "backward", "(", ")", "\n", "\n", "## Train with all-fake batch", "\n", "label", ".", "fill_", "(", "fake_label", ")", "\n", "outfake", "=", "netD", "(", "outAE", ".", "detach", "(", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "errD_fake", "=", "criterion", "(", "outfake", ",", "label", ")", "\n", "scaler", ".", "scale", "(", "errD_fake", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerD", ")", "\n", "\n", "# (2) Update G network: maximize log(D(G(z)))", "\n", "optimizerG", ".", "zero_grad", "(", ")", "\n", "label", ".", "fill_", "(", "real_label", ")", "# fake labels are real for generator cost", "\n", "outAE", ",", "_", "=", "netAE", "(", "x", ")", "\n", "outfake", "=", "netD", "(", "outAE", ")", ".", "view", "(", "-", "1", ")", "\n", "errG", "=", "criterion", "(", "outfake", ",", "label", ")", "\n", "scaler", ".", "scale", "(", "errG", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "step", "(", "optimizerG", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "\n", "gloss", "=", "ulo", "(", "gloss", ",", "errG", ",", "epoch", ")", "\n", "drloss", "=", "ulo", "(", "drloss", ",", "errD_real", ",", "epoch", ")", "\n", "dfloss", "=", "ulo", "(", "dfloss", ",", "errD_fake", ",", "epoch", ")", "\n", "\n", "", "closs", "=", "ulo", "(", "closs", ",", "errD_real", ",", "epoch", ")", "\n", "", "", "decay", "(", "ccf", ",", "epoch", ",", "optimizerCl", ")", "\n", "netAE", ".", "eval", "(", ")", "\n", "if", "(", "epoch", "%", "2", "==", "0", "and", "epoch", "<=", "10", ")", "or", "(", "epoch", "%", "10", "==", "0", "and", "epoch", ">", "10", ")", ":", "\n", "                ", "print", "(", "epoch", ",", "\"AE\"", ",", "np", ".", "round", "(", "np", ".", "array", "(", "[", "closs", "]", "+", "(", "[", "gloss", ",", "drloss", ",", "dfloss", "]", "if", "cfg", "[", "\"aeGAN\"", "]", "[", "0", "]", "else", "[", "]", ")", ")", ",", "5", ")", ",", "cfg", "[", "\"pr\"", "]", ")", "\n", "if", "np", ".", "isnan", "(", "closs", ")", ":", "\n", "                    ", "print", "(", "\"Failed!!!\"", ")", "\n", "return", "None", ",", "None", "\n", "", "", "", "lcfg", "=", "{", "\"AELo\"", ":", "closs", "}", "\n", "if", "cfg", "[", "\"aeGAN\"", "]", "[", "0", "]", ":", "lcfg", "=", "{", "**", "lcfg", ",", "**", "{", "\"glo\"", ":", "gloss", ",", "\"drlo\"", ":", "drloss", ",", "\"dflo\"", ":", "dfloss", "}", "}", "\n", "netAE", ".", "eval", "(", ")", "\n", "return", "netAE", ",", "lcfg", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.BBlock.__init__": [[11, 17], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "ker", "=", "3", ",", "down", "=", "True", ",", "pad", "=", "1", ")", ":", "\n", "        ", "super", "(", "BBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "ker", ",", "stride", "=", "1", ",", "padding", "=", "pad", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "mp", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ")", "if", "down", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.BBlock.forward": [[18, 24], ["classifierModels.BBlock.conv1", "classifierModels.BBlock.bn", "classifierModels.BBlock.relu", "classifierModels.BBlock.mp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "#out = self.ident(out)", "\n", "out", "=", "self", ".", "bn", "(", "out", ")", "#out = self.identBefR(out)", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "#out = self.identBefS(out)", "\n", "out", "=", "self", ".", "mp", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.worNet.__init__": [[27, 62], ["torch.Module.__init__", "classifierModels.worNet.__init__.getConv"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "worNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "cf", "=", "cfg", "[", "\"clcfg\"", "]", "\n", "tr", "=", "lambda", "x", ":", "max", "(", "1", ",", "int", "(", "np", ".", "round", "(", "x", "*", "cfg", "[", "\"netSi\"", "]", ")", ")", ")", "\n", "#self.addN=cfg[\"addN\"]        self.oneh = cfg[\"onehot\"]", "\n", "self", ".", "in_channels", "=", "cfg", "[", "\"imCh\"", "]", "\n", "in_channels", "=", "self", ".", "in_channels", "\n", "self", ".", "is11", "=", "1", "if", "\"11\"", "in", "cf", "[", "\"netT\"", "]", "else", "0", "\n", "#chans = [in_channels, 32, 64, 64,  128, 128, 256, 256, 512, 512] if self.is11 else [in_channels, 32, 64, 128, 256, 512]", "\n", "chans", "=", "[", "in_channels", ",", "64", ",", "64", ",", "64", ",", "128", ",", "128", ",", "256", ",", "256", ",", "512", ",", "512", "]", "if", "self", ".", "is11", "else", "[", "in_channels", ",", "64", ",", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "\n", "i", "=", "-", "1", "\n", "def", "getConv", "(", "ker", "=", "cfg", "[", "\"ker\"", "]", ",", "down", "=", "True", ")", ":", "\n", "            ", "nonlocal", "i", "\n", "i", "+=", "1", "#return nn.Sequential(*[nn.Conv2d(in_channels=inoffs[i]+ (tr(chans[i]) if i>0 else chans[i]) , out_channels=tr(chans[i+1]), kernel_size=(ker, ker), padding=ker > 1), nn.BatchNorm2d(tr(chans[i+1])), relu] + ([mp] if down else []))", "\n", "return", "BBlock", "(", "(", "tr", "(", "chans", "[", "i", "]", ")", "if", "i", ">", "0", "else", "chans", "[", "i", "]", ")", ",", "tr", "(", "chans", "[", "i", "+", "1", "]", ")", ",", "ker", "=", "ker", ",", "down", "=", "down", ",", "pad", "=", "(", "ker", "-", "1", ")", "//", "2", ")", "#inoffs[i]+", "\n", "\n", "#if self.is11: self.conv0a = nn.Identity()", "\n", "", "self", ".", "conv0", "=", "getConv", "(", ")", "\n", "if", "self", ".", "is11", ":", "self", ".", "conv1a", "=", "getConv", "(", "down", "=", "False", ")", "\n", "self", ".", "conv1", "=", "getConv", "(", ")", "\n", "if", "self", ".", "is11", ":", "self", ".", "conv2a", "=", "getConv", "(", "down", "=", "False", ")", "\n", "self", ".", "conv2", "=", "getConv", "(", ")", "\n", "if", "self", ".", "is11", ":", "self", ".", "conv3a", "=", "getConv", "(", "ker", "=", "3", ",", "down", "=", "False", ")", "\n", "self", ".", "conv3", "=", "getConv", "(", "ker", "=", "3", ")", "\n", "if", "self", ".", "is11", ":", "self", ".", "conv4a", "=", "getConv", "(", "down", "=", "False", ",", "ker", "=", "3", ")", "\n", "self", ".", "conv4", "=", "getConv", "(", "ker", "=", "3", ")", "\n", "\n", "self", ".", "allays", "=", "[", "self", ".", "conv0", ",", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "conv3", ",", "self", ".", "conv4", "]", "\n", "if", "self", ".", "is11", ":", "self", ".", "allays", "=", "[", "self", ".", "conv0", ",", "self", ".", "conv1a", ",", "self", ".", "conv1", ",", "self", ".", "conv2a", ",", "self", ".", "conv2", ",", "self", ".", "conv3a", ",", "self", ".", "conv3", ",", "self", ".", "conv4a", ",", "self", ".", "conv4", "]", "\n", "i", ",", "ker", "=", "-", "1", ",", "1", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveMaxPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "if", "cfg", "[", "\"drop\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "pred", "=", "nn", ".", "Linear", "(", "tr", "(", "512", ")", ",", "tr", "(", "128", ")", ")", "if", "cfg", "[", "\"twoLin\"", "]", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "pred2", "=", "nn", ".", "Linear", "(", "tr", "(", "128", ")", ",", "cfg", "[", "\"ds\"", "]", "[", "1", "]", ")", "if", "cfg", "[", "\"twoLin\"", "]", "else", "nn", ".", "Linear", "(", "tr", "(", "512", ")", ",", "cfg", "[", "\"ds\"", "]", "[", "1", "]", ")", "\n", "#self.k=0", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.worNet.forward": [[64, 73], ["enumerate", "classifierModels.worNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "classifierModels.worNet.dropout", "classifierModels.worNet.pred", "classifierModels.worNet.pred2", "l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# import imgutil as imgu        # print(np.sum(np.abs(x.cpu().numpy())))        # imgu.makeAndStore(x.cpu().numpy(),x.cpu().numpy(),\"Img\",str(self.k)+\".png\")        # self.k+=1        # self.k=self.k%10", "\n", "        ", "for", "il", ",", "l", "in", "enumerate", "(", "self", ".", "allays", ")", ":", "x", "=", "l", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "start_dim", "=", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "pred", "(", "x", ")", "\n", "x", "=", "self", ".", "pred2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__": [[84, 94], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "numpy.array", "classifierModels.lin", "len", "len"], "methods", ["home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.__init__", "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.lin"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "linNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_out", "=", "cfg", "[", "\"ds\"", "]", "[", "1", "]", "\n", "lw", "=", "cfg", "[", "\"aez\"", "]", "*", "np", ".", "array", "(", "[", "1", "]", "+", "cfg", "[", "\"llay\"", "]", "+", "[", "1", "]", ")", "\n", "lw", "[", "-", "1", "]", "=", "n_out", "\n", "lins", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "lw", ")", "-", "1", ")", ":", "\n", "            ", "dobn", "=", "cfg", "[", "\"lben\"", "]", "and", "not", "(", "cfg", "[", "\"dben\"", "]", "==", "2", "and", "(", "j", "+", "1", "==", "len", "(", "lw", ")", "-", "1", ")", ")", "\n", "lins", "+=", "lin", "(", "lw", "[", "j", "]", ",", "lw", "[", "j", "+", "1", "]", ",", "dobn", ",", "cfg", "[", "\"ldrop\"", "]", "[", "j", "]", ")", "\n", "", "self", ".", "lays", "=", "nn", ".", "Sequential", "(", "*", "lins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.linNet.forward": [[95, 98], ["classifierModels.linNet.lays"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "lays", "(", "x", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.johntailor_dotra.None.classifierModels.lin": [[75, 82], ["layers.append", "layers.append", "layers.append", "torch.Linear", "layers.append", "torch.ReLU", "torch.Dropout", "torch.BatchNorm1d"], "function", ["None"], ["", "", "def", "lin", "(", "c_in", ",", "c_out", ",", "bn", "=", "True", ",", "dr", "=", "False", ")", ":", "# \"\"\"Custom convolutional layer for simplicity.\"\"\"", "\n", "    ", "layers", "=", "[", "]", "\n", "if", "dr", ">", "0", ":", "layers", ".", "append", "(", "nn", ".", "Dropout", "(", "dr", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "c_in", ",", "c_out", ",", "bias", "=", "not", "bn", ")", ")", "\n", "if", "bn", ":", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "c_out", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "return", "layers", "\n", "\n"]]}