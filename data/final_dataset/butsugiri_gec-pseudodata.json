{"home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.get_args": [[17, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'my script'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "'-i'", ",", "default", "=", "None", ",", "help", "=", "'files to read, if empty, stdin is used'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "'-o'", ",", "required", "=", "True", ",", "type", "=", "os", ".", "path", ".", "abspath", ",", "\n", "help", "=", "'path to output dir'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_long_sent": [[26, 32], ["line.split", "len"], "function", ["None"], ["", "def", "remove_long_sent", "(", "line", ",", "threshold", "=", "80", ")", ":", "\n", "    ", "tokens", "=", "line", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "tokens", ")", ">", "threshold", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_short_sent": [[34, 40], ["line.split", "len"], "function", ["None"], ["", "", "def", "remove_short_sent", "(", "line", ",", "threshold", "=", "2", ")", ":", "\n", "    ", "tokens", "=", "line", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "tokens", ")", "<=", "threshold", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_too_many_puncts": [[42, 51], ["line.split", "len", "len"], "function", ["None"], ["", "", "def", "remove_too_many_puncts", "(", "line", ",", "thresh_ratio", "=", "0.20", ")", ":", "\n", "    ", "tokens", "=", "line", ".", "split", "(", "' '", ")", "\n", "n_puncs", "=", "len", "(", "[", "t", "for", "t", "in", "tokens", "if", "t", "in", "SYMBOLS", "]", ")", "\n", "n_total", "=", "len", "(", "tokens", ")", "\n", "ratio", "=", "(", "n_puncs", "/", "n_total", ")", "\n", "if", "ratio", ">=", "thresh_ratio", "and", "n_total", ">=", "10", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_nonascii_chars": [[53, 59], ["len", "len"], "function", ["None"], ["", "", "def", "remove_nonascii_chars", "(", "line", ")", ":", "\n", "    ", "filterred", "=", "''", ".", "join", "(", "c", "for", "c", "in", "line", "if", "c", "in", "ASCII_CHARS", ")", "\n", "if", "len", "(", "filterred", ")", "<", "len", "(", "line", ")", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_consecutive_whitespace": [[61, 66], ["re.search"], "function", ["None"], ["", "", "def", "remove_consecutive_whitespace", "(", "line", ")", ":", "\n", "    ", "if", "re", ".", "search", "(", "r'\\s{3,}'", ",", "line", ")", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_too_many_digits_sentence": [[68, 79], ["len", "re.findall", "line.split", "len"], "function", ["None"], ["", "", "def", "remove_too_many_digits_sentence", "(", "line", ")", ":", "\n", "    ", "total_tokens", "=", "len", "(", "line", ".", "split", "(", ")", ")", "\n", "match", "=", "re", ".", "findall", "(", "r'\\s\\d[\\d,\\/]*\\s'", ",", "line", ")", "\n", "if", "not", "match", ":", "\n", "        ", "return", "line", "\n", "", "else", ":", "\n", "        ", "n_digit_tokens", "=", "len", "(", "match", ")", "\n", "if", "n_digit_tokens", "/", "total_tokens", ">", "0.10", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.main": [[81, 117], ["pathlib.Path", "logzero.logger.info", "open", "open", "remove_too_many_digits_sentence.strip", "remove_dirty_examples.remove_long_sent", "remove_dirty_examples.remove_short_sent", "remove_dirty_examples.remove_too_many_puncts", "remove_dirty_examples.remove_nonascii_chars", "remove_dirty_examples.remove_consecutive_whitespace", "remove_dirty_examples.remove_too_many_digits_sentence", "fo.write", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_long_sent", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_short_sent", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_too_many_puncts", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_nonascii_chars", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_consecutive_whitespace", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.remove_dirty_examples.remove_too_many_digits_sentence"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "dest", "=", "Path", "(", "args", ".", "output", ",", "*", "Path", "(", "args", ".", "input", ")", ".", "parts", "[", "-", "1", ":", "]", ")", "\n", "logger", ".", "info", "(", "'Processing: {}'", ".", "format", "(", "args", ".", "input", ")", ")", "\n", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "fi", ",", "open", "(", "dest", ",", "'w'", ")", "as", "fo", ":", "\n", "        ", "for", "line", "in", "fi", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "\n", "# remove if line is too long", "\n", "if", "line", ":", "\n", "                ", "line", "=", "remove_long_sent", "(", "line", ")", "\n", "\n", "# remove if line is too short", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "remove_short_sent", "(", "line", ")", "\n", "\n", "# remove if certain ratio of tokens are symbols", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "remove_too_many_puncts", "(", "line", ")", "\n", "\n", "# remove if line contains non-ascii characters", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "remove_nonascii_chars", "(", "line", ")", "\n", "\n", "# remove if consecutive spaces exist (probably the numerical table)", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "remove_consecutive_whitespace", "(", "line", ")", "\n", "\n", "# remove if too many digits exist", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "remove_too_many_digits_sentence", "(", "line", ")", "\n", "\n", "", "if", "line", ":", "\n", "                ", "line", "=", "line", "+", "'\\n'", "\n", "# fo.write(line.encode('utf-8'))", "\n", "fo", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.count_unigram_freq.main": [[11, 24], ["logzero.logger.info", "collections.defaultdict", "logzero.logger.info", "logzero.logger.info", "sorted", "logzero.logger.info", "line.strip().split", "collections.defaultdict.items", "print", "line.strip"], "function", ["None"], ["def", "main", "(", "fi", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'start counting'", ")", "\n", "d", "=", "defaultdict", "(", "int", ")", "\n", "for", "line", "in", "fi", ":", "\n", "        ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "d", "[", "token", "]", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "'finish counting'", ")", "\n", "\n", "logger", ".", "info", "(", "'printing to stdout'", ")", "\n", "for", "token", ",", "freq", "in", "sorted", "(", "d", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", ":", "\n", "        ", "print", "(", "'{}\\t{}'", ".", "format", "(", "token", ",", "freq", ")", ")", "\n", "", "logger", ".", "info", "(", "'done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.get_args": [[17, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'sentence split and tokenize large corpus'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "'-i'", ",", "required", "=", "True", ",", "type", "=", "os", ".", "path", ".", "abspath", ",", "\n", "help", "=", "'path to input file'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "'-o'", ",", "required", "=", "True", ",", "type", "=", "os", ".", "path", ".", "abspath", ",", "\n", "help", "=", "'path to output dir'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.ssplit": [[27, 30], ["blingfire.text_to_sentences().split", "blingfire.text_to_sentences", "text.strip"], "function", ["None"], ["", "def", "ssplit", "(", "text", ")", ":", "\n", "    ", "sentences", "=", "text_to_sentences", "(", "text", ".", "strip", "(", ")", ")", ".", "split", "(", "'\\n'", ")", "\n", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.tokenize": [[32, 36], ["nlp", "text.strip", "str"], "function", ["None"], ["", "def", "tokenize", "(", "text", ",", "nlp", ")", ":", "\n", "    ", "doc", "=", "nlp", "(", "text", ".", "strip", "(", ")", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", "]", ")", "\n", "tokens", "=", "[", "str", "(", "token", ")", "for", "token", "in", "doc", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.main": [[38, 51], ["spacy.load", "logzero.logger.info", "pathlib.Path", "gzip.open", "gzip.open", "ssplit_and_tokenize.ssplit", "ssplit_and_tokenize.tokenize", "fo.write", "pathlib.Path", "out.encode"], "function", ["home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.ssplit", "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.ssplit_and_tokenize.tokenize"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "nlp", "=", "spacy", ".", "load", "(", "SPACY_MODEL", ")", "\n", "\n", "logger", ".", "info", "(", "'Processing: {}'", ".", "format", "(", "args", ".", "input", ")", ")", "\n", "dest", "=", "Path", "(", "args", ".", "output", ",", "*", "Path", "(", "args", ".", "input", ")", ".", "parts", "[", "-", "2", ":", "]", ")", "\n", "with", "gzip", ".", "open", "(", "args", ".", "input", ",", "'rt'", ")", "as", "fi", ",", "gzip", ".", "open", "(", "dest", ",", "'wb'", ")", "as", "fo", ":", "\n", "        ", "for", "line", "in", "fi", ":", "\n", "            ", "sentences", "=", "ssplit", "(", "line", ")", "\n", "for", "sent", "in", "sentences", ":", "\n", "                ", "tokens", "=", "tokenize", "(", "sent", ",", "nlp", ")", "\n", "out", "=", "' '", ".", "join", "(", "tokens", ")", "+", "'\\n'", "\n", "fo", ".", "write", "(", "out", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.create_parser": [[24, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "os", ".", "path", ".", "abspath", ",", "\n", "# metavar='PATH',", "\n", "help", "=", "\"Input text (default: standard input).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dfile'", ",", "'-d'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "help", "=", "\"If set, input file is interpreted as a dictionary where each line contains a word-count pair\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file for BPE codes (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--threshold'", ",", "'-t'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Create this many new symbols (each representing a character n-gram) (default: %(default)s))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--seed'", ",", "'-s'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'SEED'", ",", "\n", "help", "=", "'Stop if no symbol pair has frequency >= SEED (default: %(default)s))'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "'-v'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--prob_mask'", ",", "'-pm'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"probability to use mask\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--prob_orig'", ",", "'-po'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "\n", "help", "=", "\"probability to use original token\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--unigram_freq'", ",", "'-uf'", ",", "type", "=", "os", ".", "path", ".", "abspath", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--single_mistake'", ",", "'-sm'", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "\"if we want single mistake...\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_insertion'", ",", "'-ui'", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "default", "=", "1", ",", "\n", "help", "=", "\"generate error by insertion?\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_deletion'", ",", "'-ud'", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "default", "=", "1", ",", "\n", "help", "=", "\"generate error by deletion?\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.get_vocabulary": [[78, 111], ["dict", "sys.stderr.write", "line.strip().split", "phrase[].split", "phrase[].split", "phrase[].strip", "phrase[].strip", "int", "p_dict[].append", "len", "line.strip", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_vocabulary", "(", "fobj", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Read text and return dictionary that encodes vocabulary\n    \"\"\"", "\n", "p_dict", "=", "dict", "(", ")", "\n", "add_c", "=", "0", "\n", "for", "line", "in", "fobj", ":", "\n", "        ", "phrase", "=", "line", ".", "strip", "(", "'\\r\\n '", ")", ".", "split", "(", "' ||| '", ")", "\n", "\n", "src_list", "=", "phrase", "[", "0", "]", ".", "split", "(", "' '", ")", "\n", "trg_list", "=", "phrase", "[", "1", "]", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "src_list", ")", "==", "1", "or", "len", "(", "trg_list", ")", "==", "1", ":", "# \u9577\u3055\u304c1\u306e\u3082\u306e\u306f\u4f7f\u308f\u306a\u3044", "\n", "            ", "continue", "\n", "", "elif", "len", "(", "src_list", ")", "==", "len", "(", "trg_list", ")", "and", "len", "(", "trg_list", ")", ">", "1", "and", "(", "\n", "src_list", "[", "0", "]", "==", "trg_list", "[", "0", "]", "or", "src_list", "[", "-", "1", "]", "==", "trg_list", "[", "-", "1", "]", ")", ":", "# \u9577\u3055\u304c\u540c\u3058\u5834\u5408\u306f\uff0c\u5148\u982d\u304b\u672b\u5c3e\u304c\u540c\u3058\u306a\u3089\u8a31\u5bb9\u3059\u308b", "\n", "            ", "pass", "\n", "", "elif", "not", "(", "src_list", "[", "0", "]", "==", "trg_list", "[", "0", "]", "and", "src_list", "[", "-", "1", "]", "==", "trg_list", "[", "-", "1", "]", ")", ":", "# \uff08\u9577\u3055\u304c\u9055\u3046\u5834\u5408\u306f\uff09\u5148\u982d\u3068\u672b\u5c3e\u304c\u540c\u3058\u5834\u5408\u3060\u3051\u8a31\u5bb9", "\n", "            ", "continue", "\n", "\n", "", "p_src", "=", "phrase", "[", "0", "]", ".", "strip", "(", "'\\r\\n '", ")", "# .split()", "\n", "p_trg", "=", "phrase", "[", "1", "]", ".", "strip", "(", "'\\r\\n '", ")", "# .split()", "\n", "count", "=", "int", "(", "phrase", "[", "-", "1", "]", ")", "\n", "if", "p_trg", "not", "in", "p_dict", ":", "\n", "            ", "p_dict", "[", "p_trg", "]", "=", "[", "]", "\n", "", "if", "not", "(", "count", "<", "threshold", ")", ":", "\n", "            ", "p_dict", "[", "p_trg", "]", ".", "append", "(", "(", "p_src", ",", "count", ")", ")", "\n", "add_c", "+=", "1", "\n", "", "p", "=", "\"\"", "\n", "for", "w", "in", "trg_list", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "p", "=", "w", "+", "\" \"", "+", "p", "if", "p", "!=", "\"\"", "else", "w", "\n", "if", "p", "not", "in", "p_dict", ":", "\n", "                ", "p_dict", "[", "p", "]", "=", "[", "]", "\n", "", "", "", "sys", ".", "stderr", ".", "write", "(", "'vocab Done len={} add_c={}\\n'", ".", "format", "(", "len", "(", "p_dict", ")", ",", "add_c", ")", ")", "\n", "return", "p_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.update_pair_statistics": [[113, 170], ["collections.defaultdict", "old_word.index", "word.index", "len", "len", "len", "len"], "function", ["None"], ["", "def", "update_pair_statistics", "(", "pair", ",", "changed", ",", "stats", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Minimally update the indices and frequency of symbol pairs\n\n    if we merge a pair of symbols, only pairs that overlap with occurrences\n    of this pair are affected, and need to be updated.\n    \"\"\"", "\n", "stats", "[", "pair", "]", "=", "0", "\n", "indices", "[", "pair", "]", "=", "defaultdict", "(", "int", ")", "\n", "first", ",", "second", "=", "pair", "\n", "new_pair", "=", "first", "+", "second", "\n", "for", "j", ",", "word", ",", "old_word", ",", "freq", "in", "changed", ":", "\n", "\n", "# find all instances of pair, and update frequency/indices around it", "\n", "        ", "i", "=", "0", "\n", "while", "True", ":", "\n", "# find first symbol", "\n", "            ", "try", ":", "\n", "                ", "i", "=", "old_word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "1", "and", "old_word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "# assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"", "\n", "                ", "if", "i", ":", "\n", "                    ", "prev", "=", "old_word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "-=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "-=", "1", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "2", ":", "\n", "# assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".", "\n", "# however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block", "\n", "                    ", "if", "old_word", "[", "i", "+", "2", "]", "!=", "first", "or", "i", ">=", "len", "(", "old_word", ")", "-", "3", "or", "old_word", "[", "i", "+", "3", "]", "!=", "second", ":", "\n", "                        ", "nex", "=", "old_word", "[", "i", "+", "1", ":", "i", "+", "3", "]", "\n", "stats", "[", "nex", "]", "-=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "-=", "1", "\n", "", "", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "i", "+=", "1", "\n", "\n", "", "", "i", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "# find new pair", "\n", "                ", "i", "=", "word", ".", "index", "(", "new_pair", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"", "\n", "", "if", "i", ":", "\n", "                ", "prev", "=", "word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "+=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "+=", "1", "\n", "# assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"", "\n", "# however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block", "\n", "", "if", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "!=", "new_pair", ":", "\n", "                ", "nex", "=", "word", "[", "i", ":", "i", "+", "2", "]", "\n", "stats", "[", "nex", "]", "+=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "+=", "1", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.get_pair_statistics": [[172, 189], ["collections.defaultdict", "collections.defaultdict", "enumerate", "collections.defaultdict"], "function", ["None"], ["", "", "", "def", "get_pair_statistics", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Count frequency of all symbol pairs, and create index\"\"\"", "\n", "\n", "# bpe structure of pair frequencies", "\n", "stats", "=", "defaultdict", "(", "int", ")", "\n", "\n", "# index from pairs to words", "\n", "indices", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "\n", "for", "i", ",", "(", "word", ",", "freq", ")", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "            ", "stats", "[", "prev_char", ",", "char", "]", "+=", "freq", "\n", "indices", "[", "prev_char", ",", "char", "]", "[", "i", "]", "+=", "1", "\n", "prev_char", "=", "char", "\n", "\n", "", "", "return", "stats", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.replace_pair": [[191, 214], ["pair_str.replace.replace", "re.compile", "indices[].iteritems", "indices[].items", "re.compile.sub", "tuple", "changes.append", "tuple.split", "re.escape"], "function", ["None"], ["", "def", "replace_pair", "(", "pair", ",", "vocab", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"", "\n", "first", ",", "second", "=", "pair", "\n", "pair_str", "=", "''", ".", "join", "(", "pair", ")", "\n", "pair_str", "=", "pair_str", ".", "replace", "(", "'\\\\'", ",", "'\\\\\\\\'", ")", "\n", "changes", "=", "[", "]", "\n", "pattern", "=", "re", ".", "compile", "(", "r'(?<!\\S)'", "+", "re", ".", "escape", "(", "first", "+", "' '", "+", "second", ")", "+", "r'(?!\\S)'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", "0", ")", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "iteritems", "(", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "items", "(", ")", "\n", "", "for", "j", ",", "freq", "in", "iterator", ":", "\n", "        ", "if", "freq", "<", "1", ":", "\n", "            ", "continue", "\n", "", "word", ",", "freq", "=", "vocab", "[", "j", "]", "\n", "new_word", "=", "' '", ".", "join", "(", "word", ")", "\n", "new_word", "=", "pattern", ".", "sub", "(", "pair_str", ",", "new_word", ")", "\n", "new_word", "=", "tuple", "(", "new_word", ".", "split", "(", "' '", ")", ")", "\n", "\n", "vocab", "[", "j", "]", "=", "(", "new_word", ",", "freq", ")", "\n", "changes", ".", "append", "(", "(", "j", ",", "new_word", ",", "word", ",", "freq", ")", ")", "\n", "\n", "", "return", "changes", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.prune_stats": [[216, 230], ["list", "stats.items"], "function", ["None"], ["", "def", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Prune statistics dict for efficiency of max()\n\n    The frequency of a symbol pair never increases, so pruning is generally safe\n    (until we the most frequent pair is less frequent than a pair we previously pruned)\n    big_stats keeps full statistics for when we need to access pruned items\n    \"\"\"", "\n", "for", "item", ",", "freq", "in", "list", "(", "stats", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "freq", "<", "threshold", ":", "\n", "            ", "del", "stats", "[", "item", "]", "\n", "if", "freq", "<", "0", ":", "\n", "                ", "big_stats", "[", "item", "]", "+=", "freq", "\n", "", "else", ":", "\n", "                ", "big_stats", "[", "item", "]", "=", "freq", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.main": [[232, 305], ["sys.stderr.write", "random.seed", "enumerate", "sys.stderr.write", "line.strip().split", "range", "sys.stdout.write", "len", "line.strip", "random.random", "t_out.strip", "line.strip", "random.randrange", "range", "output_list.append", "output_list.append", "random.choice", "random.random", "random.choice"], "function", ["None"], ["", "", "", "", "def", "main", "(", "dict_file", ",", "infile", ",", "outfile", ",", "threshold", ",", "index2word", ",", "word_index_list", ",", "r_seed", "=", "1", ",", "verbose", "=", "False", ",", "is_dict", "=", "False", ",", "\n", "prob_mask", "=", "0.3", ",", "prob_orig", "=", "0.2", ",", "args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n    \"\"\"", "\n", "\n", "sys", ".", "stderr", ".", "write", "(", "'random seed: {}\\n'", ".", "format", "(", "r_seed", ")", ")", "\n", "random", ".", "seed", "(", "r_seed", ")", "\n", "# version 0.2 changes the handling of the end-of-word token ('</w>');", "\n", "# version numbering allows bckward compatibility", "\n", "# outfile.write('#version: 0.2\\n')", "\n", "\n", "# vocab = get_vocabulary(dict_file, threshold)", "\n", "# for z in vocab:", "\n", "#     sys.stdout.write('vocab[{}] ||| {} ||| {}\\n'.format(z, len(vocab[z]), vocab[z]))", "\n", "\n", "proceed", "=", "0", "\n", "skip", "=", "0", "\n", "# with open(infile, 'r') as fi:", "\n", "for", "c", ",", "line", "in", "enumerate", "(", "sys", ".", "stdin", ")", ":", "# \u5165\u529b\u5206\u306e\u8aad\u307f\u8fbc\u307f", "\n", "        ", "wlist", "=", "line", ".", "strip", "(", "'\\r\\n '", ")", ".", "split", "(", "' '", ")", "\n", "proceed", "+=", "1", "\n", "\n", "output_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "# \u8907\u6570\u306e\u5019\u88dc\u3092\u4f5c\u308b\u5834\u5408\u306f\u3053\u3053\u306e\u6570\u3092\u4fee\u6b63\u3059\u308b", "\n", "            ", "maxlen", "=", "len", "(", "wlist", ")", "\n", "cnt", "=", "0", "\n", "t_out", "=", "\"\"", "\n", "# sys.stdout.write('#START {}->{}: {}\\n'.format(i,maxlen, t_out))", "\n", "# print('original: ', wlist)", "\n", "# print()", "\n", "while", "cnt", "<", "maxlen", ":", "\n", "                ", "rnd", "=", "random", ".", "random", "(", ")", "\n", "# print('focus: {}'.format(wlist[cnt]))", "\n", "if", "rnd", "<", "prob_orig", ":", "# \u7a7a\u30ea\u30b9\u30c8\u306e\u3070\u3042\u3044\u306f\u5fc5\u305a\u30b9\u30ad\u30c3\u30d7 or \u78ba\u73870.3\u4ee5\u4e0b\u3067\u5143\u306e\u5358\u8a9e\u3092\u9078\u629e", "\n", "# t_out += '**' + wlist[cnt] + ' ' # \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "                    ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "# \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "# sys.stdout.write('# {} | {}\\n'.format(cnt, t_out))", "\n", "# print('keep orig: {}'.format(wlist[cnt]))", "\n", "cnt", "+=", "1", "\n", "", "elif", "rnd", "<", "prob_mask", ":", "# \u7a7a\u30ea\u30b9\u30c8\u306e\u3070\u3042\u3044\u306f\u5fc5\u305a\u30b9\u30ad\u30c3\u30d7 or \u78ba\u73870.3\u4ee5\u4e0b\u3067\u5143\u306e\u5358\u8a9e\u3092\u9078\u629e", "\n", "                    ", "t_out", "+=", "'| '", "# \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "# print('masking: {}'.format(wlist[cnt]))", "\n", "cnt", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "rnd2", "=", "random", ".", "random", "(", ")", "\n", "if", "rnd2", "<", "0.5", ":", "# insert", "\n", "                        ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "\n", "if", "args", ".", "use_insertion", ":", "\n", "                            ", "index", "=", "random", ".", "choice", "(", "word_index_list", ")", "\n", "t_out", "+=", "index2word", "[", "index", "]", "+", "' '", "\n", "", "cnt", "+=", "1", "\n", "# sys.stderr.write('insert: {}\\n'.format(index2word[index]))", "\n", "", "else", ":", "# delete", "\n", "# sys.stderr.write('delete: {}\\n'.format(wlist[cnt]))", "\n", "                        ", "if", "not", "args", ".", "use_deletion", ":", "\n", "                            ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "\n", "", "cnt", "+=", "1", "\n", "# print(t_out)", "\n", "", "", "", "if", "t_out", ".", "strip", "(", "'\\r\\n '", ")", "==", "line", ".", "strip", "(", "'\\r\\n '", ")", ":", "\n", "# sys.stdout.write('#SAME {}||| {}'.format(t_out, line))", "\n", "                ", "padsize", "=", "random", ".", "randrange", "(", "1", ",", "9", ")", "\n", "pad", "=", "\"\"", "\n", "for", "i", "in", "range", "(", "padsize", ")", ":", "\n", "                    ", "pad", "+=", "'| '", "\n", "", "output_list", ".", "append", "(", "'{}||| {}{}'", ".", "format", "(", "t_out", ",", "pad", ",", "line", ")", ")", "\n", "", "else", ":", "\n", "                ", "output_list", ".", "append", "(", "'{}||| {}'", ".", "format", "(", "t_out", ",", "line", ")", ")", "\n", "# print(output_list[0])", "\n", "# exit()", "\n", "# sys.stdout.write('{}\\n'.format( len(output_list)))", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "'{}'", ".", "format", "(", "random", ".", "choice", "(", "output_list", ")", ")", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "'# {} {}\\n'", ".", "format", "(", "proceed", ",", "skip", ")", ")", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.single_mistake": [[307, 387], ["sys.stderr.write", "random.seed", "enumerate", "sys.stderr.write", "line.strip().split", "range", "sys.stdout.write", "len", "random.choice", "line.strip", "list", "t_out.strip", "line.strip", "random.randrange", "range", "output_list.append", "output_list.append", "random.choice", "range", "random.random", "random.random", "random.choice"], "function", ["None"], ["", "def", "single_mistake", "(", "dict_file", ",", "infile", ",", "outfile", ",", "threshold", ",", "index2word", ",", "word_index_list", ",", "r_seed", "=", "1", ",", "verbose", "=", "False", ",", "is_dict", "=", "False", ",", "\n", "prob_mask", "=", "0.3", ",", "prob_orig", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n    \"\"\"", "\n", "\n", "sys", ".", "stderr", ".", "write", "(", "'random seed: {}\\n'", ".", "format", "(", "r_seed", ")", ")", "\n", "random", ".", "seed", "(", "r_seed", ")", "\n", "# version 0.2 changes the handling of the end-of-word token ('</w>');", "\n", "# version numbering allows bckward compatibility", "\n", "# outfile.write('#version: 0.2\\n')", "\n", "\n", "# vocab = get_vocabulary(dict_file, threshold)", "\n", "# for z in vocab:", "\n", "#     sys.stdout.write('vocab[{}] ||| {} ||| {}\\n'.format(z, len(vocab[z]), vocab[z]))", "\n", "\n", "proceed", "=", "0", "\n", "skip", "=", "0", "\n", "# with open(infile, 'r') as fi:", "\n", "for", "c", ",", "line", "in", "enumerate", "(", "sys", ".", "stdin", ")", ":", "# \u5165\u529b\u5206\u306e\u8aad\u307f\u8fbc\u307f", "\n", "        ", "wlist", "=", "line", ".", "strip", "(", "'\\r\\n '", ")", ".", "split", "(", "' '", ")", "\n", "proceed", "+=", "1", "\n", "\n", "output_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "# \u8907\u6570\u306e\u5019\u88dc\u3092\u4f5c\u308b\u5834\u5408\u306f\u3053\u3053\u306e\u6570\u3092\u4fee\u6b63\u3059\u308b", "\n", "            ", "maxlen", "=", "len", "(", "wlist", ")", "\n", "cnt", "=", "0", "\n", "t_out", "=", "\"\"", "\n", "# sys.stdout.write('#START {}->{}: {}\\n'.format(i,maxlen, t_out))", "\n", "# print('original: ', wlist)", "\n", "# print()", "\n", "mistake_idx", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "maxlen", ")", ")", ")", "\n", "while", "cnt", "<", "maxlen", ":", "\n", "                ", "if", "mistake_idx", "==", "cnt", ":", "\n", "# print('i am making mistake', cnt, mistake_idx)", "\n", "                    ", "rnd", "=", "random", ".", "random", "(", ")", "\n", "# print(rnd)", "\n", "# print('focus: {}'.format(wlist[cnt]))", "\n", "if", "rnd", "<", "prob_orig", ":", "# \u7a7a\u30ea\u30b9\u30c8\u306e\u3070\u3042\u3044\u306f\u5fc5\u305a\u30b9\u30ad\u30c3\u30d7 or \u78ba\u73870.3\u4ee5\u4e0b\u3067\u5143\u306e\u5358\u8a9e\u3092\u9078\u629e", "\n", "# t_out += '**' + wlist[cnt] + ' ' # \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "                        ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "# \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "# sys.stdout.write('# {} | {}\\n'.format(cnt, t_out))", "\n", "# print('keep orig: {}'.format(wlist[cnt]))", "\n", "cnt", "+=", "1", "\n", "", "elif", "rnd", "<", "prob_mask", ":", "# \u7a7a\u30ea\u30b9\u30c8\u306e\u3070\u3042\u3044\u306f\u5fc5\u305a\u30b9\u30ad\u30c3\u30d7 or \u78ba\u73870.3\u4ee5\u4e0b\u3067\u5143\u306e\u5358\u8a9e\u3092\u9078\u629e", "\n", "                        ", "t_out", "+=", "'| '", "# \u51fa\u529b\u306e\u6587\u5b57\u5217", "\n", "# print('masking: {}'.format(wlist[cnt]))", "\n", "cnt", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "rnd2", "=", "random", ".", "random", "(", ")", "\n", "# print(rnd2)", "\n", "if", "rnd2", "<", "0.5", ":", "# insert", "\n", "                            ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "\n", "index", "=", "random", ".", "choice", "(", "word_index_list", ")", "\n", "t_out", "+=", "index2word", "[", "index", "]", "+", "' '", "\n", "cnt", "+=", "1", "\n", "# sys.stdout.write('insert: {}\\n'.format(index2word[index]))", "\n", "", "else", ":", "# delete", "\n", "# sys.stdout.write('delete: {}\\n'.format(wlist[cnt]))", "\n", "                            ", "cnt", "+=", "1", "\n", "", "", "", "else", ":", "\n", "# print('keep original', wlist[cnt])", "\n", "# print(t_out)", "\n", "                    ", "t_out", "+=", "wlist", "[", "cnt", "]", "+", "' '", "\n", "cnt", "+=", "1", "\n", "# print(t_out)", "\n", "", "", "if", "t_out", ".", "strip", "(", "'\\r\\n '", ")", "==", "line", ".", "strip", "(", "'\\r\\n '", ")", ":", "\n", "# sys.stdout.write('#SAME {}||| {}'.format(t_out, line))", "\n", "                ", "padsize", "=", "random", ".", "randrange", "(", "1", ",", "9", ")", "\n", "pad", "=", "\"\"", "\n", "for", "i", "in", "range", "(", "padsize", ")", ":", "\n", "                    ", "pad", "+=", "'| '", "\n", "", "output_list", ".", "append", "(", "'{}||| {}{}'", ".", "format", "(", "t_out", ",", "pad", ",", "line", ")", ")", "\n", "", "else", ":", "\n", "                ", "output_list", ".", "append", "(", "'{}||| {}'", ".", "format", "(", "t_out", ",", "line", ")", ")", "\n", "# print(output_list[0])", "\n", "# exit()", "\n", "# sys.stdout.write('{}\\n'.format( len(output_list)))", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "'{}'", ".", "format", "(", "random", ".", "choice", "(", "output_list", ")", ")", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "'# {} {}\\n'", ".", "format", "(", "proceed", ",", "skip", ")", ")", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_pseudo_samples.read_unigram_freq": [[389, 398], ["io.open", "enumerate", "line.strip().split", "int", "line.strip"], "function", ["None"], ["", "def", "read_unigram_freq", "(", "path_to_unigram_freq", ")", ":", "\n", "    ", "index2word", "=", "{", "}", "\n", "word_index_list", "=", "[", "]", "\n", "with", "open", "(", "path_to_unigram_freq", ",", "'r'", ")", "as", "fi", ":", "\n", "        ", "for", "n", ",", "line", "in", "enumerate", "(", "fi", ")", ":", "\n", "            ", "token", ",", "freq", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "index2word", "[", "n", "]", "=", "token", "\n", "word_index_list", "+=", "[", "n", "]", "*", "int", "(", "freq", ")", "\n", "", "", "return", "index2word", ",", "word_index_list", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.normalize_unigram_freq.main": [[11, 19], ["logzero.logger.info", "line.strip().split", "max", "print", "line.strip", "int"], "function", ["None"], ["def", "main", "(", "fi", ",", "norm", ")", ":", "\n", "    ", "sum_freq", "=", "0", "\n", "for", "line", "in", "fi", ":", "\n", "        ", "token", ",", "freq", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "normalized_freq", "=", "max", "(", "int", "(", "freq", ")", "//", "norm", ",", "1", ")", "\n", "sum_freq", "+=", "normalized_freq", "\n", "print", "(", "'{}\\t{}'", ".", "format", "(", "token", ",", "normalized_freq", ")", ")", "\n", "", "logger", ".", "info", "(", "'sum_freq: {}'", ".", "format", "(", "sum_freq", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.butsugiri_gec-pseudodata.None.generate_vocab.main": [[10, 20], ["set", "logzero.logger.info", "logzero.logger.info", "line.strip().split", "print", "set.add", "line.strip"], "function", ["None"], ["def", "main", "(", "fi", ")", ":", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "logger", ".", "info", "(", "'building vocabs'", ")", "\n", "for", "line", "in", "fi", ":", "\n", "        ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "vocab", ".", "add", "(", "token", ")", "\n", "", "", "logger", ".", "info", "(", "'done'", ")", "\n", "for", "token", "in", "vocab", ":", "\n", "        ", "print", "(", "token", ")", "\n", "\n"]]}