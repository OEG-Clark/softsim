{"home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.None.distance.get_distance": [[12, 16], ["numpy.average", "numpy.abs", "numpy.asarray", "numpy.asarray"], "function", ["None"], ["def", "get_distance", "(", "lang0", ",", "lang1", ")", ":", "\n", "    ", "v0", "=", "VECS", "[", "lang0", "]", "\n", "v1", "=", "VECS", "[", "lang1", "]", "\n", "return", "np", ".", "average", "(", "np", ".", "abs", "(", "np", ".", "asarray", "(", "v0", ")", "-", "np", ".", "asarray", "(", "v1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.None.distance.draw_heatmap": [[23, 39], ["matplotlib.subplots", "ax.imshow", "ax.set_xticks", "ax.set_yticks", "ax.set_xticklabels", "ax.set_yticklabels", "matplotlib.setp", "range", "fig.tight_layout", "matplotlib.show", "numpy.arange", "numpy.arange", "ax.get_xticklabels", "len", "range", "len", "len", "len", "ax.text"], "function", ["None"], ["def", "draw_heatmap", "(", "arr", ",", "xs", ",", "ys", ")", ":", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "arr", ")", "\n", "#", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "xs", ")", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "ys", ")", ")", ")", "\n", "ax", ".", "set_xticklabels", "(", "xs", ")", "\n", "ax", ".", "set_yticklabels", "(", "ys", ")", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "45", ",", "ha", "=", "\"right\"", ",", "\n", "rotation_mode", "=", "\"anchor\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "xs", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "ys", ")", ")", ":", "\n", "            ", "text", "=", "ax", ".", "text", "(", "j", ",", "i", ",", "\"%.1f\"", "%", "(", "arr", "[", "i", ",", "j", "]", "*", "100", ")", ",", "\n", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "color", "=", "\"w\"", ")", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.None.distance.main": [[40, 55], ["numpy.zeros", "range", "print", "distance.draw_heatmap", "numpy.average", "print", "print", "print", "print", "len", "range", "numpy.average", "sorted", "sorted", "sorted", "len", "len", "len", "distance.get_distance", "range", "enumerate", "enumerate", "len", "numpy.abs", "numpy.abs", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.None.distance.draw_heatmap", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.None.distance.get_distance"], ["", "def", "main", "(", ")", ":", "\n", "# (lang, lang) distance", "\n", "    ", "matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "LANGS", ")", ",", "len", "(", "LANGS", ")", ")", ")", "\n", "for", "l1", "in", "range", "(", "len", "(", "LANGS", ")", ")", ":", "\n", "        ", "for", "l2", "in", "range", "(", "len", "(", "LANGS", ")", ")", ":", "\n", "            ", "matrix", "[", "l1", "]", "[", "l2", "]", "=", "get_distance", "(", "LANGS", "[", "l1", "]", ",", "LANGS", "[", "l2", "]", ")", "\n", "", "", "print", "(", "matrix", ")", "\n", "draw_heatmap", "(", "matrix", ",", "LANGS", ",", "LANGS", ")", "\n", "avg", "=", "np", ".", "average", "(", "matrix", ",", "-", "1", ")", "\n", "print", "(", "np", ".", "average", "(", "matrix", ",", "-", "1", ")", ")", "\n", "print", "(", "sorted", "(", "[", "(", "LANGS", "[", "i", "]", ",", "avg", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "LANGS", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", "\n", "pass", "\n", "#", "\n", "print", "(", "sorted", "(", "[", "(", "i", ",", "v", ")", "for", "i", ",", "v", "in", "enumerate", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "VECS", "[", "'en'", "]", ")", "-", "np", ".", "array", "(", "VECS", "[", "'de'", "]", ")", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "print", "(", "sorted", "(", "[", "(", "i", ",", "v", ")", "for", "i", ",", "v", "in", "enumerate", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "VECS", "[", "'en'", "]", ")", "-", "np", ".", "array", "(", "VECS", "[", "'nl'", "]", ")", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.StackPointerParser.main": [[35, 729], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "random.seed", "numpy.random.seed", "torch.manual_seed", "neuronlp2.io.get_logger", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "tuple", "neuronlp2.io.get_logger.info", "os.path.join", "os.path.join", "os.path.isdir", "neuronlp2.io.conllx_stacked_data.create_alphabets", "max", "word_alphabet.size", "char_alphabet.size", "pos_alphabet.size", "type_alphabet.size", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "torch.cuda.is_available", "StackPointerParser.main._read_one"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["def", "main", "(", ")", ":", "\n", "    ", "args_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Tuning with stack pointer parser'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "'random seed for reproducibility'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--mode'", ",", "choices", "=", "[", "'RNN'", ",", "'LSTM'", ",", "'GRU'", ",", "'FastLSTM'", "]", ",", "help", "=", "'architecture of rnn'", ",", "\n", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'Number of sentences in each batch'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decoder_input_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'Number of input units in decoder RNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'Number of hidden units in RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--arc_space'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'Dimension of tag space'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--type_space'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'Dimension of tag space'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--encoder_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of layers of encoder RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decoder_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of layers of decoder RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_filters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Number of filters in CNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--trans_hid_size'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "'#hidden units in point-wise feed-forward in transformer'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--d_k'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'d_k for multi-head-attention in transformer encoder'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--d_v'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'d_v for multi-head-attention in transformer encoder'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--multi_head_attn'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use multi-head-attention.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_head'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'Value of h in multi-head attention'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--pool_type'", ",", "default", "=", "'mean'", ",", "choices", "=", "[", "'max'", ",", "'mean'", ",", "'weight'", "]", ",", "\n", "help", "=", "'pool type to form fixed length vector from word embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--train_position'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train positional encoding for transformer.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--no_word'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not use word embedding.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--pos'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use part-of-speech embedding.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use character embedding and CNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--no_CoRNN'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not use context RNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--pos_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Dimension of POS embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Dimension of Character embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--opt'", ",", "choices", "=", "[", "'adam'", ",", "'sgd'", ",", "'adamax'", "]", ",", "help", "=", "'optimization algorithm'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'Learning rate'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "5.0", ",", "help", "=", "'gradient clipping'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'weight for regularization'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "help", "=", "'epsilon for adam or adamax'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--coverage'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'weight for coverage loss'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_rnn'", ",", "nargs", "=", "'+'", ",", "type", "=", "float", ",", "required", "=", "True", ",", "help", "=", "'dropout rate for RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_in'", ",", "type", "=", "float", ",", "default", "=", "0.33", ",", "help", "=", "'dropout rate for input embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_out'", ",", "type", "=", "float", ",", "default", "=", "0.33", ",", "help", "=", "'dropout rate for output layer'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--label_smooth'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight of label smoothing method'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--skipConnect'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use skip connection for decoder RNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--grandPar'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use grand parent.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--sibling'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use sibling.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--prior_order'", ",", "choices", "=", "[", "'inside_out'", ",", "'left2right'", ",", "'deep_first'", ",", "'shallow_first'", "]", ",", "\n", "help", "=", "'prior order of children.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--unk_replace'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "'The rate to replace a singleton word with UNK'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--punctuation'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "help", "=", "'List of punctuations'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--beam'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Beam size for decoding'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--word_embedding'", ",", "choices", "=", "[", "'word2vec'", ",", "'glove'", ",", "'senna'", ",", "'sskip'", ",", "'polyglot'", "]", ",", "\n", "help", "=", "'Embedding for words'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--word_path'", ",", "help", "=", "'path for word embedding dict'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--freeze'", ",", "action", "=", "'store_true'", ",", "help", "=", "'frozen the word embedding (disable fine-tuning).'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_embedding'", ",", "choices", "=", "[", "'random'", ",", "'polyglot'", "]", ",", "help", "=", "'Embedding for characters'", ",", "\n", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_path'", ",", "help", "=", "'path for character embedding dict'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--train'", ")", "# \"data/POS-penn/wsj/split1/wsj1.train.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--dev'", ")", "# \"data/POS-penn/wsj/split1/wsj1.dev.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--test'", ")", "# \"data/POS-penn/wsj/split1/wsj1.test.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--vocab_path'", ",", "help", "=", "'path for prebuilt alphabets.'", ",", "default", "=", "None", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_path'", ",", "help", "=", "'path for saving model file.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_name'", ",", "help", "=", "'name for saving model file.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--position_embed_num'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Minimum value of position embedding num, which usually is max-sent-length.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "'Number of training epochs'", ")", "\n", "\n", "# lrate schedule with warmup in the first iter.", "\n", "args_parser", ".", "add_argument", "(", "'--use_warmup_schedule'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use warmup lrate schedule.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.75", ",", "help", "=", "'Decay rate of learning rate'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--max_decay'", ",", "type", "=", "int", ",", "default", "=", "9", ",", "help", "=", "'Number of decays before stop'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--schedule'", ",", "type", "=", "int", ",", "help", "=", "'schedule for learning rate decay'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--double_schedule_decay'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'Number of decays to double schedule'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--check_dev'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Check development performance in every n\\'th iteration'", ")", "\n", "#", "\n", "# about decoder's bi-attention scoring with features (default is not using any)", "\n", "args_parser", ".", "add_argument", "(", "'--dec_max_dist'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"The clamp range of decoder's distance feature, 0 means turning off.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--dec_dim_feature'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"Dim for feature embed.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--dec_use_neg_dist'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use negative distance for dec's distance feature.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--dec_use_encoder_pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use pos feature combined with distance feature for child nodes.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--dec_use_decoder_pos'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use pos feature combined with distance feature for head nodes.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--dec_drop_f_embed'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Dropout for dec feature embeddings.\"", ")", "\n", "#", "\n", "# about relation-aware self attention for the transformer encoder (default is not using any)", "\n", "# args_parser.add_argument('--rel_aware', action='store_true',", "\n", "#                          help=\"Enable relation-aware self-attention (multi_head_attn flag needs to be set).\")", "\n", "args_parser", ".", "add_argument", "(", "'--enc_use_neg_dist'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use negative distance for enc's relational-distance embedding.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--enc_clip_dist'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"The clipping distance for relative position features.\"", ")", "\n", "#", "\n", "# other options about how to combine multiple input features (have to make some dims fit if not concat)", "\n", "args_parser", ".", "add_argument", "(", "'--input_concat_embeds'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Concat input embeddings, otherwise add.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--input_concat_position'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Concat position embeddings, otherwise add.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--position_dim'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'Dimension of Position embeddings.'", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--train_len_thresh'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'In training, discard sentences longer than this.'", ")", "\n", "\n", "args", "=", "args_parser", ".", "parse_args", "(", ")", "\n", "\n", "# =====", "\n", "# fix data-prepare seed", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "np", ".", "random", ".", "seed", "(", "1234", ")", "\n", "# model's seed", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# =====", "\n", "\n", "# if output directory doesn't exist, create it", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "model_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "model_path", ")", "\n", "", "logger", "=", "get_logger", "(", "\"PtrParser\"", ",", "args", ".", "model_path", "+", "'log.txt'", ")", "\n", "\n", "logger", ".", "info", "(", "'\\ncommand-line params : {0}\\n'", ".", "format", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "logger", ".", "info", "(", "'{0}\\n'", ".", "format", "(", "args", ")", ")", "\n", "\n", "mode", "=", "args", ".", "mode", "\n", "train_path", "=", "args", ".", "train", "\n", "dev_path", "=", "args", ".", "dev", "\n", "test_path", "=", "args", ".", "test", "\n", "vocab_path", "=", "args", ".", "vocab_path", "if", "args", ".", "vocab_path", "is", "not", "None", "else", "args", ".", "model_path", "\n", "model_path", "=", "args", ".", "model_path", "\n", "model_name", "=", "args", ".", "model_name", "\n", "num_epochs", "=", "args", ".", "num_epochs", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "input_size_decoder", "=", "args", ".", "decoder_input_size", "\n", "hidden_size", "=", "args", ".", "hidden_size", "\n", "arc_space", "=", "args", ".", "arc_space", "\n", "type_space", "=", "args", ".", "type_space", "\n", "encoder_layers", "=", "args", ".", "encoder_layers", "\n", "decoder_layers", "=", "args", ".", "decoder_layers", "\n", "num_filters", "=", "args", ".", "num_filters", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "opt", "=", "args", ".", "opt", "\n", "momentum", "=", "0.9", "\n", "betas", "=", "(", "0.9", ",", "0.9", ")", "\n", "eps", "=", "args", ".", "epsilon", "\n", "decay_rate", "=", "args", ".", "decay_rate", "\n", "clip", "=", "args", ".", "clip", "\n", "gamma", "=", "args", ".", "gamma", "\n", "cov", "=", "args", ".", "coverage", "\n", "schedule", "=", "args", ".", "schedule", "\n", "p_rnn", "=", "tuple", "(", "args", ".", "p_rnn", ")", "\n", "p_in", "=", "args", ".", "p_in", "\n", "p_out", "=", "args", ".", "p_out", "\n", "label_smooth", "=", "args", ".", "label_smooth", "\n", "unk_replace", "=", "args", ".", "unk_replace", "\n", "prior_order", "=", "args", ".", "prior_order", "\n", "skipConnect", "=", "args", ".", "skipConnect", "\n", "grandPar", "=", "args", ".", "grandPar", "\n", "sibling", "=", "args", ".", "sibling", "\n", "beam", "=", "args", ".", "beam", "\n", "punctuation", "=", "args", ".", "punctuation", "\n", "\n", "freeze", "=", "args", ".", "freeze", "\n", "use_word_emb", "=", "not", "args", ".", "no_word", "\n", "word_embedding", "=", "args", ".", "word_embedding", "\n", "word_path", "=", "args", ".", "word_path", "\n", "\n", "use_char", "=", "args", ".", "char", "\n", "char_embedding", "=", "args", ".", "char_embedding", "\n", "char_path", "=", "args", ".", "char_path", "\n", "\n", "use_con_rnn", "=", "not", "args", ".", "no_CoRNN", "\n", "\n", "use_pos", "=", "args", ".", "pos", "\n", "pos_dim", "=", "args", ".", "pos_dim", "\n", "word_dict", ",", "word_dim", "=", "utils", ".", "load_embedding_dict", "(", "word_embedding", ",", "word_path", ")", "if", "use_word_emb", "else", "(", "None", ",", "0", ")", "\n", "char_dict", "=", "None", "\n", "char_dim", "=", "args", ".", "char_dim", "\n", "if", "char_embedding", "!=", "'random'", ":", "\n", "        ", "char_dict", ",", "char_dim", "=", "utils", ".", "load_embedding_dict", "(", "char_embedding", ",", "char_path", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Creating Alphabets\"", ")", "\n", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "'alphabets/'", ")", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "model_name", ")", "\n", "\n", "# todo(warn): should build vocabs previously", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "alphabet_path", ")", ",", "\"should have build vocabs previously\"", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "conllx_stacked_data", ".", "create_alphabets", "(", "\n", "alphabet_path", ",", "train_path", ",", "data_paths", "=", "[", "dev_path", ",", "test_path", "]", ",", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "word_dict", ")", "\n", "# word_alphabet, char_alphabet, pos_alphabet, type_alphabet, max_sent_length = create_alphabets(alphabet_path,", "\n", "#     train_path, data_paths=[dev_path, test_path], max_vocabulary_size=50000, embedd_dict=word_dict)", "\n", "max_sent_length", "=", "max", "(", "max_sent_length", ",", "args", ".", "position_embed_num", ")", "\n", "\n", "num_words", "=", "word_alphabet", ".", "size", "(", ")", "\n", "num_chars", "=", "char_alphabet", ".", "size", "(", ")", "\n", "num_pos", "=", "pos_alphabet", ".", "size", "(", ")", "\n", "num_types", "=", "type_alphabet", ".", "size", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size: %d\"", "%", "num_words", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "num_chars", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "num_pos", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "num_types", ")", "\n", "\n", "logger", ".", "info", "(", "\"Reading Data\"", ")", "\n", "use_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "# ===== the reading", "\n", "def", "_read_one", "(", "path", ",", "is_train", ")", ":", "\n", "        ", "lang_id", "=", "guess_language_id", "(", "path", ")", "\n", "logger", ".", "info", "(", "\"Reading: guess that the language of file %s is %s.\"", "%", "(", "path", ",", "lang_id", ")", ")", "\n", "one_data", "=", "conllx_stacked_data", ".", "read_stacked_data_to_variable", "(", "path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "\n", "type_alphabet", ",", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "(", "not", "is_train", ")", ",", "prior_order", "=", "prior_order", ",", "\n", "lang_id", "=", "lang_id", ",", "len_thresh", "=", "(", "args", ".", "train_len_thresh", "if", "is_train", "else", "100000", ")", ")", "\n", "return", "one_data", "\n", "\n", "", "data_train", "=", "_read_one", "(", "train_path", ",", "True", ")", "\n", "num_data", "=", "sum", "(", "data_train", "[", "1", "]", ")", "\n", "\n", "data_dev", "=", "_read_one", "(", "dev_path", ",", "False", ")", "\n", "data_test", "=", "_read_one", "(", "test_path", ",", "False", ")", "\n", "# =====", "\n", "\n", "punct_set", "=", "None", "\n", "if", "punctuation", "is", "not", "None", ":", "\n", "        ", "punct_set", "=", "set", "(", "punctuation", ")", "\n", "logger", ".", "info", "(", "\"punctuations(%d): %s\"", "%", "(", "len", "(", "punct_set", ")", ",", "' '", ".", "join", "(", "punct_set", ")", ")", ")", "\n", "\n", "", "def", "construct_word_embedding_table", "(", ")", ":", "\n", "        ", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "word_dim", ")", "\n", "table", "=", "np", ".", "empty", "(", "[", "word_alphabet", ".", "size", "(", ")", ",", "word_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "table", "[", "conllx_stacked_data", ".", "UNK_ID", ",", ":", "]", "=", "np", ".", "zeros", "(", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", "if", "freeze", "else", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "=", "0", "\n", "for", "word", ",", "index", "in", "word_alphabet", ".", "items", "(", ")", ":", "\n", "            ", "if", "word", "in", "word_dict", ":", "\n", "                ", "embedding", "=", "word_dict", "[", "word", "]", "\n", "", "elif", "word", ".", "lower", "(", ")", "in", "word_dict", ":", "\n", "                ", "embedding", "=", "word_dict", "[", "word", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "np", ".", "zeros", "(", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "if", "freeze", "else", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "\n", "[", "1", ",", "\n", "word_dim", "]", ")", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "oov", "+=", "1", "\n", "", "table", "[", "index", ",", ":", "]", "=", "embedding", "\n", "", "logger", ".", "info", "(", "'word OOV: %d'", "%", "oov", ")", "\n", "return", "torch", ".", "from_numpy", "(", "table", ")", "\n", "\n", "", "def", "construct_char_embedding_table", "(", ")", ":", "\n", "        ", "if", "char_dict", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "char_dim", ")", "\n", "table", "=", "np", ".", "empty", "(", "[", "num_chars", ",", "char_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "table", "[", "conllx_stacked_data", ".", "UNK_ID", ",", ":", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "char_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "=", "0", "\n", "for", "char", ",", "index", ",", "in", "char_alphabet", ".", "items", "(", ")", ":", "\n", "            ", "if", "char", "in", "char_dict", ":", "\n", "                ", "embedding", "=", "char_dict", "[", "char", "]", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "char_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "+=", "1", "\n", "", "table", "[", "index", ",", ":", "]", "=", "embedding", "\n", "", "logger", ".", "info", "(", "'character OOV: %d'", "%", "oov", ")", "\n", "return", "torch", ".", "from_numpy", "(", "table", ")", "\n", "\n", "", "word_table", "=", "construct_word_embedding_table", "(", ")", "if", "use_word_emb", "else", "None", "\n", "char_table", "=", "construct_char_embedding_table", "(", ")", "\n", "\n", "window", "=", "3", "\n", "network", "=", "StackPtrNet", "(", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "window", ",", "\n", "mode", ",", "input_size_decoder", ",", "hidden_size", ",", "encoder_layers", ",", "decoder_layers", ",", "\n", "num_types", ",", "arc_space", ",", "type_space", ",", "args", ".", "pool_type", ",", "args", ".", "multi_head_attn", ",", "args", ".", "num_head", ",", "\n", "max_sent_length", ",", "args", ".", "trans_hid_size", ",", "args", ".", "d_k", ",", "args", ".", "d_v", ",", "\n", "train_position", "=", "args", ".", "train_position", ",", "embedd_word", "=", "word_table", ",", "embedd_char", "=", "char_table", ",", "p_in", "=", "p_in", ",", "\n", "p_out", "=", "p_out", ",", "p_rnn", "=", "p_rnn", ",", "biaffine", "=", "True", ",", "use_word_emb", "=", "use_word_emb", ",", "pos", "=", "use_pos", ",", "\n", "char", "=", "use_char", ",", "prior_order", "=", "prior_order", ",", "use_con_rnn", "=", "use_con_rnn", ",", "skipConnect", "=", "skipConnect", ",", "\n", "grandPar", "=", "grandPar", ",", "sibling", "=", "sibling", ",", "use_gpu", "=", "use_gpu", ",", "\n", "dec_max_dist", "=", "args", ".", "dec_max_dist", ",", "dec_use_neg_dist", "=", "args", ".", "dec_use_neg_dist", ",", "\n", "dec_use_encoder_pos", "=", "args", ".", "dec_use_encoder_pos", ",", "dec_use_decoder_pos", "=", "args", ".", "dec_use_decoder_pos", ",", "\n", "dec_dim_feature", "=", "args", ".", "dec_dim_feature", ",", "dec_drop_f_embed", "=", "args", ".", "dec_drop_f_embed", ",", "\n", "enc_clip_dist", "=", "args", ".", "enc_clip_dist", ",", "enc_use_neg_dist", "=", "args", ".", "enc_use_neg_dist", ",", "\n", "input_concat_embeds", "=", "args", ".", "input_concat_embeds", ",", "input_concat_position", "=", "args", ".", "input_concat_position", ",", "\n", "position_dim", "=", "args", ".", "position_dim", ")", "\n", "\n", "def", "save_args", "(", ")", ":", "\n", "        ", "arg_path", "=", "model_name", "+", "'.arg.json'", "\n", "arguments", "=", "[", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "window", ",", "\n", "mode", ",", "input_size_decoder", ",", "hidden_size", ",", "encoder_layers", ",", "decoder_layers", ",", "\n", "num_types", ",", "arc_space", ",", "type_space", ",", "args", ".", "pool_type", ",", "args", ".", "multi_head_attn", ",", "args", ".", "num_head", ",", "\n", "max_sent_length", ",", "args", ".", "trans_hid_size", ",", "args", ".", "d_k", ",", "args", ".", "d_v", "]", "\n", "kwargs", "=", "{", "'train_position'", ":", "args", ".", "train_position", ",", "'use_word_emb'", ":", "use_word_emb", ",", "'use_con_rnn'", ":", "use_con_rnn", ",", "\n", "'p_in'", ":", "p_in", ",", "'p_out'", ":", "p_out", ",", "'p_rnn'", ":", "p_rnn", ",", "'biaffine'", ":", "True", ",", "'pos'", ":", "use_pos", ",", "'char'", ":", "use_char", ",", "\n", "'prior_order'", ":", "prior_order", ",", "'skipConnect'", ":", "skipConnect", ",", "'grandPar'", ":", "grandPar", ",", "'sibling'", ":", "sibling", ",", "\n", "'dec_max_dist'", ":", "args", ".", "dec_max_dist", ",", "'dec_use_neg_dist'", ":", "args", ".", "dec_use_neg_dist", ",", "\n", "'dec_use_encoder_pos'", ":", "args", ".", "dec_use_encoder_pos", ",", "'dec_use_decoder_pos'", ":", "args", ".", "dec_use_decoder_pos", ",", "\n", "'dec_dim_feature'", ":", "args", ".", "dec_dim_feature", ",", "'dec_drop_f_embed'", ":", "args", ".", "dec_drop_f_embed", ",", "\n", "'enc_clip_dist'", ":", "args", ".", "enc_clip_dist", ",", "'enc_use_neg_dist'", ":", "args", ".", "enc_use_neg_dist", ",", "\n", "'input_concat_embeds'", ":", "args", ".", "input_concat_embeds", ",", "'input_concat_position'", ":", "args", ".", "input_concat_position", ",", "'position_dim'", ":", "args", ".", "position_dim", "}", "\n", "json", ".", "dump", "(", "{", "'args'", ":", "arguments", ",", "'kwargs'", ":", "kwargs", "}", ",", "open", "(", "arg_path", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "\n", "", "if", "use_word_emb", "and", "freeze", ":", "\n", "        ", "network", ".", "word_embedd", ".", "freeze", "(", ")", "\n", "\n", "", "if", "use_gpu", ":", "\n", "        ", "network", ".", "cuda", "(", ")", "\n", "\n", "", "save_args", "(", ")", "\n", "\n", "pred_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "gold_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "\n", "def", "generate_optimizer", "(", "opt", ",", "lr", ",", "params", ")", ":", "\n", "        ", "params", "=", "filter", "(", "lambda", "param", ":", "param", ".", "requires_grad", ",", "params", ")", "\n", "if", "opt", "==", "'adam'", ":", "\n", "            ", "return", "Adam", "(", "params", ",", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "weight_decay", "=", "gamma", ",", "eps", "=", "eps", ")", "\n", "", "elif", "opt", "==", "'sgd'", ":", "\n", "            ", "return", "SGD", "(", "params", ",", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "weight_decay", "=", "gamma", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "opt", "==", "'adamax'", ":", "\n", "            ", "return", "Adamax", "(", "params", ",", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "weight_decay", "=", "gamma", ",", "eps", "=", "eps", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown optimization algorithm: %s'", "%", "opt", ")", "\n", "\n", "", "", "lr", "=", "learning_rate", "\n", "optim", "=", "generate_optimizer", "(", "opt", ",", "lr", ",", "network", ".", "parameters", "(", ")", ")", "\n", "opt_info", "=", "'opt: %s, '", "%", "opt", "\n", "if", "opt", "==", "'adam'", ":", "\n", "        ", "opt_info", "+=", "'betas=%s, eps=%.1e'", "%", "(", "betas", ",", "eps", ")", "\n", "", "elif", "opt", "==", "'sgd'", ":", "\n", "        ", "opt_info", "+=", "'momentum=%.2f'", "%", "momentum", "\n", "", "elif", "opt", "==", "'adamax'", ":", "\n", "        ", "opt_info", "+=", "'betas=%s, eps=%.1e'", "%", "(", "betas", ",", "eps", ")", "\n", "\n", "", "word_status", "=", "'frozen'", "if", "freeze", "else", "'fine tune'", "\n", "char_status", "=", "'enabled'", "if", "use_char", "else", "'disabled'", "\n", "pos_status", "=", "'enabled'", "if", "use_pos", "else", "'disabled'", "\n", "logger", ".", "info", "(", "\"Embedding dim: word=%d (%s), char=%d (%s), pos=%d (%s)\"", "%", "(", "\n", "word_dim", ",", "word_status", ",", "char_dim", ",", "char_status", ",", "pos_dim", ",", "pos_status", ")", ")", "\n", "logger", ".", "info", "(", "\"CNN: filter=%d, kernel=%d\"", "%", "(", "num_filters", ",", "window", ")", ")", "\n", "logger", ".", "info", "(", "\"RNN: %s, num_layer=(%d, %d), input_dec=%d, hidden=%d, arc_space=%d, type_space=%d\"", "%", "(", "\n", "mode", ",", "encoder_layers", ",", "decoder_layers", ",", "input_size_decoder", ",", "hidden_size", ",", "arc_space", ",", "type_space", ")", ")", "\n", "logger", ".", "info", "(", "\"train: cov: %.1f, (#data: %d, batch: %d, clip: %.2f, label_smooth: %.2f, unk_repl: %.2f)\"", "%", "(", "\n", "cov", ",", "num_data", ",", "batch_size", ",", "clip", ",", "label_smooth", ",", "unk_replace", ")", ")", "\n", "logger", ".", "info", "(", "\"dropout(in, out, rnn): (%.2f, %.2f, %s)\"", "%", "(", "p_in", ",", "p_out", ",", "p_rnn", ")", ")", "\n", "logger", ".", "info", "(", "'prior order: %s, grand parent: %s, sibling: %s, '", "%", "(", "prior_order", ",", "grandPar", ",", "sibling", ")", ")", "\n", "logger", ".", "info", "(", "'skip connect: %s, beam: %d'", "%", "(", "skipConnect", ",", "beam", ")", ")", "\n", "logger", ".", "info", "(", "opt_info", ")", "\n", "\n", "num_batches", "=", "num_data", "/", "batch_size", "+", "1", "\n", "dev_ucorrect", "=", "0.0", "\n", "dev_lcorrect", "=", "0.0", "\n", "dev_ucomlpete_match", "=", "0.0", "\n", "dev_lcomplete_match", "=", "0.0", "\n", "\n", "dev_ucorrect_nopunc", "=", "0.0", "\n", "dev_lcorrect_nopunc", "=", "0.0", "\n", "dev_ucomlpete_match_nopunc", "=", "0.0", "\n", "dev_lcomplete_match_nopunc", "=", "0.0", "\n", "dev_root_correct", "=", "0.0", "\n", "\n", "best_epoch", "=", "0", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_root_correct", "=", "0.0", "\n", "test_total", "=", "0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "test_total_root", "=", "0", "\n", "\n", "# lrate decay", "\n", "patient", "=", "0", "\n", "decay", "=", "0", "\n", "max_decay", "=", "args", ".", "max_decay", "\n", "double_schedule_decay", "=", "args", ".", "double_schedule_decay", "\n", "\n", "# lrate schedule", "\n", "step_num", "=", "0", "\n", "use_warmup_schedule", "=", "args", ".", "use_warmup_schedule", "\n", "warmup_factor", "=", "(", "lr", "+", "0.", ")", "/", "num_batches", "\n", "\n", "if", "use_warmup_schedule", ":", "\n", "        ", "logger", ".", "info", "(", "\"Use warmup lrate for the first epoch, from 0 up to %s.\"", "%", "(", "lr", ",", ")", ")", "\n", "#", "\n", "", "for", "epoch", "in", "range", "(", "1", ",", "num_epochs", "+", "1", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Epoch %d (%s, optim: %s, learning rate=%.6f, eps=%.1e, decay rate=%.2f '", "\n", "'(schedule=%d, patient=%d, decay=%d (%d, %d))): '", "%", "(", "epoch", ",", "mode", ",", "opt", ",", "lr", ",", "eps", ",", "decay_rate", ",", "\n", "schedule", ",", "patient", ",", "decay", ",", "max_decay", ",", "\n", "double_schedule_decay", ")", ")", "\n", "train_err_arc_leaf", "=", "0.", "\n", "train_err_arc_non_leaf", "=", "0.", "\n", "train_err_type_leaf", "=", "0.", "\n", "train_err_type_non_leaf", "=", "0.", "\n", "train_err_cov", "=", "0.", "\n", "train_total_leaf", "=", "0.", "\n", "train_total_non_leaf", "=", "0.", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "num_back", "=", "0", "\n", "network", ".", "train", "(", ")", "\n", "for", "batch", "in", "range", "(", "1", ",", "num_batches", "+", "1", ")", ":", "\n", "# lrate schedule (before each step)", "\n", "            ", "step_num", "+=", "1", "\n", "if", "use_warmup_schedule", "and", "epoch", "<=", "1", ":", "\n", "                ", "cur_lrate", "=", "warmup_factor", "*", "step_num", "\n", "# set lr", "\n", "for", "param_group", "in", "optim", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "cur_lrate", "\n", "\n", "# train", "\n", "", "", "input_encoder", ",", "input_decoder", "=", "conllx_stacked_data", ".", "get_batch_stacked_variable", "(", "data_train", ",", "batch_size", ",", "\n", "unk_replace", "=", "unk_replace", ")", "\n", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks_e", ",", "lengths_e", "=", "input_encoder", "\n", "stacked_heads", ",", "children", ",", "sibling", ",", "stacked_types", ",", "skip_connect", ",", "masks_d", ",", "lengths_d", "=", "input_decoder", "\n", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "loss_arc_leaf", ",", "loss_arc_non_leaf", ",", "loss_type_leaf", ",", "loss_type_non_leaf", ",", "loss_cov", ",", "num_leaf", ",", "num_non_leaf", "=", "network", ".", "loss", "(", "word", ",", "char", ",", "pos", ",", "heads", ",", "stacked_heads", ",", "children", ",", "sibling", ",", "\n", "stacked_types", ",", "label_smooth", ",", "\n", "skip_connect", "=", "skip_connect", ",", "mask_e", "=", "masks_e", ",", "\n", "length_e", "=", "lengths_e", ",", "mask_d", "=", "masks_d", ",", "length_d", "=", "lengths_d", ")", "\n", "loss_arc", "=", "loss_arc_leaf", "+", "loss_arc_non_leaf", "\n", "loss_type", "=", "loss_type_leaf", "+", "loss_type_non_leaf", "\n", "loss", "=", "loss_arc", "+", "loss_type", "+", "cov", "*", "loss_cov", "\n", "loss", ".", "backward", "(", ")", "\n", "clip_grad_norm", "(", "network", ".", "parameters", "(", ")", ",", "clip", ")", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "num_leaf", "=", "num_leaf", ".", "data", "[", "0", "]", "\n", "num_non_leaf", "=", "num_non_leaf", ".", "data", "[", "0", "]", "\n", "\n", "train_err_arc_leaf", "+=", "loss_arc_leaf", ".", "data", "[", "0", "]", "*", "num_leaf", "\n", "train_err_arc_non_leaf", "+=", "loss_arc_non_leaf", ".", "data", "[", "0", "]", "*", "num_non_leaf", "\n", "\n", "train_err_type_leaf", "+=", "loss_type_leaf", ".", "data", "[", "0", "]", "*", "num_leaf", "\n", "train_err_type_non_leaf", "+=", "loss_type_non_leaf", ".", "data", "[", "0", "]", "*", "num_non_leaf", "\n", "\n", "train_err_cov", "+=", "loss_cov", ".", "data", "[", "0", "]", "*", "(", "num_leaf", "+", "num_non_leaf", ")", "\n", "\n", "train_total_leaf", "+=", "num_leaf", "\n", "train_total_non_leaf", "+=", "num_non_leaf", "\n", "\n", "time_ave", "=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "/", "batch", "\n", "time_left", "=", "(", "num_batches", "-", "batch", ")", "*", "time_ave", "\n", "\n", "# update log", "\n", "if", "batch", "%", "10", "==", "0", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\" \"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "err_arc_leaf", "=", "train_err_arc_leaf", "/", "train_total_leaf", "\n", "err_arc_non_leaf", "=", "train_err_arc_non_leaf", "/", "train_total_non_leaf", "\n", "err_arc", "=", "err_arc_leaf", "+", "err_arc_non_leaf", "\n", "\n", "err_type_leaf", "=", "train_err_type_leaf", "/", "train_total_leaf", "\n", "err_type_non_leaf", "=", "train_err_type_non_leaf", "/", "train_total_non_leaf", "\n", "err_type", "=", "err_type_leaf", "+", "err_type_non_leaf", "\n", "\n", "err_cov", "=", "train_err_cov", "/", "(", "train_total_leaf", "+", "train_total_non_leaf", ")", "\n", "\n", "err", "=", "err_arc", "+", "err_type", "+", "cov", "*", "err_cov", "\n", "log_info", "=", "'train: %d/%d loss (leaf, non_leaf): %.4f, arc: %.4f (%.4f, %.4f), type: %.4f (%.4f, %.4f), coverage: %.4f, time left (estimated): %.2fs'", "%", "(", "\n", "batch", ",", "num_batches", ",", "err", ",", "err_arc", ",", "err_arc_leaf", ",", "err_arc_non_leaf", ",", "err_type", ",", "err_type_leaf", ",", "\n", "err_type_non_leaf", ",", "err_cov", ",", "time_left", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "log_info", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "num_back", "=", "len", "(", "log_info", ")", "\n", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\" \"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "err_arc_leaf", "=", "train_err_arc_leaf", "/", "train_total_leaf", "\n", "err_arc_non_leaf", "=", "train_err_arc_non_leaf", "/", "train_total_non_leaf", "\n", "err_arc", "=", "err_arc_leaf", "+", "err_arc_non_leaf", "\n", "\n", "err_type_leaf", "=", "train_err_type_leaf", "/", "train_total_leaf", "\n", "err_type_non_leaf", "=", "train_err_type_non_leaf", "/", "train_total_non_leaf", "\n", "err_type", "=", "err_type_leaf", "+", "err_type_non_leaf", "\n", "\n", "err_cov", "=", "train_err_cov", "/", "(", "train_total_leaf", "+", "train_total_non_leaf", ")", "\n", "\n", "err", "=", "err_arc", "+", "err_type", "+", "cov", "*", "err_cov", "\n", "logger", ".", "info", "(", "\n", "'train: %d loss (leaf, non_leaf): %.4f, arc: %.4f (%.4f, %.4f), type: %.4f (%.4f, %.4f), coverage: %.4f, time: %.2fs'", "%", "(", "\n", "num_batches", ",", "err", ",", "err_arc", ",", "err_arc_leaf", ",", "err_arc_non_leaf", ",", "err_type", ",", "err_type_leaf", ",", "err_type_non_leaf", ",", "\n", "err_cov", ",", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n", "################################################################################################", "\n", "if", "epoch", "%", "args", ".", "check_dev", "!=", "0", ":", "\n", "            ", "continue", "\n", "\n", "# evaluate performance on dev data", "\n", "", "network", ".", "eval", "(", ")", "\n", "pred_filename", "=", "'tmp/%spred_dev%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "pred_writer", ".", "start", "(", "pred_filename", ")", "\n", "gold_filename", "=", "'tmp/%sgold_dev%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "gold_writer", ".", "start", "(", "gold_filename", ")", "\n", "\n", "dev_ucorr", "=", "0.0", "\n", "dev_lcorr", "=", "0.0", "\n", "dev_total", "=", "0", "\n", "dev_ucomlpete", "=", "0.0", "\n", "dev_lcomplete", "=", "0.0", "\n", "dev_ucorr_nopunc", "=", "0.0", "\n", "dev_lcorr_nopunc", "=", "0.0", "\n", "dev_total_nopunc", "=", "0", "\n", "dev_ucomlpete_nopunc", "=", "0.0", "\n", "dev_lcomplete_nopunc", "=", "0.0", "\n", "dev_root_corr", "=", "0.0", "\n", "dev_total_root", "=", "0.0", "\n", "dev_total_inst", "=", "0.0", "\n", "for", "batch", "in", "conllx_stacked_data", ".", "iterate_batch_stacked_variable", "(", "data_dev", ",", "batch_size", ")", ":", "\n", "            ", "input_encoder", ",", "_", "=", "batch", "\n", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "input_encoder", "\n", "heads_pred", ",", "types_pred", ",", "_", ",", "_", "=", "network", ".", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ",", "beam", "=", "beam", ",", "\n", "leading_symbolic", "=", "conllx_stacked_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "\n", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "\n", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "dev_ucorr", "+=", "ucorr", "\n", "dev_lcorr", "+=", "lcorr", "\n", "dev_total", "+=", "total", "\n", "dev_ucomlpete", "+=", "ucm", "\n", "dev_lcomplete", "+=", "lcm", "\n", "\n", "dev_ucorr_nopunc", "+=", "ucorr_nopunc", "\n", "dev_lcorr_nopunc", "+=", "lcorr_nopunc", "\n", "dev_total_nopunc", "+=", "total_nopunc", "\n", "dev_ucomlpete_nopunc", "+=", "ucm_nopunc", "\n", "dev_lcomplete_nopunc", "+=", "lcm_nopunc", "\n", "\n", "dev_root_corr", "+=", "corr_root", "\n", "dev_total_root", "+=", "total_root", "\n", "\n", "dev_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "print", "(", "'W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr", ",", "dev_lcorr", ",", "dev_total", ",", "dev_ucorr", "*", "100", "/", "dev_total", ",", "dev_lcorr", "*", "100", "/", "dev_total", ",", "\n", "dev_ucomlpete", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "'Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr_nopunc", ",", "dev_lcorr_nopunc", ",", "dev_total_nopunc", ",", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_lcorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "dev_ucomlpete_nopunc", "*", "100", "/", "dev_total_inst", ",", "\n", "dev_lcomplete_nopunc", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "'Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "\n", "dev_root_corr", ",", "dev_total_root", ",", "dev_root_corr", "*", "100", "/", "dev_total_root", ")", ")", "\n", "\n", "if", "dev_lcorrect_nopunc", "<", "dev_lcorr_nopunc", "or", "(", "\n", "dev_lcorrect_nopunc", "==", "dev_lcorr_nopunc", "and", "dev_ucorrect_nopunc", "<", "dev_ucorr_nopunc", ")", ":", "\n", "            ", "dev_ucorrect_nopunc", "=", "dev_ucorr_nopunc", "\n", "dev_lcorrect_nopunc", "=", "dev_lcorr_nopunc", "\n", "dev_ucomlpete_match_nopunc", "=", "dev_ucomlpete_nopunc", "\n", "dev_lcomplete_match_nopunc", "=", "dev_lcomplete_nopunc", "\n", "\n", "dev_ucorrect", "=", "dev_ucorr", "\n", "dev_lcorrect", "=", "dev_lcorr", "\n", "dev_ucomlpete_match", "=", "dev_ucomlpete", "\n", "dev_lcomplete_match", "=", "dev_lcomplete", "\n", "\n", "dev_root_correct", "=", "dev_root_corr", "\n", "\n", "best_epoch", "=", "epoch", "\n", "patient", "=", "0", "\n", "# torch.save(network, model_name)", "\n", "torch", ".", "save", "(", "network", ".", "state_dict", "(", ")", ",", "model_name", ")", "\n", "\n", "pred_filename", "=", "'tmp/%spred_test%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "pred_writer", ".", "start", "(", "pred_filename", ")", "\n", "gold_filename", "=", "'tmp/%sgold_test%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "gold_writer", ".", "start", "(", "gold_filename", ")", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "test_total", "=", "0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "\n", "test_root_correct", "=", "0.0", "\n", "test_total_root", "=", "0", "\n", "for", "batch", "in", "conllx_stacked_data", ".", "iterate_batch_stacked_variable", "(", "data_test", ",", "batch_size", ")", ":", "\n", "                ", "input_encoder", ",", "_", "=", "batch", "\n", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "input_encoder", "\n", "heads_pred", ",", "types_pred", ",", "_", ",", "_", "=", "network", ".", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ",", "beam", "=", "beam", ",", "\n", "leading_symbolic", "=", "conllx_stacked_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "\n", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "\n", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "test_ucorrect", "+=", "ucorr", "\n", "test_lcorrect", "+=", "lcorr", "\n", "test_total", "+=", "total", "\n", "test_ucomlpete_match", "+=", "ucm", "\n", "test_lcomplete_match", "+=", "lcm", "\n", "\n", "test_ucorrect_nopunc", "+=", "ucorr_nopunc", "\n", "test_lcorrect_nopunc", "+=", "lcorr_nopunc", "\n", "test_total_nopunc", "+=", "total_nopunc", "\n", "test_ucomlpete_match_nopunc", "+=", "ucm_nopunc", "\n", "test_lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "test_root_correct", "+=", "corr_root", "\n", "test_total_root", "+=", "total_root", "\n", "\n", "test_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "if", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", "<", "dev_ucorrect_nopunc", "*", "100", "/", "dev_total_nopunc", "-", "5", "or", "patient", ">=", "schedule", ":", "\n", "                ", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "lr", "=", "lr", "*", "decay_rate", "\n", "optim", "=", "generate_optimizer", "(", "opt", ",", "lr", ",", "network", ".", "parameters", "(", ")", ")", "\n", "patient", "=", "0", "\n", "decay", "+=", "1", "\n", "if", "decay", "%", "double_schedule_decay", "==", "0", ":", "\n", "                    ", "schedule", "*=", "2", "\n", "", "", "else", ":", "\n", "                ", "patient", "+=", "1", "\n", "\n", "", "", "logger", ".", "info", "(", "\n", "'----------------------------------------------------------------------------------------------------------------------------'", ")", "\n", "logger", ".", "info", "(", "\n", "'best dev  W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_ucorrect", ",", "dev_lcorrect", ",", "dev_total", ",", "dev_ucorrect", "*", "100", "/", "dev_total", ",", "dev_lcorrect", "*", "100", "/", "dev_total", ",", "\n", "dev_ucomlpete_match", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_match", "*", "100", "/", "dev_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\n", "'best dev  Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_ucorrect_nopunc", ",", "dev_lcorrect_nopunc", ",", "dev_total_nopunc", ",", "\n", "dev_ucorrect_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "dev_lcorrect_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_ucomlpete_match_nopunc", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_match_nopunc", "*", "100", "/", "dev_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "'best dev  Root: corr: %d, total: %d, acc: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_root_correct", ",", "dev_total_root", ",", "dev_root_correct", "*", "100", "/", "dev_total_root", ",", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\n", "'----------------------------------------------------------------------------------------------------------------------------'", ")", "\n", "logger", ".", "info", "(", "\n", "'best test W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucorrect", "*", "100", "/", "test_total", ",", "\n", "test_lcorrect", "*", "100", "/", "test_total", ",", "\n", "test_ucomlpete_match", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match", "*", "100", "/", "test_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\n", "'best test Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "\n", "test_ucorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "test_lcorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_ucomlpete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "\n", "test_lcomplete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "'best test Root: corr: %d, total: %d, acc: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_root_correct", ",", "test_total_root", ",", "test_root_correct", "*", "100", "/", "test_total_root", ",", "best_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\n", "'============================================================================================================================'", ")", "\n", "\n", "if", "decay", "==", "max_decay", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.main": [[36, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "neuronlp2.io.get_logger", "set", "neuronlp2.io.get_logger.info", "analyze.stackptr", "analyze.biaffine", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.stackptr", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.biaffine"], ["def", "main", "(", ")", ":", "\n", "    ", "args_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Tuning with stack pointer parser'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--parser'", ",", "choices", "=", "[", "'stackptr'", ",", "'biaffine'", "]", ",", "help", "=", "'Parser'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--test'", ")", "# \"data/POS-penn/wsj/split1/wsj1.test.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--model_path'", ",", "help", "=", "'path for saving model file.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_name'", ",", "help", "=", "'name for saving model file.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--out_filename'", ",", "help", "=", "'filename to save analysis results.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--punctuation'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "help", "=", "'List of punctuations'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--beam'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Beam size for decoding'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--ordered'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Using order constraints in decoding'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decode'", ",", "choices", "=", "[", "'mst'", ",", "'greedy'", "]", ",", "default", "=", "'mst'", ",", "help", "=", "'decoding algorithm'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--display'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Display wrong examples'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--gpu'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Using GPU'", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--extra_embed'", ",", "type", "=", "str", ",", "help", "=", "\"Path for extra embedding file for extra language testing.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--extra_embed_src'", ",", "type", "=", "str", ",", "help", "=", "\"Path for extra embedding file for src language (maybe need adding new ones).\"", ")", "\n", "\n", "args", "=", "args_parser", ".", "parse_args", "(", ")", "\n", "\n", "logger", "=", "get_logger", "(", "\"Analyzer\"", ")", "\n", "\n", "test_path", "=", "args", ".", "test", "\n", "model_path", "=", "args", ".", "model_path", "\n", "model_name", "=", "args", ".", "model_name", "\n", "\n", "punct_set", "=", "None", "\n", "punctuation", "=", "args", ".", "punctuation", "\n", "if", "punctuation", "is", "not", "None", ":", "\n", "        ", "punct_set", "=", "set", "(", "punctuation", ")", "\n", "logger", ".", "info", "(", "\"punctuations(%d): %s\"", "%", "(", "len", "(", "punct_set", ")", ",", "' '", ".", "join", "(", "punct_set", ")", ")", ")", "\n", "\n", "", "use_gpu", "=", "args", ".", "gpu", "\n", "parser", "=", "args", ".", "parser", "\n", "\n", "if", "parser", "==", "'stackptr'", ":", "\n", "        ", "stackptr", "(", "model_path", ",", "model_name", ",", "test_path", ",", "punct_set", ",", "use_gpu", ",", "logger", ",", "args", ")", "\n", "", "elif", "parser", "==", "'biaffine'", ":", "\n", "        ", "biaffine", "(", "model_path", ",", "model_name", ",", "test_path", ",", "punct_set", ",", "use_gpu", ",", "logger", ",", "args", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown parser: %s'", "%", "parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.augment_with_extra_embedding": [[79, 120], ["logger.info", "the_alphabet.open", "neuronlp2.utils.load_embedding_dict", "neuronlp2.io_multi.guess_language_id", "neuronlp2.io_multi.multi_vocab.iter_file", "the_alphabet.close", "neuronlp2.utils.load_embedding_dict", "w.startswith", "len", "the_alphabet.size", "neuronlp2.io.utils.DIGIT_RE.sub", "neuronlp2.io_multi.lang_specific_word", "extra_embeds_arr.append", "the_alphabet.add", "w.lower", "w.lower"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.neuronlp2.utils.load_embedding_dict", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.guess_language_id", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.multi_vocab.iter_file", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.neuronlp2.utils.load_embedding_dict", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add"], ["", "", "def", "augment_with_extra_embedding", "(", "the_alphabet", ",", "extra_embed_file", ",", "extra_embed_src_file", ",", "test_file", ",", "logger", ")", ":", "\n", "    ", "extra_embeds_arr", "=", "[", "]", "\n", "if", "extra_embed_file", "is", "not", "None", ":", "\n", "# reopen the vocab", "\n", "        ", "the_alphabet", ".", "open", "(", ")", "\n", "# read the embed", "\n", "extra_word_dict", ",", "_", "=", "load_embedding_dict", "(", "'word2vec'", ",", "extra_embed_file", ")", "\n", "if", "extra_embed_src_file", "is", "not", "None", ":", "\n", "            ", "src_extra_word_dict", ",", "_", "=", "load_embedding_dict", "(", "'word2vec'", ",", "extra_embed_src_file", ")", "\n", "", "lang_id", "=", "guess_language_id", "(", "test_file", ")", "\n", "for", "one_sent", "in", "iter_file", "(", "test_file", ")", ":", "\n", "            ", "for", "w", "in", "one_sent", "[", "\"word\"", "]", ":", "\n", "                ", "already_spec", "=", "w", ".", "startswith", "(", "\"!en_\"", ")", "\n", "if", "already_spec", ":", "\n", "                    ", "normed_word", "=", "w", "\n", "", "else", ":", "\n", "                    ", "normed_word", "=", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "w", ")", "\n", "normed_word", "=", "lang_specific_word", "(", "normed_word", ",", "lang_id", "=", "lang_id", ")", "\n", "#", "\n", "", "if", "normed_word", "in", "the_alphabet", ".", "instance2index", ":", "\n", "                    ", "continue", "\n", "# TODO: assume english is the source for run-translate", "\n", "", "if", "already_spec", ":", "\n", "                    ", "w", "=", "w", "[", "4", ":", "]", "\n", "check_dict", "=", "src_extra_word_dict", "\n", "", "else", ":", "\n", "                    ", "check_dict", "=", "extra_word_dict", "\n", "#", "\n", "", "if", "w", "in", "check_dict", ":", "\n", "                    ", "new_embed_arr", "=", "check_dict", "[", "w", "]", "\n", "", "elif", "w", ".", "lower", "(", ")", "in", "check_dict", ":", "\n", "                    ", "new_embed_arr", "=", "check_dict", "[", "w", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "new_embed_arr", "=", "None", "\n", "", "if", "new_embed_arr", "is", "not", "None", ":", "\n", "                    ", "extra_embeds_arr", ".", "append", "(", "new_embed_arr", ")", "\n", "the_alphabet", ".", "add", "(", "normed_word", ")", "\n", "# close the vocab", "\n", "", "", "", "the_alphabet", ".", "close", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Augmenting the vocab with new words of %s, now vocab is %s.\"", "%", "(", "len", "(", "extra_embeds_arr", ")", ",", "the_alphabet", ".", "size", "(", ")", ")", ")", "\n", "return", "extra_embeds_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.augment_network_embed": [[121, 132], ["old_embed.weight.data.cpu().numpy", "numpy.concatenate", "neuronlp2.nn.Embedding", "len", "old_embed.weight.data.cpu", "torch.from_numpy"], "function", ["None"], ["", "def", "augment_network_embed", "(", "new_size", ",", "network", ",", "extra_embeds_arr", ")", ":", "\n", "    ", "if", "len", "(", "extra_embeds_arr", ")", "==", "0", ":", "\n", "        ", "return", "\n", "", "old_embed", "=", "network", ".", "word_embedd", "\n", "if", "old_embed", "is", "None", ":", "\n", "        ", "return", "\n", "", "old_arr", "=", "old_embed", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "new_arr", "=", "np", ".", "concatenate", "(", "[", "old_arr", ",", "extra_embeds_arr", "]", ",", "0", ")", "\n", "assert", "new_arr", ".", "shape", "[", "0", "]", "==", "new_size", "\n", "new_embed", "=", "Embedding", "(", "new_size", ",", "new_arr", ".", "shape", "[", "1", "]", ",", "init_embedding", "=", "torch", ".", "from_numpy", "(", "new_arr", ")", ")", "\n", "network", ".", "word_embedd", "=", "new_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.biaffine": [[135, 284], ["os.path.join", "os.path.join", "neuronlp2.io.conllx_data.create_alphabets", "word_alphabet.size", "char_alphabet.size", "pos_alphabet.size", "type_alphabet.size", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "analyze.augment_with_extra_embedding", "analyze.biaffine._read_one"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.augment_with_extra_embedding"], ["", "def", "biaffine", "(", "model_path", ",", "model_name", ",", "test_path", ",", "punct_set", ",", "use_gpu", ",", "logger", ",", "args", ")", ":", "\n", "    ", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'alphabets/'", ")", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "model_name", ")", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "conllx_data", ".", "create_alphabets", "(", "alphabet_path", ",", "\n", "None", ",", "data_paths", "=", "[", "None", ",", "None", "]", ",", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "None", ")", "\n", "# word_alphabet, char_alphabet, pos_alphabet, type_alphabet = create_alphabets(alphabet_path,", "\n", "#     None, data_paths=[None, None], max_vocabulary_size=50000, embedd_dict=None)", "\n", "\n", "num_words", "=", "word_alphabet", ".", "size", "(", ")", "\n", "num_chars", "=", "char_alphabet", ".", "size", "(", ")", "\n", "num_pos", "=", "pos_alphabet", ".", "size", "(", ")", "\n", "num_types", "=", "type_alphabet", ".", "size", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size: %d\"", "%", "num_words", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "num_chars", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "num_pos", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "num_types", ")", "\n", "\n", "decoding", "=", "args", ".", "decode", "\n", "out_filename", "=", "args", ".", "out_filename", "\n", "\n", "logger", ".", "info", "(", "'use gpu: %s, decoding: %s'", "%", "(", "use_gpu", ",", "decoding", ")", ")", "\n", "\n", "#", "\n", "extra_embeds_arr", "=", "augment_with_extra_embedding", "(", "word_alphabet", ",", "args", ".", "extra_embed", ",", "args", ".", "extra_embed_src", ",", "test_path", ",", "logger", ")", "\n", "\n", "# ===== the reading", "\n", "def", "_read_one", "(", "path", ",", "is_train", ")", ":", "\n", "        ", "lang_id", "=", "guess_language_id", "(", "path", ")", "\n", "logger", ".", "info", "(", "\"Reading: guess that the language of file %s is %s.\"", "%", "(", "path", ",", "lang_id", ")", ")", "\n", "one_data", "=", "conllx_data", ".", "read_data_to_variable", "(", "path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "(", "not", "is_train", ")", ",", "symbolic_root", "=", "True", ",", "lang_id", "=", "lang_id", ")", "\n", "return", "one_data", "\n", "\n", "", "data_test", "=", "_read_one", "(", "test_path", ",", "False", ")", "\n", "\n", "# data_test = conllx_data.read_data_to_variable(test_path, word_alphabet, char_alphabet, pos_alphabet, type_alphabet,", "\n", "#                                               use_gpu=use_gpu, volatile=True, symbolic_root=True)", "\n", "\n", "pred_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "gold_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "\n", "logger", ".", "info", "(", "'model: %s'", "%", "model_name", ")", "\n", "\n", "def", "load_model_arguments_from_json", "(", ")", ":", "\n", "        ", "arguments", "=", "json", ".", "load", "(", "open", "(", "arg_path", ",", "'r'", ")", ")", "\n", "return", "arguments", "[", "'args'", "]", ",", "arguments", "[", "'kwargs'", "]", "\n", "\n", "", "arg_path", "=", "model_name", "+", "'.arg.json'", "\n", "args", ",", "kwargs", "=", "load_model_arguments_from_json", "(", ")", "\n", "network", "=", "BiRecurrentConvBiAffine", "(", "use_gpu", "=", "use_gpu", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "\n", "#", "\n", "augment_network_embed", "(", "word_alphabet", ".", "size", "(", ")", ",", "network", ",", "extra_embeds_arr", ")", "\n", "\n", "if", "use_gpu", ":", "\n", "        ", "network", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "network", ".", "cpu", "(", ")", "\n", "\n", "", "network", ".", "eval", "(", ")", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "test_total", "=", "0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "\n", "test_root_correct", "=", "0.0", "\n", "test_total_root", "=", "0", "\n", "\n", "if", "decoding", "==", "'greedy'", ":", "\n", "        ", "decode", "=", "network", ".", "decode", "\n", "", "elif", "decoding", "==", "'mst'", ":", "\n", "        ", "decode", "=", "network", ".", "decode_mst", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown decoding algorithm: %s'", "%", "decoding", ")", "\n", "\n", "# pred_writer.start('tmp/analyze_pred_%s' % str(uid))", "\n", "# gold_writer.start('tmp/analyze_gold_%s' % str(uid))", "\n", "# pred_writer.start(model_path + out_filename + '_pred')", "\n", "# gold_writer.start(model_path + out_filename + '_gold')", "\n", "", "pred_writer", ".", "start", "(", "out_filename", "+", "'_pred'", ")", "\n", "gold_writer", ".", "start", "(", "out_filename", "+", "'_gold'", ")", "\n", "\n", "sent", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "batch", "in", "conllx_data", ".", "iterate_batch_variable", "(", "data_test", ",", "1", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'%d, '", "%", "sent", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "sent", "+=", "1", "\n", "\n", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "batch", "\n", "heads_pred", ",", "types_pred", "=", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ",", "\n", "leading_symbolic", "=", "conllx_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "\n", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "\n", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "test_ucorrect", "+=", "ucorr", "\n", "test_lcorrect", "+=", "lcorr", "\n", "test_total", "+=", "total", "\n", "test_ucomlpete_match", "+=", "ucm", "\n", "test_lcomplete_match", "+=", "lcm", "\n", "\n", "test_ucorrect_nopunc", "+=", "ucorr_nopunc", "\n", "test_lcorrect_nopunc", "+=", "lcorr_nopunc", "\n", "test_total_nopunc", "+=", "total_nopunc", "\n", "test_ucomlpete_match_nopunc", "+=", "ucm_nopunc", "\n", "test_lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "test_root_correct", "+=", "corr_root", "\n", "test_total_root", "+=", "total_root", "\n", "\n", "test_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "\n", "print", "(", "'\\ntime: %.2fs'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "print", "(", "'test W. Punct:  ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucorrect", "*", "100", "/", "test_total", ",", "test_lcorrect", "*", "100", "/", "test_total", ",", "\n", "test_ucomlpete_match", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match", "*", "100", "/", "test_total_inst", ")", ")", "\n", "print", "(", "'test Wo Punct:  ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "\n", "test_ucorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "test_lcorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_ucomlpete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match_nopunc", "*", "100", "/", "test_total_inst", ")", ")", "\n", "print", "(", "'test Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "\n", "test_root_correct", ",", "test_total_root", ",", "test_root_correct", "*", "100", "/", "test_total_root", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.stackptr": [[286, 575], ["os.path.join", "os.path.join", "neuronlp2.io.conllx_stacked_data.create_alphabets", "word_alphabet.size", "char_alphabet.size", "pos_alphabet.size", "type_alphabet.size", "logger.info", "logger.info", "logger.info", "logger.info", "analyze.biaffine.load_model_arguments_from_json"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "stackptr", "(", "model_path", ",", "model_name", ",", "test_path", ",", "punct_set", ",", "use_gpu", ",", "logger", ",", "args", ")", ":", "\n", "    ", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'alphabets/'", ")", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "model_name", ")", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "conllx_stacked_data", ".", "create_alphabets", "(", "alphabet_path", ",", "None", ",", "data_paths", "=", "[", "None", ",", "None", "]", ",", "\n", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "None", ")", "\n", "\n", "num_words", "=", "word_alphabet", ".", "size", "(", ")", "\n", "num_chars", "=", "char_alphabet", ".", "size", "(", ")", "\n", "num_pos", "=", "pos_alphabet", ".", "size", "(", ")", "\n", "num_types", "=", "type_alphabet", ".", "size", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size: %d\"", "%", "num_words", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "num_chars", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "num_pos", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "num_types", ")", "\n", "\n", "beam", "=", "args", ".", "beam", "\n", "ordered", "=", "args", ".", "ordered", "\n", "display_inst", "=", "args", ".", "display", "\n", "out_filename", "=", "args", ".", "out_filename", "\n", "extra_embed", "=", "args", ".", "extra_embed", "\n", "\n", "def", "load_model_arguments_from_json", "(", ")", ":", "\n", "        ", "arguments", "=", "json", ".", "load", "(", "open", "(", "arg_path", ",", "'r'", ")", ")", "\n", "return", "arguments", "[", "'args'", "]", ",", "arguments", "[", "'kwargs'", "]", "\n", "\n", "", "arg_path", "=", "model_name", "+", "'.arg.json'", "\n", "args", ",", "kwargs", "=", "load_model_arguments_from_json", "(", ")", "\n", "\n", "prior_order", "=", "kwargs", "[", "'prior_order'", "]", "\n", "logger", ".", "info", "(", "'use gpu: %s, beam: %d, order: %s (%s)'", "%", "(", "use_gpu", ",", "beam", ",", "prior_order", ",", "ordered", ")", ")", "\n", "\n", "#", "\n", "extra_embeds_arr", "=", "augment_with_extra_embedding", "(", "word_alphabet", ",", "extra_embed", ",", "args", ".", "extra_embed_src", ",", "test_path", ",", "logger", ")", "\n", "\n", "# ===== the reading", "\n", "def", "_read_one", "(", "path", ",", "is_train", ")", ":", "\n", "        ", "lang_id", "=", "guess_language_id", "(", "path", ")", "\n", "logger", ".", "info", "(", "\"Reading: guess that the language of file %s is %s.\"", "%", "(", "path", ",", "lang_id", ")", ")", "\n", "one_data", "=", "conllx_stacked_data", ".", "read_stacked_data_to_variable", "(", "path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "(", "not", "is_train", ")", ",", "prior_order", "=", "prior_order", ",", "lang_id", "=", "lang_id", ")", "\n", "return", "one_data", "\n", "\n", "", "data_test", "=", "_read_one", "(", "test_path", ",", "False", ")", "\n", "\n", "pred_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "gold_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "\n", "logger", ".", "info", "(", "'model: %s'", "%", "model_name", ")", "\n", "network", "=", "StackPtrNet", "(", "use_gpu", "=", "use_gpu", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "\n", "#", "\n", "augment_network_embed", "(", "word_alphabet", ".", "size", "(", ")", ",", "network", ",", "extra_embeds_arr", ")", "\n", "\n", "if", "use_gpu", ":", "\n", "        ", "network", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "network", ".", "cpu", "(", ")", "\n", "\n", "", "network", ".", "eval", "(", ")", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "test_total", "=", "0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "\n", "test_root_correct", "=", "0.0", "\n", "test_total_root", "=", "0", "\n", "\n", "test_ucorrect_stack_leaf", "=", "0.0", "\n", "test_ucorrect_stack_non_leaf", "=", "0.0", "\n", "\n", "test_lcorrect_stack_leaf", "=", "0.0", "\n", "test_lcorrect_stack_non_leaf", "=", "0.0", "\n", "\n", "test_leaf", "=", "0", "\n", "test_non_leaf", "=", "0", "\n", "\n", "# pred_writer.start('tmp/analyze_pred_%s' % str(uid))", "\n", "# gold_writer.start('tmp/analyze_gold_%s' % str(uid))", "\n", "# pred_writer.start(model_path + out_filename + '_pred')", "\n", "# gold_writer.start(model_path + out_filename + '_gold')", "\n", "pred_writer", ".", "start", "(", "out_filename", "+", "'_pred'", ")", "\n", "gold_writer", ".", "start", "(", "out_filename", "+", "'_gold'", ")", "\n", "\n", "sent", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "batch", "in", "conllx_stacked_data", ".", "iterate_batch_stacked_variable", "(", "data_test", ",", "1", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'%d, '", "%", "sent", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "sent", "+=", "1", "\n", "\n", "input_encoder", ",", "input_decoder", "=", "batch", "\n", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "input_encoder", "\n", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", ",", "mask_d", ",", "lengths_d", "=", "input_decoder", "\n", "heads_pred", ",", "types_pred", ",", "children_pred", ",", "stacked_types_pred", "=", "network", ".", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "\n", "length", "=", "lengths", ",", "beam", "=", "beam", ",", "\n", "ordered", "=", "ordered", ",", "\n", "leading_symbolic", "=", "conllx_stacked_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "\n", "stacked_heads", "=", "stacked_heads", ".", "data", "\n", "children", "=", "children", ".", "data", "\n", "stacked_types", "=", "stacked_types", ".", "data", "\n", "children_pred", "=", "torch", ".", "from_numpy", "(", "children_pred", ")", ".", "long", "(", ")", "\n", "stacked_types_pred", "=", "torch", ".", "from_numpy", "(", "stacked_types_pred", ")", ".", "long", "(", ")", "\n", "if", "use_gpu", ":", "\n", "            ", "children_pred", "=", "children_pred", ".", "cuda", "(", ")", "\n", "stacked_types_pred", "=", "stacked_types_pred", ".", "cuda", "(", ")", "\n", "", "mask_d", "=", "mask_d", ".", "data", "\n", "mask_leaf", "=", "torch", ".", "eq", "(", "children", ",", "stacked_heads", ")", ".", "float", "(", ")", "\n", "mask_non_leaf", "=", "(", "1.0", "-", "mask_leaf", ")", "\n", "mask_leaf", "=", "mask_leaf", "*", "mask_d", "\n", "mask_non_leaf", "=", "mask_non_leaf", "*", "mask_d", "\n", "num_leaf", "=", "mask_leaf", ".", "sum", "(", ")", "\n", "num_non_leaf", "=", "mask_non_leaf", ".", "sum", "(", ")", "\n", "\n", "ucorr_stack", "=", "torch", ".", "eq", "(", "children_pred", ",", "children", ")", ".", "float", "(", ")", "\n", "lcorr_stack", "=", "ucorr_stack", "*", "torch", ".", "eq", "(", "stacked_types_pred", ",", "stacked_types", ")", ".", "float", "(", ")", "\n", "ucorr_stack_leaf", "=", "(", "ucorr_stack", "*", "mask_leaf", ")", ".", "sum", "(", ")", "\n", "ucorr_stack_non_leaf", "=", "(", "ucorr_stack", "*", "mask_non_leaf", ")", ".", "sum", "(", ")", "\n", "\n", "lcorr_stack_leaf", "=", "(", "lcorr_stack", "*", "mask_leaf", ")", ".", "sum", "(", ")", "\n", "lcorr_stack_non_leaf", "=", "(", "lcorr_stack", "*", "mask_non_leaf", ")", ".", "sum", "(", ")", "\n", "\n", "test_ucorrect_stack_leaf", "+=", "ucorr_stack_leaf", "\n", "test_ucorrect_stack_non_leaf", "+=", "ucorr_stack_non_leaf", "\n", "test_lcorrect_stack_leaf", "+=", "lcorr_stack_leaf", "\n", "test_lcorrect_stack_non_leaf", "+=", "lcorr_stack_non_leaf", "\n", "\n", "test_leaf", "+=", "num_leaf", "\n", "test_non_leaf", "+=", "num_non_leaf", "\n", "\n", "# ------------------------------------------------------------------------------------------------", "\n", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "\n", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "\n", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "test_ucorrect", "+=", "ucorr", "\n", "test_lcorrect", "+=", "lcorr", "\n", "test_total", "+=", "total", "\n", "test_ucomlpete_match", "+=", "ucm", "\n", "test_lcomplete_match", "+=", "lcm", "\n", "\n", "test_ucorrect_nopunc", "+=", "ucorr_nopunc", "\n", "test_lcorrect_nopunc", "+=", "lcorr_nopunc", "\n", "test_total_nopunc", "+=", "total_nopunc", "\n", "test_ucomlpete_match_nopunc", "+=", "ucm_nopunc", "\n", "test_lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "test_root_correct", "+=", "corr_root", "\n", "test_total_root", "+=", "total_root", "\n", "\n", "test_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "\n", "print", "(", "'\\ntime: %.2fs'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n", "print", "(", "'test W. Punct:  ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucorrect", "*", "100", "/", "test_total", ",", "test_lcorrect", "*", "100", "/", "test_total", ",", "\n", "test_ucomlpete_match", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match", "*", "100", "/", "test_total_inst", ")", ")", "\n", "print", "(", "'test Wo Punct:  ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "\n", "test_ucorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "test_lcorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_ucomlpete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match_nopunc", "*", "100", "/", "test_total_inst", ")", ")", "\n", "print", "(", "'test Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "\n", "test_root_correct", ",", "test_total_root", ",", "test_root_correct", "*", "100", "/", "test_total_root", ")", ")", "\n", "print", "(", "\n", "'============================================================================================================================'", ")", "\n", "\n", "print", "(", "'Stack leaf:     ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%'", "%", "(", "\n", "test_ucorrect_stack_leaf", ",", "test_lcorrect_stack_leaf", ",", "test_leaf", ",", "\n", "test_ucorrect_stack_leaf", "*", "100", "/", "test_leaf", ",", "test_lcorrect_stack_leaf", "*", "100", "/", "test_leaf", ")", ")", "\n", "print", "(", "'Stack non_leaf: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%'", "%", "(", "\n", "test_ucorrect_stack_non_leaf", ",", "test_lcorrect_stack_non_leaf", ",", "test_non_leaf", ",", "\n", "test_ucorrect_stack_non_leaf", "*", "100", "/", "test_non_leaf", ",", "test_lcorrect_stack_non_leaf", "*", "100", "/", "test_non_leaf", ")", ")", "\n", "print", "(", "\n", "'============================================================================================================================'", ")", "\n", "\n", "def", "analyze", "(", ")", ":", "\n", "        ", "np", ".", "set_printoptions", "(", "linewidth", "=", "100000", ")", "\n", "# pred_path = 'tmp/analyze_pred_%s' % str(uid)", "\n", "pred_path", "=", "model_path", "+", "out_filename", "+", "'_pred'", "\n", "data_gold", "=", "conllx_stacked_data", ".", "read_stacked_data_to_variable", "(", "test_path", ",", "word_alphabet", ",", "char_alphabet", ",", "\n", "pos_alphabet", ",", "type_alphabet", ",", "\n", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "True", ",", "\n", "prior_order", "=", "prior_order", ")", "\n", "data_pred", "=", "conllx_stacked_data", ".", "read_stacked_data_to_variable", "(", "pred_path", ",", "word_alphabet", ",", "char_alphabet", ",", "\n", "pos_alphabet", ",", "type_alphabet", ",", "\n", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "True", ",", "\n", "prior_order", "=", "prior_order", ")", "\n", "\n", "gold_iter", "=", "conllx_stacked_data", ".", "iterate_batch_stacked_variable", "(", "data_gold", ",", "1", ")", "\n", "test_iter", "=", "conllx_stacked_data", ".", "iterate_batch_stacked_variable", "(", "data_pred", ",", "1", ")", "\n", "model_err", "=", "0", "\n", "search_err", "=", "0", "\n", "type_err", "=", "0", "\n", "for", "gold", ",", "pred", "in", "zip", "(", "gold_iter", ",", "test_iter", ")", ":", "\n", "            ", "gold_encoder", ",", "gold_decoder", "=", "gold", "\n", "word", ",", "char", ",", "pos", ",", "gold_heads", ",", "gold_types", ",", "masks", ",", "lengths", "=", "gold_encoder", "\n", "gold_stacked_heads", ",", "gold_children", ",", "gold_siblings", ",", "gold_stacked_types", ",", "gold_skip_connect", ",", "gold_mask_d", ",", "gold_lengths_d", "=", "gold_decoder", "\n", "\n", "pred_encoder", ",", "pred_decoder", "=", "pred", "\n", "_", ",", "_", ",", "_", ",", "pred_heads", ",", "pred_types", ",", "_", ",", "_", "=", "pred_encoder", "\n", "pred_stacked_heads", ",", "pred_children", ",", "pred_siblings", ",", "pred_stacked_types", ",", "pred_skip_connect", ",", "pred_mask_d", ",", "pred_lengths_d", "=", "pred_decoder", "\n", "\n", "assert", "gold_heads", ".", "size", "(", ")", "==", "pred_heads", ".", "size", "(", ")", ",", "'sentence dis-match.'", "\n", "\n", "ucorr_stack", "=", "torch", ".", "eq", "(", "pred_children", ",", "gold_children", ")", ".", "float", "(", ")", "\n", "lcorr_stack", "=", "ucorr_stack", "*", "torch", ".", "eq", "(", "pred_stacked_types", ",", "gold_stacked_types", ")", ".", "float", "(", ")", "\n", "ucorr_stack", "=", "(", "ucorr_stack", "*", "gold_mask_d", ")", ".", "data", ".", "sum", "(", ")", "\n", "lcorr_stack", "=", "(", "lcorr_stack", "*", "gold_mask_d", ")", ".", "data", ".", "sum", "(", ")", "\n", "num_stack", "=", "gold_mask_d", ".", "data", ".", "sum", "(", ")", "\n", "\n", "if", "lcorr_stack", "<", "num_stack", ":", "\n", "                ", "loss_pred", ",", "loss_pred_arc", ",", "loss_pred_type", "=", "calc_loss", "(", "network", ",", "word", ",", "char", ",", "pos", ",", "pred_heads", ",", "\n", "pred_stacked_heads", ",", "pred_children", ",", "pred_siblings", ",", "\n", "pred_stacked_types", ",", "\n", "pred_skip_connect", ",", "masks", ",", "lengths", ",", "pred_mask_d", ",", "\n", "pred_lengths_d", ")", "\n", "\n", "loss_gold", ",", "loss_gold_arc", ",", "loss_gold_type", "=", "calc_loss", "(", "network", ",", "word", ",", "char", ",", "pos", ",", "gold_heads", ",", "\n", "gold_stacked_heads", ",", "gold_children", ",", "gold_siblings", ",", "\n", "gold_stacked_types", ",", "\n", "gold_skip_connect", ",", "masks", ",", "lengths", ",", "gold_mask_d", ",", "\n", "gold_lengths_d", ")", "\n", "\n", "if", "display_inst", ":", "\n", "                    ", "print", "(", "'%d, %d, %d'", "%", "(", "ucorr_stack", ",", "lcorr_stack", ",", "num_stack", ")", ")", "\n", "print", "(", "'pred(arc, type): %.4f (%.4f, %.4f), gold(arc, type): %.4f (%.4f, %.4f)'", "%", "(", "\n", "loss_pred", ",", "loss_pred_arc", ",", "loss_pred_type", ",", "loss_gold", ",", "loss_gold_arc", ",", "loss_gold_type", ")", ")", "\n", "word", "=", "word", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "head_gold", "=", "gold_heads", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "type_gold", "=", "gold_types", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "head_pred", "=", "pred_heads", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "type_pred", "=", "pred_types", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "display", "(", "word", ",", "pos", ",", "head_gold", ",", "type_gold", ",", "head_pred", ",", "type_pred", ",", "lengths", "[", "0", "]", ",", "word_alphabet", ",", "\n", "pos_alphabet", ",", "type_alphabet", ")", "\n", "\n", "length_dec", "=", "gold_lengths_d", "[", "0", "]", "\n", "gold_display", "=", "np", ".", "empty", "(", "[", "3", ",", "length_dec", "]", ")", "\n", "gold_display", "[", "0", "]", "=", "gold_stacked_types", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "gold_display", "[", "1", "]", "=", "gold_children", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "gold_display", "[", "2", "]", "=", "gold_stacked_heads", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "print", "(", "gold_display", ")", "\n", "print", "(", "'--------------------------------------------------------'", ")", "\n", "pred_display", "=", "np", ".", "empty", "(", "[", "3", ",", "pred_lengths_d", "[", "0", "]", "]", ")", "[", ":", "length_dec", "]", "\n", "pred_display", "[", "0", "]", "=", "pred_stacked_types", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "pred_display", "[", "1", "]", "=", "pred_children", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "pred_display", "[", "2", "]", "=", "pred_stacked_heads", ".", "data", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length_dec", "]", "\n", "print", "(", "pred_display", ")", "\n", "print", "(", "'========================================================'", ")", "\n", "raw_input", "(", ")", "\n", "\n", "", "if", "ucorr_stack", "==", "num_stack", ":", "\n", "                    ", "type_err", "+=", "1", "\n", "", "elif", "loss_pred", "<", "loss_gold", ":", "\n", "                    ", "model_err", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "search_err", "+=", "1", "\n", "", "", "", "print", "(", "'type   errors: %d'", "%", "type_err", ")", "\n", "print", "(", "'model  errors: %d'", "%", "model_err", ")", "\n", "print", "(", "'search errors: %d'", "%", "search_err", ")", "\n", "\n", "", "analyze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.calc_loss": [[577, 602], ["network.loss"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.loss"], ["", "def", "calc_loss", "(", "network", ",", "word", ",", "char", ",", "pos", ",", "heads", ",", "stacked_heads", ",", "children", ",", "sibling", ",", "stacked_types", ",", "skip_connect", ",", "mask_e", ",", "\n", "length_e", ",", "mask_d", ",", "length_d", ")", ":", "\n", "    ", "loss_arc_leaf", ",", "loss_arc_non_leaf", ",", "loss_type_leaf", ",", "loss_type_non_leaf", ",", "loss_cov", ",", "num_leaf", ",", "num_non_leaf", "=", "network", ".", "loss", "(", "word", ",", "char", ",", "pos", ",", "heads", ",", "stacked_heads", ",", "children", ",", "sibling", ",", "\n", "stacked_types", ",", "1.0", ",", "skip_connect", "=", "skip_connect", ",", "\n", "mask_e", "=", "mask_e", ",", "length_e", "=", "length_e", ",", "mask_d", "=", "mask_d", ",", "length_d", "=", "length_d", ")", "\n", "\n", "num_leaf", "=", "num_leaf", ".", "data", "[", "0", "]", "\n", "num_non_leaf", "=", "num_non_leaf", ".", "data", "[", "0", "]", "\n", "\n", "err_arc_leaf", "=", "loss_arc_leaf", ".", "data", "[", "0", "]", "*", "num_leaf", "\n", "err_arc_non_leaf", "=", "loss_arc_non_leaf", ".", "data", "[", "0", "]", "*", "num_non_leaf", "\n", "\n", "err_type_leaf", "=", "loss_type_leaf", ".", "data", "[", "0", "]", "*", "num_leaf", "\n", "err_type_non_leaf", "=", "loss_type_non_leaf", ".", "data", "[", "0", "]", "*", "num_non_leaf", "\n", "\n", "err_cov", "=", "loss_cov", ".", "data", "[", "0", "]", "*", "(", "num_leaf", "+", "num_non_leaf", ")", "\n", "\n", "err_arc", "=", "err_arc_leaf", "+", "err_arc_non_leaf", "\n", "err_type", "=", "err_type_leaf", "+", "err_type_non_leaf", "\n", "\n", "err", "=", "err_arc", "+", "err_type", "\n", "\n", "return", "err", ",", "err_arc", ",", "err_type", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.analyze.display": [[604, 614], ["range", "print", "word_alphabet.get_instance().encode", "pos_alphabet.get_instance().encode", "type_alphabet.get_instance().encode", "type_alphabet.get_instance().encode", "print", "word_alphabet.get_instance", "pos_alphabet.get_instance", "type_alphabet.get_instance", "type_alphabet.get_instance"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance"], ["", "def", "display", "(", "word", ",", "pos", ",", "head_gold", ",", "type_gold", ",", "head_pred", ",", "type_pred", ",", "length", ",", "word_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", ":", "\n", "    ", "for", "j", "in", "range", "(", "0", ",", "length", ")", ":", "\n", "        ", "w", "=", "word_alphabet", ".", "get_instance", "(", "word", "[", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "p", "=", "pos_alphabet", ".", "get_instance", "(", "pos", "[", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "t_g", "=", "type_alphabet", ".", "get_instance", "(", "type_gold", "[", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "h_g", "=", "head_gold", "[", "j", "]", "\n", "t_p", "=", "type_alphabet", ".", "get_instance", "(", "type_pred", "[", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "h_p", "=", "head_pred", "[", "j", "]", "\n", "print", "(", "'%d\\t%s\\t%s\\t%d\\t%s\\t%d\\t%s\\n'", "%", "(", "j", ",", "w", ",", "p", ",", "h_g", ",", "t_g", ",", "h_p", ",", "t_p", ")", ")", "\n", "", "print", "(", "'-----------------------------------------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.examples.GraphParser.main": [[35, 611], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "random.seed", "numpy.random.seed", "torch.manual_seed", "neuronlp2.io.get_logger", "tuple", "neuronlp2.utils.load_embedding_dict", "neuronlp2.io.get_logger.info", "os.path.join", "os.path.join", "neuronlp2.io.conllx_data.create_alphabets", "max", "word_alphabet.size", "char_alphabet.size", "pos_alphabet.size", "type_alphabet.size", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "torch.cuda.is_available", "GraphParser.main._read_one"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.neuronlp2.utils.load_embedding_dict", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["def", "main", "(", ")", ":", "\n", "    ", "args_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Tuning with graph-based parsing'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "'random seed for reproducibility'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--mode'", ",", "choices", "=", "[", "'RNN'", ",", "'LSTM'", ",", "'GRU'", ",", "'FastLSTM'", "]", ",", "\n", "help", "=", "'architecture of rnn'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'Number of training epochs'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'Number of sentences in each batch'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'Number of hidden units in RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--arc_space'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'Dimension of tag space'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--type_space'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'Dimension of tag space'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of layers of encoder.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_filters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Number of filters in CNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--pos'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use part-of-speech embedding.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use character embedding and CNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--pos_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Dimension of POS embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Dimension of Character embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--opt'", ",", "choices", "=", "[", "'adam'", ",", "'sgd'", ",", "'adamax'", "]", ",", "help", "=", "'optimization algorithm'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--objective'", ",", "choices", "=", "[", "'cross_entropy'", ",", "'crf'", "]", ",", "default", "=", "'cross_entropy'", ",", "help", "=", "'objective function of training procedure.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decode'", ",", "choices", "=", "[", "'mst'", ",", "'greedy'", "]", ",", "default", "=", "'mst'", ",", "help", "=", "'decoding algorithm'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'Learning rate'", ")", "\n", "# args_parser.add_argument('--decay_rate', type=float, default=0.05, help='Decay rate of learning rate')", "\n", "args_parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "5.0", ",", "help", "=", "'gradient clipping'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'weight for regularization'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "help", "=", "'epsilon for adam or adamax'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_rnn'", ",", "nargs", "=", "'+'", ",", "type", "=", "float", ",", "required", "=", "True", ",", "help", "=", "'dropout rate for RNN'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_in'", ",", "type", "=", "float", ",", "default", "=", "0.33", ",", "help", "=", "'dropout rate for input embeddings'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--p_out'", ",", "type", "=", "float", ",", "default", "=", "0.33", ",", "help", "=", "'dropout rate for output layer'", ")", "\n", "# args_parser.add_argument('--schedule', type=int, help='schedule for learning rate decay')", "\n", "args_parser", ".", "add_argument", "(", "'--unk_replace'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "'The rate to replace a singleton word with UNK'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--punctuation'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "help", "=", "'List of punctuations'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--word_embedding'", ",", "choices", "=", "[", "'word2vec'", ",", "'glove'", ",", "'senna'", ",", "'sskip'", ",", "'polyglot'", "]", ",", "help", "=", "'Embedding for words'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--word_path'", ",", "help", "=", "'path for word embedding dict'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--freeze'", ",", "action", "=", "'store_true'", ",", "help", "=", "'frozen the word embedding (disable fine-tuning).'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_embedding'", ",", "choices", "=", "[", "'random'", ",", "'polyglot'", "]", ",", "help", "=", "'Embedding for characters'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--char_path'", ",", "help", "=", "'path for character embedding dict'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--train'", ")", "# \"data/POS-penn/wsj/split1/wsj1.train.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--dev'", ")", "# \"data/POS-penn/wsj/split1/wsj1.dev.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--test'", ")", "# \"data/POS-penn/wsj/split1/wsj1.test.original\"", "\n", "args_parser", ".", "add_argument", "(", "'--vocab_path'", ",", "help", "=", "'path for prebuilt alphabets.'", ",", "default", "=", "None", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_path'", ",", "help", "=", "'path for saving model file.'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_name'", ",", "help", "=", "'name for saving model file.'", ",", "required", "=", "True", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--no_word'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not use word embedding.'", ")", "\n", "#", "\n", "# lrate schedule with warmup in the first iter.", "\n", "args_parser", ".", "add_argument", "(", "'--use_warmup_schedule'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Use warmup lrate schedule.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.75", ",", "help", "=", "'Decay rate of learning rate'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--max_decay'", ",", "type", "=", "int", ",", "default", "=", "9", ",", "help", "=", "'Number of decays before stop'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--schedule'", ",", "type", "=", "int", ",", "help", "=", "'schedule for learning rate decay'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--double_schedule_decay'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'Number of decays to double schedule'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--check_dev'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Check development performance in every n\\'th iteration'", ")", "\n", "# Tansformer encoder", "\n", "args_parser", ".", "add_argument", "(", "'--no_CoRNN'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not use context RNN.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--trans_hid_size'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "'#hidden units in point-wise feed-forward in transformer'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--d_k'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'d_k for multi-head-attention in transformer encoder'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--d_v'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'d_v for multi-head-attention in transformer encoder'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--multi_head_attn'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use multi-head-attention.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--num_head'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'Value of h in multi-head attention'", ")", "\n", "# - positional", "\n", "args_parser", ".", "add_argument", "(", "'--enc_use_neg_dist'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use negative distance for enc's relational-distance embedding.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--enc_clip_dist'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"The clipping distance for relative position features.\"", ")", "\n", "args_parser", ".", "add_argument", "(", "'--position_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Dimension of Position embeddings.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--position_embed_num'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Minimum value of position embedding num, which usually is max-sent-length.'", ")", "\n", "args_parser", ".", "add_argument", "(", "'--train_position'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train positional encoding for transformer.'", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--train_len_thresh'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'In training, discard sentences longer than this.'", ")", "\n", "\n", "#", "\n", "args", "=", "args_parser", ".", "parse_args", "(", ")", "\n", "\n", "# fix data-prepare seed", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "np", ".", "random", ".", "seed", "(", "1234", ")", "\n", "# model's seed", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "logger", "=", "get_logger", "(", "\"GraphParser\"", ")", "\n", "\n", "mode", "=", "args", ".", "mode", "\n", "obj", "=", "args", ".", "objective", "\n", "decoding", "=", "args", ".", "decode", "\n", "train_path", "=", "args", ".", "train", "\n", "dev_path", "=", "args", ".", "dev", "\n", "test_path", "=", "args", ".", "test", "\n", "model_path", "=", "args", ".", "model_path", "\n", "model_name", "=", "args", ".", "model_name", "\n", "num_epochs", "=", "args", ".", "num_epochs", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "hidden_size", "=", "args", ".", "hidden_size", "\n", "arc_space", "=", "args", ".", "arc_space", "\n", "type_space", "=", "args", ".", "type_space", "\n", "num_layers", "=", "args", ".", "num_layers", "\n", "num_filters", "=", "args", ".", "num_filters", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "opt", "=", "args", ".", "opt", "\n", "momentum", "=", "0.9", "\n", "betas", "=", "(", "0.9", ",", "0.9", ")", "\n", "eps", "=", "args", ".", "epsilon", "\n", "decay_rate", "=", "args", ".", "decay_rate", "\n", "clip", "=", "args", ".", "clip", "\n", "gamma", "=", "args", ".", "gamma", "\n", "schedule", "=", "args", ".", "schedule", "\n", "p_rnn", "=", "tuple", "(", "args", ".", "p_rnn", ")", "\n", "p_in", "=", "args", ".", "p_in", "\n", "p_out", "=", "args", ".", "p_out", "\n", "unk_replace", "=", "args", ".", "unk_replace", "\n", "punctuation", "=", "args", ".", "punctuation", "\n", "\n", "freeze", "=", "args", ".", "freeze", "\n", "word_embedding", "=", "args", ".", "word_embedding", "\n", "word_path", "=", "args", ".", "word_path", "\n", "\n", "use_char", "=", "args", ".", "char", "\n", "char_embedding", "=", "args", ".", "char_embedding", "\n", "char_path", "=", "args", ".", "char_path", "\n", "\n", "use_pos", "=", "args", ".", "pos", "\n", "pos_dim", "=", "args", ".", "pos_dim", "\n", "word_dict", ",", "word_dim", "=", "utils", ".", "load_embedding_dict", "(", "word_embedding", ",", "word_path", ")", "\n", "char_dict", "=", "None", "\n", "char_dim", "=", "args", ".", "char_dim", "\n", "if", "char_embedding", "!=", "'random'", ":", "\n", "        ", "char_dict", ",", "char_dim", "=", "utils", ".", "load_embedding_dict", "(", "char_embedding", ",", "char_path", ")", "\n", "\n", "#", "\n", "", "vocab_path", "=", "args", ".", "vocab_path", "if", "args", ".", "vocab_path", "is", "not", "None", "else", "args", ".", "model_path", "\n", "\n", "logger", ".", "info", "(", "\"Creating Alphabets\"", ")", "\n", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "'alphabets/'", ")", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "model_name", ")", "\n", "# todo(warn): exactly same for loading vocabs", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "conllx_data", ".", "create_alphabets", "(", "alphabet_path", ",", "train_path", ",", "data_paths", "=", "[", "dev_path", ",", "test_path", "]", ",", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "word_dict", ")", "\n", "\n", "max_sent_length", "=", "max", "(", "max_sent_length", ",", "args", ".", "position_embed_num", ")", "\n", "\n", "num_words", "=", "word_alphabet", ".", "size", "(", ")", "\n", "num_chars", "=", "char_alphabet", ".", "size", "(", ")", "\n", "num_pos", "=", "pos_alphabet", ".", "size", "(", ")", "\n", "num_types", "=", "type_alphabet", ".", "size", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size: %d\"", "%", "num_words", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "num_chars", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "num_pos", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "num_types", ")", "\n", "\n", "logger", ".", "info", "(", "\"Reading Data\"", ")", "\n", "use_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "# ===== the reading", "\n", "def", "_read_one", "(", "path", ",", "is_train", ")", ":", "\n", "        ", "lang_id", "=", "guess_language_id", "(", "path", ")", "\n", "logger", ".", "info", "(", "\"Reading: guess that the language of file %s is %s.\"", "%", "(", "path", ",", "lang_id", ")", ")", "\n", "one_data", "=", "conllx_data", ".", "read_data_to_variable", "(", "path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "\n", "use_gpu", "=", "use_gpu", ",", "volatile", "=", "(", "not", "is_train", ")", ",", "symbolic_root", "=", "True", ",", "lang_id", "=", "lang_id", ",", "\n", "len_thresh", "=", "(", "args", ".", "train_len_thresh", "if", "is_train", "else", "100000", ")", ")", "\n", "return", "one_data", "\n", "\n", "", "data_train", "=", "_read_one", "(", "train_path", ",", "True", ")", "\n", "num_data", "=", "sum", "(", "data_train", "[", "1", "]", ")", "\n", "\n", "data_dev", "=", "_read_one", "(", "dev_path", ",", "False", ")", "\n", "data_test", "=", "_read_one", "(", "test_path", ",", "False", ")", "\n", "# =====", "\n", "\n", "punct_set", "=", "None", "\n", "if", "punctuation", "is", "not", "None", ":", "\n", "        ", "punct_set", "=", "set", "(", "punctuation", ")", "\n", "logger", ".", "info", "(", "\"punctuations(%d): %s\"", "%", "(", "len", "(", "punct_set", ")", ",", "' '", ".", "join", "(", "punct_set", ")", ")", ")", "\n", "\n", "", "def", "construct_word_embedding_table", "(", ")", ":", "\n", "        ", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "word_dim", ")", "\n", "table", "=", "np", ".", "empty", "(", "[", "word_alphabet", ".", "size", "(", ")", ",", "word_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "table", "[", "conllx_data", ".", "UNK_ID", ",", ":", "]", "=", "np", ".", "zeros", "(", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "if", "freeze", "else", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "=", "0", "\n", "for", "word", ",", "index", "in", "word_alphabet", ".", "items", "(", ")", ":", "\n", "            ", "if", "word", "in", "word_dict", ":", "\n", "                ", "embedding", "=", "word_dict", "[", "word", "]", "\n", "", "elif", "word", ".", "lower", "(", ")", "in", "word_dict", ":", "\n", "                ", "embedding", "=", "word_dict", "[", "word", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "np", ".", "zeros", "(", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "if", "freeze", "else", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "word_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "+=", "1", "\n", "", "table", "[", "index", ",", ":", "]", "=", "embedding", "\n", "", "print", "(", "'word OOV: %d'", "%", "oov", ")", "\n", "return", "torch", ".", "from_numpy", "(", "table", ")", "\n", "\n", "", "def", "construct_char_embedding_table", "(", ")", ":", "\n", "        ", "if", "char_dict", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "char_dim", ")", "\n", "table", "=", "np", ".", "empty", "(", "[", "num_chars", ",", "char_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "table", "[", "conllx_data", ".", "UNK_ID", ",", ":", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "char_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "=", "0", "\n", "for", "char", ",", "index", ",", "in", "char_alphabet", ".", "items", "(", ")", ":", "\n", "            ", "if", "char", "in", "char_dict", ":", "\n", "                ", "embedding", "=", "char_dict", "[", "char", "]", "\n", "", "else", ":", "\n", "                ", "embedding", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "char_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "+=", "1", "\n", "", "table", "[", "index", ",", ":", "]", "=", "embedding", "\n", "", "print", "(", "'character OOV: %d'", "%", "oov", ")", "\n", "return", "torch", ".", "from_numpy", "(", "table", ")", "\n", "\n", "", "word_table", "=", "construct_word_embedding_table", "(", ")", "\n", "char_table", "=", "construct_char_embedding_table", "(", ")", "\n", "\n", "window", "=", "3", "\n", "if", "obj", "==", "'cross_entropy'", ":", "\n", "        ", "network", "=", "BiRecurrentConvBiAffine", "(", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "window", ",", "\n", "mode", ",", "hidden_size", ",", "num_layers", ",", "num_types", ",", "arc_space", ",", "type_space", ",", "\n", "embedd_word", "=", "word_table", ",", "embedd_char", "=", "char_table", ",", "\n", "p_in", "=", "p_in", ",", "p_out", "=", "p_out", ",", "p_rnn", "=", "p_rnn", ",", "biaffine", "=", "True", ",", "pos", "=", "use_pos", ",", "char", "=", "use_char", ",", "\n", "train_position", "=", "args", ".", "train_position", ",", "use_con_rnn", "=", "(", "not", "args", ".", "no_CoRNN", ")", ",", "trans_hid_size", "=", "args", ".", "trans_hid_size", ",", "\n", "d_k", "=", "args", ".", "d_k", ",", "d_v", "=", "args", ".", "d_v", ",", "multi_head_attn", "=", "args", ".", "multi_head_attn", ",", "num_head", "=", "args", ".", "num_head", ",", "\n", "enc_use_neg_dist", "=", "args", ".", "enc_use_neg_dist", ",", "enc_clip_dist", "=", "args", ".", "enc_clip_dist", ",", "\n", "position_dim", "=", "args", ".", "position_dim", ",", "max_sent_length", "=", "max_sent_length", ",", "\n", "use_gpu", "=", "use_gpu", ",", "no_word", "=", "args", ".", "no_word", ")", "\n", "\n", "", "elif", "obj", "==", "'crf'", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Unknown objective: %s'", "%", "obj", ")", "\n", "\n", "", "def", "save_args", "(", ")", ":", "\n", "        ", "arg_path", "=", "model_name", "+", "'.arg.json'", "\n", "arguments", "=", "[", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "window", ",", "\n", "mode", ",", "hidden_size", ",", "num_layers", ",", "num_types", ",", "arc_space", ",", "type_space", "]", "\n", "kwargs", "=", "{", "'p_in'", ":", "p_in", ",", "'p_out'", ":", "p_out", ",", "'p_rnn'", ":", "p_rnn", ",", "'biaffine'", ":", "True", ",", "'pos'", ":", "use_pos", ",", "'char'", ":", "use_char", ",", "\n", "'train_position'", ":", "args", ".", "train_position", ",", "'use_con_rnn'", ":", "(", "not", "args", ".", "no_CoRNN", ")", ",", "'trans_hid_size'", ":", "args", ".", "trans_hid_size", ",", "\n", "'d_k'", ":", "args", ".", "d_k", ",", "'d_v'", ":", "args", ".", "d_v", ",", "'multi_head_attn'", ":", "args", ".", "multi_head_attn", ",", "'num_head'", ":", "args", ".", "num_head", ",", "\n", "'enc_use_neg_dist'", ":", "args", ".", "enc_use_neg_dist", ",", "'enc_clip_dist'", ":", "args", ".", "enc_clip_dist", ",", "\n", "'position_dim'", ":", "args", ".", "position_dim", ",", "'max_sent_length'", ":", "max_sent_length", ",", "'no_word'", ":", "args", ".", "no_word", "}", "\n", "json", ".", "dump", "(", "{", "'args'", ":", "arguments", ",", "'kwargs'", ":", "kwargs", "}", ",", "open", "(", "arg_path", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "\n", "", "if", "freeze", ":", "\n", "        ", "network", ".", "word_embedd", ".", "freeze", "(", ")", "\n", "\n", "", "if", "use_gpu", ":", "\n", "        ", "network", ".", "cuda", "(", ")", "\n", "\n", "", "save_args", "(", ")", "\n", "\n", "pred_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "gold_writer", "=", "CoNLLXWriter", "(", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", "\n", "\n", "def", "generate_optimizer", "(", "opt", ",", "lr", ",", "params", ")", ":", "\n", "        ", "params", "=", "filter", "(", "lambda", "param", ":", "param", ".", "requires_grad", ",", "params", ")", "\n", "if", "opt", "==", "'adam'", ":", "\n", "            ", "return", "Adam", "(", "params", ",", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "weight_decay", "=", "gamma", ",", "eps", "=", "eps", ")", "\n", "", "elif", "opt", "==", "'sgd'", ":", "\n", "            ", "return", "SGD", "(", "params", ",", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "weight_decay", "=", "gamma", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "opt", "==", "'adamax'", ":", "\n", "            ", "return", "Adamax", "(", "params", ",", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "weight_decay", "=", "gamma", ",", "eps", "=", "eps", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown optimization algorithm: %s'", "%", "opt", ")", "\n", "\n", "", "", "lr", "=", "learning_rate", "\n", "optim", "=", "generate_optimizer", "(", "opt", ",", "lr", ",", "network", ".", "parameters", "(", ")", ")", "\n", "opt_info", "=", "'opt: %s, '", "%", "opt", "\n", "if", "opt", "==", "'adam'", ":", "\n", "        ", "opt_info", "+=", "'betas=%s, eps=%.1e'", "%", "(", "betas", ",", "eps", ")", "\n", "", "elif", "opt", "==", "'sgd'", ":", "\n", "        ", "opt_info", "+=", "'momentum=%.2f'", "%", "momentum", "\n", "", "elif", "opt", "==", "'adamax'", ":", "\n", "        ", "opt_info", "+=", "'betas=%s, eps=%.1e'", "%", "(", "betas", ",", "eps", ")", "\n", "\n", "", "word_status", "=", "'frozen'", "if", "freeze", "else", "'fine tune'", "\n", "char_status", "=", "'enabled'", "if", "use_char", "else", "'disabled'", "\n", "pos_status", "=", "'enabled'", "if", "use_pos", "else", "'disabled'", "\n", "logger", ".", "info", "(", "\"Embedding dim: word=%d (%s), char=%d (%s), pos=%d (%s)\"", "%", "(", "word_dim", ",", "word_status", ",", "char_dim", ",", "char_status", ",", "pos_dim", ",", "pos_status", ")", ")", "\n", "logger", ".", "info", "(", "\"CNN: filter=%d, kernel=%d\"", "%", "(", "num_filters", ",", "window", ")", ")", "\n", "logger", ".", "info", "(", "\"RNN: %s, num_layer=%d, hidden=%d, arc_space=%d, type_space=%d\"", "%", "(", "mode", ",", "num_layers", ",", "hidden_size", ",", "arc_space", ",", "type_space", ")", ")", "\n", "logger", ".", "info", "(", "\"train: obj: %s, l2: %f, (#data: %d, batch: %d, clip: %.2f, unk replace: %.2f)\"", "%", "(", "obj", ",", "gamma", ",", "num_data", ",", "batch_size", ",", "clip", ",", "unk_replace", ")", ")", "\n", "logger", ".", "info", "(", "\"dropout(in, out, rnn): (%.2f, %.2f, %s)\"", "%", "(", "p_in", ",", "p_out", ",", "p_rnn", ")", ")", "\n", "logger", ".", "info", "(", "\"decoding algorithm: %s\"", "%", "decoding", ")", "\n", "logger", ".", "info", "(", "opt_info", ")", "\n", "\n", "num_batches", "=", "num_data", "/", "batch_size", "+", "1", "\n", "dev_ucorrect", "=", "0.0", "\n", "dev_lcorrect", "=", "0.0", "\n", "dev_ucomlpete_match", "=", "0.0", "\n", "dev_lcomplete_match", "=", "0.0", "\n", "\n", "dev_ucorrect_nopunc", "=", "0.0", "\n", "dev_lcorrect_nopunc", "=", "0.0", "\n", "dev_ucomlpete_match_nopunc", "=", "0.0", "\n", "dev_lcomplete_match_nopunc", "=", "0.0", "\n", "dev_root_correct", "=", "0.0", "\n", "\n", "best_epoch", "=", "0", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_root_correct", "=", "0.0", "\n", "test_total", "=", "0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "test_total_root", "=", "0", "\n", "\n", "if", "decoding", "==", "'greedy'", ":", "\n", "        ", "decode", "=", "network", ".", "decode", "\n", "", "elif", "decoding", "==", "'mst'", ":", "\n", "        ", "decode", "=", "network", ".", "decode_mst", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown decoding algorithm: %s'", "%", "decoding", ")", "\n", "\n", "", "patient", "=", "0", "\n", "decay", "=", "0", "\n", "max_decay", "=", "args", ".", "max_decay", "\n", "double_schedule_decay", "=", "args", ".", "double_schedule_decay", "\n", "\n", "# lrate schedule", "\n", "step_num", "=", "0", "\n", "use_warmup_schedule", "=", "args", ".", "use_warmup_schedule", "\n", "warmup_factor", "=", "(", "lr", "+", "0.", ")", "/", "num_batches", "\n", "\n", "if", "use_warmup_schedule", ":", "\n", "        ", "logger", ".", "info", "(", "\"Use warmup lrate for the first epoch, from 0 up to %s.\"", "%", "(", "lr", ",", ")", ")", "\n", "#", "\n", "\n", "", "for", "epoch", "in", "range", "(", "1", ",", "num_epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "'Epoch %d (%s, optim: %s, learning rate=%.6f, eps=%.1e, decay rate=%.2f (schedule=%d, patient=%d, decay=%d)): '", "%", "(", "epoch", ",", "mode", ",", "opt", ",", "lr", ",", "eps", ",", "decay_rate", ",", "schedule", ",", "patient", ",", "decay", ")", ")", "\n", "train_err", "=", "0.", "\n", "train_err_arc", "=", "0.", "\n", "train_err_type", "=", "0.", "\n", "train_total", "=", "0.", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "num_back", "=", "0", "\n", "network", ".", "train", "(", ")", "\n", "for", "batch", "in", "range", "(", "1", ",", "num_batches", "+", "1", ")", ":", "\n", "# lrate schedule (before each step)", "\n", "            ", "step_num", "+=", "1", "\n", "if", "use_warmup_schedule", "and", "epoch", "<=", "1", ":", "\n", "                ", "cur_lrate", "=", "warmup_factor", "*", "step_num", "\n", "# set lr", "\n", "for", "param_group", "in", "optim", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "cur_lrate", "\n", "#", "\n", "", "", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "conllx_data", ".", "get_batch_variable", "(", "data_train", ",", "batch_size", ",", "unk_replace", "=", "unk_replace", ")", "\n", "\n", "optim", ".", "zero_grad", "(", ")", "\n", "loss_arc", ",", "loss_type", "=", "network", ".", "loss", "(", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ")", "\n", "loss", "=", "loss_arc", "+", "loss_type", "\n", "loss", ".", "backward", "(", ")", "\n", "clip_grad_norm", "(", "network", ".", "parameters", "(", ")", ",", "clip", ")", "\n", "optim", ".", "step", "(", ")", "\n", "\n", "num_inst", "=", "word", ".", "size", "(", "0", ")", "if", "obj", "==", "'crf'", "else", "masks", ".", "data", ".", "sum", "(", ")", "-", "word", ".", "size", "(", "0", ")", "\n", "train_err", "+=", "loss", ".", "data", "[", "0", "]", "*", "num_inst", "\n", "train_err_arc", "+=", "loss_arc", ".", "data", "[", "0", "]", "*", "num_inst", "\n", "train_err_type", "+=", "loss_type", ".", "data", "[", "0", "]", "*", "num_inst", "\n", "train_total", "+=", "num_inst", "\n", "\n", "time_ave", "=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "/", "batch", "\n", "time_left", "=", "(", "num_batches", "-", "batch", ")", "*", "time_ave", "\n", "\n", "# update log", "\n", "if", "batch", "%", "10", "==", "0", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\" \"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "log_info", "=", "'train: %d/%d loss: %.4f, arc: %.4f, type: %.4f, time left: %.2fs'", "%", "(", "batch", ",", "num_batches", ",", "train_err", "/", "train_total", ",", "\n", "train_err_arc", "/", "train_total", ",", "train_err_type", "/", "train_total", ",", "time_left", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "log_info", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "num_back", "=", "len", "(", "log_info", ")", "\n", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\" \"", "*", "num_back", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\b\"", "*", "num_back", ")", "\n", "print", "(", "'train: %d loss: %.4f, arc: %.4f, type: %.4f, time: %.2fs'", "%", "(", "num_batches", ",", "train_err", "/", "train_total", ",", "train_err_arc", "/", "train_total", ",", "train_err_type", "/", "train_total", ",", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "\n", "################################################################################################", "\n", "if", "epoch", "%", "args", ".", "check_dev", "!=", "0", ":", "\n", "            ", "continue", "\n", "\n", "# evaluate performance on dev data", "\n", "", "network", ".", "eval", "(", ")", "\n", "pred_filename", "=", "'tmp/%spred_dev%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "pred_writer", ".", "start", "(", "pred_filename", ")", "\n", "gold_filename", "=", "'tmp/%sgold_dev%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "gold_writer", ".", "start", "(", "gold_filename", ")", "\n", "\n", "dev_ucorr", "=", "0.0", "\n", "dev_lcorr", "=", "0.0", "\n", "dev_total", "=", "0", "\n", "dev_ucomlpete", "=", "0.0", "\n", "dev_lcomplete", "=", "0.0", "\n", "dev_ucorr_nopunc", "=", "0.0", "\n", "dev_lcorr_nopunc", "=", "0.0", "\n", "dev_total_nopunc", "=", "0", "\n", "dev_ucomlpete_nopunc", "=", "0.0", "\n", "dev_lcomplete_nopunc", "=", "0.0", "\n", "dev_root_corr", "=", "0.0", "\n", "dev_total_root", "=", "0.0", "\n", "dev_total_inst", "=", "0.0", "\n", "for", "batch", "in", "conllx_data", ".", "iterate_batch_variable", "(", "data_dev", ",", "batch_size", ")", ":", "\n", "            ", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "batch", "\n", "heads_pred", ",", "types_pred", "=", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ",", "leading_symbolic", "=", "conllx_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "dev_ucorr", "+=", "ucorr", "\n", "dev_lcorr", "+=", "lcorr", "\n", "dev_total", "+=", "total", "\n", "dev_ucomlpete", "+=", "ucm", "\n", "dev_lcomplete", "+=", "lcm", "\n", "\n", "dev_ucorr_nopunc", "+=", "ucorr_nopunc", "\n", "dev_lcorr_nopunc", "+=", "lcorr_nopunc", "\n", "dev_total_nopunc", "+=", "total_nopunc", "\n", "dev_ucomlpete_nopunc", "+=", "ucm_nopunc", "\n", "dev_lcomplete_nopunc", "+=", "lcm_nopunc", "\n", "\n", "dev_root_corr", "+=", "corr_root", "\n", "dev_total_root", "+=", "total_root", "\n", "\n", "dev_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "print", "(", "'W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr", ",", "dev_lcorr", ",", "dev_total", ",", "dev_ucorr", "*", "100", "/", "dev_total", ",", "dev_lcorr", "*", "100", "/", "dev_total", ",", "dev_ucomlpete", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "'Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr_nopunc", ",", "dev_lcorr_nopunc", ",", "dev_total_nopunc", ",", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_lcorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_ucomlpete_nopunc", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_nopunc", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "'Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "dev_root_corr", ",", "dev_total_root", ",", "dev_root_corr", "*", "100", "/", "dev_total_root", ")", ")", "\n", "\n", "if", "dev_lcorrect_nopunc", "<", "dev_lcorr_nopunc", "or", "(", "dev_lcorrect_nopunc", "==", "dev_lcorr_nopunc", "and", "dev_ucorrect_nopunc", "<", "dev_ucorr_nopunc", ")", ":", "\n", "            ", "dev_ucorrect_nopunc", "=", "dev_ucorr_nopunc", "\n", "dev_lcorrect_nopunc", "=", "dev_lcorr_nopunc", "\n", "dev_ucomlpete_match_nopunc", "=", "dev_ucomlpete_nopunc", "\n", "dev_lcomplete_match_nopunc", "=", "dev_lcomplete_nopunc", "\n", "\n", "dev_ucorrect", "=", "dev_ucorr", "\n", "dev_lcorrect", "=", "dev_lcorr", "\n", "dev_ucomlpete_match", "=", "dev_ucomlpete", "\n", "dev_lcomplete_match", "=", "dev_lcomplete", "\n", "\n", "dev_root_correct", "=", "dev_root_corr", "\n", "\n", "best_epoch", "=", "epoch", "\n", "patient", "=", "0", "\n", "# torch.save(network, model_name)", "\n", "torch", ".", "save", "(", "network", ".", "state_dict", "(", ")", ",", "model_name", ")", "\n", "\n", "pred_filename", "=", "'tmp/%spred_test%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "pred_writer", ".", "start", "(", "pred_filename", ")", "\n", "gold_filename", "=", "'tmp/%sgold_test%d'", "%", "(", "str", "(", "uid", ")", ",", "epoch", ")", "\n", "gold_writer", ".", "start", "(", "gold_filename", ")", "\n", "\n", "test_ucorrect", "=", "0.0", "\n", "test_lcorrect", "=", "0.0", "\n", "test_ucomlpete_match", "=", "0.0", "\n", "test_lcomplete_match", "=", "0.0", "\n", "test_total", "=", "0", "\n", "\n", "test_ucorrect_nopunc", "=", "0.0", "\n", "test_lcorrect_nopunc", "=", "0.0", "\n", "test_ucomlpete_match_nopunc", "=", "0.0", "\n", "test_lcomplete_match_nopunc", "=", "0.0", "\n", "test_total_nopunc", "=", "0", "\n", "test_total_inst", "=", "0", "\n", "\n", "test_root_correct", "=", "0.0", "\n", "test_total_root", "=", "0", "\n", "for", "batch", "in", "conllx_data", ".", "iterate_batch_variable", "(", "data_test", ",", "batch_size", ")", ":", "\n", "                ", "word", ",", "char", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "lengths", "=", "batch", "\n", "heads_pred", ",", "types_pred", "=", "decode", "(", "word", ",", "char", ",", "pos", ",", "mask", "=", "masks", ",", "length", "=", "lengths", ",", "leading_symbolic", "=", "conllx_data", ".", "NUM_SYMBOLIC_TAGS", ")", "\n", "word", "=", "word", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pos", "=", "pos", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "lengths", "=", "lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "heads", "=", "heads", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "types", "=", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pred_writer", ".", "write", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "gold_writer", ".", "write", "(", "word", ",", "pos", ",", "heads", ",", "types", ",", "lengths", ",", "symbolic_root", "=", "True", ")", "\n", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "parser", ".", "eval", "(", "word", ",", "pos", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "punct_set", "=", "punct_set", ",", "symbolic_root", "=", "True", ")", "\n", "ucorr", ",", "lcorr", ",", "total", ",", "ucm", ",", "lcm", "=", "stats", "\n", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucm_nopunc", ",", "lcm_nopunc", "=", "stats_nopunc", "\n", "corr_root", ",", "total_root", "=", "stats_root", "\n", "\n", "test_ucorrect", "+=", "ucorr", "\n", "test_lcorrect", "+=", "lcorr", "\n", "test_total", "+=", "total", "\n", "test_ucomlpete_match", "+=", "ucm", "\n", "test_lcomplete_match", "+=", "lcm", "\n", "\n", "test_ucorrect_nopunc", "+=", "ucorr_nopunc", "\n", "test_lcorrect_nopunc", "+=", "lcorr_nopunc", "\n", "test_total_nopunc", "+=", "total_nopunc", "\n", "test_ucomlpete_match_nopunc", "+=", "ucm_nopunc", "\n", "test_lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "test_root_correct", "+=", "corr_root", "\n", "test_total_root", "+=", "total_root", "\n", "\n", "test_total_inst", "+=", "num_inst", "\n", "\n", "", "pred_writer", ".", "close", "(", ")", "\n", "gold_writer", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "if", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", "<", "dev_ucorrect_nopunc", "*", "100", "/", "dev_total_nopunc", "-", "5", "or", "patient", ">=", "schedule", ":", "\n", "# network = torch.load(model_name)", "\n", "                ", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "lr", "=", "lr", "*", "decay_rate", "\n", "optim", "=", "generate_optimizer", "(", "opt", ",", "lr", ",", "network", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "decoding", "==", "'greedy'", ":", "\n", "                    ", "decode", "=", "network", ".", "decode", "\n", "", "elif", "decoding", "==", "'mst'", ":", "\n", "                    ", "decode", "=", "network", ".", "decode_mst", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "'Unknown decoding algorithm: %s'", "%", "decoding", ")", "\n", "\n", "", "patient", "=", "0", "\n", "decay", "+=", "1", "\n", "if", "decay", "%", "double_schedule_decay", "==", "0", ":", "\n", "                    ", "schedule", "*=", "2", "\n", "", "", "else", ":", "\n", "                ", "patient", "+=", "1", "\n", "\n", "", "", "print", "(", "'----------------------------------------------------------------------------------------------------------------------------'", ")", "\n", "print", "(", "'best dev  W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_ucorrect", ",", "dev_lcorrect", ",", "dev_total", ",", "dev_ucorrect", "*", "100", "/", "dev_total", ",", "dev_lcorrect", "*", "100", "/", "dev_total", ",", "\n", "dev_ucomlpete_match", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_match", "*", "100", "/", "dev_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "print", "(", "'best dev  Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_ucorrect_nopunc", ",", "dev_lcorrect_nopunc", ",", "dev_total_nopunc", ",", "\n", "dev_ucorrect_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "dev_lcorrect_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_ucomlpete_match_nopunc", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_match_nopunc", "*", "100", "/", "dev_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "print", "(", "'best dev  Root: corr: %d, total: %d, acc: %.2f%% (epoch: %d)'", "%", "(", "\n", "dev_root_correct", ",", "dev_total_root", ",", "dev_root_correct", "*", "100", "/", "dev_total_root", ",", "best_epoch", ")", ")", "\n", "print", "(", "'----------------------------------------------------------------------------------------------------------------------------'", ")", "\n", "print", "(", "'best test W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucorrect", "*", "100", "/", "test_total", ",", "test_lcorrect", "*", "100", "/", "test_total", ",", "\n", "test_ucomlpete_match", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match", "*", "100", "/", "test_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "print", "(", "'best test Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "\n", "test_ucorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "test_lcorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_ucomlpete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "\n", "best_epoch", ")", ")", "\n", "print", "(", "'best test Root: corr: %d, total: %d, acc: %.2f%% (epoch: %d)'", "%", "(", "\n", "test_root_correct", ",", "test_total_root", ",", "test_root_correct", "*", "100", "/", "test_total_root", ",", "best_epoch", ")", ")", "\n", "print", "(", "'============================================================================================================================'", ")", "\n", "\n", "if", "decay", "==", "max_decay", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system": [[58, 73], ["printing", "subprocess.Popen", "subprocess.Popen.wait", "str", "os.system", "printing", "subprocess.Popen.stdout.read().decode", "subprocess.Popen.stdout.read"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode"], ["def", "system", "(", "cmd", ",", "pp", "=", "False", ",", "ass", "=", "False", ",", "popen", "=", "False", ")", ":", "\n", "    ", "if", "pp", ":", "\n", "        ", "printing", "(", "\"Executing cmd: %s\"", "%", "cmd", ")", "\n", "", "if", "popen", ":", "\n", "        ", "p", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "n", "=", "p", ".", "wait", "(", ")", "\n", "output", "=", "str", "(", "p", ".", "stdout", ".", "read", "(", ")", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "n", "=", "os", ".", "system", "(", "cmd", ")", "\n", "output", "=", "None", "\n", "", "if", "pp", ":", "\n", "        ", "printing", "(", "\"Output is: %s\"", "%", "output", ")", "\n", "", "if", "ass", ":", "\n", "        ", "assert", "n", "==", "0", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.zopen": [[74, 80], ["filename.endswith", "gzip.open", "open"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["", "def", "zopen", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", ":", "\n", "    ", "if", "filename", ".", "endswith", "(", "'.gz'", ")", ":", "\n", "# \"t\" for text mode of gzip", "\n", "        ", "return", "gzip", ".", "open", "(", "filename", ",", "mode", "+", "\"t\"", ",", "encoding", "=", "encoding", ")", "\n", "", "else", ":", "\n", "        ", "return", "open", "(", "filename", ",", "mode", ",", "encoding", "=", "encoding", ")", "\n", "# =====", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.deal_conll_file": [[83, 97], ["line.strip.strip", "line.strip.split", "len", "fout.write", "int", "fout.write"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write"], ["", "", "def", "deal_conll_file", "(", "fin", ",", "fout", ")", ":", "\n", "    ", "for", "line", "in", "fin", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "fields", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "            ", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "z", "=", "int", "(", "fields", "[", "0", "]", ")", "\n", "fields", "[", "4", "]", "=", "fields", "[", "3", "]", "\n", "fields", "[", "3", "]", "=", "\"_\"", "\n", "fout", ".", "write", "(", "\"\\t\"", ".", "join", "(", "fields", ")", "+", "\"\\n\"", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.main": [[99, 127], ["prepare_data.system", "printing", "prepare_data.system", "fasttext.FastVector", "fasttext.FastVector.apply_transform", "fasttext.FastVector.export", "prepare_data.zopen", "zopen.close", "prepare_data.system", "prepare_data.system", "prepare_data.system", "[].lower", "os.path.exists", "prepare_data.zopen", "prepare_data.deal_conll_file", "fname.split"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.zopen", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.system", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.zopen", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.run_more.prepare_data.deal_conll_file"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "# first get the English one", "\n", "    ", "lang", "=", "\"en\"", "\n", "system", "(", "\"wget -nc -O %s/wiki.%s.vec https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.%s.vec\"", "%", "(", "OUT_DIR", ",", "lang", ",", "lang", ")", ",", "pp", "=", "True", ")", "\n", "# en_dict = FastVector(vector_file='%s/wiki.en.vec' % OUT_DIR)", "\n", "for", "zzz", "in", "LANGUAGE_LIST", ":", "\n", "        ", "lang", ",", "fnames", "=", "zzz", "[", "0", "]", ",", "zzz", "[", "1", "]", "\n", "printing", "(", "\"Dealing with lang %s.\"", "%", "lang", ")", "\n", "for", "curf", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "            ", "out_fname", "=", "\"%s/%s_%s.conllu\"", "%", "(", "OUT_DIR", ",", "lang", ",", "curf", ")", "\n", "fout", "=", "zopen", "(", "out_fname", ",", "\"w\"", ")", "\n", "for", "fname", "in", "fnames", ":", "\n", "                ", "last_name", "=", "fname", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "\n", "path_name", "=", "\"%s/%s/%s_%s-ud-%s.conllu\"", "%", "(", "UD2_DIR", ",", "fname", ",", "lang", ",", "last_name", ",", "curf", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "path_name", ")", ":", "\n", "                    ", "with", "zopen", "(", "path_name", ")", "as", "fin", ":", "\n", "                        ", "deal_conll_file", "(", "fin", ",", "fout", ")", "\n", "", "", "", "fout", ".", "close", "(", ")", "\n", "# stat", "\n", "system", "(", "'cat %s | grep -E \"^$\" | wc'", "%", "out_fname", ",", "pp", "=", "True", ")", "\n", "system", "(", "'cat %s | grep -Ev \"^$\" | wc'", "%", "out_fname", ",", "pp", "=", "True", ")", "\n", "system", "(", "\"cat %s | grep -Ev '^$' | cut -f 5 -d $'\\t'| grep -Ev 'PUNCT|SYM' | wc\"", "%", "out_fname", ",", "pp", "=", "True", ")", "\n", "# get original embed", "\n", "", "system", "(", "\"wget -nc -O %s/wiki.%s.vec https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.%s.vec\"", "%", "(", "OUT_DIR", ",", "lang", ",", "lang", ")", ",", "pp", "=", "True", ")", "\n", "# project with LIB-matrix", "\n", "lang_dict", "=", "FastVector", "(", "vector_file", "=", "'%s/wiki.%s.vec'", "%", "(", "OUT_DIR", ",", "lang", ")", ")", "\n", "lang_dict", ".", "apply_transform", "(", "\"%s/alignment_matrices/%s.txt\"", "%", "(", "LIB_DIR", ",", "lang", ")", ")", "\n", "lang_dict", ".", "export", "(", "\"%s/wiki.multi.%s.vec\"", "%", "(", "OUT_DIR", ",", "lang", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.__init__": [[66, 71], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_words", "=", "None", "\n", "self", ".", "embed_size", "=", "None", "\n", "self", ".", "words", "=", "[", "]", "\n", "self", ".", "vecs", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.__len__": [[72, 74], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.__contains__": [[75, 77], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "item", "in", "self", ".", "vecs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.has_key": [[78, 84], ["str.lower"], "methods", ["None"], ["", "def", "has_key", "(", "self", ",", "k", ",", "lc_back", "=", "True", ")", ":", "\n", "        ", "if", "k", "in", "self", ".", "vecs", ":", "\n", "            ", "return", "True", "\n", "", "elif", "lc_back", ":", "\n", "            ", "return", "str", ".", "lower", "(", "k", ")", "in", "self", ".", "vecs", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.get_vec": [[85, 94], ["str.lower"], "methods", ["None"], ["", "def", "get_vec", "(", "self", ",", "k", ",", "df", "=", "None", ",", "lc_back", "=", "True", ")", ":", "\n", "        ", "if", "k", "in", "self", ".", "vecs", ":", "\n", "            ", "return", "self", ".", "vecs", "[", "k", "]", "\n", "", "elif", "lc_back", ":", "\n", "# back to lowercased", "\n", "            ", "lc", "=", "str", ".", "lower", "(", "k", ")", "\n", "if", "lc", "in", "self", ".", "vecs", ":", "\n", "                ", "return", "self", ".", "vecs", "[", "lc", "]", "\n", "", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.save": [[95, 103], ["print", "open", "fd.write", "fd.write", "w.encode", "float"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write"], ["", "def", "save", "(", "self", ",", "fname", ")", ":", "\n", "        ", "print", "(", "\"Saving w2v num_words=%d, embed_size=%d to %s.\"", "%", "(", "self", ".", "num_words", ",", "self", ".", "embed_size", ",", "fname", ")", ")", "\n", "with", "open", "(", "fname", ",", "\"w\"", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "\"%d %d\\n\"", "%", "(", "self", ".", "num_words", ",", "self", ".", "embed_size", ")", ")", "\n", "for", "w", "in", "self", ".", "words", ":", "\n", "                ", "vec", "=", "self", ".", "vecs", "[", "w", "]", "\n", "print_list", "=", "[", "w", ".", "encode", "(", "'utf-8'", ")", "]", "+", "[", "\"%.6f\"", "%", "float", "(", "z", ")", "for", "z", "in", "vec", "]", "\n", "fd", ".", "write", "(", "\" \"", ".", "join", "(", "print_list", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.filter": [[104, 114], ["build_joint_vocab_embed.WordVectors", "len", "print", "WordVectors.words.append"], "methods", ["None"], ["", "", "", "def", "filter", "(", "self", ",", "key_set", ")", ":", "\n", "        ", "one", "=", "WordVectors", "(", ")", "\n", "one", ".", "num_words", ",", "one", ".", "embed_size", "=", "self", ".", "num_words", ",", "self", ".", "embed_size", "\n", "for", "w", "in", "self", ".", "words", ":", "\n", "            ", "if", "w", "in", "key_set", ":", "\n", "                ", "one", ".", "words", ".", "append", "(", "w", ")", "\n", "one", ".", "vecs", "[", "w", "]", "=", "self", ".", "vecs", "[", "w", "]", "\n", "", "", "one", ".", "num_words", "=", "len", "(", "one", ".", "vecs", ")", "\n", "print", "(", "\"Filter from num_words=%d/embed_size=%d to num_words=%s\"", "%", "(", "self", ".", "num_words", ",", "self", ".", "embed_size", ",", "one", ".", "num_words", ")", ")", "\n", "return", "one", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.load": [[115, 147], ["print", "build_joint_vocab_embed.WordVectors", "open", "fd.readline().strip().decode", "len", "print", "print", "fd.readline().strip().decode", "len", "fd.readline().strip().decode.split", "WordVectors.words.append", "fd.readline().strip().decode", "len", "fd.readline().strip", "int", "print", "len", "fd.readline().strip().decode.split", "fd.readline().strip", "float", "len", "fd.readline().strip", "fd.readline", "fd.readline", "fd.readline"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode"], ["", "@", "staticmethod", "\n", "def", "load", "(", "fname", ")", ":", "\n", "        ", "print", "(", "\"Loading pre-trained w2v from %s ...\"", "%", "fname", ")", "\n", "one", "=", "WordVectors", "(", ")", "\n", "with", "open", "(", "fname", ")", "as", "fd", ":", "\n", "# first line", "\n", "            ", "line", "=", "fd", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "try", ":", "\n", "                ", "one", ".", "num_words", ",", "one", ".", "embed_size", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line", ".", "split", "(", ")", "]", "\n", "print", "(", "\"Reading w2v num_words=%d, embed_size=%d.\"", "%", "(", "one", ".", "num_words", ",", "one", ".", "embed_size", ")", ")", "\n", "line", "=", "fd", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Reading w2v.\"", ")", "\n", "# the rest", "\n", "", "while", "len", "(", "line", ")", ">", "0", ":", "\n", "                ", "fields", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "word", ",", "vec", "=", "fields", "[", "0", "]", ",", "[", "float", "(", "x", ")", "for", "x", "in", "fields", "[", "1", ":", "]", "]", "\n", "assert", "word", "not", "in", "one", ".", "vecs", ",", "\"Repeated key.\"", "\n", "if", "one", ".", "embed_size", "is", "None", ":", "\n", "                    ", "one", ".", "embed_size", "=", "len", "(", "vec", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "vec", ")", "==", "one", ".", "embed_size", ",", "\"Unmatched embed dimension.\"", "\n", "", "one", ".", "vecs", "[", "word", "]", "=", "vec", "\n", "one", ".", "words", ".", "append", "(", "word", ")", "\n", "line", "=", "fd", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "# final", "\n", "", "", "if", "one", ".", "num_words", "is", "None", ":", "\n", "            ", "one", ".", "num_words", "=", "len", "(", "one", ".", "vecs", ")", "\n", "print", "(", "\"Reading w2v num_words=%d, embed_size=%d.\"", "%", "(", "one", ".", "num_words", ",", "one", ".", "embed_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "one", ".", "num_words", "==", "len", "(", "one", ".", "vecs", ")", ",", "\"Unmatched num of words.\"", "\n", "", "return", "one", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.combine_embeds": [[148, 172], ["len", "build_joint_vocab_embed.WordVectors", "print", "range", "len", "len", "len", "print", "neuronlp2.io_multi.lang_specific_word", "WordVectors.words.append", "range", "range"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word"], ["", "@", "staticmethod", "\n", "def", "combine_embeds", "(", "word_dicts", ",", "lang_ids", ")", ":", "\n", "        ", "assert", "len", "(", "word_dicts", ")", "==", "len", "(", "lang_ids", ")", ",", "\"One lang id for one embed!\"", "\n", "number_to_combine", "=", "len", "(", "word_dicts", ")", "\n", "#", "\n", "one", "=", "WordVectors", "(", ")", "\n", "one", ".", "embed_size", "=", "word_dicts", "[", "0", "]", ".", "embed_size", "\n", "print", "(", "\"Combining embeds of %s.\"", "%", "(", "lang_ids", ",", ")", ")", "\n", "for", "idx", "in", "range", "(", "number_to_combine", ")", ":", "\n", "            ", "repeated_counts", "=", "[", "0", "for", "_", "in", "range", "(", "number_to_combine", ")", "]", "\n", "cur_embed", ",", "cur_id", "=", "word_dicts", "[", "idx", "]", ",", "lang_ids", "[", "idx", "]", "\n", "for", "one_w", "in", "cur_embed", ".", "words", ":", "\n", "#", "\n", "                ", "prefixed_w", "=", "lang_specific_word", "(", "one_w", ",", "lang_id", "=", "cur_id", ")", "\n", "one", ".", "words", ".", "append", "(", "prefixed_w", ")", "\n", "one", ".", "vecs", "[", "prefixed_w", "]", "=", "cur_embed", ".", "vecs", "[", "one_w", "]", "\n", "#", "\n", "for", "idx2", "in", "range", "(", "number_to_combine", ")", ":", "\n", "                    ", "cur_embed2", ",", "cur_id2", "=", "word_dicts", "[", "idx2", "]", ",", "lang_ids", "[", "idx2", "]", "\n", "if", "one_w", "in", "cur_embed2", ":", "\n", "                        ", "repeated_counts", "[", "idx2", "]", "+=", "1", "\n", "", "", "", "print", "(", "\"Key repeat counts of %s: %s.\"", "%", "(", "cur_id", ",", "repeated_counts", ")", ")", "\n", "", "one", ".", "num_words", "=", "len", "(", "one", ".", "vecs", ")", "\n", "return", "one", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.parse_cmd": [[24, 33], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_cmd", "(", "args", ")", ":", "\n", "    ", "args_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Building the alphabets/vocabularies.'", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--embed_paths'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'path for word embedding dict'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--embed_lang_ids'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'lang ids for the embeddings'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--data_paths'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "\"Data files to build vocab.\"", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_path'", ",", "help", "=", "'path for saving alphabet files.'", ",", "required", "=", "True", ")", "\n", "res", "=", "args_parser", ".", "parse_args", "(", "args", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.main": [[34, 64], ["build_joint_vocab_embed.parse_cmd", "neuronlp2.io.get_logger", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "build_joint_vocab_embed.WordVectors.combine_embeds", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "os.path.join", "neuronlp2.io_multi.create_alphabets", "set", "WordVectors.combine_embeds.filter", "combined_word_dict.filter.save", "os.path.exists", "os.makedirs", "len", "len", "build_joint_vocab_embed.WordVectors.load", "os.path.exists", "os.path.join", "len", "set.add", "one_w.lower", "set.add", "one_w.lower"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.parse_cmd", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.combine_embeds", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_joint_vocab_embed.WordVectors.filter", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add"], ["", "def", "main", "(", "a", "=", "None", ")", ":", "\n", "    ", "if", "a", "is", "None", ":", "\n", "        ", "a", "=", "sys", ".", "argv", "[", "1", ":", "]", "\n", "", "args", "=", "parse_cmd", "(", "a", ")", "\n", "# if output directory doesn't exist, create it", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "model_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "model_path", ")", "\n", "", "logger", "=", "get_logger", "(", "\"VocabBuilder\"", ",", "args", ".", "model_path", "+", "'/vocab.log.txt'", ")", "\n", "logger", ".", "info", "(", "'\\ncommand-line params : {0}\\n'", ".", "format", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "logger", ".", "info", "(", "'{0}\\n'", ".", "format", "(", "args", ")", ")", "\n", "# load embeds", "\n", "logger", ".", "info", "(", "\"Load embeddings\"", ")", "\n", "assert", "len", "(", "args", ".", "embed_paths", ")", "==", "len", "(", "args", ".", "embed_lang_ids", ")", ",", "\"One lang id for one embed file!\"", "\n", "word_embeds", "=", "[", "WordVectors", ".", "load", "(", "one_embed_path", ")", "for", "one_embed_path", "in", "args", ".", "embed_paths", "]", "\n", "combined_word_dict", "=", "WordVectors", ".", "combine_embeds", "(", "word_embeds", ",", "args", ".", "embed_lang_ids", ")", "\n", "logger", ".", "info", "(", "\"Final combined un-pruned embeddings size: %d.\"", "%", "len", "(", "combined_word_dict", ")", ")", "\n", "# create vocabs", "\n", "logger", ".", "info", "(", "\"Creating Alphabets\"", ")", "\n", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'alphabets/'", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "alphabet_path", ")", ",", "\"Alphabet path exists, please build with a new path.\"", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "create_alphabets", "(", "alphabet_path", ",", "args", ".", "data_paths", "[", "0", "]", ",", "data_paths", "=", "args", ".", "data_paths", "[", "1", ":", "]", ",", "embedd_dict", "=", "combined_word_dict", ",", "max_vocabulary_size", "=", "100000", ",", "creating_mode", "=", "True", ")", "\n", "# save filtered embed", "\n", "hit_keys", "=", "set", "(", ")", "\n", "for", "one_w", "in", "word_alphabet", ".", "instance2index", ":", "\n", "        ", "if", "one_w", "in", "combined_word_dict", ":", "\n", "            ", "hit_keys", ".", "add", "(", "one_w", ")", "\n", "", "elif", "one_w", ".", "lower", "(", ")", "in", "combined_word_dict", ":", "\n", "            ", "hit_keys", ".", "add", "(", "one_w", ".", "lower", "(", ")", ")", "\n", "", "", "filtered_embed", "=", "combined_word_dict", ".", "filter", "(", "hit_keys", ")", "\n", "filtered_embed", ".", "save", "(", "os", ".", "path", ".", "join", "(", "alphabet_path", ",", "'joint_embed.vec'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.parse_cmd": [[27, 39], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_cmd", "(", "args", ")", ":", "\n", "    ", "args_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Building the alphabets/vocabularies.'", ")", "\n", "#", "\n", "args_parser", ".", "add_argument", "(", "'--word_embedding'", ",", "type", "=", "str", ",", "choices", "=", "[", "'word2vec'", ",", "'glove'", ",", "'senna'", ",", "'sskip'", ",", "'polyglot'", "]", ",", "\n", "help", "=", "'Embedding for words'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--word_paths'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "'path for word embedding dict'", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--train'", ",", "type", "=", "str", ",", "help", "=", "\"The main file to build vocab.\"", ",", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--extra'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "help", "=", "\"Extra files to build vocab, usually dev/tests.\"", ",", "\n", "required", "=", "True", ")", "\n", "args_parser", ".", "add_argument", "(", "'--model_path'", ",", "help", "=", "'path for saving model file.'", ",", "required", "=", "True", ")", "\n", "res", "=", "args_parser", ".", "parse_args", "(", "args", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab._get_keys": [[41, 47], ["wd.keys", "wd.vocab.keys"], "function", ["None"], ["", "def", "_get_keys", "(", "wd", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "wd", ".", "keys", "(", ")", "\n", "", "except", ":", "\n", "# Word2VecKeyedVectors", "\n", "        ", "return", "wd", ".", "vocab", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.combine_embeds": [[50, 62], ["len", "dict", "enumerate", "build_vocab._get_keys", "range", "range"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab._get_keys"], ["", "", "def", "combine_embeds", "(", "word_dicts", ")", ":", "\n", "    ", "num_dicts", "=", "len", "(", "word_dicts", ")", "\n", "count_ins", ",", "count_repeats", "=", "[", "0", "for", "_", "in", "range", "(", "num_dicts", ")", "]", ",", "[", "0", "for", "_", "in", "range", "(", "num_dicts", ")", "]", "\n", "res", "=", "dict", "(", ")", "\n", "for", "idx", ",", "one", "in", "enumerate", "(", "word_dicts", ")", ":", "\n", "        ", "for", "k", "in", "_get_keys", "(", "one", ")", ":", "\n", "            ", "if", "k", "in", "res", ":", "\n", "                ", "count_repeats", "[", "idx", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "count_ins", "[", "idx", "]", "+=", "1", "\n", "res", "[", "k", "]", "=", "0", "\n", "", "", "", "return", "res", ",", "count_ins", ",", "count_repeats", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.main": [[64, 104], ["build_vocab.parse_cmd", "neuronlp2.io.get_logger", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "build_vocab.combine_embeds", "neuronlp2.io.get_logger.info", "zip", "neuronlp2.io.get_logger.info", "os.path.join", "neuronlp2.io.conllx_stacked_data.create_alphabets", "word_alphabet.size", "char_alphabet.size", "pos_alphabet.size", "type_alphabet.size", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "neuronlp2.io.get_logger.info", "os.path.exists", "os.makedirs", "neuronlp2.utils.load_embedding_dict", "word_dicts.append", "neuronlp2.io.get_logger.info", "os.path.exists", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.parse_cmd", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.vocab.build_vocab.combine_embeds", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.neuronlp2.utils.load_embedding_dict"], ["", "def", "main", "(", "a", "=", "None", ")", ":", "\n", "    ", "if", "a", "is", "None", ":", "\n", "        ", "a", "=", "sys", ".", "argv", "[", "1", ":", "]", "\n", "", "args", "=", "parse_cmd", "(", "a", ")", "\n", "# if output directory doesn't exist, create it", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "model_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "model_path", ")", "\n", "", "logger", "=", "get_logger", "(", "\"VocabBuilder\"", ",", "args", ".", "model_path", "+", "'/vocab.log.txt'", ")", "\n", "logger", ".", "info", "(", "'\\ncommand-line params : {0}\\n'", ".", "format", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "logger", ".", "info", "(", "'{0}\\n'", ".", "format", "(", "args", ")", ")", "\n", "# load embeds", "\n", "logger", ".", "info", "(", "\"Load embeddings\"", ")", "\n", "word_dicts", "=", "[", "]", "\n", "word_dim", "=", "None", "\n", "for", "one", "in", "args", ".", "word_paths", ":", "\n", "        ", "one_word_dict", ",", "one_word_dim", "=", "utils", ".", "load_embedding_dict", "(", "args", ".", "word_embedding", ",", "one", ")", "\n", "assert", "word_dim", "is", "None", "or", "word_dim", "==", "one_word_dim", ",", "\"Embedding size not matched!\"", "\n", "word_dicts", ".", "append", "(", "one_word_dict", ")", "\n", "word_dim", "=", "one_word_dim", "\n", "# combine embeds", "\n", "", "combined_word_dict", ",", "count_ins", ",", "count_repeats", "=", "combine_embeds", "(", "word_dicts", ")", "\n", "logger", ".", "info", "(", "\"Final embeddings size: %d.\"", "%", "len", "(", "combined_word_dict", ")", ")", "\n", "for", "one_fname", ",", "one_count_ins", ",", "one_count_repeats", "in", "zip", "(", "args", ".", "word_paths", ",", "count_ins", ",", "count_repeats", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"For embed-file %s, count-in: %d, repeat-discard: %d.\"", "%", "(", "one_fname", ",", "one_count_ins", ",", "one_count_repeats", ")", ")", "\n", "# create vocabs", "\n", "", "logger", ".", "info", "(", "\"Creating Alphabets\"", ")", "\n", "alphabet_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_path", ",", "'alphabets/'", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "alphabet_path", ")", ",", "\"Alphabet path exists, please build with a new path.\"", "\n", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "=", "conllx_stacked_data", ".", "create_alphabets", "(", "\n", "alphabet_path", ",", "args", ".", "train", ",", "data_paths", "=", "args", ".", "extra", ",", "max_vocabulary_size", "=", "100000", ",", "embedd_dict", "=", "combined_word_dict", ")", "\n", "# printing info", "\n", "num_words", "=", "word_alphabet", ".", "size", "(", ")", "\n", "num_chars", "=", "char_alphabet", ".", "size", "(", ")", "\n", "num_pos", "=", "pos_alphabet", ".", "size", "(", ")", "\n", "num_types", "=", "type_alphabet", ".", "size", "(", ")", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size: %d\"", "%", "num_words", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "num_chars", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "num_pos", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "num_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.neuronlp2.utils.load_embedding_dict": [[11, 108], ["print", "gensim.models.KeyedVectors.load_word2vec_format", "dict", "gzip.open", "dict", "line.decode.strip", "line.decode.decode", "line.decode.split", "numpy.empty", "gzip.open", "dict", "len", "io.utils.DIGIT_RE.sub", "line.decode.strip", "line.decode.decode", "line.decode.split", "numpy.empty", "gzip.open", "file.readline", "pickle.load", "dict", "enumerate", "ValueError", "len", "len", "len", "io.utils.DIGIT_RE.sub", "line.decode.strip", "open", "numpy.empty", "len", "len", "line.decode.decode", "line.decode.split", "numpy.empty", "io.utils.DIGIT_RE.sub", "len", "len", "len", "io.utils.DIGIT_RE.sub", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode"], ["def", "load_embedding_dict", "(", "embedding", ",", "embedding_path", ",", "normalize_digits", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    load word embeddings from file\n    :param embedding:\n    :param embedding_path:\n    :return: embedding dict, embedding dimention, caseless\n    \"\"\"", "\n", "print", "(", "\"loading embedding: %s from %s\"", "%", "(", "embedding", ",", "embedding_path", ")", ")", "\n", "if", "embedding", "==", "'word2vec'", ":", "\n", "# loading word2vec", "\n", "        ", "word2vec", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "embedding_path", ",", "binary", "=", "False", ")", "\n", "embedd_dim", "=", "word2vec", ".", "vector_size", "\n", "return", "word2vec", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'glove'", ":", "\n", "# loading GloVe", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedd_dim", "<", "0", ":", "\n", "                    ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "                    ", "assert", "(", "embedd_dim", "+", "1", "==", "len", "(", "tokens", ")", ")", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "0", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "0", "]", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'senna'", ":", "\n", "# loading Senna", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedd_dim", "<", "0", ":", "\n", "                    ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "                    ", "assert", "(", "embedd_dim", "+", "1", "==", "len", "(", "tokens", ")", ")", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "0", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "0", "]", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'sskip'", ":", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "# skip the first line", "\n", "            ", "file", ".", "readline", "(", ")", "\n", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "try", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", "<", "embedd_dim", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "embedd_dim", "<", "0", ":", "\n", "                        ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "start", "=", "len", "(", "tokens", ")", "-", "embedd_dim", "\n", "word", "=", "' '", ".", "join", "(", "tokens", "[", "0", ":", "start", "]", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "start", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "word", ")", "if", "normalize_digits", "else", "word", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "                    ", "continue", "\n", "", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'polyglot'", ":", "\n", "        ", "words", ",", "embeddings", "=", "pickle", ".", "load", "(", "open", "(", "embedding_path", ",", "'rb'", ")", ")", "\n", "_", ",", "embedd_dim", "=", "embeddings", ".", "shape", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "embeddings", "[", "i", ",", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "word", ")", "if", "normalize_digits", "else", "word", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"embedding should choose from [word2vec, senna, glove, sskip, polyglot]\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.multi_vocab.iter_file": [[30, 50], ["open", "line.strip.decode", "line.strip.strip", "line.strip.split", "ret[].append", "ret[].append", "ret[].append", "len", "io.utils.get_main_deplabel"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.utils.get_main_deplabel"], ["def", "iter_file", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "ret", "=", "{", "\"len\"", ":", "0", ",", "\"word\"", ":", "[", "]", ",", "\"pos\"", ":", "[", "]", ",", "\"type\"", ":", "[", "]", "}", "\n", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "# yield and reset", "\n", "if", "len", "(", "line", ")", "==", "0", "or", "line", "[", "0", "]", "==", "\"#\"", ":", "\n", "                ", "if", "ret", "[", "\"len\"", "]", ">", "0", ":", "\n", "                    ", "yield", "ret", "\n", "", "ret", "=", "{", "\"len\"", ":", "0", ",", "\"word\"", ":", "[", "]", ",", "\"pos\"", ":", "[", "]", ",", "\"type\"", ":", "[", "]", "}", "\n", "", "else", ":", "\n", "                ", "fields", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "ret", "[", "\"len\"", "]", "+=", "1", "\n", "ret", "[", "\"word\"", "]", ".", "append", "(", "fields", "[", "1", "]", ")", "\n", "ret", "[", "\"pos\"", "]", ".", "append", "(", "fields", "[", "4", "]", ")", "\n", "# ret[\"type\"].append(fields[7])", "\n", "ret", "[", "\"type\"", "]", ".", "append", "(", "utils", ".", "get_main_deplabel", "(", "fields", "[", "7", "]", ")", ")", "\n", "", "", "if", "ret", "[", "\"len\"", "]", ">", "0", ":", "\n", "            ", "yield", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.multi_vocab.create_alphabets": [[51, 173], ["io.logger.get_logger", "io.alphabet.Alphabet", "io.alphabet.Alphabet", "io.alphabet.Alphabet", "io.alphabet.Alphabet", "lang_id.guess_language_id", "io.logger.get_logger.info", "io.alphabet.Alphabet.close", "io.alphabet.Alphabet.close", "io.alphabet.Alphabet.close", "io.alphabet.Alphabet.close", "io.logger.get_logger.info", "io.logger.get_logger.info", "io.logger.get_logger.info", "io.logger.get_logger.info", "io.logger.get_logger.info", "os.path.isdir", "io.logger.get_logger.info", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "dict", "multi_vocab.iter_file", "set", "io.logger.get_logger.info", "io.logger.get_logger.info", "io.logger.get_logger.info", "io.alphabet.Alphabet.save", "io.alphabet.Alphabet.save", "io.alphabet.Alphabet.save", "io.alphabet.Alphabet.save", "io.logger.get_logger.info", "io.alphabet.Alphabet.load", "io.alphabet.Alphabet.load", "io.alphabet.Alphabet.load", "io.alphabet.Alphabet.load", "lang_id.guess_language_id", "max", "range", "dict.keys", "sorted", "len", "zip", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.size", "io.alphabet.Alphabet.size", "io.alphabet.Alphabet.size", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "lang_id.lang_specific_word", "len", "len", "len", "set", "multi_vocab.iter_file", "io.logger.get_logger.info", "io.alphabet.Alphabet.add_singleton", "io.alphabet.Alphabet.size", "io.alphabet.Alphabet.singleton_size", "io.alphabet.Alphabet.add", "io.utils.DIGIT_RE.sub", "dict.items", "max", "range", "io.alphabet.Alphabet.get_index", "word.lower", "io.alphabet.Alphabet.add", "io.alphabet.Alphabet.add", "lang_id.lang_specific_word", "set.add", "io.alphabet.Alphabet.add", "io.utils.DIGIT_RE.sub", "len", "lang_id.lang_specific_word.lower", "vocab_list.append"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.guess_language_id", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.multi_vocab.iter_file", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.guess_language_id", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.multi_vocab.iter_file", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add_singleton", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.singleton_size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.items", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add"], ["", "", "", "def", "create_alphabets", "(", "alphabet_directory", ",", "train_path", ",", "data_paths", "=", "None", ",", "max_vocabulary_size", "=", "100000", ",", "embedd_dict", "=", "None", ",", "\n", "min_occurence", "=", "1", ",", "normalize_digits", "=", "True", ",", "creating_mode", "=", "False", ")", ":", "\n", "    ", "logger", "=", "get_logger", "(", "\"Create Alphabets\"", ")", "\n", "word_alphabet", "=", "Alphabet", "(", "'word'", ",", "defualt_value", "=", "True", ",", "singleton", "=", "True", ")", "\n", "char_alphabet", "=", "Alphabet", "(", "'character'", ",", "defualt_value", "=", "True", ")", "\n", "pos_alphabet", "=", "Alphabet", "(", "'pos'", ")", "\n", "type_alphabet", "=", "Alphabet", "(", "'type'", ")", "\n", "max_sent_length", "=", "0", "\n", "# guess language", "\n", "lang_id_train", "=", "guess_language_id", "(", "train_path", ")", "\n", "lang_id_extras", "=", "None", "if", "data_paths", "is", "None", "else", "[", "guess_language_id", "(", "fname", ")", "for", "fname", "in", "data_paths", "]", "\n", "logger", ".", "info", "(", "\"Here, the input files are: train(%s), extras(%s).\"", "%", "(", "lang_id_train", ",", "lang_id_extras", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "alphabet_directory", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating Alphabets: %s\"", "%", "alphabet_directory", ")", "\n", "# add special tokens", "\n", "char_alphabet", ".", "add", "(", "PAD_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "PAD_POS", ")", "\n", "type_alphabet", ".", "add", "(", "PAD_TYPE", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "ROOT_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "ROOT_POS", ")", "\n", "type_alphabet", ".", "add", "(", "ROOT_TYPE", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "END_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "END_POS", ")", "\n", "type_alphabet", ".", "add", "(", "END_TYPE", ")", "\n", "\n", "# special one for Chinese", "\n", "type_alphabet", ".", "add", "(", "\"clf\"", ")", "\n", "\n", "# count from the main train file", "\n", "vocab", "=", "dict", "(", ")", "\n", "for", "one_sent", "in", "iter_file", "(", "train_path", ")", ":", "\n", "            ", "cur_len", "=", "one_sent", "[", "\"len\"", "]", "\n", "max_sent_length", "=", "max", "(", "max_sent_length", ",", "cur_len", ")", "\n", "for", "idx", "in", "range", "(", "cur_len", ")", ":", "\n", "                ", "cur_word", ",", "cur_pos", ",", "cur_type", "=", "one_sent", "[", "\"word\"", "]", "[", "idx", "]", ",", "one_sent", "[", "\"pos\"", "]", "[", "idx", "]", ",", "one_sent", "[", "\"type\"", "]", "[", "idx", "]", "\n", "#", "\n", "for", "char", "in", "cur_word", ":", "\n", "                    ", "char_alphabet", ".", "add", "(", "char", ")", "\n", "", "pos_alphabet", ".", "add", "(", "cur_pos", ")", "\n", "type_alphabet", ".", "add", "(", "cur_type", ")", "\n", "normed_word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "cur_word", ")", "if", "normalize_digits", "else", "cur_word", "\n", "# add prefix", "\n", "normed_word", "=", "lang_specific_word", "(", "normed_word", ",", "lang_id", "=", "lang_id_train", ")", "\n", "if", "normed_word", "in", "vocab", ":", "\n", "                    ", "vocab", "[", "normed_word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "vocab", "[", "normed_word", "]", "=", "1", "\n", "# collect singletons", "\n", "", "", "", "singletons", "=", "set", "(", "[", "word", "for", "word", ",", "count", "in", "vocab", ".", "items", "(", ")", "if", "count", "<=", "min_occurence", "]", ")", "\n", "# if a singleton is in pretrained embedding dict, set the count to min_occur + c", "\n", "if", "embedd_dict", "is", "not", "None", ":", "\n", "            ", "for", "word", "in", "vocab", ".", "keys", "(", ")", ":", "\n", "                ", "if", "word", "in", "embedd_dict", "or", "word", ".", "lower", "(", ")", "in", "embedd_dict", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "min_occurence", "\n", "#", "\n", "", "", "", "vocab_list", "=", "_START_VOCAB", "+", "sorted", "(", "vocab", ",", "key", "=", "vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size: %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "logger", ".", "info", "(", "\"Total Singleton Size:  %d\"", "%", "len", "(", "singletons", ")", ")", "\n", "vocab_list", "=", "[", "word", "for", "word", "in", "vocab_list", "if", "word", "in", "_START_VOCAB", "or", "vocab", "[", "word", "]", ">", "min_occurence", "]", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size (w.o rare words): %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "#", "\n", "if", "len", "(", "vocab_list", ")", ">", "max_vocabulary_size", ":", "\n", "            ", "vocab_list", "=", "vocab_list", "[", ":", "max_vocabulary_size", "]", "\n", "# extra directly added files (usually dev or test)", "\n", "", "if", "data_paths", "is", "not", "None", ":", "\n", "            ", "for", "one_path", ",", "one_lang_id", "in", "zip", "(", "data_paths", ",", "lang_id_extras", ")", ":", "\n", "                ", "vocab_set", "=", "set", "(", "vocab_list", ")", "\n", "count_word_vocab_in_embed", "=", "0", "\n", "count_word_all", ",", "count_word_in", "=", "0", ",", "0", "\n", "for", "one_sent", "in", "iter_file", "(", "one_path", ")", ":", "\n", "                    ", "cur_len", "=", "one_sent", "[", "\"len\"", "]", "\n", "max_sent_length", "=", "max", "(", "max_sent_length", ",", "cur_len", ")", "\n", "for", "idx", "in", "range", "(", "cur_len", ")", ":", "\n", "                        ", "cur_word", ",", "cur_pos", ",", "cur_type", "=", "one_sent", "[", "\"word\"", "]", "[", "idx", "]", ",", "one_sent", "[", "\"pos\"", "]", "[", "idx", "]", ",", "one_sent", "[", "\"type\"", "]", "[", "idx", "]", "\n", "#", "\n", "for", "char", "in", "cur_word", ":", "\n", "                            ", "char_alphabet", ".", "add", "(", "char", ")", "\n", "", "pos_alphabet", ".", "add", "(", "cur_pos", ")", "\n", "type_alphabet", ".", "add", "(", "cur_type", ")", "\n", "normed_word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "cur_word", ")", "if", "normalize_digits", "else", "cur_word", "\n", "# add prefix", "\n", "normed_word", "=", "lang_specific_word", "(", "normed_word", ",", "lang_id", "=", "one_lang_id", ")", "\n", "if", "embedd_dict", "is", "not", "None", ":", "\n", "                            ", "if", "normed_word", "in", "embedd_dict", "or", "normed_word", ".", "lower", "(", ")", "in", "embedd_dict", ":", "\n", "                                ", "if", "normed_word", "not", "in", "vocab_set", ":", "\n", "                                    ", "vocab_list", ".", "append", "(", "normed_word", ")", "\n", "count_word_vocab_in_embed", "+=", "1", "\n", "", "count_word_in", "+=", "1", "\n", "", "", "vocab_set", ".", "add", "(", "normed_word", ")", "\n", "count_word_all", "+=", "1", "\n", "", "", "logger", ".", "info", "(", "\"For the file %s, vocab-size/in-size: %d/%d, word-size/in-size: %d/%d.\"", "%", "(", "one_path", ",", "len", "(", "vocab_set", ")", ",", "count_word_vocab_in_embed", ",", "count_word_all", ",", "count_word_in", ")", ")", "\n", "#", "\n", "", "", "for", "word", "in", "vocab_list", ":", "\n", "            ", "word_alphabet", ".", "add", "(", "word", ")", "\n", "if", "word", "in", "singletons", ":", "\n", "                ", "word_alphabet", ".", "add_singleton", "(", "word_alphabet", ".", "get_index", "(", "word", ")", ")", "\n", "#", "\n", "", "", "word_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "type_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "", "else", ":", "\n", "        ", "assert", "not", "creating_mode", ",", "\"Cannot load existed vocabs in creating mode.\"", "\n", "logger", ".", "info", "(", "\"Loading Alphabets: %s\"", "%", "alphabet_directory", ")", "\n", "word_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "type_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "#", "\n", "", "word_alphabet", ".", "close", "(", ")", "\n", "char_alphabet", ".", "close", "(", ")", "\n", "pos_alphabet", ".", "close", "(", ")", "\n", "type_alphabet", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size (Singleton): %d (%d)\"", "%", "(", "word_alphabet", ".", "size", "(", ")", ",", "word_alphabet", ".", "singleton_size", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "char_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "pos_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "type_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Maximum Sentence Length: %d\"", "%", "max_sent_length", ")", "\n", "#", "\n", "return", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "\n", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.guess_language_id": [[6, 13], ["os.path.basename", "str.lower", "print"], "function", ["None"], ["def", "guess_language_id", "(", "file_path", ")", ":", "\n", "    ", "bname", "=", "os", ".", "path", ".", "basename", "(", "file_path", ")", "\n", "lang_id", "=", "str", ".", "lower", "(", "bname", "[", ":", "2", "]", ")", "\n", "# assert lang_id in KNOWN_LANG_IDS, \"Unknown lang id %s from path %s\" % (lang_id, file_path)", "\n", "if", "lang_id", "not", "in", "KNOWN_LANG_IDS", ":", "\n", "        ", "print", "(", "\"Warning: Unknown lang id %s from path %s\"", "%", "(", "lang_id", ",", "file_path", ")", ")", "\n", "", "return", "lang_id", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word": [[14, 20], ["None"], "function", ["None"], ["", "def", "lang_specific_word", "(", "word", ",", "lang_id", ")", ":", "\n", "    ", "if", "lang_id", ":", "\n", "# assert lang_id in KNOWN_LANG_IDS, \"Unknown lang id %s\" % (lang_id, )", "\n", "        ", "return", "\"!%s_%s\"", "%", "(", "lang_id", ",", "word", ")", "\n", "", "else", ":", "\n", "        ", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.default_lang_specific_word": [[25, 27], ["lang_id.lang_specific_word"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word"], ["def", "default_lang_specific_word", "(", "word", ")", ":", "\n", "    ", "return", "lang_specific_word", "(", "word", ",", "DEFAULT_LANG_ID", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.get_word_index_with_spec": [[28, 40], ["word.startswith", "lang_id.lang_specific_word", "alphabet.get_index", "alphabet.get_index", "lang_id.default_lang_specific_word", "alphabet.get_index"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.lang_specific_word", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.default_lang_specific_word", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index"], ["", "def", "get_word_index_with_spec", "(", "alphabet", ",", "word", ",", "lang_id", ")", ":", "\n", "# if already prefixed (maybe by outside pre-processor, then go with it)", "\n", "    ", "if", "word", ".", "startswith", "(", "ALREADY_PREFIX", ")", ":", "\n", "        ", "return", "alphabet", ".", "get_index", "(", "word", ")", "\n", "#", "\n", "", "prefixed_word", "=", "lang_specific_word", "(", "word", ",", "lang_id", "=", "lang_id", ")", "\n", "if", "prefixed_word", "in", "alphabet", ".", "instance2index", ":", "\n", "        ", "return", "alphabet", ".", "get_index", "(", "prefixed_word", ")", "\n", "", "else", ":", "\n", "# try to get the English(default) word's index and later its embedding", "\n", "        ", "prefixed_word", "=", "default_lang_specific_word", "(", "word", ")", "\n", "return", "alphabet", ".", "get_index", "(", "prefixed_word", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nlinalg.nlinalg.logdet": [[8, 22], ["print", "print", "x.potrf", "torch.log", "torch.sum", "torch.log", "torch.eig", "x.potrf.diag"], "function", ["None"], ["def", "logdet", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        x: 2D positive semidefinite matrix.\n\n    Returns: log determinant of x\n\n    \"\"\"", "\n", "# TODO for pytorch 2.0.4, use inside potrf for variable.", "\n", "print", "(", "torch", ".", "log", "(", "torch", ".", "eig", "(", "x", ".", "data", ")", "[", "0", "]", ")", ")", "\n", "print", "(", "x", ")", "\n", "u_chol", "=", "x", ".", "potrf", "(", ")", "\n", "return", "torch", ".", "sum", "(", "torch", ".", "log", "(", "u_chol", ".", "diag", "(", ")", ")", ")", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nlinalg.nlinalg.logsumexp": [[24, 43], ["x.max", "x.max", "x.max", "x.max", "torch.log", "torch.log", "torch.exp().sum", "torch.exp().sum", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "logsumexp", "(", "x", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        x: A pytorch tensor (any dimension will do)\n        dim: int or None, over which to perform the summation. `None`, the\n             default, performs over all axes.\n\n    Returns: The result of the log(sum(exp(...))) operation.\n\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "        ", "xmax", "=", "x", ".", "max", "(", ")", "\n", "xmax_", "=", "x", ".", "max", "(", ")", "\n", "return", "xmax_", "+", "torch", ".", "log", "(", "torch", ".", "exp", "(", "x", "-", "xmax", ")", ".", "sum", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "xmax", ",", "_", "=", "x", ".", "max", "(", "dim", ",", "keepdim", "=", "True", ")", "\n", "xmax_", ",", "_", "=", "x", ".", "max", "(", "dim", ")", "\n", "return", "xmax_", "+", "torch", ".", "log", "(", "torch", ".", "exp", "(", "x", "-", "xmax", ")", ".", "sum", "(", "dim", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.init.assign_tensor": [[6, 21], ["isinstance", "tensor.copy_", "init.assign_tensor"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.init.assign_tensor"], ["def", "assign_tensor", "(", "tensor", ",", "val", ")", ":", "\n", "    ", "\"\"\"\n    copy val to tensor\n    Args:\n        tensor: an n-dimensional torch.Tensor or autograd.Variable\n        val: an n-dimensional torch.Tensor to fill the tensor with\n\n    Returns:\n\n    \"\"\"", "\n", "if", "isinstance", "(", "tensor", ",", "Variable", ")", ":", "\n", "        ", "assign_tensor", "(", "tensor", ".", "data", ",", "val", ")", "\n", "return", "tensor", "\n", "\n", "", "return", "tensor", ".", "copy_", "(", "val", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.utils._ntuple": [[8, 14], ["isinstance", "tuple", "itertools.repeat"], "function", ["None"], ["from", ".", "io", "import", "utils", "\n", "\n", "\n", "def", "load_embedding_dict", "(", "embedding", ",", "embedding_path", ",", "normalize_digits", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.utils.prepare_rnn_seq": [[21, 69], ["utils.prepare_rnn_seq.check_decreasing"], "function", ["None"], ["        ", "word2vec", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "embedding_path", ",", "binary", "=", "False", ")", "\n", "embedd_dim", "=", "word2vec", ".", "vector_size", "\n", "return", "word2vec", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'glove'", ":", "\n", "# loading GloVe", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedd_dim", "<", "0", ":", "\n", "                    ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "                    ", "assert", "(", "embedd_dim", "+", "1", "==", "len", "(", "tokens", ")", ")", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "0", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "0", "]", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'senna'", ":", "\n", "# loading Senna", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedd_dim", "<", "0", ":", "\n", "                    ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "                    ", "assert", "(", "embedd_dim", "+", "1", "==", "len", "(", "tokens", ")", ")", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "0", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "0", "]", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'sskip'", ":", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.utils.recover_rnn_seq": [[71, 86], ["torch.pad_packed_sequence", "output.index_select.index_select", "isinstance", "hx.index_select.index_select", "cx.index_select.index_select", "hx.index_select.index_select"], "function", ["None"], ["            ", "file", ".", "readline", "(", ")", "\n", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "try", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", "<", "embedd_dim", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "embedd_dim", "<", "0", ":", "\n", "                        ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.__init__": [[16, 36], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "max_dist", ",", "use_neg_dist", ",", "num_pos", ",", "use_encoder_pos", ",", "use_decoder_pos", ")", ":", "\n", "        ", "super", "(", "AugFeatureHelper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#", "\n", "self", ".", "max_dist", "=", "max_dist", "\n", "self", ".", "use_neg_dist", "=", "use_neg_dist", "\n", "self", ".", "num_pos", "=", "num_pos", "\n", "self", ".", "use_encoder_pos", "=", "use_encoder_pos", "\n", "self", ".", "use_decoder_pos", "=", "use_decoder_pos", "\n", "# 0: dist, 1: e-pos, 2: d-pos", "\n", "self", ".", "num_features", "=", "2", "*", "self", ".", "max_dist", "+", "1", "if", "self", ".", "use_neg_dist", "else", "self", ".", "max_dist", "+", "1", "\n", "if", "use_encoder_pos", ":", "\n", "            ", "self", ".", "alpha_epos", "=", "self", ".", "num_features", "\n", "self", ".", "num_features", "*=", "num_pos", "\n", "", "else", ":", "\n", "            ", "self", ".", "alpha_epos", "=", "0", "\n", "", "if", "use_decoder_pos", ":", "\n", "            ", "self", ".", "alpha_dpos", "=", "self", ".", "num_features", "\n", "self", ".", "num_features", "*=", "num_pos", "\n", "", "else", ":", "\n", "            ", "self", ".", "alpha_dpos", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.get_num_features": [[37, 39], ["None"], "methods", ["None"], ["", "", "def", "get_num_features", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_features", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.get_final_features": [[42, 55], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "encoder_pos.unsqueeze.unsqueeze.unsqueeze", "decoder_pos.unsqueeze.unsqueeze.unsqueeze", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "get_final_features", "(", "self", ",", "raw_dists", ",", "encoder_pos", ",", "decoder_pos", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_neg_dist", ":", "\n", "            ", "raw_dists", "=", "torch", ".", "abs", "(", "raw_dists", ")", "\n", "", "raw_dists", "=", "torch", ".", "clamp", "(", "raw_dists", ",", "min", "=", "-", "self", ".", "max_dist", ",", "max", "=", "self", ".", "max_dist", ")", "\n", "encoder_pos", "=", "encoder_pos", ".", "unsqueeze", "(", "1", ")", "\n", "decoder_pos", "=", "decoder_pos", ".", "unsqueeze", "(", "2", ")", "\n", "#", "\n", "output", "=", "raw_dists", "\n", "if", "self", ".", "alpha_epos", ">", "0", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "alpha_epos", "*", "encoder_pos", "\n", "", "if", "self", ".", "alpha_dpos", ">", "0", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "alpha_dpos", "*", "decoder_pos", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugBiAAttention.__init__": [[57, 86], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.Dropout", "torch.Dropout", "torch.Dropout", "attention_aug.AugBiAAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "attention_aug.AugBiAAttention.register_parameter", "sparse.Embedding", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "attention_aug.AugBiAAttention.add_module", "attention_aug.AugBiAAttention.register_parameter", "attention_aug.AugBiAAttention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_size_encoder", ",", "input_size_decoder", ",", "num_labels", ",", "num_features", ",", "dim_feature", ",", "drop_f_embed", ",", "biaffine", "=", "True", ")", ":", "\n", "        ", "super", "(", "AugBiAAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size_encoder", "=", "input_size_encoder", "\n", "self", ".", "input_size_decoder", "=", "input_size_decoder", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "dim_feature", "=", "dim_feature", "\n", "self", ".", "biaffine", "=", "biaffine", "\n", "# original parameters", "\n", "self", ".", "W_d", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ")", ")", "\n", "self", ".", "W_e", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "1", ",", "1", ")", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'U'", ",", "None", ")", "\n", "# extra param for aug-features", "\n", "", "self", ".", "use_features", "=", "(", "num_features", ">", "1", ")", "\n", "self", ".", "E_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_f_embed", ")", "\n", "if", "self", ".", "use_features", ":", "# only meaningful if >1 features", "\n", "            ", "self", ".", "E", "=", "Embedding", "(", "num_features", ",", "dim_feature", ")", "\n", "# concated to the enc-side, thus map to dec-size (same for all num_labels)", "\n", "self", ".", "U_f", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "dim_feature", ",", "self", ".", "input_size_decoder", ")", ")", "\n", "self", ".", "W_f", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "dim_feature", ",", "self", ".", "num_labels", ",", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_module", "(", "'E'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'U_f'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'W_f'", ",", "None", ")", "\n", "#", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugBiAAttention.reset_parameters": [[87, 96], ["torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.constant", "torch.init.constant", "torch.init.constant", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_d", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_e", ")", "\n", "nn", ".", "init", ".", "constant", "(", "self", ".", "b", ",", "0.", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "U", ")", "\n", "", "if", "self", ".", "use_features", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "U_f", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugBiAAttention.forward": [[101, 155], ["input_d.size", "input_e.size", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "input_d.size", "input_e.size", "attention_aug.AugBiAAttention.E_drop", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.transpose().transpose", "torch.matmul.transpose().transpose", "torch.matmul.transpose().transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "attention_aug.AugBiAAttention.E", "input_d.unsqueeze", "input_e.unsqueeze().transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "torch.matmul().squeeze().unsqueeze", "mask_e.unsqueeze().unsqueeze", "input_d.transpose", "input_e.transpose", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.matmul.transpose", "torch.matmul.transpose", "torch.matmul.transpose", "mask_d.unsqueeze().unsqueeze", "input_e.unsqueeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "mask_e.unsqueeze", "mask_d.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "input_d.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "input_features", ",", "mask_d", "=", "None", ",", "mask_e", "=", "None", ")", ":", "\n", "        ", "assert", "input_d", ".", "size", "(", "0", ")", "==", "input_e", ".", "size", "(", "0", ")", ",", "'batch sizes of encoder and decoder are requires to be equal.'", "\n", "batch", ",", "length_decoder", ",", "_", "=", "input_d", ".", "size", "(", ")", "\n", "_", ",", "length_encoder", ",", "_", "=", "input_e", ".", "size", "(", ")", "\n", "\n", "# compute decoder part: [num_label, input_size_decoder] * [batch, input_size_decoder, length_decoder]", "\n", "# the output shape is [batch, num_label, length_decoder]", "\n", "out_d", "=", "torch", ".", "matmul", "(", "self", ".", "W_d", ",", "input_d", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# compute decoder part: [num_label, input_size_encoder] * [batch, input_size_encoder, length_encoder]", "\n", "# the output shape is [batch, num_label, length_encoder]", "\n", "out_e", "=", "torch", ".", "matmul", "(", "self", ".", "W_e", ",", "input_e", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# scores with features", "\n", "if", "self", ".", "use_features", ":", "\n", "            ", "features_embed", "=", "self", ".", "E_drop", "(", "self", ".", "E", "(", "Variable", "(", "input_features", ")", ")", ")", "# [batch, len-d, len-e, fdim]", "\n", "features_out0", "=", "torch", ".", "matmul", "(", "features_embed", ",", "self", ".", "W_f", ")", "# [batch, len-d, len-e, num_label]", "\n", "output_f", "=", "features_out0", ".", "transpose", "(", "2", ",", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "# [batch, num_label, len-d, len-e]", "\n", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "", "if", "self", ".", "biaffine", ":", "\n", "# compute bi-affine part", "\n", "# [batch, 1, length_decoder, input_size_decoder] * [num_labels, input_size_decoder, input_size_encoder]", "\n", "# output shape [batch, num_label, length_decoder, input_size_encoder]", "\n", "            ", "output", "=", "torch", ".", "matmul", "(", "input_d", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "U", ")", "\n", "# [batch, num_label, length_decoder, input_size_encoder] * [batch, 1, input_size_encoder, length_encoder]", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "output", "=", "torch", ".", "matmul", "(", "output", ",", "input_e", ".", "unsqueeze", "(", "1", ")", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "self", ".", "use_features", ":", "\n", "# [batch, len-d, len-e, input_size_encoder] .dot [batch, 1, len-e, input_size_encoder]", "\n", "# -> [batch, 1, len-d, len-e]", "\n", "# output_f2 = torch.sum(features_embed*input_e.unsqueeze(1), dim=-1).unsqueeze(1)", "\n", "#", "\n", "# [batch, len-e, len-d, *] * [batch, len-e, *, 1]", "\n", "# output_f2 = torch.matmul(features_embed.transpose(1,2), input_e.unsqueeze(-1)).transpose(1,2).squeeze(-1).unsqueeze(1)", "\n", "\n", "# [batch, len-d, len-e, input_size_decoder]", "\n", "                ", "features_embed_map", "=", "torch", ".", "matmul", "(", "features_embed", ",", "self", ".", "U_f", ")", "\n", "# [batch, len-d, len-e, *] * [batch, len-d, *, 1]", "\n", "output_f2", "=", "torch", ".", "matmul", "(", "features_embed_map", ",", "input_d", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "output", "=", "output", "+", "out_d", "+", "out_e", "+", "output_f", "+", "output_f2", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "                ", "output", "=", "output", "+", "out_d", "+", "out_e", "+", "self", ".", "b", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "use_features", ":", "\n", "                ", "output", "=", "out_d", "+", "out_e", "+", "output_f", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "                ", "output", "=", "out_d", "+", "out_e", "+", "self", ".", "b", "\n", "\n", "", "", "if", "mask_d", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "*", "mask_d", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNBase.__init__": [[13, 36], ["torch.Module.__init__", "range", "range", "_functions.skipconnect_rnn.SkipConnectRNNBase.Cell", "_functions.skipconnect_rnn.SkipConnectRNNBase.all_cells.append", "_functions.skipconnect_rnn.SkipConnectRNNBase.add_module"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "(", "0", ",", "0", ")", ",", "bidirectional", "=", "False", ",", "initializer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "SkipConnectRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Cell", "=", "Cell", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "lstm", "=", "False", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n", "\n", "cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "p", "=", "dropout", ",", "initializer", "=", "initializer", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n", "self", ".", "add_module", "(", "'cell%d'", "%", "(", "layer", "*", "num_directions", "+", "direction", ")", ",", "cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNBase.reset_parameters": [[37, 40], ["cell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNBase.reset_noise": [[41, 44], ["cell.reset_noise"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise"], ["", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNBase.forward": [[45, 61], ["_functions.skipconnect_rnn.AutogradSkipConnectRNN", "_functions.skipconnect_rnn.SkipConnectRNNBase.reset_noise", "_functions.skipconnect_rnn.AutogradSkipConnectRNN.", "input.size", "input.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "mask.view", "input.data.new", "mask.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.AutogradSkipConnectRNN", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "skip_connect", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradSkipConnectRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "batch_first", "=", "self", ".", "batch_first", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "self", ".", "lstm", ")", "\n", "self", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "skip_connect", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNBase.step": [[62, 88], ["input.size", "_functions.skipconnect_rnn.AutogradSkipConnectStep", "_functions.skipconnect_rnn.AutogradSkipConnectStep.", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "input.data.new().zero_", "input.data.new", "input.data.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.AutogradSkipConnectStep"], ["", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "hs", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n        execute one step forward (only for one-directional RNN).\n        Args:\n            input (batch, input_size): input tensor of this step.\n            hx (num_layers, batch, hidden_size): the hidden state of last step.\n            hs (batch. hidden_size): tensor containing the skip connection state for each element in the batch.\n            mask (batch): the mask tensor of this step.\n\n        Returns:\n            output (batch, hidden_size): tensor containing the output of this step from the last layer of RNN.\n            hn (num_layers, batch, hidden_size): tensor containing the hidden state of this step\n        '''", "\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "", "", "if", "hs", "is", "None", ":", "\n", "            ", "hs", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "", "func", "=", "rnn_F", ".", "AutogradSkipConnectStep", "(", "num_layers", "=", "self", ".", "num_layers", ",", "lstm", "=", "self", ".", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "hs", ",", "mask", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNN.__init__": [[138, 140], ["_functions.skipconnect_rnn.SkipConnectRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectRNN", ",", "self", ")", ".", "__init__", "(", "SkipConnectRNNCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastLSTM.__init__": [[201, 204], ["_functions.skipconnect_rnn.SkipConnectRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectFastLSTM", ",", "self", ")", ".", "__init__", "(", "SkipConnectFastLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectLSTM.__init__": [[265, 268], ["_functions.skipconnect_rnn.SkipConnectRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectLSTM", ",", "self", ")", ".", "__init__", "(", "SkipConnectLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastGRU.__init__": [[322, 324], ["_functions.skipconnect_rnn.SkipConnectRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectFastGRU", ",", "self", ")", ".", "__init__", "(", "SkipConnectFastGRUCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectGRU.__init__": [[378, 380], ["_functions.skipconnect_rnn.SkipConnectRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectGRU", ",", "self", ")", ".", "__init__", "(", "SkipConnectGRUCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNCell.__init__": [[418, 446], ["variational_rnn.VarRNNCellBase.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectRNNCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectRNNCell.register_parameter", "_functions.skipconnect_rnn.SkipConnectRNNCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "nonlinearity", "=", "\"tanh\"", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SkipConnectRNNCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ",", "hidden_size", "*", "2", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNCell.reset_parameters": [[447, 453], ["_functions.skipconnect_rnn.SkipConnectRNNCell.parameters", "weight.dim", "weight.data.zero_", "_functions.skipconnect_rnn.SkipConnectRNNCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNCell.reset_noise": [[454, 470], ["_functions.skipconnect_rnn.SkipConnectRNNCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectRNNCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectRNNCell.bernoulli_", "_functions.skipconnect_rnn.SkipConnectRNNCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", "*", "2", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectRNNCell.forward": [[471, 485], ["func", "RuntimeError"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ",", "hs", ")", ":", "\n", "        ", "if", "self", ".", "nonlinearity", "==", "\"tanh\"", ":", "\n", "            ", "func", "=", "rnn_F", ".", "SkipConnectRNNTanhCell", "\n", "", "elif", "self", ".", "nonlinearity", "==", "\"relu\"", ":", "\n", "            ", "func", "=", "rnn_F", ".", "SkipConnectRNNReLUCell", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Unknown nonlinearity: {}\"", ".", "format", "(", "self", ".", "nonlinearity", ")", ")", "\n", "\n", "", "return", "func", "(", "\n", "input", ",", "hx", ",", "hs", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastLSTMCell.__init__": [[534, 561], ["variational_rnn.VarRNNCellBase.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.register_parameter", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SkipConnectFastLSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ",", "2", "*", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastLSTMCell.reset_parameters": [[562, 568], ["_functions.skipconnect_rnn.SkipConnectFastLSTMCell.parameters", "weight.dim", "weight.data.zero_", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastLSTMCell.reset_noise": [[569, 585], ["_functions.skipconnect_rnn.SkipConnectFastLSTMCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.bernoulli_", "_functions.skipconnect_rnn.SkipConnectFastLSTMCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", "*", "2", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastLSTMCell.forward": [[586, 592], ["_functions.skipconnect_rnn.SkipConnectFastLSTMCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectFastLSTMCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ",", "hs", ")", ":", "\n", "        ", "return", "rnn_F", ".", "SkipConnectFastLSTMCell", "(", "\n", "input", ",", "hx", ",", "hs", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectLSTMCell.__init__": [[641, 668], ["variational_rnn.VarRNNCellBase.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectLSTMCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectLSTMCell.register_parameter", "_functions.skipconnect_rnn.SkipConnectLSTMCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SkipConnectLSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "input_size", ",", "hidden_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "2", "*", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectLSTMCell.reset_parameters": [[669, 675], ["_functions.skipconnect_rnn.SkipConnectLSTMCell.parameters", "weight.dim", "weight.data.zero_", "_functions.skipconnect_rnn.SkipConnectLSTMCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectLSTMCell.reset_noise": [[676, 692], ["_functions.skipconnect_rnn.SkipConnectLSTMCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectLSTMCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectLSTMCell.bernoulli_", "_functions.skipconnect_rnn.SkipConnectLSTMCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "4", ",", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "4", ",", "batch_size", ",", "self", ".", "hidden_size", "*", "2", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectLSTMCell.forward": [[693, 699], ["_functions.skipconnect_rnn.SkipConnectLSTMCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectLSTMCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ",", "hs", ")", ":", "\n", "        ", "return", "rnn_F", ".", "SkipConnectLSTMCell", "(", "\n", "input", ",", "hx", ",", "hs", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastGRUCell.__init__": [[741, 768], ["variational_rnn.VarRNNCellBase.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.register_parameter", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SkipConnectFastGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "hidden_size", "*", "2", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastGRUCell.reset_parameters": [[769, 775], ["_functions.skipconnect_rnn.SkipConnectFastGRUCell.parameters", "weight.dim", "weight.data.zero_", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastGRUCell.reset_noise": [[776, 792], ["_functions.skipconnect_rnn.SkipConnectFastGRUCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.bernoulli_", "_functions.skipconnect_rnn.SkipConnectFastGRUCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", "*", "2", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectFastGRUCell.forward": [[793, 799], ["_functions.skipconnect_rnn.SkipConnectFastGRUCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectFastGRUCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ",", "hs", ")", ":", "\n", "        ", "return", "rnn_F", ".", "SkipConnectFastGRUCell", "(", "\n", "input", ",", "hx", ",", "hs", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectGRUCell.__init__": [[841, 868], ["variational_rnn.VarRNNCellBase.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectGRUCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.skipconnect_rnn.SkipConnectGRUCell.register_parameter", "_functions.skipconnect_rnn.SkipConnectGRUCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "SkipConnectGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "input_size", ",", "hidden_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", "*", "2", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectGRUCell.reset_parameters": [[869, 875], ["_functions.skipconnect_rnn.SkipConnectGRUCell.parameters", "weight.dim", "weight.data.zero_", "_functions.skipconnect_rnn.SkipConnectGRUCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectGRUCell.reset_noise": [[876, 892], ["_functions.skipconnect_rnn.SkipConnectGRUCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectGRUCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.skipconnect_rnn.SkipConnectGRUCell.bernoulli_", "_functions.skipconnect_rnn.SkipConnectGRUCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "3", ",", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "3", ",", "batch_size", ",", "self", ".", "hidden_size", "*", "2", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.skipconnect_rnn.SkipConnectGRUCell.forward": [[893, 899], ["_functions.skipconnect_rnn.SkipConnectGRUCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectGRUCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ",", "hs", ")", ":", "\n", "        ", "return", "rnn_F", ".", "SkipConnectGRUCell", "(", "\n", "input", ",", "hx", ",", "hs", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.ChainCRF.__init__": [[15, 45], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "crf.ChainCRF.reset_parameters", "torch.Linear", "torch.Linear", "crf.ChainCRF.register_parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "num_labels", ",", "bigram", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_size: int\n                the dimension of the input.\n            num_labels: int\n                the number of labels of the crf layer\n            bigram: bool\n                if apply bi-gram parameter.\n            **kwargs:\n        '''", "\n", "super", "(", "ChainCRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "num_labels", "=", "num_labels", "+", "1", "\n", "self", ".", "pad_label_id", "=", "num_labels", "\n", "self", ".", "bigram", "=", "bigram", "\n", "\n", "\n", "# state weight tensor", "\n", "self", ".", "state_nn", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "num_labels", ")", "\n", "if", "bigram", ":", "\n", "# transition weight tensor", "\n", "            ", "self", ".", "trans_nn", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "num_labels", "*", "self", ".", "num_labels", ")", "\n", "self", ".", "register_parameter", "(", "'trans_matrix'", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "trans_nn", "=", "None", "\n", "self", ".", "trans_matrix", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "num_labels", ")", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.ChainCRF.reset_parameters": [[46, 53], ["torch.init.constant", "torch.init.constant", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.constant", "torch.init.constant", "torch.init.normal", "torch.init.normal"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant", "(", "self", ".", "state_nn", ".", "bias", ",", "0.", ")", "\n", "if", "self", ".", "bigram", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "trans_nn", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant", "(", "self", ".", "trans_nn", ".", "bias", ",", "0.", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "normal", "(", "self", ".", "trans_matrix", ")", "\n", "# if not self.bigram:", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.ChainCRF.forward": [[56, 88], ["input.size", "crf.ChainCRF.state_nn().unsqueeze", "crf.ChainCRF.trans_nn().view", "crf.ChainCRF.state_nn", "mask.unsqueeze().unsqueeze", "crf.ChainCRF.trans_nn", "mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input: Tensor\n                the input tensor with shape = [batch, length, input_size]\n            mask: Tensor or None\n                the mask tensor with shape = [batch, length]\n\n        Returns: Tensor\n            the energy tensor with shape = [batch, length, num_label, num_label]\n\n        '''", "\n", "batch", ",", "length", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "\n", "# compute out_s by tensor dot [batch, length, input_size] * [input_size, num_label]", "\n", "# thus out_s should be [batch, length, num_label] --> [batch, length, num_label, 1]", "\n", "out_s", "=", "self", ".", "state_nn", "(", "input", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "if", "self", ".", "bigram", ":", "\n", "# compute out_s by tensor dot: [batch, length, input_size] * [input_size, num_label * num_label]", "\n", "# the output should be [batch, length, num_label,  num_label]", "\n", "            ", "out_t", "=", "self", ".", "trans_nn", "(", "input", ")", ".", "view", "(", "batch", ",", "length", ",", "self", ".", "num_labels", ",", "self", ".", "num_labels", ")", "\n", "output", "=", "out_t", "+", "out_s", "\n", "", "else", ":", "\n", "# [batch, length, num_label, num_label]", "\n", "            ", "output", "=", "self", ".", "trans_matrix", "+", "out_s", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "*", "mask", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.ChainCRF.loss": [[89, 146], ["input.size", "crf.ChainCRF.forward", "crf.ChainCRF.transpose", "target.transpose", "range", "mask.unsqueeze().transpose", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor().fill_", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.autograd.Variable", "torch.autograd.Variable", "neuronlp2.nlinalg.logsumexp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "neuronlp2.nlinalg.logsumexp", "mask.unsqueeze", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.autograd.Variable", "torch.autograd.Variable", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "partition.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nlinalg.nlinalg.logsumexp", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nlinalg.nlinalg.logsumexp"], ["", "def", "loss", "(", "self", ",", "input", ",", "target", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input: Tensor\n                the input tensor with shape = [batch, length, input_size]\n            target: Tensor\n                the tensor of target labels with shape [batch, length]\n            mask:Tensor or None\n                the mask tensor with shape = [batch, length]\n\n        Returns: Tensor\n                A 1D tensor for minus log likelihood loss\n        '''", "\n", "batch", ",", "length", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "energy", "=", "self", ".", "forward", "(", "input", ",", "mask", "=", "mask", ")", "\n", "# shape = [length, batch, num_label, num_label]", "\n", "energy_transpose", "=", "energy", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# shape = [length, batch]", "\n", "target_transpose", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# shape = [length, batch, 1]", "\n", "mask_transpose", "=", "None", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask_transpose", "=", "mask", ".", "unsqueeze", "(", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "\n", "# shape = [batch, num_label]", "\n", "", "partition", "=", "None", "\n", "\n", "if", "input", ".", "is_cuda", ":", "\n", "# shape = [batch]", "\n", "            ", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "prev_label", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "batch", ")", ".", "fill_", "(", "self", ".", "num_labels", "-", "1", ")", "\n", "tgt_energy", "=", "Variable", "(", "torch", ".", "zeros", "(", "batch", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "# shape = [batch]", "\n", "            ", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "long", "(", ")", "\n", "prev_label", "=", "torch", ".", "LongTensor", "(", "batch", ")", ".", "fill_", "(", "self", ".", "num_labels", "-", "1", ")", "\n", "tgt_energy", "=", "Variable", "(", "torch", ".", "zeros", "(", "batch", ")", ")", "\n", "\n", "", "for", "t", "in", "range", "(", "length", ")", ":", "\n", "# shape = [batch, num_label, num_label]", "\n", "            ", "curr_energy", "=", "energy_transpose", "[", "t", "]", "\n", "if", "t", "==", "0", ":", "\n", "                ", "partition", "=", "curr_energy", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "", "else", ":", "\n", "# shape = [batch, num_label]", "\n", "                ", "partition_new", "=", "logsumexp", "(", "curr_energy", "+", "partition", ".", "unsqueeze", "(", "2", ")", ",", "dim", "=", "1", ")", "\n", "if", "mask_transpose", "is", "None", ":", "\n", "                    ", "partition", "=", "partition_new", "\n", "", "else", ":", "\n", "                    ", "mask_t", "=", "mask_transpose", "[", "t", "]", "\n", "partition", "=", "partition", "+", "(", "partition_new", "-", "partition", ")", "*", "mask_t", "\n", "", "", "tgt_energy", "+=", "curr_energy", "[", "batch_index", ",", "prev_label", ",", "target_transpose", "[", "t", "]", ".", "data", "]", "\n", "prev_label", "=", "target_transpose", "[", "t", "]", ".", "data", "\n", "\n", "", "return", "logsumexp", "(", "partition", ",", "dim", "=", "1", ")", "-", "tgt_energy", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.ChainCRF.decode": [[147, 199], ["energy.transpose", "energy.transpose.size", "range", "torch.max", "torch.max", "torch.max", "torch.max", "reversed", "crf.ChainCRF.forward", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.arange().long().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.cuda.LongTensor().zero_", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.max", "torch.max", "torch.max", "torch.max", "range", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward"], ["", "def", "decode", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            input: Tensor\n                the input tensor with shape = [batch, length, input_size]\n            mask: Tensor or None\n                the mask tensor with shape = [batch, length]\n            leading_symbolic: nt\n                number of symbolic labels leading in type alphabets (set it to 0 if you are not sure)\n\n        Returns: Tensor\n            decoding results in shape [batch, length]\n\n        \"\"\"", "\n", "\n", "energy", "=", "self", ".", "forward", "(", "input", ",", "mask", "=", "mask", ")", ".", "data", "\n", "\n", "# Input should be provided as (n_batch, n_time_steps, num_labels, num_labels)", "\n", "# For convenience, we need to dimshuffle to (n_time_steps, n_batch, num_labels, num_labels)", "\n", "energy_transpose", "=", "energy", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# the last row and column is the tag for pad symbol. reduce these two dimensions by 1 to remove that.", "\n", "# also remove the first #symbolic rows and columns.", "\n", "# now the shape of energies_shuffled is [n_time_steps, b_batch, t, t] where t = num_labels - #symbolic - 1.", "\n", "energy_transpose", "=", "energy_transpose", "[", ":", ",", ":", ",", "leading_symbolic", ":", "-", "1", ",", "leading_symbolic", ":", "-", "1", "]", "\n", "\n", "length", ",", "batch_size", ",", "num_label", ",", "_", "=", "energy_transpose", ".", "size", "(", ")", "\n", "\n", "if", "input", ".", "is_cuda", ":", "\n", "            ", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "pi", "=", "torch", ".", "zeros", "(", "[", "length", ",", "batch_size", ",", "num_label", ",", "1", "]", ")", ".", "cuda", "(", ")", "\n", "pointer", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "length", ",", "batch_size", ",", "num_label", ")", ".", "zero_", "(", ")", "\n", "back_pointer", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "            ", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "long", "(", ")", "\n", "pi", "=", "torch", ".", "zeros", "(", "[", "length", ",", "batch_size", ",", "num_label", ",", "1", "]", ")", "\n", "pointer", "=", "torch", ".", "LongTensor", "(", "length", ",", "batch_size", ",", "num_label", ")", ".", "zero_", "(", ")", "\n", "back_pointer", "=", "torch", ".", "LongTensor", "(", "length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "\n", "", "pi", "[", "0", "]", "=", "energy", "[", ":", ",", "0", ",", "-", "1", ",", "leading_symbolic", ":", "-", "1", "]", "\n", "pointer", "[", "0", "]", "=", "-", "1", "\n", "for", "t", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "            ", "pi_prev", "=", "pi", "[", "t", "-", "1", "]", "\n", "pi", "[", "t", "]", ",", "pointer", "[", "t", "]", "=", "torch", ".", "max", "(", "energy_transpose", "[", "t", "]", "+", "pi_prev", ",", "dim", "=", "1", ")", "\n", "\n", "", "_", ",", "back_pointer", "[", "-", "1", "]", "=", "torch", ".", "max", "(", "pi", "[", "-", "1", "]", ",", "dim", "=", "1", ")", "\n", "for", "t", "in", "reversed", "(", "range", "(", "length", "-", "1", ")", ")", ":", "\n", "            ", "pointer_last", "=", "pointer", "[", "t", "+", "1", "]", "\n", "back_pointer", "[", "t", "]", "=", "pointer_last", "[", "batch_index", ",", "back_pointer", "[", "t", "+", "1", "]", "]", "\n", "\n", "", "return", "back_pointer", ".", "transpose", "(", "0", ",", "1", ")", "+", "leading_symbolic", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.TreeCRF.__init__": [[205, 221], ["torch.Module.__init__", "attention.BiAAttention"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "num_labels", ",", "biaffine", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_size: int\n                the dimension of the input.\n            num_labels: int\n                the number of labels of the crf layer\n            biaffine: bool\n                if apply bi-affine parameter.\n            **kwargs:\n        '''", "\n", "super", "(", "TreeCRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "attention", "=", "BiAAttention", "(", "input_size", ",", "input_size", ",", "num_labels", ",", "biaffine", "=", "biaffine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.TreeCRF.forward": [[222, 245], ["input_h.size", "crf.TreeCRF.attention", "torch.autograd.Variable", "torch.autograd.Variable", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "crf.TreeCRF.data.new().fill_", "crf.TreeCRF.data.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "forward", "(", "self", ",", "input_h", ",", "input_c", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_h: Tensor\n                the head input tensor with shape = [batch, length, input_size]\n            input_c: Tensor\n                the child input tensor with shape = [batch, length, input_size]\n            mask: Tensor or None\n                the mask tensor with shape = [batch, length]\n            lengths: Tensor or None\n                the length tensor with shape = [batch]\n\n        Returns: Tensor\n            the energy tensor with shape = [batch, num_label, length, length]\n\n        '''", "\n", "batch", ",", "length", ",", "_", "=", "input_h", ".", "size", "(", ")", "\n", "# [batch, num_labels, length, length]", "\n", "output", "=", "self", ".", "attention", "(", "input_h", ",", "input_c", ",", "mask_d", "=", "mask", ",", "mask_e", "=", "mask", ")", "\n", "# set diagonal elements to -inf", "\n", "output", "=", "output", "+", "Variable", "(", "torch", ".", "diag", "(", "output", ".", "data", ".", "new", "(", "length", ")", ".", "fill_", "(", "-", "np", ".", "inf", ")", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.crf.TreeCRF.loss": [[246, 316], ["input_h.size", "crf.TreeCRF.forward", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "A.sum.sum.sum", "A.sum.sum.sum", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "index.type_as().long.type_as().long.type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "tgt_energy.sum.sum.sum", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable().type_as", "torch.autograd.Variable().type_as", "crf.TreeCRF.data.new", "neuronlp2.nlinalg.logdet", "mask.unsqueeze().unsqueeze", "A.sum.sum.data.new().zero_", "mask.data.sum().long", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "index.type_as().long.type_as().long.type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "mask.unsqueeze().unsqueeze", "torch.autograd.Variable", "torch.autograd.Variable", "mask.unsqueeze", "A.sum.sum.data.new", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "range", "mask.data.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "types.data.t", "heads.data.t", "mask.unsqueeze", "A.sum.sum.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nlinalg.nlinalg.logdet", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "loss", "(", "self", ",", "input_h", ",", "input_c", ",", "heads", ",", "types", ",", "mask", "=", "None", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_h: Tensor\n                the head input tensor with shape = [batch, length, input_size]\n            input_c: Tensor\n                the child input tensor with shape = [batch, length, input_size]\n            target: Tensor\n                the tensor of target labels with shape [batch, length]\n            mask:Tensor or None\n                the mask tensor with shape = [batch, length]\n            lengths: tensor or list of int\n                the length of each input shape = [batch]\n\n        Returns: Tensor\n                A 1D tensor for minus log likelihood loss\n        '''", "\n", "batch", ",", "length", ",", "_", "=", "input_h", ".", "size", "(", ")", "\n", "energy", "=", "self", ".", "forward", "(", "input_h", ",", "input_c", ",", "mask", "=", "mask", ")", "\n", "# [batch, num_labels, length, length]", "\n", "A", "=", "torch", ".", "exp", "(", "energy", ")", "\n", "# mask out invalid positions", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "A", "=", "A", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# sum along the label axis [batch, length, length]", "\n", "", "A", "=", "A", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# get D [batch, 1, length]", "\n", "D", "=", "A", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# make sure L is positive-defined", "\n", "rtol", "=", "1e-4", "\n", "atol", "=", "1e-6", "\n", "D", "+=", "D", "*", "rtol", "+", "atol", "\n", "\n", "# [batch, length, length]", "\n", "D", "=", "Variable", "(", "A", ".", "data", ".", "new", "(", "A", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", ")", "+", "D", "\n", "# zeros out all elements except diagonal.", "\n", "D", "=", "D", "*", "Variable", "(", "torch", ".", "eye", "(", "length", ")", ")", ".", "type_as", "(", "D", ")", "\n", "\n", "# compute laplacian matrix", "\n", "# [batch, length, length]", "\n", "L", "=", "D", "-", "A", "\n", "\n", "# compute lengths", "\n", "if", "lengths", "is", "None", ":", "\n", "            ", "if", "mask", "is", "None", ":", "\n", "                ", "lengths", "=", "[", "length", "for", "_", "in", "range", "(", "batch", ")", "]", "\n", "", "else", ":", "\n", "                ", "lengths", "=", "mask", ".", "data", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "\n", "# compute partition Z(x) [batch]", "\n", "", "", "z", "=", "Variable", "(", "energy", ".", "data", ".", "new", "(", "batch", ")", ")", "\n", "for", "b", "in", "range", "(", "batch", ")", ":", "\n", "            ", "Lx", "=", "L", "[", "b", ",", "1", ":", "lengths", "[", "b", "]", ",", "1", ":", "lengths", "[", "b", "]", "]", "\n", "# print(torch.log(torch.eig(Lx.data)[0]))", "\n", "z", "[", "b", "]", "=", "logdet", "(", "Lx", ")", "\n", "\n", "# first create index matrix [length, batch]", "\n", "# index = torch.zeros(length, batch) + torch.arange(0, length).view(length, 1)", "\n", "", "index", "=", "torch", ".", "arange", "(", "0", ",", "length", ")", ".", "view", "(", "length", ",", "1", ")", ".", "expand", "(", "length", ",", "batch", ")", "\n", "index", "=", "index", ".", "type_as", "(", "energy", ".", "data", ")", ".", "long", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "energy", ".", "data", ")", ".", "long", "(", ")", "\n", "# compute target energy [length-1, batch]", "\n", "tgt_energy", "=", "energy", "[", "batch_index", ",", "types", ".", "data", ".", "t", "(", ")", ",", "heads", ".", "data", ".", "t", "(", ")", ",", "index", "]", "[", "1", ":", "]", "\n", "# sum over dim=0 shape = [batch]", "\n", "tgt_energy", "=", "tgt_energy", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "return", "z", "-", "tgt_energy", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNNBase.__init__": [[20, 43], ["torch.Module.__init__", "range", "range", "_functions.variational_rnn.VarMaskedRNNBase.Cell", "_functions.variational_rnn.VarMaskedRNNBase.all_cells.append", "_functions.variational_rnn.VarMaskedRNNBase.add_module"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "(", "0", ",", "0", ")", ",", "bidirectional", "=", "False", ",", "initializer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "VarMaskedRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Cell", "=", "Cell", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "lstm", "=", "False", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n", "\n", "cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "p", "=", "dropout", ",", "initializer", "=", "initializer", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n", "self", ".", "add_module", "(", "'cell%d'", "%", "(", "layer", "*", "num_directions", "+", "direction", ")", ",", "cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNNBase.reset_parameters": [[44, 47], ["cell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNNBase.reset_noise": [[48, 51], ["cell.reset_noise"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise"], ["", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNNBase.forward": [[52, 69], ["_functions.variational_rnn.AutogradVarMaskedRNN", "_functions.variational_rnn.VarMaskedRNNBase.reset_noise", "_functions.variational_rnn.AutogradVarMaskedRNN.", "input.size", "input.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "mask.view", "input.data.new", "mask.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.AutogradVarMaskedRNN", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradVarMaskedRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "batch_first", "=", "self", ".", "batch_first", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "self", ".", "lstm", ")", "\n", "\n", "self", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNNBase.step": [[70, 93], ["input.size", "_functions.variational_rnn.AutogradVarMaskedStep", "_functions.variational_rnn.AutogradVarMaskedStep.", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "input.data.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.AutogradVarMaskedStep"], ["", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n        execute one step forward (only for one-directional RNN).\n        Args:\n            input (batch, input_size): input tensor of this step.\n            hx (num_layers, batch, hidden_size): the hidden state of last step.\n            mask (batch): the mask tensor of this step.\n\n        Returns:\n            output (batch, hidden_size): tensor containing the output of this step from the last layer of RNN.\n            hn (num_layers, batch, hidden_size): tensor containing the hidden state of this step\n        '''", "\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradVarMaskedStep", "(", "num_layers", "=", "self", ".", "num_layers", ",", "lstm", "=", "self", ".", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "mask", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedRNN.__init__": [[142, 144], ["_functions.variational_rnn.VarMaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedRNN", ",", "self", ")", ".", "__init__", "(", "VarRNNCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedLSTM.__init__": [[204, 207], ["_functions.variational_rnn.VarMaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedLSTM", ",", "self", ")", ".", "__init__", "(", "VarLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedFastLSTM.__init__": [[268, 271], ["_functions.variational_rnn.VarMaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedFastLSTM", ",", "self", ")", ".", "__init__", "(", "VarFastLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedGRU.__init__": [[324, 326], ["_functions.variational_rnn.VarMaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedGRU", ",", "self", ")", ".", "__init__", "(", "VarGRUCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarMaskedFastGRU.__init__": [[379, 381], ["_functions.variational_rnn.VarMaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedFastGRU", ",", "self", ")", ".", "__init__", "(", "VarFastGRUCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCellBase.__repr__": [[384, 392], ["s.format"], "methods", ["None"], ["    ", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{name}({input_size}, {hidden_size}'", "\n", "if", "'bias'", "in", "self", ".", "__dict__", "and", "self", ".", "bias", "is", "not", "True", ":", "\n", "            ", "s", "+=", "', bias={bias}'", "\n", "", "if", "'nonlinearity'", "in", "self", ".", "__dict__", "and", "self", ".", "nonlinearity", "!=", "\"tanh\"", ":", "\n", "            ", "s", "+=", "', nonlinearity={nonlinearity}'", "\n", "", "s", "+=", "')'", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCellBase.reset_noise": [[393, 400], ["None"], "methods", ["None"], ["", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Should be overriden by all subclasses.\n        Args:\n            batch_size: (int) batch size of input.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCell.__init__": [[436, 464], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarRNNCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarRNNCell.register_parameter", "_functions.variational_rnn.VarRNNCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "nonlinearity", "=", "\"tanh\"", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "VarRNNCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "nonlinearity", "=", "nonlinearity", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCell.reset_parameters": [[465, 471], ["_functions.variational_rnn.VarRNNCell.parameters", "weight.dim", "weight.data.zero_", "_functions.variational_rnn.VarRNNCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCell.reset_noise": [[472, 488], ["_functions.variational_rnn.VarRNNCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarRNNCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarRNNCell.bernoulli_", "_functions.variational_rnn.VarRNNCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarRNNCell.forward": [[489, 503], ["func", "RuntimeError"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ")", ":", "\n", "        ", "if", "self", ".", "nonlinearity", "==", "\"tanh\"", ":", "\n", "            ", "func", "=", "rnn_F", ".", "VarRNNTanhCell", "\n", "", "elif", "self", ".", "nonlinearity", "==", "\"relu\"", ":", "\n", "            ", "func", "=", "rnn_F", ".", "VarRNNReLUCell", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Unknown nonlinearity: {}\"", ".", "format", "(", "self", ".", "nonlinearity", ")", ")", "\n", "\n", "", "return", "func", "(", "\n", "input", ",", "hx", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarLSTMCell.__init__": [[550, 577], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarLSTMCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarLSTMCell.register_parameter", "_functions.variational_rnn.VarLSTMCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "VarLSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "input_size", ",", "hidden_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", ",", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarLSTMCell.reset_parameters": [[578, 584], ["_functions.variational_rnn.VarLSTMCell.parameters", "weight.dim", "weight.data.zero_", "_functions.variational_rnn.VarLSTMCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarLSTMCell.reset_noise": [[585, 601], ["_functions.variational_rnn.VarLSTMCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarLSTMCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarLSTMCell.bernoulli_", "_functions.variational_rnn.VarLSTMCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "4", ",", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "4", ",", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarLSTMCell.forward": [[602, 608], ["_functions.variational_rnn.VarLSTMCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarLSTMCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ")", ":", "\n", "        ", "return", "rnn_F", ".", "VarLSTMCell", "(", "\n", "input", ",", "hx", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarGRUCell.__init__": [[648, 675], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarGRUCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarGRUCell.register_parameter", "_functions.variational_rnn.VarGRUCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "VarGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "input_size", ",", "hidden_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", ",", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarGRUCell.reset_parameters": [[676, 682], ["_functions.variational_rnn.VarGRUCell.parameters", "weight.dim", "weight.data.zero_", "_functions.variational_rnn.VarGRUCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarGRUCell.reset_noise": [[683, 699], ["_functions.variational_rnn.VarGRUCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarGRUCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarGRUCell.bernoulli_", "_functions.variational_rnn.VarGRUCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "3", ",", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "3", ",", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarGRUCell.forward": [[700, 706], ["_functions.variational_rnn.VarGRUCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarGRUCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ")", ":", "\n", "        ", "return", "rnn_F", ".", "VarGRUCell", "(", "\n", "input", ",", "hx", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastLSTMCell.__init__": [[753, 780], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarFastLSTMCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarFastLSTMCell.register_parameter", "_functions.variational_rnn.VarFastLSTMCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "VarFastLSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "4", "*", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastLSTMCell.reset_parameters": [[781, 787], ["_functions.variational_rnn.VarFastLSTMCell.parameters", "weight.dim", "weight.data.zero_", "_functions.variational_rnn.VarFastLSTMCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastLSTMCell.reset_noise": [[788, 804], ["_functions.variational_rnn.VarFastLSTMCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarFastLSTMCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarFastLSTMCell.bernoulli_", "_functions.variational_rnn.VarFastLSTMCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastLSTMCell.forward": [[805, 811], ["_functions.variational_rnn.VarFastLSTMCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarFastLSTMCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ")", ":", "\n", "        ", "return", "rnn_F", ".", "VarFastLSTMCell", "(", "\n", "input", ",", "hx", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.__init__": [[851, 878], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarFastGRUCell.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "_functions.variational_rnn.VarFastGRUCell.register_parameter", "_functions.variational_rnn.VarFastGRUCell.register_parameter", "variational_rnn.default_initializer", "ValueError", "ValueError", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ",", "p", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "VarFastGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "weight_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "input_size", ")", ")", "\n", "self", ".", "weight_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ",", "hidden_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias_ih", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ")", ")", "\n", "self", ".", "bias_hh", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias_ih'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias_hh'", ",", "None", ")", "\n", "\n", "", "self", ".", "initializer", "=", "default_initializer", "(", "self", ".", "hidden_size", ")", "if", "initializer", "is", "None", "else", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "p_in", ",", "p_hidden", "=", "p", "\n", "if", "p_in", "<", "0", "or", "p_in", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"input dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_in", ")", ")", "\n", "", "if", "p_hidden", "<", "0", "or", "p_hidden", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"hidden state dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p_hidden", ")", ")", "\n", "", "self", ".", "p_in", "=", "p_in", "\n", "self", ".", "p_hidden", "=", "p_hidden", "\n", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_parameters": [[879, 885], ["_functions.variational_rnn.VarFastGRUCell.parameters", "weight.dim", "weight.data.zero_", "_functions.variational_rnn.VarFastGRUCell.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "initializer", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise": [[886, 902], ["_functions.variational_rnn.VarFastGRUCell.weight_ih.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarFastGRUCell.weight_hh.data.new", "torch.autograd.Variable", "torch.autograd.Variable", "_functions.variational_rnn.VarFastGRUCell.bernoulli_", "_functions.variational_rnn.VarFastGRUCell.bernoulli_"], "methods", ["None"], ["", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "p_in", ":", "\n", "                ", "noise", "=", "self", ".", "weight_ih", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "input_size", ")", "\n", "self", ".", "noise_in", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_in", ")", "/", "(", "1.0", "-", "self", ".", "p_in", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_in", "=", "None", "\n", "\n", "", "if", "self", ".", "p_hidden", ":", "\n", "                ", "noise", "=", "self", ".", "weight_hh", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "noise_hidden", "=", "Variable", "(", "noise", ".", "bernoulli_", "(", "1.0", "-", "self", ".", "p_hidden", ")", "/", "(", "1.0", "-", "self", ".", "p_hidden", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "noise_hidden", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "noise_in", "=", "None", "\n", "self", ".", "noise_hidden", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.forward": [[903, 909], ["_functions.variational_rnn.VarFastGRUCell"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarFastGRUCell"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hx", ")", ":", "\n", "        ", "return", "rnn_F", ".", "VarFastGRUCell", "(", "\n", "input", ",", "hx", ",", "\n", "self", ".", "weight_ih", ",", "self", ".", "weight_hh", ",", "\n", "self", ".", "bias_ih", ",", "self", ".", "bias_hh", ",", "\n", "self", ".", "noise_in", ",", "self", ".", "noise_hidden", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.default_initializer": [[11, 17], ["math.sqrt", "torch.init.uniform"], "function", ["None"], ["def", "default_initializer", "(", "hidden_size", ")", ":", "\n", "    ", "stdv", "=", "1.0", "/", "math", ".", "sqrt", "(", "hidden_size", ")", "\n", "def", "forward", "(", "tensor", ")", ":", "\n", "        ", "nn", ".", "init", ".", "uniform", "(", "tensor", ",", "-", "stdv", ",", "stdv", ")", "\n", "\n", "", "return", "forward", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.sparse.Embedding.__init__": [[40, 54], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "sparse.Embedding.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "init_embedding", "=", "None", ",", "freeze", "=", "False", ",", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "norm_type", "=", "2", ",", "scale_grad_by_freq", "=", "False", ",", "sparse", "=", "False", ")", ":", "\n", "        ", "super", "(", "Embedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "self", ".", "frozen", "=", "freeze", "\n", "self", ".", "sparse", "=", "sparse", "\n", "\n", "self", ".", "reset_parameters", "(", "init_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.sparse.Embedding.reset_parameters": [[55, 68], ["numpy.sqrt", "sparse.Embedding.weight.data.uniform_", "init.assign_tensor", "sparse.Embedding.weight.data[].fill_", "Warning"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.init.assign_tensor"], ["", "def", "reset_parameters", "(", "self", ",", "init_embedding", ")", ":", "\n", "        ", "if", "init_embedding", "is", "None", ":", "\n", "            ", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "self", ".", "embedding_dim", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "scale", ",", "scale", ")", "\n", "", "else", ":", "\n", "            ", "assign_tensor", "(", "self", ".", "weight", ",", "init_embedding", ")", "\n", "", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", ".", "data", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n", "", "if", "self", ".", "frozen", ":", "\n", "            ", "if", "init_embedding", "is", "None", ":", "\n", "                ", "raise", "Warning", "(", "'Freeze embeddings which are randomly initialized.'", ")", "\n", "", "self", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.sparse.Embedding.freeze": [[69, 72], ["None"], "methods", ["None"], ["", "", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight", ".", "requires_grad", "=", "False", "\n", "self", ".", "frozen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.sparse.Embedding.forward": [[73, 88], ["input.view.view.size", "sparse.Embedding._backend.Embedding.apply().view", "input.view.view.dim", "int", "input.view.view.view", "numpy.prod", "sparse.Embedding._backend.Embedding.apply"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "padding_idx", "=", "self", ".", "padding_idx", "\n", "if", "padding_idx", "is", "None", ":", "\n", "            ", "padding_idx", "=", "-", "1", "\n", "\n", "", "input_size", "=", "input", ".", "size", "(", ")", "\n", "if", "input", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "num_inputs", "=", "int", "(", "np", ".", "prod", "(", "input_size", "[", ":", "-", "1", "]", ")", ")", "\n", "input", "=", "input", ".", "view", "(", "num_inputs", ",", "input_size", "[", "-", "1", "]", ")", "\n", "\n", "", "output_size", "=", "input_size", "+", "(", "self", ".", "embedding_dim", ",", ")", "\n", "return", "self", ".", "_backend", ".", "Embedding", ".", "apply", "(", "\n", "input", ",", "self", ".", "weight", ",", "\n", "padding_idx", ",", "self", ".", "max_norm", ",", "self", ".", "norm_type", ",", "\n", "self", ".", "scale_grad_by_freq", ",", "self", ".", "sparse", ")", ".", "view", "(", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.sparse.Embedding.__repr__": [[89, 103], ["s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{name}({num_embeddings}, {embedding_dim}'", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', padding_idx={padding_idx}'", "\n", "", "if", "self", ".", "max_norm", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', max_norm={max_norm}'", "\n", "", "if", "self", ".", "norm_type", "!=", "2", ":", "\n", "            ", "s", "+=", "', norm_type={norm_type}'", "\n", "", "if", "self", ".", "scale_grad_by_freq", "is", "not", "False", ":", "\n", "            ", "s", "+=", "', scale_grad_by_freq={scale_grad_by_freq}'", "\n", "", "if", "self", ".", "sparse", "is", "not", "False", ":", "\n", "            ", "s", "+=", "', sparse=True'", "\n", "", "s", "+=", "')'", "\n", "return", "s", ".", "format", "(", "name", "=", "self", ".", "__class__", ".", "__name__", ",", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.BiAAttention.__init__": [[14, 43], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "attention.BiAAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "attention.BiAAttention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size_encoder", ",", "input_size_decoder", ",", "num_labels", ",", "biaffine", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_size_encoder: int\n                the dimension of the encoder input.\n            input_size_decoder: int\n                the dimension of the decoder input.\n            num_labels: int\n                the number of labels of the crf layer\n            biaffine: bool\n                if apply bi-affine parameter.\n            **kwargs:\n        '''", "\n", "super", "(", "BiAAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size_encoder", "=", "input_size_encoder", "\n", "self", ".", "input_size_decoder", "=", "input_size_decoder", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "biaffine", "=", "biaffine", "\n", "\n", "self", ".", "W_d", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ")", ")", "\n", "self", ".", "W_e", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "1", ",", "1", ")", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'U'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.BiAAttention.reset_parameters": [[44, 50], ["torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.constant", "torch.init.constant", "torch.init.constant", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_d", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_e", ")", "\n", "nn", ".", "init", ".", "constant", "(", "self", ".", "b", ",", "0.", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.BiAAttention.forward": [[51, 97], ["input_d.size", "input_e.size", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "input_d.size", "input_e.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "input_d.unsqueeze", "input_e.unsqueeze().transpose", "mask_e.unsqueeze().unsqueeze", "input_d.transpose", "input_e.transpose", "mask_d.unsqueeze().unsqueeze", "input_e.unsqueeze", "mask_e.unsqueeze", "mask_d.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "mask_d", "=", "None", ",", "mask_e", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_d: Tensor\n                the decoder input tensor with shape = [batch, length_decoder, input_size]\n            input_e: Tensor\n                the child input tensor with shape = [batch, length_encoder, input_size]\n            mask_d: Tensor or None\n                the mask tensor for decoder with shape = [batch, length_decoder]\n            mask_e: Tensor or None\n                the mask tensor for encoder with shape = [batch, length_encoder]\n\n        Returns: Tensor\n            the energy tensor with shape = [batch, num_label, length, length]\n\n        '''", "\n", "assert", "input_d", ".", "size", "(", "0", ")", "==", "input_e", ".", "size", "(", "0", ")", ",", "'batch sizes of encoder and decoder are requires to be equal.'", "\n", "batch", ",", "length_decoder", ",", "_", "=", "input_d", ".", "size", "(", ")", "\n", "_", ",", "length_encoder", ",", "_", "=", "input_e", ".", "size", "(", ")", "\n", "\n", "# compute decoder part: [num_label, input_size_decoder] * [batch, input_size_decoder, length_decoder]", "\n", "# the output shape is [batch, num_label, length_decoder]", "\n", "out_d", "=", "torch", ".", "matmul", "(", "self", ".", "W_d", ",", "input_d", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# compute decoder part: [num_label, input_size_encoder] * [batch, input_size_encoder, length_encoder]", "\n", "# the output shape is [batch, num_label, length_encoder]", "\n", "out_e", "=", "torch", ".", "matmul", "(", "self", ".", "W_e", ",", "input_e", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "if", "self", ".", "biaffine", ":", "\n", "# compute bi-affine part", "\n", "# [batch, 1, length_decoder, input_size_decoder] * [num_labels, input_size_decoder, input_size_encoder]", "\n", "# output shape [batch, num_label, length_decoder, input_size_encoder]", "\n", "            ", "output", "=", "torch", ".", "matmul", "(", "input_d", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "U", ")", "\n", "# [batch, num_label, length_decoder, input_size_encoder] * [batch, 1, input_size_encoder, length_encoder]", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "output", "=", "torch", ".", "matmul", "(", "output", ",", "input_e", ".", "unsqueeze", "(", "1", ")", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "output", "=", "output", "+", "out_d", "+", "out_e", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "            ", "output", "=", "out_d", "+", "out_d", "+", "self", ".", "b", "\n", "\n", "", "if", "mask_d", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "*", "mask_d", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.ConcatAttention.__init__": [[105, 133], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "attention.ConcatAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size_encoder", ",", "input_size_decoder", ",", "hidden_size", ",", "num_labels", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_size_encoder: int\n                the dimension of the encoder input.\n            input_size_decoder: int\n                the dimension of the decoder input.\n            hidden_size: int\n                the dimension of the hidden.\n            num_labels: int\n                the number of labels of the crf layer\n            biaffine: bool\n                if apply bi-affine parameter.\n            **kwargs:\n        '''", "\n", "super", "(", "ConcatAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size_encoder", "=", "input_size_encoder", "\n", "self", ".", "input_size_decoder", "=", "input_size_decoder", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "\n", "self", ".", "W_d", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "input_size_decoder", ",", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "W_e", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "input_size_encoder", ",", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "hidden_size", ",", "self", ".", "num_labels", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.ConcatAttention.reset_parameters": [[134, 139], ["torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.constant", "torch.init.constant", "torch.init.constant"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_d", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_e", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "v", ")", "\n", "nn", ".", "init", ".", "constant", "(", "self", ".", "b", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention.ConcatAttention.forward": [[140, 178], ["input_d.size", "input_e.size", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "torch.matmul().transpose", "input_d.size", "input_e.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "mask_d", "=", "None", ",", "mask_e", "=", "None", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_d: Tensor\n                the decoder input tensor with shape = [batch, length_decoder, input_size]\n            input_e: Tensor\n                the child input tensor with shape = [batch, length_encoder, input_size]\n            mask_d: Tensor or None\n                the mask tensor for decoder with shape = [batch, length_decoder]\n            mask_e: Tensor or None\n                the mask tensor for encoder with shape = [batch, length_encoder]\n\n        Returns: Tensor\n            the energy tensor with shape = [batch, num_label, length, length]\n\n        '''", "\n", "assert", "input_d", ".", "size", "(", "0", ")", "==", "input_e", ".", "size", "(", "0", ")", ",", "'batch sizes of encoder and decoder are requires to be equal.'", "\n", "batch", ",", "length_decoder", ",", "_", "=", "input_d", ".", "size", "(", ")", "\n", "_", ",", "length_encoder", ",", "_", "=", "input_e", ".", "size", "(", ")", "\n", "\n", "# compute decoder part: [batch, length_decoder, input_size_decoder] * [input_size_decoder, hidden_size]", "\n", "# the output shape is [batch, length_decoder, hidden_size]", "\n", "# then --> [batch, 1, length_decoder, hidden_size]", "\n", "out_d", "=", "torch", ".", "matmul", "(", "input_d", ",", "self", ".", "W_d", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# compute decoder part: [batch, length_encoder, input_size_encoder] * [input_size_encoder, hidden_size]", "\n", "# the output shape is [batch, length_encoder, hidden_size]", "\n", "# then --> [batch, length_encoder, 1, hidden_size]", "\n", "out_e", "=", "torch", ".", "matmul", "(", "input_e", ",", "self", ".", "W_e", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# add them together [batch, length_encoder, length_decoder, hidden_size]", "\n", "out", "=", "F", ".", "tanh", "(", "out_d", "+", "out_e", "+", "self", ".", "b", ")", "\n", "\n", "# product with v", "\n", "# [batch, length_encoder, length_decoder, hidden_size] * [hidden, num_label]", "\n", "# [batch, length_encoder, length_decoder, num_labels]", "\n", "# then --> [batch, num_labels, length_decoder, length_encoder]", "\n", "return", "torch", ".", "matmul", "(", "out", ",", "self", ".", "v", ")", ".", "transpose", "(", "1", ",", "3", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.__init__": [[12, 35], ["torch.Module.__init__", "range", "range", "masked_rnn.MaskedRNNBase.Cell", "masked_rnn.MaskedRNNBase.all_cells.append", "masked_rnn.MaskedRNNBase.add_module"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "0", ",", "bidirectional", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "MaskedRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Cell", "=", "Cell", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n", "\n", "cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n", "self", ".", "add_module", "(", "'cell%d'", "%", "(", "layer", "*", "num_directions", "+", "direction", ")", ",", "cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.reset_parameters": [[36, 39], ["cell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.forward": [[40, 58], ["_functions.masked_rnn.AutogradMaskedRNN", "_functions.masked_rnn.AutogradMaskedRNN.", "input.size", "input.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "mask.view", "input.data.new", "mask.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.AutogradMaskedRNN", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "lstm", "=", "self", ".", "Cell", "is", "nn", ".", "LSTMCell", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "AutogradMaskedRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "batch_first", "=", "self", ".", "batch_first", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "train", "=", "self", ".", "training", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.step": [[59, 86], ["input.size", "_functions.masked_rnn.AutogradMaskedStep", "_functions.masked_rnn.AutogradMaskedStep.", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input.data.new().zero_", "input.data.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.AutogradMaskedStep"], ["", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n        execute one step forward (only for one-directional RNN).\n        Args:\n            input (batch, input_size): input tensor of this step.\n            hx (num_layers, batch, hidden_size): the hidden state of last step.\n            mask (batch): the mask tensor of this step.\n\n        Returns:\n            output (batch, hidden_size): tensor containing the output of this step from the last layer of RNN.\n            hn (num_layers, batch, hidden_size): tensor containing the hidden state of this step\n        '''", "\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "lstm", "=", "self", ".", "Cell", "is", "nn", ".", "LSTMCell", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "AutogradMaskedStep", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "train", "=", "self", ".", "training", ",", "\n", "lstm", "=", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "mask", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNN.__init__": [[134, 136], ["masked_rnn.MaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MaskedRNN", ",", "self", ")", ".", "__init__", "(", "nn", ".", "RNNCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedLSTM.__init__": [[196, 198], ["masked_rnn.MaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MaskedLSTM", ",", "self", ")", ".", "__init__", "(", "nn", ".", "LSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedGRU.__init__": [[250, 252], ["masked_rnn.MaskedRNNBase.__init__"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MaskedGRU", ",", "self", ")", ".", "__init__", "(", "nn", ".", "GRUCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.linear.BiLinear.__init__": [[15, 40], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "linear.BiLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "linear.BiLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["def", "__init__", "(", "self", ",", "left_features", ",", "right_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "'''\n\n        Args:\n            left_features: size of left input\n            right_features: size of right input\n            out_features: size of output\n            bias: If set to False, the layer will not learn an additive bias.\n                Default: True\n        '''", "\n", "super", "(", "BiLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left_features", "=", "left_features", "\n", "self", ".", "right_features", "=", "right_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ",", "self", ".", "right_features", ")", ")", "\n", "self", ".", "W_l", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "self", ".", "W_r", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.linear.BiLinear.reset_parameters": [[41, 46], ["torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.constant", "torch.init.constant", "torch.init.constant", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_l", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "W_r", ")", "\n", "nn", ".", "init", ".", "constant", "(", "self", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "xavier_uniform", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.linear.BiLinear.forward": [[47, 75], ["input_left.view.view.size", "input_right.view.view.size", "int", "input_left.view.view.view", "input_right.view.view.view", "torch.bilinear", "torch.bilinear", "torch.bilinear", "torch.bilinear.view", "numpy.prod", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "forward", "(", "self", ",", "input_left", ",", "input_right", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_left: Tensor\n                the left input tensor with shape = [batch1, batch2, ..., left_features]\n            input_right: Tensor\n                the right input tensor with shape = [batch1, batch2, ..., right_features]\n\n        Returns:\n\n        '''", "\n", "\n", "left_size", "=", "input_left", ".", "size", "(", ")", "\n", "right_size", "=", "input_right", ".", "size", "(", ")", "\n", "assert", "left_size", "[", ":", "-", "1", "]", "==", "right_size", "[", ":", "-", "1", "]", ",", "\"batch size of left and right inputs mis-match: (%s, %s)\"", "%", "(", "left_size", "[", ":", "-", "1", "]", ",", "right_size", "[", ":", "-", "1", "]", ")", "\n", "batch", "=", "int", "(", "np", ".", "prod", "(", "left_size", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# convert left and right input to matrices [batch, left_features], [batch, right_features]", "\n", "input_left", "=", "input_left", ".", "view", "(", "batch", ",", "self", ".", "left_features", ")", "\n", "input_right", "=", "input_right", ".", "view", "(", "batch", ",", "self", ".", "right_features", ")", "\n", "\n", "# output [batch, out_features]", "\n", "output", "=", "F", ".", "bilinear", "(", "input_left", ",", "input_right", ",", "self", ".", "U", ",", "self", ".", "bias", ")", "\n", "output", "=", "output", "+", "F", ".", "linear", "(", "input_left", ",", "self", ".", "W_l", ",", "None", ")", "+", "F", ".", "linear", "(", "input_right", ",", "self", ".", "W_r", ",", "None", ")", "\n", "# convert back to [batch1, batch2, ..., out_features]", "\n", "return", "output", ".", "view", "(", "left_size", "[", ":", "-", "1", "]", "+", "(", "self", ".", "out_features", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.linear.BiLinear.__repr__": [[76, 81], ["str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "'in1_features='", "+", "str", "(", "self", ".", "left_features", ")", "+", "', in2_features='", "+", "str", "(", "self", ".", "right_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectRNNReLUCell": [[9, 19], ["torch.cat", "torch.nn.functional.relu", "torch.nn.functional.linear", "torch.nn.functional.linear"], "function", ["None"], ["from", ".", "variational_rnn", "import", "VarRNNCellBase", ",", "default_initializer", "\n", "\n", "\n", "class", "SkipConnectRNNBase", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "(", "0", ",", "0", ")", ",", "bidirectional", "=", "False", ",", "initializer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "SkipConnectRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Cell", "=", "Cell", "\n", "self", ".", "input_size", "=", "input_size", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectRNNTanhCell": [[21, 31], ["torch.cat", "torch.nn.functional.tanh", "torch.nn.functional.linear", "torch.nn.functional.linear"], "function", ["None"], ["self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "lstm", "=", "False", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectLSTMCell": [[33, 53], ["torch.cat", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.sigmoid", "input.expand", "torch.cat.expand", "torch.baddbmm", "torch.baddbmm", "torch.nn.functional.tanh", "input.unsqueeze", "torch.cat.unsqueeze", "b_ih.unsqueeze", "b_hh.unsqueeze", "input.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "p", "=", "dropout", ",", "initializer", "=", "initializer", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n", "self", ".", "add_module", "(", "'cell%d'", "%", "(", "layer", "*", "num_directions", "+", "direction", ")", ",", "cell", ")", "\n", "\n", "", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "skip_connect", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradSkipConnectRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectFastLSTMCell": [[55, 83], ["torch.cat", "gates.chunk", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.sigmoid", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.tanh", "state", "state"], "function", ["None"], ["bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "self", ".", "lstm", ")", "\n", "self", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "skip_connect", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n", "", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "hs", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n        execute one step forward (only for one-directional RNN).\n        Args:\n            input (batch, input_size): input tensor of this step.\n            hx (num_layers, batch, hidden_size): the hidden state of last step.\n            hs (batch. hidden_size): tensor containing the skip connection state for each element in the batch.\n            mask (batch): the mask tensor of this step.\n\n        Returns:\n            output (batch, hidden_size): tensor containing the output of this step from the last layer of RNN.\n            hn (num_layers, batch, hidden_size): tensor containing the hidden state of this step\n        '''", "\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "", "", "if", "hs", "is", "None", ":", "\n", "            ", "hs", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectGRUCell": [[85, 101], ["torch.cat", "torch.baddbmm", "torch.baddbmm", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "input.expand", "torch.cat.expand", "b_ih.unsqueeze", "b_hh.unsqueeze", "input.unsqueeze", "torch.cat.unsqueeze", "input.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "hs", ",", "mask", ")", "\n", "return", "output", ",", "hidden", "\n", "\n", "\n", "", "", "class", "SkipConnectRNN", "(", "SkipConnectRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectFastGRUCell": [[103, 128], ["torch.cat", "torch.nn.functional.linear", "torch.nn.functional.linear", "F.linear.chunk", "F.linear.chunk", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.linear", "torch.nn.functional.linear", "state", "state"], "function", ["None"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectRecurrent": [[130, 169], ["torch.arange().type_as", "isinstance", "torch.autograd.Variable", "range", "range", "input.data.new().zero_", "input.size", "torch.arange", "cell", "input.size", "h0.size", "mask[].data.min", "mask[].data.max", "cell", "isinstance", "isinstance", "isinstance", "input.data.new", "input.size", "h0.size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectRNN", ",", "self", ")", ".", "__init__", "(", "SkipConnectRNNCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "class", "SkipConnectFastLSTM", "(", "SkipConnectRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.StackedRNN": [[171, 212], ["len", "range", "len", "skipconnect_rnn.StackedRNN.reverse_skip_connection"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectFastLSTM", ",", "self", ")", ".", "__init__", "(", "SkipConnectFastLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n", "\n", "", "", "class", "SkipConnectLSTM", "(", "SkipConnectRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.AutogradSkipConnectRNN": [[214, 241], ["skipconnect_rnn.StackedRNN", "StackedRNN.", "rec_factory", "rec_factory", "rec_factory", "input.transpose.transpose", "skip_connect.transpose.transpose", "output.transpose.transpose", "mask.transpose.transpose"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedRNN"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectStep": [[243, 262], ["cell", "isinstance", "mask.data.min", "mask.data.max", "cell", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.StackedStep": [[264, 289], ["range", "len", "list", "layer", "torch.cat().view.append", "zip", "torch.cat().view", "zip", "torch.cat().view", "torch.cat().view", "torch.cat", "next_hidden[].size", "torch.cat", "next_h[].size", "torch.cat", "next_c[].size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SkipConnectLSTM", ",", "self", ")", ".", "__init__", "(", "SkipConnectLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "lstm", "=", "True", "\n", "\n", "\n", "", "", "class", "SkipConnectFastGRU", "(", "SkipConnectRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.AutogradSkipConnectStep": [[291, 303], ["skipconnect_rnn.SkipConnectStep", "skipconnect_rnn.StackedStep", "StackedStep."], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.skipconnect_rnn.SkipConnectStep", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedStep"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarRNNReLUCell": [[8, 15], ["torch.nn.functional.relu", "torch.nn.functional.linear", "torch.nn.functional.linear"], "function", ["None"], ["from", ".", ".", "_functions", "import", "variational_rnn", "as", "rnn_F", "\n", "\n", "\n", "def", "default_initializer", "(", "hidden_size", ")", ":", "\n", "    ", "stdv", "=", "1.0", "/", "math", ".", "sqrt", "(", "hidden_size", ")", "\n", "def", "forward", "(", "tensor", ")", ":", "\n", "        ", "nn", ".", "init", ".", "uniform", "(", "tensor", ",", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarRNNTanhCell": [[17, 24], ["torch.nn.functional.tanh", "torch.nn.functional.linear", "torch.nn.functional.linear"], "function", ["None"], ["\n", "\n", "", "class", "VarMaskedRNNBase", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "(", "0", ",", "0", ")", ",", "bidirectional", "=", "False", ",", "initializer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "VarMaskedRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarLSTMCell": [[26, 45], ["torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.sigmoid", "input.expand", "hx.expand", "torch.baddbmm", "torch.baddbmm", "torch.nn.functional.tanh", "input.unsqueeze", "hx.unsqueeze", "b_ih.unsqueeze", "b_hh.unsqueeze", "input.size", "hx.size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "lstm", "=", "False", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n", "\n", "cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "p", "=", "dropout", ",", "initializer", "=", "initializer", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n", "self", ".", "add_module", "(", "'cell%d'", "%", "(", "layer", "*", "num_directions", "+", "direction", ")", ",", "cell", ")", "\n", "\n", "", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarFastLSTMCell": [[47, 73], ["gates.chunk", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.sigmoid", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.tanh", "torch.nn.functional.linear", "torch.nn.functional.linear", "state", "state"], "function", ["None"], ["\n", "", "", "def", "reset_noise", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradVarMaskedRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "batch_first", "=", "self", ".", "batch_first", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "self", ".", "lstm", ")", "\n", "\n", "self", ".", "reset_noise", "(", "batch_size", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n", "", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarGRUCell": [[75, 90], ["torch.baddbmm", "torch.baddbmm", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "input.expand", "hidden.expand", "b_ih.unsqueeze", "b_hh.unsqueeze", "input.unsqueeze", "hidden.unsqueeze", "input.size", "hidden.size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "self", ".", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "rnn_F", ".", "AutogradVarMaskedStep", "(", "num_layers", "=", "self", ".", "num_layers", ",", "lstm", "=", "self", ".", "lstm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarFastGRUCell": [[92, 114], ["torch.nn.functional.linear", "torch.nn.functional.linear", "F.linear.chunk", "F.linear.chunk", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "torch.nn.functional.tanh", "torch.nn.functional.linear", "torch.nn.functional.linear", "state", "state"], "function", ["None"], ["return", "output", ",", "hidden", "\n", "\n", "\n", "", "", "class", "VarMaskedRNN", "(", "VarMaskedRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarMaskedRecurrent": [[116, 142], ["torch.cat().view", "range", "range", "torch.cat().view.append", "torch.cat().view.reverse", "input.size", "input.size", "cell", "torch.cat", "output[].size", "input.size", "mask[].data.min", "mask[].data.max", "cell", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.StackedRNN": [[144, 177], ["len", "range", "len", "list", "enumerate", "torch.cat", "zip", "torch.cat().view", "zip", "inner", "torch.cat().view.append", "all_output.append", "torch.cat().view", "torch.cat().view", "torch.cat.dim", "torch.cat", "next_hidden[].size", "torch.cat", "next_h[].size", "torch.cat", "next_c[].size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "\n", "", "", "class", "VarMaskedLSTM", "(", "VarMaskedRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.AutogradVarMaskedRNN": [[179, 205], ["variational_rnn.StackedRNN", "StackedRNN.", "rec_factory", "rec_factory", "rec_factory", "input.transpose.transpose", "output.transpose.transpose", "mask.transpose.transpose"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedRNN"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VarMaskedLSTM", ",", "self", ")", ".", "__init__", "(", "VarLSTMCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarMaskedStep": [[207, 226], ["cell", "isinstance", "mask.data.min", "mask.data.max", "cell", "isinstance"], "function", ["None"], ["\n", "\n", "", "", "class", "VarMaskedFastLSTM", "(", "VarMaskedRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.StackedStep": [[228, 253], ["range", "len", "list", "layer", "torch.cat().view.append", "zip", "torch.cat().view", "zip", "torch.cat().view", "torch.cat().view", "torch.cat", "next_hidden[].size", "torch.cat", "next_h[].size", "torch.cat", "next_c[].size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.AutogradVarMaskedStep": [[255, 267], ["variational_rnn.VarMaskedStep", "variational_rnn.StackedStep", "StackedStep."], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.variational_rnn.VarMaskedStep", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedStep"], ["\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.MaskedRecurrent": [[7, 33], ["torch.cat().view", "range", "range", "torch.cat().view.append", "torch.cat().view.reverse", "input.size", "input.size", "cell", "torch.cat", "output[].size", "input.size", "mask[].data.min", "mask[].data.max", "cell", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", ".", ".", "_functions", ".", "masked_rnn", "import", "AutogradMaskedRNN", ",", "AutogradMaskedStep", "\n", "\n", "\n", "class", "MaskedRNNBase", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "Cell", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "False", ",", "\n", "dropout", "=", "0", ",", "bidirectional", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", "MaskedRNNBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Cell", "=", "Cell", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "\n", "self", ".", "all_cells", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "direction", "in", "range", "(", "num_directions", ")", ":", "\n", "                ", "layer_input_size", "=", "input_size", "if", "layer", "==", "0", "else", "hidden_size", "*", "num_directions", "\n", "\n", "cell", "=", "self", ".", "Cell", "(", "layer_input_size", ",", "hidden_size", ",", "self", ".", "bias", ",", "**", "kwargs", ")", "\n", "self", ".", "all_cells", ".", "append", "(", "cell", ")", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedRNN": [[35, 71], ["len", "range", "len", "list", "enumerate", "torch.cat", "zip", "torch.cat().view", "zip", "inner", "torch.cat().view.append", "all_output.append", "torch.nn.functional.dropout", "torch.cat().view", "torch.cat().view", "F.dropout.dim", "torch.cat", "next_hidden[].size", "torch.cat", "next_h[].size", "torch.cat", "next_c[].size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "cell", "in", "self", ".", "all_cells", ":", "\n", "            ", "cell", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "input", ".", "size", "(", "0", ")", "if", "self", ".", "batch_first", "else", "input", ".", "size", "(", "1", ")", "\n", "lstm", "=", "self", ".", "Cell", "is", "nn", ".", "LSTMCell", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", "*", "num_directions", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "AutogradMaskedRNN", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "batch_first", "=", "self", ".", "batch_first", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "train", "=", "self", ".", "training", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "lstm", "=", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "None", "if", "mask", "is", "None", "else", "mask", ".", "view", "(", "mask", ".", "size", "(", ")", "+", "(", "1", ",", ")", ")", ")", "\n", "return", "output", ",", "hidden", "\n", "\n", "", "def", "step", "(", "self", ",", "input", ",", "hx", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "'''\n        execute one step forward (only for one-directional RNN).\n        Args:\n            input (batch, input_size): input tensor of this step.\n            hx (num_layers, batch, hidden_size): the hidden state of last step.\n            mask (batch): the mask tensor of this step.\n\n        Returns:\n            output (batch, hidden_size): tensor containing the output of this step from the last layer of RNN.\n            hn (num_layers, batch, hidden_size): tensor containing the hidden state of this step\n        '''", "\n", "assert", "not", "self", ".", "bidirectional", ",", "\"step only cannot be applied to bidirectional RNN.\"", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.AutogradMaskedRNN": [[73, 101], ["masked_rnn.StackedRNN", "StackedRNN.", "rec_factory", "rec_factory", "rec_factory", "input.transpose.transpose", "output.transpose.transpose", "mask.transpose.transpose"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedRNN"], ["lstm", "=", "self", ".", "Cell", "is", "nn", ".", "LSTMCell", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ".", "data", ".", "new", "(", "self", ".", "num_layers", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "zero_", "(", ")", ")", "\n", "if", "lstm", ":", "\n", "                ", "hx", "=", "(", "hx", ",", "hx", ")", "\n", "\n", "", "", "func", "=", "AutogradMaskedStep", "(", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "train", "=", "self", ".", "training", ",", "\n", "lstm", "=", "lstm", ")", "\n", "\n", "output", ",", "hidden", "=", "func", "(", "input", ",", "self", ".", "all_cells", ",", "hx", ",", "mask", ")", "\n", "return", "output", ",", "hidden", "\n", "\n", "\n", "", "", "class", "MaskedRNN", "(", "MaskedRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.MaskedStep": [[103, 122], ["cell", "isinstance", "mask.data.min", "mask.data.max", "cell", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedStep": [[124, 152], ["range", "len", "list", "layer", "torch.cat().view.append", "zip", "torch.cat().view", "zip", "torch.nn.functional.dropout", "torch.cat().view", "torch.cat().view", "torch.cat", "next_hidden[].size", "torch.cat", "next_h[].size", "torch.cat", "next_c[].size"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MaskedRNN", ",", "self", ")", ".", "__init__", "(", "nn", ".", "RNNCell", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "class", "MaskedLSTM", "(", "MaskedRNNBase", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.AutogradMaskedStep": [[154, 168], ["masked_rnn.MaskedStep", "masked_rnn.StackedStep", "StackedStep."], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.MaskedStep", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser._functions.masked_rnn.StackedStep"], []], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.is_uni_punctuation": [[6, 9], ["re.match"], "function", ["None"], ["def", "is_uni_punctuation", "(", "word", ")", ":", "\n", "    ", "match", "=", "re", ".", "match", "(", "\"^[^\\w\\s]+$]\"", ",", "word", ",", "flags", "=", "re", ".", "UNICODE", ")", "\n", "return", "match", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.is_punctuation": [[11, 16], ["parser.is_uni_punctuation"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.is_uni_punctuation"], ["", "def", "is_punctuation", "(", "word", ",", "pos", ",", "punct_set", "=", "None", ")", ":", "\n", "    ", "if", "punct_set", "is", "None", ":", "\n", "        ", "return", "is_uni_punctuation", "(", "word", ")", "\n", "", "else", ":", "\n", "        ", "return", "pos", "in", "punct_set", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.eval": [[18, 84], ["range", "range", "word_alphabet.get_instance", "word.encode.encode", "pos_alphabet.get_instance", "pos.encode.encode", "parser.is_punctuation"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.is_punctuation"], ["", "", "def", "eval", "(", "words", ",", "postags", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "word_alphabet", ",", "pos_alphabet", ",", "lengths", ",", "\n", "punct_set", "=", "None", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ")", ":", "\n", "    ", "batch_size", ",", "_", "=", "words", ".", "shape", "\n", "ucorr", "=", "0.", "\n", "lcorr", "=", "0.", "\n", "total", "=", "0.", "\n", "ucomplete_match", "=", "0.", "\n", "lcomplete_match", "=", "0.", "\n", "\n", "ucorr_nopunc", "=", "0.", "\n", "lcorr_nopunc", "=", "0.", "\n", "total_nopunc", "=", "0.", "\n", "ucomplete_match_nopunc", "=", "0.", "\n", "lcomplete_match_nopunc", "=", "0.", "\n", "\n", "corr_root", "=", "0.", "\n", "total_root", "=", "0.", "\n", "start", "=", "1", "if", "symbolic_root", "else", "0", "\n", "end", "=", "1", "if", "symbolic_end", "else", "0", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "ucm", "=", "1.", "\n", "lcm", "=", "1.", "\n", "ucm_nopunc", "=", "1.", "\n", "lcm_nopunc", "=", "1.", "\n", "for", "j", "in", "range", "(", "start", ",", "lengths", "[", "i", "]", "-", "end", ")", ":", "\n", "            ", "word", "=", "word_alphabet", ".", "get_instance", "(", "words", "[", "i", ",", "j", "]", ")", "\n", "word", "=", "word", ".", "encode", "(", "'utf8'", ")", "\n", "\n", "pos", "=", "pos_alphabet", ".", "get_instance", "(", "postags", "[", "i", ",", "j", "]", ")", "\n", "pos", "=", "pos", ".", "encode", "(", "'utf8'", ")", "\n", "\n", "total", "+=", "1", "\n", "if", "heads", "[", "i", ",", "j", "]", "==", "heads_pred", "[", "i", ",", "j", "]", ":", "\n", "                ", "ucorr", "+=", "1", "\n", "if", "types", "[", "i", ",", "j", "]", "==", "types_pred", "[", "i", ",", "j", "]", ":", "\n", "                    ", "lcorr", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "lcm", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "ucm", "=", "0", "\n", "lcm", "=", "0", "\n", "\n", "", "if", "not", "is_punctuation", "(", "word", ",", "pos", ",", "punct_set", ")", ":", "\n", "                ", "total_nopunc", "+=", "1", "\n", "if", "heads", "[", "i", ",", "j", "]", "==", "heads_pred", "[", "i", ",", "j", "]", ":", "\n", "                    ", "ucorr_nopunc", "+=", "1", "\n", "if", "types", "[", "i", ",", "j", "]", "==", "types_pred", "[", "i", ",", "j", "]", ":", "\n", "                        ", "lcorr_nopunc", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "lcm_nopunc", "=", "0", "\n", "", "", "else", ":", "\n", "                    ", "ucm_nopunc", "=", "0", "\n", "lcm_nopunc", "=", "0", "\n", "\n", "", "", "if", "heads", "[", "i", ",", "j", "]", "==", "0", ":", "\n", "                ", "total_root", "+=", "1", "\n", "corr_root", "+=", "1", "if", "heads_pred", "[", "i", ",", "j", "]", "==", "0", "else", "0", "\n", "\n", "", "", "ucomplete_match", "+=", "ucm", "\n", "lcomplete_match", "+=", "lcm", "\n", "ucomplete_match_nopunc", "+=", "ucm_nopunc", "\n", "lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "", "return", "(", "ucorr", ",", "lcorr", ",", "total", ",", "ucomplete_match", ",", "lcomplete_match", ")", ",", "(", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucomplete_match_nopunc", ",", "lcomplete_match_nopunc", ")", ",", "(", "corr_root", ",", "total_root", ")", ",", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.decode_MST": [[86, 309], ["numpy.zeros", "range", "numpy.zeros", "set", "range", "numpy.zeros", "range", "parser.decode_MST.find_cycle"], "function", ["None"], ["", "def", "decode_MST", "(", "energies", ",", "lengths", ",", "leading_symbolic", "=", "0", ",", "labeled", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    decode best parsing tree with MST algorithm.\n    :param energies: energies: numpy 4D tensor\n        energies of each edge. the shape is [batch_size, num_labels, n_steps, n_steps],\n        where the summy root is at index 0.\n    :param masks: numpy 2D tensor\n        masks in the shape [batch_size, n_steps].\n    :param leading_symbolic: int\n        number of symbolic dependency types leading in type alphabets)\n    :return:\n    \"\"\"", "\n", "\n", "def", "find_cycle", "(", "par", ")", ":", "\n", "        ", "added", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "np", ".", "bool", ")", "\n", "added", "[", "0", "]", "=", "True", "\n", "cycle", "=", "set", "(", ")", "\n", "findcycle", "=", "False", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "            ", "if", "findcycle", ":", "\n", "                ", "break", "\n", "\n", "", "if", "added", "[", "i", "]", "or", "not", "curr_nodes", "[", "i", "]", ":", "\n", "                ", "continue", "\n", "\n", "# init cycle", "\n", "", "tmp_cycle", "=", "set", "(", ")", "\n", "tmp_cycle", ".", "add", "(", "i", ")", "\n", "added", "[", "i", "]", "=", "True", "\n", "findcycle", "=", "True", "\n", "l", "=", "i", "\n", "\n", "while", "par", "[", "l", "]", "not", "in", "tmp_cycle", ":", "\n", "                ", "l", "=", "par", "[", "l", "]", "\n", "if", "added", "[", "l", "]", ":", "\n", "                    ", "findcycle", "=", "False", "\n", "break", "\n", "", "added", "[", "l", "]", "=", "True", "\n", "tmp_cycle", ".", "add", "(", "l", ")", "\n", "\n", "", "if", "findcycle", ":", "\n", "                ", "lorg", "=", "l", "\n", "cycle", ".", "add", "(", "lorg", ")", "\n", "l", "=", "par", "[", "lorg", "]", "\n", "while", "l", "!=", "lorg", ":", "\n", "                    ", "cycle", ".", "add", "(", "l", ")", "\n", "l", "=", "par", "[", "l", "]", "\n", "", "break", "\n", "\n", "", "", "return", "findcycle", ",", "cycle", "\n", "\n", "", "def", "chuLiuEdmonds", "(", ")", ":", "\n", "        ", "par", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# create best graph", "\n", "par", "[", "0", "]", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "# only interested at current nodes", "\n", "            ", "if", "curr_nodes", "[", "i", "]", ":", "\n", "                ", "max_score", "=", "score_matrix", "[", "0", ",", "i", "]", "\n", "par", "[", "i", "]", "=", "0", "\n", "for", "j", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                    ", "if", "j", "==", "i", "or", "not", "curr_nodes", "[", "j", "]", ":", "\n", "                        ", "continue", "\n", "\n", "", "new_score", "=", "score_matrix", "[", "j", ",", "i", "]", "\n", "if", "new_score", ">", "max_score", ":", "\n", "                        ", "max_score", "=", "new_score", "\n", "par", "[", "i", "]", "=", "j", "\n", "\n", "# find a cycle", "\n", "", "", "", "", "findcycle", ",", "cycle", "=", "find_cycle", "(", "par", ")", "\n", "# no cycles, get all edges and return them.", "\n", "if", "not", "findcycle", ":", "\n", "            ", "final_edges", "[", "0", "]", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                ", "if", "not", "curr_nodes", "[", "i", "]", ":", "\n", "                    ", "continue", "\n", "\n", "", "pr", "=", "oldI", "[", "par", "[", "i", "]", ",", "i", "]", "\n", "ch", "=", "oldO", "[", "par", "[", "i", "]", ",", "i", "]", "\n", "final_edges", "[", "ch", "]", "=", "pr", "\n", "", "return", "\n", "\n", "", "cyc_len", "=", "len", "(", "cycle", ")", "\n", "cyc_weight", "=", "0.0", "\n", "cyc_nodes", "=", "np", ".", "zeros", "(", "[", "cyc_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "id", "=", "0", "\n", "for", "cyc_node", "in", "cycle", ":", "\n", "            ", "cyc_nodes", "[", "id", "]", "=", "cyc_node", "\n", "id", "+=", "1", "\n", "cyc_weight", "+=", "score_matrix", "[", "par", "[", "cyc_node", "]", ",", "cyc_node", "]", "\n", "\n", "", "rep", "=", "cyc_nodes", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "            ", "if", "not", "curr_nodes", "[", "i", "]", "or", "i", "in", "cycle", ":", "\n", "                ", "continue", "\n", "\n", "", "max1", "=", "float", "(", "\"-inf\"", ")", "\n", "wh1", "=", "-", "1", "\n", "max2", "=", "float", "(", "\"-inf\"", ")", "\n", "wh2", "=", "-", "1", "\n", "\n", "for", "j", "in", "range", "(", "cyc_len", ")", ":", "\n", "                ", "j1", "=", "cyc_nodes", "[", "j", "]", "\n", "if", "score_matrix", "[", "j1", ",", "i", "]", ">", "max1", ":", "\n", "                    ", "max1", "=", "score_matrix", "[", "j1", ",", "i", "]", "\n", "wh1", "=", "j1", "\n", "\n", "", "scr", "=", "cyc_weight", "+", "score_matrix", "[", "i", ",", "j1", "]", "-", "score_matrix", "[", "par", "[", "j1", "]", ",", "j1", "]", "\n", "\n", "if", "scr", ">", "max2", ":", "\n", "                    ", "max2", "=", "scr", "\n", "wh2", "=", "j1", "\n", "\n", "", "", "score_matrix", "[", "rep", ",", "i", "]", "=", "max1", "\n", "oldI", "[", "rep", ",", "i", "]", "=", "oldI", "[", "wh1", ",", "i", "]", "\n", "oldO", "[", "rep", ",", "i", "]", "=", "oldO", "[", "wh1", ",", "i", "]", "\n", "score_matrix", "[", "i", ",", "rep", "]", "=", "max2", "\n", "oldO", "[", "i", ",", "rep", "]", "=", "oldO", "[", "i", ",", "wh2", "]", "\n", "oldI", "[", "i", ",", "rep", "]", "=", "oldI", "[", "i", ",", "wh2", "]", "\n", "\n", "", "rep_cons", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cyc_len", ")", ":", "\n", "            ", "rep_cons", ".", "append", "(", "set", "(", ")", ")", "\n", "cyc_node", "=", "cyc_nodes", "[", "i", "]", "\n", "for", "cc", "in", "reps", "[", "cyc_node", "]", ":", "\n", "                ", "rep_cons", "[", "i", "]", ".", "add", "(", "cc", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "cyc_len", ")", ":", "\n", "            ", "cyc_node", "=", "cyc_nodes", "[", "i", "]", "\n", "curr_nodes", "[", "cyc_node", "]", "=", "False", "\n", "for", "cc", "in", "reps", "[", "cyc_node", "]", ":", "\n", "                ", "reps", "[", "rep", "]", ".", "add", "(", "cc", ")", "\n", "\n", "", "", "chuLiuEdmonds", "(", ")", "\n", "\n", "# check each node in cycle, if one of its representatives is a key in the final_edges, it is the one.", "\n", "found", "=", "False", "\n", "wh", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "cyc_len", ")", ":", "\n", "            ", "for", "repc", "in", "rep_cons", "[", "i", "]", ":", "\n", "                ", "if", "repc", "in", "final_edges", ":", "\n", "                    ", "wh", "=", "cyc_nodes", "[", "i", "]", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "found", ":", "\n", "                ", "break", "\n", "\n", "", "", "l", "=", "par", "[", "wh", "]", "\n", "while", "l", "!=", "wh", ":", "\n", "            ", "ch", "=", "oldO", "[", "par", "[", "l", "]", ",", "l", "]", "\n", "pr", "=", "oldI", "[", "par", "[", "l", "]", ",", "l", "]", "\n", "final_edges", "[", "ch", "]", "=", "pr", "\n", "l", "=", "par", "[", "l", "]", "\n", "\n", "", "", "if", "labeled", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "4", ",", "'dimension of energies is not equal to 4'", "\n", "", "else", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "3", ",", "'dimension of energies is not equal to 3'", "\n", "", "input_shape", "=", "energies", ".", "shape", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "\n", "max_length", "=", "input_shape", "[", "2", "]", "\n", "\n", "pars", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "max_length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "types", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "max_length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "if", "labeled", "else", "None", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "energy", "=", "energies", "[", "i", "]", "\n", "\n", "# calc the realy length of this instance", "\n", "length", "=", "lengths", "[", "i", "]", "\n", "\n", "# calc real energy matrix shape = [length, length, num_labels - #symbolic] (remove the label for symbolic types).", "\n", "if", "labeled", ":", "\n", "            ", "energy", "=", "energy", "[", "leading_symbolic", ":", ",", ":", "length", ",", ":", "length", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energy", ".", "argmax", "(", "axis", "=", "0", ")", "+", "leading_symbolic", "\n", "energy", "=", "energy", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "energy", "=", "energy", "[", ":", "length", ",", ":", "length", "]", "\n", "label_id_matrix", "=", "None", "\n", "# get original score matrix", "\n", "", "orig_score_matrix", "=", "energy", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "np", ".", "array", "(", "orig_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "oldI", "=", "np", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "oldO", "=", "np", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "curr_nodes", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "reps", "=", "[", "]", "\n", "\n", "for", "s", "in", "range", "(", "length", ")", ":", "\n", "            ", "orig_score_matrix", "[", "s", ",", "s", "]", "=", "0.0", "\n", "score_matrix", "[", "s", ",", "s", "]", "=", "0.0", "\n", "curr_nodes", "[", "s", "]", "=", "True", "\n", "reps", ".", "append", "(", "set", "(", ")", ")", "\n", "reps", "[", "s", "]", ".", "add", "(", "s", ")", "\n", "for", "t", "in", "range", "(", "s", "+", "1", ",", "length", ")", ":", "\n", "                ", "oldI", "[", "s", ",", "t", "]", "=", "s", "\n", "oldO", "[", "s", ",", "t", "]", "=", "t", "\n", "\n", "oldI", "[", "t", ",", "s", "]", "=", "t", "\n", "oldO", "[", "t", ",", "s", "]", "=", "s", "\n", "\n", "", "", "final_edges", "=", "dict", "(", ")", "\n", "chuLiuEdmonds", "(", ")", "\n", "par", "=", "np", ".", "zeros", "(", "[", "max_length", "]", ",", "np", ".", "int32", ")", "\n", "if", "labeled", ":", "\n", "            ", "type", "=", "np", ".", "ones", "(", "[", "max_length", "]", ",", "np", ".", "int32", ")", "\n", "type", "[", "0", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "type", "=", "None", "\n", "\n", "", "for", "ch", ",", "pr", "in", "final_edges", ".", "items", "(", ")", ":", "\n", "            ", "par", "[", "ch", "]", "=", "pr", "\n", "if", "labeled", "and", "ch", "!=", "0", ":", "\n", "                ", "type", "[", "ch", "]", "=", "label_id_matrix", "[", "pr", ",", "ch", "]", "\n", "\n", "", "", "par", "[", "0", "]", "=", "0", "\n", "pars", "[", "i", "]", "=", "par", "\n", "if", "labeled", ":", "\n", "            ", "types", "[", "i", "]", "=", "type", "\n", "\n", "", "", "return", "pars", ",", "types", "\n", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.__init__": [[12, 47], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "RNN", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "torch.NLLLoss", "torch.NLLLoss", "torch.NLLLoss", "sequence_labeling.BiRecurrentConv.reset_parameters", "torch.Linear", "torch.Linear", "torch.Linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "0", ",", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.5", ",", "p_rnn", "=", "(", "0.5", ",", "0.5", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiRecurrentConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embedd", "=", "Embedding", "(", "num_words", ",", "word_dim", ",", "init_embedding", "=", "embedd_word", ")", "\n", "self", ".", "char_embedd", "=", "Embedding", "(", "num_chars", ",", "char_dim", ",", "init_embedding", "=", "embedd_char", ")", "\n", "self", ".", "conv1d", "=", "nn", ".", "Conv1d", "(", "char_dim", ",", "num_filters", ",", "kernel_size", ",", "padding", "=", "kernel_size", "-", "1", ")", "\n", "# dropout word", "\n", "self", ".", "dropout_in", "=", "nn", ".", "Dropout2d", "(", "p", "=", "p_in", ")", "\n", "# standard dropout", "\n", "self", ".", "dropout_rnn_in", "=", "nn", ".", "Dropout", "(", "p", "=", "p_rnn", "[", "0", "]", ")", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout", "(", "p_out", ")", "\n", "\n", "if", "rnn_mode", "==", "'RNN'", ":", "\n", "            ", "RNN", "=", "nn", ".", "RNN", "\n", "", "elif", "rnn_mode", "==", "'LSTM'", ":", "\n", "            ", "RNN", "=", "nn", ".", "LSTM", "\n", "", "elif", "rnn_mode", "==", "'GRU'", ":", "\n", "            ", "RNN", "=", "nn", ".", "GRU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown RNN mode: %s'", "%", "rnn_mode", ")", "\n", "\n", "", "self", ".", "rnn", "=", "RNN", "(", "word_dim", "+", "num_filters", ",", "hidden_size", ",", "num_layers", "=", "num_layers", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "dropout", "=", "p_rnn", "[", "1", "]", ")", "\n", "\n", "self", ".", "dense", "=", "None", "\n", "out_dim", "=", "hidden_size", "*", "2", "\n", "if", "tag_space", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "out_dim", ",", "tag_space", ")", "\n", "out_dim", "=", "tag_space", "\n", "", "self", ".", "dense_softmax", "=", "nn", ".", "Linear", "(", "out_dim", ",", "num_labels", ")", "\n", "self", ".", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "nll_loss", "=", "nn", ".", "NLLLoss", "(", "size_average", "=", "False", ",", "reduce", "=", "False", ")", "\n", "\n", "self", ".", "initializer", "=", "initializer", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.reset_parameters": [[48, 58], ["sequence_labeling.BiRecurrentConv.named_parameters", "name.find", "parameter.dim", "parameter.data.zero_", "sequence_labeling.BiRecurrentConv.initializer"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "initializer", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "for", "name", ",", "parameter", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", ".", "find", "(", "'embedd'", ")", "==", "-", "1", ":", "\n", "                ", "if", "parameter", ".", "dim", "(", ")", "==", "1", ":", "\n", "                    ", "parameter", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "initializer", "(", "parameter", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv._get_rnn_output": [[59, 106], ["sequence_labeling.BiRecurrentConv.word_embedd", "sequence_labeling.BiRecurrentConv.char_embedd", "sequence_labeling.BiRecurrentConv.size", "sequence_labeling.BiRecurrentConv.view().transpose", "sequence_labeling.BiRecurrentConv.conv1d().max", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "sequence_labeling.BiRecurrentConv.dropout_in", "sequence_labeling.BiRecurrentConv.dropout_in", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sequence_labeling.BiRecurrentConv.dropout_rnn_in", "sequence_labeling.BiRecurrentConv.dropout_out", "mask.data.sum().long", "torch.utils.prepare_rnn_seq", "sequence_labeling.BiRecurrentConv.rnn", "torch.utils.recover_rnn_seq", "sequence_labeling.BiRecurrentConv.rnn", "sequence_labeling.BiRecurrentConv.dropout_out", "sequence_labeling.BiRecurrentConv.view", "sequence_labeling.BiRecurrentConv.conv1d", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.elu", "torch.elu", "torch.elu", "mask.data.sum", "sequence_labeling.BiRecurrentConv.dense"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.utils.prepare_rnn_seq", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.nn.utils.recover_rnn_seq"], ["", "", "", "", "def", "_get_rnn_output", "(", "self", ",", "input_word", ",", "input_char", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# hack length from mask", "\n", "# we do not hack mask from length for special reasons.", "\n", "# Thus, always provide mask if it is necessary.", "\n", "        ", "if", "length", "is", "None", "and", "mask", "is", "not", "None", ":", "\n", "            ", "length", "=", "mask", ".", "data", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "\n", "# [batch, length, word_dim]", "\n", "", "word", "=", "self", ".", "word_embedd", "(", "input_word", ")", "\n", "\n", "# [batch, length, char_length, char_dim]", "\n", "char", "=", "self", ".", "char_embedd", "(", "input_char", ")", "\n", "char_size", "=", "char", ".", "size", "(", ")", "\n", "# first transform to [batch *length, char_length, char_dim]", "\n", "# then transpose to [batch * length, char_dim, char_length]", "\n", "char", "=", "char", ".", "view", "(", "char_size", "[", "0", "]", "*", "char_size", "[", "1", "]", ",", "char_size", "[", "2", "]", ",", "char_size", "[", "3", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# put into cnn [batch*length, char_filters, char_length]", "\n", "# then put into maxpooling [batch * length, char_filters]", "\n", "char", ",", "_", "=", "self", ".", "conv1d", "(", "char", ")", ".", "max", "(", "dim", "=", "2", ")", "\n", "# reshape to [batch, length, char_filters]", "\n", "char", "=", "torch", ".", "tanh", "(", "char", ")", ".", "view", "(", "char_size", "[", "0", "]", ",", "char_size", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "# apply dropout word on input", "\n", "word", "=", "self", ".", "dropout_in", "(", "word", ")", "\n", "char", "=", "self", ".", "dropout_in", "(", "char", ")", "\n", "\n", "# concatenate word and char [batch, length, word_dim+char_filter]", "\n", "input", "=", "torch", ".", "cat", "(", "[", "word", ",", "char", "]", ",", "dim", "=", "2", ")", "\n", "# apply dropout rnn input", "\n", "input", "=", "self", ".", "dropout_rnn_in", "(", "input", ")", "\n", "# prepare packed_sequence", "\n", "if", "length", "is", "not", "None", ":", "\n", "            ", "seq_input", ",", "hx", ",", "rev_order", ",", "mask", "=", "utils", ".", "prepare_rnn_seq", "(", "input", ",", "length", ",", "hx", "=", "hx", ",", "masks", "=", "mask", ",", "batch_first", "=", "True", ")", "\n", "seq_output", ",", "hn", "=", "self", ".", "rnn", "(", "seq_input", ",", "hx", "=", "hx", ")", "\n", "output", ",", "hn", "=", "utils", ".", "recover_rnn_seq", "(", "seq_output", ",", "rev_order", ",", "hx", "=", "hn", ",", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "            ", "output", ",", "hn", "=", "self", ".", "rnn", "(", "input", ",", "hx", "=", "hx", ")", "\n", "\n", "# apply dropout for the output of rnn", "\n", "", "output", "=", "self", ".", "dropout_out", "(", "output", ")", "\n", "\n", "if", "self", ".", "dense", "is", "not", "None", ":", "\n", "# [batch, length, tag_space]", "\n", "            ", "output", "=", "self", ".", "dropout_out", "(", "F", ".", "elu", "(", "self", ".", "dense", "(", "output", ")", ")", ")", "\n", "\n", "", "return", "output", ",", "hn", ",", "mask", ",", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.forward": [[107, 111], ["sequence_labeling.BiRecurrentConv._get_rnn_output"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output"], ["", "def", "forward", "(", "self", ",", "input_word", ",", "input_char", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "return", "output", ",", "mask", ",", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConv.loss": [[112, 137], ["sequence_labeling.BiRecurrentConv.forward", "sequence_labeling.BiRecurrentConv.dense_softmax", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "output.view.view.size", "output.view.view.view", "length.max", "target[].contiguous", "target[].contiguous.size", "mask.size", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "torch.eq().type_as().sum", "mask.sum", "sequence_labeling.BiRecurrentConv.nll_loss().sum", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "torch.eq().type_as", "sequence_labeling.BiRecurrentConv.nll_loss", "sequence_labeling.BiRecurrentConv.nll_loss", "mask.contiguous().view", "sequence_labeling.BiRecurrentConv.logsoftmax", "target[].contiguous.view", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "sequence_labeling.BiRecurrentConv.logsoftmax", "target[].contiguous.view", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "mask.contiguous"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "loss", "(", "self", ",", "input_word", ",", "input_char", ",", "target", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# [batch, length, tag_space]", "\n", "        ", "output", ",", "mask", ",", "length", "=", "self", ".", "forward", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "# [batch, length, num_labels]", "\n", "output", "=", "self", ".", "dense_softmax", "(", "output", ")", "\n", "# preds = [batch, length]", "\n", "_", ",", "preds", "=", "torch", ".", "max", "(", "output", "[", ":", ",", ":", ",", "leading_symbolic", ":", "]", ",", "dim", "=", "2", ")", "\n", "preds", "+=", "leading_symbolic", "\n", "\n", "output_size", "=", "output", ".", "size", "(", ")", "\n", "# [batch * length, num_labels]", "\n", "output_size", "=", "(", "output_size", "[", "0", "]", "*", "output_size", "[", "1", "]", ",", "output_size", "[", "2", "]", ")", "\n", "output", "=", "output", ".", "view", "(", "output_size", ")", "\n", "\n", "if", "length", "is", "not", "None", "and", "target", ".", "size", "(", "1", ")", "!=", "mask", ".", "size", "(", "1", ")", ":", "\n", "            ", "max_len", "=", "length", ".", "max", "(", ")", "\n", "target", "=", "target", "[", ":", ",", ":", "max_len", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "return", "(", "self", ".", "nll_loss", "(", "self", ".", "logsoftmax", "(", "output", ")", ",", "target", ".", "view", "(", "-", "1", ")", ")", "*", "mask", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", ",", "(", "torch", ".", "eq", "(", "preds", ",", "target", ")", ".", "type_as", "(", "mask", ")", "*", "mask", ")", ".", "sum", "(", ")", ",", "preds", "\n", "", "else", ":", "\n", "            ", "num", "=", "output_size", "[", "0", "]", "*", "output_size", "[", "1", "]", "\n", "return", "self", ".", "nll_loss", "(", "self", ".", "logsoftmax", "(", "output", ")", ",", "target", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "/", "num", ",", "(", "torch", ".", "eq", "(", "preds", ",", "target", ")", ".", "type_as", "(", "output", ")", ")", ".", "sum", "(", ")", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConv.__init__": [[140, 159], ["sequence_labeling.BiRecurrentConv.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "RNN", "ValueError"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "0", ",", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.33", ",", "p_rnn", "=", "(", "0.33", ",", "0.33", ")", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiVarRecurrentConv", ",", "self", ")", ".", "__init__", "(", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "tag_space", ",", "embedd_word", "=", "embedd_word", ",", "embedd_char", "=", "embedd_char", ",", "\n", "p_in", "=", "p_in", ",", "p_out", "=", "p_out", ",", "p_rnn", "=", "p_rnn", ",", "initializer", "=", "initializer", ")", "\n", "\n", "self", ".", "dropout_rnn_in", "=", "None", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout2d", "(", "p_out", ")", "\n", "\n", "if", "rnn_mode", "==", "'RNN'", ":", "\n", "            ", "RNN", "=", "VarMaskedRNN", "\n", "", "elif", "rnn_mode", "==", "'LSTM'", ":", "\n", "            ", "RNN", "=", "VarMaskedLSTM", "\n", "", "elif", "rnn_mode", "==", "'GRU'", ":", "\n", "            ", "RNN", "=", "VarMaskedGRU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown RNN mode: %s'", "%", "rnn_mode", ")", "\n", "\n", "", "self", ".", "rnn", "=", "RNN", "(", "word_dim", "+", "num_filters", ",", "hidden_size", ",", "num_layers", "=", "num_layers", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "dropout", "=", "p_rnn", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConv._get_rnn_output": [[160, 194], ["sequence_labeling.BiVarRecurrentConv.word_embedd", "sequence_labeling.BiVarRecurrentConv.char_embedd", "sequence_labeling.BiVarRecurrentConv.size", "sequence_labeling.BiVarRecurrentConv.view().transpose", "sequence_labeling.BiVarRecurrentConv.conv1d().max", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "sequence_labeling.BiVarRecurrentConv.dropout_in", "sequence_labeling.BiVarRecurrentConv.dropout_in", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sequence_labeling.BiVarRecurrentConv.rnn", "sequence_labeling.BiVarRecurrentConv.dropout_out().transpose", "sequence_labeling.BiVarRecurrentConv.dropout_out().transpose", "sequence_labeling.BiVarRecurrentConv.view", "sequence_labeling.BiVarRecurrentConv.conv1d", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "sequence_labeling.BiVarRecurrentConv.dropout_out", "sequence_labeling.BiVarRecurrentConv.transpose", "sequence_labeling.BiVarRecurrentConv.dropout_out", "torch.elu().transpose", "torch.elu().transpose", "torch.elu().transpose", "torch.elu", "torch.elu", "torch.elu", "sequence_labeling.BiVarRecurrentConv.dense"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_get_rnn_output", "(", "self", ",", "input_word", ",", "input_char", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# [batch, length, word_dim]", "\n", "        ", "word", "=", "self", ".", "word_embedd", "(", "input_word", ")", "\n", "\n", "# [batch, length, char_length, char_dim]", "\n", "char", "=", "self", ".", "char_embedd", "(", "input_char", ")", "\n", "char_size", "=", "char", ".", "size", "(", ")", "\n", "# first transform to [batch *length, char_length, char_dim]", "\n", "# then transpose to [batch * length, char_dim, char_length]", "\n", "char", "=", "char", ".", "view", "(", "char_size", "[", "0", "]", "*", "char_size", "[", "1", "]", ",", "char_size", "[", "2", "]", ",", "char_size", "[", "3", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# put into cnn [batch*length, char_filters, char_length]", "\n", "# then put into maxpooling [batch * length, char_filters]", "\n", "char", ",", "_", "=", "self", ".", "conv1d", "(", "char", ")", ".", "max", "(", "dim", "=", "2", ")", "\n", "# reshape to [batch, length, char_filters]", "\n", "char", "=", "torch", ".", "tanh", "(", "char", ")", ".", "view", "(", "char_size", "[", "0", "]", ",", "char_size", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "# apply dropout word on input", "\n", "word", "=", "self", ".", "dropout_in", "(", "word", ")", "\n", "char", "=", "self", ".", "dropout_in", "(", "char", ")", "\n", "\n", "# concatenate word and char [batch, length, word_dim+char_filter]", "\n", "input", "=", "torch", ".", "cat", "(", "[", "word", ",", "char", "]", ",", "dim", "=", "2", ")", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "output", ",", "hn", "=", "self", ".", "rnn", "(", "input", ",", "mask", ",", "hx", "=", "hx", ")", "\n", "\n", "# apply dropout for the output of rnn", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "output", "=", "self", ".", "dropout_out", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "self", ".", "dense", "is", "not", "None", ":", "\n", "# [batch, length, tag_space] --> [batch, tag_space, length] --> [batch, length, tag_space]", "\n", "            ", "output", "=", "self", ".", "dropout_out", "(", "F", ".", "elu", "(", "self", ".", "dense", "(", "output", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "return", "output", ",", "hn", ",", "mask", ",", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConvCRF.__init__": [[197, 208], ["sequence_labeling.BiRecurrentConv.__init__", "torch.ChainCRF"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "0", ",", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.5", ",", "p_rnn", "=", "(", "0.5", ",", "0.5", ")", ",", "bigram", "=", "False", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiRecurrentConvCRF", ",", "self", ")", ".", "__init__", "(", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "tag_space", ",", "embedd_word", "=", "embedd_word", ",", "embedd_char", "=", "embedd_char", ",", "\n", "p_in", "=", "p_in", ",", "p_out", "=", "p_out", ",", "p_rnn", "=", "p_rnn", ",", "initializer", "=", "initializer", ")", "\n", "\n", "out_dim", "=", "tag_space", "if", "tag_space", "else", "hidden_size", "*", "2", "\n", "self", ".", "crf", "=", "ChainCRF", "(", "out_dim", ",", "num_labels", ",", "bigram", "=", "bigram", ")", "\n", "self", ".", "dense_softmax", "=", "None", "\n", "self", ".", "logsoftmax", "=", "None", "\n", "self", ".", "nll_loss", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConvCRF.forward": [[209, 214], ["sequence_labeling.BiRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiRecurrentConvCRF.crf"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output"], ["", "def", "forward", "(", "self", ",", "input_word", ",", "input_char", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "# [batch, length, num_label,  num_label]", "\n", "return", "self", ".", "crf", "(", "output", ",", "mask", "=", "mask", ")", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConvCRF.loss": [[215, 225], ["sequence_labeling.BiRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiRecurrentConvCRF.crf.loss().mean", "length.max", "sequence_labeling.BiRecurrentConvCRF.crf.loss"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.loss"], ["", "def", "loss", "(", "self", ",", "input_word", ",", "input_char", ",", "target", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "\n", "if", "length", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "length", ".", "max", "(", ")", "\n", "target", "=", "target", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "# [batch, length, num_label,  num_label]", "\n", "", "return", "self", ".", "crf", ".", "loss", "(", "output", ",", "target", ",", "mask", "=", "mask", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiRecurrentConvCRF.decode": [[226, 242], ["sequence_labeling.BiRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiRecurrentConvCRF.crf.decode", "length.max", "sequence_labeling.BiRecurrentConvCRF.crf.decode", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode"], ["", "def", "decode", "(", "self", ",", "input_word", ",", "input_char", ",", "target", "=", "None", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "\n", "if", "target", "is", "None", ":", "\n", "            ", "return", "self", ".", "crf", ".", "decode", "(", "output", ",", "mask", "=", "mask", ",", "leading_symbolic", "=", "leading_symbolic", ")", ",", "None", "\n", "\n", "", "if", "length", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "length", ".", "max", "(", ")", "\n", "target", "=", "target", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "", "preds", "=", "self", ".", "crf", ".", "decode", "(", "output", ",", "mask", "=", "mask", ",", "leading_symbolic", "=", "leading_symbolic", ")", "\n", "if", "mask", "is", "None", ":", "\n", "            ", "return", "preds", ",", "torch", ".", "eq", "(", "preds", ",", "target", ".", "data", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "preds", ",", "(", "torch", ".", "eq", "(", "preds", ",", "target", ".", "data", ")", ".", "float", "(", ")", "*", "mask", ".", "data", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConvCRF.__init__": [[245, 256], ["sequence_labeling.BiVarRecurrentConv.__init__", "torch.ChainCRF"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "0", ",", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.33", ",", "p_rnn", "=", "(", "0.33", ",", "0.33", ")", ",", "bigram", "=", "False", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiVarRecurrentConvCRF", ",", "self", ")", ".", "__init__", "(", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "\n", "tag_space", "=", "tag_space", ",", "embedd_word", "=", "embedd_word", ",", "embedd_char", "=", "embedd_char", ",", "\n", "p_in", "=", "p_in", ",", "p_out", "=", "p_out", ",", "p_rnn", "=", "p_rnn", ",", "initializer", "=", "initializer", ")", "\n", "\n", "out_dim", "=", "tag_space", "if", "tag_space", "else", "hidden_size", "*", "2", "\n", "self", ".", "crf", "=", "ChainCRF", "(", "out_dim", ",", "num_labels", ",", "bigram", "=", "bigram", ")", "\n", "self", ".", "dense_softmax", "=", "None", "\n", "self", ".", "logsoftmax", "=", "None", "\n", "self", ".", "nll_loss", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConvCRF.forward": [[257, 262], ["sequence_labeling.BiVarRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiVarRecurrentConvCRF.crf"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output"], ["", "def", "forward", "(", "self", ",", "input_word", ",", "input_char", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "# [batch, length, num_label,  num_label]", "\n", "return", "self", ".", "crf", "(", "output", ",", "mask", "=", "mask", ")", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConvCRF.loss": [[263, 273], ["sequence_labeling.BiVarRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiVarRecurrentConvCRF.crf.loss().mean", "length.max", "sequence_labeling.BiVarRecurrentConvCRF.crf.loss"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.loss"], ["", "def", "loss", "(", "self", ",", "input_word", ",", "input_char", ",", "target", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "\n", "if", "length", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "length", ".", "max", "(", ")", "\n", "target", "=", "target", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "# [batch, length, num_label,  num_label]", "\n", "", "return", "self", ".", "crf", ".", "loss", "(", "output", ",", "target", ",", "mask", "=", "mask", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.sequence_labeling.BiVarRecurrentConvCRF.decode": [[274, 290], ["sequence_labeling.BiVarRecurrentConvCRF._get_rnn_output", "sequence_labeling.BiVarRecurrentConvCRF.crf.decode", "length.max", "sequence_labeling.BiVarRecurrentConvCRF.crf.decode", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float().sum", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode"], ["", "def", "decode", "(", "self", ",", "input_word", ",", "input_char", ",", "target", "=", "None", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "output", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "\n", "if", "target", "is", "None", ":", "\n", "            ", "return", "self", ".", "crf", ".", "decode", "(", "output", ",", "mask", "=", "mask", ",", "leading_symbolic", "=", "leading_symbolic", ")", ",", "None", "\n", "\n", "", "if", "length", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "length", ".", "max", "(", ")", "\n", "target", "=", "target", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "", "preds", "=", "self", ".", "crf", ".", "decode", "(", "output", ",", "mask", "=", "mask", ",", "leading_symbolic", "=", "leading_symbolic", ")", "\n", "if", "mask", "is", "None", ":", "\n", "            ", "return", "preds", ",", "torch", ".", "eq", "(", "preds", ",", "target", ".", "data", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "preds", ",", "(", "torch", ".", "eq", "(", "preds", ",", "target", ".", "data", ")", ".", "float", "(", ")", "*", "mask", ".", "data", ")", ".", "sum", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine.__init__": [[26, 121], ["torch.Module.__init__", "torch.Embedding", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BiAAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BiLinear", "torch.Embedding", "torch.Embedding", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "RNN", "transformer.TransformerEncoder", "NotImplementedError", "torch.Embedding", "torch.Embedding", "torch.Embedding", "ValueError", "numpy.array", "numpy.sin", "numpy.cos", "parsing.BiRecurrentConvBiAffine.position_embedding.weight.data.copy_", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "numpy.zeros", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.power", "range"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "kernel_size", ",", "rnn_mode", ",", "\n", "hidden_size", ",", "num_layers", ",", "num_labels", ",", "arc_space", ",", "type_space", ",", "\n", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "embedd_pos", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.33", ",", "p_rnn", "=", "(", "0.33", ",", "0.33", ")", ",", "\n", "biaffine", "=", "True", ",", "pos", "=", "True", ",", "char", "=", "True", ",", "\n", "train_position", "=", "False", ",", "use_con_rnn", "=", "True", ",", "trans_hid_size", "=", "1028", ",", "d_k", "=", "64", ",", "d_v", "=", "64", ",", "multi_head_attn", "=", "True", ",", "\n", "num_head", "=", "8", ",", "enc_use_neg_dist", "=", "False", ",", "enc_clip_dist", "=", "0", ",", "position_dim", "=", "50", ",", "max_sent_length", "=", "200", ",", "\n", "use_gpu", "=", "False", ",", "no_word", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "BiRecurrentConvBiAffine", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embedd", "=", "Embedding", "(", "num_words", ",", "word_dim", ",", "init_embedding", "=", "embedd_word", ")", "\n", "self", ".", "pos_embedd", "=", "Embedding", "(", "num_pos", ",", "pos_dim", ",", "init_embedding", "=", "embedd_pos", ")", "if", "pos", "else", "None", "\n", "self", ".", "char_embedd", "=", "Embedding", "(", "num_chars", ",", "char_dim", ",", "init_embedding", "=", "embedd_char", ")", "if", "char", "else", "None", "\n", "self", ".", "conv1d", "=", "nn", ".", "Conv1d", "(", "char_dim", ",", "num_filters", ",", "kernel_size", ",", "padding", "=", "kernel_size", "-", "1", ")", "if", "char", "else", "None", "\n", "self", ".", "dropout_in", "=", "nn", ".", "Dropout2d", "(", "p", "=", "p_in", ")", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout2d", "(", "p", "=", "p_out", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "pos", "=", "pos", "\n", "self", ".", "char", "=", "char", "\n", "self", ".", "no_word", "=", "no_word", "\n", "#", "\n", "self", ".", "use_con_rnn", "=", "use_con_rnn", "\n", "self", ".", "multi_head_attn", "=", "multi_head_attn", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "position_dim", "=", "position_dim", "\n", "\n", "if", "rnn_mode", "==", "'RNN'", ":", "\n", "            ", "RNN", "=", "VarMaskedRNN", "\n", "", "elif", "rnn_mode", "==", "'LSTM'", ":", "\n", "            ", "RNN", "=", "VarMaskedLSTM", "\n", "", "elif", "rnn_mode", "==", "'FastLSTM'", ":", "\n", "            ", "RNN", "=", "VarMaskedFastLSTM", "\n", "", "elif", "rnn_mode", "==", "'GRU'", ":", "\n", "            ", "RNN", "=", "VarMaskedGRU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown RNN mode: %s'", "%", "rnn_mode", ")", "\n", "\n", "", "dim_enc", "=", "0", "\n", "if", "not", "no_word", ":", "\n", "            ", "dim_enc", "=", "word_dim", "\n", "", "if", "pos", ":", "\n", "            ", "dim_enc", "+=", "pos_dim", "\n", "", "if", "char", ":", "\n", "            ", "dim_enc", "+=", "num_filters", "\n", "\n", "#", "\n", "", "self", ".", "encoder_layers", "=", "num_layers", "\n", "if", "self", ".", "use_con_rnn", ":", "\n", "            ", "self", ".", "rnn", "=", "RNN", "(", "dim_enc", ",", "hidden_size", ",", "num_layers", "=", "self", ".", "encoder_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "dropout", "=", "p_rnn", ")", "\n", "enc_output_dim", "=", "2", "*", "hidden_size", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "multi_head_attn", ":", "\n", "                ", "pos_emb_size", "=", "position_dim", "\n", "d_model", "=", "pos_emb_size", "+", "dim_enc", "\n", "if", "position_dim", ">", "0", ":", "\n", "                    ", "self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "max_sent_length", ",", "pos_emb_size", ")", "\n", "if", "not", "train_position", ":", "\n", "                        ", "self", ".", "position_embedding", ".", "weight", ".", "requires_grad", "=", "False", "# turn off pos embedding training", "\n", "######################### init positional embedding ##########################", "\n", "# keep dim 0 for padding token position encoding zero vector", "\n", "position_enc", "=", "np", ".", "array", "(", "[", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "pos_emb_size", ")", "for", "j", "in", "\n", "range", "(", "pos_emb_size", ")", "]", "if", "pos", "!=", "0", "else", "np", ".", "zeros", "(", "pos_emb_size", ")", "for", "pos", "in", "\n", "range", "(", "max_sent_length", ")", "]", ")", "\n", "position_enc", "[", "1", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "position_enc", "[", "1", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "position_enc", "[", "1", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "position_enc", "[", "1", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "self", ".", "position_embedding", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "position_enc", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "##############################################################################", "\n", "#", "\n", "", "", "self", ".", "transformer", "=", "TransformerEncoder", "(", "self", ".", "encoder_layers", ",", "\n", "d_model", "=", "d_model", ",", "\n", "heads", "=", "num_head", ",", "\n", "d_ff", "=", "trans_hid_size", ",", "\n", "d_k", "=", "d_k", ",", "\n", "d_v", "=", "d_v", ",", "\n", "attn_drop", "=", "p_rnn", "[", "0", "]", ",", "\n", "relu_drop", "=", "p_rnn", "[", "1", "]", ",", "\n", "res_drop", "=", "p_rnn", "[", "2", "]", ",", "\n", "clip_dist", "=", "enc_clip_dist", ",", "\n", "use_neg_dist", "=", "enc_use_neg_dist", ")", "\n", "\n", "enc_output_dim", "=", "d_model", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# self.rnn = RNN(dim_enc, hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=p_rnn)", "\n", "\n", "", "", "out_dim", "=", "enc_output_dim", "\n", "self", ".", "arc_h", "=", "nn", ".", "Linear", "(", "out_dim", ",", "arc_space", ")", "\n", "self", ".", "arc_c", "=", "nn", ".", "Linear", "(", "out_dim", ",", "arc_space", ")", "\n", "self", ".", "attention", "=", "BiAAttention", "(", "arc_space", ",", "arc_space", ",", "1", ",", "biaffine", "=", "biaffine", ")", "\n", "\n", "self", ".", "type_h", "=", "nn", ".", "Linear", "(", "out_dim", ",", "type_space", ")", "\n", "self", ".", "type_c", "=", "nn", ".", "Linear", "(", "out_dim", ",", "type_space", ")", "\n", "self", ".", "bilinear", "=", "BiLinear", "(", "type_space", ",", "type_space", ",", "self", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output": [[122, 206], ["parsing.BiRecurrentConvBiAffine.dropout_out().transpose", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "parsing.BiRecurrentConvBiAffine.dropout_out().transpose", "parsing.BiRecurrentConvBiAffine.chunk", "parsing.BiRecurrentConvBiAffine.dropout_out().transpose", "parsing.BiRecurrentConvBiAffine.chunk", "type_h.contiguous.contiguous.contiguous", "type_c.contiguous.contiguous.contiguous", "parsing.BiRecurrentConvBiAffine.word_embedd", "parsing.BiRecurrentConvBiAffine.dropout_in", "parsing.BiRecurrentConvBiAffine.char_embedd", "parsing.BiRecurrentConvBiAffine.size", "parsing.BiRecurrentConvBiAffine.view().transpose", "parsing.BiRecurrentConvBiAffine.conv1d().max", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "parsing.BiRecurrentConvBiAffine.dropout_in", "parsing.BiRecurrentConvBiAffine.pos_embedd", "parsing.BiRecurrentConvBiAffine.rnn", "parsing.BiRecurrentConvBiAffine.arc_h", "parsing.BiRecurrentConvBiAffine.arc_c", "parsing.BiRecurrentConvBiAffine.type_h", "parsing.BiRecurrentConvBiAffine.type_c", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "parsing.BiRecurrentConvBiAffine.transformer", "NotImplementedError", "parsing.BiRecurrentConvBiAffine.dropout_out", "parsing.BiRecurrentConvBiAffine.dropout_out", "parsing.BiRecurrentConvBiAffine.dropout_out", "parsing.BiRecurrentConvBiAffine.view", "parsing.BiRecurrentConvBiAffine.conv1d", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "position_encoding.cuda.cuda.expand", "parsing.BiRecurrentConvBiAffine.position_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "parsing.BiRecurrentConvBiAffine.transpose", "parsing.BiRecurrentConvBiAffine.transpose", "parsing.BiRecurrentConvBiAffine.transpose", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "position_encoding.cuda.cuda.cuda", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_get_rnn_output", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "input", "=", "None", "\n", "\n", "if", "not", "self", ".", "no_word", ":", "\n", "# [batch, length, word_dim]", "\n", "            ", "word", "=", "self", ".", "word_embedd", "(", "input_word", ")", "\n", "# apply dropout on input", "\n", "word", "=", "self", ".", "dropout_in", "(", "word", ")", "\n", "\n", "input", "=", "word", "\n", "\n", "", "if", "self", ".", "char", ":", "\n", "# [batch, length, char_length, char_dim]", "\n", "            ", "char", "=", "self", ".", "char_embedd", "(", "input_char", ")", "\n", "char_size", "=", "char", ".", "size", "(", ")", "\n", "# first transform to [batch *length, char_length, char_dim]", "\n", "# then transpose to [batch * length, char_dim, char_length]", "\n", "char", "=", "char", ".", "view", "(", "char_size", "[", "0", "]", "*", "char_size", "[", "1", "]", ",", "char_size", "[", "2", "]", ",", "char_size", "[", "3", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# put into cnn [batch*length, char_filters, char_length]", "\n", "# then put into maxpooling [batch * length, char_filters]", "\n", "char", ",", "_", "=", "self", ".", "conv1d", "(", "char", ")", ".", "max", "(", "dim", "=", "2", ")", "\n", "# reshape to [batch, length, char_filters]", "\n", "char", "=", "torch", ".", "tanh", "(", "char", ")", ".", "view", "(", "char_size", "[", "0", "]", ",", "char_size", "[", "1", "]", ",", "-", "1", ")", "\n", "# apply dropout on input", "\n", "char", "=", "self", ".", "dropout_in", "(", "char", ")", "\n", "# concatenate word and char [batch, length, word_dim+char_filter]", "\n", "input", "=", "char", "if", "input", "is", "None", "else", "torch", ".", "cat", "(", "[", "input", ",", "char", "]", ",", "dim", "=", "2", ")", "\n", "\n", "", "if", "self", ".", "pos", ":", "\n", "# [batch, length, pos_dim]", "\n", "            ", "pos", "=", "self", ".", "pos_embedd", "(", "input_pos", ")", "\n", "# # apply dropout on input", "\n", "# pos = self.dropout_in(pos)", "\n", "input", "=", "pos", "if", "input", "is", "None", "else", "torch", ".", "cat", "(", "[", "input", ",", "pos", "]", ",", "dim", "=", "2", ")", "\n", "\n", "# # output from rnn [batch, length, hidden_size]", "\n", "# output, hn = self.rnn(input, mask, hx=hx)", "\n", "\n", "", "if", "self", ".", "use_con_rnn", ":", "\n", "            ", "output", ",", "hn", "=", "self", ".", "rnn", "(", "input", ",", "mask", ",", "hx", "=", "hx", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "multi_head_attn", ":", "\n", "                ", "src_encoding", "=", "input", "\n", "if", "self", ".", "position_dim", ">", "0", ":", "\n", "                    ", "position_encoding", "=", "Variable", "(", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "src_encoding", ".", "size", "(", "1", ")", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "# ----- modified by zs", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                        ", "position_encoding", "=", "position_encoding", ".", "cuda", "(", ")", "\n", "# -----", "\n", "", "position_encoding", "=", "position_encoding", ".", "expand", "(", "*", "src_encoding", ".", "size", "(", ")", "[", ":", "-", "1", "]", ")", "\n", "position_encoding", "=", "self", ".", "position_embedding", "(", "position_encoding", ")", "\n", "# src_encoding = src_encoding + position_encoding", "\n", "src_encoding", "=", "torch", ".", "cat", "(", "[", "src_encoding", ",", "position_encoding", "]", ",", "dim", "=", "2", ")", "\n", "", "src_encoding", "=", "self", ".", "transformer", "(", "src_encoding", ")", "\n", "output", ",", "hn", "=", "src_encoding", ",", "None", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# apply dropout for output", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "", "", "output", "=", "self", ".", "dropout_out", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# output size [batch, length, arc_space]", "\n", "arc_h", "=", "F", ".", "elu", "(", "self", ".", "arc_h", "(", "output", ")", ")", "\n", "arc_c", "=", "F", ".", "elu", "(", "self", ".", "arc_c", "(", "output", ")", ")", "\n", "\n", "# output size [batch, length, type_space]", "\n", "type_h", "=", "F", ".", "elu", "(", "self", ".", "type_h", "(", "output", ")", ")", "\n", "type_c", "=", "F", ".", "elu", "(", "self", ".", "type_c", "(", "output", ")", ")", "\n", "\n", "# apply dropout", "\n", "# [batch, length, dim] --> [batch, 2 * length, dim]", "\n", "arc", "=", "torch", ".", "cat", "(", "[", "arc_h", ",", "arc_c", "]", ",", "dim", "=", "1", ")", "\n", "type", "=", "torch", ".", "cat", "(", "[", "type_h", ",", "type_c", "]", ",", "dim", "=", "1", ")", "\n", "\n", "arc", "=", "self", ".", "dropout_out", "(", "arc", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "arc_h", ",", "arc_c", "=", "arc", ".", "chunk", "(", "2", ",", "1", ")", "\n", "\n", "type", "=", "self", ".", "dropout_out", "(", "type", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "type_h", ",", "type_c", "=", "type", ".", "chunk", "(", "2", ",", "1", ")", "\n", "type_h", "=", "type_h", ".", "contiguous", "(", ")", "\n", "type_c", "=", "type_c", ".", "contiguous", "(", ")", "\n", "\n", "return", "(", "arc_h", ",", "arc_c", ")", ",", "(", "type_h", ",", "type_c", ")", ",", "hn", ",", "mask", ",", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine.forward": [[207, 214], ["parsing.BiRecurrentConvBiAffine._get_rnn_output", "parsing.BiRecurrentConvBiAffine.attention().squeeze", "parsing.BiRecurrentConvBiAffine.attention"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._get_rnn_output"], ["", "def", "forward", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# output from rnn [batch, length, tag_space]", "\n", "        ", "arc", ",", "type", ",", "_", ",", "mask", ",", "length", "=", "self", ".", "_get_rnn_output", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "\n", "hx", "=", "hx", ")", "\n", "# [batch, length, length]", "\n", "out_arc", "=", "self", ".", "attention", "(", "arc", "[", "0", "]", ",", "arc", "[", "1", "]", ",", "mask_d", "=", "mask", ",", "mask_e", "=", "mask", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "return", "out_arc", ",", "type", ",", "mask", ",", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine.loss": [[215, 264], ["parsing.BiRecurrentConvBiAffine.forward", "out_arc.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "type_h[].transpose().contiguous", "parsing.BiRecurrentConvBiAffine.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "child_index.type_as().long.type_as().long.type_as().long", "heads.size", "mask.size", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "type_h[].transpose", "minus_mask.unsqueeze", "mask.unsqueeze", "mask.unsqueeze", "mask.sum", "float", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "child_index.type_as().long.type_as().long.type_as", "minus_mask.unsqueeze", "mask.unsqueeze", "torch.log_softmax.sum", "torch.log_softmax.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "heads.data.t", "types.data.t", "heads.data.t"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "loss", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "heads", ",", "types", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# out_arc shape [batch, length, length]", "\n", "        ", "out_arc", ",", "out_type", ",", "mask", ",", "length", "=", "self", ".", "forward", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "\n", "hx", "=", "hx", ")", "\n", "batch", ",", "max_len", ",", "_", "=", "out_arc", ".", "size", "(", ")", "\n", "\n", "if", "length", "is", "not", "None", "and", "heads", ".", "size", "(", "1", ")", "!=", "mask", ".", "size", "(", "1", ")", ":", "\n", "            ", "heads", "=", "heads", "[", ":", ",", ":", "max_len", "]", "\n", "types", "=", "types", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "# out_type shape [batch, length, type_space]", "\n", "", "type_h", ",", "type_c", "=", "out_type", "\n", "\n", "# create batch index [batch]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "out_arc", ".", "data", ")", ".", "long", "(", ")", "\n", "# get vector for heads [batch, length, type_space],", "\n", "type_h", "=", "type_h", "[", "batch_index", ",", "heads", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# compute output for type [batch, length, num_labels]", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", ",", "type_c", ")", "\n", "\n", "# mask invalid position to -inf for log_softmax", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "minus_inf", "=", "-", "1e8", "\n", "minus_mask", "=", "(", "1", "-", "mask", ")", "*", "minus_inf", "\n", "out_arc", "=", "out_arc", "+", "minus_mask", ".", "unsqueeze", "(", "2", ")", "+", "minus_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# loss_arc shape [batch, length, length]", "\n", "", "loss_arc", "=", "F", ".", "log_softmax", "(", "out_arc", ",", "dim", "=", "1", ")", "\n", "# loss_type shape [batch, length, num_labels]", "\n", "loss_type", "=", "F", ".", "log_softmax", "(", "out_type", ",", "dim", "=", "2", ")", "\n", "\n", "# mask invalid position to 0 for sum loss", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "loss_arc", "=", "loss_arc", "*", "mask", ".", "unsqueeze", "(", "2", ")", "*", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "loss_type", "=", "loss_type", "*", "mask", ".", "unsqueeze", "(", "2", ")", "\n", "# number of valid positions which contribute to loss (remove the symbolic head for each sentence.", "\n", "num", "=", "mask", ".", "sum", "(", ")", "-", "batch", "\n", "", "else", ":", "\n", "# number of valid positions which contribute to loss (remove the symbolic head for each sentence.", "\n", "            ", "num", "=", "float", "(", "max_len", "-", "1", ")", "*", "batch", "\n", "\n", "# first create index matrix [length, batch]", "\n", "", "child_index", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "view", "(", "max_len", ",", "1", ")", ".", "expand", "(", "max_len", ",", "batch", ")", "\n", "child_index", "=", "child_index", ".", "type_as", "(", "out_arc", ".", "data", ")", ".", "long", "(", ")", "\n", "# [length-1, batch]", "\n", "loss_arc", "=", "loss_arc", "[", "batch_index", ",", "heads", ".", "data", ".", "t", "(", ")", ",", "child_index", "]", "[", "1", ":", "]", "\n", "loss_type", "=", "loss_type", "[", "batch_index", ",", "child_index", ",", "types", ".", "data", ".", "t", "(", ")", "]", "[", "1", ":", "]", "\n", "\n", "return", "-", "loss_arc", ".", "sum", "(", ")", "/", "num", ",", "-", "loss_type", ".", "sum", "(", ")", "/", "num", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._decode_types": [[265, 280], ["type_h[].transpose().contiguous.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "type_h[].transpose().contiguous", "parsing.BiRecurrentConvBiAffine.bilinear", "parsing.BiRecurrentConvBiAffine.max", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "type_h[].transpose", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "heads.t"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_decode_types", "(", "self", ",", "out_type", ",", "heads", ",", "leading_symbolic", ")", ":", "\n", "# out_type shape [batch, length, type_space]", "\n", "        ", "type_h", ",", "type_c", "=", "out_type", "\n", "batch", ",", "max_len", ",", "_", "=", "type_h", ".", "size", "(", ")", "\n", "# create batch index [batch]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "type_h", ".", "data", ")", ".", "long", "(", ")", "\n", "# get vector for heads [batch, length, type_space],", "\n", "type_h", "=", "type_h", "[", "batch_index", ",", "heads", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# compute output for type [batch, length, num_labels]", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", ",", "type_c", ")", "\n", "# remove the first #leading_symbolic types.", "\n", "out_type", "=", "out_type", "[", ":", ",", ":", ",", "leading_symbolic", ":", "]", "\n", "# compute the prediction of types [batch, length]", "\n", "_", ",", "types", "=", "out_type", ".", "max", "(", "dim", "=", "2", ")", "\n", "return", "types", "+", "leading_symbolic", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine.decode": [[281, 302], ["parsing.BiRecurrentConvBiAffine.forward", "out_arc.size", "out_arc.max", "parsing.BiRecurrentConvBiAffine._decode_types", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "out_arc.masked_fill_", "heads.cpu().numpy", "parsing.BiRecurrentConvBiAffine.data.cpu().numpy", "out_arc.new().fill_", "heads.cpu", "parsing.BiRecurrentConvBiAffine.data.cpu", "out_arc.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine._decode_types"], ["", "def", "decode", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "# out_arc shape [batch, length, length]", "\n", "        ", "out_arc", ",", "out_type", ",", "mask", ",", "length", "=", "self", ".", "forward", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "\n", "hx", "=", "hx", ")", "\n", "out_arc", "=", "out_arc", ".", "data", "\n", "batch", ",", "max_len", ",", "_", "=", "out_arc", ".", "size", "(", ")", "\n", "# set diagonal elements to -inf", "\n", "out_arc", "=", "out_arc", "+", "torch", ".", "diag", "(", "out_arc", ".", "new", "(", "max_len", ")", ".", "fill_", "(", "-", "np", ".", "inf", ")", ")", "\n", "# set invalid positions to -inf", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# minus_mask = (1 - mask.data).byte().view(batch, max_len, 1)", "\n", "            ", "minus_mask", "=", "(", "1", "-", "mask", ".", "data", ")", ".", "byte", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "out_arc", ".", "masked_fill_", "(", "minus_mask", ",", "-", "np", ".", "inf", ")", "\n", "\n", "# compute naive predictions.", "\n", "# predition shape = [batch, length]", "\n", "", "_", ",", "heads", "=", "out_arc", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "types", "=", "self", ".", "_decode_types", "(", "out_type", ",", "heads", ",", "leading_symbolic", ")", "\n", "\n", "return", "heads", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "types", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.BiRecurrentConvBiAffine.decode_mst": [[303, 359], ["parsing.BiRecurrentConvBiAffine.forward", "type_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.size", "type_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "type_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "parsing.BiRecurrentConvBiAffine.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax().permute", "torch.log_softmax().permute", "torch.log_softmax().permute", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "neuronlp2.tasks.parser.decode_MST", "torch.exp.data.cpu().numpy", "torch.exp.data.cpu().numpy", "torch.exp.data.cpu().numpy", "mask.data.sum().long().cpu().numpy", "type_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "type_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "minus_mask.unsqueeze", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.unsqueeze", "minus_mask.unsqueeze", "torch.exp.data.cpu", "torch.exp.data.cpu", "torch.exp.data.cpu", "range", "mask.data.sum().long().cpu", "type_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "type_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "mask.data.sum().long", "mask.data.sum"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.tasks.parser.decode_MST"], ["", "def", "decode_mst", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "leading_symbolic", "=", "0", ")", ":", "\n", "        ", "'''\n        Args:\n            input_word: Tensor\n                the word input tensor with shape = [batch, length]\n            input_char: Tensor\n                the character input tensor with shape = [batch, length, char_length]\n            input_pos: Tensor\n                the pos input tensor with shape = [batch, length]\n            mask: Tensor or None\n                the mask tensor with shape = [batch, length]\n            length: Tensor or None\n                the length tensor with shape = [batch]\n            hx: Tensor or None\n                the initial states of RNN\n            leading_symbolic: int\n                number of symbolic labels leading in type alphabets (set it to 0 if you are not sure)\n\n        Returns: (Tensor, Tensor)\n                predicted heads and types.\n\n        '''", "\n", "# out_arc shape [batch, length, length]", "\n", "out_arc", ",", "out_type", ",", "mask", ",", "length", "=", "self", ".", "forward", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "mask", ",", "length", "=", "length", ",", "\n", "hx", "=", "hx", ")", "\n", "\n", "# out_type shape [batch, length, type_space]", "\n", "type_h", ",", "type_c", "=", "out_type", "\n", "batch", ",", "max_len", ",", "type_space", "=", "type_h", ".", "size", "(", ")", "\n", "\n", "# compute lengths", "\n", "if", "length", "is", "None", ":", "\n", "            ", "if", "mask", "is", "None", ":", "\n", "                ", "length", "=", "[", "max_len", "for", "_", "in", "range", "(", "batch", ")", "]", "\n", "", "else", ":", "\n", "                ", "length", "=", "mask", ".", "data", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "type_h", "=", "type_h", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "batch", ",", "max_len", ",", "max_len", ",", "type_space", ")", ".", "contiguous", "(", ")", "\n", "type_c", "=", "type_c", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch", ",", "max_len", ",", "max_len", ",", "type_space", ")", ".", "contiguous", "(", ")", "\n", "# compute output for type [batch, length, length, num_labels]", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", ",", "type_c", ")", "\n", "\n", "# mask invalid position to -inf for log_softmax", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "minus_inf", "=", "-", "1e8", "\n", "minus_mask", "=", "(", "1", "-", "mask", ")", "*", "minus_inf", "\n", "out_arc", "=", "out_arc", "+", "minus_mask", ".", "unsqueeze", "(", "2", ")", "+", "minus_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# loss_arc shape [batch, length, length]", "\n", "", "loss_arc", "=", "F", ".", "log_softmax", "(", "out_arc", ",", "dim", "=", "1", ")", "\n", "# loss_type shape [batch, length, length, num_labels]", "\n", "loss_type", "=", "F", ".", "log_softmax", "(", "out_type", ",", "dim", "=", "3", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "# [batch, num_labels, length, length]", "\n", "energy", "=", "torch", ".", "exp", "(", "loss_arc", ".", "unsqueeze", "(", "1", ")", "+", "loss_type", ")", "\n", "\n", "return", "parser", ".", "decode_MST", "(", "energy", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "length", ",", "leading_symbolic", "=", "leading_symbolic", ",", "labeled", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.__init__": [[362, 513], ["torch.Module.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.Linear", "RNN_DECODER", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.modules.attention_aug.AugFeatureHelper", "torch.modules.attention_aug.AugBiAAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BiLinear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "RNN_ENCODER", "transformer.TransformerEncoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "parsing.StackPtrNet.attention_helper.get_num_features", "ValueError", "torch.Embedding", "torch.Embedding", "torch.Embedding", "ValueError", "numpy.array", "numpy.sin", "numpy.cos", "parsing.StackPtrNet.position_embedding.weight.data.copy_", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "torch.from_numpy().type", "numpy.zeros", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.power", "range"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.get_num_features"], ["    ", "def", "__init__", "(", "self", ",", "word_dim", ",", "num_words", ",", "char_dim", ",", "num_chars", ",", "pos_dim", ",", "num_pos", ",", "num_filters", ",", "kernel_size", ",", "\n", "rnn_mode", ",", "input_size_decoder", ",", "hidden_size", ",", "encoder_layers", ",", "decoder_layers", ",", "num_labels", ",", "arc_space", ",", "\n", "type_space", ",", "pool_type", ",", "multi_head_attn", ",", "num_head", ",", "max_sent_length", ",", "trans_hid_size", ",", "d_k", ",", "d_v", ",", "\n", "train_position", "=", "False", ",", "embedd_word", "=", "None", ",", "embedd_char", "=", "None", ",", "embedd_pos", "=", "None", ",", "p_in", "=", "0.33", ",", "p_out", "=", "0.33", ",", "\n", "p_rnn", "=", "(", "0.33", ",", "0.33", ")", ",", "biaffine", "=", "True", ",", "use_word_emb", "=", "True", ",", "pos", "=", "True", ",", "char", "=", "True", ",", "prior_order", "=", "'inside_out'", ",", "\n", "skipConnect", "=", "False", ",", "use_con_rnn", "=", "True", ",", "grandPar", "=", "False", ",", "sibling", "=", "False", ",", "use_gpu", "=", "False", ",", "\n", "dec_max_dist", "=", "0", ",", "dec_use_neg_dist", "=", "False", ",", "dec_use_encoder_pos", "=", "False", ",", "dec_use_decoder_pos", "=", "False", ",", "\n", "dec_dim_feature", "=", "10", ",", "dec_drop_f_embed", "=", "0.", ",", "\n", "enc_clip_dist", "=", "0", ",", "enc_use_neg_dist", "=", "False", ",", "\n", "input_concat_embeds", "=", "False", ",", "input_concat_position", "=", "False", ",", "position_dim", "=", "50", ")", ":", "\n", "\n", "        ", "super", "(", "StackPtrNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embedd", "=", "Embedding", "(", "num_words", ",", "word_dim", ",", "init_embedding", "=", "embedd_word", ")", "if", "use_word_emb", "else", "None", "\n", "self", ".", "pos_embedd", "=", "Embedding", "(", "num_pos", ",", "pos_dim", ",", "init_embedding", "=", "embedd_pos", ")", "if", "pos", "else", "None", "\n", "self", ".", "char_embedd", "=", "Embedding", "(", "num_chars", ",", "char_dim", ",", "init_embedding", "=", "embedd_char", ")", "if", "char", "else", "None", "\n", "self", ".", "conv1d", "=", "nn", ".", "Conv1d", "(", "char_dim", ",", "num_filters", ",", "kernel_size", ",", "padding", "=", "kernel_size", "-", "1", ")", "if", "char", "else", "None", "\n", "self", ".", "dropout_in", "=", "nn", ".", "Dropout2d", "(", "p", "=", "p_in", ")", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout2d", "(", "p", "=", "p_out", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "if", "prior_order", "in", "[", "'deep_first'", ",", "'shallow_first'", "]", ":", "\n", "            ", "self", ".", "prior_order", "=", "PriorOrder", ".", "DEPTH", "\n", "", "elif", "prior_order", "==", "'inside_out'", ":", "\n", "            ", "self", ".", "prior_order", "=", "PriorOrder", ".", "INSIDE_OUT", "\n", "", "elif", "prior_order", "==", "'left2right'", ":", "\n", "            ", "self", ".", "prior_order", "=", "PriorOrder", ".", "LEFT2RIGTH", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown prior order: %s'", "%", "prior_order", ")", "\n", "", "self", ".", "pos", "=", "pos", "\n", "self", ".", "char", "=", "char", "\n", "self", ".", "use_word_emb", "=", "use_word_emb", "\n", "self", ".", "use_con_rnn", "=", "use_con_rnn", "\n", "self", ".", "multi_head_attn", "=", "multi_head_attn", "\n", "self", ".", "pool_type", "=", "pool_type", "\n", "self", ".", "skipConnect", "=", "skipConnect", "\n", "self", ".", "grandPar", "=", "grandPar", "\n", "self", ".", "sibling", "=", "sibling", "\n", "#", "\n", "self", ".", "input_concat_embeds", "=", "input_concat_embeds", "\n", "self", ".", "input_concat_position", "=", "input_concat_position", "\n", "self", ".", "position_dim", "=", "position_dim", "\n", "\n", "if", "rnn_mode", "==", "'RNN'", ":", "\n", "            ", "RNN_ENCODER", "=", "VarMaskedRNN", "\n", "RNN_DECODER", "=", "SkipConnectRNN", "if", "skipConnect", "else", "VarMaskedRNN", "\n", "", "elif", "rnn_mode", "==", "'LSTM'", ":", "\n", "            ", "RNN_ENCODER", "=", "VarMaskedLSTM", "\n", "RNN_DECODER", "=", "SkipConnectLSTM", "if", "skipConnect", "else", "VarMaskedLSTM", "\n", "", "elif", "rnn_mode", "==", "'FastLSTM'", ":", "\n", "            ", "RNN_ENCODER", "=", "VarMaskedFastLSTM", "\n", "RNN_DECODER", "=", "SkipConnectFastLSTM", "if", "skipConnect", "else", "VarMaskedFastLSTM", "\n", "", "elif", "rnn_mode", "==", "'GRU'", ":", "\n", "            ", "RNN_ENCODER", "=", "VarMaskedGRU", "\n", "RNN_DECODER", "=", "SkipConnectGRU", "if", "skipConnect", "else", "VarMaskedGRU", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown RNN mode: %s'", "%", "rnn_mode", ")", "\n", "\n", "# embed", "\n", "", "dim_enc", "=", "0", "\n", "if", "use_word_emb", ":", "\n", "            ", "dim_enc", "=", "word_dim", "\n", "", "if", "pos", ":", "\n", "            ", "dim_enc", "=", "dim_enc", "+", "pos_dim", "if", "input_concat_embeds", "else", "pos_dim", "\n", "", "if", "char", ":", "\n", "            ", "dim_enc", "=", "dim_enc", "+", "num_filters", "if", "input_concat_embeds", "else", "num_filters", "\n", "\n", "# enc", "\n", "", "self", ".", "encoder_layers", "=", "encoder_layers", "\n", "if", "self", ".", "use_con_rnn", ":", "\n", "            ", "self", ".", "encoder", "=", "RNN_ENCODER", "(", "dim_enc", ",", "hidden_size", ",", "num_layers", "=", "encoder_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ",", "dropout", "=", "p_rnn", ")", "\n", "enc_output_dim", "=", "2", "*", "hidden_size", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "multi_head_attn", ":", "\n", "# pos_emb_size = 0", "\n", "# if self.use_word_emb:", "\n", "#     # pos_emb_size += word_dim", "\n", "#     pos_emb_size = word_dim", "\n", "# if self.char:", "\n", "#     # pos_emb_size += char_dim", "\n", "#     pos_emb_size = char_dim", "\n", "# if self.pos:", "\n", "#     # pos_emb_size += pos_dim", "\n", "#     pos_emb_size = pos_dim", "\n", "\n", "                ", "pos_emb_size", "=", "position_dim", "\n", "if", "input_concat_position", ":", "\n", "                    ", "d_model", "=", "pos_emb_size", "+", "dim_enc", "\n", "", "else", ":", "\n", "                    ", "d_model", "=", "dim_enc", "\n", "\n", "", "if", "position_dim", ">", "0", ":", "\n", "                    ", "self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "max_sent_length", ",", "pos_emb_size", ")", "\n", "if", "not", "train_position", ":", "\n", "                        ", "self", ".", "position_embedding", ".", "weight", ".", "requires_grad", "=", "False", "# turn off pos embedding training", "\n", "######################### init positional embedding ##########################", "\n", "# keep dim 0 for padding token position encoding zero vector", "\n", "position_enc", "=", "np", ".", "array", "(", "[", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "pos_emb_size", ")", "for", "j", "in", "\n", "range", "(", "pos_emb_size", ")", "]", "if", "pos", "!=", "0", "else", "np", ".", "zeros", "(", "pos_emb_size", ")", "for", "pos", "in", "\n", "range", "(", "max_sent_length", ")", "]", ")", "\n", "position_enc", "[", "1", ":", ",", "0", ":", ":", "2", "]", "=", "np", ".", "sin", "(", "position_enc", "[", "1", ":", ",", "0", ":", ":", "2", "]", ")", "# dim 2i", "\n", "position_enc", "[", "1", ":", ",", "1", ":", ":", "2", "]", "=", "np", ".", "cos", "(", "position_enc", "[", "1", ":", ",", "1", ":", ":", "2", "]", ")", "# dim 2i+1", "\n", "self", ".", "position_embedding", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "position_enc", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "##############################################################################", "\n", "\n", "", "", "self", ".", "transformer", "=", "TransformerEncoder", "(", "self", ".", "encoder_layers", ",", "\n", "d_model", "=", "d_model", ",", "\n", "heads", "=", "num_head", ",", "\n", "d_ff", "=", "trans_hid_size", ",", "\n", "d_k", "=", "d_k", ",", "\n", "d_v", "=", "d_v", ",", "\n", "attn_drop", "=", "p_rnn", "[", "0", "]", ",", "\n", "relu_drop", "=", "p_rnn", "[", "1", "]", ",", "\n", "res_drop", "=", "p_rnn", "[", "2", "]", ",", "\n", "clip_dist", "=", "enc_clip_dist", ",", "\n", "use_neg_dist", "=", "enc_use_neg_dist", ")", "\n", "\n", "enc_output_dim", "=", "d_model", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "dim_enc", ",", "dim_enc", ")", "\n", "enc_output_dim", "=", "dim_enc", "\n", "\n", "", "if", "self", ".", "pool_type", "==", "'weight'", ":", "\n", "                ", "self", ".", "self_attn", "=", "nn", ".", "Linear", "(", "enc_output_dim", ",", "1", ")", "\n", "\n", "# dec", "\n", "", "", "dim_dec", "=", "input_size_decoder", "\n", "self", ".", "src_dense", "=", "nn", ".", "Linear", "(", "enc_output_dim", ",", "dim_dec", ")", "\n", "\n", "self", ".", "decoder_layers", "=", "decoder_layers", "\n", "drop_rnn", "=", "p_rnn", "[", ":", "2", "]", "if", "self", ".", "multi_head_attn", "else", "p_rnn", "\n", "self", ".", "decoder", "=", "RNN_DECODER", "(", "dim_dec", ",", "hidden_size", ",", "num_layers", "=", "decoder_layers", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "False", ",", "dropout", "=", "drop_rnn", ")", "\n", "\n", "self", ".", "hx_dense", "=", "nn", ".", "Linear", "(", "enc_output_dim", ",", "hidden_size", ")", "\n", "self", ".", "arc_h", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "arc_space", ")", "# arc dense for decoder", "\n", "self", ".", "arc_c", "=", "nn", ".", "Linear", "(", "enc_output_dim", ",", "arc_space", ")", "# arc dense for encoder", "\n", "\n", "# AugAttentioner (with dist/pos features included)", "\n", "# self.attention = BiAAttention(arc_space, arc_space, 1, biaffine=biaffine)", "\n", "self", ".", "attention_helper", "=", "AugFeatureHelper", "(", "dec_max_dist", ",", "dec_use_neg_dist", ",", "num_pos", ",", "dec_use_encoder_pos", ",", "\n", "dec_use_decoder_pos", ")", "\n", "self", ".", "attention", "=", "AugBiAAttention", "(", "arc_space", ",", "arc_space", ",", "1", ",", "num_features", "=", "self", ".", "attention_helper", ".", "get_num_features", "(", ")", ",", "\n", "dim_feature", "=", "dec_dim_feature", ",", "drop_f_embed", "=", "dec_drop_f_embed", ",", "biaffine", "=", "biaffine", ")", "\n", "\n", "self", ".", "type_h", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "type_space", ")", "# type dense for decoder", "\n", "self", ".", "type_c", "=", "nn", ".", "Linear", "(", "enc_output_dim", ",", "type_space", ")", "# type dense for encoder", "\n", "self", ".", "bilinear", "=", "BiLinear", "(", "type_space", ",", "type_space", ",", "self", ".", "num_labels", ")", "\n", "\n", "# ----- modified by zs (used for position inputs)", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_encoder_output": [[514, 609], ["parsing.StackPtrNet.dropout_out().transpose", "parsing.StackPtrNet.word_embedd", "parsing.StackPtrNet.dropout_in", "parsing.StackPtrNet.char_embedd", "parsing.StackPtrNet.size", "parsing.StackPtrNet.view().transpose", "parsing.StackPtrNet.conv1d().max", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "torch.tanh().view", "parsing.StackPtrNet.dropout_in", "parsing.StackPtrNet.pos_embedd", "parsing.StackPtrNet.encoder", "parsing.StackPtrNet.dropout_in", "parsing.StackPtrNet.transformer", "parsing.StackPtrNet.linear1", "hw.view.view.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "torch.sum().div().unsqueeze", "parsing.StackPtrNet.dropout_out", "parsing.StackPtrNet.view", "parsing.StackPtrNet.conv1d", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "position_encoding.cuda.cuda.expand", "parsing.StackPtrNet.position_embedding", "torch.bmm.view", "torch.bmm.view", "torch.bmm.view", "hw.view.view.transpose", "[].unsqueeze", "parsing.StackPtrNet.transpose", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "position_encoding.cuda.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.sum().div", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "parsing.StackPtrNet.self_attn().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "attn_rep.unsqueeze.unsqueeze.unsqueeze", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.softmax.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "parsing.StackPtrNet.self_attn", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.bmm.view", "torch.bmm.view", "torch.bmm.view", "torch.bmm.transpose", "torch.bmm.transpose", "torch.bmm.transpose", "torch.softmax.unsqueeze", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size", "torch.bmm.size"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_get_encoder_output", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask_e", "=", "None", ",", "length_e", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "src_encoding", "=", "None", "\n", "if", "self", ".", "use_word_emb", ":", "\n", "# [batch, length, word_dim]", "\n", "            ", "word", "=", "self", ".", "word_embedd", "(", "input_word", ")", "\n", "# apply dropout on input", "\n", "word", "=", "self", ".", "dropout_in", "(", "word", ")", "\n", "src_encoding", "=", "word", "\n", "\n", "", "if", "self", ".", "char", ":", "\n", "# [batch, length, char_length, char_dim]", "\n", "            ", "char", "=", "self", ".", "char_embedd", "(", "input_char", ")", "\n", "char_size", "=", "char", ".", "size", "(", ")", "\n", "# first transform to [batch *length, char_length, char_dim]", "\n", "# then transpose to [batch * length, char_dim, char_length]", "\n", "char", "=", "char", ".", "view", "(", "char_size", "[", "0", "]", "*", "char_size", "[", "1", "]", ",", "char_size", "[", "2", "]", ",", "char_size", "[", "3", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# put into cnn [batch*length, char_filters, char_length]", "\n", "# then put into maxpooling [batch * length, char_filters]", "\n", "char", ",", "_", "=", "self", ".", "conv1d", "(", "char", ")", ".", "max", "(", "dim", "=", "2", ")", "\n", "# reshape to [batch, length, char_filters]", "\n", "char", "=", "torch", ".", "tanh", "(", "char", ")", ".", "view", "(", "char_size", "[", "0", "]", ",", "char_size", "[", "1", "]", ",", "-", "1", ")", "\n", "# apply dropout on input", "\n", "char", "=", "self", ".", "dropout_in", "(", "char", ")", "\n", "# concatenate word and char [batch, length, word_dim+char_filter]", "\n", "if", "src_encoding", "is", "None", ":", "\n", "                ", "src_encoding", "=", "char", "\n", "", "else", ":", "\n", "                ", "src_encoding", "=", "torch", ".", "cat", "(", "[", "src_encoding", ",", "char", "]", ",", "dim", "=", "2", ")", "if", "self", ".", "input_concat_embeds", "else", "src_encoding", "+", "char", "\n", "\n", "", "", "if", "self", ".", "pos", ":", "\n", "# [batch, length, pos_dim]", "\n", "            ", "pos", "=", "self", ".", "pos_embedd", "(", "input_pos", ")", "\n", "# apply dropout on input", "\n", "if", "self", ".", "use_con_rnn", ":", "\n", "                ", "pos", "=", "self", ".", "dropout_in", "(", "pos", ")", "\n", "\n", "", "if", "src_encoding", "is", "None", ":", "\n", "                ", "src_encoding", "=", "pos", "\n", "", "else", ":", "\n", "                ", "src_encoding", "=", "torch", ".", "cat", "(", "[", "src_encoding", ",", "pos", "]", ",", "dim", "=", "2", ")", "if", "self", ".", "input_concat_embeds", "else", "src_encoding", "+", "pos", "\n", "\n", "", "", "if", "self", ".", "use_con_rnn", ":", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "            ", "output", ",", "hn", "=", "self", ".", "encoder", "(", "src_encoding", ",", "mask_e", ",", "hx", "=", "hx", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "multi_head_attn", ":", "\n", "# padding_idx = 1", "\n", "# words = src_encoding[:, :, 0]", "\n", "# w_batch, w_len = words.size()", "\n", "# mask = words.data.eq(padding_idx).unsqueeze(1).expand(w_batch, w_len, w_len)", "\n", "# Run the forward pass of every layer of the tranformer.", "\n", "\n", "                ", "if", "self", ".", "position_dim", ">", "0", ":", "\n", "                    ", "position_encoding", "=", "Variable", "(", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "src_encoding", ".", "size", "(", "1", ")", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "# ----- modified by zs", "\n", "if", "self", ".", "use_gpu", ":", "\n", "                        ", "position_encoding", "=", "position_encoding", ".", "cuda", "(", ")", "\n", "# -----", "\n", "", "position_encoding", "=", "position_encoding", ".", "expand", "(", "*", "src_encoding", ".", "size", "(", ")", "[", ":", "-", "1", "]", ")", "\n", "position_encoding", "=", "self", ".", "position_embedding", "(", "position_encoding", ")", "\n", "# src_encoding = src_encoding + position_encoding", "\n", "src_encoding", "=", "torch", ".", "cat", "(", "[", "src_encoding", ",", "position_encoding", "]", ",", "dim", "=", "2", ")", "if", "self", ".", "input_concat_position", "else", "src_encoding", "+", "position_encoding", "\n", "", "src_encoding", "=", "self", ".", "transformer", "(", "src_encoding", ")", "\n", "", "else", ":", "\n", "# if we want to apply self-attention to compute the fixed-length vector", "\n", "                ", "hw", "=", "self", ".", "linear1", "(", "src_encoding", ".", "view", "(", "-", "1", ",", "src_encoding", ".", "size", "(", "2", ")", ")", ")", "# (B*S) x h", "\n", "hw", "=", "hw", ".", "view", "(", "*", "src_encoding", ".", "size", "(", ")", ")", "# B x S x h", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "src_encoding", ",", "hw", ".", "transpose", "(", "1", ",", "2", ")", ")", "# B x S x S", "\n", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "2", ")", "# B x S x S", "\n", "src_encoding", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "src_encoding", ")", "# B x S x h", "\n", "\n", "", "if", "self", ".", "pool_type", "==", "'mean'", ":", "\n", "# if we want to use averaging to compute the fixed-length vector", "\n", "                ", "temp_hidden", "=", "torch", ".", "sum", "(", "src_encoding", ",", "1", ")", ".", "div", "(", "src_encoding", ".", "size", "(", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "output", ",", "hn", "=", "src_encoding", ",", "(", "temp_hidden", ",", "torch", ".", "zeros_like", "(", "temp_hidden", ")", ")", "\n", "", "elif", "self", ".", "pool_type", "==", "'max'", ":", "\n", "# if we want to use max-pooling to compute the fixed-length vector", "\n", "                ", "temp_hidden", "=", "torch", ".", "max", "(", "src_encoding", ",", "dim", "=", "1", ")", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", "\n", "output", ",", "hn", "=", "src_encoding", ",", "(", "temp_hidden", ",", "torch", ".", "zeros_like", "(", "temp_hidden", ")", ")", "\n", "", "elif", "self", ".", "pool_type", "==", "'weight'", ":", "\n", "# if we want to apply weighted-pooling to compute the fixed-length vector", "\n", "                ", "att_weights", "=", "self", ".", "self_attn", "(", "src_encoding", ".", "view", "(", "-", "1", ",", "src_encoding", ".", "size", "(", "2", ")", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "att_weights", "=", "F", ".", "softmax", "(", "att_weights", ".", "view", "(", "src_encoding", ".", "size", "(", "0", ")", ",", "src_encoding", ".", "size", "(", "1", ")", ")", ",", "1", ")", "\n", "attn_rep", "=", "torch", ".", "bmm", "(", "src_encoding", ".", "transpose", "(", "1", ",", "2", ")", ",", "att_weights", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "attn_rep", "=", "attn_rep", ".", "unsqueeze", "(", "0", ")", "\n", "output", ",", "hn", "=", "src_encoding", ",", "(", "attn_rep", ",", "torch", ".", "zeros_like", "(", "attn_rep", ")", ")", "\n", "\n", "# apply dropout", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "", "", "output", "=", "self", ".", "dropout_out", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "output", ",", "hn", ",", "mask_e", ",", "length_e", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_decoder_output": [[610, 642], ["output_enc.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "output_enc[].transpose", "torch.elu", "torch.elu", "torch.elu", "parsing.StackPtrNet.decoder", "parsing.StackPtrNet.dropout_out().transpose", "siblings.ne().float().unsqueeze", "output_enc[].transpose", "parsing.StackPtrNet.src_dense", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "output_enc[].transpose", "parsing.StackPtrNet.dropout_out", "siblings.ne().float", "parsing.StackPtrNet.transpose", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "heads_stack.data.t", "siblings.ne", "heads_stack.data.t", "siblings.data.t"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_get_decoder_output", "(", "self", ",", "output_enc", ",", "heads", ",", "heads_stack", ",", "siblings", ",", "hx", ",", "mask_d", "=", "None", ",", "length_d", "=", "None", ")", ":", "\n", "        ", "batch", ",", "_", ",", "_", "=", "output_enc", ".", "size", "(", ")", "\n", "# create batch index [batch]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "output_enc", ".", "data", ")", ".", "long", "(", ")", "\n", "# get vector for heads [batch, length_decoder, input_dim],", "\n", "src_encoding", "=", "output_enc", "[", "batch_index", ",", "heads_stack", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "sibling", ":", "\n", "# [batch, length_decoder, hidden_size * 2]", "\n", "            ", "mask_sibs", "=", "siblings", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "output_enc_sibling", "=", "output_enc", "[", "batch_index", ",", "siblings", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "*", "mask_sibs", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_sibling", "\n", "\n", "", "if", "self", ".", "grandPar", ":", "\n", "# [length_decoder, batch]", "\n", "            ", "gpars", "=", "heads", "[", "batch_index", ",", "heads_stack", ".", "data", ".", "t", "(", ")", "]", ".", "data", "\n", "# [batch, length_decoder, hidden_size * 2]", "\n", "output_enc_gpar", "=", "output_enc", "[", "batch_index", ",", "gpars", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_gpar", "\n", "\n", "# transform to decoder input", "\n", "# [batch, length_decoder, dec_dim]", "\n", "", "src_encoding", "=", "F", ".", "elu", "(", "self", ".", "src_dense", "(", "src_encoding", ")", ")", "\n", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "output", ",", "hn", "=", "self", ".", "decoder", "(", "src_encoding", ",", "mask_d", ",", "hx", "=", "hx", ")", "\n", "\n", "# apply dropout", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "output", "=", "self", ".", "dropout_out", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "output", ",", "hn", ",", "mask_d", ",", "length_d", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_decoder_output_with_skip_connect": [[643, 676], ["output_enc.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "output_enc[].transpose", "torch.elu", "torch.elu", "torch.elu", "parsing.StackPtrNet.decoder", "parsing.StackPtrNet.dropout_out().transpose", "siblings.ne().float().unsqueeze", "output_enc[].transpose", "parsing.StackPtrNet.src_dense", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "output_enc[].transpose", "parsing.StackPtrNet.dropout_out", "siblings.ne().float", "parsing.StackPtrNet.transpose", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "heads_stack.data.t", "siblings.ne", "heads_stack.data.t", "siblings.data.t"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_get_decoder_output_with_skip_connect", "(", "self", ",", "output_enc", ",", "heads", ",", "heads_stack", ",", "siblings", ",", "skip_connect", ",", "hx", ",", "\n", "mask_d", "=", "None", ",", "length_d", "=", "None", ")", ":", "\n", "        ", "batch", ",", "_", ",", "_", "=", "output_enc", ".", "size", "(", ")", "\n", "# create batch index [batch]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "output_enc", ".", "data", ")", ".", "long", "(", ")", "\n", "# get vector for heads [batch, length_decoder, input_dim],", "\n", "src_encoding", "=", "output_enc", "[", "batch_index", ",", "heads_stack", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "sibling", ":", "\n", "# [batch, length_decoder, hidden_size * 2]", "\n", "            ", "mask_sibs", "=", "siblings", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "output_enc_sibling", "=", "output_enc", "[", "batch_index", ",", "siblings", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "*", "mask_sibs", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_sibling", "\n", "\n", "", "if", "self", ".", "grandPar", ":", "\n", "# [length_decoder, batch]", "\n", "            ", "gpars", "=", "heads", "[", "batch_index", ",", "heads_stack", ".", "data", ".", "t", "(", ")", "]", ".", "data", "\n", "# [batch, length_decoder, hidden_size * 2]", "\n", "output_enc_gpar", "=", "output_enc", "[", "batch_index", ",", "gpars", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_gpar", "\n", "\n", "# transform to decoder input", "\n", "# [batch, length_decoder, dec_dim]", "\n", "", "src_encoding", "=", "F", ".", "elu", "(", "self", ".", "src_dense", "(", "src_encoding", ")", ")", "\n", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "output", ",", "hn", "=", "self", ".", "decoder", "(", "src_encoding", ",", "skip_connect", ",", "mask_d", ",", "hx", "=", "hx", ")", "\n", "\n", "# apply dropout", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "output", "=", "self", ".", "dropout_out", "(", "output", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "output", ",", "hn", ",", "mask_d", ",", "length_d", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.forward": [[677, 679], ["RuntimeError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Stack Pointer Network does not implement forward'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._transform_decoder_init_state": [[680, 723], ["isinstance", "parsing.StackPtrNet.hx_dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "torch.cat.transpose().contiguous", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat.view().transpose", "torch.cat.view().transpose", "parsing.StackPtrNet.hx_dense", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new().zero_", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new", "torch.cat.data.new"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_transform_decoder_init_state", "(", "self", ",", "hn", ")", ":", "\n", "        ", "if", "isinstance", "(", "hn", ",", "tuple", ")", ":", "\n", "            ", "if", "self", ".", "use_con_rnn", ":", "\n", "                ", "hn", ",", "cn", "=", "hn", "\n", "# take the last layers", "\n", "# [2, batch, hidden_size]", "\n", "cn", "=", "cn", "[", "-", "2", ":", "]", "\n", "# hn [2, batch, hidden_size]", "\n", "_", ",", "batch", ",", "hidden_size", "=", "cn", ".", "size", "(", ")", "\n", "# first convert cn t0 [batch, 2, hidden_size]", "\n", "cn", "=", "cn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# then view to [batch, 1, 2 * hidden_size] --> [1, batch, 2 * hidden_size]", "\n", "cn", "=", "cn", ".", "view", "(", "batch", ",", "1", ",", "2", "*", "hidden_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "cn", ",", "hn", "=", "hn", "\n", "\n", "# take hx_dense to [1, batch, hidden_size]", "\n", "", "cn", "=", "self", ".", "hx_dense", "(", "cn", ")", "\n", "# [decoder_layers, batch, hidden_size]", "\n", "if", "self", ".", "decoder_layers", ">", "1", ":", "\n", "                ", "cn", "=", "torch", ".", "cat", "(", "[", "cn", ",", "Variable", "(", "cn", ".", "data", ".", "new", "(", "self", ".", "decoder_layers", "-", "1", ",", "batch", ",", "hidden_size", ")", ".", "zero_", "(", ")", ")", "]", ",", "dim", "=", "0", ")", "\n", "# hn is tanh(cn)", "\n", "", "hn", "=", "F", ".", "tanh", "(", "cn", ")", "\n", "hn", "=", "(", "hn", ",", "cn", ")", "\n", "", "else", ":", "\n", "# take the last layers", "\n", "# [2, batch, hidden_size]", "\n", "            ", "hn", "=", "hn", "[", "-", "2", ":", "]", "\n", "# hn [2, batch, hidden_size]", "\n", "_", ",", "batch", ",", "hidden_size", "=", "hn", ".", "size", "(", ")", "\n", "# first convert hn t0 [batch, 2, hidden_size]", "\n", "hn", "=", "hn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# then view to [batch, 1, 2 * hidden_size] --> [1, batch, 2 * hidden_size]", "\n", "if", "self", ".", "use_con_rnn", ":", "\n", "                ", "hn", "=", "hn", ".", "view", "(", "batch", ",", "1", ",", "2", "*", "hidden_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "hn", "=", "hn", ".", "view", "(", "batch", ",", "1", ",", "hidden_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# take hx_dense to [1, batch, hidden_size]", "\n", "", "hn", "=", "F", ".", "tanh", "(", "self", ".", "hx_dense", "(", "hn", ")", ")", "\n", "# [decoder_layers, batch, hidden_size]", "\n", "if", "self", ".", "decoder_layers", ">", "1", ":", "\n", "                ", "hn", "=", "torch", ".", "cat", "(", "[", "hn", ",", "Variable", "(", "hn", ".", "data", ".", "new", "(", "self", ".", "decoder_layers", "-", "1", ",", "batch", ",", "hidden_size", ")", ".", "zero_", "(", ")", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "", "return", "hn", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.loss": [[724, 858], ["parsing.StackPtrNet._get_encoder_output", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "parsing.StackPtrNet._transform_decoder_init_state", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu.size", "parsing.StackPtrNet.dropout_out().transpose", "parsing.StackPtrNet.dropout_out().transpose", "type[].contiguous", "parsing.StackPtrNet.attention().squeeze", "torch.elu.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "type_c[].transpose().contiguous", "parsing.StackPtrNet.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.exp().cumsum", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "head_index.type_as().long.type_as().long.type_as().long", "parsing.StackPtrNet.arc_c", "parsing.StackPtrNet.type_c", "parsing.StackPtrNet._get_decoder_output_with_skip_connect", "parsing.StackPtrNet._get_decoder_output", "parsing.StackPtrNet.arc_h", "parsing.StackPtrNet.type_h", "torch.elu.size", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "input_pos[].transpose", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "stacked_heads.unsqueeze", "parsing.StackPtrNet.attention_helper.get_final_features", "torch.eq().float.sum", "torch.eq().float.sum", "torch.eq().float.sum", "mask_non_leaf.sum", "loss_arc[].transpose", "loss_type[].transpose", "loss_arc[].transpose", "loss_type[].transpose", "children.size", "mask_d.size", "parsing.StackPtrNet.dropout_out", "parsing.StackPtrNet.dropout_out", "torch.arange().type_as().long().expand().unsqueeze.expand", "torch.arange().type_as().long().expand().unsqueeze.expand", "torch.arange().type_as().long().expand().unsqueeze.expand", "parsing.StackPtrNet.attention", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "type_c[].transpose", "minus_mask_e.unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "mask_e.unsqueeze", "mask_e.unsqueeze", "mask_d.unsqueeze", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "head_index.type_as().long.type_as().long.type_as", "loss_arc[].transpose.sum", "mask_e.sum().unsqueeze", "loss_type[].transpose.sum", "loss_cov.sum", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "torch.arange().type_as().long().expand", "stacked_heads.unsqueeze.expand", "minus_mask_d.unsqueeze", "mask_d.unsqueeze", "mask_d.unsqueeze", "loss_arc_leaf.sum", "loss_arc_non_leaf.sum", "loss_type_leaf.sum", "loss_type_non_leaf.sum", "stacked_heads.unsqueeze.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask_e.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long().expand().unsqueeze.size", "torch.arange().type_as().long().expand().unsqueeze.size", "torch.arange().type_as().long().expand().unsqueeze.size", "stacked_heads.data.t", "children.data.t", "stacked_types.data.t", "children.data.t", "stacked_types.data.t", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "children.data.t", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_encoder_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._transform_decoder_init_state", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_decoder_output_with_skip_connect", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_decoder_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.get_final_features", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "loss", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "heads", ",", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "\n", "label_smooth", ",", "\n", "skip_connect", "=", "None", ",", "mask_e", "=", "None", ",", "length_e", "=", "None", ",", "mask_d", "=", "None", ",", "length_d", "=", "None", ",", "hx", "=", "None", ")", ":", "\n", "# output from encoder [batch, length_encoder, tag_space]", "\n", "        ", "output_enc", ",", "hn", ",", "mask_e", ",", "_", "=", "self", ".", "_get_encoder_output", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask_e", "=", "mask_e", ",", "\n", "length_e", "=", "length_e", ",", "hx", "=", "hx", ")", "\n", "\n", "# output size [batch, length_encoder, arc_space]", "\n", "arc_c", "=", "F", ".", "elu", "(", "self", ".", "arc_c", "(", "output_enc", ")", ")", "\n", "# output size [batch, length_encoder, type_space]", "\n", "type_c", "=", "F", ".", "elu", "(", "self", ".", "type_c", "(", "output_enc", ")", ")", "\n", "\n", "# transform hn to [decoder_layers, batch, hidden_size]", "\n", "hn", "=", "self", ".", "_transform_decoder_init_state", "(", "hn", ")", "\n", "\n", "# output from decoder [batch, length_decoder, tag_space]", "\n", "if", "self", ".", "skipConnect", ":", "\n", "            ", "output_dec", ",", "_", ",", "mask_d", ",", "_", "=", "self", ".", "_get_decoder_output_with_skip_connect", "(", "output_enc", ",", "heads", ",", "stacked_heads", ",", "\n", "siblings", ",", "skip_connect", ",", "hn", ",", "\n", "mask_d", "=", "mask_d", ",", "length_d", "=", "length_d", ")", "\n", "", "else", ":", "\n", "            ", "output_dec", ",", "_", ",", "mask_d", ",", "_", "=", "self", ".", "_get_decoder_output", "(", "output_enc", ",", "heads", ",", "stacked_heads", ",", "siblings", ",", "hn", ",", "\n", "mask_d", "=", "mask_d", ",", "length_d", "=", "length_d", ")", "\n", "\n", "# output size [batch, length_decoder, arc_space]", "\n", "", "arc_h", "=", "F", ".", "elu", "(", "self", ".", "arc_h", "(", "output_dec", ")", ")", "\n", "type_h", "=", "F", ".", "elu", "(", "self", ".", "type_h", "(", "output_dec", ")", ")", "\n", "\n", "_", ",", "max_len_d", ",", "_", "=", "arc_h", ".", "size", "(", ")", "\n", "if", "mask_d", "is", "not", "None", "and", "children", ".", "size", "(", "1", ")", "!=", "mask_d", ".", "size", "(", "1", ")", ":", "\n", "            ", "stacked_heads", "=", "stacked_heads", "[", ":", ",", ":", "max_len_d", "]", "\n", "children", "=", "children", "[", ":", ",", ":", "max_len_d", "]", "\n", "stacked_types", "=", "stacked_types", "[", ":", ",", ":", "max_len_d", "]", "\n", "\n", "# apply dropout", "\n", "# [batch, length_decoder, dim] + [batch, length_encoder, dim] --> [batch, length_decoder + length_encoder, dim]", "\n", "", "arc", "=", "self", ".", "dropout_out", "(", "torch", ".", "cat", "(", "[", "arc_h", ",", "arc_c", "]", ",", "dim", "=", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "arc_h", "=", "arc", "[", ":", ",", ":", "max_len_d", "]", "\n", "arc_c", "=", "arc", "[", ":", ",", "max_len_d", ":", "]", "\n", "\n", "type", "=", "self", ".", "dropout_out", "(", "torch", ".", "cat", "(", "[", "type_h", ",", "type_c", "]", ",", "dim", "=", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "type_h", "=", "type", "[", ":", ",", ":", "max_len_d", "]", ".", "contiguous", "(", ")", "\n", "type_c", "=", "type", "[", ":", ",", "max_len_d", ":", "]", "\n", "\n", "# [batch, length_decoder, length_encoder]", "\n", "if", "self", ".", "attention", ".", "use_features", ":", "\n", "            ", "batch", ",", "max_len_e", ",", "_", "=", "arc_c", ".", "size", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "arc_c", ".", "data", ")", ".", "long", "(", ")", "\n", "child_pos", "=", "input_pos", "# [batch, len-e]", "\n", "head_pos", "=", "input_pos", "[", "batch_index", ",", "stacked_heads", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "# [batch, len-d]", "\n", "child_position_idxes", "=", "torch", ".", "arange", "(", "max_len_e", ")", ".", "type_as", "(", "arc_c", ".", "data", ")", ".", "long", "(", ")", ".", "expand", "(", "batch", ",", "-", "1", ")", ".", "unsqueeze", "(", "\n", "-", "2", ")", "# [batch, 1, len-e]", "\n", "head_position_idxes", "=", "stacked_heads", ".", "unsqueeze", "(", "-", "1", ")", "# [batch, len-d, 1]", "\n", "raw_distances", "=", "head_position_idxes", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "child_position_idxes", ".", "size", "(", ")", "[", "\n", "-", "1", "]", ")", ".", "data", "-", "child_position_idxes", ".", "expand", "(", "-", "1", ",", "head_position_idxes", ".", "size", "(", ")", "[", "-", "2", "]", ",", "-", "1", ")", "# [batch, len-d, len-e]", "\n", "input_features", "=", "self", ".", "attention_helper", ".", "get_final_features", "(", "raw_distances", ",", "child_pos", ".", "data", ",", "head_pos", ".", "data", ")", "\n", "", "else", ":", "\n", "            ", "input_features", "=", "None", "\n", "", "out_arc", "=", "self", ".", "attention", "(", "arc_h", ",", "arc_c", ",", "input_features", "=", "input_features", ",", "mask_d", "=", "mask_d", ",", "mask_e", "=", "mask_e", ")", ".", "squeeze", "(", "\n", "dim", "=", "1", ")", "\n", "\n", "batch", ",", "max_len_e", ",", "_", "=", "arc_c", ".", "size", "(", ")", "\n", "# create batch index [batch]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "0", ",", "batch", ")", ".", "type_as", "(", "arc_c", ".", "data", ")", ".", "long", "(", ")", "\n", "# get vector for heads [batch, length_decoder, type_space],", "\n", "type_c", "=", "type_c", "[", "batch_index", ",", "children", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# compute output for type [batch, length_decoder, num_labels]", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", ",", "type_c", ")", "\n", "\n", "# mask invalid position to -inf for log_softmax", "\n", "if", "mask_e", "is", "not", "None", ":", "\n", "            ", "minus_inf", "=", "-", "1e8", "\n", "minus_mask_d", "=", "(", "1", "-", "mask_d", ")", "*", "minus_inf", "\n", "minus_mask_e", "=", "(", "1", "-", "mask_e", ")", "*", "minus_inf", "\n", "out_arc", "=", "out_arc", "+", "minus_mask_d", ".", "unsqueeze", "(", "2", ")", "+", "minus_mask_e", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# [batch, length_decoder, length_encoder]", "\n", "", "loss_arc", "=", "F", ".", "log_softmax", "(", "out_arc", ",", "dim", "=", "2", ")", "\n", "# [batch, length_decoder, num_labels]", "\n", "loss_type", "=", "F", ".", "log_softmax", "(", "out_type", ",", "dim", "=", "2", ")", "\n", "\n", "# compute coverage loss", "\n", "# [batch, length_decoder, length_encoder]", "\n", "coverage", "=", "torch", ".", "exp", "(", "loss_arc", ")", ".", "cumsum", "(", "dim", "=", "1", ")", "\n", "\n", "# get leaf and non-leaf mask", "\n", "# shape = [batch, length_decoder]", "\n", "mask_leaf", "=", "torch", ".", "eq", "(", "children", ",", "stacked_heads", ")", ".", "float", "(", ")", "\n", "mask_non_leaf", "=", "(", "1.0", "-", "mask_leaf", ")", "\n", "\n", "# mask invalid position to 0 for sum loss", "\n", "if", "mask_e", "is", "not", "None", ":", "\n", "            ", "loss_arc", "=", "loss_arc", "*", "mask_d", ".", "unsqueeze", "(", "2", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", "\n", "coverage", "=", "coverage", "*", "mask_d", ".", "unsqueeze", "(", "2", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", "\n", "loss_type", "=", "loss_type", "*", "mask_d", ".", "unsqueeze", "(", "2", ")", "\n", "mask_leaf", "=", "mask_leaf", "*", "mask_d", "\n", "mask_non_leaf", "=", "mask_non_leaf", "*", "mask_d", "\n", "\n", "# number of valid positions which contribute to loss (remove the symbolic head for each sentence.", "\n", "num_leaf", "=", "mask_leaf", ".", "sum", "(", ")", "\n", "num_non_leaf", "=", "mask_non_leaf", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "# number of valid positions which contribute to loss (remove the symbolic head for each sentence.", "\n", "            ", "num_leaf", "=", "max_len_e", "\n", "num_non_leaf", "=", "max_len_e", "-", "1", "\n", "\n", "# first create index matrix [length, batch]", "\n", "", "head_index", "=", "torch", ".", "arange", "(", "0", ",", "max_len_d", ")", ".", "view", "(", "max_len_d", ",", "1", ")", ".", "expand", "(", "max_len_d", ",", "batch", ")", "\n", "head_index", "=", "head_index", ".", "type_as", "(", "out_arc", ".", "data", ")", ".", "long", "(", ")", "\n", "# [batch, length_decoder]", "\n", "if", "0.0", "<", "label_smooth", "<", "1.0", "-", "1e-4", ":", "\n", "# label smoothing", "\n", "            ", "loss_arc1", "=", "loss_arc", "[", "batch_index", ",", "head_index", ",", "children", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "loss_arc2", "=", "loss_arc", ".", "sum", "(", "dim", "=", "2", ")", "/", "mask_e", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "loss_arc", "=", "loss_arc1", "*", "label_smooth", "+", "loss_arc2", "*", "(", "1", "-", "label_smooth", ")", "\n", "\n", "loss_type1", "=", "loss_type", "[", "batch_index", ",", "head_index", ",", "stacked_types", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "loss_type2", "=", "loss_type", ".", "sum", "(", "dim", "=", "2", ")", "/", "self", ".", "num_labels", "\n", "loss_type", "=", "loss_type1", "*", "label_smooth", "+", "loss_type2", "*", "(", "1", "-", "label_smooth", ")", "\n", "", "else", ":", "\n", "            ", "loss_arc", "=", "loss_arc", "[", "batch_index", ",", "head_index", ",", "children", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "loss_type", "=", "loss_type", "[", "batch_index", ",", "head_index", ",", "stacked_types", ".", "data", ".", "t", "(", ")", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "loss_arc_leaf", "=", "loss_arc", "*", "mask_leaf", "\n", "loss_arc_non_leaf", "=", "loss_arc", "*", "mask_non_leaf", "\n", "\n", "loss_type_leaf", "=", "loss_type", "*", "mask_leaf", "\n", "loss_type_non_leaf", "=", "loss_type", "*", "mask_non_leaf", "\n", "\n", "loss_cov", "=", "(", "coverage", "-", "2.0", ")", ".", "clamp", "(", "min", "=", "0.", ")", "\n", "\n", "return", "-", "loss_arc_leaf", ".", "sum", "(", ")", "/", "num_leaf", ",", "-", "loss_arc_non_leaf", ".", "sum", "(", ")", "/", "num_non_leaf", ",", "-", "loss_type_leaf", ".", "sum", "(", ")", "/", "num_leaf", ",", "-", "loss_type_non_leaf", ".", "sum", "(", ")", "/", "num_non_leaf", ",", "loss_cov", ".", "sum", "(", ")", "/", "(", "num_leaf", "+", "num_non_leaf", ")", ",", "num_leaf", ",", "num_non_leaf", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._decode_per_sentence": [[859, 1119], ["isinstance", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long", "torch.zeros().type_as().long.new().zero_", "torch.zeros().type_as().long.new().zero_", "torch.zeros().type_as().long.new().zero_", "output_enc.data.new().zero_", "numpy.zeros", "numpy.zeros", "torch.zeros().type_as().long.new().zero_", "torch.zeros().type_as().long.new().zero_", "torch.zeros().type_as().long.new().zero_", "torch.zeros().type_as().long.new().zero_.new().zero_", "range", "numpy.zeros", "numpy.zeros", "range", "output_enc.size", "hx.unsqueeze.unsqueeze.unsqueeze", "cx.unsqueeze.unsqueeze.unsqueeze", "hx.unsqueeze.unsqueeze.unsqueeze", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "parsing.StackPtrNet.attention().squeeze().squeeze", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "numpy.zeros", "numpy.zeros", "range", "len", "parsing.StackPtrNet.bilinear", "hyp_type_scores.max", "range", "torch.zeros().type_as().long.copy_", "torch.zeros().type_as().long.copy_", "torch.zeros().type_as().long.copy_", "torch.zeros().type_as().long.new().zero_.copy_", "isinstance", "torch.zeros().type_as().long.cpu().numpy", "torch.zeros().type_as().long.cpu().numpy", "torch.zeros().type_as().long.cpu().numpy", "torch.zeros().type_as().long.new().zero_.cpu().numpy", "range", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as().long.new", "torch.zeros().type_as().long.new", "torch.zeros().type_as().long.new", "output_enc.data.new", "range", "torch.zeros().type_as().long.new", "torch.zeros().type_as().long.new", "torch.zeros().type_as().long.new", "torch.zeros().type_as().long.new().zero_.new", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.LongTensor().type_as", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "parsing.StackPtrNet.src_dense", "parsing.StackPtrNet.decoder.step", "parsing.StackPtrNet.decoder.step", "parsing.StackPtrNet.arc_h", "parsing.StackPtrNet.type_h", "input_pos.expand", "input_pos[].unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.arange().type_as().long().expand().unsqueeze", "torch.LongTensor().type_as.unsqueeze().unsqueeze", "torch.LongTensor().type_as.unsqueeze().unsqueeze", "torch.LongTensor().type_as.unsqueeze().unsqueeze", "parsing.StackPtrNet.attention_helper.get_final_features", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "hypothesis_scores[].unsqueeze", "new_hypothesis_scores.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "stack.append", "stack.pop", "range", "range", "range", "torch.zeros().type_as().long.size", "torch.zeros().type_as().long.size", "torch.zeros().type_as().long.size", "range", "range", "range", "torch.zeros().type_as().long.size", "torch.zeros().type_as().long.size", "torch.zeros().type_as().long.size", "torch.zeros().type_as().long.new().zero_.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "sibs.ne().float().unsqueeze", "output_dec.unsqueeze", "parsing.StackPtrNet.attention().squeeze", "parsing.StackPtrNet._decode_per_sentence.valid_hyp"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.step", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.masked_rnn.MaskedRNNBase.step", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.attention_aug.AugFeatureHelper.get_final_features", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "_decode_per_sentence", "(", "self", ",", "output_enc", ",", "arc_c", ",", "type_c", ",", "hx", ",", "length", ",", "beam", ",", "ordered", ",", "leading_symbolic", ",", "input_pos", ")", ":", "\n", "        ", "def", "valid_hyp", "(", "base_id", ",", "child_id", ",", "head", ")", ":", "\n", "            ", "if", "constraints", "[", "base_id", ",", "child_id", "]", ":", "\n", "                ", "return", "False", "\n", "", "elif", "not", "ordered", "or", "self", ".", "prior_order", "==", "PriorOrder", ".", "DEPTH", "or", "child_orders", "[", "base_id", ",", "head", "]", "==", "0", ":", "\n", "                ", "return", "True", "\n", "", "elif", "self", ".", "prior_order", "==", "PriorOrder", ".", "LEFT2RIGTH", ":", "\n", "                ", "return", "child_id", ">", "child_orders", "[", "base_id", ",", "head", "]", "\n", "", "else", ":", "\n", "                ", "if", "child_id", "<", "head", ":", "\n", "                    ", "return", "child_id", "<", "child_orders", "[", "base_id", ",", "head", "]", "<", "head", "\n", "", "else", ":", "\n", "                    ", "return", "child_id", ">", "child_orders", "[", "base_id", ",", "head", "]", "\n", "\n", "# output_enc [length, hidden_size * 2]", "\n", "# arc_c [length, arc_space]", "\n", "# type_c [length, type_space]", "\n", "# hx [decoder_layers, hidden_size]", "\n", "", "", "", "if", "length", "is", "not", "None", ":", "\n", "            ", "output_enc", "=", "output_enc", "[", ":", "length", "]", "\n", "arc_c", "=", "arc_c", "[", ":", "length", "]", "\n", "type_c", "=", "type_c", "[", ":", "length", "]", "\n", "input_pos", "=", "input_pos", "[", ":", "length", "]", "# input_pos: [length]", "\n", "", "else", ":", "\n", "            ", "length", "=", "output_enc", ".", "size", "(", "0", ")", "\n", "\n", "# [decoder_layers, 1, hidden_size]", "\n", "# hack to handle LSTM", "\n", "", "if", "isinstance", "(", "hx", ",", "tuple", ")", ":", "\n", "            ", "hx", ",", "cx", "=", "hx", "\n", "hx", "=", "hx", ".", "unsqueeze", "(", "1", ")", "\n", "cx", "=", "cx", ".", "unsqueeze", "(", "1", ")", "\n", "h0", "=", "hx", "\n", "hx", "=", "(", "hx", ",", "cx", ")", "\n", "", "else", ":", "\n", "            ", "hx", "=", "hx", ".", "unsqueeze", "(", "1", ")", "\n", "h0", "=", "hx", "\n", "\n", "", "stacked_heads", "=", "[", "[", "0", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "\n", "grand_parents", "=", "[", "[", "0", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "grandPar", "else", "None", "\n", "siblings", "=", "[", "[", "0", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "sibling", "else", "None", "\n", "skip_connects", "=", "[", "[", "h0", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "skipConnect", "else", "None", "\n", "children", "=", "torch", ".", "zeros", "(", "beam", ",", "2", "*", "length", "-", "1", ")", ".", "type_as", "(", "output_enc", ".", "data", ")", ".", "long", "(", ")", "\n", "stacked_types", "=", "children", ".", "new", "(", "children", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", "\n", "hypothesis_scores", "=", "output_enc", ".", "data", ".", "new", "(", "beam", ")", ".", "zero_", "(", ")", "\n", "constraints", "=", "np", ".", "zeros", "(", "[", "beam", ",", "length", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "constraints", "[", ":", ",", "0", "]", "=", "True", "\n", "child_orders", "=", "np", ".", "zeros", "(", "[", "beam", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "# temporal tensors for each step.", "\n", "new_stacked_heads", "=", "[", "[", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "\n", "new_grand_parents", "=", "[", "[", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "grandPar", "else", "None", "\n", "new_siblings", "=", "[", "[", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "sibling", "else", "None", "\n", "new_skip_connects", "=", "[", "[", "]", "for", "_", "in", "range", "(", "beam", ")", "]", "if", "self", ".", "skipConnect", "else", "None", "\n", "new_children", "=", "children", ".", "new", "(", "children", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", "\n", "new_stacked_types", "=", "stacked_types", ".", "new", "(", "stacked_types", ".", "size", "(", ")", ")", ".", "zero_", "(", ")", "\n", "num_hyp", "=", "1", "\n", "num_step", "=", "2", "*", "length", "-", "1", "\n", "for", "t", "in", "range", "(", "num_step", ")", ":", "\n", "# [num_hyp]", "\n", "            ", "heads", "=", "torch", ".", "LongTensor", "(", "[", "stacked_heads", "[", "i", "]", "[", "-", "1", "]", "for", "i", "in", "range", "(", "num_hyp", ")", "]", ")", ".", "type_as", "(", "children", ")", "\n", "gpars", "=", "torch", ".", "LongTensor", "(", "[", "grand_parents", "[", "i", "]", "[", "-", "1", "]", "for", "i", "in", "range", "(", "num_hyp", ")", "]", ")", ".", "type_as", "(", "\n", "children", ")", "if", "self", ".", "grandPar", "else", "None", "\n", "sibs", "=", "torch", ".", "LongTensor", "(", "[", "siblings", "[", "i", "]", ".", "pop", "(", ")", "for", "i", "in", "range", "(", "num_hyp", ")", "]", ")", ".", "type_as", "(", "\n", "children", ")", "if", "self", ".", "sibling", "else", "None", "\n", "\n", "# [decoder_layers, num_hyp, hidden_size]", "\n", "hs", "=", "torch", ".", "cat", "(", "[", "skip_connects", "[", "i", "]", ".", "pop", "(", ")", "for", "i", "in", "range", "(", "num_hyp", ")", "]", ",", "dim", "=", "1", ")", "if", "self", ".", "skipConnect", "else", "None", "\n", "\n", "# [num_hyp, hidden_size * 2]", "\n", "src_encoding", "=", "output_enc", "[", "heads", "]", "\n", "\n", "if", "self", ".", "sibling", ":", "\n", "                ", "mask_sibs", "=", "Variable", "(", "sibs", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "output_enc_sibling", "=", "output_enc", "[", "sibs", "]", "*", "mask_sibs", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_sibling", "\n", "\n", "", "if", "self", ".", "grandPar", ":", "\n", "                ", "output_enc_gpar", "=", "output_enc", "[", "gpars", "]", "\n", "src_encoding", "=", "src_encoding", "+", "output_enc_gpar", "\n", "\n", "# transform to decoder input", "\n", "# [num_hyp, dec_dim]", "\n", "", "src_encoding", "=", "F", ".", "elu", "(", "self", ".", "src_dense", "(", "src_encoding", ")", ")", "\n", "\n", "# output [num_hyp, hidden_size]", "\n", "# hx [decoder_layer, num_hyp, hidden_size]", "\n", "output_dec", ",", "hx", "=", "self", ".", "decoder", ".", "step", "(", "src_encoding", ",", "hx", "=", "hx", ",", "hs", "=", "hs", ")", "if", "self", ".", "skipConnect", "else", "self", ".", "decoder", ".", "step", "(", "\n", "src_encoding", ",", "hx", "=", "hx", ")", "\n", "\n", "# arc_h size [num_hyp, 1, arc_space]", "\n", "arc_h", "=", "F", ".", "elu", "(", "self", ".", "arc_h", "(", "output_dec", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "# type_h size [num_hyp, type_space]", "\n", "type_h", "=", "F", ".", "elu", "(", "self", ".", "type_h", "(", "output_dec", ")", ")", "\n", "\n", "# [num_hyp, length_encoder]", "\n", "if", "self", ".", "attention", ".", "use_features", ":", "\n", "# len-d == 1", "\n", "                ", "child_pos", "=", "input_pos", ".", "expand", "(", "num_hyp", ",", "*", "input_pos", ".", "size", "(", ")", ")", "# [num-hyp, len-e]", "\n", "head_pos", "=", "input_pos", "[", "heads", "]", ".", "unsqueeze", "(", "-", "1", ")", "# [num-hyp, 1]", "\n", "child_position_idxes", "=", "torch", ".", "arange", "(", "length", ")", ".", "type_as", "(", "input_pos", ".", "data", ")", ".", "long", "(", ")", ".", "expand", "(", "num_hyp", ",", "\n", "-", "1", ")", ".", "unsqueeze", "(", "\n", "-", "2", ")", "# [batch, 1, len-e]", "\n", "head_position_idxes", "=", "heads", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# [batch, 1, 1]", "\n", "raw_distances", "=", "head_position_idxes", "-", "child_position_idxes", "# [batch, 1, len-e]", "\n", "input_features", "=", "self", ".", "attention_helper", ".", "get_final_features", "(", "raw_distances", ",", "child_pos", ".", "data", ",", "head_pos", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "input_features", "=", "None", "\n", "", "out_arc", "=", "self", ".", "attention", "(", "arc_h", ",", "arc_c", ".", "expand", "(", "num_hyp", ",", "*", "arc_c", ".", "size", "(", ")", ")", ",", "\n", "input_features", "=", "input_features", ")", ".", "squeeze", "(", "dim", "=", "1", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n", "# [num_hyp, length_encoder]", "\n", "hyp_scores", "=", "F", ".", "log_softmax", "(", "out_arc", ",", "dim", "=", "1", ")", ".", "data", "\n", "\n", "new_hypothesis_scores", "=", "hypothesis_scores", "[", ":", "num_hyp", "]", ".", "unsqueeze", "(", "1", ")", "+", "hyp_scores", "\n", "# [num_hyp * length_encoder]", "\n", "new_hypothesis_scores", ",", "hyp_index", "=", "torch", ".", "sort", "(", "new_hypothesis_scores", ".", "view", "(", "-", "1", ")", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "base_index", "=", "hyp_index", "/", "length", "\n", "child_index", "=", "hyp_index", "%", "length", "\n", "\n", "cc", "=", "0", "\n", "ids", "=", "[", "]", "\n", "new_constraints", "=", "np", ".", "zeros", "(", "[", "beam", ",", "length", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "new_child_orders", "=", "np", ".", "zeros", "(", "[", "beam", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "id", "in", "range", "(", "num_hyp", "*", "length", ")", ":", "\n", "                ", "base_id", "=", "base_index", "[", "id", "]", "\n", "child_id", "=", "child_index", "[", "id", "]", "\n", "head", "=", "heads", "[", "base_id", "]", "\n", "new_hyp_score", "=", "new_hypothesis_scores", "[", "id", "]", "\n", "if", "child_id", "==", "head", ":", "\n", "                    ", "assert", "constraints", "[", "base_id", ",", "child_id", "]", ",", "'constrains error: %d, %d'", "%", "(", "base_id", ",", "child_id", ")", "\n", "if", "head", "!=", "0", "or", "t", "+", "1", "==", "num_step", ":", "\n", "                        ", "new_constraints", "[", "cc", "]", "=", "constraints", "[", "base_id", "]", "\n", "new_child_orders", "[", "cc", "]", "=", "child_orders", "[", "base_id", "]", "\n", "\n", "new_stacked_heads", "[", "cc", "]", "=", "[", "stacked_heads", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "stacked_heads", "[", "base_id", "]", ")", ")", "]", "\n", "new_stacked_heads", "[", "cc", "]", ".", "pop", "(", ")", "\n", "\n", "if", "self", ".", "grandPar", ":", "\n", "                            ", "new_grand_parents", "[", "cc", "]", "=", "[", "grand_parents", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "\n", "range", "(", "len", "(", "grand_parents", "[", "base_id", "]", ")", ")", "]", "\n", "new_grand_parents", "[", "cc", "]", ".", "pop", "(", ")", "\n", "\n", "", "if", "self", ".", "sibling", ":", "\n", "                            ", "new_siblings", "[", "cc", "]", "=", "[", "siblings", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "siblings", "[", "base_id", "]", ")", ")", "]", "\n", "\n", "", "if", "self", ".", "skipConnect", ":", "\n", "                            ", "new_skip_connects", "[", "cc", "]", "=", "[", "skip_connects", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "\n", "range", "(", "len", "(", "skip_connects", "[", "base_id", "]", ")", ")", "]", "\n", "\n", "", "new_children", "[", "cc", "]", "=", "children", "[", "base_id", "]", "\n", "new_children", "[", "cc", ",", "t", "]", "=", "child_id", "\n", "\n", "hypothesis_scores", "[", "cc", "]", "=", "new_hyp_score", "\n", "ids", ".", "append", "(", "id", ")", "\n", "cc", "+=", "1", "\n", "", "", "elif", "valid_hyp", "(", "base_id", ",", "child_id", ",", "head", ")", ":", "\n", "                    ", "new_constraints", "[", "cc", "]", "=", "constraints", "[", "base_id", "]", "\n", "new_constraints", "[", "cc", ",", "child_id", "]", "=", "True", "\n", "\n", "new_child_orders", "[", "cc", "]", "=", "child_orders", "[", "base_id", "]", "\n", "new_child_orders", "[", "cc", ",", "head", "]", "=", "child_id", "\n", "\n", "new_stacked_heads", "[", "cc", "]", "=", "[", "stacked_heads", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "stacked_heads", "[", "base_id", "]", ")", ")", "]", "\n", "new_stacked_heads", "[", "cc", "]", ".", "append", "(", "child_id", ")", "\n", "\n", "if", "self", ".", "grandPar", ":", "\n", "                        ", "new_grand_parents", "[", "cc", "]", "=", "[", "grand_parents", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "grand_parents", "[", "base_id", "]", ")", ")", "]", "\n", "new_grand_parents", "[", "cc", "]", ".", "append", "(", "head", ")", "\n", "\n", "", "if", "self", ".", "sibling", ":", "\n", "                        ", "new_siblings", "[", "cc", "]", "=", "[", "siblings", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "siblings", "[", "base_id", "]", ")", ")", "]", "\n", "new_siblings", "[", "cc", "]", ".", "append", "(", "child_id", ")", "\n", "new_siblings", "[", "cc", "]", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "self", ".", "skipConnect", ":", "\n", "                        ", "new_skip_connects", "[", "cc", "]", "=", "[", "skip_connects", "[", "base_id", "]", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "skip_connects", "[", "base_id", "]", ")", ")", "]", "\n", "# hack to handle LSTM", "\n", "if", "isinstance", "(", "hx", ",", "tuple", ")", ":", "\n", "                            ", "new_skip_connects", "[", "cc", "]", ".", "append", "(", "hx", "[", "0", "]", "[", ":", ",", "base_id", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "                            ", "new_skip_connects", "[", "cc", "]", ".", "append", "(", "hx", "[", ":", ",", "base_id", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "new_skip_connects", "[", "cc", "]", ".", "append", "(", "h0", ")", "\n", "\n", "", "new_children", "[", "cc", "]", "=", "children", "[", "base_id", "]", "\n", "new_children", "[", "cc", ",", "t", "]", "=", "child_id", "\n", "\n", "hypothesis_scores", "[", "cc", "]", "=", "new_hyp_score", "\n", "ids", ".", "append", "(", "id", ")", "\n", "cc", "+=", "1", "\n", "\n", "", "if", "cc", "==", "beam", ":", "\n", "                    ", "break", "\n", "\n", "# [num_hyp]", "\n", "", "", "num_hyp", "=", "len", "(", "ids", ")", "\n", "if", "num_hyp", "==", "0", ":", "\n", "                ", "return", "None", "\n", "", "elif", "num_hyp", "==", "1", ":", "\n", "                ", "index", "=", "base_index", ".", "new", "(", "1", ")", ".", "fill_", "(", "ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "index", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "ids", ")", ")", ".", "type_as", "(", "base_index", ")", "\n", "", "base_index", "=", "base_index", "[", "index", "]", "\n", "child_index", "=", "child_index", "[", "index", "]", "\n", "\n", "# predict types for new hypotheses", "\n", "# compute output for type [num_hyp, num_labels]", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", "[", "base_index", "]", ",", "type_c", "[", "child_index", "]", ")", "\n", "hyp_type_scores", "=", "F", ".", "log_softmax", "(", "out_type", ",", "dim", "=", "1", ")", ".", "data", "\n", "# compute the prediction of types [num_hyp]", "\n", "hyp_type_scores", ",", "hyp_types", "=", "hyp_type_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "hypothesis_scores", "[", ":", "num_hyp", "]", "=", "hypothesis_scores", "[", ":", "num_hyp", "]", "+", "hyp_type_scores", "\n", "\n", "for", "i", "in", "range", "(", "num_hyp", ")", ":", "\n", "                ", "base_id", "=", "base_index", "[", "i", "]", "\n", "new_stacked_types", "[", "i", "]", "=", "stacked_types", "[", "base_id", "]", "\n", "new_stacked_types", "[", "i", ",", "t", "]", "=", "hyp_types", "[", "i", "]", "\n", "\n", "", "stacked_heads", "=", "[", "[", "new_stacked_heads", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "len", "(", "new_stacked_heads", "[", "i", "]", ")", ")", "]", "for", "i", "in", "\n", "range", "(", "num_hyp", ")", "]", "\n", "if", "self", ".", "grandPar", ":", "\n", "                ", "grand_parents", "=", "[", "[", "new_grand_parents", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "len", "(", "new_grand_parents", "[", "i", "]", ")", ")", "]", "for", "i", "in", "\n", "range", "(", "num_hyp", ")", "]", "\n", "", "if", "self", ".", "sibling", ":", "\n", "                ", "siblings", "=", "[", "[", "new_siblings", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "len", "(", "new_siblings", "[", "i", "]", ")", ")", "]", "for", "i", "in", "range", "(", "num_hyp", ")", "]", "\n", "", "if", "self", ".", "skipConnect", ":", "\n", "                ", "skip_connects", "=", "[", "[", "new_skip_connects", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "len", "(", "new_skip_connects", "[", "i", "]", ")", ")", "]", "for", "i", "in", "\n", "range", "(", "num_hyp", ")", "]", "\n", "", "constraints", "=", "new_constraints", "\n", "child_orders", "=", "new_child_orders", "\n", "children", ".", "copy_", "(", "new_children", ")", "\n", "stacked_types", ".", "copy_", "(", "new_stacked_types", ")", "\n", "# hx [decoder_layers, num_hyp, hidden_size]", "\n", "# hack to handle LSTM", "\n", "if", "isinstance", "(", "hx", ",", "tuple", ")", ":", "\n", "                ", "hx", ",", "cx", "=", "hx", "\n", "hx", "=", "hx", "[", ":", ",", "base_index", ",", ":", "]", "\n", "cx", "=", "cx", "[", ":", ",", "base_index", ",", ":", "]", "\n", "hx", "=", "(", "hx", ",", "cx", ")", "\n", "", "else", ":", "\n", "                ", "hx", "=", "hx", "[", ":", ",", "base_index", ",", ":", "]", "\n", "\n", "", "", "children", "=", "children", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "stacked_types", "=", "stacked_types", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "heads", "=", "np", ".", "zeros", "(", "length", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "types", "=", "np", ".", "zeros", "(", "length", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "stack", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "num_step", ")", ":", "\n", "            ", "head", "=", "stack", "[", "-", "1", "]", "\n", "child", "=", "children", "[", "i", "]", "\n", "type", "=", "stacked_types", "[", "i", "]", "\n", "if", "child", "!=", "head", ":", "\n", "                ", "heads", "[", "child", "]", "=", "head", "\n", "types", "[", "child", "]", "=", "type", "\n", "stack", ".", "append", "(", "child", ")", "\n", "", "else", ":", "\n", "                ", "stacked_types", "[", "i", "]", "=", "0", "\n", "stack", ".", "pop", "(", ")", "\n", "\n", "", "", "return", "heads", ",", "types", ",", "length", ",", "children", ",", "stacked_types", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode": [[1120, 1170], ["parsing.StackPtrNet.decoder.reset_noise", "parsing.StackPtrNet._get_encoder_output", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "parsing.StackPtrNet._transform_decoder_init_state", "output_enc.size", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "parsing.StackPtrNet.arc_c", "parsing.StackPtrNet.type_c", "isinstance", "parsing.StackPtrNet._decode_per_sentence", "hx[].contiguous", "cx[].contiguous", "hn[].contiguous", "parsing.StackPtrNet._decode_per_sentence"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.modules.variational_rnn.VarFastGRUCell.reset_noise", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._get_encoder_output", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._transform_decoder_init_state", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._decode_per_sentence", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet._decode_per_sentence"], ["", "def", "decode", "(", "self", ",", "input_word", ",", "input_char", ",", "input_pos", ",", "mask", "=", "None", ",", "length", "=", "None", ",", "hx", "=", "None", ",", "beam", "=", "1", ",", "leading_symbolic", "=", "0", ",", "\n", "ordered", "=", "True", ")", ":", "\n", "# reset noise for decoder", "\n", "        ", "self", ".", "decoder", ".", "reset_noise", "(", "0", ")", "\n", "\n", "# output from encoder [batch, length_encoder, tag_space]", "\n", "# output_enc [batch, length, input_size]", "\n", "# arc_c [batch, length, arc_space]", "\n", "# type_c [batch, length, type_space]", "\n", "# hn [num_direction, batch, hidden_size]", "\n", "output_enc", ",", "hn", ",", "mask", ",", "length", "=", "self", ".", "_get_encoder_output", "(", "input_word", ",", "input_char", ",", "input_pos", ",", "mask_e", "=", "mask", ",", "\n", "length_e", "=", "length", ",", "hx", "=", "hx", ")", "\n", "# output size [batch, length_encoder, arc_space]", "\n", "arc_c", "=", "F", ".", "elu", "(", "self", ".", "arc_c", "(", "output_enc", ")", ")", "\n", "# output size [batch, length_encoder, type_space]", "\n", "type_c", "=", "F", ".", "elu", "(", "self", ".", "type_c", "(", "output_enc", ")", ")", "\n", "# [decoder_layers, batch, hidden_size", "\n", "hn", "=", "self", ".", "_transform_decoder_init_state", "(", "hn", ")", "\n", "batch", ",", "max_len_e", ",", "_", "=", "output_enc", ".", "size", "(", ")", "\n", "\n", "heads", "=", "np", ".", "zeros", "(", "[", "batch", ",", "max_len_e", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "types", "=", "np", ".", "zeros", "(", "[", "batch", ",", "max_len_e", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "children", "=", "np", ".", "zeros", "(", "[", "batch", ",", "2", "*", "max_len_e", "-", "1", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "stack_types", "=", "np", ".", "zeros", "(", "[", "batch", ",", "2", "*", "max_len_e", "-", "1", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "for", "b", "in", "range", "(", "batch", ")", ":", "\n", "            ", "sent_len", "=", "None", "if", "length", "is", "None", "else", "length", "[", "b", "]", "\n", "# hack to handle LSTM", "\n", "if", "isinstance", "(", "hn", ",", "tuple", ")", ":", "\n", "                ", "hx", ",", "cx", "=", "hn", "\n", "hx", "=", "hx", "[", ":", ",", "b", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "cx", "=", "cx", "[", ":", ",", "b", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "hx", "=", "(", "hx", ",", "cx", ")", "\n", "", "else", ":", "\n", "                ", "hx", "=", "hn", "[", ":", ",", "b", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "preds", "=", "self", ".", "_decode_per_sentence", "(", "output_enc", "[", "b", "]", ",", "arc_c", "[", "b", "]", ",", "type_c", "[", "b", "]", ",", "hx", ",", "sent_len", ",", "beam", ",", "ordered", ",", "\n", "leading_symbolic", ",", "input_pos", "[", "b", "]", ")", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "self", ".", "_decode_per_sentence", "(", "output_enc", "[", "b", "]", ",", "arc_c", "[", "b", "]", ",", "type_c", "[", "b", "]", ",", "hx", ",", "sent_len", ",", "beam", ",", "False", ",", "\n", "leading_symbolic", ",", "input_pos", "[", "b", "]", ")", "\n", "", "hids", ",", "tids", ",", "sent_len", ",", "chids", ",", "stids", "=", "preds", "\n", "heads", "[", "b", ",", ":", "sent_len", "]", "=", "hids", "\n", "types", "[", "b", ",", ":", "sent_len", "]", "=", "tids", "\n", "\n", "children", "[", "b", ",", ":", "2", "*", "sent_len", "-", "1", "]", "=", "chids", "\n", "stack_types", "[", "b", ",", ":", "2", "*", "sent_len", "-", "1", "]", "=", "stids", "\n", "\n", "", "return", "heads", ",", "types", ",", "children", ",", "stack_types", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.util_class.LayerNorm.__init__": [[11, 16], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.util_class.LayerNorm.forward": [[17, 21], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.util_class.aeq": [[23, 31], ["next", "all", "str"], "function", ["None"], ["", "", "def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.encoder.EncoderBase._check_args": [[33, 38], ["src.size", "lengths.size", "util_class.aeq"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.util_class.aeq"], ["def", "_check_args", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "n_batch", ",", "_", ",", "_", "=", "src", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.encoder.EncoderBase.forward": [[39, 51], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (:obj:`LongTensor`):\n               padded sequences of sparse indices `[src_len x batch x nfeat]`\n            lengths (:obj:`LongTensor`): length of each sequence `[batch]`\n        Returns:\n            (tuple of :obj:`FloatTensor`, :obj:`FloatTensor`):\n                * final encoder state, used to initialize decoder\n                * memory bank for attention, `[src_len x batch x hidden]`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.position_ffn.PositionwiseFeedForward.__init__": [[19, 27], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "util_class.LayerNorm", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "relu_drop", "=", "0.1", ",", "res_drop", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "relu_dropout", "=", "nn", ".", "Dropout", "(", "relu_drop", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "residual_dropout", "=", "nn", ".", "Dropout", "(", "res_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.position_ffn.PositionwiseFeedForward.forward": [[28, 39], ["position_ffn.PositionwiseFeedForward.relu_dropout", "position_ffn.PositionwiseFeedForward.residual_dropout", "position_ffn.PositionwiseFeedForward.relu", "position_ffn.PositionwiseFeedForward.w_2", "position_ffn.PositionwiseFeedForward.w_1", "position_ffn.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Layer definition.\n        Args:\n            input: [ batch_size, input_len, model_dim ]\n        Returns:\n            output: [ batch_size, input_len, model_dim ]\n        \"\"\"", "\n", "inter", "=", "self", ".", "relu_dropout", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "residual_dropout", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.multi_head_attn.MultiHeadedAttention.__init__": [[45, 69], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.nn.init.xavier_normal", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "clip_dist", "=", "0", ",", "use_neg_dist", "=", "False", ")", ":", "\n", "        ", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "head_count", "=", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "self", ".", "clip_dist", "=", "clip_dist", "\n", "self", ".", "use_neg_dist", "=", "use_neg_dist", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "head_count", "*", "self", ".", "d_k", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "head_count", "*", "self", ".", "d_k", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "head_count", "*", "self", ".", "d_v", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "self", ".", "head_count", "*", "d_v", ",", "model_dim", ")", "\n", "\n", "# for relative-position aware self-attention", "\n", "if", "self", ".", "clip_dist", ">", "0", ":", "\n", "            ", "self", ".", "edge_keys", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", "*", "self", ".", "clip_dist", "+", "1", ",", "self", ".", "d_k", ")", ")", "\n", "self", ".", "edge_values", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", "*", "self", ".", "clip_dist", "+", "1", ",", "self", ".", "d_v", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "edge_keys", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal", "(", "self", ".", "edge_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.multi_head_attn.MultiHeadedAttention.forward": [[70, 184], ["key.size", "key.size", "query.size", "multi_head_attn.MultiHeadedAttention.forward.shape"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n        Args:\n           key (`FloatTensor`): set of `key_len`\n                key vectors `[batch, key_len, dim]`\n           value (`FloatTensor`): set of `key_len`\n                value vectors `[batch, key_len, dim]`\n           query (`FloatTensor`): set of `query_len`\n                 query vectors  `[batch, query_len, dim]`\n           mask: binary mask indicating which keys have\n                 non-zero attention `[batch, query_len, key_len]`\n        Returns:\n           (`FloatTensor`, `FloatTensor`) :\n           * output context vectors `[batch, query_len, dim]`\n           * one of the attention vectors `[batch, query_len, key_len]`\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "def", "shape", "(", "x", ",", "dim", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ",", "dim", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim", ")", "\n", "\n", "", "if", "self", ".", "clip_dist", ">", "0", ":", "\n", "            ", "dist_x", "=", "torch", ".", "arange", "(", "0", ",", "key_len", ")", ".", "unsqueeze", "(", "0", ")", "\n", "dist_y", "=", "torch", ".", "arange", "(", "0", ",", "key_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "distance", "=", "dist_x", "-", "dist_y", "\n", "if", "not", "self", ".", "use_neg_dist", ":", "\n", "                ", "distance", "=", "torch", ".", "abs", "(", "distance", ")", "\n", "", "distance", "=", "torch", ".", "clamp", "(", "distance", ",", "min", "=", "-", "self", ".", "clip_dist", ",", "max", "=", "self", ".", "clip_dist", ")", "\n", "distance", "=", "Variable", "(", "(", "distance", "+", "self", ".", "clip_dist", ")", ".", "long", "(", ")", ")", "# [1,1,len,len]", "\n", "# distance = distance.repeat(head_count, 1, 1)  # nhead x seq_len x seq_len", "\n", "# distance = distance.repeat(batch_size, 1, 1, 1)  # bsz x nhead x seq_len x seq_len", "\n", "distance", "=", "distance", ".", "cuda", "(", ")", "if", "key", ".", "is_cuda", "else", "distance", "\n", "\n", "# 1) Project key, value, and query.", "\n", "# key_up: bsz x nhead x key_len x d_k", "\n", "", "key_up", "=", "shape", "(", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "d_k", ")", "# x_j W^K", "\n", "# value_up: bsz x nhead x key_len x d_v", "\n", "value_up", "=", "shape", "(", "self", ".", "linear_values", "(", "value", ")", ",", "self", ".", "d_v", ")", "# x_j W^V", "\n", "# query_up: bsz x nhead x query_len x d_k", "\n", "query_up", "=", "shape", "(", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "d_k", ")", "# x_j W^Q", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query_up", "=", "query_up", "/", "math", ".", "sqrt", "(", "self", ".", "d_k", ")", "# (x_j W^Q) / sqrt(d_k)", "\n", "# bsz x nhead x query_len x key_len", "\n", "scores", "=", "torch", ".", "matmul", "(", "query_up", ",", "key_up", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "if", "self", ".", "clip_dist", ">", "0", ":", "\n", "            ", "out", "=", "self", ".", "edge_keys", ".", "index_select", "(", "0", ",", "distance", ".", "view", "(", "-", "1", ")", ")", "\n", "# 1 x 1 x key_len x key_len x d_k", "\n", "# out = out.view(1, 1, query_len, query_len, self.d_k).contiguous()", "\n", "out", "=", "out", ".", "view", "(", "1", ",", "1", ",", "query_len", ",", "query_len", ",", "self", ".", "d_k", ")", "\n", "# bsz x nhead x query_len x key_len", "\n", "add_term", "=", "torch", ".", "matmul", "(", "query_up", ".", "unsqueeze", "(", "3", ")", ",", "out", ".", "transpose", "(", "3", ",", "4", ")", ")", ".", "squeeze", "(", "3", ")", "\n", "scores", "=", "scores", "+", "add_term", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e20", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "# bsz x nhead x seq_len x seq_len", "\n", "context", "=", "torch", ".", "matmul", "(", "drop_attn", ",", "value_up", ")", "# bsz x nhead x seq_len x d_v", "\n", "if", "self", ".", "clip_dist", ">", "0", ":", "\n", "# TODO: modify `value_up` tensor to add a_{ij}^V [Eq.3 in https://arxiv.org/pdf/1803.02155.pdf]", "\n", "# also split Eq.3 to save space", "\n", "            ", "out", "=", "self", ".", "edge_values", ".", "index_select", "(", "0", ",", "distance", ".", "view", "(", "-", "1", ")", ")", "\n", "# 1 x 1 x key_len x key_len x dim", "\n", "# out = out.view(1, 1, key_len, key_len, self.d_v).contiguous()", "\n", "out", "=", "out", ".", "view", "(", "1", ",", "1", ",", "key_len", ",", "key_len", ",", "self", ".", "d_v", ")", "\n", "add_term", "=", "torch", ".", "matmul", "(", "drop_attn", ".", "unsqueeze", "(", "3", ")", ",", "out", ")", ".", "squeeze", "(", "3", ")", "# bsz x nhead x seq_len x d_v", "\n", "context", "=", "context", "+", "add_term", "\n", "\n", "# bsz x nhead x seq_len x d_v --> bsz x seq_len x (nhead * d_v)", "\n", "", "context", "=", "unshape", "(", "context", ",", "self", ".", "d_v", ")", "\n", "\n", "# bsz x seq_len x (nhead * d_v) --> bsz x seq_len x model_dim", "\n", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "batch_size", ",", "head_count", ",", "query_len", ",", "key_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoderLayer.__init__": [[25, 35], ["torch.Module.__init__", "multi_head_attn.MultiHeadedAttention", "position_ffn.PositionwiseFeedForward", "util_class.LayerNorm", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "d_k", ",", "d_v", ",", "\n", "attn_drop", ",", "relu_drop", ",", "res_drop", ",", "clip_dist", "=", "0", ",", "use_neg_dist", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerEncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn", "=", "MultiHeadedAttention", "(", "heads", ",", "d_model", ",", "d_k", ",", "d_v", ",", "\n", "dropout", "=", "attn_drop", ",", "\n", "clip_dist", "=", "clip_dist", ",", "use_neg_dist", "=", "use_neg_dist", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "relu_drop", ",", "res_drop", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "res_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoderLayer.forward": [[36, 50], ["transformer.TransformerEncoderLayer.layer_norm", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.feed_forward", "transformer.TransformerEncoderLayer.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Transformer Encoder Layer definition.\n        Args:\n            inputs (`FloatTensor`): `[batch_size x src_len x model_dim]`\n            mask (`LongTensor`): `[batch_size x src_len x src_len]`\n        Returns:\n            (`FloatTensor`):\n            * outputs `[batch_size x src_len x model_dim]`\n        \"\"\"", "\n", "input_norm", "=", "self", ".", "layer_norm", "(", "inputs", ")", "\n", "context", ",", "_", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "mask", "=", "mask", ")", "\n", "out", "=", "self", ".", "dropout", "(", "context", ")", "+", "inputs", "\n", "return", "self", ".", "feed_forward", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.__init__": [[78, 91], ["encoder.EncoderBase.__init__", "torch.ModuleList", "util_class.LayerNorm", "transformer.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "d_model", ",", "heads", ",", "\n", "d_ff", ",", "d_k", ",", "d_v", ",", "\n", "attn_drop", ",", "relu_drop", ",", "res_drop", ",", "\n", "clip_dist", "=", "0", ",", "use_neg_dist", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "transformer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "d_model", ",", "heads", ",", "d_ff", ",", "d_k", ",", "d_v", ",", "\n", "attn_drop", ",", "relu_drop", ",", "res_drop", ",", "\n", "clip_dist", "=", "clip_dist", ",", "use_neg_dist", "=", "use_neg_dist", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.transformer.TransformerEncoder.forward": [[92, 103], ["transformer.TransformerEncoder._check_args", "range", "transformer.TransformerEncoder.layer_norm"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.transformer.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "emb", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "emb", ",", "lengths", ")", "\n", "\n", "out", "=", "emb", "\n", "# Run the forward pass of every layer of the tranformer.", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "out", "=", "self", ".", "transformer", "[", "i", "]", "(", "out", ",", "mask", "=", "None", ")", "\n", "", "out", "=", "self", ".", "layer_norm", "(", "out", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLL03Writer.__init__": [[5, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "None", "\n", "self", ".", "__word_alphabet", "=", "word_alphabet", "\n", "self", ".", "__char_alphabet", "=", "char_alphabet", "\n", "self", ".", "__pos_alphabet", "=", "pos_alphabet", "\n", "self", ".", "__chunk_alphabet", "=", "chunk_alphabet", "\n", "self", ".", "__ner_alphabet", "=", "ner_alphabet", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLL03Writer.start": [[13, 15], ["open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["", "def", "start", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "open", "(", "file_path", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLL03Writer.close": [[16, 18], ["writer.CoNLL03Writer.__source_file.close"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "__source_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLL03Writer.write": [[19, 30], ["range", "range", "writer.CoNLL03Writer.__source_file.write", "writer.CoNLL03Writer.__word_alphabet.get_instance().encode", "writer.CoNLL03Writer.__pos_alphabet.get_instance().encode", "writer.CoNLL03Writer.__chunk_alphabet.get_instance().encode", "writer.CoNLL03Writer.__ner_alphabet.get_instance().encode", "writer.CoNLL03Writer.__ner_alphabet.get_instance().encode", "writer.CoNLL03Writer.__source_file.write", "writer.CoNLL03Writer.__word_alphabet.get_instance", "writer.CoNLL03Writer.__pos_alphabet.get_instance", "writer.CoNLL03Writer.__chunk_alphabet.get_instance", "writer.CoNLL03Writer.__ner_alphabet.get_instance", "writer.CoNLL03Writer.__ner_alphabet.get_instance"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance"], ["", "def", "write", "(", "self", ",", "word", ",", "pos", ",", "chunk", ",", "predictions", ",", "targets", ",", "lengths", ")", ":", "\n", "        ", "batch_size", ",", "_", "=", "word", ".", "shape", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "lengths", "[", "i", "]", ")", ":", "\n", "                ", "w", "=", "self", ".", "__word_alphabet", ".", "get_instance", "(", "word", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "p", "=", "self", ".", "__pos_alphabet", ".", "get_instance", "(", "pos", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "ch", "=", "self", ".", "__chunk_alphabet", ".", "get_instance", "(", "chunk", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "tgt", "=", "self", ".", "__ner_alphabet", ".", "get_instance", "(", "targets", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "pred", "=", "self", ".", "__ner_alphabet", ".", "get_instance", "(", "predictions", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "self", ".", "__source_file", ".", "write", "(", "'%d %s %s %s %s %s\\n'", "%", "(", "j", "+", "1", ",", "w", ",", "p", ",", "ch", ",", "tgt", ",", "pred", ")", ")", "\n", "", "self", ".", "__source_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.__init__": [[33, 39], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "None", "\n", "self", ".", "__word_alphabet", "=", "word_alphabet", "\n", "self", ".", "__char_alphabet", "=", "char_alphabet", "\n", "self", ".", "__pos_alphabet", "=", "pos_alphabet", "\n", "self", ".", "__type_alphabet", "=", "type_alphabet", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.start": [[40, 42], ["open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["", "def", "start", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "open", "(", "file_path", ",", "'w'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.close": [[43, 45], ["writer.CoNLLXWriter.__source_file.close"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "__source_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write": [[46, 58], ["range", "range", "writer.CoNLLXWriter.__source_file.write", "writer.CoNLLXWriter.__word_alphabet.get_instance().encode", "writer.CoNLLXWriter.__pos_alphabet.get_instance().encode", "writer.CoNLLXWriter.__type_alphabet.get_instance().encode", "writer.CoNLLXWriter.__source_file.write", "writer.CoNLLXWriter.__word_alphabet.get_instance", "writer.CoNLLXWriter.__pos_alphabet.get_instance", "writer.CoNLLXWriter.__type_alphabet.get_instance"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.writer.CoNLLXWriter.write", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance"], ["", "def", "write", "(", "self", ",", "word", ",", "pos", ",", "head", ",", "type", ",", "lengths", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ")", ":", "\n", "        ", "batch_size", ",", "_", "=", "word", ".", "shape", "\n", "start", "=", "1", "if", "symbolic_root", "else", "0", "\n", "end", "=", "1", "if", "symbolic_end", "else", "0", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "start", ",", "lengths", "[", "i", "]", "-", "end", ")", ":", "\n", "                ", "w", "=", "self", ".", "__word_alphabet", ".", "get_instance", "(", "word", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "p", "=", "self", ".", "__pos_alphabet", ".", "get_instance", "(", "pos", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "t", "=", "self", ".", "__type_alphabet", ".", "get_instance", "(", "type", "[", "i", ",", "j", "]", ")", ".", "encode", "(", "'utf-8'", ")", "\n", "h", "=", "head", "[", "i", ",", "j", "]", "\n", "self", ".", "__source_file", ".", "write", "(", "'%d\\t%s\\t_\\t_\\t%s\\t_\\t%d\\t%s\\n'", "%", "(", "j", ",", "w", ",", "p", ",", "h", ",", "t", ")", ")", "\n", "", "self", ".", "__source_file", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.create_alphabets": [[31, 148], ["logger.get_logger", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "set", "os.path.isdir", "logger.get_logger.info", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "dict", "set", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "open", "dict.keys", "sorted", "len", "conll03_data.create_alphabets.expand_vocab"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["def", "create_alphabets", "(", "alphabet_directory", ",", "train_path", ",", "data_paths", "=", "None", ",", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "None", ",", "\n", "min_occurence", "=", "1", ",", "normalize_digits", "=", "True", ")", ":", "\n", "\n", "    ", "def", "expand_vocab", "(", ")", ":", "\n", "        ", "vocab_set", "=", "set", "(", "vocab_list", ")", "\n", "for", "data_path", "in", "data_paths", ":", "\n", "# logger.info(\"Processing data: %s\" % data_path)", "\n", "            ", "with", "open", "(", "data_path", ",", "'r'", ")", "as", "file", ":", "\n", "                ", "for", "line", "in", "file", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", "' '", ")", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "2", "]", "\n", "chunk", "=", "tokens", "[", "3", "]", "\n", "ner", "=", "tokens", "[", "4", "]", "\n", "\n", "pos_alphabet", ".", "add", "(", "pos", ")", "\n", "chunk_alphabet", ".", "add", "(", "chunk", ")", "\n", "ner_alphabet", ".", "add", "(", "ner", ")", "\n", "\n", "if", "word", "not", "in", "vocab_set", "and", "(", "word", "in", "embedd_dict", "or", "word", ".", "lower", "(", ")", "in", "embedd_dict", ")", ":", "\n", "                        ", "vocab_set", ".", "add", "(", "word", ")", "\n", "vocab_list", ".", "append", "(", "word", ")", "\n", "\n", "", "", "", "", "", "logger", "=", "get_logger", "(", "\"Create Alphabets\"", ")", "\n", "word_alphabet", "=", "Alphabet", "(", "'word'", ",", "defualt_value", "=", "True", ",", "singleton", "=", "True", ")", "\n", "char_alphabet", "=", "Alphabet", "(", "'character'", ",", "defualt_value", "=", "True", ")", "\n", "pos_alphabet", "=", "Alphabet", "(", "'pos'", ")", "\n", "chunk_alphabet", "=", "Alphabet", "(", "'chunk'", ")", "\n", "ner_alphabet", "=", "Alphabet", "(", "'ner'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "alphabet_directory", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating Alphabets: %s\"", "%", "alphabet_directory", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "PAD_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "PAD_POS", ")", "\n", "chunk_alphabet", ".", "add", "(", "PAD_CHUNK", ")", "\n", "ner_alphabet", ".", "add", "(", "PAD_NER", ")", "\n", "\n", "vocab", "=", "dict", "(", ")", "\n", "with", "open", "(", "train_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", "' '", ")", "\n", "for", "char", "in", "tokens", "[", "1", "]", ":", "\n", "                    ", "char_alphabet", ".", "add", "(", "char", ")", "\n", "\n", "", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "2", "]", "\n", "chunk", "=", "tokens", "[", "3", "]", "\n", "ner", "=", "tokens", "[", "4", "]", "\n", "\n", "pos_alphabet", ".", "add", "(", "pos", ")", "\n", "chunk_alphabet", ".", "add", "(", "chunk", ")", "\n", "ner_alphabet", ".", "add", "(", "ner", ")", "\n", "\n", "if", "word", "in", "vocab", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "vocab", "[", "word", "]", "=", "1", "\n", "# collect singletons", "\n", "", "", "", "singletons", "=", "set", "(", "[", "word", "for", "word", ",", "count", "in", "vocab", ".", "items", "(", ")", "if", "count", "<=", "min_occurence", "]", ")", "\n", "\n", "# if a singleton is in pretrained embedding dict, set the count to min_occur + c", "\n", "if", "embedd_dict", "is", "not", "None", ":", "\n", "            ", "for", "word", "in", "vocab", ".", "keys", "(", ")", ":", "\n", "                ", "if", "word", "in", "embedd_dict", "or", "word", ".", "lower", "(", ")", "in", "embedd_dict", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "min_occurence", "\n", "\n", "", "", "", "vocab_list", "=", "_START_VOCAB", "+", "sorted", "(", "vocab", ",", "key", "=", "vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size: %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "logger", ".", "info", "(", "\"Total Singleton Size:  %d\"", "%", "len", "(", "singletons", ")", ")", "\n", "vocab_list", "=", "[", "word", "for", "word", "in", "vocab_list", "if", "word", "in", "_START_VOCAB", "or", "vocab", "[", "word", "]", ">", "min_occurence", "]", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size (w.o rare words): %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "\n", "if", "len", "(", "vocab_list", ")", ">", "max_vocabulary_size", ":", "\n", "            ", "vocab_list", "=", "vocab_list", "[", ":", "max_vocabulary_size", "]", "\n", "\n", "", "if", "data_paths", "is", "not", "None", "and", "embedd_dict", "is", "not", "None", ":", "\n", "            ", "expand_vocab", "(", ")", "\n", "\n", "", "for", "word", "in", "vocab_list", ":", "\n", "            ", "word_alphabet", ".", "add", "(", "word", ")", "\n", "if", "word", "in", "singletons", ":", "\n", "                ", "word_alphabet", ".", "add_singleton", "(", "word_alphabet", ".", "get_index", "(", "word", ")", ")", "\n", "\n", "", "", "word_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "chunk_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "ner_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "", "else", ":", "\n", "        ", "word_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "chunk_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "ner_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "\n", "", "word_alphabet", ".", "close", "(", ")", "\n", "char_alphabet", ".", "close", "(", ")", "\n", "pos_alphabet", ".", "close", "(", ")", "\n", "chunk_alphabet", ".", "close", "(", ")", "\n", "ner_alphabet", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size (Singleton): %d (%d)\"", "%", "(", "word_alphabet", ".", "size", "(", ")", ",", "word_alphabet", ".", "singleton_size", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "char_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "pos_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Chunk Alphabet Size: %d\"", "%", "chunk_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"NER Alphabet Size: %d\"", "%", "ner_alphabet", ".", "size", "(", ")", ")", "\n", "return", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.read_data": [[150, 177], ["print", "reader.CoNLL03Reader", "reader.CoNLL03Reader.getNext", "reader.CoNLL03Reader.close", "print", "reader.getNext.length", "enumerate", "reader.CoNLL03Reader.getNext", "print", "data[].append", "max", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext"], ["", "def", "read_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", ",", "max_size", "=", "None", ",", "\n", "normalize_digits", "=", "True", ")", ":", "\n", "    ", "data", "=", "[", "[", "]", "for", "_", "in", "_buckets", "]", "\n", "max_char_length", "=", "[", "0", "for", "_", "in", "_buckets", "]", "\n", "print", "(", "'Reading data from %s'", "%", "source_path", ")", "\n", "counter", "=", "0", "\n", "reader", "=", "CoNLL03Reader", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", ")", "\n", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", ")", "\n", "while", "inst", "is", "not", "None", "and", "(", "not", "max_size", "or", "counter", "<", "max_size", ")", ":", "\n", "        ", "counter", "+=", "1", "\n", "if", "counter", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\"reading data: %d\"", "%", "counter", ")", "\n", "\n", "", "inst_size", "=", "inst", ".", "length", "(", ")", "\n", "sent", "=", "inst", ".", "sentence", "\n", "for", "bucket_id", ",", "bucket_size", "in", "enumerate", "(", "_buckets", ")", ":", "\n", "            ", "if", "inst_size", "<", "bucket_size", ":", "\n", "                ", "data", "[", "bucket_id", "]", ".", "append", "(", "[", "sent", ".", "word_ids", ",", "sent", ".", "char_id_seqs", ",", "inst", ".", "pos_ids", ",", "inst", ".", "chunk_ids", ",", "inst", ".", "ner_ids", "]", ")", "\n", "max_len", "=", "max", "(", "[", "len", "(", "char_seq", ")", "for", "char_seq", "in", "sent", ".", "char_seqs", "]", ")", "\n", "if", "max_char_length", "[", "bucket_id", "]", "<", "max_len", ":", "\n", "                    ", "max_char_length", "[", "bucket_id", "]", "=", "max_len", "\n", "", "break", "\n", "\n", "", "", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", ")", "\n", "", "reader", ".", "close", "(", ")", "\n", "print", "(", "\"Total number of data: %d\"", "%", "counter", ")", "\n", "return", "data", ",", "max_char_length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.get_batch": [[179, 240], ["float", "numpy.random.random_sample", "min", "min", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "range", "len", "sum", "random.choice", "len", "enumerate", "numpy.random.binomial", "range", "sum", "range", "enumerate", "len", "len", "range", "word_alphabet.is_singleton", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "def", "get_batch", "(", "data", ",", "batch_size", ",", "word_alphabet", "=", "None", ",", "unk_replace", "=", "0.", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "data", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "# A bucket scale is a list of increasing numbers from 0 to 1 that we'll use", "\n", "# to select a bucket. Length of [scale[i], scale[i+1]] is proportional to", "\n", "# the size if i-th training bucket, as used later.", "\n", "buckets_scale", "=", "[", "sum", "(", "bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "total_size", "for", "i", "in", "range", "(", "len", "(", "bucket_sizes", ")", ")", "]", "\n", "\n", "# Choose a bucket according to data distribution. We pick a random number", "\n", "# in [0, 1] and use the corresponding interval in train_buckets_scale.", "\n", "random_number", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "buckets_scale", ")", ")", "if", "buckets_scale", "[", "i", "]", ">", "random_number", "]", ")", "\n", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "batch_size", "=", "min", "(", "bucket_size", ",", "batch_size", ")", "\n", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "chid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "nid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "wids", ",", "cid_seqs", ",", "pids", ",", "chids", ",", "nids", "=", "random", ".", "choice", "(", "data", "[", "bucket_id", "]", ")", "\n", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "# word ids", "\n", "wid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "            ", "cid_inputs", "[", "b", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "b", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "b", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# chunk ids", "\n", "chid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "chids", "\n", "chid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# ner ids", "\n", "nid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "nids", "\n", "nid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "b", ",", ":", "inst_size", "]", "=", "1.0", "\n", "\n", "if", "unk_replace", ":", "\n", "            ", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                    ", "single", "[", "b", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "", "if", "unk_replace", ":", "\n", "        ", "noise", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "unk_replace", ",", "size", "=", "[", "batch_size", ",", "bucket_length", "]", ")", "\n", "wid_inputs", "=", "wid_inputs", "*", "(", "1", "-", "noise", "*", "single", ")", "\n", "\n", "", "return", "wid_inputs", ",", "cid_inputs", ",", "pid_inputs", ",", "chid_inputs", ",", "nid_inputs", ",", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.iterate_batch": [[242, 307], ["float", "numpy.arange", "len", "sum", "len", "numpy.random.shuffle", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "enumerate", "range", "range", "len", "enumerate", "numpy.random.binomial", "numpy.arange", "numpy.random.shuffle", "len", "enumerate", "slice", "word_alphabet.is_singleton", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "def", "iterate_batch", "(", "data", ",", "batch_size", ",", "word_alphabet", "=", "None", ",", "unk_replace", "=", "0.", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "data", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "bucket_indices", "=", "np", ".", "arange", "(", "len", "(", "_buckets", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "(", "bucket_indices", ")", ")", "\n", "\n", "", "for", "bucket_id", "in", "bucket_indices", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "chid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "nid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "i", ",", "inst", "in", "enumerate", "(", "data", "[", "bucket_id", "]", ")", ":", "\n", "            ", "wids", ",", "cid_seqs", ",", "pids", ",", "chids", ",", "nids", "=", "inst", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "# word ids", "\n", "wid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "                ", "cid_inputs", "[", "i", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "i", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "i", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# chunk ids", "\n", "chid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "chids", "\n", "chid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# heads", "\n", "nid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "nids", "\n", "nid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "i", ",", ":", "inst_size", "]", "=", "1.0", "\n", "if", "unk_replace", ":", "\n", "                ", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                    ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                        ", "single", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "", "if", "unk_replace", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "unk_replace", ",", "size", "=", "[", "bucket_size", ",", "bucket_length", "]", ")", "\n", "wid_inputs", "=", "wid_inputs", "*", "(", "1", "-", "noise", "*", "single", ")", "\n", "\n", "", "indices", "=", "None", "\n", "if", "shuffle", ":", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "bucket_size", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "bucket_size", ",", "batch_size", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "                ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "wid_inputs", "[", "excerpt", "]", ",", "cid_inputs", "[", "excerpt", "]", ",", "pid_inputs", "[", "excerpt", "]", ",", "chid_inputs", "[", "excerpt", "]", ",", "nid_inputs", "[", "excerpt", "]", ",", "masks", "[", "excerpt", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.read_data_to_variable": [[309, 384], ["conll03_data.read_data", "range", "len", "len", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "numpy.empty", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "data_variable.append", "range", "data_variable.append", "len", "enumerate", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "words.cuda.cuda", "chars.cuda.cuda", "pos.cuda.cuda", "chunks.cuda.cuda", "ners.cuda.cuda", "masks.cuda.cuda", "single.cuda.cuda", "lengths.cuda.cuda", "len", "word_alphabet.is_singleton", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.read_data", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "", "", "def", "read_data_to_variable", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", ",", "\n", "max_size", "=", "None", ",", "normalize_digits", "=", "True", ",", "use_gpu", "=", "False", ",", "volatile", "=", "False", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "read_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "\n", "chunk_alphabet", ",", "ner_alphabet", ",", "\n", "max_size", "=", "max_size", ",", "normalize_digits", "=", "normalize_digits", ")", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "\n", "data_variable", "=", "[", "]", "\n", "\n", "for", "bucket_id", "in", "range", "(", "len", "(", "_buckets", ")", ")", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "data_variable", ".", "append", "(", "(", "1", ",", "1", ")", ")", "\n", "continue", "\n", "\n", "", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "chid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "nid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "lengths", "=", "np", ".", "empty", "(", "bucket_size", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "i", ",", "inst", "in", "enumerate", "(", "data", "[", "bucket_id", "]", ")", ":", "\n", "            ", "wids", ",", "cid_seqs", ",", "pids", ",", "chids", ",", "nids", "=", "inst", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "lengths", "[", "i", "]", "=", "inst_size", "\n", "# word ids", "\n", "wid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "                ", "cid_inputs", "[", "i", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "i", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "i", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# chunk ids", "\n", "chid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "chids", "\n", "chid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# ner ids", "\n", "nid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "nids", "\n", "nid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "i", ",", ":", "inst_size", "]", "=", "1.0", "\n", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                    ", "single", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "words", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "wid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "chars", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "cid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "pos", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "pid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "chunks", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "chid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "ners", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "nid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "masks", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "masks", ")", ",", "volatile", "=", "volatile", ")", "\n", "single", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "single", ")", ",", "volatile", "=", "volatile", ")", "\n", "lengths", "=", "torch", ".", "from_numpy", "(", "lengths", ")", "\n", "if", "use_gpu", ":", "\n", "            ", "words", "=", "words", ".", "cuda", "(", ")", "\n", "chars", "=", "chars", ".", "cuda", "(", ")", "\n", "pos", "=", "pos", ".", "cuda", "(", ")", "\n", "chunks", "=", "chunks", ".", "cuda", "(", ")", "\n", "ners", "=", "ners", ".", "cuda", "(", ")", "\n", "masks", "=", "masks", ".", "cuda", "(", ")", "\n", "single", "=", "single", ".", "cuda", "(", ")", "\n", "lengths", "=", "lengths", ".", "cuda", "(", ")", "\n", "\n", "", "data_variable", ".", "append", "(", "(", "words", ",", "chars", ",", "pos", ",", "chunks", ",", "ners", ",", "masks", ",", "single", ",", "lengths", ")", ")", "\n", "\n", "", "return", "data_variable", ",", "bucket_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.get_batch_variable": [[386, 414], ["float", "numpy.random.random_sample", "min", "min", "sum", "torch.randperm().long", "index.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "sum", "range", "single.data.new().fill_", "masks.data.new().bernoulli_().long", "len", "range", "torch.randperm", "len", "single.data.new", "masks.data.new().bernoulli_", "masks.data.new"], "function", ["None"], ["", "def", "get_batch_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "# A bucket scale is a list of increasing numbers from 0 to 1 that we'll use", "\n", "# to select a bucket. Length of [scale[i], scale[i+1]] is proportional to", "\n", "# the size if i-th training bucket, as used later.", "\n", "buckets_scale", "=", "[", "sum", "(", "bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "total_size", "for", "i", "in", "range", "(", "len", "(", "bucket_sizes", ")", ")", "]", "\n", "\n", "# Choose a bucket according to data distribution. We pick a random number", "\n", "# in [0, 1] and use the corresponding interval in train_buckets_scale.", "\n", "random_number", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "buckets_scale", ")", ")", "if", "buckets_scale", "[", "i", "]", ">", "random_number", "]", ")", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "\n", "words", ",", "chars", ",", "pos", ",", "chunks", ",", "ners", ",", "masks", ",", "single", ",", "lengths", "=", "data_variable", "[", "bucket_id", "]", "\n", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "batch_size", "=", "min", "(", "bucket_size", ",", "batch_size", ")", "\n", "index", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "[", ":", "batch_size", "]", "\n", "if", "words", ".", "is_cuda", ":", "\n", "        ", "index", "=", "index", ".", "cuda", "(", ")", "\n", "\n", "", "words", "=", "words", "[", "index", "]", "\n", "if", "unk_replace", ":", "\n", "        ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "[", "index", "]", "*", "noise", ")", "\n", "\n", "", "return", "words", ",", "chars", "[", "index", "]", ",", "pos", "[", "index", "]", ",", "chunks", "[", "index", "]", ",", "ners", "[", "index", "]", ",", "masks", "[", "index", "]", ",", "lengths", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conll03_data.iterate_batch_variable": [[416, 447], ["numpy.arange", "len", "numpy.random.shuffle", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randperm().long", "single.data.new().fill_", "masks.data.new().bernoulli_().long", "indices.cuda.cuda", "slice", "torch.randperm", "single.data.new", "masks.data.new().bernoulli_", "masks.data.new"], "function", ["None"], ["", "def", "iterate_batch_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "\n", "bucket_indices", "=", "np", ".", "arange", "(", "len", "(", "_buckets", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "(", "bucket_indices", ")", ")", "\n", "\n", "", "for", "bucket_id", "in", "bucket_indices", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "words", ",", "chars", ",", "pos", ",", "chunks", ",", "ners", ",", "masks", ",", "single", ",", "lengths", "=", "data_variable", "[", "bucket_id", "]", "\n", "if", "unk_replace", ":", "\n", "            ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "*", "noise", ")", "\n", "\n", "", "indices", "=", "None", "\n", "if", "shuffle", ":", "\n", "            ", "indices", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "\n", "if", "words", ".", "is_cuda", ":", "\n", "                ", "indices", "=", "indices", ".", "cuda", "(", ")", "\n", "", "", "for", "start_idx", "in", "range", "(", "0", ",", "bucket_size", ",", "batch_size", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "                ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "words", "[", "excerpt", "]", ",", "chars", "[", "excerpt", "]", ",", "pos", "[", "excerpt", "]", ",", "chunks", "[", "excerpt", "]", ",", "ners", "[", "excerpt", "]", ",", "masks", "[", "excerpt", "]", ",", "lengths", "[", "excerpt", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_left2right": [[13, 20], ["range", "len", "child_ids[].append", "range", "len"], "function", ["None"], ["def", "_obtain_child_index_for_left2right", "(", "heads", ")", ":", "\n", "    ", "child_ids", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "# skip the symbolic root.", "\n", "for", "child", "in", "range", "(", "1", ",", "len", "(", "heads", ")", ")", ":", "\n", "        ", "head", "=", "heads", "[", "child", "]", "\n", "child_ids", "[", "head", "]", ".", "append", "(", "child", ")", "\n", "", "return", "child_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_inside_out": [[22, 34], ["range", "len", "reversed", "range", "range", "range", "len", "len", "child_ids[].append", "child_ids[].append"], "function", ["None"], ["", "def", "_obtain_child_index_for_inside_out", "(", "heads", ")", ":", "\n", "    ", "child_ids", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "for", "head", "in", "range", "(", "len", "(", "heads", ")", ")", ":", "\n", "# first find left children inside-out", "\n", "        ", "for", "child", "in", "reversed", "(", "range", "(", "1", ",", "head", ")", ")", ":", "\n", "            ", "if", "heads", "[", "child", "]", "==", "head", ":", "\n", "                ", "child_ids", "[", "head", "]", ".", "append", "(", "child", ")", "\n", "# second find right children inside-out", "\n", "", "", "for", "child", "in", "range", "(", "head", "+", "1", ",", "len", "(", "heads", ")", ")", ":", "\n", "            ", "if", "heads", "[", "child", "]", "==", "head", ":", "\n", "                ", "child_ids", "[", "head", "]", ".", "append", "(", "child", ")", "\n", "", "", "", "return", "child_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_depth": [[36, 51], ["conllx_stacked_data._obtain_child_index_for_left2right", "conllx_stacked_data._obtain_child_index_for_depth.calc_depth"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_left2right"], ["", "def", "_obtain_child_index_for_depth", "(", "heads", ",", "reverse", ")", ":", "\n", "    ", "def", "calc_depth", "(", "head", ")", ":", "\n", "        ", "children", "=", "child_ids", "[", "head", "]", "\n", "max_depth", "=", "0", "\n", "for", "child", "in", "children", ":", "\n", "            ", "depth", "=", "calc_depth", "(", "child", ")", "\n", "child_with_depth", "[", "head", "]", ".", "append", "(", "(", "child", ",", "depth", ")", ")", "\n", "max_depth", "=", "max", "(", "max_depth", ",", "depth", "+", "1", ")", "\n", "", "child_with_depth", "[", "head", "]", "=", "sorted", "(", "child_with_depth", "[", "head", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "reverse", ")", "\n", "return", "max_depth", "\n", "\n", "", "child_ids", "=", "_obtain_child_index_for_left2right", "(", "heads", ")", "\n", "child_with_depth", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "calc_depth", "(", "0", ")", "\n", "return", "[", "[", "child", "for", "child", ",", "depth", "in", "child_with_depth", "[", "head", "]", "]", "for", "head", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._generate_stack_inputs": [[53, 95], ["conllx_stacked_data._obtain_child_index_for_depth", "len", "stacked_heads.append", "siblings.append", "skip_connect.append", "conllx_stacked_data._obtain_child_index_for_depth", "range", "range", "len", "children.append", "stacked_types.append", "stack.pop", "child_id.pop", "children.append", "stack.append", "stacked_types.append", "conllx_stacked_data._obtain_child_index_for_left2right", "len", "len", "conllx_stacked_data._obtain_child_index_for_inside_out", "ValueError"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_depth", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_depth", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_left2right", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._obtain_child_index_for_inside_out"], ["", "def", "_generate_stack_inputs", "(", "heads", ",", "types", ",", "prior_order", ")", ":", "\n", "    ", "if", "prior_order", "==", "'deep_first'", ":", "\n", "        ", "child_ids", "=", "_obtain_child_index_for_depth", "(", "heads", ",", "True", ")", "\n", "", "elif", "prior_order", "==", "'shallow_first'", ":", "\n", "        ", "child_ids", "=", "_obtain_child_index_for_depth", "(", "heads", ",", "False", ")", "\n", "", "elif", "prior_order", "==", "'left2right'", ":", "\n", "        ", "child_ids", "=", "_obtain_child_index_for_left2right", "(", "heads", ")", "\n", "", "elif", "prior_order", "==", "'inside_out'", ":", "\n", "        ", "child_ids", "=", "_obtain_child_index_for_inside_out", "(", "heads", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown prior order: %s'", "%", "prior_order", ")", "\n", "\n", "", "stacked_heads", "=", "[", "]", "\n", "children", "=", "[", "]", "\n", "siblings", "=", "[", "]", "\n", "stacked_types", "=", "[", "]", "\n", "skip_connect", "=", "[", "]", "\n", "prev", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "sibs", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "heads", ")", ")", "]", "\n", "stack", "=", "[", "0", "]", "\n", "position", "=", "1", "\n", "while", "len", "(", "stack", ")", ">", "0", ":", "\n", "        ", "head", "=", "stack", "[", "-", "1", "]", "\n", "stacked_heads", ".", "append", "(", "head", ")", "\n", "siblings", ".", "append", "(", "sibs", "[", "head", "]", ")", "\n", "child_id", "=", "child_ids", "[", "head", "]", "\n", "skip_connect", ".", "append", "(", "prev", "[", "head", "]", ")", "\n", "prev", "[", "head", "]", "=", "position", "\n", "if", "len", "(", "child_id", ")", "==", "0", ":", "\n", "            ", "children", ".", "append", "(", "head", ")", "\n", "sibs", "[", "head", "]", "=", "0", "\n", "stacked_types", ".", "append", "(", "PAD_ID_TAG", ")", "\n", "stack", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "child", "=", "child_id", ".", "pop", "(", "0", ")", "\n", "children", ".", "append", "(", "child", ")", "\n", "sibs", "[", "head", "]", "=", "child", "\n", "stack", ".", "append", "(", "child", ")", "\n", "stacked_types", ".", "append", "(", "types", "[", "child", "]", ")", "\n", "", "position", "+=", "1", "\n", "\n", "", "return", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data.read_stacked_data": [[97, 132], ["print", "reader.CoNLLXReader", "reader.CoNLLXReader.getNext", "reader.CoNLLXReader.close", "print", "reader.getNext.length", "reader.CoNLLXReader.getNext", "print", "enumerate", "conllx_stacked_data._generate_stack_inputs", "data[].append", "max", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data._generate_stack_inputs"], ["", "def", "read_stacked_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_size", "=", "None", ",", "\n", "normalize_digits", "=", "True", ",", "prior_order", "=", "'deep_first'", ",", "lang_id", "=", "\"\"", ",", "len_thresh", "=", "None", ")", ":", "\n", "    ", "data", "=", "[", "[", "]", "for", "_", "in", "_buckets", "]", "\n", "max_char_length", "=", "[", "0", "for", "_", "in", "_buckets", "]", "\n", "print", "(", "'Reading data from %s'", "%", "source_path", ")", "\n", "counter", "=", "0", "\n", "counter_added", "=", "0", "\n", "reader", "=", "CoNLLXReader", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "lang_id", "=", "lang_id", ")", "\n", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", "=", "normalize_digits", ",", "symbolic_root", "=", "True", ",", "symbolic_end", "=", "False", ")", "\n", "while", "inst", "is", "not", "None", "and", "(", "not", "max_size", "or", "counter", "<", "max_size", ")", ":", "\n", "        ", "counter", "+=", "1", "\n", "if", "counter", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\"reading data: %d\"", "%", "counter", ")", "\n", "\n", "", "inst_size", "=", "inst", ".", "length", "(", ")", "\n", "if", "inst_size", "<=", "len_thresh", ":", "\n", "            ", "sent", "=", "inst", ".", "sentence", "\n", "for", "bucket_id", ",", "bucket_size", "in", "enumerate", "(", "_buckets", ")", ":", "\n", "                ", "if", "inst_size", "<", "bucket_size", ":", "\n", "                    ", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", "=", "_generate_stack_inputs", "(", "inst", ".", "heads", ",", "\n", "inst", ".", "type_ids", ",", "\n", "prior_order", ")", "\n", "data", "[", "bucket_id", "]", ".", "append", "(", "\n", "[", "sent", ".", "word_ids", ",", "sent", ".", "char_id_seqs", ",", "inst", ".", "pos_ids", ",", "inst", ".", "heads", ",", "inst", ".", "type_ids", ",", "stacked_heads", ",", "children", ",", "\n", "siblings", ",", "stacked_types", ",", "skip_connect", "]", ")", "\n", "max_len", "=", "max", "(", "[", "len", "(", "char_seq", ")", "for", "char_seq", "in", "sent", ".", "char_seqs", "]", ")", "\n", "if", "max_char_length", "[", "bucket_id", "]", "<", "max_len", ":", "\n", "                        ", "max_char_length", "[", "bucket_id", "]", "=", "max_len", "\n", "", "break", "\n", "", "", "counter_added", "+=", "1", "\n", "\n", "", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", "=", "normalize_digits", ",", "symbolic_root", "=", "True", ",", "symbolic_end", "=", "False", ")", "\n", "", "reader", ".", "close", "(", ")", "\n", "print", "(", "\"Total number of data: %d, used: %d\"", "%", "(", "counter", ",", "counter_added", ")", ")", "\n", "return", "data", ",", "max_char_length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data.read_stacked_data_to_variable": [[134, 255], ["conllx_stacked_data.read_stacked_data", "range", "len", "len", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.empty", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "torch.autograd.Variable", "torch.from_numpy", "data_variable.append", "range", "data_variable.append", "len", "enumerate", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "words.cuda.cuda", "chars.cuda.cuda", "pos.cuda.cuda", "heads.cuda.cuda", "types.cuda.cuda", "masks_e.cuda.cuda", "single.cuda.cuda", "lengths_e.cuda.cuda", "stacked_heads.cuda.cuda", "children.cuda.cuda", "siblings.cuda.cuda", "stacked_types.cuda.cuda", "skip_connect.cuda.cuda", "masks_d.cuda.cuda", "lengths_d.cuda.cuda", "len", "word_alphabet.is_singleton", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data.read_stacked_data", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "def", "read_stacked_data_to_variable", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "\n", "max_size", "=", "None", ",", "normalize_digits", "=", "True", ",", "prior_order", "=", "'deep_first'", ",", "use_gpu", "=", "False", ",", "\n", "volatile", "=", "False", ",", "lang_id", "=", "\"\"", ",", "len_thresh", "=", "100000", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "read_stacked_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "\n", "max_size", "=", "max_size", ",", "normalize_digits", "=", "normalize_digits", ",", "\n", "prior_order", "=", "prior_order", ",", "lang_id", "=", "lang_id", ",", "len_thresh", "=", "len_thresh", ")", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "\n", "data_variable", "=", "[", "]", "\n", "\n", "for", "bucket_id", "in", "range", "(", "len", "(", "_buckets", ")", ")", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "data_variable", ".", "append", "(", "(", "1", ",", "1", ")", ")", "\n", "continue", "\n", "\n", "", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "hid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "tid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks_e", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "lengths_e", "=", "np", ".", "empty", "(", "bucket_size", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "stack_hid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "chid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "ssid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "stack_tid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "skip_connect_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks_d", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "2", "*", "bucket_length", "-", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "lengths_d", "=", "np", ".", "empty", "(", "bucket_size", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "i", ",", "inst", "in", "enumerate", "(", "data", "[", "bucket_id", "]", ")", ":", "\n", "            ", "wids", ",", "cid_seqs", ",", "pids", ",", "hids", ",", "tids", ",", "stack_hids", ",", "chids", ",", "ssids", ",", "stack_tids", ",", "skip_ids", "=", "inst", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "lengths_e", "[", "i", "]", "=", "inst_size", "\n", "# word ids", "\n", "wid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "                ", "cid_inputs", "[", "i", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "i", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "i", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# type ids", "\n", "tid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "tids", "\n", "tid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# heads", "\n", "hid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "hids", "\n", "hid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks_e", "\n", "masks_e", "[", "i", ",", ":", "inst_size", "]", "=", "1.0", "\n", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                    ", "single", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "", "inst_size_decoder", "=", "2", "*", "inst_size", "-", "1", "\n", "lengths_d", "[", "i", "]", "=", "inst_size_decoder", "\n", "# stacked heads", "\n", "stack_hid_inputs", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "stack_hids", "\n", "stack_hid_inputs", "[", "i", ",", "inst_size_decoder", ":", "]", "=", "PAD_ID_TAG", "\n", "# children", "\n", "chid_inputs", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "chids", "\n", "chid_inputs", "[", "i", ",", "inst_size_decoder", ":", "]", "=", "PAD_ID_TAG", "\n", "# siblings", "\n", "ssid_inputs", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "ssids", "\n", "ssid_inputs", "[", "i", ",", "inst_size_decoder", ":", "]", "=", "PAD_ID_TAG", "\n", "# stacked types", "\n", "stack_tid_inputs", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "stack_tids", "\n", "stack_tid_inputs", "[", "i", ",", "inst_size_decoder", ":", "]", "=", "PAD_ID_TAG", "\n", "# skip connects", "\n", "skip_connect_inputs", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "skip_ids", "\n", "skip_connect_inputs", "[", "i", ",", "inst_size_decoder", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks_d", "\n", "masks_d", "[", "i", ",", ":", "inst_size_decoder", "]", "=", "1.0", "\n", "\n", "", "words", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "wid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "chars", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "cid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "pos", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "pid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "heads", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "hid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "types", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "tid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "masks_e", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "masks_e", ")", ",", "volatile", "=", "volatile", ")", "\n", "single", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "single", ")", ",", "volatile", "=", "volatile", ")", "\n", "lengths_e", "=", "torch", ".", "from_numpy", "(", "lengths_e", ")", "\n", "\n", "stacked_heads", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "stack_hid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "children", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "chid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "siblings", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "ssid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "stacked_types", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "stack_tid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "skip_connect", "=", "torch", ".", "from_numpy", "(", "skip_connect_inputs", ")", "\n", "masks_d", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "masks_d", ")", ",", "volatile", "=", "volatile", ")", "\n", "lengths_d", "=", "torch", ".", "from_numpy", "(", "lengths_d", ")", "\n", "\n", "if", "use_gpu", ":", "\n", "            ", "words", "=", "words", ".", "cuda", "(", ")", "\n", "chars", "=", "chars", ".", "cuda", "(", ")", "\n", "pos", "=", "pos", ".", "cuda", "(", ")", "\n", "heads", "=", "heads", ".", "cuda", "(", ")", "\n", "types", "=", "types", ".", "cuda", "(", ")", "\n", "masks_e", "=", "masks_e", ".", "cuda", "(", ")", "\n", "single", "=", "single", ".", "cuda", "(", ")", "\n", "lengths_e", "=", "lengths_e", ".", "cuda", "(", ")", "\n", "stacked_heads", "=", "stacked_heads", ".", "cuda", "(", ")", "\n", "children", "=", "children", ".", "cuda", "(", ")", "\n", "siblings", "=", "siblings", ".", "cuda", "(", ")", "\n", "stacked_types", "=", "stacked_types", ".", "cuda", "(", ")", "\n", "skip_connect", "=", "skip_connect", ".", "cuda", "(", ")", "\n", "masks_d", "=", "masks_d", ".", "cuda", "(", ")", "\n", "lengths_d", "=", "lengths_d", ".", "cuda", "(", ")", "\n", "\n", "", "data_variable", ".", "append", "(", "(", "(", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks_e", ",", "single", ",", "lengths_e", ")", ",", "\n", "(", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", ",", "masks_d", ",", "lengths_d", ")", ")", ")", "\n", "\n", "", "return", "data_variable", ",", "bucket_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data.get_batch_stacked_variable": [[257, 289], ["float", "numpy.random.random_sample", "min", "min", "sum", "torch.randperm().long", "index.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "sum", "range", "single.data.new().fill_", "masks_e.data.new().bernoulli_().long", "len", "range", "torch.randperm", "len", "single.data.new", "masks_e.data.new().bernoulli_", "masks_e.data.new"], "function", ["None"], ["", "def", "get_batch_stacked_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "# A bucket scale is a list of increasing numbers from 0 to 1 that we'll use", "\n", "# to select a bucket. Length of [scale[i], scale[i+1]] is proportional to", "\n", "# the size if i-th training bucket, as used later.", "\n", "buckets_scale", "=", "[", "sum", "(", "bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "total_size", "for", "i", "in", "range", "(", "len", "(", "bucket_sizes", ")", ")", "]", "\n", "\n", "# Choose a bucket according to data distribution. We pick a random number", "\n", "# in [0, 1] and use the corresponding interval in train_buckets_scale.", "\n", "random_number", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "buckets_scale", ")", ")", "if", "buckets_scale", "[", "i", "]", ">", "random_number", "]", ")", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "\n", "data_encoder", ",", "data_decoder", "=", "data_variable", "[", "bucket_id", "]", "\n", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks_e", ",", "single", ",", "lengths_e", "=", "data_encoder", "\n", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", ",", "masks_d", ",", "lengths_d", "=", "data_decoder", "\n", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "batch_size", "=", "min", "(", "bucket_size", ",", "batch_size", ")", "\n", "index", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "[", ":", "batch_size", "]", "\n", "if", "words", ".", "is_cuda", ":", "\n", "        ", "index", "=", "index", ".", "cuda", "(", ")", "\n", "\n", "", "words", "=", "words", "[", "index", "]", "\n", "if", "unk_replace", ":", "\n", "        ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks_e", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "[", "index", "]", "*", "noise", ")", "\n", "\n", "", "return", "(", "words", ",", "chars", "[", "index", "]", ",", "pos", "[", "index", "]", ",", "heads", "[", "index", "]", ",", "types", "[", "index", "]", ",", "masks_e", "[", "index", "]", ",", "lengths_e", "[", "index", "]", ")", ",", "(", "stacked_heads", "[", "index", "]", ",", "children", "[", "index", "]", ",", "siblings", "[", "index", "]", ",", "stacked_types", "[", "index", "]", ",", "skip_connect", "[", "index", "]", ",", "\n", "masks_d", "[", "index", "]", ",", "lengths_d", "[", "index", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_stacked_data.iterate_batch_stacked_variable": [[291, 325], ["numpy.arange", "len", "numpy.random.shuffle", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randperm().long", "single.data.new().fill_", "masks_e.data.new().bernoulli_().long", "indices.cuda.cuda", "slice", "torch.randperm", "single.data.new", "masks_e.data.new().bernoulli_", "masks_e.data.new"], "function", ["None"], ["", "def", "iterate_batch_stacked_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "\n", "bucket_indices", "=", "np", ".", "arange", "(", "len", "(", "_buckets", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "(", "bucket_indices", ")", ")", "\n", "\n", "", "for", "bucket_id", "in", "bucket_indices", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "continue", "\n", "", "data_encoder", ",", "data_decoder", "=", "data_variable", "[", "bucket_id", "]", "\n", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks_e", ",", "single", ",", "lengths_e", "=", "data_encoder", "\n", "stacked_heads", ",", "children", ",", "siblings", ",", "stacked_types", ",", "skip_connect", ",", "masks_d", ",", "lengths_d", "=", "data_decoder", "\n", "if", "unk_replace", ":", "\n", "            ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks_e", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "*", "noise", ")", "\n", "\n", "", "indices", "=", "None", "\n", "if", "shuffle", ":", "\n", "            ", "indices", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "\n", "if", "words", ".", "is_cuda", ":", "\n", "                ", "indices", "=", "indices", ".", "cuda", "(", ")", "\n", "", "", "for", "start_idx", "in", "range", "(", "0", ",", "bucket_size", ",", "batch_size", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "                ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "(", "words", "[", "excerpt", "]", ",", "chars", "[", "excerpt", "]", ",", "pos", "[", "excerpt", "]", ",", "heads", "[", "excerpt", "]", ",", "types", "[", "excerpt", "]", ",", "masks_e", "[", "excerpt", "]", ",", "\n", "lengths_e", "[", "excerpt", "]", ")", ",", "(", "stacked_heads", "[", "excerpt", "]", ",", "children", "[", "excerpt", "]", ",", "siblings", "[", "excerpt", "]", ",", "stacked_types", "[", "excerpt", "]", ",", "\n", "skip_connect", "[", "excerpt", "]", ",", "masks_d", "[", "excerpt", "]", ",", "lengths_d", "[", "excerpt", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger": [[7, 24], ["logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "get_logger", "(", "name", ",", "filepath", "=", "None", ",", "level", "=", "logging", ".", "INFO", ",", "handler", "=", "sys", ".", "stdout", ",", "\n", "formatter", "=", "'%(asctime)s - %(name)s - %(levelname)s - %(message)s'", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "formatter", ")", "\n", "stream_handler", "=", "logging", ".", "StreamHandler", "(", "handler", ")", "\n", "stream_handler", ".", "setLevel", "(", "level", ")", "\n", "stream_handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "stream_handler", ")", "\n", "\n", "if", "filepath", "is", "not", "None", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "filepath", ",", "\"w\"", ")", "\n", "file_handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "file_handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.create_alphabets": [[39, 239], ["logger.get_logger", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "alphabet.Alphabet.close", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "set", "dic1.items", "dic2.values", "logger.get_logger.info", "dict", "os.path.isdir", "logger.get_logger.info", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "alphabet.Alphabet.add", "dict", "dict", "set", "logger.get_logger.info", "logger.get_logger.info", "logger.get_logger.info", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.save", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "alphabet.Alphabet.load", "math.sqrt", "open", "print", "print", "print", "open", "dict.keys", "sorted", "len", "conllx_data.create_alphabets.expand_vocab"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.items", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["def", "create_alphabets", "(", "alphabet_directory", ",", "train_path", ",", "data_paths", "=", "None", ",", "max_vocabulary_size", "=", "50000", ",", "embedd_dict", "=", "None", ",", "\n", "min_occurence", "=", "1", ",", "normalize_digits", "=", "True", ")", ":", "\n", "    ", "def", "expand_vocab", "(", ")", ":", "\n", "        ", "vocab_set", "=", "set", "(", "vocab_list", ")", "\n", "max_sent_length", "=", "0", "\n", "for", "data_path", "in", "data_paths", ":", "\n", "# logger.info(\"Processing data: %s\" % data_path)", "\n", "            ", "with", "open", "(", "data_path", ",", "'r'", ")", "as", "file", ":", "\n", "                ", "sent_length", "=", "1", "\n", "for", "line", "in", "file", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                        ", "for", "val", "in", "_buckets", ":", "\n", "                            ", "if", "val", ">", "sent_length", ":", "\n", "                                ", "sent_length", "=", "val", "\n", "break", "\n", "", "", "if", "sent_length", ">", "max_sent_length", ":", "\n", "                            ", "max_sent_length", "=", "sent_length", "\n", "", "sent_length", "=", "1", "\n", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "for", "char", "in", "tokens", "[", "1", "]", ":", "\n", "                        ", "char_alphabet", ".", "add", "(", "char", ")", "\n", "\n", "", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "4", "]", "\n", "type", "=", "utils", ".", "get_main_deplabel", "(", "tokens", "[", "7", "]", ")", "\n", "\n", "pos_alphabet", ".", "add", "(", "pos", ")", "\n", "type_alphabet", ".", "add", "(", "type", ")", "\n", "\n", "if", "embedd_dict", "is", "not", "None", ":", "\n", "                        ", "if", "word", "not", "in", "vocab_set", "and", "(", "word", "in", "embedd_dict", "or", "word", ".", "lower", "(", ")", "in", "embedd_dict", ")", ":", "\n", "                            ", "vocab_set", ".", "add", "(", "word", ")", "\n", "vocab_list", ".", "append", "(", "word", ")", "\n", "\n", "", "", "", "", "", "return", "max_sent_length", "\n", "\n", "", "def", "cosine_dict", "(", "dic1", ",", "dic2", ")", ":", "\n", "        ", "numerator", "=", "0", "\n", "dena", "=", "0", "\n", "for", "key1", ",", "val1", "in", "dic1", ".", "items", "(", ")", ":", "\n", "            ", "numerator", "+=", "val1", "*", "dic2", ".", "get", "(", "key1", ",", "0", ")", "\n", "dena", "+=", "val1", "*", "val1", "\n", "", "denb", "=", "0", "\n", "for", "val2", "in", "dic2", ".", "values", "(", ")", ":", "\n", "            ", "denb", "+=", "val2", "*", "val2", "\n", "", "import", "math", "\n", "return", "numerator", "/", "math", ".", "sqrt", "(", "dena", "*", "denb", ")", "\n", "\n", "", "def", "check_sentences_for_types", "(", "data_path", ",", "src_types", ",", "freq_dict", ")", ":", "\n", "        ", "\"\"\"temporarily written for stat check - wasi\"\"\"", "\n", "logger", ".", "info", "(", "\"Processing data: %s\"", "%", "data_path", ")", "\n", "count1", ",", "count2", "=", "1", ",", "0", "\n", "new_line", "=", "True", "\n", "type_alph_dict", "=", "dict", "(", ")", "\n", "with", "open", "(", "data_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "new_line", "=", "True", "\n", "count1", "+=", "1", "\n", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "type", "=", "tokens", "[", "7", "]", "\n", "if", "type", "in", "type_alph_dict", ":", "\n", "                    ", "type_alph_dict", "[", "type", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "type_alph_dict", "[", "type", "]", "=", "1", "\n", "\n", "", "if", "type", "not", "in", "src_types", "and", "new_line", ":", "\n", "                    ", "count2", "+=", "1", "\n", "new_line", "=", "False", "\n", "\n", "", "", "print", "(", "'total sentences = '", ",", "count1", ")", "\n", "print", "(", "'total sentences that contain a label not appeared in src lang = '", ",", "count2", ")", "\n", "print", "(", "'cosine similarity = '", ",", "cosine_dict", "(", "freq_dict", ",", "type_alph_dict", ")", ")", "\n", "\n", "", "", "logger", "=", "get_logger", "(", "\"Create Alphabets\"", ")", "\n", "word_alphabet", "=", "Alphabet", "(", "'word'", ",", "defualt_value", "=", "True", ",", "singleton", "=", "True", ")", "\n", "char_alphabet", "=", "Alphabet", "(", "'character'", ",", "defualt_value", "=", "True", ")", "\n", "pos_alphabet", "=", "Alphabet", "(", "'pos'", ")", "\n", "type_alphabet", "=", "Alphabet", "(", "'type'", ")", "\n", "max_sent_length", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "alphabet_directory", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating Alphabets: %s\"", "%", "alphabet_directory", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "PAD_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "PAD_POS", ")", "\n", "type_alphabet", ".", "add", "(", "PAD_TYPE", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "ROOT_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "ROOT_POS", ")", "\n", "type_alphabet", ".", "add", "(", "ROOT_TYPE", ")", "\n", "\n", "char_alphabet", ".", "add", "(", "END_CHAR", ")", "\n", "pos_alphabet", ".", "add", "(", "END_POS", ")", "\n", "type_alphabet", ".", "add", "(", "END_TYPE", ")", "\n", "\n", "vocab", "=", "dict", "(", ")", "\n", "type_alph_dict", "=", "dict", "(", ")", "## temporary", "\n", "sent_length", "=", "1", "\n", "with", "open", "(", "train_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "for", "val", "in", "_buckets", ":", "\n", "                        ", "if", "val", ">", "sent_length", ":", "\n", "                            ", "sent_length", "=", "val", "\n", "break", "\n", "", "", "if", "sent_length", ">", "max_sent_length", ":", "\n", "                        ", "max_sent_length", "=", "sent_length", "\n", "", "sent_length", "=", "1", "\n", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "for", "char", "in", "tokens", "[", "1", "]", ":", "\n", "                    ", "char_alphabet", ".", "add", "(", "char", ")", "\n", "\n", "", "sent_length", "+=", "1", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "4", "]", "\n", "type", "=", "utils", ".", "get_main_deplabel", "(", "tokens", "[", "7", "]", ")", "\n", "\n", "pos_alphabet", ".", "add", "(", "pos", ")", "\n", "type_alphabet", ".", "add", "(", "type", ")", "\n", "if", "type", "in", "type_alph_dict", ":", "\n", "                    ", "type_alph_dict", "[", "type", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "type_alph_dict", "[", "type", "]", "=", "1", "\n", "\n", "", "if", "word", "in", "vocab", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "vocab", "[", "word", "]", "=", "1", "\n", "\n", "#############################", "\n", "# temporary code", "\n", "# if data_paths is not None:", "\n", "#     check_sentences_for_types(data_paths[1], type_alphabet.items(), type_alph_dict)", "\n", "############################", "\n", "\n", "# collect singletons", "\n", "", "", "", "singletons", "=", "set", "(", "[", "word", "for", "word", ",", "count", "in", "vocab", ".", "items", "(", ")", "if", "count", "<=", "min_occurence", "]", ")", "\n", "\n", "# if a singleton is in pretrained embedding dict, set the count to min_occur + c", "\n", "if", "embedd_dict", "is", "not", "None", ":", "\n", "            ", "for", "word", "in", "vocab", ".", "keys", "(", ")", ":", "\n", "                ", "if", "word", "in", "embedd_dict", "or", "word", ".", "lower", "(", ")", "in", "embedd_dict", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "min_occurence", "\n", "\n", "", "", "", "vocab_list", "=", "_START_VOCAB", "+", "sorted", "(", "vocab", ",", "key", "=", "vocab", ".", "get", ",", "reverse", "=", "True", ")", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size: %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "logger", ".", "info", "(", "\"Total Singleton Size:  %d\"", "%", "len", "(", "singletons", ")", ")", "\n", "vocab_list", "=", "[", "word", "for", "word", "in", "vocab_list", "if", "word", "in", "_START_VOCAB", "or", "vocab", "[", "word", "]", ">", "min_occurence", "]", "\n", "logger", ".", "info", "(", "\"Total Vocabulary Size (w.o rare words): %d\"", "%", "len", "(", "vocab_list", ")", ")", "\n", "\n", "if", "len", "(", "vocab_list", ")", ">", "max_vocabulary_size", ":", "\n", "            ", "vocab_list", "=", "vocab_list", "[", ":", "max_vocabulary_size", "]", "\n", "\n", "", "if", "data_paths", "is", "not", "None", ":", "\n", "# logger.info(\"expanding vocab\")", "\n", "            ", "sent_length", "=", "expand_vocab", "(", ")", "\n", "if", "sent_length", ">", "max_sent_length", ":", "\n", "                ", "max_sent_length", "=", "sent_length", "\n", "\n", "# if data_paths is not None and embedd_dict is not None:", "\n", "#     expand_vocab()", "\n", "\n", "", "", "for", "word", "in", "vocab_list", ":", "\n", "            ", "word_alphabet", ".", "add", "(", "word", ")", "\n", "if", "word", "in", "singletons", ":", "\n", "                ", "word_alphabet", ".", "add_singleton", "(", "word_alphabet", ".", "get_index", "(", "word", ")", ")", "\n", "\n", "", "", "word_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "type_alphabet", ".", "save", "(", "alphabet_directory", ")", "\n", "", "else", ":", "\n", "        ", "word_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "char_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "pos_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "type_alphabet", ".", "load", "(", "alphabet_directory", ")", "\n", "\n", "", "word_alphabet", ".", "close", "(", ")", "\n", "char_alphabet", ".", "close", "(", ")", "\n", "pos_alphabet", ".", "close", "(", ")", "\n", "type_alphabet", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Word Alphabet Size (Singleton): %d (%d)\"", "%", "(", "word_alphabet", ".", "size", "(", ")", ",", "word_alphabet", ".", "singleton_size", "(", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Character Alphabet Size: %d\"", "%", "char_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"POS Alphabet Size: %d\"", "%", "pos_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Type Alphabet Size: %d\"", "%", "type_alphabet", ".", "size", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Maximum Sentence Length: %d\"", "%", "max_sent_length", ")", "\n", "\n", "return", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_sent_length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.read_data": [[241, 271], ["print", "reader.CoNLLXReader", "reader.CoNLLXReader.getNext", "reader.CoNLLXReader.close", "print", "reader.getNext.length", "reader.CoNLLXReader.getNext", "print", "enumerate", "data[].append", "max", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext"], ["", "def", "read_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_size", "=", "None", ",", "\n", "normalize_digits", "=", "True", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ",", "lang_id", "=", "\"\"", ",", "len_thresh", "=", "None", ")", ":", "\n", "    ", "data", "=", "[", "[", "]", "for", "_", "in", "_buckets", "]", "\n", "max_char_length", "=", "[", "0", "for", "_", "in", "_buckets", "]", "\n", "print", "(", "'Reading data from %s'", "%", "source_path", ")", "\n", "counter", "=", "0", "\n", "counter_added", "=", "0", "\n", "reader", "=", "CoNLLXReader", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "lang_id", "=", "lang_id", ")", "\n", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", "=", "normalize_digits", ",", "symbolic_root", "=", "symbolic_root", ",", "symbolic_end", "=", "symbolic_end", ")", "\n", "while", "inst", "is", "not", "None", "and", "(", "not", "max_size", "or", "counter", "<", "max_size", ")", ":", "\n", "        ", "counter", "+=", "1", "\n", "if", "counter", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\"reading data: %d\"", "%", "counter", ")", "\n", "\n", "", "inst_size", "=", "inst", ".", "length", "(", ")", "\n", "if", "inst_size", "<=", "len_thresh", ":", "\n", "            ", "sent", "=", "inst", ".", "sentence", "\n", "for", "bucket_id", ",", "bucket_size", "in", "enumerate", "(", "_buckets", ")", ":", "\n", "                ", "if", "inst_size", "<", "bucket_size", ":", "\n", "                    ", "data", "[", "bucket_id", "]", ".", "append", "(", "[", "sent", ".", "word_ids", ",", "sent", ".", "char_id_seqs", ",", "inst", ".", "pos_ids", ",", "inst", ".", "heads", ",", "inst", ".", "type_ids", "]", ")", "\n", "max_len", "=", "max", "(", "[", "len", "(", "char_seq", ")", "for", "char_seq", "in", "sent", ".", "char_seqs", "]", ")", "\n", "if", "max_char_length", "[", "bucket_id", "]", "<", "max_len", ":", "\n", "                        ", "max_char_length", "[", "bucket_id", "]", "=", "max_len", "\n", "", "break", "\n", "", "", "counter_added", "+=", "1", "\n", "\n", "", "inst", "=", "reader", ".", "getNext", "(", "normalize_digits", "=", "normalize_digits", ",", "symbolic_root", "=", "symbolic_root", ",", "symbolic_end", "=", "symbolic_end", ")", "\n", "", "reader", ".", "close", "(", ")", "\n", "print", "(", "\"Total number of data: %d, used: %d\"", "%", "(", "counter", ",", "counter_added", ")", ")", "\n", "return", "data", ",", "max_char_length", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.get_batch": [[273, 334], ["float", "numpy.random.random_sample", "min", "min", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "range", "len", "sum", "random.choice", "len", "enumerate", "numpy.random.binomial", "range", "sum", "range", "enumerate", "len", "len", "range", "word_alphabet.is_singleton", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "def", "get_batch", "(", "data", ",", "batch_size", ",", "word_alphabet", "=", "None", ",", "unk_replace", "=", "0.", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "data", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "# A bucket scale is a list of increasing numbers from 0 to 1 that we'll use", "\n", "# to select a bucket. Length of [scale[i], scale[i+1]] is proportional to", "\n", "# the size if i-th training bucket, as used later.", "\n", "buckets_scale", "=", "[", "sum", "(", "bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "total_size", "for", "i", "in", "range", "(", "len", "(", "bucket_sizes", ")", ")", "]", "\n", "\n", "# Choose a bucket according to data distribution. We pick a random number", "\n", "# in [0, 1] and use the corresponding interval in train_buckets_scale.", "\n", "random_number", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "buckets_scale", ")", ")", "if", "buckets_scale", "[", "i", "]", ">", "random_number", "]", ")", "\n", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "batch_size", "=", "min", "(", "bucket_size", ",", "batch_size", ")", "\n", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "hid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "tid_inputs", "=", "np", ".", "empty", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "wids", ",", "cid_seqs", ",", "pids", ",", "hids", ",", "tids", "=", "random", ".", "choice", "(", "data", "[", "bucket_id", "]", ")", "\n", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "# word ids", "\n", "wid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "            ", "cid_inputs", "[", "b", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "b", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "b", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# type ids", "\n", "tid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "tids", "\n", "tid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# heads", "\n", "hid_inputs", "[", "b", ",", ":", "inst_size", "]", "=", "hids", "\n", "hid_inputs", "[", "b", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "b", ",", ":", "inst_size", "]", "=", "1.0", "\n", "\n", "if", "unk_replace", ":", "\n", "            ", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                    ", "single", "[", "b", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "", "if", "unk_replace", ":", "\n", "        ", "noise", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "unk_replace", ",", "size", "=", "[", "batch_size", ",", "bucket_length", "]", ")", "\n", "wid_inputs", "=", "wid_inputs", "*", "(", "1", "-", "noise", "*", "single", ")", "\n", "\n", "", "return", "wid_inputs", ",", "cid_inputs", ",", "pid_inputs", ",", "hid_inputs", ",", "tid_inputs", ",", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.iterate_batch": [[336, 401], ["float", "numpy.arange", "len", "sum", "len", "numpy.random.shuffle", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "enumerate", "range", "range", "len", "enumerate", "numpy.random.binomial", "numpy.arange", "numpy.random.shuffle", "len", "enumerate", "slice", "word_alphabet.is_singleton", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "def", "iterate_batch", "(", "data", ",", "batch_size", ",", "word_alphabet", "=", "None", ",", "unk_replace", "=", "0.", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "data", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "bucket_indices", "=", "np", ".", "arange", "(", "len", "(", "_buckets", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "(", "bucket_indices", ")", ")", "\n", "\n", "", "for", "bucket_id", "in", "bucket_indices", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "hid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "tid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "i", ",", "inst", "in", "enumerate", "(", "data", "[", "bucket_id", "]", ")", ":", "\n", "            ", "wids", ",", "cid_seqs", ",", "pids", ",", "hids", ",", "tids", "=", "inst", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "# word ids", "\n", "wid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "                ", "cid_inputs", "[", "i", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "i", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "i", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# type ids", "\n", "tid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "tids", "\n", "tid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# heads", "\n", "hid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "hids", "\n", "hid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "i", ",", ":", "inst_size", "]", "=", "1.0", "\n", "if", "unk_replace", ":", "\n", "                ", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                    ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                        ", "single", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "", "if", "unk_replace", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "unk_replace", ",", "size", "=", "[", "bucket_size", ",", "bucket_length", "]", ")", "\n", "wid_inputs", "=", "wid_inputs", "*", "(", "1", "-", "noise", "*", "single", ")", "\n", "\n", "", "indices", "=", "None", "\n", "if", "shuffle", ":", "\n", "            ", "indices", "=", "np", ".", "arange", "(", "bucket_size", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "for", "start_idx", "in", "range", "(", "0", ",", "bucket_size", ",", "batch_size", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "                ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "wid_inputs", "[", "excerpt", "]", ",", "cid_inputs", "[", "excerpt", "]", ",", "pid_inputs", "[", "excerpt", "]", ",", "hid_inputs", "[", "excerpt", "]", ",", "tid_inputs", "[", "excerpt", "]", ",", "masks", "[", "excerpt", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.read_data_to_variable": [[403, 479], ["conllx_data.read_data", "range", "len", "len", "min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.zeros", "numpy.empty", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.from_numpy", "data_variable.append", "range", "data_variable.append", "len", "enumerate", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "words.cuda.cuda", "chars.cuda.cuda", "pos.cuda.cuda", "heads.cuda.cuda", "types.cuda.cuda", "masks.cuda.cuda", "single.cuda.cuda", "lengths.cuda.cuda", "len", "word_alphabet.is_singleton", "len", "len"], "function", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.read_data", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton"], ["", "", "", "def", "read_data_to_variable", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "max_size", "=", "None", ",", "\n", "normalize_digits", "=", "True", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ",", "\n", "use_gpu", "=", "False", ",", "volatile", "=", "False", ",", "lang_id", "=", "\"\"", ",", "len_thresh", "=", "100000", ")", ":", "\n", "    ", "data", ",", "max_char_length", "=", "read_data", "(", "source_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "\n", "max_size", "=", "max_size", ",", "normalize_digits", "=", "normalize_digits", ",", "symbolic_root", "=", "symbolic_root", ",", "\n", "symbolic_end", "=", "symbolic_end", ",", "lang_id", "=", "lang_id", ",", "len_thresh", "=", "len_thresh", ")", "\n", "bucket_sizes", "=", "[", "len", "(", "data", "[", "b", "]", ")", "for", "b", "in", "range", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "\n", "data_variable", "=", "[", "]", "\n", "\n", "for", "bucket_id", "in", "range", "(", "len", "(", "_buckets", ")", ")", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "data_variable", ".", "append", "(", "(", "1", ",", "1", ")", ")", "\n", "continue", "\n", "\n", "", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "char_length", "=", "min", "(", "utils", ".", "MAX_CHAR_LENGTH", ",", "max_char_length", "[", "bucket_id", "]", "+", "utils", ".", "NUM_CHAR_PAD", ")", "\n", "wid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "cid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", ",", "char_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "pid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "hid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "tid_inputs", "=", "np", ".", "empty", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "masks", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "single", "=", "np", ".", "zeros", "(", "[", "bucket_size", ",", "bucket_length", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "lengths", "=", "np", ".", "empty", "(", "bucket_size", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "i", ",", "inst", "in", "enumerate", "(", "data", "[", "bucket_id", "]", ")", ":", "\n", "            ", "wids", ",", "cid_seqs", ",", "pids", ",", "hids", ",", "tids", "=", "inst", "\n", "inst_size", "=", "len", "(", "wids", ")", "\n", "lengths", "[", "i", "]", "=", "inst_size", "\n", "# word ids", "\n", "wid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "wids", "\n", "wid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_WORD", "\n", "for", "c", ",", "cids", "in", "enumerate", "(", "cid_seqs", ")", ":", "\n", "                ", "cid_inputs", "[", "i", ",", "c", ",", ":", "len", "(", "cids", ")", "]", "=", "cids", "\n", "cid_inputs", "[", "i", ",", "c", ",", "len", "(", "cids", ")", ":", "]", "=", "PAD_ID_CHAR", "\n", "", "cid_inputs", "[", "i", ",", "inst_size", ":", ",", ":", "]", "=", "PAD_ID_CHAR", "\n", "# pos ids", "\n", "pid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "pids", "\n", "pid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# type ids", "\n", "tid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "tids", "\n", "tid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# heads", "\n", "hid_inputs", "[", "i", ",", ":", "inst_size", "]", "=", "hids", "\n", "hid_inputs", "[", "i", ",", "inst_size", ":", "]", "=", "PAD_ID_TAG", "\n", "# masks", "\n", "masks", "[", "i", ",", ":", "inst_size", "]", "=", "1.0", "\n", "for", "j", ",", "wid", "in", "enumerate", "(", "wids", ")", ":", "\n", "                ", "if", "word_alphabet", ".", "is_singleton", "(", "wid", ")", ":", "\n", "                    ", "single", "[", "i", ",", "j", "]", "=", "1", "\n", "\n", "", "", "", "words", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "wid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "chars", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "cid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "pos", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "pid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "heads", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "hid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "types", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "tid_inputs", ")", ",", "volatile", "=", "volatile", ")", "\n", "masks", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "masks", ")", ",", "volatile", "=", "volatile", ")", "\n", "single", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "single", ")", ",", "volatile", "=", "volatile", ")", "\n", "lengths", "=", "torch", ".", "from_numpy", "(", "lengths", ")", "\n", "if", "use_gpu", ":", "\n", "            ", "words", "=", "words", ".", "cuda", "(", ")", "\n", "chars", "=", "chars", ".", "cuda", "(", ")", "\n", "pos", "=", "pos", ".", "cuda", "(", ")", "\n", "heads", "=", "heads", ".", "cuda", "(", ")", "\n", "types", "=", "types", ".", "cuda", "(", ")", "\n", "masks", "=", "masks", ".", "cuda", "(", ")", "\n", "single", "=", "single", ".", "cuda", "(", ")", "\n", "lengths", "=", "lengths", ".", "cuda", "(", ")", "\n", "\n", "", "data_variable", ".", "append", "(", "(", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "single", ",", "lengths", ")", ")", "\n", "\n", "", "return", "data_variable", ",", "bucket_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.get_batch_variable": [[481, 509], ["float", "numpy.random.random_sample", "min", "min", "sum", "torch.randperm().long", "index.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "sum", "range", "single.data.new().fill_", "masks.data.new().bernoulli_().long", "len", "range", "torch.randperm", "len", "single.data.new", "masks.data.new().bernoulli_", "masks.data.new"], "function", ["None"], ["", "def", "get_batch_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "total_size", "=", "float", "(", "sum", "(", "bucket_sizes", ")", ")", "\n", "# A bucket scale is a list of increasing numbers from 0 to 1 that we'll use", "\n", "# to select a bucket. Length of [scale[i], scale[i+1]] is proportional to", "\n", "# the size if i-th training bucket, as used later.", "\n", "buckets_scale", "=", "[", "sum", "(", "bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "total_size", "for", "i", "in", "range", "(", "len", "(", "bucket_sizes", ")", ")", "]", "\n", "\n", "# Choose a bucket according to data distribution. We pick a random number", "\n", "# in [0, 1] and use the corresponding interval in train_buckets_scale.", "\n", "random_number", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "buckets_scale", ")", ")", "if", "buckets_scale", "[", "i", "]", ">", "random_number", "]", ")", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "\n", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "single", ",", "lengths", "=", "data_variable", "[", "bucket_id", "]", "\n", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "batch_size", "=", "min", "(", "bucket_size", ",", "batch_size", ")", "\n", "index", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "[", ":", "batch_size", "]", "\n", "if", "words", ".", "is_cuda", ":", "\n", "        ", "index", "=", "index", ".", "cuda", "(", ")", "\n", "\n", "", "words", "=", "words", "[", "index", "]", "\n", "if", "unk_replace", ":", "\n", "        ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks", ".", "data", ".", "new", "(", "batch_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "[", "index", "]", "*", "noise", ")", "\n", "\n", "", "return", "words", ",", "chars", "[", "index", "]", ",", "pos", "[", "index", "]", ",", "heads", "[", "index", "]", ",", "types", "[", "index", "]", ",", "masks", "[", "index", "]", ",", "lengths", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.conllx_data.iterate_batch_variable": [[511, 542], ["numpy.arange", "len", "numpy.random.shuffle", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randperm().long", "single.data.new().fill_", "masks.data.new().bernoulli_().long", "indices.cuda.cuda", "slice", "torch.randperm", "single.data.new", "masks.data.new().bernoulli_", "masks.data.new"], "function", ["None"], ["", "def", "iterate_batch_variable", "(", "data", ",", "batch_size", ",", "unk_replace", "=", "0.", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "data_variable", ",", "bucket_sizes", "=", "data", "\n", "\n", "bucket_indices", "=", "np", ".", "arange", "(", "len", "(", "_buckets", ")", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "(", "bucket_indices", ")", ")", "\n", "\n", "", "for", "bucket_id", "in", "bucket_indices", ":", "\n", "        ", "bucket_size", "=", "bucket_sizes", "[", "bucket_id", "]", "\n", "bucket_length", "=", "_buckets", "[", "bucket_id", "]", "\n", "if", "bucket_size", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "words", ",", "chars", ",", "pos", ",", "heads", ",", "types", ",", "masks", ",", "single", ",", "lengths", "=", "data_variable", "[", "bucket_id", "]", "\n", "if", "unk_replace", ":", "\n", "            ", "ones", "=", "Variable", "(", "single", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "fill_", "(", "1", ")", ")", "\n", "noise", "=", "Variable", "(", "masks", ".", "data", ".", "new", "(", "bucket_size", ",", "bucket_length", ")", ".", "bernoulli_", "(", "unk_replace", ")", ".", "long", "(", ")", ")", "\n", "words", "=", "words", "*", "(", "ones", "-", "single", "*", "noise", ")", "\n", "\n", "", "indices", "=", "None", "\n", "if", "shuffle", ":", "\n", "            ", "indices", "=", "torch", ".", "randperm", "(", "bucket_size", ")", ".", "long", "(", ")", "\n", "if", "words", ".", "is_cuda", ":", "\n", "                ", "indices", "=", "indices", ".", "cuda", "(", ")", "\n", "", "", "for", "start_idx", "in", "range", "(", "0", ",", "bucket_size", ",", "batch_size", ")", ":", "\n", "            ", "if", "shuffle", ":", "\n", "                ", "excerpt", "=", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", "\n", "", "else", ":", "\n", "                ", "excerpt", "=", "slice", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "yield", "words", "[", "excerpt", "]", ",", "chars", "[", "excerpt", "]", ",", "pos", "[", "excerpt", "]", ",", "heads", "[", "excerpt", "]", ",", "types", "[", "excerpt", "]", ",", "masks", "[", "excerpt", "]", ",", "lengths", "[", "excerpt", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.__init__": [[11, 27], ["logger.get_logger", "set"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.logger.get_logger"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "defualt_value", "=", "False", ",", "keep_growing", "=", "True", ",", "singleton", "=", "False", ")", ":", "\n", "        ", "self", ".", "__name", "=", "name", "\n", "\n", "self", ".", "instance2index", "=", "{", "}", "\n", "self", ".", "instances", "=", "[", "]", "\n", "self", ".", "default_value", "=", "defualt_value", "\n", "self", ".", "offset", "=", "1", "if", "self", ".", "default_value", "else", "0", "\n", "self", ".", "keep_growing", "=", "keep_growing", "\n", "self", ".", "singletons", "=", "set", "(", ")", "if", "singleton", "else", "None", "\n", "\n", "# Index 0 is occupied by default, all else following.", "\n", "self", ".", "default_index", "=", "0", "if", "self", ".", "default_value", "else", "None", "\n", "\n", "self", ".", "next_index", "=", "self", ".", "offset", "\n", "\n", "self", ".", "logger", "=", "get_logger", "(", "'Alphabet'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add": [[28, 33], ["alphabet.Alphabet.instances.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "instance", ")", ":", "\n", "        ", "if", "instance", "not", "in", "self", ".", "instance2index", ":", "\n", "            ", "self", ".", "instances", ".", "append", "(", "instance", ")", "\n", "self", ".", "instance2index", "[", "instance", "]", "=", "self", ".", "next_index", "\n", "self", ".", "next_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add_singleton": [[34, 39], ["RuntimeError", "alphabet.Alphabet.singletons.add"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add"], ["", "", "def", "add_singleton", "(", "self", ",", "id", ")", ":", "\n", "        ", "if", "self", ".", "singletons", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Alphabet %s does not have singleton.'", "%", "self", ".", "__name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "singletons", ".", "add", "(", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add_singletons": [[40, 45], ["RuntimeError", "alphabet.Alphabet.singletons.update"], "methods", ["None"], ["", "", "def", "add_singletons", "(", "self", ",", "ids", ")", ":", "\n", "        ", "if", "self", ".", "singletons", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Alphabet %s does not have singleton.'", "%", "self", ".", "__name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "singletons", ".", "update", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.is_singleton": [[46, 51], ["RuntimeError"], "methods", ["None"], ["", "", "def", "is_singleton", "(", "self", ",", "id", ")", ":", "\n", "        ", "if", "self", ".", "singletons", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Alphabet %s does not have singleton.'", "%", "self", ".", "__name", ")", "\n", "", "else", ":", "\n", "            ", "return", "id", "in", "self", ".", "singletons", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index": [[52, 65], ["alphabet.Alphabet.add", "KeyError"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.add"], ["", "", "def", "get_index", "(", "self", ",", "instance", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "instance2index", "[", "instance", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "if", "self", ".", "keep_growing", ":", "\n", "                ", "index", "=", "self", ".", "next_index", "\n", "self", ".", "add", "(", "instance", ")", "\n", "return", "index", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "default_value", ":", "\n", "                    ", "return", "self", ".", "default_index", "\n", "", "else", ":", "\n", "                    ", "raise", "KeyError", "(", "\"instance not found: %s\"", "%", "instance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_instance": [[66, 75], ["IndexError"], "methods", ["None"], ["", "", "", "", "def", "get_instance", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "default_value", "and", "index", "==", "self", ".", "default_index", ":", "\n", "# First index is occupied by the wildcard element.", "\n", "            ", "return", "'<_UNK>'", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "self", ".", "instances", "[", "index", "-", "self", ".", "offset", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "raise", "IndexError", "(", "'unknown index: %d'", "%", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size": [[76, 78], ["len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "+", "self", ".", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.singleton_size": [[79, 81], ["len"], "methods", ["None"], ["", "def", "singleton_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "singletons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.items": [[82, 84], ["alphabet.Alphabet.instance2index.items"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.items"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "instance2index", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.enumerate_items": [[85, 89], ["zip", "IndexError", "range", "alphabet.Alphabet.size", "len"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.size"], ["", "def", "enumerate_items", "(", "self", ",", "start", ")", ":", "\n", "        ", "if", "start", "<", "self", ".", "offset", "or", "start", ">=", "self", ".", "size", "(", ")", ":", "\n", "            ", "raise", "IndexError", "(", "\"Enumerate is allowed between [%d : size of the alphabet)\"", "%", "self", ".", "offset", ")", "\n", "", "return", "zip", "(", "range", "(", "start", ",", "len", "(", "self", ".", "instances", ")", "+", "self", ".", "offset", ")", ",", "self", ".", "instances", "[", "start", "-", "self", ".", "offset", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.close": [[90, 92], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "keep_growing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open": [[93, 95], ["None"], "methods", ["None"], ["", "def", "open", "(", "self", ")", ":", "\n", "        ", "self", ".", "keep_growing", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_content": [[96, 102], ["list"], "methods", ["None"], ["", "def", "get_content", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "singletons", "is", "None", ":", "\n", "            ", "return", "{", "'instance2index'", ":", "self", ".", "instance2index", ",", "'instances'", ":", "self", ".", "instances", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "'instance2index'", ":", "self", ".", "instance2index", ",", "'instances'", ":", "self", ".", "instances", ",", "\n", "'singletions'", ":", "list", "(", "self", ".", "singletons", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.__from_json": [[103, 110], ["set"], "methods", ["None"], ["", "", "def", "__from_json", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "instances", "=", "data", "[", "\"instances\"", "]", "\n", "self", ".", "instance2index", "=", "data", "[", "\"instance2index\"", "]", "\n", "if", "'singletions'", "in", "data", ":", "\n", "            ", "self", ".", "singletons", "=", "set", "(", "data", "[", "'singletions'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "singletons", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.save": [[111, 127], ["json.dump", "os.path.exists", "os.makedirs", "alphabet.Alphabet.get_content", "alphabet.Alphabet.open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_content", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["", "", "def", "save", "(", "self", ",", "output_directory", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Save both alhpabet records to the given directory.\n        :param output_directory: Directory to save model and weights.\n        :param name: The alphabet saving name, optional.\n        :return:\n        \"\"\"", "\n", "saving_name", "=", "name", "if", "name", "else", "self", ".", "__name", "\n", "try", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_directory", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_directory", ")", "\n", "\n", "", "json", ".", "dump", "(", "self", ".", "get_content", "(", ")", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "output_directory", ",", "saving_name", "+", "\".json\"", ")", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "logger", ".", "warn", "(", "\"Alphabet is not saved: %s\"", "%", "repr", "(", "e", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load": [[128, 139], ["alphabet.Alphabet.__from_json", "json.load", "len", "alphabet.Alphabet.open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.__from_json", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.load", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["", "", "def", "load", "(", "self", ",", "input_directory", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Load model architecture and weights from the give directory. This allow we use old models even the structure\n        changes.\n        :param input_directory: Directory to save model and weights\n        :return:\n        \"\"\"", "\n", "loading_name", "=", "name", "if", "name", "else", "self", ".", "__name", "\n", "self", ".", "__from_json", "(", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "input_directory", ",", "loading_name", "+", "\".json\"", ")", ")", ")", ")", "\n", "self", ".", "next_index", "=", "len", "(", "self", ".", "instances", ")", "+", "self", ".", "offset", "\n", "self", ".", "keep_growing", "=", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.Sentence.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "words", ",", "word_ids", ",", "char_seqs", ",", "char_id_seqs", ")", ":", "\n", "        ", "self", ".", "words", "=", "words", "\n", "self", ".", "word_ids", "=", "word_ids", "\n", "self", ".", "char_seqs", "=", "char_seqs", "\n", "self", ".", "char_id_seqs", "=", "char_id_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.Sentence.length": [[11, 13], ["len"], "methods", ["None"], ["", "def", "length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.DependencyInstance.__init__": [[16, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sentence", ",", "postags", ",", "pos_ids", ",", "heads", ",", "types", ",", "type_ids", ")", ":", "\n", "        ", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "postags", "=", "postags", "\n", "self", ".", "pos_ids", "=", "pos_ids", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "types", "=", "types", "\n", "self", ".", "type_ids", "=", "type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.DependencyInstance.length": [[24, 26], ["instance.DependencyInstance.sentence.length"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length"], ["", "def", "length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentence", ".", "length", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.__init__": [[29, 37], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sentence", ",", "postags", ",", "pos_ids", ",", "chunk_tags", ",", "chunk_ids", ",", "ner_tags", ",", "ner_ids", ")", ":", "\n", "        ", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "postags", "=", "postags", "\n", "self", ".", "pos_ids", "=", "pos_ids", "\n", "self", ".", "chunk_tags", "=", "chunk_tags", "\n", "self", ".", "chunk_ids", "=", "chunk_ids", "\n", "self", ".", "ner_tags", "=", "ner_tags", "\n", "self", ".", "ner_ids", "=", "ner_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length": [[38, 40], ["instance.NERInstance.sentence.length"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.instance.NERInstance.length"], ["", "def", "length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentence", ".", "length", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.utils.get_main_deplabel": [[11, 13], ["label.split"], "function", ["None"], ["def", "load_embedding_dict", "(", "embedding", ",", "embedding_path", ",", "normalize_digits", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLLXReader.__init__": [[10, 17], ["open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "type_alphabet", ",", "lang_id", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "self", ".", "__word_alphabet", "=", "word_alphabet", "\n", "self", ".", "__char_alphabet", "=", "char_alphabet", "\n", "self", ".", "__pos_alphabet", "=", "pos_alphabet", "\n", "self", ".", "__type_alphabet", "=", "type_alphabet", "\n", "self", ".", "lang_id", "=", "lang_id", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLLXReader.close": [[18, 20], ["reader.CoNLLXReader.__source_file.close"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "__source_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLLXReader.getNext": [[21, 99], ["reader.CoNLLXReader.__source_file.readline", "len", "instance.DependencyInstance", "reader.CoNLLXReader.strip", "reader.CoNLLXReader.decode", "lines.append", "reader.CoNLLXReader.__source_file.readline", "words.append", "word_ids.append", "char_seqs.append", "char_id_seqs.append", "postags.append", "pos_ids.append", "types.append", "type_ids.append", "heads.append", "char_seqs.append", "char_id_seqs.append", "int", "utils.get_main_deplabel", "words.append", "io_multi.get_word_index_with_spec", "word_ids.append", "postags.append", "pos_ids.append", "types.append", "type_ids.append", "heads.append", "words.append", "word_ids.append", "char_seqs.append", "char_id_seqs.append", "postags.append", "pos_ids.append", "types.append", "type_ids.append", "heads.append", "instance.Sentence", "len", "reader.CoNLLXReader.split", "reader.CoNLLXReader.__word_alphabet.get_index", "reader.CoNLLXReader.__pos_alphabet.get_index", "reader.CoNLLXReader.__type_alphabet.get_index", "chars.append", "char_ids.append", "len", "utils.DIGIT_RE.sub", "reader.CoNLLXReader.__pos_alphabet.get_index", "reader.CoNLLXReader.__type_alphabet.get_index", "reader.CoNLLXReader.__word_alphabet.get_index", "reader.CoNLLXReader.__pos_alphabet.get_index", "reader.CoNLLXReader.__type_alphabet.get_index", "reader.CoNLLXReader.strip", "reader.CoNLLXReader.__char_alphabet.get_index", "reader.CoNLLXReader.__char_alphabet.get_index", "reader.CoNLLXReader.__char_alphabet.get_index"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.utils.get_main_deplabel", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io_multi.lang_id.get_word_index_with_spec", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index"], ["", "def", "getNext", "(", "self", ",", "normalize_digits", "=", "True", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "while", "line", "is", "not", "None", "and", "len", "(", "line", ".", "strip", "(", ")", ")", ">", "0", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "lines", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "\n", "", "length", "=", "len", "(", "lines", ")", "\n", "if", "length", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "words", "=", "[", "]", "\n", "word_ids", "=", "[", "]", "\n", "char_seqs", "=", "[", "]", "\n", "char_id_seqs", "=", "[", "]", "\n", "postags", "=", "[", "]", "\n", "pos_ids", "=", "[", "]", "\n", "types", "=", "[", "]", "\n", "type_ids", "=", "[", "]", "\n", "heads", "=", "[", "]", "\n", "\n", "if", "symbolic_root", ":", "\n", "            ", "words", ".", "append", "(", "ROOT", ")", "\n", "word_ids", ".", "append", "(", "self", ".", "__word_alphabet", ".", "get_index", "(", "ROOT", ")", ")", "\n", "char_seqs", ".", "append", "(", "[", "ROOT_CHAR", ",", "]", ")", "\n", "char_id_seqs", ".", "append", "(", "[", "self", ".", "__char_alphabet", ".", "get_index", "(", "ROOT_CHAR", ")", ",", "]", ")", "\n", "postags", ".", "append", "(", "ROOT_POS", ")", "\n", "pos_ids", ".", "append", "(", "self", ".", "__pos_alphabet", ".", "get_index", "(", "ROOT_POS", ")", ")", "\n", "types", ".", "append", "(", "ROOT_TYPE", ")", "\n", "type_ids", ".", "append", "(", "self", ".", "__type_alphabet", ".", "get_index", "(", "ROOT_TYPE", ")", ")", "\n", "heads", ".", "append", "(", "0", ")", "\n", "\n", "", "for", "tokens", "in", "lines", ":", "\n", "            ", "chars", "=", "[", "]", "\n", "char_ids", "=", "[", "]", "\n", "for", "char", "in", "tokens", "[", "1", "]", ":", "\n", "                ", "chars", ".", "append", "(", "char", ")", "\n", "char_ids", ".", "append", "(", "self", ".", "__char_alphabet", ".", "get_index", "(", "char", ")", ")", "\n", "", "if", "len", "(", "chars", ")", ">", "utils", ".", "MAX_CHAR_LENGTH", ":", "\n", "                ", "chars", "=", "chars", "[", ":", "utils", ".", "MAX_CHAR_LENGTH", "]", "\n", "char_ids", "=", "char_ids", "[", ":", "utils", ".", "MAX_CHAR_LENGTH", "]", "\n", "", "char_seqs", ".", "append", "(", "chars", ")", "\n", "char_id_seqs", ".", "append", "(", "char_ids", ")", "\n", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "4", "]", "\n", "head", "=", "int", "(", "tokens", "[", "6", "]", ")", "\n", "type", "=", "utils", ".", "get_main_deplabel", "(", "tokens", "[", "7", "]", ")", "\n", "\n", "words", ".", "append", "(", "word", ")", "\n", "# ===== modified: with lang_id prefix (with backoff to default lang)", "\n", "one_word_id", "=", "get_word_index_with_spec", "(", "self", ".", "__word_alphabet", ",", "word", ",", "self", ".", "lang_id", ")", "\n", "word_ids", ".", "append", "(", "one_word_id", ")", "\n", "# =====", "\n", "\n", "postags", ".", "append", "(", "pos", ")", "\n", "pos_ids", ".", "append", "(", "self", ".", "__pos_alphabet", ".", "get_index", "(", "pos", ")", ")", "\n", "\n", "types", ".", "append", "(", "type", ")", "\n", "type_ids", ".", "append", "(", "self", ".", "__type_alphabet", ".", "get_index", "(", "type", ")", ")", "\n", "\n", "heads", ".", "append", "(", "head", ")", "\n", "\n", "", "if", "symbolic_end", ":", "\n", "            ", "words", ".", "append", "(", "END", ")", "\n", "word_ids", ".", "append", "(", "self", ".", "__word_alphabet", ".", "get_index", "(", "END", ")", ")", "\n", "char_seqs", ".", "append", "(", "[", "END_CHAR", ",", "]", ")", "\n", "char_id_seqs", ".", "append", "(", "[", "self", ".", "__char_alphabet", ".", "get_index", "(", "END_CHAR", ")", ",", "]", ")", "\n", "postags", ".", "append", "(", "END_POS", ")", "\n", "pos_ids", ".", "append", "(", "self", ".", "__pos_alphabet", ".", "get_index", "(", "END_POS", ")", ")", "\n", "types", ".", "append", "(", "END_TYPE", ")", "\n", "type_ids", ".", "append", "(", "self", ".", "__type_alphabet", ".", "get_index", "(", "END_TYPE", ")", ")", "\n", "heads", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "DependencyInstance", "(", "Sentence", "(", "words", ",", "word_ids", ",", "char_seqs", ",", "char_id_seqs", ")", ",", "postags", ",", "pos_ids", ",", "heads", ",", "types", ",", "\n", "type_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.__init__": [[102, 109], ["open"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.open"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ",", "word_alphabet", ",", "char_alphabet", ",", "pos_alphabet", ",", "chunk_alphabet", ",", "ner_alphabet", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "self", ".", "__word_alphabet", "=", "word_alphabet", "\n", "self", ".", "__char_alphabet", "=", "char_alphabet", "\n", "self", ".", "__pos_alphabet", "=", "pos_alphabet", "\n", "self", ".", "__chunk_alphabet", "=", "chunk_alphabet", "\n", "self", ".", "__ner_alphabet", "=", "ner_alphabet", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close": [[110, 112], ["reader.CoNLL03Reader.__source_file.close"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "__source_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.reader.CoNLL03Reader.getNext": [[113, 168], ["reader.CoNLL03Reader.__source_file.readline", "len", "instance.NERInstance", "reader.CoNLL03Reader.strip", "reader.CoNLL03Reader.decode", "lines.append", "reader.CoNLL03Reader.__source_file.readline", "char_seqs.append", "char_id_seqs.append", "words.append", "word_ids.append", "postags.append", "pos_ids.append", "chunk_tags.append", "chunk_ids.append", "ner_tags.append", "ner_ids.append", "instance.Sentence", "len", "reader.CoNLL03Reader.split", "chars.append", "char_ids.append", "len", "utils.DIGIT_RE.sub", "reader.CoNLL03Reader.__word_alphabet.get_index", "reader.CoNLL03Reader.__pos_alphabet.get_index", "reader.CoNLL03Reader.__chunk_alphabet.get_index", "reader.CoNLL03Reader.__ner_alphabet.get_index", "reader.CoNLL03Reader.strip", "reader.CoNLL03Reader.__char_alphabet.get_index"], "methods", ["home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.models.parsing.StackPtrNet.decode", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index", "home.repos.pwc.inspect_result.uclanlp_CrossLingualDepParser.io.alphabet.Alphabet.get_index"], ["", "def", "getNext", "(", "self", ",", "normalize_digits", "=", "True", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "while", "line", "is", "not", "None", "and", "len", "(", "line", ".", "strip", "(", ")", ")", ">", "0", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "lines", ".", "append", "(", "line", ".", "split", "(", "' '", ")", ")", "\n", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "\n", "", "length", "=", "len", "(", "lines", ")", "\n", "if", "length", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "words", "=", "[", "]", "\n", "word_ids", "=", "[", "]", "\n", "char_seqs", "=", "[", "]", "\n", "char_id_seqs", "=", "[", "]", "\n", "postags", "=", "[", "]", "\n", "pos_ids", "=", "[", "]", "\n", "chunk_tags", "=", "[", "]", "\n", "chunk_ids", "=", "[", "]", "\n", "ner_tags", "=", "[", "]", "\n", "ner_ids", "=", "[", "]", "\n", "\n", "for", "tokens", "in", "lines", ":", "\n", "            ", "chars", "=", "[", "]", "\n", "char_ids", "=", "[", "]", "\n", "for", "char", "in", "tokens", "[", "1", "]", ":", "\n", "                ", "chars", ".", "append", "(", "char", ")", "\n", "char_ids", ".", "append", "(", "self", ".", "__char_alphabet", ".", "get_index", "(", "char", ")", ")", "\n", "", "if", "len", "(", "chars", ")", ">", "utils", ".", "MAX_CHAR_LENGTH", ":", "\n", "                ", "chars", "=", "chars", "[", ":", "utils", ".", "MAX_CHAR_LENGTH", "]", "\n", "char_ids", "=", "char_ids", "[", ":", "utils", ".", "MAX_CHAR_LENGTH", "]", "\n", "", "char_seqs", ".", "append", "(", "chars", ")", "\n", "char_id_seqs", ".", "append", "(", "char_ids", ")", "\n", "\n", "word", "=", "utils", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "1", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "2", "]", "\n", "chunk", "=", "tokens", "[", "3", "]", "\n", "ner", "=", "tokens", "[", "4", "]", "\n", "\n", "words", ".", "append", "(", "word", ")", "\n", "word_ids", ".", "append", "(", "self", ".", "__word_alphabet", ".", "get_index", "(", "word", ")", ")", "\n", "\n", "postags", ".", "append", "(", "pos", ")", "\n", "pos_ids", ".", "append", "(", "self", ".", "__pos_alphabet", ".", "get_index", "(", "pos", ")", ")", "\n", "\n", "chunk_tags", ".", "append", "(", "chunk", ")", "\n", "chunk_ids", ".", "append", "(", "self", ".", "__chunk_alphabet", ".", "get_index", "(", "chunk", ")", ")", "\n", "\n", "ner_tags", ".", "append", "(", "ner", ")", "\n", "ner_ids", ".", "append", "(", "self", ".", "__ner_alphabet", ".", "get_index", "(", "ner", ")", ")", "\n", "\n", "", "return", "NERInstance", "(", "Sentence", "(", "words", ",", "word_ids", ",", "char_seqs", ",", "char_id_seqs", ")", ",", "postags", ",", "pos_ids", ",", "chunk_tags", ",", "chunk_ids", ",", "\n", "ner_tags", ",", "ner_ids", ")", "\n", "", "", ""]]}