{"home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.check_existing_pt_files": [[15, 25], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "    ", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup exisiting pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.parse_args": [[27, 41], ["argparse.ArgumentParser", "opts.add_md_help_argument", "opts.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.add_md_help_argument", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.preprocess_opts", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.parse_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.build_save_text_dataset_in_shards": [[43, 117], ["os.path.getsize", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "print", "print", "onmt.io.ShardedTextCorpusIterator.hit_end", "onmt.io.TextDataset", "print", "torch.save", "ret_list.append"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_text_dataset_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "per_corpus", ",", "nli_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "'''\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n    '''", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "print", "(", "\"Warning. The corpus %s is larger than 10M bytes, you can \"", "\n", "\"set '-max_shard_size' to process it by small shards \"", "\n", "\"to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "tgt_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "per_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "per_corpus", ",", "opt", ".", "per_seq_length_trunc", ",", "\n", "\"per\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "nli_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "nli_corpus", ",", "opt", ".", "nli_seq_length_trunc", ",", "\n", "\"nli\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "print", "(", "' * divide corpus into shards and build dataset separately'", "\n", "'(shard_size = %d bytes).'", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "onmt", ".", "io", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "tgt_iter", ",", "per_iter", ",", "nli_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "per_seq_length", "=", "opt", ".", "per_seq_length", ",", "\n", "nli_seq_length", "=", "opt", ".", "nli_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "print", "(", "\" * saving train data shard to %s.\"", "%", "pt_file", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.build_save_dataset": [[119, 164], ["onmt.io.build_dataset", "print", "torch.save", "preprocess.build_save_text_dataset_in_shards"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_text_dataset_in_shards"], ["", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "per_corpus", "=", "opt", ".", "train_per", "\n", "nli_corpus", "=", "opt", ".", "train_nli", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "per_corpus", "=", "opt", ".", "valid_per", "\n", "nli_corpus", "=", "opt", ".", "valid_nli", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_text_dataset_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "per_corpus", ",", "nli_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "onmt", ".", "io", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "src_corpus", ",", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "print", "(", "\" * saving train dataset to %s.\"", "%", "pt_file", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.build_save_vocab": [[166, 177], ["onmt.io.build_vocab", "torch.save", "onmt.io.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "onmt", ".", "io", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.None.preprocess.main": [[179, 199], ["preprocess.parse_args", "print", "onmt.io.get_num_features", "onmt.io.get_num_features", "print", "print", "print", "onmt.io.get_fields", "print", "preprocess.build_save_dataset", "print", "preprocess.build_save_vocab", "print", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.parse_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "\n", "print", "(", "\"Extracting features...\"", ")", "\n", "src_nfeats", "=", "onmt", ".", "io", ".", "get_num_features", "(", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "onmt", ".", "io", ".", "get_num_features", "(", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "print", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "print", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "print", "(", "\"Loading Fields object...\"", ")", "\n", "fields", "=", "onmt", ".", "io", ".", "get_fields", "(", "opt", ".", "data_type", ",", "src_nfeats", ",", "tgt_nfeats", ")", "\n", "\n", "print", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "print", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n", "print", "(", "\"Building & saving validation data...\"", ")", "\n", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpFormatter._format_usage": [[502, 504], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpFormatter.format_help": [[505, 509], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpFormatter.start_section": [[510, 513], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpFormatter._format_action": [[514, 526], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpAction.__init__": [[529, 538], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.MarkdownHelpAction.__call__": [[539, 543], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.DeprecateAction.__init__": [[546, 549], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.DeprecateAction.__call__": [[550, 554], ["argparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "argparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.model_opts": [[5, 115], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Deocder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "group", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "\n", "# Genenerator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.preprocess_opts": [[117, 217], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Data options", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training nli data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation nli data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes.\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "\n", "help", "=", "\"Path to an existing source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "\n", "help", "=", "\"Path to an existing target vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum persona sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate persona sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum nli sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate nli sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.train_opts": [[219, 386], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_epochN_PPL.pt where PPL is the\n                       validation perplexity\"\"\"", ")", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                           path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "group", ".", "add_argument", "(", "'-g_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-g_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                           Recommended settings: sgd = 1, adagrad = 0.1,\n                           adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                               Recommended settings: sgd = 1, adagrad = 0.1,\n                               adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) epoch has gone past\n                       start_decay_at\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this\n                       epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including\n                       this epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.translate_opts": [[388, 479], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Persona sentence to use (one line per\n                           personas, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"nli sentence to use (one line per\n                           nlis, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.opts.add_md_help_argument": [[481, 484], ["parser.add_argument"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.DatasetLazyIter.__init__": [[114, 126], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.DatasetLazyIter.__iter__": [[127, 133], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n", "while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.DatasetLazyIter.__len__": [[134, 140], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.DatasetLazyIter.get_cur_dataset": [[141, 143], ["None"], "methods", ["None"], ["", "def", "get_cur_dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.DatasetLazyIter._next_dataset_iterator": [[144, 161], ["onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "next"], "methods", ["None"], ["", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n", "# We clear `fields` when saving, restore when loading.", "\n", "", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "onmt", ".", "io", ".", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.report_func": [[76, 100], ["onmt.Statistics.output", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics.log"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.output", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "report_func", "(", "epoch", ",", "batch", ",", "num_batches", ",", "\n", "start_time", ",", "lr", ",", "report_stats", ",", "report_flag", ")", ":", "\n", "    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "# if batch % opt.report_every == -1 % opt.report_every:", "\n", "if", "report_flag", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "report_stats", ".", "log", "(", "\"progress\"", ",", "experiment", ",", "lr", ")", "\n", "", "report_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.make_dataset_iter": [[163, 180], ["train.DatasetLazyIter", "max", "len", "len"], "function", ["None"], ["", "", "def", "make_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over during each train epoch. We implement simple\n    ordered iterator strategy here, but more sophisticated strategy\n    like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "batch_size_fn", "=", "None", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "sofar", "+", "max", "(", "len", "(", "new", ".", "tgt", ")", ",", "len", "(", "new", ".", "src", ")", ")", "+", "1", "\n", "\n", "", "", "device", "=", "opt", ".", "gpuid", "[", "0", "]", "if", "opt", ".", "gpuid", "else", "-", "1", "\n", "\n", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.make_loss_compute": [[182, 200], ["onmt.Utils.use_gpu", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute.cuda"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "def", "make_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "onmt", ".", "Loss", ".", "NMTLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "\n", "label_smoothing", "=", "opt", ".", "label_smoothing", ")", "\n", "\n", "", "if", "use_gpu", "(", "opt", ")", ":", "\n", "        ", "compute", ".", "cuda", "(", ")", "\n", "\n", "", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.train_model": [[202, 244], ["train.make_loss_compute", "train.make_loss_compute", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "range", "print", "train.lazily_load_dataset", "train.make_dataset_iter", "onmt.Trainer.train", "print", "print", "train.make_dataset_iter", "onmt.Trainer.validate", "print", "print", "onmt.Trainer.epoch_step", "train.lazily_load_dataset", "trainer.train.log", "trainer.validate.log", "trainer.validate.ppl", "onmt.Trainer.drop_checkpoint", "trainer.train.ppl", "trainer.train.accuracy", "trainer.validate.ppl", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy"], ["", "def", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", ":", "\n", "\n", "    ", "train_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "disc", ",", "nli", ",", "train_loss", ",", "valid_loss", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "\n", "trunc_size", ",", "shard_size", ",", "data_type", ",", "\n", "opt", ".", "normalization", ",", "opt", ".", "accum_count", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "train_iter", "=", "make_dataset_iter", "(", "train_datasets", ",", "fields", ",", "opt", ")", "\n", "train_stats", "=", "trainer", ".", "train", "(", "train_iter", ",", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_iter", "=", "make_dataset_iter", "(", "lazily_load_dataset", "(", "\"valid\"", ")", ",", "\n", "fields", ",", "opt", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", "valid_iter", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "train_stats", ".", "log", "(", "\"train\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "valid_stats", ".", "log", "(", "\"valid\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "\n", "# 4. Update the learning rate", "\n", "", "trainer", ".", "epoch_step", "(", "valid_stats", ".", "ppl", "(", ")", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "model_opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.check_save_model_path": [[246, 251], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "", "def", "check_save_model_path", "(", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.tally_parameters": [[253, 265], ["sum", "print", "model.named_parameters", "print", "print", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "print", "(", "'encoder: '", ",", "enc", ")", "\n", "print", "(", "'decoder: '", ",", "dec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.lazily_load_dataset": [[267, 294], ["sorted", "torch.load", "torch.load", "print", "glob.glob", "train.lazily_load_dataset.lazy_dataset_loader"], "function", ["None"], ["", "def", "lazily_load_dataset", "(", "corpus_type", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "print", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "return", "dataset", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one onmt.io.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.load_fields": [[296, 317], ["onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "dict", "torch.load", "torch.load", "print", "print", "dict.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab"], ["", "", "def", "load_fields", "(", "dataset", ",", "data_type", ",", "checkpoint", ")", ":", "\n", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "load_fields_from_vocab", "(", "\n", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", ",", "data_type", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "dataset", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "fields", "[", "'per'", "]", ".", "vocab", "=", "fields", "[", "'tgt'", "]", ".", "vocab", "\n", "\n", "# if checkpoint is not None:", "\n", "#     print('Loading vocab from checkpoint at %s.' % opt.train_from)", "\n", "#     fields = onmt.io.load_fields_from_vocab(", "\n", "#                 checkpoint['vocab'], data_type)", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'src'", "]", ".", "vocab", ")", ",", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "' * vocabulary size. target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.collect_report_features": [[319, 327], ["onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "enumerate", "enumerate", "print", "print", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features"], ["", "def", "collect_report_features", "(", "fields", ")", ":", "\n", "    ", "src_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'src'", ")", "\n", "tgt_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'tgt'", ")", "\n", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "print", "(", "' * src feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "print", "(", "' * tgt feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.build_model": [[329, 339], ["print", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "print", "onmt.Utils.use_gpu", "len", "print", "torch.DataParallel"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", ":", "\n", "    ", "print", "(", "'Building model...'", ")", "\n", "model", ",", "disc", ",", "nli", "=", "onmt", ".", "ModelConstructor", ".", "make_base_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "print", "(", "'Multi gpu training: '", ",", "opt", ".", "gpuid", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "opt", ".", "gpuid", ",", "dim", "=", "1", ")", "\n", "", "print", "(", "model", ")", "\n", "\n", "return", "model", ",", "disc", ",", "nli", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.build_optim": [[341, 362], ["onmt.Optim.set_parameters", "print", "onmt.Optim.optimizer.load_state_dict", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.set_parameters"], ["", "def", "build_optim", "(", "model", ",", "checkpoint", ",", "type", ",", "optim", ",", "learning_rate", ")", ":", "\n", "    ", "if", "opt", ".", "train_from", "and", "checkpoint", "and", "False", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "type", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "type", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "onmt", ".", "Optim", "(", "\n", "optim", ",", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.NLI_pretrain.train.main": [[364, 411], ["print", "train.lazily_load_dataset", "print", "next", "itertools.chain", "train.load_fields", "train.collect_report_features", "train.build_model", "train.tally_parameters", "train.check_save_model_path", "train.build_optim", "train.build_optim", "train.build_optim", "train.train_model", "print", "torch.load", "torch.load", "torch.load", "torch.load"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.load_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.collect_report_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.tally_parameters", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.check_save_model_path", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.train_model"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# Lazily load a list of train/validate dataset.", "\n", "    ", "print", "(", "\"Lazily loading train/validate datasets from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Peek the fisrt dataset to determine the data_type.", "\n", "# (This will load the first dataset.)", "\n", "first_dataset", "=", "next", "(", "train_datasets", ")", "\n", "train_datasets", "=", "chain", "(", "[", "first_dataset", "]", ",", "train_datasets", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear.", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "d_train_from", ":", "\n", "            ", "d_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "d_train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "first_dataset", ",", "data_type", ",", "checkpoint", ")", "\n", "\n", "# Report src/tgt features.", "\n", "collect_report_features", "(", "fields", ")", "\n", "\n", "# Build model.", "\n", "model", ",", "disc", ",", "nli", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "tally_parameters", "(", "model", ")", "\n", "check_save_model_path", "(", ")", "\n", "\n", "# Build optimizer.", "\n", "g_optim", "=", "build_optim", "(", "model", ",", "checkpoint", ",", "'g_optim'", ",", "opt", ".", "g_optim", ",", "opt", ".", "g_learning_rate", ")", "\n", "d_optim", "=", "build_optim", "(", "disc", ",", "checkpoint", ",", "'d_optim'", ",", "opt", ".", "d_optim", ",", "opt", ".", "d_learning_rate", ")", "\n", "nli_optim", "=", "build_optim", "(", "nli", ",", "checkpoint", ",", "'nli_optim'", ",", "opt", ".", "nli_optim", ",", "opt", ".", "nli_learning_rate", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings": [[22, 54], ["len", "onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "make_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Make an Embeddings instance.\n    Args:\n        opt: the option in current environment.\n        word_dict(Vocab): words dictionary.\n        feature_dicts([Vocab], optional): a list of feature dictionary.\n        for_encoder(bool): make Embeddings for encoder or decoder?\n    \"\"\"", "\n", "if", "for_encoder", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "src_word_vec_size", "\n", "", "else", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "tgt_word_vec_size", "\n", "\n", "", "word_padding_idx", "=", "word_dict", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", "\n", "num_word_embeddings", "=", "len", "(", "word_dict", ")", "\n", "\n", "feats_padding_idx", "=", "[", "feat_dict", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", "\n", "for", "feat_dict", "in", "feature_dicts", "]", "\n", "num_feat_embeddings", "=", "[", "len", "(", "feat_dict", ")", "for", "feat_dict", "in", "\n", "feature_dicts", "]", "\n", "\n", "return", "Embeddings", "(", "word_vec_size", "=", "embedding_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feats_padding_idx", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_encoder": [[56, 76], ["onmt.modules.TransformerEncoder", "onmt.modules.CNNEncoder", "onmt.Models.MeanEncoder", "onmt.Models.RNNEncoder"], "function", ["None"], ["", "def", "make_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "\"transformer\"", ":", "\n", "        ", "return", "TransformerEncoder", "(", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNEncoder", "(", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"mean\"", ":", "\n", "        ", "return", "MeanEncoder", "(", "opt", ".", "enc_layers", ",", "embeddings", ")", "\n", "", "else", ":", "\n", "# \"rnn\" or \"brnn\"", "\n", "        ", "return", "RNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_decoder": [[78, 112], ["onmt.modules.TransformerDecoder", "onmt.modules.CNNDecoder", "onmt.Models.InputFeedRNNDecoder", "onmt.Models.StdRNNDecoder"], "function", ["None"], ["", "", "def", "make_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this decoder.\n    \"\"\"", "\n", "if", "opt", ".", "decoder_type", "==", "\"transformer\"", ":", "\n", "        ", "return", "TransformerDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "decoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "", "elif", "opt", ".", "input_feed", ":", "\n", "        ", "return", "InputFeedRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "", "else", ":", "\n", "        ", "return", "StdRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_discriminitor": [[113, 121], ["onmt.modules.Disc"], "function", ["None"], ["", "", "def", "make_discriminitor", "(", "opt", ",", "embeddings", ",", "dsc_dict", ")", ":", "\n", "    ", "\"\"\"\n    Various decoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this discriminitor.\n    \"\"\"", "\n", "return", "Disc", "(", "opt", ".", "tgt_word_vec_size", ",", "opt", ".", "rnn_size", ",", "embeddings", ",", "dsc_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_nli_discriminitor": [[122, 124], ["onmt.modules.NLI"], "function", ["None"], ["", "def", "make_nli_discriminitor", "(", "opt", ",", "embeddings", ",", "dsc_dict", ")", ":", "\n", "    ", "return", "NLI", "(", "opt", ".", "tgt_word_vec_size", ",", "opt", ".", "rnn_size", ",", "embeddings", ",", "dsc_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model": [[125, 141], ["torch.load", "torch.load", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "ModelConstructor.make_base_model", "model.eval", "model.generator.eval", "onmt.Utils.use_gpu"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "fields", "=", "onmt", ".", "io", ".", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", "=", "opt", ".", "data_type", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "for", "arg", "in", "dummy_opt", ":", "\n", "        ", "if", "arg", "not", "in", "model_opt", ":", "\n", "            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", "[", "arg", "]", "\n", "\n", "", "", "model", ",", "disc", ",", "nli", "=", "make_base_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model": [[143, 279], ["onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "ModelConstructor.make_embeddings", "ModelConstructor.make_decoder", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "ModelConstructor.make_embeddings", "ModelConstructor.make_discriminitor", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "ModelConstructor.make_embeddings", "ModelConstructor.make_nli_discriminitor", "onmt.Models.NMTModel", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "ModelConstructor.make_embeddings", "ModelConstructor.make_encoder", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "onmt.io.collect_feature_vocabs", "ModelConstructor.make_embeddings", "ModelConstructor.make_encoder", "torch.Sequential", "onmt.modules.CopyGenerator", "print", "onmt.Models.NMTModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "make_discriminitor.load_state_dict", "make_nli_discriminitor.load_state_dict", "hasattr", "hasattr", "onmt.Models.NMTModel.cuda", "make_discriminitor.cuda", "make_nli_discriminitor.cuda", "onmt.Models.NMTModel.cpu", "make_discriminitor.cpu", "make_nli_discriminitor.cpu", "onmt.modules.ImageEncoder", "AssertionError", "AssertionError", "AssertionError", "torch.Linear", "torch.LogSoftmax", "make_discriminitor.load_state_dict", "make_nli_discriminitor.load_state_dict", "print", "onmt.Models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.Models.NMTModel.encoder.embeddings.load_pretrained_vectors", "onmt.Models.NMTModel.decoder.embeddings.load_pretrained_vectors", "onmt.modules.AudioEncoder", "len", "p.data.uniform_", "p.data.uniform_"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_decoder", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_discriminitor", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_nli_discriminitor", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_encoder", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_embeddings", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_encoder", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.AudioEncoder.AudioEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.AudioEncoder.AudioEncoder.load_pretrained_vectors"], ["", "def", "make_base_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ",", "d_checkpoint", "=", "None", ",", "nli_checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        model_opt: the option loaded from checkpoint.\n        fields: `Field` objects for the model.\n        gpu(bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n    Returns:\n        the NMTModel.\n    \"\"\"", "\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", "]", ",", "(", "\"Unsupported model type %s\"", "%", "(", "model_opt", ".", "model_type", ")", ")", "\n", "\n", "# Make encoder.", "\n", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "src_dict", "=", "fields", "[", "\"src\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "onmt", ".", "io", ".", "collect_feature_vocabs", "(", "fields", ",", "'src'", ")", "\n", "src_embeddings", "=", "make_embeddings", "(", "model_opt", ",", "src_dict", ",", "\n", "feature_dicts", ")", "\n", "encoder", "=", "make_encoder", "(", "model_opt", ",", "src_embeddings", ")", "\n", "\n", "ref_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "onmt", ".", "io", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "ref_embeddings", "=", "make_embeddings", "(", "model_opt", ",", "ref_dict", ",", "\n", "feature_dicts", ")", "\n", "ref_encoder", "=", "make_encoder", "(", "model_opt", ",", "ref_embeddings", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"img\"", ":", "\n", "        ", "encoder", "=", "ImageEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"audio\"", ":", "\n", "        ", "encoder", "=", "AudioEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "model_opt", ".", "sample_rate", ",", "\n", "model_opt", ".", "window_size", ")", "\n", "\n", "# Make decoder.", "\n", "", "tgt_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "onmt", ".", "io", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "tgt_embeddings", "=", "make_embeddings", "(", "model_opt", ",", "tgt_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "tgt_embeddings", ".", "word_lut", ".", "weight", "=", "src_embeddings", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "make_decoder", "(", "model_opt", ",", "tgt_embeddings", ")", "\n", "\n", "# Make discriminator", "\n", "dsc_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "onmt", ".", "io", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "dsc_embeddings", "=", "make_embeddings", "(", "model_opt", ",", "dsc_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "        ", "if", "tgt_dict", "!=", "dsc_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "", "disc", "=", "make_discriminitor", "(", "model_opt", ",", "dsc_embeddings", ",", "dsc_dict", ")", "\n", "\n", "# Make NLI discriminator", "\n", "nli_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "onmt", ".", "io", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "nli_embeddings", "=", "make_embeddings", "(", "model_opt", ",", "nli_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "        ", "if", "tgt_dict", "!=", "dsc_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "", "nli", "=", "make_nli_discriminitor", "(", "model_opt", ",", "nli_embeddings", ",", "nli_dict", ")", "\n", "\n", "# Make NMTModel(= encoder + decoder).", "\n", "model", "=", "NMTModel", "(", "encoder", ",", "decoder", ",", "ref_encoder", ")", "\n", "model", ".", "model_type", "=", "model_opt", ".", "model_type", "\n", "\n", "# Make Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "        ", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "rnn_size", ",", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading model parameters.'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "disc", ".", "load_state_dict", "(", "checkpoint", "[", "'disc'", "]", ")", "\n", "nli", ".", "load_state_dict", "(", "checkpoint", "[", "'nli'", "]", ")", "\n", "if", "d_checkpoint", ":", "\n", "            ", "disc", ".", "load_state_dict", "(", "d_checkpoint", "[", "'disc'", "]", ")", "\n", "", "if", "nli_checkpoint", ":", "\n", "            ", "nli", ".", "load_state_dict", "(", "d_checkpoint", "[", "'nli'", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "print", "(", "'Intializing model parameters.'", ")", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "hasattr", "(", "model", ".", "encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ",", "model_opt", ".", "fix_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ",", "model_opt", ".", "fix_word_vecs_dec", ")", "\n", "\n", "# Add generator to model (this registers it as parameter of model).", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "\n", "# Make the whole model leverage GPU if indicated to do so.", "\n", "if", "gpu", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "disc", ".", "cuda", "(", ")", "\n", "nli", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "cpu", "(", ")", "\n", "disc", ".", "cpu", "(", ")", "\n", "nli", ".", "cpu", "(", ")", "\n", "\n", "", "return", "model", ",", "disc", ",", "nli", "\n", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.__init__": [[34, 46], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "loss", "=", "0", ",", "n_words", "=", "0", ",", "n_correct", "=", "0", ",", "d1", "=", "0", ",", "d2", "=", "0", ",", "n_acc", "=", "0", ",", "n_batchsize", "=", "0", ",", "step_type", "=", "'teacher_force'", ")", ":", "\n", "        ", "self", ".", "loss", "=", "loss", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "n_correct", "=", "n_correct", "\n", "self", ".", "n_src_words", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "d1", "=", "d1", "\n", "self", ".", "d2", "=", "d2", "\n", "self", ".", "n_acc", "=", "n_acc", "\n", "self", ".", "n_batch", "=", "n_batchsize", "\n", "self", ".", "step_type", "=", "step_type", "\n", "self", ".", "num_batchs", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update": [[47, 64], ["math.exp", "math.exp", "math.exp", "math.exp"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "stat", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "loss", "+=", "stat", ".", "loss", "\n", "self", ".", "n_words", "+=", "stat", ".", "n_words", "\n", "self", ".", "n_correct", "+=", "stat", ".", "n_correct", "\n", "self", ".", "n_acc", "+=", "stat", ".", "n_acc", "\n", "self", ".", "n_batch", "+=", "stat", ".", "n_batch", "\n", "self", ".", "step_type", "=", "stat", ".", "step_type", "\n", "\n", "\n", "if", "mode", "==", "'valid'", ":", "\n", "            ", "self", ".", "d1", "+=", "math", ".", "exp", "(", "-", "stat", ".", "d1", ")", "\n", "self", ".", "d2", "+=", "math", ".", "exp", "(", "-", "stat", ".", "d2", ")", "\n", "self", ".", "num_batchs", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "d1", "=", "math", ".", "exp", "(", "-", "stat", ".", "d1", ")", "\n", "self", ".", "d2", "=", "math", ".", "exp", "(", "-", "stat", ".", "d2", ")", "\n", "self", ".", "num_batchs", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy": [[65, 67], ["None"], "methods", ["None"], ["", "", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "return", "100", "*", "(", "self", ".", "n_correct", "/", "self", ".", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl": [[68, 70], ["math.exp", "min"], "methods", ["None"], ["", "def", "ppl", "(", "self", ")", ":", "\n", "        ", "self", ".", "n_words", "=", "self", ".", "n_words", "+", "1", "\n", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "loss", "/", "self", ".", "n_words", ",", "100", ")", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.d_acc": [[71, 73], ["None"], "methods", ["None"], ["\n", "", "def", "d_acc", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "d1", "/", "self", ".", "num_batchs", "+", "self", ".", "d2", "/", "self", ".", "num_batchs", ")", "/", "2", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.nli_acc": [[74, 76], ["None"], "methods", ["None"], ["\n", "", "def", "nli_acc", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_acc", "/", "self", ".", "n_batch", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.elapsed_time": [[77, 79], ["time.time"], "methods", ["None"], ["\n", "", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.output": [[80, 107], ["Trainer.Statistics.elapsed_time", "sys.stdout.flush", "print", "print", "print", "Trainer.Statistics.accuracy", "Trainer.Statistics.ppl", "time.time", "Trainer.Statistics.d_acc", "Trainer.Statistics.nli_acc"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.elapsed_time", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.d_acc", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.nli_acc"], ["\n", "", "def", "output", "(", "self", ",", "epoch", ",", "batch", ",", "n_batches", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           epoch (int): current epoch\n           batch (int): current batch\n           n_batch (int): total batches\n           start (int): start time of epoch.\n        \"\"\"", "\n", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "if", "self", ".", "step_type", "==", "'teacher_force'", "or", "self", ".", "step_type", "==", "'self_sample'", ":", "\n", "            ", "print", "(", "(", "\"Epoch %2d, %s %5d/%5d; acc: %6.2f; ppl: %6.2f; \"", "+", "\n", "\"%3.0f src tok/s; %3.0f tgt tok/s; %6.0f s elapsed\"", ")", "%", "\n", "(", "epoch", ",", "self", ".", "step_type", ",", "batch", ",", "n_batches", ",", "\n", "self", ".", "accuracy", "(", ")", ",", "\n", "self", ".", "ppl", "(", ")", ",", "\n", "self", ".", "n_src_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "self", ".", "n_words", "/", "(", "t", "+", "1e-5", ")", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "", "elif", "self", ".", "step_type", "==", "'d_step'", ":", "\n", "            ", "print", "(", "\"Epoch %2d, %s %5d/%5d; d: %.5f\"", "%", "\n", "(", "epoch", ",", "self", ".", "step_type", ",", "batch", ",", "n_batches", ",", "self", ".", "d_acc", "(", ")", ")", ")", "\n", "", "elif", "self", ".", "step_type", "==", "'nli_step'", ":", "\n", "            ", "print", "(", "\"Epoch %2d, %s %5d/%5d; nli: %.5f\"", "%", "\n", "(", "epoch", ",", "self", ".", "step_type", ",", "batch", ",", "n_batches", ",", "self", ".", "nli_acc", "(", ")", ")", ")", "\n", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.log": [[108, 114], ["Trainer.Statistics.elapsed_time", "experiment.add_scalar_value", "experiment.add_scalar_value", "experiment.add_scalar_value", "experiment.add_scalar_value", "Trainer.Statistics.ppl", "Trainer.Statistics.accuracy"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.elapsed_time", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy"], ["\n", "", "def", "log", "(", "self", ",", "prefix", ",", "experiment", ",", "lr", ")", ":", "\n", "        ", "t", "=", "self", ".", "elapsed_time", "(", ")", "\n", "experiment", ".", "add_scalar_value", "(", "prefix", "+", "\"_ppl\"", ",", "self", ".", "ppl", "(", ")", ")", "\n", "experiment", ".", "add_scalar_value", "(", "prefix", "+", "\"_accuracy\"", ",", "self", ".", "accuracy", "(", ")", ")", "\n", "experiment", ".", "add_scalar_value", "(", "prefix", "+", "\"_tgtper\"", ",", "self", ".", "n_words", "/", "t", ")", "\n", "experiment", ".", "add_scalar_value", "(", "prefix", "+", "\"_lr\"", ",", "lr", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.__init__": [[134, 163], ["Trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train"], ["\n", "def", "__init__", "(", "self", ",", "model", ",", "disc", ",", "nli", ",", "\n", "train_loss", ",", "valid_loss", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "\n", "trunc_size", "=", "0", ",", "shard_size", "=", "32", ",", "data_type", "=", "'text'", ",", "\n", "normalization", "=", "\"sents\"", ",", "accum_count", "=", "1", ")", ":", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "disc", "=", "disc", "\n", "self", ".", "nli", "=", "nli", "\n", "self", ".", "train_loss", "=", "train_loss", "\n", "self", ".", "valid_loss", "=", "valid_loss", "\n", "self", ".", "g_optim", "=", "g_optim", "\n", "self", ".", "d_optim", "=", "d_optim", "\n", "self", ".", "nli_optim", "=", "nli_optim", "\n", "self", ".", "trunc_size", "=", "trunc_size", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "accum_count", "=", "accum_count", "\n", "self", ".", "padding_idx", "=", "self", ".", "train_loss", ".", "padding_idx", "\n", "self", ".", "eos_idx", "=", "self", ".", "train_loss", ".", "tgt_vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "EOS_WORD", "]", "\n", "self", ".", "bos_idx", "=", "self", ".", "train_loss", ".", "tgt_vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "BOS_WORD", "]", "\n", "self", ".", "normalization", "=", "normalization", "\n", "assert", "(", "accum_count", ">", "0", ")", "\n", "if", "accum_count", ">", "1", ":", "\n", "            ", "assert", "(", "self", ".", "trunc_size", "==", "0", ")", ",", "\"\"\"To enable accumulated gradients,\n                   you must disable target sequence truncating.\"\"\"", "\n", "\n", "# Set model in training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train": [[164, 385], ["Trainer.Statistics", "Trainer.Statistics", "enumerate", "train_iter.get_cur_dataset", "truebatch.append", "len", "Trainer.Trainer.train.gradient_accumulation"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.get_cur_dataset"], ["\n", "", "def", "train", "(", "self", ",", "train_iter", ",", "epoch", ",", "report_func", "=", "None", ")", ":", "\n", "        ", "\"\"\" Train next epoch.\n        Args:\n            train_iter: training data iterator\n            epoch(int): the epoch number\n            report_func(fn): function for logging\n\n        Returns:\n            stats (:obj:`onmt.Statistics`): epoch loss statistics\n        \"\"\"", "\n", "total_stats", "=", "Statistics", "(", ")", "\n", "report_stats", "=", "Statistics", "(", ")", "\n", "report_freq", "=", "40", "\n", "idx", "=", "0", "\n", "truebatch", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "try", ":", "\n", "            ", "add_on", "=", "0", "\n", "if", "len", "(", "train_iter", ")", "%", "self", ".", "accum_count", ">", "0", ":", "\n", "                ", "add_on", "+=", "1", "\n", "", "num_batches", "=", "len", "(", "train_iter", ")", "/", "self", ".", "accum_count", "+", "add_on", "\n", "", "except", "NotImplementedError", ":", "\n", "# Dynamic batching", "\n", "            ", "num_batches", "=", "-", "1", "\n", "\n", "", "def", "gradient_accumulation", "(", "truebatch_", ",", "total_stats_", ",", "\n", "report_stats_", ",", "nt_", ",", "step_type_", ")", ":", "\n", "            ", "if", "self", ".", "accum_count", ">", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "self", ".", "disc", ".", "zero_grad", "(", ")", "\n", "self", ".", "nli", ".", "zero_grad", "(", ")", "\n", "\n", "# d1_acc, d2_acc = 0.0, 0.0", "\n", "\n", "", "for", "batch", "in", "truebatch_", ":", "\n", "                ", "target_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "# Truncated BPTT", "\n", "if", "self", ".", "trunc_size", ":", "\n", "                    ", "trunc_size", "=", "self", ".", "trunc_size", "\n", "", "else", ":", "\n", "                    ", "trunc_size", "=", "target_size", "\n", "\n", "", "dec_state", "=", "None", "\n", "src", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                    ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "per", "=", "batch", ".", "per", "\n", "nli_data", "=", "batch", ".", "nli", "\n", "\n", "'''\n                    print('-'*50)\n                    for n, n_len in nli_data:\n                        print(n)\n                        print(n_len)\n                    '''", "\n", "\n", "report_stats", ".", "n_src_words", "+=", "src_lengths", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "                    ", "src_lengths", "=", "None", "\n", "ref_lengths", "=", "None", "\n", "\n", "", "tgt_outer", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ",", "target_size", "-", "1", ",", "trunc_size", ")", ":", "\n", "# 1. Create truncated target.", "\n", "                    ", "tgt", "=", "tgt_outer", "[", "j", ":", "j", "+", "trunc_size", "]", "\n", "tgt_lengths", "=", "self", ".", "get_length", "(", "tgt", "[", "1", ":", "]", ")", "# exclude start symbol", "\n", "\n", "# 2. F-prop all but generator.", "\n", "if", "self", ".", "accum_count", "==", "1", ":", "\n", "                        ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "self", ".", "disc", ".", "zero_grad", "(", ")", "\n", "self", ".", "nli", ".", "zero_grad", "(", ")", "\n", "\n", "", "outputs", ",", "attns", ",", "fak_tok", ",", "fak_outputs", ",", "d1", ",", "d2", ",", "n1", ",", "n2", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "if", "step_type_", "==", "'self_sample'", ":", "\n", "                        ", "enc_hidden", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "enc_state", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "context", ",", "enc_hidden", ")", "\n", "\n", "# ref_context, ref_lengths = self.model.encode_ref(ref)", "\n", "ref_context", ",", "ref_lengths", "=", "None", ",", "None", "\n", "fak_tok", ",", "fak_outputs", "=", "self", ".", "model", ".", "infer", "(", "ref_context", ",", "ref_lengths", ",", "tgt", ".", "size", "(", "0", ")", "-", "1", ",", "enc_state", ",", "\n", "context", ",", "src_lengths", ",", "self", ".", "bos_idx", ",", "sample", "=", "False", ")", "\n", "fak_tok", "=", "self", ".", "mask_eos", "(", "fak_tok", ")", "\n", "fak_tok_lengths", "=", "self", ".", "get_length", "(", "fak_tok", "[", "1", ":", "]", ")", "# exclude start symbol", "\n", "fak_tok", "=", "fak_tok", "[", ":", "torch", ".", "max", "(", "fak_tok_lengths", ")", "+", "1", "]", "# remove extra padding symbols in tail", "\n", "fak_outputs", "=", "fak_outputs", "[", ":", "torch", ".", "max", "(", "fak_tok_lengths", ")", "]", "\n", "\n", "# d2 = self.roll_out(src, src_lengths, fak_tok[1:], fak_tok_lengths, per, 3, enc_state, context, src_lengths)[:, :, :1]", "\n", "d2", "=", "self", ".", "disc", "(", "fak_tok", "[", "1", ":", "]", ",", "fak_tok_lengths", ",", "src", ",", "src_lengths", ",", "per", ",", "step_type", "=", "'self_sample'", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "# n2 = self.nli(fak_tok[1:], fak_tok_lengths, src, src_lengths, per, nli_data, step_type='self_sample')[:, :, 2:3]", "\n", "\n", "", "if", "step_type_", "==", "'teacher_force'", ":", "\n", "                        ", "enc_hidden", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "enc_state", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "context", ",", "enc_hidden", ")", "\n", "\n", "outputs", ",", "dec_state", ",", "attns", "=", "self", ".", "model", ".", "decoder", "(", "tgt", "[", ":", "-", "1", "]", ",", "context", ",", "\n", "enc_state", "if", "dec_state", "is", "None", "\n", "else", "dec_state", ",", "\n", "context_lengths", "=", "src_lengths", ")", "\n", "\n", "d1", "=", "Variable", "(", "torch", ".", "ones", "(", "tgt", "[", "1", ":", "]", ".", "size", "(", ")", ")", ",", "requires_grad", "=", "False", ")", "\n", "n1", "=", "Variable", "(", "torch", ".", "ones", "(", "tgt", "[", "1", ":", "]", ".", "size", "(", ")", ")", ",", "requires_grad", "=", "False", ")", "\n", "if", "tgt", ".", "is_cuda", ":", "\n", "                            ", "d1", "=", "d1", ".", "cuda", "(", ")", "\n", "n1", "=", "n1", ".", "cuda", "(", ")", "\n", "\n", "", "", "if", "step_type_", "==", "'d_step'", ":", "\n", "                        ", "enc_hidden", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "enc_state", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "context", ",", "enc_hidden", ")", "\n", "\n", "ref_context", ",", "ref_lengths", "=", "None", ",", "None", "\n", "fak_tok", ",", "fak_outputs", "=", "self", ".", "model", ".", "infer", "(", "ref_context", ",", "ref_lengths", ",", "tgt", ".", "size", "(", "0", ")", "-", "1", ",", "enc_state", ",", "context", ",", "src_lengths", ",", "self", ".", "bos_idx", ")", "\n", "fak_tok", "=", "self", ".", "mask_eos", "(", "fak_tok", ")", "\n", "fak_tok_lengths", "=", "self", ".", "get_length", "(", "fak_tok", "[", "1", ":", "]", ")", "# exclude start symbol", "\n", "\n", "enc_hidden", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "enc_state", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "context", ",", "enc_hidden", ")", "\n", "\n", "outputs", ",", "dec_state", ",", "attns", "=", "self", ".", "model", ".", "decoder", "(", "tgt", "[", ":", "-", "1", "]", ",", "context", ",", "\n", "enc_state", "if", "dec_state", "is", "None", "\n", "else", "dec_state", ",", "\n", "context_lengths", "=", "src_lengths", ")", "\n", "\n", "d1", "=", "self", ".", "disc", "(", "tgt", "[", "1", ":", "]", ",", "tgt_lengths", ",", "src", ",", "src_lengths", ",", "per", ")", "\n", "d2", "=", "self", ".", "disc", "(", "fak_tok", "[", "1", ":", "]", ",", "fak_tok_lengths", ",", "src", ",", "src_lengths", ",", "per", ")", "\n", "\n", "", "if", "step_type_", "==", "'nli_step'", ":", "\n", "                        ", "n1", "=", "self", ".", "nli", "(", "tgt", "[", "1", ":", "]", ",", "tgt_lengths", ",", "src", ",", "src_lengths", ",", "per", ",", "nli_data", ",", "step_type", "=", "step_type", ")", "\n", "n2", "=", "n1", "\n", "\n", "# 3. Compute loss in shards for memory efficiency.", "\n", "", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "\n", "batch", ",", "fak_tok", ",", "outputs", ",", "fak_outputs", ",", "nli_data", ",", "d1", ",", "d2", ",", "n1", ",", "n2", ",", "attns", ",", "j", ",", "\n", "trunc_size", ",", "self", ".", "shard_size", ",", "nt_", ",", "step_type", ")", "\n", "\n", "# 4. Update the parameters and statistics.", "\n", "if", "self", ".", "accum_count", "==", "1", ":", "\n", "                        ", "if", "step_type_", "==", "'d_step'", ":", "\n", "                            ", "pass", "\n", "# self.d_optim.step()", "\n", "", "elif", "step_type_", "==", "'nli_step'", ":", "\n", "                            ", "self", ".", "nli_optim", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                            ", "pass", "\n", "# self.g_optim.step()", "\n", "", "", "total_stats_", ".", "update", "(", "batch_stats", ")", "\n", "report_stats_", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# If truncated, don't backprop fully.", "\n", "if", "dec_state", "is", "not", "None", ":", "\n", "                        ", "dec_state", ".", "detach", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "accum_count", ">", "1", ":", "\n", "                ", "if", "step_type_", "==", "'d_step'", ":", "\n", "                    ", "pass", "\n", "# self.d_optim.step()", "\n", "", "elif", "step_type", "==", "'nli_step'", ":", "\n", "                    ", "self", ".", "nli_optim", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "# self.g_optim.step()", "\n", "\n", "# if d1_acc < 0.5 or (1-d2_acc) < 0.5:", "\n", "#     step_type_ = 'd_step'", "\n", "# else:", "\n", "#     step_type_ = 'g_step'", "\n", "# return step_type_", "\n", "\n", "", "", "", "step_type", "=", "'d_step'", "\n", "for", "i", ",", "batch_", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "            ", "if", "i", "%", "report_freq", "<", "10", ":", "\n", "                ", "step_type", "=", "'nli_step'", "\n", "", "elif", "i", "%", "report_freq", "<", "20", ":", "\n", "                ", "step_type", "=", "'nli_step'", "\n", "", "elif", "i", "%", "report_freq", "<", "30", ":", "\n", "                ", "step_type", "=", "'nli_step'", "\n", "", "else", ":", "\n", "                ", "step_type", "=", "'nli_step'", "\n", "\n", "", "cur_dataset", "=", "train_iter", ".", "get_cur_dataset", "(", ")", "\n", "self", ".", "train_loss", ".", "cur_dataset", "=", "cur_dataset", "\n", "\n", "truebatch", ".", "append", "(", "batch_", ")", "\n", "accum", "+=", "1", "\n", "if", "self", ".", "normalization", "is", "\"tokens\"", ":", "\n", "                ", "normalization", "+=", "batch_", ".", "tgt", "[", "1", ":", "]", ".", "data", ".", "view", "(", "-", "1", ")", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "", "else", ":", "\n", "                ", "normalization", "+=", "batch_", ".", "batch_size", "\n", "\n", "", "if", "accum", "==", "self", ".", "accum_count", ":", "\n", "                ", "gradient_accumulation", "(", "\n", "truebatch", ",", "total_stats", ",", "\n", "report_stats", ",", "normalization", ",", "step_type", ")", "\n", "\n", "if", "report_func", "is", "not", "None", ":", "\n", "                    ", "if", "i", "%", "10", "==", "0", ":", "\n", "                        ", "report_flag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "report_flag", "=", "False", "\n", "\n", "", "report_stats", "=", "report_func", "(", "\n", "epoch", ",", "idx", ",", "num_batches", ",", "\n", "total_stats", ".", "start_time", ",", "self", ".", "g_optim", ".", "lr", ",", "\n", "report_stats", ",", "report_flag", ")", "\n", "\n", "", "truebatch", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "idx", "+=", "1", "\n", "\n", "", "", "if", "len", "(", "truebatch", ")", ">", "0", ":", "\n", "            ", "gradient_accumulation", "(", "\n", "truebatch", ",", "total_stats", ",", "\n", "report_stats", ",", "normalization", ")", "\n", "truebatch", "=", "[", "]", "\n", "\n", "", "return", "total_stats", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.validate": [[386, 424], ["Trainer.Trainer.model.eval", "Trainer.Statistics", "Trainer.Trainer.model.train", "valid_iter.get_cur_dataset", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "Trainer.Trainer.model", "Trainer.Trainer.valid_loss.monolithic_compute_loss", "Trainer.Statistics.update"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.get_cur_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase.monolithic_compute_loss", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["\n", "", "def", "validate", "(", "self", ",", "valid_iter", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`onmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "stats", "=", "Statistics", "(", ")", "\n", "\n", "for", "batch", "in", "valid_iter", ":", "\n", "            ", "cur_dataset", "=", "valid_iter", ".", "get_cur_dataset", "(", ")", "\n", "self", ".", "valid_loss", ".", "cur_dataset", "=", "cur_dataset", "\n", "\n", "src", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "", "tgt", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "per", "=", "batch", ".", "per", "\n", "\n", "# F-prop through the model.", "\n", "outputs", ",", "attns", ",", "_", ",", "_", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "per", ",", "src_lengths", ")", "\n", "\n", "# Compute loss.", "\n", "batch_stats", "=", "self", ".", "valid_loss", ".", "monolithic_compute_loss", "(", "\n", "batch", ",", "outputs", ",", "attns", ")", "\n", "\n", "# Update statistics.", "\n", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# Set model back to training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "stats", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.epoch_step": [[425, 428], ["Trainer.Trainer.d_optim.update_learning_rate", "Trainer.Trainer.g_optim.update_learning_rate"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.update_learning_rate", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.update_learning_rate"], ["\n", "", "def", "epoch_step", "(", "self", ",", "ppl", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "d_optim", ".", "update_learning_rate", "(", "ppl", ",", "epoch", ")", "\n", "return", "self", ".", "g_optim", ".", "update_learning_rate", "(", "ppl", ",", "epoch", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.drop_checkpoint": [[430, 467], ["real_model.state_dict", "real_generator.state_dict", "Trainer.Trainer.disc.state_dict", "Trainer.Trainer.nli.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "onmt.io.save_fields_to_vocab", "real_model.state_dict.items", "valid_stats.accuracy", "valid_stats.ppl"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl"], ["\n", "", "def", "drop_checkpoint", "(", "self", ",", "opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", ":", "\n", "        ", "\"\"\" Save a resumable checkpoint.\n\n        Args:\n            opt (dict): option object\n            epoch (int): epoch number\n            fields (dict): fields and vocabulary\n            valid_stats : statistics of last validation run\n        \"\"\"", "\n", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n", "disc_state_dict", "=", "self", ".", "disc", ".", "state_dict", "(", ")", "\n", "nli_state_dict", "=", "self", ".", "nli", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'disc'", ":", "disc_state_dict", ",", "\n", "'nli'", ":", "nli_state_dict", ",", "\n", "'vocab'", ":", "onmt", ".", "io", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'g_optim'", ":", "self", ".", "g_optim", ",", "\n", "'d_optim'", ":", "self", ".", "d_optim", "\n", "}", "\n", "torch", ".", "save", "(", "checkpoint", ",", "\n", "'%s_acc_%.2f_ppl_%.2f_e%d.pt'", "\n", "%", "(", "opt", ".", "save_model", ",", "valid_stats", ".", "accuracy", "(", ")", ",", "\n", "valid_stats", ".", "ppl", "(", ")", ",", "epoch", ")", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.roll_out": [[473, 501], ["Trainer.Trainer.disc.encode", "seq.size", "range", "torch.autograd.Variable", "torch.autograd.Variable", "range", "Trainer.Trainer.disc().unsqueeze", "Trainer.Trainer.model.sample", "Trainer.Trainer.get_length", "Trainer.Trainer.disc().unsqueeze", "torch.autograd.Variable.append", "torch.autograd.Variable.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable.append", "torch.autograd.Variable.append", "Trainer.Trainer.disc", "Trainer.Trainer.disc"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.NMTModel.sample", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.get_length"], ["\n", "", "def", "roll_out", "(", "self", ",", "src", ",", "src_lengths", ",", "seq", ",", "seq_lengths", ",", "ref", ",", "roll_num", ",", "init_state", ",", "context", ",", "context_lengths", ")", ":", "\n", "        ", "src_hidden", ",", "ref_hidden", ",", "_", ",", "_", "=", "self", ".", "disc", ".", "encode", "(", "src", ",", "src_lengths", ",", "ref", ")", "\n", "seq_len", ",", "batch_size", ",", "_", "=", "seq", ".", "size", "(", ")", "\n", "rewards", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "roll_num", ")", ":", "\n", "            ", "for", "l", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "data", "=", "seq", "[", "0", ":", "l", "]", "# l from 1 to seq_len-1", "\n", "samples", "=", "self", ".", "model", ".", "sample", "(", "\n", "batch_size", ",", "seq_len", ",", "data", ",", "init_state", ",", "context", ",", "context_lengths", ",", "self", ".", "bos_idx", ")", "\n", "sample_lengths", "=", "self", ".", "get_length", "(", "samples", ")", "\n", "pred", "=", "self", ".", "disc", "(", "samples", ",", "sample_lengths", ",", "src", ",", "src_lengths", ",", "ref", ",", "step_type", "=", "'d_step'", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "rewards", ".", "append", "(", "pred", ".", "data", ")", "\n", "", "else", ":", "\n", "                    ", "rewards", "[", "l", "-", "1", "]", "+=", "pred", ".", "data", "\n", "\n", "", "", "pred", "=", "self", ".", "disc", "(", "seq", ",", "seq_lengths", ",", "src", ",", "src_lengths", ",", "ref", ",", "step_type", "=", "'d_step'", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "rewards", ".", "append", "(", "pred", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "rewards", "[", "seq_len", "-", "1", "]", "+=", "pred", ".", "data", "\n", "\n", "", "", "rewards", "=", "Variable", "(", "torch", ".", "cat", "(", "rewards", ",", "dim", "=", "0", ")", "/", "(", "1.0", "*", "roll_num", ")", ")", "\n", "'''\n        print('='*50)\n        print(rewards)\n        '''", "\n", "return", "rewards", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.mask_eos": [[502, 513], ["tensor.squeeze().t", "tensor.squeeze().t.size", "range", "tensor.squeeze().t.t().unsqueeze", "range", "tensor.squeeze", "tensor.squeeze().t.t"], "methods", ["None"], ["\n", "", "def", "mask_eos", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "t", "=", "tensor", ".", "squeeze", "(", "2", ")", ".", "t", "(", ")", "\n", "batch_size", ",", "seq_len", "=", "t", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "flag", "=", "False", "\n", "for", "j", "in", "range", "(", "seq_len", ")", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "t", "[", "i", "]", "[", "j", "]", ".", "data", "[", "0", "]", "=", "self", ".", "padding_idx", "\n", "", "elif", "t", "[", "i", "]", "[", "j", "]", ".", "data", "[", "0", "]", "==", "self", ".", "eos_idx", ":", "\n", "                    ", "flag", "=", "True", "\n", "", "", "", "return", "t", ".", "t", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.get_length": [[514, 518], ["x.squeeze().t.squeeze().t.squeeze().t", "x.squeeze().t.squeeze().t.ne().long", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.squeeze().t.squeeze().t.squeeze", "x.squeeze().t.squeeze().t.ne"], "methods", ["None"], ["\n", "", "def", "get_length", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "squeeze", "(", "2", ")", ".", "t", "(", ")", "\n", "mask", "=", "x", ".", "ne", "(", "self", ".", "padding_idx", ")", ".", "long", "(", ")", "\n", "return", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", ".", "data", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.decode_tensor": [[519, 523], ["t.squeeze().t.squeeze().t.squeeze().t", "print", "t.squeeze().t.squeeze().t.squeeze"], "methods", ["None"], ["\n", "", "def", "decode_tensor", "(", "self", ",", "t", ")", ":", "\n", "        ", "t", "=", "t", ".", "squeeze", "(", "2", ")", ".", "t", "(", ")", "\n", "for", "sample", "in", "t", ":", "\n", "            ", "print", "(", "' '", ".", "join", "(", "[", "self", ".", "train_loss", ".", "tgt_vocab", ".", "itos", "[", "i", ".", "data", "[", "0", "]", "]", "for", "i", "in", "sample", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq": [[5, 13], ["next", "all", "str"], "function", ["None"], ["def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.sequence_mask": [[15, 25], ["lengths.numel", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu": [[27, 30], ["hasattr", "hasattr", "len"], "function", ["None"], ["", "def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "return", "(", "hasattr", "(", "opt", ",", "'gpuid'", ")", "and", "len", "(", "opt", ".", "gpuid", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize": [[32, 55], ["torch.sort", "batch_length.view().tolist.view().tolist", "sorted", "dict", "torch.autograd.Variable", "dict.items", "batch.data.new", "batch_length.view().tolist.view", "enumerate", "batch.size", "enumerate"], "function", ["None"], ["", "def", "formalize", "(", "batch", ",", "batch_length", ",", "batch_first", "=", "False", ")", ":", "\n", "    ", "\"\"\"formalize a batch to sort the batch according to its length\n\n    Args:\n        batch: batch\n        batch_length: batch length list\n    Returns:\n        formalized batch\n    \"\"\"", "\n", "sorted_lengths", ",", "_", "=", "torch", ".", "sort", "(", "batch_length", ",", "descending", "=", "True", ")", "\n", "batch_length", "=", "batch_length", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "index_length", "=", "[", "(", "i", ",", "l", ")", "for", "i", ",", "l", "in", "enumerate", "(", "batch_length", ")", "]", "\n", "ordered_index", "=", "sorted", "(", "index_length", ",", "key", "=", "lambda", "e", ":", "e", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "origin_new", "=", "dict", "(", "[", "(", "v", "[", "0", "]", ",", "k", ")", "for", "k", ",", "v", "in", "enumerate", "(", "ordered_index", ")", "]", ")", "\n", "\n", "sorted_batch", "=", "Variable", "(", "batch", ".", "data", ".", "new", "(", "batch", ".", "size", "(", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "origin_new", ".", "items", "(", ")", ":", "\n", "        ", "if", "batch_first", ":", "\n", "            ", "sorted_batch", "[", "v", "]", "=", "batch", "[", "k", "]", "\n", "", "else", ":", "\n", "            ", "sorted_batch", "[", ":", ",", "v", "]", "=", "batch", "[", ":", ",", "k", "]", "\n", "", "", "return", "sorted_batch", ",", "sorted_lengths", ",", "origin_new", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize": [[57, 70], ["torch.autograd.Variable", "origin_new.items", "batch.data.new", "batch.size"], "function", ["None"], ["", "def", "deformalize", "(", "batch", ",", "origin_new", ")", ":", "\n", "    ", "\"\"\"reform batch in the origin order, batch is the second dimension.\n\n    Args:\n        batch: encoded batch, length*batch_size*dim\n        origin_new: origin->new index dict\n    Returns:\n        reformed batch\n    \"\"\"", "\n", "desorted_batch", "=", "Variable", "(", "batch", ".", "data", ".", "new", "(", "batch", ".", "size", "(", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "origin_new", ".", "items", "(", ")", ":", "\n", "        ", "desorted_batch", "[", ":", ",", "k", "]", "=", "batch", "[", ":", ",", "v", "]", "\n", "", "return", "desorted_batch", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase._check_args": [[38, 43], ["input.size", "lengths.size", "onmt.Utils.aeq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["def", "_check_args", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "s_len", ",", "n_batch", ",", "n_feats", "=", "input", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase.forward": [[44, 60], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (:obj:`LongTensor`):\n               padded sequences of sparse indices `[src_len x batch x nfeat]`\n            lengths (:obj:`LongTensor`): length of each sequence `[batch]`\n            hidden (class specific):\n               initial hidden state.\n\n        Returns:k\n            (tuple of :obj:`FloatTensor`, :obj:`FloatTensor`):\n                * final encoder state, used to initialize decoder\n                   `[layers x batch x hidden]`\n                * contexts for attention, `[src_len x batch x hidden]`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.MeanEncoder.__init__": [[69, 73], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "MeanEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.MeanEncoder.forward": [[74, 82], ["Models.MeanEncoder._check_args", "Models.MeanEncoder.embeddings", "Models.MeanEncoder.size", "Models.MeanEncoder.mean().expand", "Models.MeanEncoder.mean"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "s_len", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "mean", "=", "emb", ".", "mean", "(", "0", ")", ".", "expand", "(", "self", ".", "num_layers", ",", "batch", ",", "emb_dim", ")", "\n", "return", "(", "mean", ",", "mean", ")", ",", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNEncoder.__init__": [[96, 124], ["torch.Module.__init__", "onmt.modules.SRU", "getattr"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "no_pack_padded_seq", "=", "False", "\n", "\n", "# Use pytorch version when available.", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "# SRU doesn't support PackedSequence.", "\n", "            ", "self", ".", "no_pack_padded_seq", "=", "True", "\n", "self", ".", "rnn", "=", "onmt", ".", "modules", ".", "SRU", "(", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNEncoder.forward": [[125, 144], ["Models.RNNEncoder._check_args", "Models.RNNEncoder.embeddings", "Models.RNNEncoder.size", "Models.RNNEncoder.rnn", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase._check_args"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "s_len", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Variable.", "\n", "            ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "lengths", ")", "\n", "\n", "", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "packed_emb", ",", "hidden", ")", "\n", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "            ", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "\n", "", "return", "hidden_t", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase.__init__": [[192, 232], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "Models.RNNDecoderBase._build_rnn", "onmt.modules.GlobalAttention", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.InputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.context_gate_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "self", ".", "_input_size", ",", "hidden_size", ",", "\n", "num_layers", ",", "dropout", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "onmt", ".", "modules", ".", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", "\n", ")", "\n", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", "\n", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase.forward": [[233, 275], ["isinstance", "input.size", "context.size", "onmt.Utils.aeq", "Models.RNNDecoderBase._run_forward_pass", "state.update_state", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "final_output.unsqueeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "coverage.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.InputFeedRNNDecoder._run_forward_pass", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.update_state"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (`LongTensor`): sequences of padded tokens\n                                `[tgt_len x batch x nfeats]`.\n            context (`FloatTensor`): vectors from the encoder\n                 `[src_len x batch x hidden]`.\n            state (:obj:`onmt.Models.DecoderState`):\n                 decoder state object to initialize the decoder\n            context_lengths (`LongTensor`): the padded source lengths\n                `[batch]`.\n        Returns:\n            (`FloatTensor`,:obj:`onmt.Models.DecoderState`,`FloatTensor`):\n                * outputs: output from the decoder\n                         `[tgt_len x batch x hidden]`.\n                * state: final hidden state from the decoder\n                * attns: distribution over src at each tgt\n                        `[tgt_len x batch x src_len]`.\n        \"\"\"", "\n", "# Args Check", "\n", "assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "input_len", ",", "input_batch", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "contxt_len", ",", "contxt_batch", ",", "_", "=", "context", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ")", "\n", "# END Args Check", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "hidden", ",", "outputs", ",", "attns", ",", "coverage", "=", "self", ".", "_run_forward_pass", "(", "\n", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "context_lengths", ")", "\n", "\n", "# Update the state with the result.", "\n", "final_output", "=", "outputs", "[", "-", "1", "]", "\n", "state", ".", "update_state", "(", "hidden", ",", "final_output", ".", "unsqueeze", "(", "0", ")", ",", "\n", "coverage", ".", "unsqueeze", "(", "0", ")", "\n", "if", "coverage", "is", "not", "None", "else", "None", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "for", "k", "in", "attns", ":", "\n", "            ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n", "", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase._fix_enc_hidden": [[276, 284], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["", "def", "_fix_enc_hidden", "(", "self", ",", "h", ")", ":", "\n", "        ", "\"\"\"\n        The encoder hidden is  (layers*directions) x batch x dim.\n        We need to convert it to layers x batch x (directions*dim).\n        \"\"\"", "\n", "if", "self", ".", "bidirectional_encoder", ":", "\n", "            ", "h", "=", "torch", ".", "cat", "(", "[", "h", "[", "0", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", ",", "h", "[", "1", ":", "h", ".", "size", "(", "0", ")", ":", "2", "]", "]", ",", "2", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase.init_decoder_state": [[285, 293], ["isinstance", "Models.RNNDecoderState", "Models.RNNDecoderState", "tuple", "Models.RNNDecoderBase._fix_enc_hidden", "Models.RNNDecoderBase._fix_enc_hidden", "range", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase._fix_enc_hidden", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderBase._fix_enc_hidden"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "if", "isinstance", "(", "enc_hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "return", "RNNDecoderState", "(", "context", ",", "self", ".", "hidden_size", ",", "\n", "tuple", "(", "[", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "enc_hidden", ")", ")", "]", ")", ")", "\n", "", "else", ":", "# GRU", "\n", "            ", "return", "RNNDecoderState", "(", "context", ",", "self", ".", "hidden_size", ",", "\n", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.StdRNNDecoder._run_forward_pass": [[310, 375], ["Models.StdRNNDecoder.embeddings", "isinstance", "input.size", "rnn_output.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "Models.StdRNNDecoder.attn", "Models.StdRNNDecoder.rnn", "Models.StdRNNDecoder.rnn", "rnn_output.transpose().contiguous", "context.transpose", "Models.StdRNNDecoder.context_gate", "Models.StdRNNDecoder.view", "Models.StdRNNDecoder.dropout", "Models.StdRNNDecoder.dropout", "Models.StdRNNDecoder.view", "rnn_output.view", "attn_outputs.view", "rnn_output.transpose", "Models.StdRNNDecoder.size", "rnn_output.size", "attn_outputs.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["def", "_run_forward_pass", "(", "self", ",", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            input (LongTensor): a sequence of input tokens tensors\n                                of size (len x batch x nfeats).\n            context (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n            context_lengths (LongTensor): the source context lengths.\n        Returns:\n            hidden (Variable): final hidden state from the decoder.\n            outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n            coverage (FloatTensor, optional): coverage from the decoder.\n        \"\"\"", "\n", "assert", "not", "self", ".", "_copy", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "# Initialize local and return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "coverage", "=", "None", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "# Result Check", "\n", "", "input_len", ",", "input_batch", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "input_len", ",", "output_len", ")", "\n", "aeq", "(", "input_batch", ",", "output_batch", ")", "\n", "# END Result Check", "\n", "\n", "# Calculate the attention.", "\n", "attn_outputs", ",", "attn_scores", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "# (output_len, batch, d)", "\n", "context", ".", "transpose", "(", "0", ",", "1", ")", ",", "# (contxt_len, batch, d)", "\n", "context_lengths", "=", "context_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "attn_scores", "\n", "\n", "# Calculate the context gate.", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "self", ".", "context_gate", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "attn_outputs", ".", "view", "(", "-", "1", ",", "attn_outputs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n", "outputs", "=", "outputs", ".", "view", "(", "input_len", ",", "input_batch", ",", "self", ".", "hidden_size", ")", "\n", "outputs", "=", "self", ".", "dropout", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self", ".", "dropout", "(", "attn_outputs", ")", "# (input_len, batch, d)", "\n", "\n", "# Return result.", "\n", "", "return", "hidden", ",", "outputs", ",", "attns", ",", "coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.StdRNNDecoder._build_rnn": [[376, 392], ["onmt.modules.SRU", "getattr"], "methods", ["None"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for building standard decoder RNN.\n        \"\"\"", "\n", "# Use pytorch version when available.", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "            ", "return", "onmt", ".", "modules", ".", "SRU", "(", "\n", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n", "", "return", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "\n", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.StdRNNDecoder._input_size": [[393, 399], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Private helper returning the number of expected features.\n        \"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.InputFeedRNNDecoder._run_forward_pass": [[428, 494], ["state.input_feed.squeeze", "Models.InputFeedRNNDecoder.size", "input.size", "onmt.Utils.aeq", "Models.InputFeedRNNDecoder.embeddings", "enumerate", "Models.InputFeedRNNDecoder.dim", "state.coverage.squeeze", "Models.InputFeedRNNDecoder.split", "Models.InputFeedRNNDecoder.attn", "torch.cat.squeeze", "torch.cat.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.InputFeedRNNDecoder.rnn", "Models.InputFeedRNNDecoder.dropout", "context.transpose", "Models.InputFeedRNNDecoder.copy_attn", "context.transpose"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["def", "_run_forward_pass", "(", "self", ",", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See StdRNNDecoder._run_forward_pass() for description\n        of arguments and return values.\n        \"\"\"", "\n", "# Additional args check.", "\n", "output", "=", "state", ".", "input_feed", ".", "squeeze", "(", "0", ")", "\n", "output_batch", ",", "_", "=", "output", ".", "size", "(", ")", "\n", "input_len", ",", "input_batch", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "output_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "# Initialize local and return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "hidden", "=", "state", ".", "hidden", "\n", "coverage", "=", "state", ".", "coverage", ".", "squeeze", "(", "0", ")", "if", "state", ".", "coverage", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "for", "i", ",", "emb_t", "in", "enumerate", "(", "emb", ".", "split", "(", "1", ")", ")", ":", "\n", "            ", "attn_output", ",", "attn", "=", "self", ".", "attn", "(", "\n", "output", ",", "\n", "context", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "context_lengths", "=", "context_lengths", ")", "\n", "\n", "emb_t", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "emb_t", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "output", ",", "attn_output", "]", ",", "1", ")", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb_t", ",", "hidden", ")", "\n", "\n", "# if self.context_gate is not None:", "\n", "#     # TODO: context gate should be employed", "\n", "#     # instead of second RNN transform.", "\n", "#     output = self.context_gate(", "\n", "#         emb_t, rnn_output, attn_output", "\n", "#     )", "\n", "#     output = self.dropout(output)", "\n", "# else:", "\n", "#     output = self.dropout(rnn_output)", "\n", "output", "=", "self", ".", "dropout", "(", "rnn_output", ")", "\n", "outputs", "+=", "[", "output", "]", "\n", "attns", "[", "\"std\"", "]", "+=", "[", "attn", "]", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "coverage", "+", "attn", "if", "coverage", "is", "not", "None", "else", "attn", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n", "# Run the forward pass of the copy attention layer.", "\n", "", "if", "self", ".", "_copy", ":", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "output", ",", "\n", "context", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "\n", "# Return result.", "\n", "", "", "return", "hidden", ",", "outputs", ",", "attns", ",", "coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.InputFeedRNNDecoder._build_rnn": [[495, 505], ["stacked_cell"], "methods", ["None"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "assert", "not", "rnn_type", "==", "\"SRU\"", ",", "\"SRU doesn't support input feed! \"", "\"Please set -input_feed 0!\"", "\n", "if", "rnn_type", "==", "\"LSTM\"", ":", "\n", "            ", "stacked_cell", "=", "onmt", ".", "modules", ".", "StackedLSTM", "\n", "", "else", ":", "\n", "            ", "stacked_cell", "=", "onmt", ".", "modules", ".", "StackedGRU", "\n", "", "return", "stacked_cell", "(", "num_layers", ",", "input_size", ",", "\n", "hidden_size", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.InputFeedRNNDecoder._input_size": [[506, 512], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Using input feed by concatenating input with attention vectors.\n        \"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "+", "self", ".", "hidden_size", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.NMTModel.__init__": [[524, 529], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "ref_encoder", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.NMTModel.forward": [[530, 565], ["Models.NMTModel.encoder", "Models.NMTModel.decoder.init_decoder_state", "Models.NMTModel.decoder"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.init_decoder_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "ref", ",", "lengths", ",", "dec_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (:obj:`Tensor`):\n                a source sequence passed to encoder.\n                typically for inputs this will be a padded :obj:`LongTensor`\n                of size `[len x batch x features]`. however, may be an\n                image or other generic input depending on encoder.\n            tgt (:obj:`LongTensor`):\n                 a target sequence of size `[tgt_len x batch]`.\n            lengths(:obj:`LongTensor`): the src lengths, pre-padding `[batch]`.\n            dec_state (:obj:`DecoderState`, optional): initial decoder state\n        Returns:\n            (:obj:`FloatTensor`, `dict`, :obj:`onmt.Models.DecoderState`):\n\n                 * decoder output `[tgt_len x batch x hidden]`\n                 * dictionary attention dists of `[tgt_len x batch x src_len]`\n                 * final decoder state\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "enc_hidden", ",", "context", "=", "self", ".", "encoder", "(", "src", ",", "lengths", ")", "\n", "enc_state", "=", "self", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "context", ",", "enc_hidden", ")", "\n", "out", ",", "dec_state", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "context", ",", "\n", "enc_state", "if", "dec_state", "is", "None", "\n", "else", "dec_state", ",", "\n", "context_lengths", "=", "lengths", ")", "\n", "if", "self", ".", "multigpu", ":", "\n", "# Not yet supported on multi-gpu", "\n", "            ", "dec_state", "=", "None", "\n", "attns", "=", "None", "\n", "\n", "", "rec_dict", "=", "{", "'init_state'", ":", "enc_state", ",", "'context'", ":", "context", ",", "'context_length'", ":", "lengths", "}", "\n", "return", "out", ",", "attns", ",", "dec_state", ",", "rec_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.NMTModel.sample": [[566, 611], ["torch.autograd.Variable().unsqueeze", "torch.autograd.Variable().unsqueeze", "torch.exp.multinomial().unsqueeze.unsqueeze", "prefix.size", "prefix.chunk", "range", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.exp.multinomial().unsqueeze.cuda", "prefix.size", "Models.NMTModel.decoder", "dec_states.hidden[].detach_", "dec_states.hidden[].detach_", "dec_states.input_feed.detach_", "samples.append", "Models.NMTModel.decoder", "dec_out.squeeze.squeeze.squeeze", "dec_states.hidden[].detach_", "dec_states.hidden[].detach_", "dec_states.input_feed.detach_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "samples.append", "torch.exp.multinomial().unsqueeze", "torch.exp.multinomial().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.autograd.Variable", "Models.NMTModel.generator.forward", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.exp.multinomial", "torch.exp.multinomial"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "seq_len", ",", "prefix", ",", "init_state", ",", "context", ",", "context_lengths", ",", "bos_idx", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prefix: without bos\n        \"\"\"", "\n", "inp", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "bos_idx", "]", "*", "batch_size", ")", ",", "requires_grad", "=", "False", ")", ".", "unsqueeze", "(", "0", ")", "\n", "inp", "=", "inp", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "if", "prefix", ".", "is_cuda", ":", "\n", "            ", "inp", "=", "inp", ".", "cuda", "(", ")", "\n", "\n", "", "given_len", "=", "prefix", ".", "size", "(", "0", ")", "\n", "lis", "=", "prefix", ".", "chunk", "(", "prefix", ".", "size", "(", "0", ")", ",", "dim", "=", "0", ")", "\n", "\n", "dec_states", "=", "init_state", "\n", "samples", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "given_len", ")", ":", "\n", "            ", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "decoder", "(", "\n", "inp", ",", "context", ",", "dec_states", ",", "context_lengths", "=", "context_lengths", ")", "\n", "dec_states", ".", "hidden", "[", "0", "]", ".", "detach_", "(", ")", "\n", "dec_states", ".", "hidden", "[", "1", "]", ".", "detach_", "(", ")", "\n", "dec_states", ".", "input_feed", ".", "detach_", "(", ")", "\n", "inp", "=", "lis", "[", "i", "]", "\n", "samples", ".", "append", "(", "lis", "[", "i", "]", ".", "data", ")", "\n", "\n", "# dec_out, dec_states, attn = self.decoder(", "\n", "#     inp, context, dec_states, context_lengths=context_lengths)", "\n", "# dec_out = dec_out.squeeze(0)", "\n", "# out = torch.exp(self.generator.forward(dec_out))", "\n", "# inp = out.multinomial(1)", "\n", "\n", "", "for", "i", "in", "range", "(", "given_len", ",", "seq_len", ")", ":", "\n", "            ", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "decoder", "(", "\n", "inp", ",", "context", ",", "dec_states", ",", "context_lengths", "=", "context_lengths", ")", "\n", "dec_out", "=", "dec_out", ".", "squeeze", "(", "0", ")", "\n", "dec_states", ".", "hidden", "[", "0", "]", ".", "detach_", "(", ")", "\n", "dec_states", ".", "hidden", "[", "1", "]", ".", "detach_", "(", ")", "\n", "dec_states", ".", "input_feed", ".", "detach_", "(", ")", "\n", "out", "=", "torch", ".", "exp", "(", "self", ".", "generator", ".", "forward", "(", "dec_out", ")", ")", "\n", "samples", ".", "append", "(", "inp", ".", "data", ")", "\n", "inp", "=", "out", ".", "multinomial", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "output", "=", "Variable", "(", "torch", ".", "cat", "(", "samples", ",", "dim", "=", "0", ")", ",", "requires_grad", "=", "False", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.NMTModel.infer": [[612, 644], ["context.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.exp.multinomial.unsqueeze", "torch.exp.multinomial.unsqueeze", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.exp.multinomial.cuda", "Models.NMTModel.decoder", "torch.cat.append", "torch.cat.append", "dec_out.squeeze.squeeze.squeeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "samples.append", "torch.exp.multinomial.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Models.NMTModel.generator.forward", "torch.exp.multinomial", "torch.exp.multinomial", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "[].unsqueeze", "torch.topk", "torch.topk", "torch.topk", "torch.topk"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward"], ["", "def", "infer", "(", "self", ",", "ref_context", ",", "ref_lengths", ",", "seq_len", ",", "init_state", ",", "context", ",", "context_lengths", ",", "bos_idx", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            prefix: without bos\n        \"\"\"", "\n", "batch_size", "=", "context", ".", "size", "(", "1", ")", "\n", "inp", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "bos_idx", "]", "*", "batch_size", ")", ",", "requires_grad", "=", "False", ")", "#.unsqueeze(0)", "\n", "inp", "=", "inp", ".", "unsqueeze", "(", "1", ")", "\n", "inp", "=", "inp", ".", "unsqueeze", "(", "0", ")", "\n", "if", "context", ".", "is_cuda", ":", "\n", "            ", "inp", "=", "inp", ".", "cuda", "(", ")", "\n", "\n", "", "dec_states", "=", "init_state", "\n", "samples", "=", "[", "inp", ".", "data", "]", "\n", "hidden_states", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "decoder", "(", "\n", "inp", ",", "context", ",", "dec_states", ",", "context_lengths", "=", "context_lengths", ")", "\n", "hidden_states", ".", "append", "(", "dec_out", ")", "\n", "dec_out", "=", "dec_out", ".", "squeeze", "(", "0", ")", "\n", "out", "=", "torch", ".", "exp", "(", "self", ".", "generator", ".", "forward", "(", "dec_out", ")", ")", "\n", "samples", ".", "append", "(", "torch", ".", "topk", "(", "out", ",", "1", ")", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", ".", "data", ")", "\n", "if", "sample", ":", "\n", "                ", "inp", "=", "out", ".", "multinomial", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "inp", "=", "torch", ".", "topk", "(", "out", ",", "1", ")", "\n", "", "inp", "=", "inp", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "fak", "=", "Variable", "(", "torch", ".", "cat", "(", "samples", ",", "dim", "=", "0", ")", ",", "requires_grad", "=", "False", ")", "\n", "hidden_states", "=", "torch", ".", "cat", "(", "hidden_states", ",", "dim", "=", "0", ")", "\n", "return", "fak", ",", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.DecoderState.detach": [[653, 657], ["h.detach_"], "methods", ["None"], ["def", "detach", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "_all", ":", "\n", "            ", "if", "h", "is", "not", "None", ":", "\n", "                ", "h", ".", "detach_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.DecoderState.beam_update": [[658, 664], ["e.size", "sent_states.data.copy_", "e.view", "sent_states.data.index_select"], "methods", ["None"], ["", "", "", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "for", "e", "in", "self", ".", "_all", ":", "\n", "            ", "a", ",", "br", ",", "d", "=", "e", ".", "size", "(", ")", "\n", "sent_states", "=", "e", ".", "view", "(", "a", ",", "beam_size", ",", "br", "//", "beam_size", ",", "d", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "sent_states", ".", "data", ".", "copy_", "(", "\n", "sent_states", ".", "data", ".", "index_select", "(", "1", ",", "positions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderState.__init__": [[667, 689], ["context.size", "torch.autograd.Variable().unsqueeze", "torch.autograd.Variable().unsqueeze", "isinstance", "torch.autograd.Variable", "torch.autograd.Variable", "context.data.new().zero_", "context.data.new"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "context", ",", "hidden_size", ",", "rnnstate", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            context (FloatTensor): output from the encoder of size\n                                   len x batch x rnn_size.\n            hidden_size (int): the size of hidden layer of the decoder.\n            rnnstate (Variable): final hidden state from the encoder.\n                transformed to shape: layers x batch x (directions*dim).\n            input_feed (FloatTensor): output from last layer of the decoder.\n            coverage (FloatTensor): coverage output from the decoder.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden", "=", "rnnstate", "\n", "", "self", ".", "coverage", "=", "None", "\n", "\n", "# Init the input feed.", "\n", "batch_size", "=", "context", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "hidden_size", ")", "\n", "self", ".", "input_feed", "=", "Variable", "(", "context", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ",", "\n", "requires_grad", "=", "False", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderState._all": [[690, 693], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "hidden", "+", "(", "self", ".", "input_feed", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderState.update_state": [[694, 701], ["isinstance"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "rnnstate", ",", "input_feed", ",", "coverage", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden", "=", "rnnstate", "\n", "", "self", ".", "input_feed", "=", "input_feed", "\n", "self", ".", "coverage", "=", "coverage", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.RNNDecoderState.repeat_beam_size_times": [[702, 708], ["tuple", "torch.autograd.Variable", "torch.autograd.Variable", "e.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "vars", "=", "[", "Variable", "(", "e", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ",", "volatile", "=", "True", ")", "\n", "for", "e", "in", "self", ".", "_all", "]", "\n", "self", ".", "hidden", "=", "tuple", "(", "vars", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "input_feed", "=", "vars", "[", "-", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.__init__": [[34, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "method", ",", "lr", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_at", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "adagrad_accum", "=", "0.0", ",", "\n", "decay_method", "=", "None", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "model_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "original_lr", "=", "lr", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_at", "=", "start_decay_at", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "adagrad_accum", "=", "adagrad_accum", "\n", "self", ".", "decay_method", "=", "decay_method", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "model_size", "=", "model_size", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.set_parameters": [[56, 73], ["torch.SGD", "torch.Adagrad", "torch.Adadelta", "[].fill_", "torch.Adam", "RuntimeError"], "methods", ["None"], ["", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "[", "p", "for", "p", "in", "params", "if", "p", ".", "requires_grad", "]", "\n", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", ".", "fill_", "(", "self", ".", "adagrad_accum", ")", "\n", "", "", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-9", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim._set_rate": [[74, 77], ["None"], "methods", ["None"], ["", "", "def", "_set_rate", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "lr", "=", "lr", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.step": [[78, 97], ["Optim.Optim.optimizer.step", "Optim.Optim._set_rate", "torch.nn.utils.clip_grad_norm", "min"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.step", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim._set_rate"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "decay_method", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_set_rate", "(", "\n", "self", ".", "original_lr", "*", "\n", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "            ", "clip_grad_norm", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.update_learning_rate": [[98, 115], ["print"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ",", "ppl", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Decay learning rate if val perf does not improve\n        or we hit the start_decay_at limit.\n        \"\"\"", "\n", "\n", "if", "self", ".", "start_decay_at", "is", "not", "None", "and", "epoch", ">=", "self", ".", "start_decay_at", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "", "if", "self", ".", "last_ppl", "is", "not", "None", "and", "ppl", ">", "self", ".", "last_ppl", ":", "\n", "            ", "self", ".", "start_decay", "=", "True", "\n", "\n", "", "if", "self", ".", "start_decay", ":", "\n", "            ", "self", ".", "lr", "=", "self", ".", "lr", "*", "self", ".", "lr_decay", "\n", "print", "(", "\"Decaying learning rate to %g\"", "%", "self", ".", "lr", ")", "\n", "\n", "", "self", ".", "last_ppl", "=", "ppl", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "lr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase.__init__": [[36, 41], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "padding_idx", "=", "tgt_vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._make_shard_state": [[42, 55], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            range_: the range of examples for computing, the whole\n                    batch or a trunc of it?\n            attns: the attns dictionary returned from the model.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._compute_loss": [[56, 68], ["None"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n\n        Args:\n\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            **kwargs(optional): additional info for computing loss.\n        \"\"\"", "\n", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase.monolithic_compute_loss": [[69, 92], ["batch.tgt.size", "torch.autograd.Variable", "torch.autograd.Variable", "Loss.LossComputeBase._make_shard_state", "Loss.LossComputeBase._compute_loss", "batch.tgt.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "rewards.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._compute_loss"], ["", "def", "monolithic_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "attns", ")", ":", "\n", "        ", "\"\"\"\n        Compute the forward loss for the batch.\n\n        Args:\n          batch (batch): batch of labeled examples\n          output (:obj:`FloatTensor`):\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict of :obj:`FloatTensor`) :\n              dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n        Returns:\n            :obj:`onmt.Statistics`: loss statistics\n        \"\"\"", "\n", "range_", "=", "(", "0", ",", "batch", ".", "tgt", ".", "size", "(", "0", ")", ")", "\n", "seq_len", ",", "batch_size", "=", "batch", ".", "tgt", ".", "size", "(", ")", "\n", "rewards", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "[", "1.0", "]", "*", "batch_size", "]", "*", "(", "seq_len", "-", "1", ")", ")", ")", "\n", "if", "output", ".", "is_cuda", ":", "\n", "            ", "rewards", "=", "rewards", ".", "cuda", "(", ")", "\n", "", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ".", "tgt", ",", "output", ",", "rewards", ",", "range_", ",", "attns", ")", "\n", "_", ",", "batch_stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "\n", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase.sharded_compute_loss": [[93, 134], ["onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "Loss.LossComputeBase._make_shard_state", "Loss.shards", "Loss.LossComputeBase._compute_loss", "loss.div().backward", "onmt.Statistics.update", "onmt.Statistics.update", "loss.div"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.shards", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "fak_tok", ",", "output", ",", "fak_output", ",", "nli_data", ",", "d1", ",", "d2", ",", "n1", ",", "n2", ",", "attns", ",", "\n", "cur_trunc", ",", "trunc_size", ",", "shard_size", ",", "\n", "normalization", ",", "step_type", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note harding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          cur_trunc (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n          shard_size (int) : maximum number of examples in a shard\n\n        Returns:\n            :obj:`onmt.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "batch_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "range_", "=", "(", "cur_trunc", ",", "cur_trunc", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "range_", ",", "attns", ")", "\n", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "\n", "loss", ".", "div", "(", "normalization", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "break", "\n", "\n", "", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._stats": [[135, 151], ["target.ne", "pred.eq().masked_select().sum", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "scores.max", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`Statistics` : statistics for this batch.\n        \"\"\"", "\n", "pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", "\n", "return", "onmt", ".", "Statistics", "(", "loss", "[", "0", "]", ",", "non_padding", ".", "sum", "(", ")", ",", "num_correct", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._bottle": [[152, 154], ["v.view", "v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "v", ")", ":", "\n", "        ", "return", "v", ".", "view", "(", "-", "1", ",", "v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._unbottle": [[155, 157], ["v.view", "v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "v", ",", "batch_size", ")", ":", "\n", "        ", "return", "v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.NMTLossCompute.__init__": [[163, 188], ["Loss.LossComputeBase.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.Sigmoid", "torch.Sigmoid", "torch.KLDivLoss", "torch.KLDivLoss", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn.fill_", "torch.randn.fill_", "Loss.NMTLossCompute.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.NLLLoss", "torch.NLLLoss", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ",", "normalization", "=", "\"sents\"", ",", "\n", "label_smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "NMTLossCompute", ",", "self", ")", ".", "__init__", "(", "generator", ",", "tgt_vocab", ")", "\n", "assert", "(", "label_smoothing", ">=", "0.0", "and", "label_smoothing", "<=", "1.0", ")", "\n", "\n", "if", "label_smoothing", ">", "0", ":", "\n", "# When label smoothing is turned on,", "\n", "# KL-divergence between q_{smoothed ground truth prob.}(w)", "\n", "# and p_{prob. computed by model}(w) is minimized.", "\n", "# If label smoothing value is set to zero, the loss", "\n", "# is equivalent to NLLLoss or CrossEntropyLoss.", "\n", "# All non-true labels are uniformly set to low-confidence.", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ")", "\n", "one_hot", "=", "torch", ".", "randn", "(", "1", ",", "len", "(", "tgt_vocab", ")", ")", "\n", "one_hot", ".", "fill_", "(", "label_smoothing", "/", "(", "len", "(", "tgt_vocab", ")", "-", "2", ")", ")", "\n", "one_hot", "[", "0", "]", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "self", ".", "register_buffer", "(", "'one_hot'", ",", "one_hot", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "torch", ".", "ones", "(", "len", "(", "tgt_vocab", ")", ")", "\n", "weight", "[", "self", ".", "padding_idx", "]", "=", "0", "\n", "self", ".", "criterion", "=", "nn", ".", "NLLLoss", "(", "weight", ",", "size_average", "=", "False", ")", "\n", "# self.criterion = GANLoss(self.padding_idx)", "\n", "", "self", ".", "confidence", "=", "1.0", "-", "label_smoothing", "\n", "self", ".", "d_crit", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.NMTLossCompute._make_shard_state": [[189, 194], ["None"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "fak_tok", ",", "output", ",", "rewards", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        ", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "fak_tok", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"rewards\"", ":", "rewards", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.NMTLossCompute._compute_loss": [[196, 222], ["Loss.NMTLossCompute.generator", "rewards.view.view.view", "rewards.view.view.detach_", "target.view", "Loss.NMTLossCompute.criterion", "Loss.NMTLossCompute._stats", "Loss.NMTLossCompute._bottle", "rewards.view.view.repeat", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "Loss.NMTLossCompute.one_hot.repeat", "Loss.NMTLossCompute.scatter_", "torch.autograd.Variable", "torch.autograd.Variable", "Loss.NMTLossCompute.data.clone", "rewards.view.view.size", "rewards.view.view.size", "Loss.NMTLossCompute.size", "tdata.unsqueeze", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "tdata.unsqueeze", "torch.nonzero().squeeze.dim", "torch.nonzero().squeeze.dim", "torch.gather.index_fill_", "torch.gather.index_fill_", "Loss.NMTLossCompute.index_fill_", "torch.gather.sum", "torch.gather.sum", "target.view", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "tdata.eq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._stats", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._bottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "rewards", ")", ":", "\n", "        ", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "output", ")", ")", "\n", "rewards", "=", "rewards", ".", "view", "(", "rewards", ".", "size", "(", "0", ")", "*", "rewards", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "rewards", ".", "detach_", "(", ")", "\n", "scores", "=", "scores", "*", "rewards", ".", "repeat", "(", "1", ",", "scores", ".", "size", "(", "1", ")", ")", "\n", "gtruth", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "if", "self", ".", "confidence", "<", "1", ":", "\n", "            ", "tdata", "=", "gtruth", ".", "data", "\n", "mask", "=", "torch", ".", "nonzero", "(", "tdata", ".", "eq", "(", "self", ".", "padding_idx", ")", ")", ".", "squeeze", "(", ")", "\n", "likelihood", "=", "torch", ".", "gather", "(", "scores", ".", "data", ",", "1", ",", "tdata", ".", "unsqueeze", "(", "1", ")", ")", "\n", "tmp_", "=", "self", ".", "one_hot", ".", "repeat", "(", "gtruth", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "tmp_", ".", "scatter_", "(", "1", ",", "tdata", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "if", "mask", ".", "dim", "(", ")", ">", "0", ":", "\n", "                ", "likelihood", ".", "index_fill_", "(", "0", ",", "mask", ",", "0", ")", "\n", "tmp_", ".", "index_fill_", "(", "0", ",", "mask", ",", "0", ")", "\n", "", "gtruth", "=", "Variable", "(", "tmp_", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "gtruth", ")", "\n", "if", "self", ".", "confidence", "<", "1", ":", "\n", "            ", "loss_data", "=", "-", "likelihood", ".", "sum", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "loss_data", "=", "loss", ".", "data", ".", "clone", "(", ")", "\n", "\n", "", "stats", "=", "self", ".", "_stats", "(", "loss_data", ",", "scores", ".", "data", ",", "target", ".", "view", "(", "-", "1", ")", ".", "data", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.NMTLossCompute.sharded_compute_loss": [[223, 332], ["onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "batch.tgt.size", "torch.autograd.Variable().repeat", "torch.autograd.Variable().repeat", "torch.autograd.Variable().repeat", "torch.autograd.Variable().repeat", "torch.autograd.Variable().repeat.cuda", "torch.autograd.Variable().repeat.cuda", "Loss.NMTLossCompute.d_crit", "Loss.NMTLossCompute.d_crit", "Loss.NMTLossCompute.data.clone", "Loss.NMTLossCompute.data.clone", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "[].float().transpose", "Loss.NMTLossCompute.d_crit", "Loss.NMTLossCompute.backward", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "acc_ind.data.float().view.data.float().view.data.float().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "Loss.NMTLossCompute._make_shard_state", "Loss.shards", "Loss.NMTLossCompute.sigmoid", "Loss.NMTLossCompute.sigmoid", "Loss.NMTLossCompute._make_shard_state", "Loss.shards", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "random.random", "Loss.NMTLossCompute.backward", "Loss.NMTLossCompute.backward", "Loss.NMTLossCompute._compute_loss", "loss.div().backward", "onmt.Statistics.update", "onmt.Statistics.update", "Loss.NMTLossCompute._compute_loss", "loss.div().backward", "onmt.Statistics.update", "onmt.Statistics.update", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "[].float", "acc_ind.data.float().view.data.float().view.data.float", "fak_tok.size", "loss.div", "loss.div"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.shards", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.shards", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "fak_tok", ",", "output", ",", "fak_outputs", ",", "nli_data", ",", "d1", ",", "d2", ",", "n1", ",", "n2", ",", "attns", ",", "\n", "cur_trunc", ",", "trunc_size", ",", "shard_size", ",", "\n", "normalization", ",", "step_type", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note harding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          cur_trunc (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n          shard_size (int) : maximum number of examples in a shard\n\n        Returns:\n            :obj:`onmt.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "batch_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "\n", "# range_ = (0, batch.tgt.size(0))", "\n", "batch_size", "=", "batch", ".", "tgt", ".", "size", "(", "1", ")", "\n", "zero_label", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "[", "0.0", ",", "1.0", "]", "]", ")", ",", "requires_grad", "=", "False", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "zero_label", "=", "zero_label", ".", "cuda", "(", ")", "if", "batch", ".", "tgt", ".", "is_cuda", "else", "zero_label", "\n", "one_label", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "[", "1.0", ",", "0.0", "]", "]", ")", ",", "requires_grad", "=", "False", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", "one_label", "=", "one_label", ".", "cuda", "(", ")", "if", "batch", ".", "tgt", ".", "is_cuda", "else", "one_label", "\n", "\n", "if", "step_type", "==", "'d_step'", ":", "\n", "            ", "d1_loss", "=", "self", ".", "d_crit", "(", "d1", ",", "one_label", ")", "\n", "d2_loss", "=", "self", ".", "d_crit", "(", "d2", ",", "zero_label", ")", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "                ", "d1_loss", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "                ", "d2_loss", ".", "backward", "(", ")", "\n", "\n", "", "d1_data", "=", "d1_loss", ".", "data", ".", "clone", "(", ")", "\n", "d2_data", "=", "d2_loss", ".", "data", ".", "clone", "(", ")", "\n", "return", "onmt", ".", "Statistics", "(", "d1", "=", "d1_data", "[", "0", "]", ",", "d2", "=", "d2_data", "[", "0", "]", ",", "step_type", "=", "'d_step'", ")", "\n", "\n", "", "if", "step_type", "==", "'nli_step'", ":", "\n", "            ", "src", "=", "n1", "\n", "label", "=", "nli_data", "[", "2", "]", "[", "0", "]", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "nli_loss", "=", "self", ".", "d_crit", "(", "src", ",", "label", ")", "\n", "\n", "nli_loss", ".", "backward", "(", ")", "\n", "\n", "_", ",", "src_ind", "=", "torch", ".", "max", "(", "src", ",", "dim", "=", "1", ")", "\n", "_", ",", "tgt_ind", "=", "torch", ".", "max", "(", "label", ",", "dim", "=", "1", ")", "\n", "acc_ind", "=", "torch", ".", "eq", "(", "src_ind", ",", "tgt_ind", ")", "\n", "acc_ind", "=", "acc_ind", ".", "data", ".", "float", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "acc_sum", "=", "torch", ".", "sum", "(", "acc_ind", ")", "\n", "batch_size", "=", "float", "(", "src", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "onmt", ".", "Statistics", "(", "n_acc", "=", "acc_sum", ",", "n_batchsize", "=", "batch_size", ",", "step_type", "=", "'nli_step'", ")", "\n", "\n", "", "if", "step_type", "==", "'teacher_force'", ":", "\n", "            ", "'''\n            d1.shape = len x batchsize x 1, in teacher_force mode all element is 1, torch.FloatTensor.\n            '''", "\n", "rewards", "=", "d1", "\n", "range_", "=", "(", "cur_trunc", ",", "cur_trunc", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ".", "tgt", ",", "output", ",", "rewards", ",", "range_", ",", "attns", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "                ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "(", "loss", ")", ".", "div", "(", "normalization", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "\n", "", "", "if", "step_type", "==", "'self_sample'", ":", "\n", "            ", "'''\n            d2.shape = len x batchsize x 1, torch.FloatTensor.\n            \n            n2.shape = 1 x batchsize x 1, torch.FloatTensor.\n            '''", "\n", "d2", "=", "self", ".", "sigmoid", "(", "d2", ")", "\n", "n2", "=", "self", ".", "sigmoid", "(", "n2", ")", "\n", "'''\n            print('=' * 50)\n            print(d2[-1, :, :])\n            print(n2[-1, :, :])\n            '''", "\n", "\n", "# rewards = (d2 + n2) / 2.0", "\n", "# rewards -= 0.5", "\n", "rewards", "=", "(", "d2", "+", "n2", ")", "-", "0.8", "\n", "\n", "# print(rewards[-1, :, :])", "\n", "range_", "=", "(", "0", ",", "fak_tok", ".", "size", "(", "0", ")", "+", "1", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "fak_tok", ",", "fak_outputs", ",", "rewards", ",", "range_", ",", "attns", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "                ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "(", "loss", ")", ".", "div", "(", "normalization", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "batch_stats", ".", "step_type", "=", "'self_sample'", "\n", "\n", "# loss, stats = self._compute_loss(batch, d_fake, **shard_state)", "\n", "# loss.div(normalization).backward()", "\n", "# batch_stats.update(stats)", "\n", "", "", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.GANLoss.__init__": [[390, 393], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "padding_idx", ")", ":", "\n", "        ", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.GANLoss.forward": [[394, 413], ["target.eq", "target.size", "prob.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "one_hot.cuda.cuda.scatter_", "one_hot.cuda.cuda.type", "torch.autograd.Variable", "torch.autograd.Variable", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select.data.masked_fill_", "torch.masked_select.data.masked_fill_", "reward.view.view.view", "reward.view.view.detach_", "one_hot.cuda.cuda.cuda", "target.data.view", "one_hot.cuda.cuda.cuda", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "reward.view.view.size", "reward.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prob", ",", "target", ",", "reward", ")", ":", "\n", "        ", "mask", "=", "target", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "N", "=", "target", ".", "size", "(", "0", ")", "\n", "C", "=", "prob", ".", "size", "(", "1", ")", "\n", "one_hot", "=", "torch", ".", "zeros", "(", "(", "N", ",", "C", ")", ")", "\n", "if", "prob", ".", "is_cuda", ":", "\n", "            ", "one_hot", "=", "one_hot", ".", "cuda", "(", ")", "\n", "", "one_hot", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "view", "(", "(", "-", "1", ",", "1", ")", ")", ",", "1", ")", "\n", "one_hot", "=", "one_hot", ".", "type", "(", "torch", ".", "ByteTensor", ")", "\n", "one_hot", "=", "Variable", "(", "one_hot", ")", "\n", "if", "prob", ".", "is_cuda", ":", "\n", "            ", "one_hot", "=", "one_hot", ".", "cuda", "(", ")", "\n", "", "loss", "=", "torch", ".", "masked_select", "(", "prob", ",", "one_hot", ")", "\n", "loss", ".", "data", ".", "masked_fill_", "(", "mask", ".", "data", ",", "0.0", ")", "\n", "reward", "=", "reward", ".", "view", "(", "(", "reward", ".", "size", "(", "0", ")", "*", "reward", ".", "size", "(", "1", ")", ",", ")", ")", "\n", "reward", ".", "detach_", "(", ")", "\n", "loss", "=", "loss", "*", "reward", "\n", "loss", "=", "-", "torch", ".", "sum", "(", "loss", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.filter_shard_state": [[334, 340], ["state.items", "isinstance", "torch.autograd.Variable"], "function", ["None"], ["", "", "def", "filter_shard_state", "(", "state", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "        ", "if", "v", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "Variable", ")", "and", "v", ".", "requires_grad", ":", "\n", "                ", "v", "=", "Variable", "(", "v", ".", "data", ",", "requires_grad", "=", "True", ",", "volatile", "=", "False", ")", "\n", "", "yield", "k", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.shards": [[342, 387], ["dict", "zip", "zip", "zip", "torch.autograd.backward", "torch.autograd.backward", "Loss.filter_shard_state", "dict", "dict.items", "zip", "isinstance", "torch.split", "torch.split", "dict.items"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.filter_shard_state"], ["", "", "", "def", "shards", "(", "state", ",", "shard_size", ",", "eval", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        state: A dictionary which corresponds to the output of\n               *LossCompute._make_shard_state(). The values for\n               those keys are Tensor-like or None.\n        shard_size: The maximum size of the shards yielded by the model.\n        eval: If True, only yield the state, nothing else.\n              Otherwise, yield shards.\n\n    Yields:\n        Each yielded shard is a dict.\n\n    Side effect:\n        After the last shard, this function does back-propagation.\n    \"\"\"", "\n", "if", "eval", ":", "\n", "        ", "yield", "state", "\n", "", "else", ":", "\n", "# non_none: the subdict of the state dictionary where the values", "\n", "# are not None.", "\n", "        ", "non_none", "=", "dict", "(", "filter_shard_state", "(", "state", ")", ")", "\n", "\n", "# Now, the iteration:", "\n", "# state is a dictionary of sequences of tensor-like but we", "\n", "# want a sequence of dictionaries of tensors.", "\n", "# First, unzip the dictionary into a sequence of keys and a", "\n", "# sequence of tensor-like sequences.", "\n", "keys", ",", "values", "=", "zip", "(", "*", "(", "(", "k", ",", "torch", ".", "split", "(", "v", ",", "shard_size", ")", ")", "\n", "for", "k", ",", "v", "in", "non_none", ".", "items", "(", ")", ")", ")", "\n", "\n", "# Now, yield a dictionary for each shard. The keys are always", "\n", "# the same. values is a sequence of length #keys where each", "\n", "# element is a sequence of length #shards. We want to iterate", "\n", "# over the shards, not over the keys: therefore, the values need", "\n", "# to be re-zipped by shard and then each shard can be paired", "\n", "# with the keys.", "\n", "for", "shard_tensors", "in", "zip", "(", "*", "values", ")", ":", "\n", "            ", "yield", "dict", "(", "zip", "(", "keys", ",", "shard_tensors", ")", ")", "\n", "\n", "# Assumed backprop'd", "\n", "", "variables", "=", "(", "(", "state", "[", "k", "]", ",", "v", ".", "grad", ".", "data", ")", "for", "k", ",", "v", "in", "non_none", ".", "items", "(", ")", "\n", "if", "isinstance", "(", "v", ",", "Variable", ")", "and", "v", ".", "grad", "is", "not", "None", ")", "\n", "inputs", ",", "grads", "=", "zip", "(", "*", "variables", ")", "\n", "torch", ".", "autograd", ".", "backward", "(", "inputs", ",", "grads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.CheckSRU.__init__": [[16, 18], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CheckSRU", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.CheckSRU.__call__": [[19, 24], ["setattr", "SRU.check_sru_requirement"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.check_sru_requirement"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "values", "==", "'SRU'", ":", "\n", "            ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "# Check pass, set the args.", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.__init__": [[372, 377], ["torch.autograd.Function.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation_type", ",", "d_out", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "super", "(", "SRU_Compute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation_type", "=", "activation_type", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.forward": [[378, 422], ["x.size", "min", "x.new", "x.new", "FUNC", "SRU.SRU_Compute.save_for_backward", "x.size", "u.size", "x.new().zero_", "x.dim", "x.dim", "x.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.new", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.contiguous().data_ptr", "mask_h.data_ptr", "u.contiguous", "init_.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "u", ",", "x", ",", "bias", ",", "init", "=", "None", ",", "mask_h", "=", "None", ")", ":", "\n", "        ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "size", "=", "(", "length", ",", "batch", ",", "d", "*", "bidir", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "c", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "h", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "\n", "FUNC", "=", "SRU_FWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiFWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "h", ".", "data_ptr", "(", ")", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "\n", "self", ".", "save_for_backward", "(", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", ")", "\n", "self", ".", "intermediate", "=", "c", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "last_hidden", "=", "c", "\n", "", "elif", "self", ".", "bidirectional", ":", "\n", "# -> directions x batch x dim", "\n", "            ", "last_hidden", "=", "torch", ".", "stack", "(", "(", "c", "[", "-", "1", ",", ":", ",", ":", "d", "]", ",", "c", "[", "0", ",", ":", ",", "d", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_hidden", "=", "c", "[", "-", "1", "]", "\n", "", "return", "h", ",", "last_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU_Compute.backward": [[423, 474], ["x.size", "min", "u.new", "x.new", "x.new", "FUNC", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "u.size", "x.new().zero_", "x.new", "x.new.sum().view", "x.dim", "u.size", "x.new", "x.size", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "c.data_ptr", "grad_h.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "u.new.data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.new.sum", "x.contiguous().data_ptr", "mask_h.data_ptr", "grad_x.data_ptr", "u.contiguous", "init_.contiguous", "grad_h.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_h", ",", "grad_last", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "grad_last", "=", "torch", ".", "cat", "(", "(", "grad_last", "[", "0", "]", ",", "grad_last", "[", "1", "]", ")", ",", "1", ")", "\n", "", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", "=", "self", ".", "saved_tensors", "\n", "c", "=", "self", ".", "intermediate", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "grad_u", "=", "u", ".", "new", "(", "*", "u", ".", "size", "(", ")", ")", "\n", "grad_bias", "=", "x", ".", "new", "(", "2", ",", "batch", ",", "d", "*", "bidir", ")", "\n", "grad_init", "=", "x", ".", "new", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "\n", "# For DEBUG", "\n", "# size = (length, batch, x.size(-1)) \\", "\n", "#         if x.dim() == 3 else (batch, x.size(-1))", "\n", "# grad_x = x.new(*x.size()) if k_ == 3 else x.new(*size).zero_()", "\n", "\n", "# Normal use", "\n", "grad_x", "=", "x", ".", "new", "(", "*", "x", ".", "size", "(", ")", ")", "if", "k_", "==", "3", "else", "None", "\n", "\n", "FUNC", "=", "SRU_BWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiBWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "grad_h", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "grad_last", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "grad_u", ".", "data_ptr", "(", ")", ",", "\n", "grad_x", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "grad_bias", ".", "data_ptr", "(", ")", ",", "\n", "grad_init", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "return", "grad_u", ",", "grad_x", ",", "grad_bias", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ")", ",", "grad_init", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.__init__": [[477, 498], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "SRU.SRUCell.init_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.init_weight"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "        ", "super", "(", "SRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "activation_type", "=", "2", "if", "use_relu", "else", "(", "1", "if", "use_tanh", "else", "0", ")", "\n", "\n", "out_size", "=", "n_out", "*", "2", "if", "bidirectional", "else", "n_out", "\n", "k", "=", "4", "if", "n_in", "!=", "out_size", "else", "3", "\n", "self", ".", "size_per_dir", "=", "n_out", "*", "k", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_in", ",", "\n", "self", ".", "size_per_dir", "*", "2", "if", "bidirectional", "else", "self", ".", "size_per_dir", "\n", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_out", "*", "4", "if", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ")", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.init_weight": [[499, 503], ["SRU.SRUCell.weight.data.uniform_", "SRU.SRUCell.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "val_range", "=", "(", "3.0", "/", "self", ".", "n_in", ")", "**", "0.5", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val_range", ",", "val_range", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.set_bias": [[504, 510], ["SRU.SRUCell.bias.data[].zero_().add_", "SRU.SRUCell.bias.data[].zero_().add_", "SRU.SRUCell.bias.data[].zero_", "SRU.SRUCell.bias.data[].zero_"], "methods", ["None"], ["", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "n_out", "=", "self", ".", "n_out", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", "*", "2", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.forward": [[511, 543], ["input.size", "x_2d.mm", "torch.autograd.Variable", "torch.autograd.Variable", "SRU.SRUCell.get_dropout_mask_", "x.contiguous().view", "SRU.SRUCell.get_dropout_mask_", "input.dim", "input.dim", "input.data.new().zero_", "SRU.SRUCell.expand_as", "x.dim", "SRU.SRU_Compute", "SRU.SRU_Compute", "x.contiguous", "input.data.new"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.get_dropout_mask_", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.get_dropout_mask_"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "2", "or", "input", ".", "dim", "(", ")", "==", "3", "\n", "n_in", ",", "n_out", "=", "self", ".", "n_in", ",", "self", ".", "n_out", "\n", "batch", "=", "input", ".", "size", "(", "-", "2", ")", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "c0", "=", "Variable", "(", "input", ".", "data", ".", "new", "(", "\n", "batch", ",", "n_out", "if", "not", "self", ".", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "self", ".", "rnn_dropout", ">", "0", ")", ":", "\n", "            ", "mask", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_in", ")", ",", "self", ".", "rnn_dropout", ")", "\n", "x", "=", "input", "*", "mask", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "x_2d", "=", "x", "if", "x", ".", "dim", "(", ")", "==", "2", "else", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_in", ")", "\n", "u", "=", "x_2d", ".", "mm", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "training", "and", "(", "self", ".", "dropout", ">", "0", ")", ":", "\n", "            ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "mask_h", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_out", "*", "bidir", ")", ",", "self", ".", "dropout", ")", "\n", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", ",", "mask_h", "\n", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", "\n", ")", "\n", "\n", "", "return", "h", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRUCell.get_dropout_mask_": [[544, 547], ["torch.autograd.Variable", "torch.autograd.Variable", "w.new().bernoulli_().div_", "w.new().bernoulli_", "w.new"], "methods", ["None"], ["", "def", "get_dropout_mask_", "(", "self", ",", "size", ",", "p", ")", ":", "\n", "        ", "w", "=", "self", ".", "weight", ".", "data", "\n", "return", "Variable", "(", "w", ".", "new", "(", "*", "size", ")", ".", "bernoulli_", "(", "1", "-", "p", ")", ".", "div_", "(", "1", "-", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU.__init__": [[570, 597], ["SRU.check_sru_requirement", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "SRU.SRUCell", "SRU.SRU.rnn_lst.append"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.check_sru_requirement", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "# An entry check here, will catch on train side and translate side", "\n", "# if requirements are not satisfied.", "\n", "        ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "input_size", "\n", "self", ".", "n_out", "=", "hidden_size", "\n", "self", ".", "depth", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "rnn_lst", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "out_size", "=", "hidden_size", "*", "2", "if", "bidirectional", "else", "hidden_size", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "sru_cell", "=", "SRUCell", "(", "\n", "n_in", "=", "self", ".", "n_in", "if", "i", "==", "0", "else", "self", ".", "out_size", ",", "\n", "n_out", "=", "self", ".", "n_out", ",", "\n", "dropout", "=", "dropout", "if", "i", "+", "1", "!=", "num_layers", "else", "0", ",", "\n", "rnn_dropout", "=", "rnn_dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "use_tanh", "=", "use_tanh", ",", "\n", "use_relu", "=", "use_relu", ",", "\n", ")", "\n", "self", ".", "rnn_lst", ".", "append", "(", "sru_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU.set_bias": [[598, 601], ["l.set_bias"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU.set_bias"], ["", "", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "rnn_lst", ":", "\n", "            ", "l", ".", "set_bias", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.SRU.forward": [[602, 634], ["enumerate", "input.dim", "torch.autograd.Variable", "torch.autograd.Variable", "isinstance", "rnn", "lstc.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "input.data.new().zero_", "c0.dim", "h.squeeze", "range", "c0.chunk", "input.data.new", "input.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ",", "return_hidden", "=", "True", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "3", "# (len, batch, n_in)", "\n", "dir_", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "zeros", "=", "Variable", "(", "input", ".", "data", ".", "new", "(", "\n", "input", ".", "size", "(", "1", ")", ",", "self", ".", "n_out", "*", "dir_", "\n", ")", ".", "zero_", "(", ")", ")", "\n", "c0", "=", "[", "zeros", "for", "i", "in", "range", "(", "self", ".", "depth", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "c0", ",", "tuple", ")", ":", "\n", "# RNNDecoderState wraps hidden as a tuple.", "\n", "                ", "c0", "=", "c0", "[", "0", "]", "\n", "", "assert", "c0", ".", "dim", "(", ")", "==", "3", "# (depth, batch, dir_*n_out)", "\n", "c0", "=", "[", "h", ".", "squeeze", "(", "0", ")", "for", "h", "in", "c0", ".", "chunk", "(", "self", ".", "depth", ",", "0", ")", "]", "\n", "\n", "", "prevx", "=", "input", "\n", "lstc", "=", "[", "]", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnn_lst", ")", ":", "\n", "            ", "h", ",", "c", "=", "rnn", "(", "prevx", ",", "c0", "[", "i", "]", ")", "\n", "prevx", "=", "h", "\n", "lstc", ".", "append", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "# fh -> (layers*directions) x batch x dim", "\n", "            ", "fh", "=", "torch", ".", "cat", "(", "lstc", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "torch", ".", "stack", "(", "lstc", ")", "\n", "\n", "", "if", "return_hidden", ":", "\n", "            ", "return", "prevx", ",", "fh", "\n", "", "else", ":", "\n", "            ", "return", "prevx", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.SRU.check_sru_requirement": [[31, 68], ["re.compile", "os.getenv", "torch.cuda.is_available", "torch.cuda.is_available", "AssertionError", "re.match", "AssertionError", "platform.system", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "AssertionError"], "function", ["None"], ["", "", "def", "check_sru_requirement", "(", "abort", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return True if check pass; if check fails and abort is True,\n    raise an Exception, othereise return False.\n    \"\"\"", "\n", "# Check 1.", "\n", "try", ":", "\n", "        ", "if", "platform", ".", "system", "(", ")", "==", "'Windows'", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | findstr cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | findstr pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "else", ":", "# Unix-like systems", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires 'cupy' and 'pynvrtc' \"", "\n", "\"python packages installed.\"", ")", "\n", "\n", "# Check 2.", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "is", "False", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires pytorch built with cuda.\"", ")", "\n", "\n", "# Check 3.", "\n", "", "pattern", "=", "re", ".", "compile", "(", "\".*cuda/lib.*\"", ")", "\n", "ld_path", "=", "os", ".", "getenv", "(", "'LD_LIBRARY_PATH'", ",", "\"\"", ")", "\n", "if", "re", ".", "match", "(", "pattern", ",", "ld_path", ")", "is", "None", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires setting cuda lib path, e.g. \"", "\n", "\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64.\"", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.GlobalAttention.GlobalAttention.__init__": [[62, 85], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "onmt.modules.UtilClass.BottleLinear", "torch.Linear", "torch.Linear", "onmt.modules.UtilClass.BottleLinear"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "assert", "(", "self", ".", "attn_type", "in", "[", "\"dot\"", ",", "\"general\"", ",", "\"mlp\"", "]", ")", ",", "(", "\n", "\"Please select a valid attention type.\"", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "BottleLinear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "BottleLinear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "self", ".", "sm", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.GlobalAttention.GlobalAttention.score": [[86, 128], ["h_s.size", "GlobalAttention.GlobalAttention.view.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "GlobalAttention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "GlobalAttention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "GlobalAttention.GlobalAttention.tanh", "GlobalAttention.GlobalAttention.v().view", "GlobalAttention.GlobalAttention.view.view", "GlobalAttention.GlobalAttention.linear_in", "GlobalAttention.GlobalAttention.view", "GlobalAttention.GlobalAttention.view.view", "h_s.contiguous().view", "GlobalAttention.GlobalAttention.v", "h_s.contiguous", "GlobalAttention.GlobalAttention.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (`FloatTensor`): sequence of queries `[batch x tgt_len x dim]`\n          h_s (`FloatTensor`): sequence of sources `[batch x src_len x dim]`\n\n        Returns:\n          :obj:`FloatTensor`:\n           raw attention scores (unnormalized) for each src index\n          `[batch x tgt_len x src_len]`\n\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "self", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.GlobalAttention.GlobalAttention.forward": [[129, 216], ["GlobalAttention.GlobalAttention.size", "input.unsqueeze.unsqueeze.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "GlobalAttention.GlobalAttention.score", "GlobalAttention.GlobalAttention.sm", "align_vectors.transpose().contiguous.transpose().contiguous.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "GlobalAttention.GlobalAttention.linear_out().view", "input.unsqueeze.unsqueeze.dim", "input.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "coverage.view().unsqueeze", "GlobalAttention.GlobalAttention.linear_cover().view_as", "GlobalAttention.GlobalAttention.tanh", "onmt.Utils.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "GlobalAttention.GlobalAttention.data.masked_fill_", "GlobalAttention.GlobalAttention.view", "GlobalAttention.GlobalAttention.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GlobalAttention.GlobalAttention.linear_out", "coverage.view", "GlobalAttention.GlobalAttention.linear_cover", "float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.sequence_mask", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "context_lengths", "=", "None", ",", "coverage", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          input (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          context (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          context_lengths (`LongTensor`): the source context lengths `[batch]`\n          coverage (`FloatTensor`): None (not supported yet)\n\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "input", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "sourceL", ",", "dim", "=", "context", ".", "size", "(", ")", "\n", "batch_", ",", "targetL", ",", "dim_", "=", "input", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "sourceL_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "context", "+=", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "context", ")", "\n", "context", "=", "self", ".", "tanh", "(", "context", ")", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "align", "=", "self", ".", "score", "(", "input", ",", "context", ")", "\n", "\n", "if", "context_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "context_lengths", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "data", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax to normalize attention weights", "\n", "", "align_vectors", "=", "self", ".", "sm", "(", "align", ".", "view", "(", "batch", "*", "targetL", ",", "sourceL", ")", ")", "\n", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "targetL", ",", "sourceL", ")", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "context", ")", "\n", "\n", "# concatenate", "\n", "concat_c", "=", "torch", ".", "cat", "(", "[", "c", ",", "input", "]", ",", "2", ")", ".", "view", "(", "batch", "*", "targetL", ",", "dim", "*", "2", ")", "\n", "attn_h", "=", "self", ".", "linear_out", "(", "concat_c", ")", ".", "view", "(", "batch", ",", "targetL", ",", "dim", ")", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "attn_h", "=", "self", ".", "tanh", "(", "attn_h", ")", "\n", "\n", "", "if", "one_step", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "squeeze", "(", "1", ")", "\n", "align_vectors", "=", "align_vectors", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Check output sizes", "\n", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "batch_", ",", "sourceL_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "", "else", ":", "\n", "            ", "attn_h", "=", "attn_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "align_vectors", "=", "align_vectors", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Check output sizes", "\n", "targetL_", ",", "batch_", ",", "dim_", "=", "attn_h", ".", "size", "(", ")", "\n", "aeq", "(", "targetL", ",", "targetL_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "targetL_", ",", "batch_", ",", "sourceL_", "=", "align_vectors", ".", "size", "(", ")", "\n", "aeq", "(", "targetL", ",", "targetL_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "sourceL", ",", "sourceL_", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.PositionalEncoding.__init__": [[22, 32], ["torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "Embeddings.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "div_term.expand_as", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "pe", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "max_len", ",", "dim", ")", "\n", "div_term", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "torch", ".", "arange", "(", "0", ",", "dim", "*", "2", ",", "2", ")", "/", "dim", ")", "\n", "pe", "=", "pe", "*", "div_term", ".", "expand_as", "(", "pe", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "pe", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "pe", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.PositionalEncoding.forward": [[33, 41], ["Embeddings.PositionalEncoding.dropout", "torch.autograd.Variable", "torch.autograd.Variable", "Embeddings.PositionalEncoding.pe[].expand_as", "Embeddings.PositionalEncoding.size", "Embeddings.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ")", ":", "\n", "# We must wrap the self.pe in Variable to compute, not the other", "\n", "# way - unwrap emb(i.e. emb.data). Otherwise the computation", "\n", "# wouldn't be watched to build the compute graph.", "\n", "        ", "emb", "=", "emb", "+", "Variable", "(", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", ",", ":", "1", ",", ":", "emb", ".", "size", "(", "2", ")", "]", "\n", ".", "expand_as", "(", "emb", ")", ",", "requires_grad", "=", "False", ")", "\n", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.Embeddings.__init__": [[85, 147], ["vocab_sizes.extend", "emb_dims.extend", "pad_indices.extend", "zip", "onmt.modules.Elementwise", "torch.Module.__init__", "torch.Sequential", "torch.Sequential", "Embeddings.Embeddings.make_embedding.add_module", "torch.Embedding", "torch.Embedding", "sum", "sum", "torch.Sequential", "torch.Sequential", "Embeddings.Embeddings.make_embedding.add_module", "Embeddings.PositionalEncoding", "Embeddings.Embeddings.make_embedding.add_module", "len", "onmt.modules.BottleLinear", "torch.ReLU", "torch.ReLU", "len", "int"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "word_vec_size", ",", "\n", "word_vocab_size", ",", "\n", "word_padding_idx", ",", "\n", "position_encoding", "=", "False", ",", "\n", "feat_merge", "=", "\"concat\"", ",", "\n", "feat_vec_exponent", "=", "0.7", ",", "feat_vec_size", "=", "-", "1", ",", "\n", "feat_padding_idx", "=", "[", "]", ",", "\n", "feat_vocab_sizes", "=", "[", "]", ",", "\n", "dropout", "=", "0", ")", ":", "\n", "\n", "        ", "self", ".", "word_padding_idx", "=", "word_padding_idx", "\n", "\n", "# Dimensions and padding for constructing the word embedding matrix", "\n", "vocab_sizes", "=", "[", "word_vocab_size", "]", "\n", "emb_dims", "=", "[", "word_vec_size", "]", "\n", "pad_indices", "=", "[", "word_padding_idx", "]", "\n", "\n", "# Dimensions and padding for feature embedding matrices", "\n", "# (these have no effect if feat_vocab_sizes is empty)", "\n", "if", "feat_merge", "==", "'sum'", ":", "\n", "            ", "feat_dims", "=", "[", "word_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "            ", "feat_dims", "=", "[", "feat_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "else", ":", "\n", "            ", "feat_dims", "=", "[", "int", "(", "vocab", "**", "feat_vec_exponent", ")", "\n", "for", "vocab", "in", "feat_vocab_sizes", "]", "\n", "", "vocab_sizes", ".", "extend", "(", "feat_vocab_sizes", ")", "\n", "emb_dims", ".", "extend", "(", "feat_dims", ")", "\n", "pad_indices", ".", "extend", "(", "feat_padding_idx", ")", "\n", "\n", "# The embedding matrix look-up tables. The first look-up table", "\n", "# is for words. Subsequent ones are for features, if any exist.", "\n", "emb_params", "=", "zip", "(", "vocab_sizes", ",", "emb_dims", ",", "pad_indices", ")", "\n", "embeddings", "=", "[", "nn", ".", "Embedding", "(", "vocab", ",", "dim", ",", "padding_idx", "=", "pad", ")", "\n", "for", "vocab", ",", "dim", ",", "pad", "in", "emb_params", "]", "\n", "emb_luts", "=", "Elementwise", "(", "feat_merge", ",", "embeddings", ")", "\n", "\n", "# The final output size of word + feature vectors. This can vary", "\n", "# from the word vector size if and only if features are defined.", "\n", "# This is the attribute you should access if you need to know", "\n", "# how big your embeddings are going to be.", "\n", "self", ".", "embedding_size", "=", "(", "sum", "(", "emb_dims", ")", "if", "feat_merge", "==", "'concat'", "\n", "else", "word_vec_size", ")", "\n", "\n", "# The sequence of operations that converts the input sequence", "\n", "# into a sequence of embeddings. At minimum this consists of", "\n", "# looking up the embeddings for each word and feature in the", "\n", "# input. Model parameters may require the sequence to contain", "\n", "# additional operations as well.", "\n", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "make_embedding", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'emb_luts'", ",", "emb_luts", ")", "\n", "\n", "if", "feat_merge", "==", "'mlp'", ":", "\n", "            ", "in_dim", "=", "sum", "(", "emb_dims", ")", "\n", "out_dim", "=", "word_vec_size", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "BottleLinear", "(", "in_dim", ",", "out_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'mlp'", ",", "mlp", ")", "\n", "\n", "", "if", "position_encoding", ":", "\n", "            ", "pe", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embedding_size", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.Embeddings.word_lut": [[148, 151], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "word_lut", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.Embeddings.emb_luts": [[152, 155], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "emb_luts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "make_embedding", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.Embeddings.load_pretrained_vectors": [[156, 168], ["torch.load", "torch.load", "torch.load", "torch.load", "Embeddings.Embeddings.word_lut.weight.data.copy_"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "emb_file", ",", "fixed", ")", ":", "\n", "        ", "\"\"\"Load in pretrained embeddings.\n\n        Args:\n          emb_file (str) : path to torch serialized embeddings\n          fixed (bool) : if true, embeddings are not updated\n        \"\"\"", "\n", "if", "emb_file", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "emb_file", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "if", "fixed", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Embeddings.Embeddings.forward": [[169, 189], ["input.size", "onmt.Utils.aeq", "Embeddings.Embeddings.make_embedding", "Embeddings.Embeddings.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings for words and features.\n\n        Args:\n            input (`LongTensor`): index tensor `[len x batch x nfeat]`\n        Return:\n            `FloatTensor`: word embeddings `[len x batch x embedding_size]`\n        \"\"\"", "\n", "in_length", ",", "in_batch", ",", "nfeat", "=", "input", ".", "size", "(", ")", "\n", "aeq", "(", "nfeat", ",", "len", "(", "self", ".", "emb_luts", ")", ")", "\n", "\n", "emb", "=", "self", ".", "make_embedding", "(", "input", ")", "\n", "\n", "out_length", ",", "out_batch", ",", "emb_size", "=", "emb", ".", "size", "(", ")", "\n", "aeq", "(", "in_length", ",", "out_length", ")", "\n", "aeq", "(", "in_batch", ",", "out_batch", ")", "\n", "aeq", "(", "emb_size", ",", "self", ".", "embedding_size", ")", "\n", "\n", "return", "emb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.ContextGate.__init__": [[26, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.ContextGate.forward": [[36, 43], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "Gate.ContextGate.sig", "Gate.ContextGate.source_proj", "Gate.ContextGate.target_proj", "Gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.SourceContextGate.__init__": [[48, 54], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.SourceContextGate.forward": [[55, 59], ["Gate.SourceContextGate.context_gate", "Gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.TargetContextGate.__init__": [[64, 70], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.TargetContextGate.forward": [[71, 74], ["Gate.TargetContextGate.context_gate", "Gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.BothContextGate.__init__": [[79, 85], ["torch.Module.__init__", "Gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.BothContextGate.forward": [[86, 89], ["Gate.BothContextGate.context_gate", "Gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Gate.context_gate_factory": [[5, 16], ["None"], "function", ["None"], ["def", "context_gate_factory", "(", "type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "type", ")", "\n", "return", "gate_types", "[", "type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.Disc.__init__": [[17, 27], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_input_size", ",", "hidden_size", ",", "embeddings", ",", "_", ")", ":", "\n", "        ", "super", "(", "Disc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "src_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "tgt_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "ref_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "2", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "project1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "64", ")", "\n", "self", ".", "project2", "=", "nn", ".", "Linear", "(", "64", ",", "2", ")", "\n", "self", ".", "dp", "=", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", "\n", "self", ".", "sf", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.Disc.encode": [[28, 54], ["Distriminitor.Disc.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.Disc.src_rnn", "src_lengths.tolist", "onmt.Utils.formalize", "Distriminitor.Disc.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.Disc.ref_rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "onmt.Utils.deformalize", "onmt.Utils.deformalize", "ref_hidden.append", "ref_context.append", "ref_lengths.append", "r.unsqueeze", "r_len_sorted.view().tolist", "r_len_sorted.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize"], ["", "def", "encode", "(", "self", ",", "src", ",", "src_lengths", ",", "ref", ")", ":", "\n", "        ", "src_emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "packed_src_emb", "=", "pack", "(", "src_emb", ",", "src_lengths", ".", "tolist", "(", ")", ")", "\n", "src_output", ",", "src_hidden", "=", "self", ".", "src_rnn", "(", "packed_src_emb", ")", "\n", "\n", "ref_hidden", "=", "[", "]", "\n", "ref_context", "=", "[", "]", "\n", "ref_lengths", "=", "[", "]", "\n", "\n", "for", "r", ",", "r_len", "in", "ref", ":", "\n", "            ", "r", ",", "r_len_sorted", ",", "origin_new", "=", "formalize", "(", "r", ",", "r_len", ")", "\n", "\n", "r_emb", "=", "self", ".", "embeddings", "(", "r", ".", "unsqueeze", "(", "2", ")", ")", "\n", "packed_r_emb", "=", "pack", "(", "r_emb", ",", "r_len_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "r_output", ",", "r_hidden", "=", "self", ".", "ref_rnn", "(", "packed_r_emb", ")", "\n", "r_output", ",", "_", "=", "unpack", "(", "r_output", ")", "\n", "\n", "r_output", "=", "deformalize", "(", "r_output", ",", "origin_new", ")", "\n", "r_hidden", "=", "deformalize", "(", "r_hidden", ",", "origin_new", ")", "\n", "\n", "ref_hidden", ".", "append", "(", "r_hidden", ")", "\n", "ref_context", ".", "append", "(", "r_output", ")", "\n", "ref_lengths", ".", "append", "(", "r_len", ")", "\n", "\n", "", "return", "src_hidden", ",", "ref_hidden", ",", "ref_context", ",", "ref_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.Disc.forward": [[55, 77], ["Distriminitor.Disc.encode", "onmt.Utils.formalize", "Distriminitor.Disc.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.Disc.tgt_rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "onmt.Utils.deformalize", "onmt.Utils.deformalize", "Distriminitor.Disc.project1", "Distriminitor.Disc.project2", "tgt_lengths_sorted.view().tolist", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.Disc.dp", "logits.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.tanh", "torch.tanh", "torch.tanh", "onmt.Utils.deformalize.size", "tgt_lengths_sorted.view", "onmt.Utils.deformalize.squeeze", "logits.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "tgt_lengths", ",", "src", ",", "src_lengths", ",", "ref", ",", "step_type", "=", "'d_step'", ")", ":", "\n", "\n", "        ", "src_hidden", ",", "ref_hidden", ",", "ref_context", ",", "ref_lengths", "=", "self", ".", "encode", "(", "src", ",", "src_lengths", ",", "ref", ")", "\n", "# tgt_lengths_list = tgt_lengths.data.tolist()", "\n", "tgt", ",", "tgt_lengths_sorted", ",", "origin_new", "=", "formalize", "(", "tgt", ",", "tgt_lengths", ")", "\n", "\n", "tgt_emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "packed_tgt_emb", "=", "pack", "(", "tgt_emb", ",", "tgt_lengths_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "tgt_output", ",", "tgt_hidden", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "src_hidden", ")", "\n", "tgt_output", ",", "_", "=", "unpack", "(", "tgt_output", ")", "\n", "\n", "tgt_output", "=", "deformalize", "(", "tgt_output", ",", "origin_new", ")", "\n", "tgt_hidden", "=", "deformalize", "(", "tgt_hidden", ",", "origin_new", ")", "\n", "# logits = self.project1(torch.cat([ref_attn_tgt.squeeze(0), tgt_hidden.squeeze(0)], dim=-1))", "\n", "logits", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits", ")", ")", ")", "\n", "\n", "if", "step_type", "==", "'self_sample'", ":", "\n", "            ", "logits", "=", "logits", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "tgt_output", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.__init__": [[81, 91], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_input_size", ",", "hidden_size", ",", "embeddings", ",", "_", ")", ":", "\n", "        ", "super", "(", "NLI", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "src_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "tgt_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "ref_rnn", "=", "nn", ".", "GRU", "(", "d_input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "0.2", ")", "\n", "self", ".", "project1", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "64", ")", "\n", "self", ".", "project2", "=", "nn", ".", "Linear", "(", "64", ",", "3", ")", "\n", "self", ".", "dp", "=", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", "\n", "self", ".", "sf", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode": [[92, 114], ["Distriminitor.NLI.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.NLI.src_rnn", "src_lengths.tolist", "onmt.Utils.formalize", "Distriminitor.NLI.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.NLI.ref_rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "onmt.Utils.deformalize", "onmt.Utils.deformalize", "per_hidden.append", "per_context.append", "per_lengths.append", "p.unsqueeze", "p_len_sorted.view().tolist", "p_len_sorted.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize"], ["", "def", "encode", "(", "self", ",", "src", ",", "src_lengths", ",", "per", ")", ":", "\n", "        ", "src_emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "packed_src_emb", "=", "pack", "(", "src_emb", ",", "src_lengths", ".", "tolist", "(", ")", ")", "\n", "src_output", ",", "src_hidden", "=", "self", ".", "src_rnn", "(", "packed_src_emb", ")", "\n", "\n", "per_hidden", "=", "[", "]", "\n", "per_context", "=", "[", "]", "\n", "per_lengths", "=", "[", "]", "\n", "\n", "for", "p", ",", "p_len", "in", "per", ":", "\n", "            ", "p", ",", "p_len_sorted", ",", "origin_new", "=", "formalize", "(", "p", ",", "p_len", ")", "\n", "p_emb", "=", "self", ".", "embeddings", "(", "p", ".", "unsqueeze", "(", "2", ")", ")", "\n", "packed_r_emb", "=", "pack", "(", "p_emb", ",", "p_len_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "p_output", ",", "p_hidden", "=", "self", ".", "ref_rnn", "(", "packed_r_emb", ")", "\n", "p_output", ",", "_", "=", "unpack", "(", "p_output", ")", "\n", "p_output", "=", "deformalize", "(", "p_output", ",", "origin_new", ")", "\n", "p_hidden", "=", "deformalize", "(", "p_hidden", ",", "origin_new", ")", "\n", "per_hidden", ".", "append", "(", "p_hidden", ")", "\n", "per_context", ".", "append", "(", "p_output", ")", "\n", "per_lengths", ".", "append", "(", "p_len", ")", "\n", "\n", "", "return", "src_hidden", ",", "per_hidden", ",", "per_context", ",", "per_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode_nli": [[115, 132], ["onmt.Utils.formalize", "Distriminitor.NLI.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.NLI.ref_rnn", "onmt.Utils.deformalize", "onmt.Utils.formalize", "Distriminitor.NLI.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.NLI.ref_rnn", "onmt.Utils.deformalize", "src.unsqueeze", "src_len_sorted.view().tolist", "tgt.unsqueeze", "tgt_len_sorted.view().tolist", "src_len_sorted.view", "tgt_len_sorted.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize"], ["", "def", "encode_nli", "(", "self", ",", "nli_data", ")", ":", "\n", "        ", "src", ",", "src_len", "=", "nli_data", "[", "0", "]", "\n", "tgt", ",", "tgt_len", "=", "nli_data", "[", "1", "]", "\n", "\n", "src", ",", "src_len_sorted", ",", "src_origin_new", "=", "formalize", "(", "src", ",", "src_len", ")", "\n", "src_emb", "=", "self", ".", "embeddings", "(", "src", ".", "unsqueeze", "(", "2", ")", ")", "\n", "packed_src_emb", "=", "pack", "(", "src_emb", ",", "src_len_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "_", ",", "src_hidden", "=", "self", ".", "ref_rnn", "(", "packed_src_emb", ")", "\n", "src_hidden", "=", "deformalize", "(", "src_hidden", ",", "src_origin_new", ")", "\n", "\n", "tgt", ",", "tgt_len_sorted", ",", "tgt_origin_new", "=", "formalize", "(", "tgt", ",", "tgt_len", ")", "\n", "tgt_emb", "=", "self", ".", "embeddings", "(", "tgt", ".", "unsqueeze", "(", "2", ")", ")", "\n", "packed_tgt_emb", "=", "pack", "(", "tgt_emb", ",", "tgt_len_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "_", ",", "tgt_hidden", "=", "self", ".", "ref_rnn", "(", "packed_tgt_emb", ")", "\n", "tgt_hidden", "=", "deformalize", "(", "tgt_hidden", ",", "tgt_origin_new", ")", "\n", "\n", "return", "src_hidden", ",", "tgt_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.forward": [[134, 201], ["Distriminitor.NLI.encode", "onmt.Utils.formalize", "Distriminitor.NLI.embeddings", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "Distriminitor.NLI.tgt_rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "onmt.Utils.deformalize", "onmt.Utils.deformalize", "tgt_lengths_sorted.view().tolist", "Distriminitor.NLI.encode_nli", "Distriminitor.NLI.project1", "Distriminitor.NLI.project2", "Distriminitor.NLI.tgt_rnn", "onmt.Utils.deformalize", "Distriminitor.NLI.project1", "Distriminitor.NLI.project2", "Distriminitor.NLI.tgt_rnn", "onmt.Utils.deformalize", "Distriminitor.NLI.project1", "Distriminitor.NLI.project2", "Distriminitor.NLI.tgt_rnn", "onmt.Utils.deformalize", "Distriminitor.NLI.project1", "Distriminitor.NLI.project2", "Distriminitor.NLI.tgt_rnn", "onmt.Utils.deformalize", "Distriminitor.NLI.project1", "Distriminitor.NLI.project2", "logits_1[].contiguous().view", "logits_2[].contiguous().view", "logits_3[].contiguous().view", "logits_4[].contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.NLI.dp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.NLI.dp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.NLI.dp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.NLI.dp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Distriminitor.NLI.dp", "tmp.append", "logits.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "tgt_lengths_sorted.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "logits_1[].contiguous", "logits_2[].contiguous", "logits_3[].contiguous", "logits_4[].contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "onmt.Utils.deformalize.size", "src_hidden.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "onmt.Utils.deformalize.squeeze", "logits.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.formalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode_nli", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.deformalize"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "tgt_lengths", ",", "src", ",", "src_lengths", ",", "per", ",", "nli_data", ",", "step_type", "=", "'nli_step'", ")", ":", "\n", "        ", "\"\"\"Feed forward process of seq2seq\n\n        Args:\n            input: Variable(LongTensor(batch_size, N)), N is the length of input sequence.\n        Returns:\n            list of decoded tensor\n        \"\"\"", "\n", "\n", "src_hidden", ",", "per_hidden", ",", "_", ",", "per_lengths", "=", "self", ".", "encode", "(", "src", ",", "src_lengths", ",", "per", ")", "\n", "tgt", ",", "tgt_lengths_sorted", ",", "origin_new", "=", "formalize", "(", "tgt", ",", "tgt_lengths", ")", "\n", "\n", "tgt_emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "packed_tgt_emb", "=", "pack", "(", "tgt_emb", ",", "tgt_lengths_sorted", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "tgt_output", ",", "tgt_hidden", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "src_hidden", ")", "\n", "tgt_output", ",", "_", "=", "unpack", "(", "tgt_output", ")", "\n", "\n", "tgt_output", "=", "deformalize", "(", "tgt_output", ",", "origin_new", ")", "\n", "tgt_hidden", "=", "deformalize", "(", "tgt_hidden", ",", "origin_new", ")", "\n", "\n", "if", "step_type", "==", "'nli_step'", ":", "\n", "            ", "assert", "(", "nli_data", "is", "not", "None", ")", "\n", "src_hidden", ",", "tgt_hidden", "=", "self", ".", "encode_nli", "(", "nli_data", ")", "\n", "logits", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "src_hidden", ".", "squeeze", "(", "0", ")", ",", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits", ")", ")", ")", "\n", "# logits = self.sf(logits)", "\n", "\n", "", "else", ":", "\n", "            ", "_", ",", "ref_tgt_hidden1", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "per_hidden", "[", "0", "]", ")", "\n", "ref_tgt_hidden1", "=", "deformalize", "(", "ref_tgt_hidden1", ",", "origin_new", ")", "\n", "logits_1", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "ref_tgt_hidden1", ".", "squeeze", "(", "0", ")", ",", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits_1", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits_1", ")", ")", ")", "\n", "\n", "_", ",", "ref_tgt_hidden2", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "per_hidden", "[", "1", "]", ")", "\n", "ref_tgt_hidden2", "=", "deformalize", "(", "ref_tgt_hidden2", ",", "origin_new", ")", "\n", "logits_2", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "ref_tgt_hidden2", ".", "squeeze", "(", "0", ")", ",", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits_2", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits_2", ")", ")", ")", "\n", "\n", "_", ",", "ref_tgt_hidden3", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "per_hidden", "[", "2", "]", ")", "\n", "ref_tgt_hidden3", "=", "deformalize", "(", "ref_tgt_hidden3", ",", "origin_new", ")", "\n", "logits_3", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "ref_tgt_hidden3", ".", "squeeze", "(", "0", ")", ",", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits_3", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits_3", ")", ")", ")", "\n", "\n", "_", ",", "ref_tgt_hidden4", "=", "self", ".", "tgt_rnn", "(", "packed_tgt_emb", ",", "per_hidden", "[", "3", "]", ")", "\n", "ref_tgt_hidden4", "=", "deformalize", "(", "ref_tgt_hidden4", ",", "origin_new", ")", "\n", "logits_4", "=", "self", ".", "project1", "(", "torch", ".", "cat", "(", "[", "ref_tgt_hidden4", ".", "squeeze", "(", "0", ")", ",", "tgt_hidden", ".", "squeeze", "(", "0", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "logits_4", "=", "self", ".", "project2", "(", "self", ".", "dp", "(", "F", ".", "tanh", "(", "logits_4", ")", ")", ")", "\n", "\n", "a", "=", "logits_1", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "b", "=", "logits_2", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "c", "=", "logits_3", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "d", "=", "logits_4", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "a", ",", "b", ",", "c", ",", "d", "]", ",", "dim", "=", "1", ")", "\n", "y", ",", "ind", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "1", ")", "\n", "z", "=", "torch", ".", "cat", "(", "[", "logits_1", ",", "logits_2", ",", "logits_3", ",", "logits_4", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "[", "-", "1", ",", "4", ",", "3", "]", ")", "\n", "tmp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "logits_1", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "tmp", ".", "append", "(", "z", "[", "i", "]", "[", "ind", "[", "i", "]", "]", ")", "\n", "", "logits", "=", "torch", ".", "cat", "(", "tmp", ",", "dim", "=", "0", ")", "\n", "\n", "# logits = (logits_1 + logits_2 + logits_3) / 3.0", "\n", "\n", "if", "step_type", "==", "'self_sample'", ":", "\n", "                ", "logits", "=", "logits", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "tgt_output", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "\n", "", "", "return", "logits", "# len x batch_size x 3 if step_type == 'self_sample' else batch_size x 3", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StackedRNN.StackedLSTM.__init__": [[10, 19], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "StackedRNN.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StackedRNN.StackedLSTM.forward": [[20, 35], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "StackedRNN.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StackedRNN.StackedGRU.__init__": [[39, 48], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "StackedRNN.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StackedRNN.StackedGRU.forward": [[49, 60], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "StackedRNN.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input", "=", "self", ".", "dropout", "(", "input", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.PositionwiseFeedForward.__init__": [[27, 35], ["torch.Module.__init__", "onmt.modules.BottleLinear", "onmt.modules.BottleLinear", "onmt.modules.BottleLayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "hidden_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "onmt", ".", "modules", ".", "BottleLinear", "(", "size", ",", "hidden_size", ")", "\n", "self", ".", "w_2", "=", "onmt", ".", "modules", ".", "BottleLinear", "(", "hidden_size", ",", "size", ")", "\n", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "size", ")", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.PositionwiseFeedForward.forward": [[36, 40], ["Transformer.PositionwiseFeedForward.dropout_1", "Transformer.PositionwiseFeedForward.dropout_2", "Transformer.PositionwiseFeedForward.relu", "Transformer.PositionwiseFeedForward.w_2", "Transformer.PositionwiseFeedForward.w_1", "Transformer.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerEncoderLayer.__init__": [[55, 65], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "Transformer.PositionwiseFeedForward", "onmt.modules.BottleLayerNorm"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ",", "\n", "head_count", "=", "8", ",", "hidden_size", "=", "2048", ")", ":", "\n", "        ", "super", "(", "TransformerEncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "head_count", ",", "size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "size", ",", "\n", "hidden_size", ",", "\n", "dropout", ")", "\n", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerEncoderLayer.forward": [[66, 71], ["Transformer.TransformerEncoderLayer.layer_norm", "Transformer.TransformerEncoderLayer.self_attn", "Transformer.TransformerEncoderLayer.feed_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", ")", ":", "\n", "        ", "input_norm", "=", "self", ".", "layer_norm", "(", "input", ")", "\n", "mid", ",", "_", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "mask", "=", "mask", ")", "\n", "out", "=", "self", ".", "feed_forward", "(", "mid", "+", "input", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerEncoder.__init__": [[98, 108], ["onmt.Models.EncoderBase.__init__", "torch.ModuleList", "torch.ModuleList", "onmt.modules.BottleLayerNorm", "Transformer.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "\n", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "TransformerEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "transformer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerEncoderLayer", "(", "hidden_size", ",", "dropout", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerEncoder.forward": [[109, 136], ["Transformer.TransformerEncoder._check_args", "Transformer.TransformerEncoder.embeddings", "Transformer.TransformerEncoder.size", "Transformer.TransformerEncoder.transpose().contiguous", "input[].transpose", "Transformer.TransformerEncoder.size", "input[].transpose.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "input[].transpose.data.eq().unsqueeze().expand", "range", "Transformer.TransformerEncoder.layer_norm", "torch.autograd.Variable", "torch.autograd.Variable", "Transformer.TransformerEncoder.transpose().contiguous", "Transformer.TransformerEncoder.transpose", "input[].transpose.data.eq().unsqueeze", "Transformer.TransformerEncoder.transpose", "input[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase._check_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "s_len", ",", "n_batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "\n", "out", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "words", "=", "input", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# CHECKS", "\n", "out_batch", ",", "out_len", ",", "_", "=", "out", ".", "size", "(", ")", "\n", "w_batch", ",", "w_len", "=", "words", ".", "size", "(", ")", "\n", "aeq", "(", "out_batch", ",", "w_batch", ")", "\n", "aeq", "(", "out_len", ",", "w_len", ")", "\n", "# END CHECKS", "\n", "\n", "# Make mask.", "\n", "padding_idx", "=", "self", ".", "embeddings", ".", "word_padding_idx", "\n", "mask", "=", "words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "w_batch", ",", "w_len", ",", "w_len", ")", "\n", "\n", "# Run the forward pass of every layer of the tranformer.", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "out", "=", "self", ".", "transformer", "[", "i", "]", "(", "out", ",", "mask", ")", "\n", "", "out", "=", "self", ".", "layer_norm", "(", "out", ")", "\n", "\n", "return", "Variable", "(", "emb", ".", "data", ")", ",", "out", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderLayer.__init__": [[148, 165], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.MultiHeadedAttention", "Transformer.PositionwiseFeedForward", "onmt.modules.BottleLayerNorm", "onmt.modules.BottleLayerNorm", "Transformer.TransformerDecoderLayer._get_attn_subsequent_mask", "Transformer.TransformerDecoderLayer.register_buffer"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderLayer._get_attn_subsequent_mask"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ",", "\n", "head_count", "=", "8", ",", "hidden_size", "=", "2048", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "head_count", ",", "size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "context_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "head_count", ",", "size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "size", ",", "\n", "hidden_size", ",", "\n", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "size", ")", "\n", "self", ".", "layer_norm_2", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "size", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderLayer.forward": [[166, 202], ["input.size", "context.size", "onmt.Utils.aeq", "src_pad_mask.size", "tgt_pad_mask.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "Transformer.TransformerDecoderLayer.layer_norm_1", "Transformer.TransformerDecoderLayer.self_attn", "Transformer.TransformerDecoderLayer.layer_norm_2", "Transformer.TransformerDecoderLayer.context_attn", "Transformer.TransformerDecoderLayer.feed_forward", "Transformer.TransformerDecoderLayer.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "attn.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "Transformer.TransformerDecoderLayer.mask[].expand_as", "tgt_pad_mask.size", "tgt_pad_mask.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "src_pad_mask", ",", "tgt_pad_mask", ")", ":", "\n", "# Args Checks", "\n", "        ", "input_batch", ",", "input_len", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "contxt_batch", ",", "contxt_len", ",", "_", "=", "context", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ")", "\n", "\n", "src_batch", ",", "t_len", ",", "s_len", "=", "src_pad_mask", ".", "size", "(", ")", "\n", "tgt_batch", ",", "t_len_", ",", "t_len__", "=", "tgt_pad_mask", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ",", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "t_len", ",", "t_len_", ",", "t_len__", ",", "input_len", ")", "\n", "aeq", "(", "s_len", ",", "contxt_len", ")", "\n", "# END Args Checks", "\n", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "self", ".", "mask", "[", ":", ",", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", ",", "\n", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", "]", "\n", ".", "expand_as", "(", "tgt_pad_mask", ")", ",", "0", ")", "\n", "input_norm", "=", "self", ".", "layer_norm_1", "(", "input", ")", "\n", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "input_norm", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ")", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", "+", "input", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "context", ",", "context", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "mid", "+", "query", "+", "input", ")", "\n", "\n", "# CHECKS", "\n", "output_batch", ",", "output_len", ",", "_", "=", "output", ".", "size", "(", ")", "\n", "aeq", "(", "input_len", ",", "output_len", ")", "\n", "aeq", "(", "contxt_batch", ",", "output_batch", ")", "\n", "\n", "n_batch_", ",", "t_len_", ",", "s_len_", "=", "attn", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "n_batch_", ")", "\n", "aeq", "(", "contxt_len", ",", "s_len_", ")", "\n", "aeq", "(", "input_len", ",", "t_len_", ")", "\n", "# END CHECKS", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderLayer._get_attn_subsequent_mask": [[203, 209], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "methods", ["None"], ["", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "''' Get an attention mask to avoid using the subsequent info.'''", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoder.__init__": [[239, 261], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "onmt.modules.BottleLayerNorm", "onmt.modules.GlobalAttention", "Transformer.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "TransformerDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'transformer'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "# Build TransformerDecoder.", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerDecoderLayer", "(", "hidden_size", ",", "dropout", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "# TransformerDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "BottleLayerNorm", "(", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoder.forward": [[262, 324], ["isinstance", "torch.cat.size", "torch.cat.size", "context.size", "onmt.Utils.aeq", "src[].transpose", "input[].transpose", "src[].transpose.size", "input[].transpose.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "Transformer.TransformerDecoder.embeddings", "Transformer.TransformerDecoder.transpose().contiguous", "context.transpose().contiguous", "src[].transpose.data.eq().unsqueeze().expand", "input[].transpose.data.eq().unsqueeze().expand", "range", "Transformer.TransformerDecoder.layer_norm", "Transformer.TransformerDecoder.transpose().contiguous", "state.update_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Transformer.TransformerDecoder.dim", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "Transformer.TransformerDecoder.transpose", "context.transpose", "src[].transpose.data.eq().unsqueeze", "input[].transpose.data.eq().unsqueeze", "Transformer.TransformerDecoder.transpose", "state.previous_input.size", "src[].transpose.data.eq", "input[].transpose.data.eq", "state.previous_input.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :obj:`onmt.modules.RNNDecoderBase.forward()`\n        \"\"\"", "\n", "# CHECKS", "\n", "assert", "isinstance", "(", "state", ",", "TransformerDecoderState", ")", "\n", "input_len", ",", "input_batch", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "contxt_len", ",", "contxt_batch", ",", "_", "=", "context", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ")", "\n", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "[", "state", ".", "previous_input", ",", "input", "]", ",", "0", ")", "\n", "\n", "", "src", "=", "state", ".", "src", "\n", "src_words", "=", "src", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tgt_words", "=", "input", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_batch", ",", "src_len", "=", "src_words", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", "=", "tgt_words", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ",", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "contxt_len", ",", "src_len", ")", "\n", "# aeq(input_len, tgt_len)", "\n", "# END CHECKS", "\n", "\n", "# Initialize return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "# Run the forward pass of the TransformerDecoder.", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "output", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "src_context", "=", "context", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "padding_idx", "=", "self", ".", "embeddings", ".", "word_padding_idx", "\n", "src_pad_mask", "=", "src_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "tgt_pad_mask", "=", "tgt_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_len", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "output", ",", "attn", "=", "self", ".", "transformer_layers", "[", "i", "]", "(", "output", ",", "src_context", ",", "\n", "src_pad_mask", ",", "tgt_pad_mask", ")", "\n", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "[", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "state", ".", "update_state", "(", "input", ")", "\n", "\n", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoder.init_decoder_state": [[325, 327], ["Transformer.TransformerDecoderState"], "methods", ["None"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "return", "TransformerDecoderState", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderState.__init__": [[330, 338], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "src", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (FloatTensor): a sequence of source words tensors\n                    with optional feature tensors, of size (len x batch).\n        \"\"\"", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "previous_input", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderState._all": [[339, 345], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "return", "(", "self", ".", "previous_input", ",", "self", ".", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderState.update_state": [[346, 349], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\" Called for every decoder forward pass. \"\"\"", "\n", "self", ".", "previous_input", "=", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Transformer.TransformerDecoderState.repeat_beam_size_times": [[350, 354], ["torch.autograd.Variable", "torch.autograd.Variable", "Transformer.TransformerDecoderState.src.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "src", "=", "Variable", "(", "self", ".", "src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ",", "\n", "volatile", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ImageEncoder.ImageEncoder.__init__": [[18, 47], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "batch_norm3", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "input_size", "=", "512", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "pos_lut", "=", "nn", ".", "Embedding", "(", "1000", ",", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ImageEncoder.ImageEncoder.load_pretrained_vectors": [[48, 51], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "# Pass in needed options only when modify function definition.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ImageEncoder.ImageEncoder.forward": [[52, 108], ["torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ImageEncoder.ImageEncoder.layer1", "ImageEncoder.ImageEncoder.layer2", "ImageEncoder.ImageEncoder.batch_norm1", "ImageEncoder.ImageEncoder.layer4", "ImageEncoder.ImageEncoder.batch_norm2", "ImageEncoder.ImageEncoder.batch_norm3", "torch.relu.size", "input[].transpose().transpose", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "ImageEncoder.ImageEncoder.pos_lut", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ImageEncoder.ImageEncoder.rnn", "all_outputs.append", "ImageEncoder.ImageEncoder.layer3", "ImageEncoder.ImageEncoder.layer5", "ImageEncoder.ImageEncoder.layer6", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input[].transpose", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "ImageEncoder.ImageEncoder.view", "ImageEncoder.ImageEncoder.size", "ImageEncoder.ImageEncoder.size", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.modules.EncoderBase.forward()`\"", "\n", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "# (batch_size, 64, imgH, imgW)", "\n", "# layer 1", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer1", "(", "input", "[", ":", ",", ":", ",", ":", ",", ":", "]", "-", "0.5", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 64, imgH/2, imgW/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 128, imgH/2, imgW/2)", "\n", "# layer 2", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer2", "(", "input", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 128, imgH/2/2, imgW/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "#  (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer 3", "\n", "# batch norm 1", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm1", "(", "self", ".", "layer3", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer4", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "layer4", "(", "input", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2/2, imgW/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "1", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2)", "\n", "# layer 5", "\n", "# batch norm 2", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm2", "(", "self", ".", "layer5", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "input", "=", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", "=", "(", "2", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "input", "=", "F", ".", "relu", "(", "self", ".", "batch_norm3", "(", "self", ".", "layer6", "(", "input", ")", ")", ",", "True", ")", "\n", "\n", "# # (batch_size, 512, H, W)", "\n", "all_outputs", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "input", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "inp", "=", "input", "[", ":", ",", ":", ",", "row", ",", ":", "]", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "row_vec", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "inp", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "row", ")", "\n", "pos_emb", "=", "self", ".", "pos_lut", "(", "Variable", "(", "row_vec", ")", ")", "\n", "with_pos", "=", "torch", ".", "cat", "(", "\n", "(", "pos_emb", ".", "view", "(", "1", ",", "pos_emb", ".", "size", "(", "0", ")", ",", "pos_emb", ".", "size", "(", "1", ")", ")", ",", "inp", ")", ",", "0", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "with_pos", ")", "\n", "all_outputs", ".", "append", "(", "outputs", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "all_outputs", ",", "0", ")", "\n", "\n", "return", "hidden_t", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.GatedConv.__init__": [[26, 33], ["torch.Module.__init__", "onmt.modules.WeightNorm.WeightNormConv2d", "torch.xavier_uniform", "torch.xavier_uniform", "torch.xavier_uniform", "torch.xavier_uniform", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "width", "=", "3", ",", "dropout", "=", "0.2", ",", "nopad", "=", "False", ")", ":", "\n", "        ", "super", "(", "GatedConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "WeightNormConv2d", "(", "input_size", ",", "2", "*", "input_size", ",", "\n", "kernel_size", "=", "(", "width", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "width", "//", "2", "*", "(", "1", "-", "nopad", ")", ",", "0", ")", ")", "\n", "init", ".", "xavier_uniform", "(", "self", ".", "conv", ".", "weight", ",", "gain", "=", "(", "4", "*", "(", "1", "-", "dropout", ")", ")", "**", "0.5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.GatedConv.forward": [[34, 40], ["Conv2Conv.GatedConv.dropout", "Conv2Conv.GatedConv.conv", "Conv2Conv.GatedConv.split", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "Conv2Conv.GatedConv.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "x_var", "=", "self", ".", "dropout", "(", "x_var", ")", "\n", "x_var", "=", "self", ".", "conv", "(", "x_var", ")", "\n", "out", ",", "gate", "=", "x_var", ".", "split", "(", "int", "(", "x_var", ".", "size", "(", "1", ")", "/", "2", ")", ",", "1", ")", "\n", "out", "=", "out", "*", "F", ".", "sigmoid", "(", "gate", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.StackedCNN.__init__": [[43, 52], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "Conv2Conv.StackedCNN.layers.append", "Conv2Conv.GatedConv"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "cnn_kernel_width", "=", "3", ",", "\n", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "StackedCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "GatedConv", "(", "input_size", ",", "cnn_kernel_width", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.StackedCNN.forward": [[53, 58], ["conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "x", "+", "conv", "(", "x", ")", "\n", "x", "*=", "SCALE_WEIGHT", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNEncoder.__init__": [[65, 74], ["onmt.Models.EncoderBase.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Conv2Conv.StackedCNN"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "input_size", "=", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "cnn", "=", "StackedCNN", "(", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNEncoder.forward": [[75, 91], ["Conv2Conv.CNNEncoder._check_args", "Conv2Conv.CNNEncoder.embeddings", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.view", "Conv2Conv.CNNEncoder.linear", "shape_transform.view", "Conv2Conv.shape_transform", "Conv2Conv.CNNEncoder.cnn", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "shape_transform.squeeze().transpose().contiguous", "Conv2Conv.CNNEncoder.squeeze().transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.transpose", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "shape_transform.squeeze().transpose", "Conv2Conv.CNNEncoder.squeeze().transpose", "shape_transform.squeeze", "Conv2Conv.CNNEncoder.squeeze"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Models.EncoderBase._check_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.shape_transform"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "s_len", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "\n", "emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "emb_reshape", "=", "emb", ".", "view", "(", "emb", ".", "size", "(", "0", ")", "*", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "emb_remap", "=", "emb_remap", ".", "view", "(", "emb", ".", "size", "(", "0", ")", ",", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "shape_transform", "(", "emb_remap", ")", "\n", "out", "=", "self", ".", "cnn", "(", "emb_remap", ")", "\n", "\n", "return", "emb_remap", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "out", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.__init__": [[100, 133], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "Conv2Conv.CNNDecoder.conv_layers.append", "Conv2Conv.CNNDecoder.attn_layers.append", "onmt.modules.GlobalAttention", "Conv2Conv.GatedConv", "onmt.modules.ConvMultiStepAttention"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'cnn'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "cnn_kernel_width", "=", "cnn_kernel_width", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Build the CNN.", "\n", "input_size", "=", "self", ".", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "conv_layers", ".", "append", "(", "\n", "GatedConv", "(", "self", ".", "hidden_size", ",", "self", ".", "cnn_kernel_width", ",", "\n", "self", ".", "dropout", ",", "True", ")", ")", "\n", "\n", "", "self", ".", "attn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "attn_layers", ".", "append", "(", "\n", "onmt", ".", "modules", ".", "ConvMultiStepAttention", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n", "# CNNDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.forward": [[134, 196], ["isinstance", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "context.size", "onmt.Utils.aeq", "Conv2Conv.CNNDecoder.embeddings", "Conv2Conv.CNNDecoder.transpose().contiguous", "context.transpose().contiguous", "state.init_src.transpose().contiguous", "Conv2Conv.CNNDecoder.transpose().contiguous.contiguous().view", "Conv2Conv.CNNDecoder.linear", "Conv2Conv.CNNDecoder.view", "Conv2Conv.shape_transform", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "pad.type_as.type_as.type_as", "zip", "shape_transform.squeeze().transpose", "shape_transform.squeeze().transpose.transpose().contiguous", "state.update_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Conv2Conv.CNNDecoder.dim", "Conv2Conv.CNNDecoder.transpose().contiguous.size", "Conv2Conv.CNNDecoder.transpose().contiguous.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "attention", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "Conv2Conv.CNNDecoder.transpose", "context.transpose", "state.init_src.transpose", "Conv2Conv.CNNDecoder.transpose().contiguous.contiguous", "Conv2Conv.CNNDecoder.transpose().contiguous.size", "Conv2Conv.CNNDecoder.transpose().contiguous.size", "shape_transform.size", "shape_transform.size", "shape_transform.squeeze", "shape_transform.squeeze().transpose.transpose", "state.previous_input.size", "state.previous_input.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.shape_transform", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.update_state"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "context", ",", "state", ",", "context_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.RNNDecoderBase.forward()`\"\"\"", "\n", "# CHECKS", "\n", "assert", "isinstance", "(", "state", ",", "CNNDecoderState", ")", "\n", "input_len", ",", "input_batch", ",", "_", "=", "input", ".", "size", "(", ")", "\n", "contxt_len", ",", "contxt_batch", ",", "_", "=", "context", ".", "size", "(", ")", "\n", "aeq", "(", "input_batch", ",", "contxt_batch", ")", "\n", "# END CHECKS", "\n", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "input", "=", "torch", ".", "cat", "(", "[", "state", ".", "previous_input", ",", "input", "]", ",", "0", ")", "\n", "\n", "# Initialize return variables.", "\n", "", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "assert", "not", "self", ".", "_copy", ",", "\"Copy mechanism not yet tested in conv2conv\"", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "tgt_emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The output of CNNEncoder.", "\n", "src_context_t", "=", "context", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The combination of output of CNNEncoder and source embeddings.", "\n", "src_context_c", "=", "state", ".", "init_src", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Run the forward pass of the CNNDecoder.", "\n", "emb_reshape", "=", "tgt_emb", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_emb", ".", "size", "(", "0", ")", "*", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "linear_out", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "x", "=", "linear_out", ".", "view", "(", "tgt_emb", ".", "size", "(", "0", ")", ",", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "shape_transform", "(", "x", ")", "\n", "\n", "pad", "=", "Variable", "(", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "cnn_kernel_width", "-", "1", ",", "1", ")", ")", "\n", "pad", "=", "pad", ".", "type_as", "(", "x", ")", "\n", "base_target_emb", "=", "x", "\n", "\n", "for", "conv", ",", "attention", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "attn_layers", ")", ":", "\n", "            ", "new_target_input", "=", "torch", ".", "cat", "(", "[", "pad", ",", "x", "]", ",", "2", ")", "\n", "out", "=", "conv", "(", "new_target_input", ")", "\n", "c", ",", "attn", "=", "attention", "(", "base_target_emb", ",", "out", ",", "\n", "src_context_t", ",", "src_context_c", ")", "\n", "x", "=", "(", "x", "+", "(", "c", "+", "out", ")", "*", "SCALE_WEIGHT", ")", "*", "SCALE_WEIGHT", "\n", "", "output", "=", "x", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "[", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "state", ".", "update_state", "(", "input", ")", "\n", "\n", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.init_decoder_state": [[197, 199], ["Conv2Conv.CNNDecoderState"], "methods", ["None"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "return", "CNNDecoderState", "(", "context", ",", "enc_hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.__init__": [[202, 205], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "context", ",", "enc_hidden", ")", ":", "\n", "        ", "self", ".", "init_src", "=", "(", "context", "+", "enc_hidden", ")", "*", "SCALE_WEIGHT", "\n", "self", ".", "previous_input", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState._all": [[206, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "return", "(", "self", ".", "previous_input", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.update_state": [[213, 216], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\" Called for every decoder forward pass. \"\"\"", "\n", "self", ".", "previous_input", "=", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoderState.repeat_beam_size_times": [[217, 221], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "Conv2Conv.CNNDecoderState.init_src.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "init_src", "=", "Variable", "(", "\n", "self", ".", "init_src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ",", "volatile", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.shape_transform": [[20, 23], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "shape_transform", "(", "x", ")", ":", "\n", "    ", "\"\"\" Tranform the size of the tensors to fit for conv input. \"\"\"", "\n", "return", "torch", ".", "unsqueeze", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StructuredAttention.MatrixTree.__init__": [[15, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "super", "(", "MatrixTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.StructuredAttention.MatrixTree.forward": [[19, 41], ["input.clone", "range", "input.exp", "input.size", "laplacian[].masked_fill", "input[].diag().exp", "laplacian[].masked_fill.inverse", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as().transpose", "input[].exp().mul().clone", "input[].exp().mul().clone", "input[].diag().exp().mul", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "laplacian[].masked_fill.sum", "input[].diag", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as", "input[].exp().mul", "input[].exp().mul", "input[].diag().exp", "laplacian[].masked_fill.inverse.transpose", "laplacian[].masked_fill.inverse.transpose", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "laplacian[].masked_fill.inverse.diag().unsqueeze", "input[].exp", "input[].exp", "input[].diag", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "laplacian[].masked_fill.inverse.diag", "input.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "laplacian", "=", "input", ".", "exp", "(", ")", "+", "self", ".", "eps", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "for", "b", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "lap", "=", "laplacian", "[", "b", "]", ".", "masked_fill", "(", "\n", "Variable", "(", "torch", ".", "eye", "(", "input", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", ".", "ne", "(", "0", ")", ")", ",", "0", ")", "\n", "lap", "=", "-", "lap", "+", "torch", ".", "diag", "(", "lap", ".", "sum", "(", "0", ")", ")", "\n", "# store roots on diagonal", "\n", "lap", "[", "0", "]", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", "\n", "inv_laplacian", "=", "lap", ".", "inverse", "(", ")", "\n", "\n", "factor", "=", "inv_laplacian", ".", "diag", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "input", "[", "b", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "term1", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "factor", ")", ".", "clone", "(", ")", "\n", "term2", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "clone", "(", ")", "\n", "term1", "[", ":", ",", "0", "]", "=", "0", "\n", "term2", "[", "0", "]", "=", "0", "\n", "output", "[", "b", "]", "=", "term1", "-", "term2", "\n", "roots_output", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", ".", "mul", "(", "\n", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", ")", "\n", "output", "[", "b", "]", "=", "output", "[", "b", "]", "+", "torch", ".", "diag", "(", "roots_output", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.AudioEncoder.AudioEncoder.__init__": [[20, 42], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "int", "int", "int", "torch.LSTM", "torch.LSTM", "math.floor", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ",", "\n", "sample_rate", ",", "window_size", ")", ":", "\n", "        ", "super", "(", "AudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "kernel_size", "=", "(", "41", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "10", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "(", "21", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "0", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "41", ")", "/", "2", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "21", ")", "/", "2", "+", "1", ")", "\n", "input_size", "*=", "32", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.AudioEncoder.AudioEncoder.load_pretrained_vectors": [[43, 46], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "# Pass in needed options only when modify function definition.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.AudioEncoder.AudioEncoder.forward": [[47, 71], ["AudioEncoder.AudioEncoder.batch_norm1", "torch.hardtanh", "torch.hardtanh", "AudioEncoder.AudioEncoder.batch_norm2", "torch.hardtanh", "torch.hardtanh", "input.transpose().transpose.transpose().transpose.size", "input.transpose().transpose.transpose().transpose.size", "input.transpose().transpose.transpose().transpose.view", "input.transpose().transpose.transpose().transpose.transpose().transpose", "AudioEncoder.AudioEncoder.rnn", "AudioEncoder.AudioEncoder.layer1", "AudioEncoder.AudioEncoder.layer2", "input.transpose().transpose.transpose().transpose.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.modules.EncoderBase.forward()`\"", "\n", "# (batch_size, 1, nfft, t)", "\n", "# layer 1", "\n", "input", "=", "self", ".", "batch_norm1", "(", "self", ".", "layer1", "(", "input", "[", ":", ",", ":", ",", ":", ",", ":", "]", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2, t/2)", "\n", "input", "=", "F", ".", "hardtanh", "(", "input", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "# layer 2", "\n", "input", "=", "self", ".", "batch_norm2", "(", "self", ".", "layer2", "(", "input", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "input", "=", "F", ".", "hardtanh", "(", "input", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "batch_size", "=", "input", ".", "size", "(", "0", ")", "\n", "length", "=", "input", ".", "size", "(", "3", ")", "\n", "input", "=", "input", ".", "view", "(", "batch_size", ",", "-", "1", ",", "length", ")", "\n", "input", "=", "input", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "input", ")", "\n", "\n", "return", "hidden", ",", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ConvMultiStepAttention.ConvMultiStepAttention.__init__": [[28, 32], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "ConvMultiStepAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ConvMultiStepAttention.ConvMultiStepAttention.apply_mask": [[33, 35], ["None"], "methods", ["None"], ["", "def", "apply_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ConvMultiStepAttention.ConvMultiStepAttention.forward": [[36, 78], ["base_target_emb.size", "input.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "encoder_out_top.size", "encoder_out_combine.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "ConvMultiStepAttention.seq_linear", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "pre_attn.transpose.transpose.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "pre_attn.transpose.transpose.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "attn.transpose().contiguous.transpose().contiguous.transpose", "float"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ConvMultiStepAttention.seq_linear"], ["", "def", "forward", "(", "self", ",", "base_target_emb", ",", "input", ",", "encoder_out_top", ",", "\n", "encoder_out_combine", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_target_emb: target emb tensor\n            input: output of decode conv\n            encoder_out_t: the key matrix for calculation of attetion weight,\n                which is the top output of encode conv\n            encoder_out_combine:\n                the value matrix for the attention-weighted sum,\n                which is the combination of base emb and top output of encode\n\n        \"\"\"", "\n", "# checks", "\n", "batch", ",", "channel", ",", "height", ",", "width", "=", "base_target_emb", ".", "size", "(", ")", "\n", "batch_", ",", "channel_", ",", "height_", ",", "width_", "=", "input", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "height", ",", "height_", ")", "\n", "\n", "enc_batch", ",", "enc_channel", ",", "enc_height", "=", "encoder_out_top", ".", "size", "(", ")", "\n", "enc_batch_", ",", "enc_channel_", ",", "enc_height_", "=", "encoder_out_combine", ".", "size", "(", ")", "\n", "\n", "aeq", "(", "enc_batch", ",", "enc_batch_", ")", "\n", "aeq", "(", "enc_height", ",", "enc_height_", ")", "\n", "\n", "preatt", "=", "seq_linear", "(", "self", ".", "linear_in", ",", "input", ")", "\n", "target", "=", "(", "base_target_emb", "+", "preatt", ")", "*", "SCALE_WEIGHT", "\n", "target", "=", "torch", ".", "squeeze", "(", "target", ",", "3", ")", "\n", "target", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", "\n", "pre_attn", "=", "torch", ".", "bmm", "(", "target", ",", "encoder_out_top", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "pre_attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "pre_attn", "=", "pre_attn", ".", "transpose", "(", "0", ",", "2", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "pre_attn", ")", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "context_output", "=", "torch", ".", "bmm", "(", "\n", "attn", ",", "torch", ".", "transpose", "(", "encoder_out_combine", ",", "1", ",", "2", ")", ")", "\n", "context_output", "=", "torch", ".", "transpose", "(", "\n", "torch", ".", "unsqueeze", "(", "context_output", ",", "3", ")", ",", "1", ",", "2", ")", "\n", "return", "context_output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.ConvMultiStepAttention.seq_linear": [[10, 16], ["x.size", "linear", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "linear.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "seq_linear", "(", "linear", ",", "x", ")", ":", "\n", "# linear transform for 3-d tensor", "\n", "    ", "batch", ",", "hidden_size", ",", "length", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "h", "=", "linear", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch", "*", "length", ",", "hidden_size", ")", ")", "\n", "return", "torch", ".", "transpose", "(", "h", ".", "view", "(", "batch", ",", "length", ",", "hidden_size", ",", "1", ")", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormLinear.__init__": [[39, 56], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.register_buffer", "WeightNorm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormLinear.reset_parameters": [[57, 59], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormLinear.forward": [[60, 94], ["WeightNorm.WeightNormLinear.V.data.copy_", "WeightNorm.WeightNormLinear.g.data.copy_", "WeightNorm.WeightNormLinear.b.data.copy_", "WeightNorm.WeightNormLinear.V_avg.copy_", "WeightNorm.WeightNormLinear.g_avg.copy_", "WeightNorm.WeightNormLinear.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "WeightNorm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "m_init.view().expand_as", "scalar.view().expand_as", "WeightNorm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "WeightNorm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "Variable", "(", "v_norm", ")", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "V", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "V", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "V", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConv2d.__init__": [[97, 115], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.register_buffer", "WeightNorm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "WeightNorm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConv2d.reset_parameters": [[116, 118], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConv2d.forward": [[119, 165], ["WeightNorm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "WeightNorm.WeightNormConv2d.g.data.copy_", "WeightNorm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "WeightNorm.WeightNormConv2d.V_avg.copy_", "WeightNorm.WeightNormConv2d.g_avg.copy_", "WeightNorm.WeightNormConv2d.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "WeightNorm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "v.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "WeightNorm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "WeightNorm.WeightNormConv2d.V.data.size", "WeightNorm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "WeightNorm.WeightNormConv2d.V.data.view", "len", "len", "v.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "Variable", "(", "v_norm", ")", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "v", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "w", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.__init__": [[168, 188], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.register_buffer", "WeightNorm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "WeightNorm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.reset_parameters": [[189, 191], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.WeightNormConvTranspose2d.forward": [[192, 240], ["WeightNorm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "WeightNorm.WeightNormConvTranspose2d.g.data.copy_", "WeightNorm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "WeightNorm.WeightNormConvTranspose2d.V_avg.copy_", "WeightNorm.WeightNormConvTranspose2d.g_avg.copy_", "WeightNorm.WeightNormConvTranspose2d.b_avg.copy_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "WeightNorm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x_init.tranpose().contiguous", "m_init.view.expand_as", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "V.transpose().contiguous().view", "WeightNorm.WeightNormConvTranspose2d.V.data.size", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "V.transpose().contiguous", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "V.transpose", "V.size", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "WeightNorm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "Variable", "(", "v_norm", ")", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "Variable", "(", "x_init", ")", "\n", "", "else", ":", "\n", "            ", "V", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "V", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "w", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "V", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "V", ")", "*", "V", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_var_maybe_avg": [[8, 19], ["getattr", "getattr", "torch.autograd.Variable"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "# utility for retrieving polyak averaged params", "\n", "# Update average", "\n", "    ", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "Variable", "(", "v_avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_vars_maybe_avg": [[21, 28], ["vars.append", "WeightNorm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.WeightNorm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "# utility for retrieving polyak averaged params", "\n", "    ", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGenerator.__init__": [[61, 66], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", "CopyGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "len", "(", "tgt_dict", ")", ")", "\n", "self", ".", "linear_copy", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGenerator.forward": [[67, 104], ["hidden.size", "attn.size", "src_map.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "CopyGenerator.CopyGenerator.linear", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "copy_prob.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "float", "CopyGenerator.CopyGenerator.linear_copy", "torch.sigmoid.expand_as", "torch.sigmoid.expand_as", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "copy_prob.contiguous().view.contiguous().view.contiguous", "torch.mul.view().transpose", "torch.mul.view().transpose", "torch.mul.view().transpose", "torch.mul.view().transpose", "src_map.transpose", "torch.mul.view", "torch.mul.view", "torch.mul.view", "torch.mul.view"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", ",", "src_map", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by compying\n        source words.\n\n        Args:\n           hidden (`FloatTensor`): hidden outputs `[batch*tlen, input_size]`\n           attn (`FloatTensor`): attn for each `[batch*tlen, input_size]`\n           src_map (`FloatTensor`):\n             A sparse indicator matrix mapping each source word to\n             its index in the \"extended\" vocab containing.\n             `[src_len, batch, extra_words]`\n        \"\"\"", "\n", "# CHECKS", "\n", "batch_by_tlen", ",", "_", "=", "hidden", ".", "size", "(", ")", "\n", "batch_by_tlen_", ",", "slen", "=", "attn", ".", "size", "(", ")", "\n", "slen_", ",", "batch", ",", "cvocab", "=", "src_map", ".", "size", "(", ")", "\n", "aeq", "(", "batch_by_tlen", ",", "batch_by_tlen_", ")", "\n", "aeq", "(", "slen", ",", "slen_", ")", "\n", "\n", "# Original probabilities.", "\n", "logits", "=", "self", ".", "linear", "(", "hidden", ")", "\n", "logits", "[", ":", ",", "self", ".", "tgt_dict", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "prob", "=", "F", ".", "softmax", "(", "logits", ")", "\n", "\n", "# Probability of copying p(z=1) batch.", "\n", "copy", "=", "F", ".", "sigmoid", "(", "self", ".", "linear_copy", "(", "hidden", ")", ")", "\n", "\n", "# Probibility of not copying: p_{word}(w) * (1 - p(z))", "\n", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "1", "-", "copy", ".", "expand_as", "(", "prob", ")", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "copy", ".", "expand_as", "(", "attn", ")", ")", "\n", "copy_prob", "=", "torch", ".", "bmm", "(", "mul_attn", ".", "view", "(", "-", "1", ",", "batch", ",", "slen", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "src_map", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "copy_prob", "=", "copy_prob", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "cvocab", ")", "\n", "return", "torch", ".", "cat", "(", "[", "out_prob", ",", "copy_prob", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorCriterion.__init__": [[107, 112], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "force_copy", ",", "pad", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "offset", "=", "vocab_size", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorCriterion.__call__": [[113, 132], ["align.view.view.view", "scores.gather().view().mul", "scores.gather().view", "align.view.view.ne().float", "scores.gather().view().mul.log().mul().sum", "scores.gather().view", "scores.gather", "scores.gather().view.mul().mul", "scores.gather().view.mul", "align.view.view.ne", "target.view", "scores.gather().view.mul", "target.eq().float", "align.view.view.eq().float", "scores.gather().view().mul.log().mul", "scores.gather", "target.ne().float", "scores.gather().view.mul", "target.ne().float", "align.view.view.eq().float", "target.eq", "align.view.view.eq", "scores.gather().view().mul.log", "align.view.view.view", "target.ne", "target.ne", "align.view.view.eq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "__call__", "(", "self", ",", "scores", ",", "align", ",", "target", ")", ":", "\n", "        ", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Copy prob.", "\n", "out", "=", "scores", ".", "gather", "(", "1", ",", "align", ".", "view", "(", "-", "1", ",", "1", ")", "+", "self", ".", "offset", ")", ".", "view", "(", "-", "1", ")", ".", "mul", "(", "align", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ")", "\n", "tmp", "=", "scores", ".", "gather", "(", "1", ",", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Regular prob (no unks and unks that can't be copied)", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "            ", "out", "=", "out", "+", "self", ".", "eps", "+", "tmp", ".", "mul", "(", "target", ".", "ne", "(", "0", ")", ".", "float", "(", ")", ")", "+", "tmp", ".", "mul", "(", "align", ".", "eq", "(", "0", ")", ".", "float", "(", ")", ")", ".", "mul", "(", "target", ".", "eq", "(", "0", ")", ".", "float", "(", ")", ")", "\n", "", "else", ":", "\n", "# Forced copy.", "\n", "            ", "out", "=", "out", "+", "self", ".", "eps", "+", "tmp", ".", "mul", "(", "align", ".", "eq", "(", "0", ")", ".", "float", "(", ")", ")", "\n", "\n", "# Drop padding.", "\n", "", "loss", "=", "-", "out", ".", "log", "(", ")", ".", "mul", "(", "target", ".", "ne", "(", "self", ".", "pad", ")", ".", "float", "(", ")", ")", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute.__init__": [[138, 149], ["super().__init__", "CopyGenerator.CopyGeneratorCriterion", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ",", "\n", "force_copy", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLossCompute", ",", "self", ")", ".", "__init__", "(", "\n", "generator", ",", "tgt_vocab", ")", "\n", "\n", "# We lazily load datasets when there are more than one, so postpone", "\n", "# the setting of cur_dataset.", "\n", "self", ".", "cur_dataset", "=", "None", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "criterion", "=", "CopyGeneratorCriterion", "(", "len", "(", "tgt_vocab", ")", ",", "force_copy", ",", "\n", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._make_shard_state": [[150, 161], ["getattr", "AssertionError", "attns.get"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", ")", ":", "\n", "        ", "\"\"\" See base class for args description. \"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"copy_attn\"", ":", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"align\"", ":", "batch", ".", "alignment", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.CopyGenerator.CopyGeneratorLossCompute._compute_loss": [[163, 201], ["target.view.view.view", "align.view.view.view", "CopyGenerator.CopyGeneratorLossCompute.generator", "CopyGenerator.CopyGeneratorLossCompute.criterion", "CopyGenerator.CopyGeneratorLossCompute.data.clone", "onmt.io.TextDataset.collapse_copy_scores", "onmt.io.TextDataset.collapse_copy_scores", "onmt.io.TextDataset.collapse_copy_scores", "onmt.io.TextDataset.collapse_copy_scores", "CopyGenerator.CopyGeneratorLossCompute._bottle", "target.view.view.data.clone", "CopyGenerator.CopyGeneratorLossCompute.data.clone", "CopyGenerator.CopyGeneratorLossCompute._stats", "CopyGenerator.CopyGeneratorLossCompute._bottle", "CopyGenerator.CopyGeneratorLossCompute._bottle", "CopyGenerator.CopyGeneratorLossCompute._unbottle", "target.view.data.clone.eq", "align.view.view.data.ne", "correct_mask.long", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._stats", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._bottle", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Loss.LossComputeBase._unbottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "copy_attn", ",", "align", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. The args must match self._make_shard_state().\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            copy_attn: the copy attention value.\n            align: the align info.\n        \"\"\"", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "output", ")", ",", "\n", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "\n", "batch", ".", "src_map", ")", "\n", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "align", ",", "target", ")", "\n", "\n", "scores_data", "=", "scores", ".", "data", ".", "clone", "(", ")", "\n", "scores_data", "=", "onmt", ".", "io", ".", "TextDataset", ".", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores_data", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "self", ".", "cur_dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "target", ".", "data", ".", "clone", "(", ")", "\n", "correct_mask", "=", "target_data", ".", "eq", "(", "0", ")", "*", "align", ".", "data", ".", "ne", "(", "0", ")", "\n", "correct_copy", "=", "(", "align", ".", "data", "+", "len", "(", "self", ".", "tgt_vocab", ")", ")", "*", "correct_mask", ".", "long", "(", ")", "\n", "target_data", "=", "target_data", "+", "correct_copy", "\n", "\n", "# Coverage loss term.", "\n", "loss_data", "=", "loss", ".", "data", ".", "clone", "(", ")", "\n", "\n", "stats", "=", "self", ".", "_stats", "(", "loss_data", ",", "scores_data", ",", "target_data", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.MultiHeadedAttn.MultiHeadedAttention.__init__": [[51, 72], ["torch.Module.__init__", "onmt.modules.UtilClass.BottleLinear", "onmt.modules.UtilClass.BottleLinear", "onmt.modules.UtilClass.BottleLinear", "onmt.modules.UtilClass.BottleSoftmax", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "BottleLinear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "linear_values", "=", "BottleLinear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "BottleLinear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "sm", "=", "BottleSoftmax", "(", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "res_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.MultiHeadedAttn.MultiHeadedAttention.forward": [[73, 158], ["key.size", "value.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "query.size", "onmt.Utils.aeq", "onmt.Utils.aeq", "onmt.Utils.aeq", "MultiHeadedAttn.MultiHeadedAttention.forward.shape_projection"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (`FloatTensor`): set of `key_len`\n                key vectors `[batch, key_len, dim]`\n           value (`FloatTensor`): set of `key_len`\n                value vectors `[batch, key_len, dim]`\n           query (`FloatTensor`): set of `query_len`\n                 query vectors  `[batch, query_len, dim]`\n           mask: binary mask indicating which keys have\n                 non-zero attention `[batch, query_len, key_len]`\n        Returns:\n           (`FloatTensor`, `FloatTensor`) :\n\n           * output context vectors `[batch, query_len, dim]`\n           * one of the attention vectors `[batch, query_len, key_len]`\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "batch", ",", "k_len", ",", "d", "=", "key", ".", "size", "(", ")", "\n", "batch_", ",", "k_len_", ",", "d_", "=", "value", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "k_len", ",", "k_len_", ")", "\n", "aeq", "(", "d", ",", "d_", ")", "\n", "batch_", ",", "q_len", ",", "d_", "=", "query", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "d", ",", "d_", ")", "\n", "aeq", "(", "self", ".", "model_dim", "%", "8", ",", "0", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "q_len_", ",", "k_len_", "=", "mask", ".", "size", "(", ")", "\n", "aeq", "(", "batch_", ",", "batch", ")", "\n", "aeq", "(", "k_len_", ",", "k_len", ")", "\n", "aeq", "(", "q_len_", "==", "q_len", ")", "\n", "# END CHECKS", "\n", "\n", "", "def", "shape_projection", "(", "x", ")", ":", "\n", "            ", "b", ",", "l", ",", "d", "=", "x", ".", "size", "(", ")", "\n", "return", "x", ".", "view", "(", "b", ",", "l", ",", "self", ".", "head_count", ",", "self", ".", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", "*", "self", ".", "head_count", ",", "l", ",", "self", ".", "dim_per_head", ")", "\n", "\n", "", "def", "unshape_projection", "(", "x", ",", "q", ")", ":", "\n", "            ", "b", ",", "l", ",", "d", "=", "q", ".", "size", "(", ")", "\n", "return", "x", ".", "view", "(", "b", ",", "self", ".", "head_count", ",", "l", ",", "self", ".", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "l", ",", "self", ".", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "\n", "", "residual", "=", "query", "\n", "key_up", "=", "shape_projection", "(", "self", ".", "linear_keys", "(", "key", ")", ")", "\n", "value_up", "=", "shape_projection", "(", "self", ".", "linear_values", "(", "value", ")", ")", "\n", "query_up", "=", "shape_projection", "(", "self", ".", "linear_query", "(", "query", ")", ")", "\n", "\n", "scaled", "=", "torch", ".", "bmm", "(", "query_up", ",", "key_up", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "scaled", "=", "scaled", "/", "math", ".", "sqrt", "(", "self", ".", "dim_per_head", ")", "\n", "bh", ",", "l", ",", "dim_per_head", "=", "scaled", ".", "size", "(", ")", "\n", "b", "=", "bh", "//", "self", ".", "head_count", "\n", "if", "mask", "is", "not", "None", ":", "\n", "\n", "            ", "scaled", "=", "scaled", ".", "view", "(", "b", ",", "self", ".", "head_count", ",", "l", ",", "dim_per_head", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scaled", ")", "\n", "scaled", "=", "scaled", ".", "masked_fill", "(", "Variable", "(", "mask", ")", ",", "-", "1e18", ")", ".", "view", "(", "bh", ",", "l", ",", "dim_per_head", ")", "\n", "", "attn", "=", "self", ".", "sm", "(", "scaled", ")", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "b", ",", "self", ".", "head_count", ",", "l", ",", "dim_per_head", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "self", ".", "sm", "(", "scaled", ")", ")", "\n", "\n", "# values : (batch * 8) x qlen x dim", "\n", "out", "=", "unshape_projection", "(", "torch", ".", "bmm", "(", "drop_attn", ",", "value_up", ")", ",", "residual", ")", "\n", "\n", "# Residual and layer norm", "\n", "ret", "=", "self", ".", "res_dropout", "(", "out", ")", "\n", "\n", "# CHECK", "\n", "batch_", ",", "q_len_", ",", "d_", "=", "ret", ".", "size", "(", ")", "\n", "aeq", "(", "q_len", ",", "q_len_", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "d", ",", "d_", ")", "\n", "# END CHECK", "\n", "return", "ret", ",", "top_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Bottle.forward": [[6, 12], ["super().forward", "super().forward.contiguous().view", "len", "super().forward", "input.size", "input.view", "input.size", "super().forward.contiguous"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward"], ["        ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "            ", "if", "len", "(", "input", ".", "size", "(", ")", ")", "<=", "2", ":", "\n", "                ", "return", "super", "(", "Bottle", ",", "self", ")", ".", "forward", "(", "input", ")", "\n", "", "size", "=", "input", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "out", "=", "super", "(", "Bottle", ",", "self", ")", ".", "forward", "(", "input", ".", "view", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ",", "-", "1", ")", ")", "\n", "return", "out", ".", "contiguous", "(", ")", ".", "view", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Bottle2.forward": [[15, 22], ["input.size", "super().forward", "super().forward.contiguous().view", "len", "super().forward", "input.view", "input.size", "super().forward.contiguous"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward"], ["        ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "            ", "if", "len", "(", "input", ".", "size", "(", ")", ")", "<=", "3", ":", "\n", "                ", "return", "super", "(", "Bottle2", ",", "self", ")", ".", "forward", "(", "input", ")", "\n", "", "size", "=", "input", ".", "size", "(", ")", "\n", "out", "=", "super", "(", "Bottle2", ",", "self", ")", ".", "forward", "(", "input", ".", "view", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ",", "\n", "size", "[", "2", "]", ",", "size", "[", "3", "]", ")", ")", "\n", "return", "out", ".", "contiguous", "(", ")", ".", "view", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ",", "size", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.LayerNorm.__init__": [[27, 33], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "d_hid", ",", "eps", "=", "1e-3", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.LayerNorm.forward": [[34, 47], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.std", "torch.std", "torch.std", "torch.std", "z.size", "mu.unsqueeze.unsqueeze.dim", "mu.unsqueeze.unsqueeze.unsqueeze", "sigma.unsqueeze.unsqueeze.unsqueeze", "ln_out.mul", "UtilClass.LayerNorm.b_2.expand_as", "mu.unsqueeze.unsqueeze.expand_as", "sigma.unsqueeze.unsqueeze.expand_as", "UtilClass.LayerNorm.a_2.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "if", "z", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "            ", "return", "z", "\n", "", "mu", "=", "torch", ".", "mean", "(", "z", ",", "dim", "=", "1", ")", "\n", "sigma", "=", "torch", ".", "std", "(", "z", ",", "dim", "=", "1", ")", "\n", "# HACK. PyTorch is changing behavior", "\n", "if", "mu", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "mu", "=", "mu", ".", "unsqueeze", "(", "1", ")", "\n", "sigma", "=", "sigma", ".", "unsqueeze", "(", "1", ")", "\n", "", "ln_out", "=", "(", "z", "-", "mu", ".", "expand_as", "(", "z", ")", ")", "/", "(", "sigma", ".", "expand_as", "(", "z", ")", "+", "self", ".", "eps", ")", "\n", "ln_out", "=", "ln_out", ".", "mul", "(", "self", ".", "a_2", ".", "expand_as", "(", "ln_out", ")", ")", "+", "self", ".", "b_2", ".", "expand_as", "(", "ln_out", ")", "\n", "return", "ln_out", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.__init__": [[72, 76], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward": [[77, 89], ["feat.squeeze", "len", "len", "f", "input.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "inputs", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "input", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translator.Translator.__init__": [[26, 49], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "fields", ",", "\n", "beam_size", ",", "n_best", "=", "1", ",", "\n", "max_length", "=", "100", ",", "\n", "global_scorer", "=", "None", ",", "copy_attn", "=", "False", ",", "cuda", "=", "False", ",", "\n", "beam_trace", "=", "False", ",", "min_length", "=", "0", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "cuda", "=", "cuda", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translator.Translator.translate_batch": [[50, 177], ["onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "Translator.Translator.model.encoder", "Translator.Translator.model.decoder.init_decoder_state", "Translator.Translator.translate_batch.rvar"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.init_decoder_state"], ["", "", "def", "translate_batch", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Translate a batch of sentences.\n\n        Mostly a wrapper around :obj:`Beam`.\n\n        Args:\n           batch (:obj:`Batch`): a batch from a dataset object\n           data (:obj:`Dataset`): the dataset object\n\n\n        Todo:\n           Shouldn't need the original dataset.\n        \"\"\"", "\n", "\n", "# (0) Prep each of the components of the search.", "\n", "# And helper method for reducing verbosity.", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "data_type", "=", "data", ".", "data_type", "\n", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "beam", "=", "[", "onmt", ".", "translate", ".", "Beam", "(", "beam_size", ",", "n_best", "=", "self", ".", "n_best", ",", "\n", "cuda", "=", "self", ".", "cuda", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", ",", "\n", "eos", "=", "vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "EOS_WORD", "]", ",", "\n", "bos", "=", "vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "BOS_WORD", "]", ",", "\n", "min_length", "=", "self", ".", "min_length", ")", "\n", "for", "__", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# Help functions for working with beams and batches", "\n", "def", "var", "(", "a", ")", ":", "return", "Variable", "(", "a", ",", "volatile", "=", "True", ")", "\n", "\n", "def", "rvar", "(", "a", ")", ":", "return", "var", "(", "a", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ")", "\n", "\n", "def", "bottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "\n", "", "def", "unbottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "beam_size", ",", "batch_size", ",", "-", "1", ")", "\n", "\n", "# (1) Run the encoder on the src.", "\n", "", "src", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "src_lengths", "=", "None", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "", "enc_states", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "\n", "src", ",", "context", ",", "enc_states", ")", "\n", "\n", "if", "src_lengths", "is", "None", ":", "\n", "            ", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "context", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "context", ".", "size", "(", "0", ")", ")", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "", "src_map", "=", "rvar", "(", "batch", ".", "src_map", ".", "data", ")", "if", "data_type", "==", "'text'", "and", "self", ".", "copy_attn", "else", "None", "\n", "context", "=", "rvar", "(", "context", ".", "data", ")", "\n", "context_lengths", "=", "src_lengths", ".", "repeat", "(", "beam_size", ")", "\n", "dec_states", ".", "repeat_beam_size_times", "(", "beam_size", ")", "\n", "\n", "# repeat ref and ref lengths", "\n", "per", "=", "[", "]", "\n", "for", "p", ",", "p_len", "in", "batch", ".", "per", ":", "\n", "            ", "p", "=", "p", ".", "repeat", "(", "1", ",", "beam_size", ")", "\n", "p_len", "=", "p_len", ".", "repeat", "(", "beam_size", ")", "\n", "per", ".", "append", "(", "[", "p", ",", "p_len", "]", ")", "\n", "\n", "# (3) run the decoder to generate sentences, using beam search.", "\n", "", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "if", "all", "(", "(", "b", ".", "done", "(", ")", "for", "b", "in", "beam", ")", ")", ":", "\n", "                ", "break", "\n", "\n", "# Construct batch x beam_size nxt words.", "\n", "# Get all the pending current beam words and arrange for forward.", "\n", "", "inp", "=", "var", "(", "torch", ".", "stack", "(", "[", "b", ".", "get_current_state", "(", ")", "for", "b", "in", "beam", "]", ")", "\n", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "\n", "# Turn any copied words to UNKs", "\n", "# 0 is unk", "\n", "if", "self", ".", "copy_attn", ":", "\n", "                ", "inp", "=", "inp", ".", "masked_fill", "(", "\n", "inp", ".", "gt", "(", "len", "(", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "-", "1", ")", ",", "0", ")", "\n", "\n", "# Temporary kludge solution to handle changed dim expectation", "\n", "# in the decoder", "\n", "", "inp", "=", "inp", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Run one step.", "\n", "# ref_context, ref_lengths = self.model.encode_ref(ref)", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "inp", ",", "context", ",", "dec_states", ",", "context_lengths", "=", "context_lengths", ")", "\n", "dec_out", "=", "dec_out", ".", "squeeze", "(", "0", ")", "\n", "# dec_out: beam x rnn_size", "\n", "\n", "# (b) Compute a vector of batch*beam word scores.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ")", ".", "data", "\n", "out", "=", "unbottle", "(", "out", ")", "\n", "# beam x tgt_vocab", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ",", "\n", "attn", "[", "\"copy\"", "]", ".", "squeeze", "(", "0", ")", ",", "\n", "src_map", ")", "\n", "# beam x (tgt_vocab + extra_vocab)", "\n", "out", "=", "data", ".", "collapse_copy_scores", "(", "\n", "unbottle", "(", "out", ".", "data", ")", ",", "\n", "batch", ",", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "# beam x tgt_vocab", "\n", "out", "=", "out", ".", "log", "(", ")", "\n", "\n", "# (c) Advance each beam.", "\n", "", "for", "j", ",", "b", "in", "enumerate", "(", "beam", ")", ":", "\n", "                ", "b", ".", "advance", "(", "\n", "out", "[", ":", ",", "j", "]", ",", "\n", "unbottle", "(", "attn", "[", "\"std\"", "]", ")", ".", "data", "[", ":", ",", "j", ",", ":", "context_lengths", "[", "j", "]", "]", ")", "\n", "dec_states", ".", "beam_update", "(", "j", ",", "b", ".", "get_current_origin", "(", ")", ",", "beam_size", ")", "\n", "\n", "# (4) Extract sentences from beam.", "\n", "", "", "ret", "=", "self", ".", "_from_beam", "(", "beam", ")", "\n", "ret", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n", "if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "ret", "[", "\"gold_score\"", "]", "=", "self", ".", "_run_target", "(", "batch", ",", "data", ")", "\n", "", "ret", "[", "\"batch\"", "]", "=", "batch", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translator.Translator._from_beam": [[178, 194], ["b.sort_finished", "enumerate", "ret[].append", "ret[].append", "ret[].append", "b.get_hyp", "hyps.append", "attn.append"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.sort_finished", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.get_hyp"], ["", "def", "_from_beam", "(", "self", ",", "beam", ")", ":", "\n", "        ", "ret", "=", "{", "\"predictions\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"attention\"", ":", "[", "]", "}", "\n", "for", "b", "in", "beam", ":", "\n", "            ", "n_best", "=", "self", ".", "n_best", "\n", "scores", ",", "ks", "=", "b", ".", "sort_finished", "(", "minimum", "=", "n_best", ")", "\n", "hyps", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "(", "times", ",", "k", ")", "in", "enumerate", "(", "ks", "[", ":", "n_best", "]", ")", ":", "\n", "                ", "hyp", ",", "att", "=", "b", ".", "get_hyp", "(", "times", ",", "k", ")", "\n", "hyps", ".", "append", "(", "hyp", ")", "\n", "attn", ".", "append", "(", "att", ")", "\n", "", "ret", "[", "\"predictions\"", "]", ".", "append", "(", "hyps", ")", "\n", "ret", "[", "\"scores\"", "]", ".", "append", "(", "scores", ")", "\n", "ret", "[", "\"attention\"", "]", ".", "append", "(", "attn", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translator.Translator._run_target": [[195, 227], ["onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "Translator.Translator.model.encoder", "Translator.Translator.model.decoder.init_decoder_state", "tt.FloatTensor().fill_", "Translator.Translator.model.decoder", "zip", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "onmt.io.make_features", "Translator.Translator.model.generator.forward", "tgt.unsqueeze.unsqueeze.unsqueeze", "Translator.Translator.data.gather", "Translator.Translator.data.gather.masked_fill_", "tt.FloatTensor", "tgt.unsqueeze.unsqueeze.eq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Conv2Conv.CNNDecoder.init_decoder_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.UtilClass.Elementwise.forward"], ["", "def", "_run_target", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "        ", "data_type", "=", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "", "else", ":", "\n", "            ", "src_lengths", "=", "None", "\n", "", "src", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "tgt_in", "=", "onmt", ".", "io", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "[", ":", "-", "1", "]", "\n", "per", "=", "batch", ".", "per", "\n", "\n", "#  (1) run the encoder on the src", "\n", "enc_states", ",", "context", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "\n", "context", ",", "enc_states", ")", "\n", "\n", "#  (2) if a target is specified, compute the 'goldScore'", "\n", "#  (i.e. log likelihood) of the target under the model", "\n", "tt", "=", "torch", ".", "cuda", "if", "self", ".", "cuda", "else", "torch", "\n", "gold_scores", "=", "tt", ".", "FloatTensor", "(", "batch", ".", "batch_size", ")", ".", "fill_", "(", "0", ")", "\n", "# ref_context, ref_lengths = self.model.encode_ref(ref)", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "tgt_in", ",", "context", ",", "dec_states", ",", "context_lengths", "=", "src_lengths", ")", "\n", "\n", "tgt_pad", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ".", "stoi", "[", "onmt", ".", "io", ".", "PAD_WORD", "]", "\n", "for", "dec", ",", "tgt", "in", "zip", "(", "dec_out", ",", "batch", ".", "tgt", "[", "1", ":", "]", ".", "data", ")", ":", "\n", "# Log prob of each word.", "\n", "            ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec", ")", "\n", "tgt", "=", "tgt", ".", "unsqueeze", "(", "1", ")", "\n", "scores", "=", "out", ".", "data", ".", "gather", "(", "1", ",", "tgt", ")", "\n", "scores", ".", "masked_fill_", "(", "tgt", ".", "eq", "(", "tgt_pad", ")", ",", "0", ")", "\n", "gold_scores", "+=", "scores", "\n", "", "return", "gold_scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder.__init__": [[22, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "fields", ",", "n_best", "=", "1", ",", "replace_unk", "=", "False", ",", "\n", "has_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "has_tgt", "=", "has_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder._build_target_tokens": [[30, 47], ["range", "len", "tokens.append", "tokens.append", "len", "attn[].max", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "onmt", ".", "io", ".", "EOS_WORD", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "(", "attn", "is", "not", "None", ")", "and", "(", "src", "is", "not", "None", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "vocab", ".", "itos", "[", "onmt", ".", "io", ".", "UNK", "]", ":", "\n", "                    ", "_", ",", "maxIndex", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "maxIndex", "[", "0", "]", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder.from_batch": [[48, 103], ["list", "torch.sort", "range", "len", "len", "zip", "batch.src[].data.index_select", "batch.tgt.data.index_select", "Translation.Translation", "translations.append", "Translation.TranslationBuilder._build_target_tokens", "Translation.TranslationBuilder._build_target_tokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder._build_target_tokens", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder._build_target_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ".", "data", ")", "\n", "data_type", "=", "self", ".", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "src", "=", "batch", ".", "src", "[", "0", "]", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "\n", "", "if", "self", ".", "has_tgt", ":", "\n", "            ", "tgt", "=", "batch", ".", "tgt", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "tgt", "=", "None", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "data_type", "==", "'text'", ":", "\n", "                ", "src_vocab", "=", "self", ".", "data", ".", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "self", ".", "data", ".", "src_vocabs", "else", "None", "\n", "src_raw", "=", "self", ".", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "\n", "", "else", ":", "\n", "                ", "src_vocab", "=", "None", "\n", "src_raw", "=", "None", "\n", "", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "gold_sent", "=", "None", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "gold_sent", "=", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "tgt", "[", "1", ":", ",", "b", "]", "if", "tgt", "is", "not", "None", "else", "None", ",", "None", ")", "\n", "\n", "", "translation", "=", "Translation", "(", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_raw", ",", "pred_sents", ",", "\n", "attn", "[", "b", "]", ",", "pred_score", "[", "b", "]", ",", "gold_sent", ",", "\n", "gold_score", "[", "b", "]", ")", "\n", "translations", ".", "append", "(", "translation", ")", "\n", "\n", "", "return", "translations", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.__init__": [[120, 129], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n", "attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log": [[130, 153], ["print", "len", "print", "zip"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation to stdout.\n        \"\"\"", "\n", "output", "=", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "output", "+=", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", "\n", "print", "(", "\"PRED SCORE: {:.4f}\"", ".", "format", "(", "best_score", ")", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n", "            ", "tgt_sent", "=", "' '", ".", "join", "(", "self", ".", "gold_sent", ")", "\n", "output", "+=", "'GOLD {}: {}\\n'", ".", "format", "(", "sent_number", ",", "tgt_sent", ")", "\n", "output", "+=", "(", "\"GOLD SCORE: {:.4f}\"", ".", "format", "(", "self", ".", "gold_score", ")", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "pred_sents", ")", ">", "1", ":", "\n", "            ", "print", "(", "'\\nBEST HYP:'", ")", "\n", "for", "score", ",", "sent", "in", "zip", "(", "self", ".", "pred_scores", ",", "self", ".", "pred_sents", ")", ":", "\n", "                ", "output", "+=", "\"[{:.4f}] {}\\n\"", ".", "format", "(", "score", ",", "sent", ")", "\n", "\n", "", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.__init__": [[18, 55], ["Beam.Beam.tt.FloatTensor().zero_", "Beam.Beam.tt.LongTensor().fill_", "Beam.Beam.tt.FloatTensor", "Beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.get_current_state": [[56, 59], ["None"], "methods", ["None"], ["", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.get_current_origin": [[60, 63], ["None"], "methods", ["None"], ["", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.advance": [[64, 124], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "Beam.Beam.all_scores.append", "Beam.Beam.prev_ks.append", "Beam.Beam.next_ys.append", "Beam.Beam.attn.append", "range", "range", "len", "range", "attn_out.index_select", "Beam.Beam.global_scorer.update_global_state", "Beam.Beam.next_ys[].size", "len", "Beam.Beam.scores.unsqueeze().expand_as", "Beam.Beam.next_ys[].size", "Beam.Beam.finished.append", "Beam.Beam.global_scorer.score", "Beam.Beam.scores.unsqueeze", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.update_global_state", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.score"], ["", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Parameters:\n\n        * `word_probs`- probs of advancing from the last step (K x words)\n        * `attn_out`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "\n", "# force the output to be longer than self.min_length", "\n", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<", "self", ".", "min_length", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "word_probs", ")", ")", ":", "\n", "                ", "word_probs", "[", "k", "]", "[", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "\n", "# Sum the previous scores.", "\n", "", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "word_probs", ")", "\n", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beam_scores", "[", "i", "]", "=", "-", "1e20", "\n", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "\n", "if", "self", ".", "global_scorer", "is", "not", "None", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "s", "=", "self", ".", "scores", "[", "i", "]", "\n", "if", "self", ".", "global_scorer", "is", "not", "None", ":", "\n", "                    ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "# self.all_scores.append(self.scores)", "\n", "            ", "self", ".", "eos_top", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.done": [[125, 127], ["len"], "methods", ["None"], ["", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.sort_finished": [[128, 143], ["Beam.Beam.finished.sort", "len", "Beam.Beam.finished.append", "Beam.Beam.global_scorer.score", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "s", "=", "self", ".", "scores", "[", "i", "]", "\n", "if", "self", ".", "global_scorer", "is", "not", "None", ":", "\n", "                    ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.Beam.get_hyp": [[144, 154], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Walk back to construct the full hypothesis.\n        \"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.__init__": [[165, 168], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "beta", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.score": [[169, 176], ["torch.min().log().sum", "torch.min().log", "len", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"Additional term add to log probability\"", "\n", "cov", "=", "beam", ".", "global_state", "[", "\"coverage\"", "]", "\n", "pen", "=", "self", ".", "beta", "*", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "1", ")", "\n", "l_term", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "next_ys", ")", ")", "**", "self", ".", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "self", ".", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "l_term", ")", "+", "pen", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Beam.GNMTGlobalScorer.update_global_state": [[177, 184], ["len", "beam.global_state[].index_select().add", "beam.global_state[].index_select"], "methods", ["None"], ["", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"Keeps the coverage vector as sum of attens\"", "\n", "if", "len", "(", "beam", ".", "prev_ks", ")", "==", "1", ":", "\n", "            ", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "attn", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "global_state", "[", "\"coverage\"", "]", ".", "index_select", "(", "0", ",", "beam", ".", "prev_ks", "[", "-", "1", "]", ")", ".", "add", "(", "beam", ".", "attn", "[", "-", "1", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.__getstate__": [[27, 29], ["None"], "methods", ["None"], ["def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.__setstate__": [[30, 32], ["DatasetBase.ONMTDatasetBase.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.__reduce_ex__": [[33, 36], ["super().__reduce_ex__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.__reduce_ex__"], ["", "def", "__reduce_ex__", "(", "self", ",", "proto", ")", ":", "\n", "        ", "\"This is a hack. Something is broken with torch pickle.\"", "\n", "return", "super", "(", "ONMTDatasetBase", ",", "self", ")", ".", "__reduce_ex__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.load_fields": [[37, 48], ["load_fields_from_vocab", "dict", "vocab_dict.items", "load_fields_from_vocab.items"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab"], ["", "def", "load_fields", "(", "self", ",", "vocab_dict", ")", ":", "\n", "        ", "\"\"\" Load fields from vocab.pt, and set the `fields` attribute.\n\n        Args:\n            vocab_dict (dict): a dict of loaded vocab from vocab.pt file.\n        \"\"\"", "\n", "from", "onmt", ".", "io", ".", "IO", "import", "load_fields_from_vocab", "\n", "\n", "fields", "=", "load_fields_from_vocab", "(", "vocab_dict", ".", "items", "(", ")", ",", "self", ".", "data_type", ")", "\n", "self", ".", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "self", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.coalesce_datasets": [[49, 70], ["onmt.Utils.aeq", "onmt.Utils.aeq"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq"], ["", "@", "staticmethod", "\n", "def", "coalesce_datasets", "(", "datasets", ")", ":", "\n", "        ", "\"\"\"Coalesce all dataset instances. \"\"\"", "\n", "final", "=", "datasets", "[", "0", "]", "\n", "for", "d", "in", "datasets", "[", "1", ":", "]", ":", "\n", "# `src_vocabs` is a list of `torchtext.vocab.Vocab`.", "\n", "# Each sentence transforms into on Vocab.", "\n", "# Coalesce them into one big list.", "\n", "            ", "final", ".", "src_vocabs", "+=", "d", ".", "src_vocabs", "\n", "\n", "# All datasets have same number of features.", "\n", "aeq", "(", "final", ".", "n_src_feats", ",", "d", ".", "n_src_feats", ")", "\n", "aeq", "(", "final", ".", "n_tgt_feats", ",", "d", ".", "n_tgt_feats", ")", "\n", "\n", "# `examples` is a list of `torchtext.data.Example`.", "\n", "# Coalesce them into one big list.", "\n", "final", ".", "examples", "+=", "d", ".", "examples", "\n", "\n", "# All datasets have same fields, no need to update.", "\n", "\n", "", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features": [[71, 94], ["len", "all", "list", "token.split", "zip", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "extract_text_features", "(", "tokens", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokens: A list of tokens, where each token consists of a word,\n                optionally followed by u\"\uffe8\"-delimited features.\n        Returns:\n            A sequence of words, a sequence of features, and num of features.\n        \"\"\"", "\n", "if", "not", "tokens", ":", "\n", "            ", "return", "[", "]", ",", "[", "]", ",", "-", "1", "\n", "\n", "", "split_tokens", "=", "[", "token", ".", "split", "(", "u\"\uffe8\"", ")", "for", "token", "in", "tokens", "]", "\n", "split_tokens", "=", "[", "token", "for", "token", "in", "split_tokens", "if", "token", "[", "0", "]", "]", "\n", "token_size", "=", "len", "(", "split_tokens", "[", "0", "]", ")", "\n", "\n", "assert", "all", "(", "len", "(", "token", ")", "==", "token_size", "for", "token", "in", "split_tokens", ")", ",", "\"all words must have the same number of features\"", "\n", "words_and_features", "=", "list", "(", "zip", "(", "*", "split_tokens", ")", ")", "\n", "words", "=", "words_and_features", "[", "0", "]", "\n", "features", "=", "words_and_features", "[", "1", ":", "]", "\n", "\n", "return", "words", ",", "features", ",", "token_size", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._join_dicts": [[97, 106], ["dict", "itertools.chain", "d.items"], "methods", ["None"], ["", "def", "_join_dicts", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dictionaries with disjoint keys.\n\n        Returns:\n            a single dictionary that has the union of these keys.\n        \"\"\"", "\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._peek": [[107, 119], ["next", "itertools.chain"], "methods", ["None"], ["", "def", "_peek", "(", "self", ",", "seq", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            seq: an iterator.\n\n        Returns:\n            the first thing returned by calling next() on the iterator\n            and an iterator created by re-chaining that value to the beginning\n            of the iterator.\n        \"\"\"", "\n", "first", "=", "next", "(", "seq", ")", "\n", "return", "first", ",", "chain", "(", "[", "first", "]", ",", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._construct_example_fromlist": [[120, 139], ["torchtext.data.Example", "zip", "setattr", "setattr", "field.preprocess"], "methods", ["None"], ["", "def", "_construct_example_fromlist", "(", "self", ",", "data", ",", "fields", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data: the data to be set as the value of the attributes of\n                the to-be-created `Example`, associating with respective\n                `Field` objects with same key.\n            fields: a dict of `torchtext.data.Field` objects. The keys\n                are attributes of the to-be-created `Example`.\n\n        Returns:\n            the created `Example` object.\n        \"\"\"", "\n", "ex", "=", "torchtext", ".", "data", ".", "Example", "(", ")", "\n", "for", "(", "name", ",", "field", ")", ",", "val", "in", "zip", "(", "fields", ",", "data", ")", ":", "\n", "            ", "if", "field", "is", "not", "None", ":", "\n", "                ", "setattr", "(", "ex", ",", "name", ",", "field", ".", "preprocess", "(", "val", ")", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "ex", ",", "name", ",", "val", ")", "\n", "", "", "return", "ex", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.__init__": [[39, 89], ["TextDataset.TextDataset._peek", "ex.keys", "list", "onmt.io.DatasetBase.ONMTDatasetBase.__init__", "TextDataset.TextDataset._dynamic_dict", "TextDataset.TextDataset._construct_example_fromlist", "TextDataset.TextDataset._join_dicts", "zip", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._peek", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset._dynamic_dict", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "per_examples_iter", ",", "nli_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "per_seq_length", "=", "0", ",", "nli_seq_length", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'text'", "\n", "\n", "# self.src_vocabs: mutated in dynamic_dict, used in", "\n", "# collapse_copy_scores and in Translator.py", "\n", "self", ".", "src_vocabs", "=", "[", "]", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "# Each element of an example is a dictionary whose keys represents", "\n", "# at minimum the src tokens and their indices and potentially also", "\n", "# the src and tgt features and alignment information.", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ",", "per", ",", "nli", ")", "for", "src", ",", "tgt", ",", "per", ",", "nli", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ",", "per_examples_iter", ",", "nli_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "", "if", "dynamic_dict", ":", "\n", "            ", "examples_iter", "=", "self", ".", "_dynamic_dict", "(", "examples_iter", ")", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "return", "0", "<", "len", "(", "example", ".", "src", ")", "<=", "src_seq_length", "and", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "and", "0", "<", "len", "(", "example", ".", "per", ")", "<=", "per_seq_length", "and", "0", "<", "len", "(", "example", ".", "nli", ")", "<=", "nli_seq_length", "\n", "\n", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "TextDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.sort_key": [[91, 94], ["len"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using length of source sentences. \"\"\"", "\n", "return", "len", "(", "ex", ".", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.collapse_copy_scores": [[95, 113], ["len", "range", "range", "len", "scores[].fill_"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collapse_copy_scores", "(", "scores", ",", "batch", ",", "tgt_vocab", ",", "src_vocabs", ")", ":", "\n", "        ", "\"\"\"\n        Given scores from an expanded dictionary\n        corresponeding to a batch, sums together copies,\n        with a dictionary word when it is ambigious.\n        \"\"\"", "\n", "offset", "=", "len", "(", "tgt_vocab", ")", "\n", "for", "b", "in", "range", "(", "batch", ".", "batch_size", ")", ":", "\n", "            ", "index", "=", "batch", ".", "indices", ".", "data", "[", "b", "]", "\n", "src_vocab", "=", "src_vocabs", "[", "index", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "src_vocab", ")", ")", ":", "\n", "                ", "sw", "=", "src_vocab", ".", "itos", "[", "i", "]", "\n", "ti", "=", "tgt_vocab", ".", "stoi", "[", "sw", "]", "\n", "if", "ti", "!=", "0", ":", "\n", "                    ", "scores", "[", ":", ",", "b", ",", "ti", "]", "+=", "scores", "[", ":", ",", "b", ",", "offset", "+", "i", "]", "\n", "scores", "[", ":", ",", "b", ",", "offset", "+", "i", "]", ".", "fill_", "(", "1e-20", ")", "\n", "", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl": [[114, 143], ["TextDataset.read_text_file", "next", "itertools.chain"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.read_text_file"], ["", "@", "staticmethod", "\n", "def", "make_text_examples_nfeats_tpl", "(", "path", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src or tgt file.\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Returns:\n            (example_dict iterator, num_feats) tuple.\n        \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", ",", "'per'", ",", "'nli'", "]", "\n", "\n", "if", "path", "is", "None", ":", "\n", "            ", "return", "(", "None", ",", "0", ")", "\n", "\n", "# All examples have same number of features, so we peek first one", "\n", "# to get the num_feats.", "\n", "", "examples_nfeats_iter", "=", "TextDataset", ".", "read_text_file", "(", "path", ",", "truncate", ",", "side", ")", "\n", "\n", "first_ex", "=", "next", "(", "examples_nfeats_iter", ")", "\n", "num_feats", "=", "first_ex", "[", "1", "]", "\n", "\n", "# Chain back the first element - we only want to peek it.", "\n", "examples_nfeats_iter", "=", "chain", "(", "[", "first_ex", "]", ",", "examples_nfeats_iter", ")", "\n", "examples_iter", "=", "(", "ex", "for", "ex", ",", "nfeats", "in", "examples_nfeats_iter", ")", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.read_text_file": [[144, 170], ["codecs.open", "enumerate", "line.strip().split.strip().split.strip().split", "TextDataset.extract_text_features", "example_dict.update", "line.strip().split.strip().split.strip", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "@", "staticmethod", "\n", "def", "read_text_file", "(", "path", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src or tgt file.\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Yields:\n            (word, features, nfeat) triples for each line.\n        \"\"\"", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "corpus_file", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "truncate", ":", "\n", "                    ", "line", "=", "line", "[", ":", "truncate", "]", "\n", "\n", "", "words", ",", "feats", ",", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "\n", "example_dict", "=", "{", "side", ":", "words", ",", "\"indices\"", ":", "i", "}", "\n", "if", "feats", ":", "\n", "                    ", "prefix", "=", "side", "+", "\"_feat_\"", "\n", "example_dict", ".", "update", "(", "(", "prefix", "+", "str", "(", "j", ")", ",", "f", ")", "\n", "for", "j", ",", "f", "in", "enumerate", "(", "feats", ")", ")", "\n", "", "yield", "example_dict", ",", "n_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.get_fields": [[171, 240], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "TextDataset.PerField", "TextDataset.NliField", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "max", "len", "enumerate", "t.size", "t.size", "torch.zeros", "str", "str", "t.max", "len", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features (int): the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features (int): the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"per\"", "]", "=", "PerField", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "fields", "[", "\"nli\"", "]", "=", "NliField", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "def", "make_src", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "FloatTensor", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.get_num_features": [[241, 261], ["codecs.open", "cf.readline().strip().split", "TextDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Peek one line and get number of features of it.\n        (All lines must have same number of features).\n        For text corpus, both sides are in text form, thus\n        it works the same.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "            ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "TextDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "return", "num_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset._dynamic_dict": [[263, 278], ["torchtext.vocab.Vocab", "TextDataset.TextDataset.src_vocabs.append", "torch.LongTensor", "collections.Counter", "torch.LongTensor"], "methods", ["None"], ["", "def", "_dynamic_dict", "(", "self", ",", "examples_iter", ")", ":", "\n", "        ", "for", "example", "in", "examples_iter", ":", "\n", "            ", "src", "=", "example", "[", "\"src\"", "]", "\n", "src_vocab", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "src", ")", ")", "\n", "self", ".", "src_vocabs", ".", "append", "(", "src_vocab", ")", "\n", "# Mapping source tokens to indices in the dynamic dict.", "\n", "src_map", "=", "torch", ".", "LongTensor", "(", "[", "src_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "src", "]", ")", "\n", "example", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n", "if", "\"tgt\"", "in", "example", ":", "\n", "                ", "tgt", "=", "example", "[", "\"tgt\"", "]", "\n", "mask", "=", "torch", ".", "LongTensor", "(", "\n", "[", "0", "]", "+", "[", "src_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "tgt", "]", "+", "[", "0", "]", ")", "\n", "example", "[", "\"alignment\"", "]", "=", "mask", "\n", "", "yield", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.__init__": [[289, 316], ["io.open", "sys.stderr.write", "sys.exit"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "corpus_path", ",", "line_truncate", ",", "side", ",", "shard_size", ",", "\n", "assoc_iter", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            corpus_path: the corpus file path.\n            line_truncate: the maximum length of a line to read.\n                            0 for unlimited.\n            side: \"src\" or \"tgt\".\n            shard_size: the shard size, 0 means not sharding the file.\n            assoc_iter: if not None, it is the associate iterator that\n                        this iterator should align its step with.\n        \"\"\"", "\n", "try", ":", "\n", "# The codecs module seems to have bugs with seek()/tell(),", "\n", "# so we use io.open().", "\n", "            ", "self", ".", "corpus", "=", "io", ".", "open", "(", "corpus_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Failed to open corpus file: %s\"", "%", "corpus_path", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "self", ".", "line_truncate", "=", "line_truncate", "\n", "self", ".", "side", "=", "side", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "assoc_iter", "=", "assoc_iter", "\n", "self", ".", "last_pos", "=", "0", "\n", "self", ".", "line_index", "=", "-", "1", "\n", "self", ".", "eof", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.__iter__": [[317, 361], ["TextDataset.ShardedTextCorpusIterator.corpus.seek", "TextDataset.ShardedTextCorpusIterator.corpus.readline", "TextDataset.ShardedTextCorpusIterator.corpus.close", "TextDataset.ShardedTextCorpusIterator.corpus.readline", "AssertionError", "TextDataset.ShardedTextCorpusIterator._example_dict_iter", "TextDataset.ShardedTextCorpusIterator.corpus.tell", "TextDataset.ShardedTextCorpusIterator.corpus.close", "TextDataset.ShardedTextCorpusIterator._example_dict_iter"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator._example_dict_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator._example_dict_iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Iterator of (example_dict, nfeats).\n        On each call, it iterates over as many (example_dict, nfeats) tuples\n        until this shard's size equals to or approximates `self.shard_size`.\n        \"\"\"", "\n", "if", "self", ".", "assoc_iter", "is", "not", "None", ":", "\n", "# We have associate iterator, just yields tuples", "\n", "# util we run parallel with it.", "\n", "            ", "while", "self", ".", "line_index", "<", "self", ".", "assoc_iter", ".", "line_index", ":", "\n", "                ", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                    ", "raise", "AssertionError", "(", "\n", "\"Two corpuses must have same number of lines!\"", ")", "\n", "\n", "", "self", ".", "line_index", "+=", "1", "\n", "yield", "self", ".", "_example_dict_iter", "(", "line", ")", "\n", "\n", "", "if", "self", ".", "assoc_iter", ".", "eof", ":", "\n", "                ", "self", ".", "eof", "=", "True", "\n", "self", ".", "corpus", ".", "close", "(", ")", "\n", "", "", "else", ":", "\n", "# Yield tuples util this shard's size reaches the threshold.", "\n", "            ", "self", ".", "corpus", ".", "seek", "(", "self", ".", "last_pos", ")", "\n", "while", "True", ":", "\n", "                ", "if", "self", ".", "shard_size", "!=", "0", "and", "self", ".", "line_index", "%", "64", "==", "0", ":", "\n", "# This part of check is time consuming on Py2 (but", "\n", "# it is quite fast on Py3, weird!). So we don't bother", "\n", "# to check for very line. Instead we chekc every 64", "\n", "# lines. Thus we are not dividing exactly per", "\n", "# `shard_size`, but it is not too much difference.", "\n", "                    ", "cur_pos", "=", "self", ".", "corpus", ".", "tell", "(", ")", "\n", "if", "cur_pos", ">=", "self", ".", "last_pos", "+", "self", ".", "shard_size", ":", "\n", "                        ", "self", ".", "last_pos", "=", "cur_pos", "\n", "raise", "StopIteration", "\n", "\n", "", "", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                    ", "self", ".", "eof", "=", "True", "\n", "self", ".", "corpus", ".", "close", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "", "self", ".", "line_index", "+=", "1", "\n", "yield", "self", ".", "_example_dict_iter", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.hit_end": [[362, 364], ["None"], "methods", ["None"], ["", "", "", "def", "hit_end", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eof", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.num_feats": [[365, 379], ["TextDataset.ShardedTextCorpusIterator.corpus.tell", "TextDataset.ShardedTextCorpusIterator.corpus.readline().split", "TextDataset.extract_text_features", "TextDataset.ShardedTextCorpusIterator.corpus.seek", "TextDataset.ShardedTextCorpusIterator.corpus.readline"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features"], ["", "@", "property", "\n", "def", "num_feats", "(", "self", ")", ":", "\n", "# We peek the first line and seek back to", "\n", "# the beginning of the file.", "\n", "        ", "saved_pos", "=", "self", ".", "corpus", ".", "tell", "(", ")", "\n", "\n", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "if", "self", ".", "line_truncate", ":", "\n", "            ", "line", "=", "line", "[", ":", "self", ".", "line_truncate", "]", "\n", "", "_", ",", "_", ",", "self", ".", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "\n", "self", ".", "corpus", ".", "seek", "(", "saved_pos", ")", "\n", "\n", "return", "self", ".", "n_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator._example_dict_iter": [[380, 395], ["line.split.split.split", "TextDataset.extract_text_features", "onmt.Utils.aeq", "example_dict.update", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.aeq", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "_example_dict_iter", "(", "self", ",", "line", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "if", "self", ".", "line_truncate", ":", "\n", "            ", "line", "=", "line", "[", ":", "self", ".", "line_truncate", "]", "\n", "", "words", ",", "feats", ",", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "example_dict", "=", "{", "self", ".", "side", ":", "words", ",", "\"indices\"", ":", "self", ".", "line_index", "}", "\n", "if", "feats", ":", "\n", "# All examples must have same number of features.", "\n", "            ", "aeq", "(", "self", ".", "n_feats", ",", "n_feats", ")", "\n", "\n", "prefix", "=", "self", ".", "side", "+", "\"_feat_\"", "\n", "example_dict", ".", "update", "(", "(", "prefix", "+", "str", "(", "j", ")", ",", "f", ")", "\n", "for", "j", ",", "f", "in", "enumerate", "(", "feats", ")", ")", "\n", "\n", "", "return", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.PerField.process": [[398, 426], ["range", "TextDataset.PerField.pad", "TextDataset.PerField.numericalize", "ret.append", "len", "per.append", "per.append", "tmp[].strip().split", "tmp[].strip().split", "tmp[].strip", "tmp[].strip", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.pad", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.numericalize"], ["    ", "def", "process", "(", "self", ",", "batch", ",", "device", ",", "train", ")", ":", "\n", "        ", "\"\"\" Process a list of examples to create a torch.Tensor.\n\n        Pad, numericalize, and postprocess a batch and create a tensor.\n\n        Args:\n            batch (list(object)): A list of object from a batch of examples.\n        Returns:\n            data (torch.autograd.Varaible): Processed object given the input\n                and custom postprocessing Pipeline.\n        \"\"\"", "\n", "per_count", "=", "4", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "per_count", ")", ":", "\n", "# per = [(' '.join(sample)).strip().split('</s>')[i].strip().split(' ') for sample in batch]", "\n", "\n", "            ", "per", "=", "[", "]", "\n", "for", "sample", "in", "batch", ":", "\n", "                ", "tmp", "=", "(", "' '", ".", "join", "(", "sample", ")", ")", ".", "strip", "(", ")", ".", "split", "(", "'</s>'", ")", "\n", "if", "i", "<", "len", "(", "tmp", ")", ":", "\n", "                    ", "per", ".", "append", "(", "tmp", "[", "i", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "else", ":", "\n", "                    ", "per", ".", "append", "(", "tmp", "[", "len", "(", "tmp", ")", "-", "1", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "\n", "\n", "", "", "padded", "=", "self", ".", "pad", "(", "per", ")", "\n", "per_tensor", "=", "self", ".", "numericalize", "(", "padded", ",", "device", "=", "device", ",", "train", "=", "train", ")", "\n", "ret", ".", "append", "(", "per_tensor", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.PerField.pad": [[427, 463], ["list", "max", "lengths.append", "padded.append", "padded.append", "len", "len", "max", "list", "max", "len", "list", "max", "len", "len"], "methods", ["None"], ["", "def", "pad", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "\"\"\"Pad a batch of examples using this field.\n\n        Pads to self.fix_length if provided, otherwise pads to the length of\n        the longest example in the batch. Prepends self.init_token and appends\n        self.eos_token if those attributes are not None. Returns a tuple of the\n        padded list and a list containing lengths of each example if\n        `self.include_lengths` is `True` and `self.sequential` is `True`, else just\n        returns the padded list. If `self.sequential` is `False`, no padding is applied.\n        \"\"\"", "\n", "minibatch", "=", "list", "(", "minibatch", ")", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "            ", "return", "minibatch", "\n", "", "if", "self", ".", "fix_length", "is", "None", ":", "\n", "            ", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "minibatch", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "self", ".", "fix_length", "+", "(", "\n", "self", ".", "init_token", ",", "self", ".", "eos_token", ")", ".", "count", "(", "None", ")", "-", "2", "\n", "", "padded", ",", "lengths", "=", "[", "]", ",", "[", "]", "\n", "for", "x", "in", "minibatch", ":", "\n", "            ", "if", "self", ".", "pad_first", ":", "\n", "                ", "padded", ".", "append", "(", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "padded", ".", "append", "(", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", "+", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "lengths", ".", "append", "(", "len", "(", "padded", "[", "-", "1", "]", ")", "-", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "(", "padded", ",", "lengths", ")", "\n", "", "return", "padded", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.PerField.numericalize": [[465, 529], ["isinstance", "TextDataset.PerField.tensor_type", "torch.nn.functional.Variable", "ValueError", "torch.LongTensor", "arr.contiguous.contiguous.t_", "arr.contiguous.contiguous.cuda", "isinstance", "TextDataset.PerField.postprocessing", "ValueError", "TextDataset.PerField.postprocessing", "arr.contiguous.contiguous.contiguous", "lengths.cuda.cuda.cuda", "torch.nn.functional.Variable", "isinstance", "numericalization_func"], "methods", ["None"], ["", "def", "numericalize", "(", "self", ",", "arr", ",", "device", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Turn a batch of examples that use this field into a Variable.\n\n        If the field has include_lengths=True, a tensor of lengths will be\n        included in the return value.\n\n        Arguments:\n            arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n                List of tokenized and padded examples, or tuple of List of\n                tokenized and padded examples and List of lengths of each\n                example if self.include_lengths is True.\n            device (-1 or None): Device to create the Variable's Tensor on.\n                Use -1 for CPU and None for the currently active GPU device.\n                Default: None.\n            train (boolean): Whether the batch is for a training set.\n                If False, the Variable will be created with volatile=True.\n                Default: True.\n        \"\"\"", "\n", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "arr", ",", "lengths", "=", "arr", "\n", "lengths", "=", "torch", ".", "LongTensor", "(", "lengths", ")", "\n", "\n", "", "if", "self", ".", "use_vocab", ":", "\n", "            ", "if", "self", ".", "sequential", ":", "\n", "                ", "arr", "=", "[", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "ex", "]", "for", "ex", "in", "arr", "]", "\n", "", "else", ":", "\n", "                ", "arr", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "arr", "]", "\n", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "                ", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "self", ".", "vocab", ",", "train", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "tensor_type", "not", "in", "self", ".", "tensor_types", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Specified Field tensor_type {} can not be used with \"", "\n", "\"use_vocab=False because we do not know how to numericalize it. \"", "\n", "\"Please raise an issue at \"", "\n", "\"https://github.com/pytorch/text/issues\"", ".", "format", "(", "self", ".", "tensor_type", ")", ")", "\n", "", "numericalization_func", "=", "self", ".", "tensor_types", "[", "self", ".", "tensor_type", "]", "\n", "# It doesn't make sense to explictly coerce to a numeric type if", "\n", "# the data is sequential, since it's unclear how to coerce padding tokens", "\n", "# to a numeric type.", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "                ", "arr", "=", "[", "numericalization_func", "(", "x", ")", "if", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "\n", "else", "x", "for", "x", "in", "arr", "]", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "                ", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "None", ",", "train", ")", "\n", "\n", "", "", "arr", "=", "self", ".", "tensor_type", "(", "arr", ")", "\n", "if", "self", ".", "sequential", "and", "not", "self", ".", "batch_first", ":", "\n", "            ", "arr", ".", "t_", "(", ")", "\n", "", "if", "device", "==", "-", "1", ":", "\n", "            ", "if", "self", ".", "sequential", ":", "\n", "                ", "arr", "=", "arr", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "arr", "=", "arr", ".", "cuda", "(", "device", ")", "\n", "if", "self", ".", "include_lengths", ":", "\n", "                ", "lengths", "=", "lengths", ".", "cuda", "(", "device", ")", "\n", "", "", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", ",", "lengths", "\n", "", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.process": [[533, 552], ["range", "TextDataset.NliField.pad", "TextDataset.NliField.numericalize", "ret.append", "[].strip().split", "[].strip"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.pad", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.numericalize"], ["    ", "def", "process", "(", "self", ",", "batch", ",", "device", ",", "train", ")", ":", "\n", "        ", "\"\"\" Process a list of examples to create a torch.Tensor.\n\n        Pad, numericalize, and postprocess a batch and create a tensor.\n\n        Args:\n            batch (list(object)): A list of object from a batch of examples.\n        Returns:\n            data (torch.autograd.Varaible): Processed object given the input\n                and custom postprocessing Pipeline.\n        \"\"\"", "\n", "nli_count", "=", "3", "\n", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nli_count", ")", ":", "\n", "            ", "nli", "=", "[", "(", "' '", ".", "join", "(", "sample", ")", ")", ".", "strip", "(", ")", ".", "split", "(", "'</s>'", ")", "[", "i", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "sample", "in", "batch", "]", "\n", "padded", "=", "self", ".", "pad", "(", "nli", ")", "\n", "nli_tensor", "=", "self", ".", "numericalize", "(", "padded", ",", "i", ",", "device", "=", "device", ",", "train", "=", "train", ")", "\n", "ret", ".", "append", "(", "nli_tensor", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.pad": [[553, 580], ["list", "max", "lengths.append", "padded.append", "padded.append", "len", "len", "max", "list", "max", "len", "list", "max", "len", "len"], "methods", ["None"], ["", "def", "pad", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "minibatch", "=", "list", "(", "minibatch", ")", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "            ", "return", "minibatch", "\n", "", "if", "self", ".", "fix_length", "is", "None", ":", "\n", "            ", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "minibatch", ")", "\n", "", "else", ":", "\n", "            ", "max_len", "=", "self", ".", "fix_length", "+", "(", "\n", "self", ".", "init_token", ",", "self", ".", "eos_token", ")", ".", "count", "(", "None", ")", "-", "2", "\n", "", "padded", ",", "lengths", "=", "[", "]", ",", "[", "]", "\n", "for", "x", "in", "minibatch", ":", "\n", "            ", "if", "self", ".", "pad_first", ":", "\n", "                ", "padded", ".", "append", "(", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "padded", ".", "append", "(", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", "+", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "lengths", ".", "append", "(", "len", "(", "padded", "[", "-", "1", "]", ")", "-", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "(", "padded", ",", "lengths", ")", "\n", "", "return", "padded", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.NliField.numericalize": [[581, 654], ["isinstance", "TextDataset.NliField.tensor_type", "torch.nn.functional.Variable", "ValueError", "torch.LongTensor", "TextDataset.NliField.t_", "TextDataset.NliField.cuda", "isinstance", "ValueError", "TextDataset.NliField.postprocessing", "TextDataset.NliField.contiguous", "lengths.cuda.cuda.cuda", "torch.nn.functional.Variable", "TextDataset.NliField.postprocessing", "isinstance", "numericalization_func"], "methods", ["None"], ["", "def", "numericalize", "(", "self", ",", "arr", ",", "nli_count", ",", "device", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "            ", "arr", ",", "lengths", "=", "arr", "\n", "lengths", "=", "torch", ".", "LongTensor", "(", "lengths", ")", "\n", "\n", "", "if", "self", ".", "use_vocab", ":", "\n", "            ", "if", "nli_count", "==", "2", ":", "\n", "                ", "tmp", "=", "[", "]", "\n", "if", "self", ".", "sequential", ":", "\n", "                    ", "for", "ex", "in", "arr", ":", "\n", "                        ", "for", "x", "in", "ex", ":", "\n", "                            ", "if", "x", "==", "\"negative\"", ":", "\n", "                                ", "tmp", "+=", "[", "[", "1", ",", "0", ",", "0", "]", "]", "\n", "", "elif", "x", "==", "\"neutral\"", ":", "\n", "                                ", "tmp", "+=", "[", "[", "0", ",", "1", ",", "0", "]", "]", "\n", "", "elif", "x", "==", "\"positive\"", ":", "\n", "                                ", "tmp", "+=", "[", "[", "0", ",", "0", ",", "1", "]", "]", "\n", "", "else", ":", "\n", "                                ", "tmp", "+=", "[", "[", "0", ",", "0", ",", "0", "]", "]", "\n", "", "", "", "arr", "=", "tmp", "\n", "", "else", ":", "\n", "                    ", "for", "x", "in", "arr", ":", "\n", "                        ", "if", "x", "==", "\"negative\"", ":", "\n", "                            ", "tmp", "+=", "[", "[", "1", ",", "0", ",", "0", "]", "]", "\n", "", "elif", "x", "==", "\"neutral\"", ":", "\n", "                            ", "tmp", "+=", "[", "[", "0", ",", "1", ",", "0", "]", "]", "\n", "", "elif", "x", "==", "\"positive\"", ":", "\n", "                            ", "tmp", "+=", "[", "[", "0", ",", "0", ",", "1", "]", "]", "\n", "", "else", ":", "\n", "                            ", "tmp", "+=", "[", "[", "0", ",", "0", ",", "0", "]", "]", "\n", "", "", "arr", "=", "tmp", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "sequential", ":", "\n", "                    ", "arr", "=", "[", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "ex", "]", "for", "ex", "in", "arr", "]", "\n", "", "else", ":", "\n", "                    ", "arr", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "arr", "]", "\n", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "                    ", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "self", ".", "vocab", ",", "train", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "self", ".", "tensor_type", "not", "in", "self", ".", "tensor_types", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Specified Field tensor_type {} can not be used with \"", "\n", "\"use_vocab=False because we do not know how to numericalize it. \"", "\n", "\"Please raise an issue at \"", "\n", "\"https://github.com/pytorch/text/issues\"", ".", "format", "(", "self", ".", "tensor_type", ")", ")", "\n", "", "numericalization_func", "=", "self", ".", "tensor_types", "[", "self", ".", "tensor_type", "]", "\n", "# It doesn't make sense to explictly coerce to a numeric type if", "\n", "# the data is sequential, since it's unclear how to coerce padding tokens", "\n", "# to a numeric type.", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "                ", "arr", "=", "[", "numericalization_func", "(", "x", ")", "if", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "\n", "else", "x", "for", "x", "in", "arr", "]", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "                ", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "None", ",", "train", ")", "\n", "\n", "", "", "arr", "=", "self", ".", "tensor_type", "(", "arr", ")", "\n", "if", "self", ".", "sequential", "and", "not", "self", ".", "batch_first", ":", "\n", "            ", "arr", ".", "t_", "(", ")", "\n", "", "if", "device", "==", "-", "1", ":", "\n", "            ", "if", "self", ".", "sequential", ":", "\n", "                ", "arr", "=", "arr", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "arr", "=", "arr", ".", "cuda", "(", "device", ")", "\n", "if", "self", ".", "include_lengths", ":", "\n", "                ", "lengths", "=", "lengths", ".", "cuda", "(", "device", ")", "\n", "", "", "if", "self", ".", "include_lengths", ":", "\n", "            ", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", ",", "lengths", "\n", "", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.OrderedIterator.create_batches": [[338, 349], ["torchtext.data.pool", "torchtext.data.pool", "torchtext.data.pool", "torchtext.data.pool", "torchtext.data.batch", "torchtext.data.batch", "torchtext.data.batch", "torchtext.data.batch", "IO.OrderedIterator.data", "IO.OrderedIterator.data", "IO.OrderedIterator.batches.append", "sorted"], "methods", ["None"], ["    ", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "self", ".", "batches", "=", "torchtext", ".", "data", ".", "pool", "(", "\n", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "sort_key", ",", "self", ".", "batch_size_fn", ",", "\n", "random_shuffler", "=", "self", ".", "random_shuffler", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "torchtext", ".", "data", ".", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "batch_size_fn", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._getstate": [[16, 18], ["dict", "dict"], "function", ["None"], ["def", "_getstate", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "self", ".", "__dict__", ",", "stoi", "=", "dict", "(", "self", ".", "stoi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._setstate": [[20, 23], ["IO..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "_setstate", "(", "self", ",", "state", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.get_fields": [[29, 48], ["onmt.io.TextDataset.TextDataset.get_fields", "onmt.io.ImageDataset.ImageDataset.get_fields", "onmt.io.AudioDataset.AudioDataset.get_fields"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields"], ["def", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type: type of the source input. Options are [text|img|audio].\n        n_src_features: the number of source features to\n            create `torchtext.data.Field` for.\n        n_tgt_features: the number of target features to\n            create `torchtext.data.Field` for.\n\n    Returns:\n        A dictionary whose keys are strings and whose values are the\n        corresponding Field objects.\n    \"\"\"", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "TextDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab": [[50, 63], ["dict", "len", "len", "IO.get_fields", "dict.items", "IO.collect_features", "IO.collect_features", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features"], ["", "", "def", "load_fields_from_vocab", "(", "vocab", ",", "data_type", "=", "\"text\"", ")", ":", "\n", "    ", "\"\"\"\n    Load Field objects from `vocab.pt` file.\n    \"\"\"", "\n", "vocab", "=", "dict", "(", "vocab", ")", "\n", "n_src_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'src'", ")", ")", "\n", "n_tgt_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'tgt'", ")", ")", "\n", "fields", "=", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", "\n", "for", "k", ",", "v", "in", "vocab", ".", "items", "(", ")", ":", "\n", "# Hack. Can't pickle defaultdict :(", "\n", "        ", "v", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "v", ".", "stoi", ")", "\n", "fields", "[", "k", "]", ".", "vocab", "=", "v", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab": [[65, 75], ["fields.items", "dict", "vocab.append"], "function", ["None"], ["", "def", "save_fields_to_vocab", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Save Vocab objects in Field objects to `vocab.pt` file.\n    \"\"\"", "\n", "vocab", "=", "[", "]", "\n", "for", "k", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n", "        ", "if", "f", "is", "not", "None", "and", "'vocab'", "in", "f", ".", "__dict__", ":", "\n", "            ", "f", ".", "vocab", ".", "stoi", "=", "dict", "(", "f", ".", "vocab", ".", "stoi", ")", "\n", "vocab", ".", "append", "(", "(", "k", ",", "f", ".", "vocab", ")", ")", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.merge_vocabs": [[77, 92], ["sum", "torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "collections.Counter"], "function", ["None"], ["", "def", "merge_vocabs", "(", "vocabs", ",", "vocab_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Merge individual vocabularies (assumed to be generated from disjoint\n    documents) into a larger vocabulary.\n\n    Args:\n        vocabs: `torchtext.vocab.Vocab` vocabularies to be merged\n        vocab_size: `int` the final vocabulary size. `None` for no limit.\n    Return:\n        `torchtext.vocab.Vocab`\n    \"\"\"", "\n", "merged", "=", "sum", "(", "[", "vocab", ".", "freqs", "for", "vocab", "in", "vocabs", "]", ",", "Counter", "(", ")", ")", "\n", "return", "torchtext", ".", "vocab", ".", "Vocab", "(", "merged", ",", "\n", "specials", "=", "[", "PAD_WORD", ",", "BOS_WORD", ",", "EOS_WORD", "]", ",", "\n", "max_size", "=", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.get_num_features": [[94, 113], ["onmt.io.TextDataset.TextDataset.get_num_features", "onmt.io.ImageDataset.ImageDataset.get_num_features", "onmt.io.AudioDataset.AudioDataset.get_num_features"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features"], ["", "def", "get_num_features", "(", "data_type", ",", "corpus_file", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n        corpus_file (str): file path to get the features.\n        side (str): for source or for target.\n\n    Returns:\n        number of features on `side`.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "TextDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.make_features": [[115, 141], ["isinstance", "sorted", "torch.cat", "level.unsqueeze"], "function", ["None"], ["", "", "def", "make_features", "(", "batch", ",", "side", ",", "data_type", "=", "'text'", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        batch (Variable): a batch of source or target data.\n        side (str): for source or for target.\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n    Returns:\n        A sequence of src/tgt tensors with optional feature tensors\n        of size (len x batch).\n    \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n", "if", "isinstance", "(", "batch", ".", "__dict__", "[", "side", "]", ",", "tuple", ")", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "\n", "\n", "", "feat_start", "=", "side", "+", "\"_feat_\"", "\n", "keys", "=", "sorted", "(", "[", "k", "for", "k", "in", "batch", ".", "__dict__", "if", "feat_start", "in", "k", "]", ")", "\n", "features", "=", "[", "batch", ".", "__dict__", "[", "k", "]", "for", "k", "in", "keys", "]", "\n", "levels", "=", "[", "data", "]", "+", "features", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "level", ".", "unsqueeze", "(", "2", ")", "for", "level", "in", "levels", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "        ", "return", "levels", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features": [[143, 155], ["itertools.count", "feats.append", "str"], "function", ["None"], ["", "", "def", "collect_features", "(", "fields", ",", "side", "=", "\"src\"", ")", ":", "\n", "    ", "\"\"\"\n    Collect features from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n", "feats", "=", "[", "]", "\n", "for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feats", ".", "append", "(", "key", ")", "\n", "", "return", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_feature_vocabs": [[157, 169], ["itertools.count", "feature_vocabs.append", "str"], "function", ["None"], ["", "def", "collect_feature_vocabs", "(", "fields", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Collect feature Vocab objects from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n", "feature_vocabs", "=", "[", "]", "\n", "for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feature_vocabs", ".", "append", "(", "fields", "[", "key", "]", ".", "vocab", ")", "\n", "", "return", "feature_vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset": [[171, 225], ["IO._make_examples_nfeats_tpl", "onmt.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "onmt.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "onmt.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "onmt.io.TextDataset.TextDataset", "onmt.io.ImageDataset.ImageDataset", "onmt.io.AudioDataset.AudioDataset"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._make_examples_nfeats_tpl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl"], ["", "def", "build_dataset", "(", "fields", ",", "data_type", ",", "src_path", ",", "tgt_path", ",", "per_path", ",", "nli_path", ",", "src_dir", "=", "None", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "\n", "src_seq_length_trunc", "=", "0", ",", "tgt_seq_length_trunc", "=", "0", ",", "per_seq_length_trunc", "=", "0", ",", "nli_seq_length_trunc", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0", ",", "window_stride", "=", "0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "\n", "# Build src/tgt examples iterator from corpus files, also extract", "\n", "# number of features.", "\n", "    ", "src_examples_iter", ",", "num_src_feats", "=", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ")", "\n", "\n", "# For all data types, the tgt side corpus is in form of text.", "\n", "tgt_examples_iter", ",", "num_tgt_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "tgt_path", ",", "tgt_seq_length_trunc", ",", "\"tgt\"", ")", "\n", "\n", "per_examples_iter", ",", "num_per_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "per_path", ",", "per_seq_length_trunc", ",", "\"per\"", ")", "\n", "\n", "nli_examples_iter", ",", "num_nli_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "nli_path", ",", "nli_seq_length_trunc", ",", "\"nli\"", ")", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "dataset", "=", "TextDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "per_examples_iter", ",", "nli_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "src_seq_length", "=", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "dynamic_dict", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "dataset", "=", "ImageDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "dataset", "=", "AudioDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "window_size", "=", "window_size", ",", "\n", "window_stride", "=", "window_stride", ",", "\n", "window", "=", "window", ",", "\n", "normalize_audio", "=", "normalize_audio", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._build_field_vocab": [[227, 233], ["list", "field.vocab_cls", "collections.OrderedDict.fromkeys"], "function", ["None"], ["", "def", "_build_field_vocab", "(", "field", ",", "counter", ",", "**", "kwargs", ")", ":", "\n", "    ", "specials", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "\n", "tok", "for", "tok", "in", "[", "field", ".", "unk_token", ",", "field", ".", "pad_token", ",", "field", ".", "init_token", ",", "\n", "field", ".", "eos_token", "]", "\n", "if", "tok", "is", "not", "None", ")", ")", "\n", "field", ".", "vocab", "=", "field", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_vocab": [[235, 306], ["IO._build_field_vocab", "print", "range", "collections.Counter", "torch.load", "print", "IO._build_field_vocab", "print", "IO._build_field_vocab", "print", "range", "len", "str", "IO._build_field_vocab", "print", "print", "IO.merge_vocabs", "getattr", "counter[].update", "len", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._build_field_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._build_field_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._build_field_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._build_field_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.merge_vocabs", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.update"], ["", "def", "build_vocab", "(", "train_dataset_files", ",", "fields", ",", "data_type", ",", "share_vocab", ",", "\n", "src_vocab_size", ",", "src_words_min_frequency", ",", "\n", "tgt_vocab_size", ",", "tgt_words_min_frequency", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        train_dataset_files: a list of train dataset pt file.\n        fields (dict): fields to build vocab for.\n        data_type: \"text\", \"img\" or \"audio\"?\n        share_vocab(bool): share source and target vocabulary?\n        src_vocab_size(int): size of the source vocabulary.\n        src_words_min_frequency(int): the minimum frequency needed to\n                include a source word in the vocabulary.\n        tgt_vocab_size(int): size of the target vocabulary.\n        tgt_words_min_frequency(int): the minimum frequency needed to\n                include a target word in the vocabulary.\n\n    Returns:\n        Dict of Fields\n    \"\"\"", "\n", "counter", "=", "{", "}", "\n", "for", "k", "in", "fields", ":", "\n", "        ", "counter", "[", "k", "]", "=", "Counter", "(", ")", "\n", "\n", "", "for", "path", "in", "train_dataset_files", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "print", "(", "\" * reloading %s\"", "%", "path", ")", "\n", "for", "ex", "in", "dataset", ".", "examples", ":", "\n", "            ", "for", "k", "in", "fields", ":", "\n", "                ", "val", "=", "getattr", "(", "ex", ",", "k", ",", "None", ")", "\n", "if", "val", "is", "not", "None", "and", "not", "fields", "[", "k", "]", ".", "sequential", ":", "\n", "                    ", "val", "=", "[", "val", "]", "\n", "", "counter", "[", "k", "]", ".", "update", "(", "val", ")", "\n", "\n", "", "", "", "_build_field_vocab", "(", "fields", "[", "\"tgt\"", "]", ",", "counter", "[", "\"tgt\"", "]", ",", "\n", "max_size", "=", "tgt_vocab_size", ",", "\n", "min_freq", "=", "tgt_words_min_frequency", ")", "\n", "print", "(", "\" * tgt vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_tgt_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_tgt_feats", ")", ":", "\n", "        ", "key", "=", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "print", "(", "\" * %s vocab size: %d.\"", "%", "(", "key", ",", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "if", "data_type", "==", "'text'", ":", "\n", "        ", "_build_field_vocab", "(", "fields", "[", "\"src\"", "]", ",", "counter", "[", "\"src\"", "]", ",", "\n", "max_size", "=", "src_vocab_size", ",", "\n", "min_freq", "=", "src_words_min_frequency", ")", "\n", "print", "(", "\" * src vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"src\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_src_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_src_feats", ")", ":", "\n", "            ", "key", "=", "\"src_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "print", "(", "\" * %s vocab size: %d.\"", "%", "(", "key", ",", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "# Merge the input and output vocabularies.", "\n", "", "if", "share_vocab", ":", "\n", "# `tgt_vocab_size` is ignored when sharing vocabularies", "\n", "            ", "print", "(", "\" * merging src and tgt vocab...\"", ")", "\n", "merged_vocab", "=", "merge_vocabs", "(", "\n", "[", "fields", "[", "\"src\"", "]", ".", "vocab", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", "]", ",", "\n", "vocab_size", "=", "src_vocab_size", ")", "\n", "fields", "[", "\"src\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "fields", "[", "\"per\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "fields", "[", "\"nli\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "\n", "", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO._make_examples_nfeats_tpl": [[308, 335], ["onmt.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "onmt.io.ImageDataset.ImageDataset.make_image_examples_nfeats_tpl", "onmt.io.AudioDataset.AudioDataset.make_audio_examples_nfeats_tpl"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.TextDataset.make_text_examples_nfeats_tpl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.make_image_examples_nfeats_tpl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.make_audio_examples_nfeats_tpl"], ["", "def", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ")", ":", "\n", "    ", "\"\"\"\n    Process the corpus into (example_dict iterator, num_feats) tuple\n    on source side for different 'data_type'.\n    \"\"\"", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "src_examples_iter", ",", "num_src_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "src_path", ",", "src_seq_length_trunc", ",", "\"src\"", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "src_examples_iter", ",", "num_src_feats", "=", "ImageDataset", ".", "make_image_examples_nfeats_tpl", "(", "\n", "src_path", ",", "src_dir", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "src_examples_iter", ",", "num_src_feats", "=", "AudioDataset", ".", "make_audio_examples_nfeats_tpl", "(", "\n", "src_path", ",", "src_dir", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ")", "\n", "\n", "", "return", "src_examples_iter", ",", "num_src_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.__init__": [[36, 83], ["AudioDataset.AudioDataset._peek", "ex.keys", "list", "onmt.io.DatasetBase.ONMTDatasetBase.__init__", "AudioDataset.AudioDataset._construct_example_fromlist", "AudioDataset.AudioDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._peek", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0.0", ",", "window_stride", "=", "0.0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'audio'", "\n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "AudioDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.sort_key": [[85, 88], ["ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using duration time of the sound spectrogram. \"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.make_audio_examples_nfeats_tpl": [[89, 116], ["AudioDataset.read_audio_file"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.read_audio_file"], ["", "@", "staticmethod", "\n", "def", "make_audio_examples_nfeats_tpl", "(", "path", ",", "audio_dir", ",", "\n", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            audio_dir (str): location of source audio files.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "examples_iter", "=", "AudioDataset", ".", "read_audio_file", "(", "\n", "path", ",", "audio_dir", ",", "\"src\"", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", ")", "\n", "num_feats", "=", "0", "# Source side(audio) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.read_audio_file": [[117, 192], ["os.path.exists", "codecs.open", "os.path.join", "os.path.exists", "torchaudio.load", "sound.mean.mean.numpy", "int", "int", "librosa.stft", "librosa.magphase", "np.log1p", "torch.FloatTensor", "line.strip", "os.path.exists", "line.strip", "len", "torch.FloatTensor.mean", "torch.FloatTensor.std", "torch.FloatTensor.add_", "torch.FloatTensor.div_", "line.strip", "sound.mean.mean.size", "sound.mean.mean.squeeze", "sound.mean.mean.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "read_audio_file", "(", "path", ",", "src_dir", ",", "side", ",", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "normalize_audio", ",", "\n", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            src_dir (str): location of source audio files.\n            side (str): 'src' or 'tgt'.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Yields:\n            a dictionary containing audio data for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "\"src_dir must be a valid directory if data_type is audio\"", "\n", "\n", "global", "torchaudio", ",", "librosa", ",", "np", "\n", "import", "torchaudio", "\n", "import", "librosa", "\n", "import", "numpy", "as", "np", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "index", "=", "0", "\n", "for", "line", "in", "corpus_file", ":", "\n", "                ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "line", ".", "strip", "(", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ":", "\n", "                    ", "audio_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ",", "'audio path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "sound", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "audio_path", ")", "\n", "if", "truncate", "and", "truncate", ">", "0", ":", "\n", "                    ", "if", "sound", ".", "size", "(", "0", ")", ">", "truncate", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "assert", "sample_rate", "==", "sample_rate", ",", "'Sample rate of %s != -sample_rate (%d vs %d)'", "%", "(", "audio_path", ",", "sample_rate", ",", "sample_rate", ")", "\n", "\n", "sound", "=", "sound", ".", "numpy", "(", ")", "\n", "if", "len", "(", "sound", ".", "shape", ")", ">", "1", ":", "\n", "                    ", "if", "sound", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "                        ", "sound", "=", "sound", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sound", "=", "sound", ".", "mean", "(", "axis", "=", "1", ")", "# average multiple channels", "\n", "\n", "", "", "n_fft", "=", "int", "(", "sample_rate", "*", "window_size", ")", "\n", "win_length", "=", "n_fft", "\n", "hop_length", "=", "int", "(", "sample_rate", "*", "window_stride", ")", "\n", "# STFT", "\n", "d", "=", "librosa", ".", "stft", "(", "sound", ",", "n_fft", "=", "n_fft", ",", "hop_length", "=", "hop_length", ",", "\n", "win_length", "=", "win_length", ",", "window", "=", "window", ")", "\n", "spect", ",", "_", "=", "librosa", ".", "magphase", "(", "d", ")", "\n", "spect", "=", "np", ".", "log1p", "(", "spect", ")", "\n", "spect", "=", "torch", ".", "FloatTensor", "(", "spect", ")", "\n", "if", "normalize_audio", ":", "\n", "                    ", "mean", "=", "spect", ".", "mean", "(", ")", "\n", "std", "=", "spect", ".", "std", "(", ")", "\n", "spect", ".", "add_", "(", "-", "mean", ")", "\n", "spect", ".", "div_", "(", "std", ")", "\n", "\n", "", "example_dict", "=", "{", "side", ":", "spect", ",", "\n", "side", "+", "'_path'", ":", "line", ".", "strip", "(", ")", ",", "\n", "'indices'", ":", "index", "}", "\n", "index", "+=", "1", "\n", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.get_fields": [[193, 262], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "torch.zeros", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "len", "max", "len", "enumerate", "max.size", "max.size", "max.size", "torch.zeros", "str", "str", "max.max", "len", "spect.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_audio", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "nfft", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "t", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "sounds", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "1", ",", "nfft", ",", "t", ")", "\n", "for", "i", ",", "spect", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "sounds", "[", "i", ",", ":", ",", ":", ",", "0", ":", "spect", ".", "size", "(", "1", ")", "]", "=", "spect", "\n", "", "return", "sounds", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "FloatTensor", ",", "\n", "postprocessing", "=", "make_audio", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "FloatTensor", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.AudioDataset.AudioDataset.get_num_features": [[263, 285], ["codecs.open", "cf.readline().strip().split", "AudioDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For audio corpus, source side is in form of audio, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "AudioDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.__init__": [[30, 69], ["ImageDataset.ImageDataset._peek", "ex.keys", "list", "onmt.io.DatasetBase.ONMTDatasetBase.__init__", "ImageDataset.ImageDataset._construct_example_fromlist", "ImageDataset.ImageDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._peek", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'img'", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "ImageDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.sort_key": [[71, 74], ["ex.src.size", "ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using the size of the image: (width, height).\"\"\"", "\n", "return", "(", "ex", ".", "src", ".", "size", "(", "2", ")", ",", "ex", ".", "src", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.make_image_examples_nfeats_tpl": [[75, 89], ["ImageDataset.read_img_file"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.read_img_file"], ["", "@", "staticmethod", "\n", "def", "make_image_examples_nfeats_tpl", "(", "path", ",", "img_dir", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing image paths\n            src_dir (str): location of source images\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "examples_iter", "=", "ImageDataset", ".", "read_img_file", "(", "path", ",", "img_dir", ",", "'src'", ")", "\n", "num_feats", "=", "0", "# Source side(img) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.read_img_file": [[90, 131], ["os.path.exists", "codecs.open", "os.path.join", "os.path.exists", "line.strip", "os.path.exists", "line.strip", "transforms.ToTensor", "Image.open", "line.strip", "img.size", "img.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "read_img_file", "(", "path", ",", "src_dir", ",", "side", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing image paths\n            src_dir (str): location of source images\n            side (str): 'src' or 'tgt'\n            truncate: maximum img size ((0,0) or None for unlimited)\n\n        Yields:\n            a dictionary containing image data, path and index for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "'src_dir must be a valid directory if data_type is img'", "\n", "\n", "global", "Image", ",", "transforms", "\n", "from", "PIL", "import", "Image", "\n", "from", "torchvision", "import", "transforms", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "index", "=", "0", "\n", "for", "line", "in", "corpus_file", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "line", ".", "strip", "(", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                    ", "img_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "img_path", ")", ",", "'img path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "Image", ".", "open", "(", "img_path", ")", ")", "\n", "if", "truncate", "and", "truncate", "!=", "(", "0", ",", "0", ")", ":", "\n", "                    ", "if", "not", "(", "img", ".", "size", "(", "1", ")", "<=", "truncate", "[", "0", "]", "\n", "and", "img", ".", "size", "(", "2", ")", "<=", "truncate", "[", "1", "]", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "example_dict", "=", "{", "side", ":", "img", ",", "\n", "side", "+", "'_path'", ":", "line", ".", "strip", "(", ")", ",", "\n", "'indices'", ":", "index", "}", "\n", "index", "+=", "1", "\n", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields": [[132, 202], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "max", "torch.zeros", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "len", "max", "len", "enumerate", "t.size", "t.size", "t.size", "t.size", "torch.zeros", "str", "str", "t.max", "len", "img.size", "img.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_img", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "c", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "h", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "w", "=", "max", "(", "[", "t", ".", "size", "(", "2", ")", "for", "t", "in", "data", "]", ")", "\n", "imgs", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "c", ",", "h", ",", "w", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "imgs", "[", "i", ",", ":", ",", "0", ":", "img", ".", "size", "(", "1", ")", ",", "0", ":", "img", ".", "size", "(", "2", ")", "]", "=", "img", "\n", "", "return", "imgs", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "FloatTensor", ",", "\n", "postprocessing", "=", "make_img", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "FloatTensor", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ",", "is_train", ")", ":", "\n", "            ", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features": [[203, 225], ["codecs.open", "cf.readline().strip().split", "ImageDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.DatasetBase.ONMTDatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For image corpus, source side is in form of image, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "ImageDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpFormatter._format_usage": [[502, 504], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpFormatter.format_help": [[505, 509], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpFormatter.start_section": [[510, 513], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpFormatter._format_action": [[514, 526], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpAction.__init__": [[529, 538], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.MarkdownHelpAction.__call__": [[539, 543], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.DeprecateAction.__init__": [[546, 549], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.DeprecateAction.__call__": [[550, 554], ["argparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "argparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.model_opts": [[5, 115], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Deocder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "group", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "\n", "# Genenerator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.preprocess_opts": [[117, 217], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Data options", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training nli data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation nli data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes.\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "\n", "help", "=", "\"Path to an existing source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "\n", "help", "=", "\"Path to an existing target vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum persona sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate persona sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum nli sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate nli sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.train_opts": [[219, 386], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_epochN_PPL.pt where PPL is the\n                       validation perplexity\"\"\"", ")", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                           path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "group", ".", "add_argument", "(", "'-g_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-g_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                           Recommended settings: sgd = 1, adagrad = 0.1,\n                           adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                               Recommended settings: sgd = 1, adagrad = 0.1,\n                               adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) epoch has gone past\n                       start_decay_at\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this\n                       epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including\n                       this epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.translate_opts": [[388, 479], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Persona sentence to use (one line per\n                           personas, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"nli sentence to use (one line per\n                           nlis, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.opts.add_md_help_argument": [[481, 484], ["parser.add_argument"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.DatasetLazyIter.__init__": [[114, 126], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.DatasetLazyIter.__iter__": [[127, 133], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n", "while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.DatasetLazyIter.__len__": [[134, 140], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.DatasetLazyIter.get_cur_dataset": [[141, 143], ["None"], "methods", ["None"], ["", "def", "get_cur_dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.DatasetLazyIter._next_dataset_iterator": [[144, 161], ["onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "next"], "methods", ["None"], ["", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n", "# We clear `fields` when saving, restore when loading.", "\n", "", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "onmt", ".", "io", ".", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.report_func": [[76, 100], ["onmt.Statistics.output", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics.log"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.output", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "report_func", "(", "epoch", ",", "batch", ",", "num_batches", ",", "\n", "start_time", ",", "lr", ",", "report_stats", ",", "report_flag", ")", ":", "\n", "    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "# if batch % opt.report_every == -1 % opt.report_every:", "\n", "if", "report_flag", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "report_stats", ".", "log", "(", "\"progress\"", ",", "experiment", ",", "lr", ")", "\n", "", "report_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.make_dataset_iter": [[163, 180], ["train.DatasetLazyIter", "max", "len", "len"], "function", ["None"], ["", "", "def", "make_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over during each train epoch. We implement simple\n    ordered iterator strategy here, but more sophisticated strategy\n    like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "batch_size_fn", "=", "None", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "sofar", "+", "max", "(", "len", "(", "new", ".", "tgt", ")", ",", "len", "(", "new", ".", "src", ")", ")", "+", "1", "\n", "\n", "", "", "device", "=", "opt", ".", "gpuid", "[", "0", "]", "if", "opt", ".", "gpuid", "else", "-", "1", "\n", "\n", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.make_loss_compute": [[182, 200], ["onmt.Utils.use_gpu", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute.cuda"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "def", "make_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "onmt", ".", "Loss", ".", "NMTLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "\n", "label_smoothing", "=", "opt", ".", "label_smoothing", ")", "\n", "\n", "", "if", "use_gpu", "(", "opt", ")", ":", "\n", "        ", "compute", ".", "cuda", "(", ")", "\n", "\n", "", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.train_model": [[202, 244], ["train.make_loss_compute", "train.make_loss_compute", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "range", "print", "train.lazily_load_dataset", "train.make_dataset_iter", "onmt.Trainer.train", "print", "print", "train.make_dataset_iter", "onmt.Trainer.validate", "print", "print", "onmt.Trainer.epoch_step", "train.lazily_load_dataset", "trainer.train.log", "trainer.validate.log", "trainer.validate.ppl", "onmt.Trainer.drop_checkpoint", "trainer.train.ppl", "trainer.train.accuracy", "trainer.validate.ppl", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy"], ["", "def", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", ":", "\n", "\n", "    ", "train_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "disc", ",", "nli", ",", "train_loss", ",", "valid_loss", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "\n", "trunc_size", ",", "shard_size", ",", "data_type", ",", "\n", "opt", ".", "normalization", ",", "opt", ".", "accum_count", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "train_iter", "=", "make_dataset_iter", "(", "train_datasets", ",", "fields", ",", "opt", ")", "\n", "train_stats", "=", "trainer", ".", "train", "(", "train_iter", ",", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_iter", "=", "make_dataset_iter", "(", "lazily_load_dataset", "(", "\"valid\"", ")", ",", "\n", "fields", ",", "opt", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", "valid_iter", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "train_stats", ".", "log", "(", "\"train\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "valid_stats", ".", "log", "(", "\"valid\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "\n", "# 4. Update the learning rate", "\n", "", "trainer", ".", "epoch_step", "(", "valid_stats", ".", "ppl", "(", ")", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "model_opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.check_save_model_path": [[246, 251], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "", "def", "check_save_model_path", "(", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.tally_parameters": [[253, 265], ["sum", "print", "model.named_parameters", "print", "print", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "print", "(", "'encoder: '", ",", "enc", ")", "\n", "print", "(", "'decoder: '", ",", "dec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.lazily_load_dataset": [[267, 294], ["sorted", "torch.load", "torch.load", "print", "glob.glob", "train.lazily_load_dataset.lazy_dataset_loader"], "function", ["None"], ["", "def", "lazily_load_dataset", "(", "corpus_type", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "print", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "return", "dataset", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one onmt.io.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.load_fields": [[296, 317], ["onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "dict", "torch.load", "torch.load", "print", "print", "dict.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab"], ["", "", "def", "load_fields", "(", "dataset", ",", "data_type", ",", "checkpoint", ")", ":", "\n", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "load_fields_from_vocab", "(", "\n", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", ",", "data_type", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "dataset", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "fields", "[", "'per'", "]", ".", "vocab", "=", "fields", "[", "'tgt'", "]", ".", "vocab", "\n", "\n", "# if checkpoint is not None:", "\n", "#     print('Loading vocab from checkpoint at %s.' % opt.train_from)", "\n", "#     fields = onmt.io.load_fields_from_vocab(", "\n", "#                 checkpoint['vocab'], data_type)", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'src'", "]", ".", "vocab", ")", ",", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "' * vocabulary size. target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.collect_report_features": [[319, 327], ["onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "enumerate", "enumerate", "print", "print", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features"], ["", "def", "collect_report_features", "(", "fields", ")", ":", "\n", "    ", "src_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'src'", ")", "\n", "tgt_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'tgt'", ")", "\n", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "print", "(", "' * src feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "print", "(", "' * tgt feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.build_model": [[329, 339], ["print", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "print", "onmt.Utils.use_gpu", "len", "print", "torch.DataParallel"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", ":", "\n", "    ", "print", "(", "'Building model...'", ")", "\n", "model", ",", "disc", ",", "nli", "=", "onmt", ".", "ModelConstructor", ".", "make_base_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "print", "(", "'Multi gpu training: '", ",", "opt", ".", "gpuid", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "opt", ".", "gpuid", ",", "dim", "=", "1", ")", "\n", "", "print", "(", "model", ")", "\n", "\n", "return", "model", ",", "disc", ",", "nli", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.build_optim": [[341, 362], ["onmt.Optim.set_parameters", "print", "onmt.Optim.optimizer.load_state_dict", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.set_parameters"], ["", "def", "build_optim", "(", "model", ",", "checkpoint", ",", "type", ",", "optim", ",", "learning_rate", ")", ":", "\n", "    ", "if", "opt", ".", "train_from", "and", "checkpoint", "and", "False", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "type", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "type", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "onmt", ".", "Optim", "(", "\n", "optim", ",", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.D_pretrain.train.main": [[364, 411], ["print", "train.lazily_load_dataset", "print", "next", "itertools.chain", "train.load_fields", "train.collect_report_features", "train.build_model", "train.tally_parameters", "train.check_save_model_path", "train.build_optim", "train.build_optim", "train.build_optim", "train.train_model", "print", "torch.load", "torch.load", "torch.load", "torch.load"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.load_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.collect_report_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.tally_parameters", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.check_save_model_path", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.train_model"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# Lazily load a list of train/validate dataset.", "\n", "    ", "print", "(", "\"Lazily loading train/validate datasets from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Peek the fisrt dataset to determine the data_type.", "\n", "# (This will load the first dataset.)", "\n", "first_dataset", "=", "next", "(", "train_datasets", ")", "\n", "train_datasets", "=", "chain", "(", "[", "first_dataset", "]", ",", "train_datasets", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear.", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "d_train_from", ":", "\n", "            ", "d_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "d_train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "first_dataset", ",", "data_type", ",", "checkpoint", ")", "\n", "\n", "# Report src/tgt features.", "\n", "collect_report_features", "(", "fields", ")", "\n", "\n", "# Build model.", "\n", "model", ",", "disc", ",", "nli", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "tally_parameters", "(", "model", ")", "\n", "check_save_model_path", "(", ")", "\n", "\n", "# Build optimizer.", "\n", "g_optim", "=", "build_optim", "(", "model", ",", "checkpoint", ",", "'g_optim'", ",", "opt", ".", "g_optim", ",", "opt", ".", "g_learning_rate", ")", "\n", "d_optim", "=", "build_optim", "(", "disc", ",", "checkpoint", ",", "'d_optim'", ",", "opt", ".", "d_optim", ",", "opt", ".", "d_learning_rate", ")", "\n", "nli_optim", "=", "build_optim", "(", "nli", ",", "checkpoint", ",", "'nli_optim'", ",", "opt", ".", "nli_optim", ",", "opt", ".", "nli_learning_rate", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpFormatter._format_usage": [[502, 504], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpFormatter.format_help": [[505, 509], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpFormatter.start_section": [[510, 513], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpFormatter._format_action": [[514, 526], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpAction.__init__": [[529, 538], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.MarkdownHelpAction.__call__": [[539, 543], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.DeprecateAction.__init__": [[546, 549], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.DeprecateAction.__call__": [[550, 554], ["argparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "argparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.model_opts": [[5, 115], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Deocder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "group", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "\n", "# Genenerator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.preprocess_opts": [[117, 217], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Data options", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training nli data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation nli data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes.\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "\n", "help", "=", "\"Path to an existing source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "\n", "help", "=", "\"Path to an existing target vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum persona sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate persona sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum nli sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate nli sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.train_opts": [[219, 386], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_epochN_PPL.pt where PPL is the\n                       validation perplexity\"\"\"", ")", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                           path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "group", ".", "add_argument", "(", "'-g_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-g_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                           Recommended settings: sgd = 1, adagrad = 0.1,\n                           adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                               Recommended settings: sgd = 1, adagrad = 0.1,\n                               adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) epoch has gone past\n                       start_decay_at\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this\n                       epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including\n                       this epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.translate_opts": [[388, 479], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Persona sentence to use (one line per\n                           personas, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"nli sentence to use (one line per\n                           nlis, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.opts.add_md_help_argument": [[481, 484], ["parser.add_argument"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_score": [[28, 32], ["print", "math.exp"], "function", ["None"], ["def", "_report_score", "(", "name", ",", "score_total", ",", "words_total", ")", ":", "\n", "    ", "print", "(", "\"%s AVG SCORE: %.4f, %s PPL: %.4f\"", "%", "(", "\n", "name", ",", "score_total", "/", "words_total", ",", "\n", "name", ",", "math", ".", "exp", "(", "-", "score_total", "/", "words_total", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_bleu": [[34, 41], ["print", "subprocess.check_output().decode", "print", "subprocess.check_output", "subprocess.check_output().decode.strip"], "function", ["None"], ["", "def", "_report_bleu", "(", ")", ":", "\n", "    ", "import", "subprocess", "\n", "print", "(", ")", "\n", "res", "=", "subprocess", ".", "check_output", "(", "\n", "\"perl tools/multi-bleu.perl %s < %s\"", "%", "(", "opt", ".", "tgt", ",", "opt", ".", "output", ")", ",", "\n", "shell", "=", "True", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "print", "(", "\">> \"", "+", "res", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_rouge": [[43, 49], ["subprocess.check_output().decode", "print", "subprocess.check_output().decode.strip", "subprocess.check_output"], "function", ["None"], ["", "def", "_report_rouge", "(", ")", ":", "\n", "    ", "import", "subprocess", "\n", "res", "=", "subprocess", ".", "check_output", "(", "\n", "\"python tools/test_rouge.py -r %s -c %s\"", "%", "(", "opt", ".", "tgt", ",", "opt", ".", "output", ")", ",", "\n", "shell", "=", "True", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "print", "(", "res", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict.main": [[51, 138], ["argparse.ArgumentParser", "opts.model_opts", "onmt.ModelConstructor.load_test_model", "onmt.ModelConstructor.load_test_model", "onmt.ModelConstructor.load_test_model", "onmt.ModelConstructor.load_test_model", "onmt.ModelConstructor.load_test_model", "codecs.open", "onmt.io.build_dataset", "onmt.io.build_dataset", "onmt.io.build_dataset", "onmt.io.build_dataset", "onmt.io.build_dataset", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.Translator", "onmt.translate.Translator", "onmt.translate.Translator", "onmt.translate.Translator", "onmt.translate.Translator", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "itertools.count", "predict._report_score", "argparse.ArgumentParser.parse_known_args", "torch.cuda.set_device", "onmt.translate.Translator.translate_batch", "onmt.translate.TranslationBuilder.from_batch", "predict._report_score", "json.dump", "len", "codecs.open.write", "codecs.open.write", "codecs.open.flush", "predict._report_bleu", "predict._report_rouge", "codecs.open", "len", "next", "trans.log", "os.write", "trans.log.encode"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.model_opts", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.load_test_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_score", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translator.Translator.translate_batch", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_score", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_bleu", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.predict._report_rouge", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.modules.Distriminitor.NLI.encode"], ["", "def", "main", "(", ")", ":", "\n", "    ", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "if", "opt", ".", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "# Load the model.", "\n", "", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "ModelConstructor", ".", "load_test_model", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "\n", "# File to write sentences to.", "\n", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w'", ",", "'utf-8'", ")", "\n", "\n", "# Test data", "\n", "data", "=", "onmt", ".", "io", ".", "build_dataset", "(", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "src", ",", "opt", ".", "tgt", ",", "opt", ".", "per", ",", "opt", ".", "nli", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ",", "\n", "use_filter_pred", "=", "False", ")", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "data_iter", "=", "onmt", ".", "io", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "opt", ".", "gpu", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "shuffle", "=", "False", ")", "\n", "\n", "# Translator", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", "(", "opt", ".", "alpha", ",", "opt", ".", "beta", ")", "\n", "translator", "=", "onmt", ".", "translate", ".", "Translator", "(", "model", ",", "fields", ",", "\n", "beam_size", "=", "opt", ".", "beam_size", ",", "\n", "n_best", "=", "opt", ".", "n_best", ",", "\n", "global_scorer", "=", "scorer", ",", "\n", "max_length", "=", "opt", ".", "max_length", ",", "\n", "copy_attn", "=", "model_opt", ".", "copy_attn", ",", "\n", "cuda", "=", "opt", ".", "cuda", ",", "\n", "beam_trace", "=", "opt", ".", "dump_beam", "!=", "\"\"", ",", "\n", "min_length", "=", "opt", ".", "min_length", ")", "\n", "builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "translator", ".", "fields", ",", "\n", "opt", ".", "n_best", ",", "opt", ".", "replace_unk", ",", "opt", ".", "tgt", ")", "\n", "\n", "# Statistics", "\n", "counter", "=", "count", "(", "1", ")", "\n", "pred_score_total", ",", "pred_words_total", "=", "0", ",", "0", "\n", "gold_score_total", ",", "gold_words_total", "=", "0", ",", "0", "\n", "\n", "for", "batch", "in", "data_iter", ":", "\n", "        ", "batch_data", "=", "translator", ".", "translate_batch", "(", "batch", ",", "data", ")", "\n", "translations", "=", "builder", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "            ", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "if", "opt", ".", "tgt", ":", "\n", "                ", "gold_score_total", "+=", "trans", ".", "gold_score", "\n", "gold_words_total", "+=", "len", "(", "trans", ".", "gold_sent", ")", "\n", "\n", "", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "opt", ".", "n_best", "]", "]", "\n", "out_file", ".", "write", "(", "'\\n'", ".", "join", "(", "n_best_preds", ")", ")", "\n", "out_file", ".", "write", "(", "'\\n'", ")", "\n", "out_file", ".", "flush", "(", ")", "\n", "\n", "if", "opt", ".", "verbose", ":", "\n", "                ", "sent_number", "=", "next", "(", "counter", ")", "\n", "output", "=", "trans", ".", "log", "(", "sent_number", ")", "\n", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "", "", "", "_report_score", "(", "'PRED'", ",", "pred_score_total", ",", "pred_words_total", ")", "\n", "if", "opt", ".", "tgt", ":", "\n", "        ", "_report_score", "(", "'GOLD'", ",", "gold_score_total", ",", "gold_words_total", ")", "\n", "if", "opt", ".", "report_bleu", ":", "\n", "            ", "_report_bleu", "(", ")", "\n", "", "if", "opt", ".", "report_rouge", ":", "\n", "            ", "_report_rouge", "(", ")", "\n", "\n", "", "", "if", "opt", ".", "dump_beam", ":", "\n", "        ", "import", "json", "\n", "json", ".", "dump", "(", "translator", ".", "beam_accum", ",", "\n", "codecs", ".", "open", "(", "opt", ".", "dump_beam", ",", "'w'", ",", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.DatasetLazyIter.__init__": [[114, 126], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.DatasetLazyIter.__iter__": [[127, 133], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n", "while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.DatasetLazyIter.__len__": [[134, 140], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.DatasetLazyIter.get_cur_dataset": [[141, 143], ["None"], "methods", ["None"], ["", "def", "get_cur_dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.DatasetLazyIter._next_dataset_iterator": [[144, 161], ["onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "next"], "methods", ["None"], ["", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n", "# We clear `fields` when saving, restore when loading.", "\n", "", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "onmt", ".", "io", ".", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.report_func": [[76, 100], ["onmt.Statistics.output", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics.log"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.output", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "report_func", "(", "epoch", ",", "batch", ",", "num_batches", ",", "\n", "start_time", ",", "lr", ",", "report_stats", ",", "report_flag", ")", ":", "\n", "    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "# if batch % opt.report_every == -1 % opt.report_every:", "\n", "if", "report_flag", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "report_stats", ".", "log", "(", "\"progress\"", ",", "experiment", ",", "lr", ")", "\n", "", "report_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.make_dataset_iter": [[163, 180], ["train.DatasetLazyIter", "max", "len", "len"], "function", ["None"], ["", "", "def", "make_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over during each train epoch. We implement simple\n    ordered iterator strategy here, but more sophisticated strategy\n    like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "batch_size_fn", "=", "None", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "sofar", "+", "max", "(", "len", "(", "new", ".", "tgt", ")", ",", "len", "(", "new", ".", "src", ")", ")", "+", "1", "\n", "\n", "", "", "device", "=", "opt", ".", "gpuid", "[", "0", "]", "if", "opt", ".", "gpuid", "else", "-", "1", "\n", "\n", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.make_loss_compute": [[182, 200], ["onmt.Utils.use_gpu", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute.cuda"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "def", "make_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "onmt", ".", "Loss", ".", "NMTLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "\n", "label_smoothing", "=", "opt", ".", "label_smoothing", ")", "\n", "\n", "", "if", "use_gpu", "(", "opt", ")", ":", "\n", "        ", "compute", ".", "cuda", "(", ")", "\n", "\n", "", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.train_model": [[202, 244], ["train.make_loss_compute", "train.make_loss_compute", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "range", "print", "train.lazily_load_dataset", "train.make_dataset_iter", "onmt.Trainer.train", "print", "print", "train.make_dataset_iter", "onmt.Trainer.validate", "print", "print", "onmt.Trainer.epoch_step", "train.lazily_load_dataset", "trainer.train.log", "trainer.validate.log", "trainer.validate.ppl", "onmt.Trainer.drop_checkpoint", "trainer.train.ppl", "trainer.train.accuracy", "trainer.validate.ppl", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy"], ["", "def", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", ":", "\n", "\n", "    ", "train_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "disc", ",", "nli", ",", "train_loss", ",", "valid_loss", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "\n", "trunc_size", ",", "shard_size", ",", "data_type", ",", "\n", "opt", ".", "normalization", ",", "opt", ".", "accum_count", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "train_iter", "=", "make_dataset_iter", "(", "train_datasets", ",", "fields", ",", "opt", ")", "\n", "train_stats", "=", "trainer", ".", "train", "(", "train_iter", ",", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_iter", "=", "make_dataset_iter", "(", "lazily_load_dataset", "(", "\"valid\"", ")", ",", "\n", "fields", ",", "opt", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", "valid_iter", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "train_stats", ".", "log", "(", "\"train\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "valid_stats", ".", "log", "(", "\"valid\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "\n", "# 4. Update the learning rate", "\n", "", "trainer", ".", "epoch_step", "(", "valid_stats", ".", "ppl", "(", ")", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "model_opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.check_save_model_path": [[246, 251], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "", "def", "check_save_model_path", "(", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.tally_parameters": [[253, 265], ["sum", "print", "model.named_parameters", "print", "print", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "print", "(", "'encoder: '", ",", "enc", ")", "\n", "print", "(", "'decoder: '", ",", "dec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.lazily_load_dataset": [[267, 294], ["sorted", "torch.load", "torch.load", "print", "glob.glob", "train.lazily_load_dataset.lazy_dataset_loader"], "function", ["None"], ["", "def", "lazily_load_dataset", "(", "corpus_type", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "print", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "return", "dataset", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one onmt.io.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.load_fields": [[296, 317], ["onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "dict", "torch.load", "torch.load", "print", "print", "dict.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab"], ["", "", "def", "load_fields", "(", "dataset", ",", "data_type", ",", "checkpoint", ")", ":", "\n", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "load_fields_from_vocab", "(", "\n", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", ",", "data_type", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "dataset", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "fields", "[", "'per'", "]", ".", "vocab", "=", "fields", "[", "'tgt'", "]", ".", "vocab", "\n", "\n", "# if checkpoint is not None:", "\n", "#     print('Loading vocab from checkpoint at %s.' % opt.train_from)", "\n", "#     fields = onmt.io.load_fields_from_vocab(", "\n", "#                 checkpoint['vocab'], data_type)", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'src'", "]", ".", "vocab", ")", ",", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "' * vocabulary size. target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.collect_report_features": [[319, 327], ["onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "enumerate", "enumerate", "print", "print", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features"], ["", "def", "collect_report_features", "(", "fields", ")", ":", "\n", "    ", "src_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'src'", ")", "\n", "tgt_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'tgt'", ")", "\n", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "print", "(", "' * src feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "print", "(", "' * tgt feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.build_model": [[329, 339], ["print", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "print", "onmt.Utils.use_gpu", "len", "print", "torch.DataParallel"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", ":", "\n", "    ", "print", "(", "'Building model...'", ")", "\n", "model", ",", "disc", ",", "nli", "=", "onmt", ".", "ModelConstructor", ".", "make_base_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "print", "(", "'Multi gpu training: '", ",", "opt", ".", "gpuid", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "opt", ".", "gpuid", ",", "dim", "=", "1", ")", "\n", "", "print", "(", "model", ")", "\n", "\n", "return", "model", ",", "disc", ",", "nli", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.build_optim": [[341, 362], ["onmt.Optim.set_parameters", "print", "onmt.Optim.optimizer.load_state_dict", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.set_parameters"], ["", "def", "build_optim", "(", "model", ",", "checkpoint", ",", "type", ",", "optim", ",", "learning_rate", ")", ":", "\n", "    ", "if", "opt", ".", "train_from", "and", "checkpoint", "and", "False", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "type", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "type", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "onmt", ".", "Optim", "(", "\n", "optim", ",", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.train.main": [[364, 411], ["print", "train.lazily_load_dataset", "print", "next", "itertools.chain", "train.load_fields", "train.collect_report_features", "train.build_model", "train.tally_parameters", "train.check_save_model_path", "train.build_optim", "train.build_optim", "train.build_optim", "train.train_model", "print", "torch.load", "torch.load", "torch.load", "torch.load"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.load_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.collect_report_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.tally_parameters", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.check_save_model_path", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.train_model"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# Lazily load a list of train/validate dataset.", "\n", "    ", "print", "(", "\"Lazily loading train/validate datasets from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Peek the fisrt dataset to determine the data_type.", "\n", "# (This will load the first dataset.)", "\n", "first_dataset", "=", "next", "(", "train_datasets", ")", "\n", "train_datasets", "=", "chain", "(", "[", "first_dataset", "]", ",", "train_datasets", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear.", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "d_train_from", ":", "\n", "            ", "d_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "d_train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "first_dataset", ",", "data_type", ",", "checkpoint", ")", "\n", "\n", "# Report src/tgt features.", "\n", "collect_report_features", "(", "fields", ")", "\n", "\n", "# Build model.", "\n", "model", ",", "disc", ",", "nli", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "tally_parameters", "(", "model", ")", "\n", "check_save_model_path", "(", ")", "\n", "\n", "# Build optimizer.", "\n", "g_optim", "=", "build_optim", "(", "model", ",", "checkpoint", ",", "'g_optim'", ",", "opt", ".", "g_optim", ",", "opt", ".", "g_learning_rate", ")", "\n", "d_optim", "=", "build_optim", "(", "disc", ",", "checkpoint", ",", "'d_optim'", ",", "opt", ".", "d_optim", ",", "opt", ".", "d_learning_rate", ")", "\n", "nli_optim", "=", "build_optim", "(", "nli", ",", "checkpoint", ",", "'nli_optim'", ",", "opt", ".", "nli_optim", ",", "opt", ".", "nli_learning_rate", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.check_existing_pt_files": [[15, 25], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "    ", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup exisiting pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.parse_args": [[27, 41], ["argparse.ArgumentParser", "opts.add_md_help_argument", "opts.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.add_md_help_argument", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.preprocess_opts", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.parse_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_text_dataset_in_shards": [[43, 117], ["os.path.getsize", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "onmt.io.ShardedTextCorpusIterator", "print", "print", "onmt.io.ShardedTextCorpusIterator.hit_end", "onmt.io.TextDataset", "print", "torch.save", "ret_list.append"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.TextDataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_text_dataset_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "per_corpus", ",", "nli_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "'''\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n    '''", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "print", "(", "\"Warning. The corpus %s is larger than 10M bytes, you can \"", "\n", "\"set '-max_shard_size' to process it by small shards \"", "\n", "\"to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "tgt_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "per_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "per_corpus", ",", "opt", ".", "per_seq_length_trunc", ",", "\n", "\"per\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "nli_iter", "=", "onmt", ".", "io", ".", "ShardedTextCorpusIterator", "(", "\n", "nli_corpus", ",", "opt", ".", "nli_seq_length_trunc", ",", "\n", "\"nli\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "print", "(", "' * divide corpus into shards and build dataset separately'", "\n", "'(shard_size = %d bytes).'", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "onmt", ".", "io", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "tgt_iter", ",", "per_iter", ",", "nli_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "per_seq_length", "=", "opt", ".", "per_seq_length", ",", "\n", "nli_seq_length", "=", "opt", ".", "nli_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "print", "(", "\" * saving train data shard to %s.\"", "%", "pt_file", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_dataset": [[119, 164], ["onmt.io.build_dataset", "print", "torch.save", "preprocess.build_save_text_dataset_in_shards"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_text_dataset_in_shards"], ["", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "per_corpus", "=", "opt", ".", "train_per", "\n", "nli_corpus", "=", "opt", ".", "train_nli", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "per_corpus", "=", "opt", ".", "valid_per", "\n", "nli_corpus", "=", "opt", ".", "valid_nli", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_text_dataset_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "per_corpus", ",", "nli_corpus", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "onmt", ".", "io", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "src_corpus", ",", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "print", "(", "\" * saving train dataset to %s.\"", "%", "pt_file", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_vocab": [[166, 177], ["onmt.io.build_vocab", "torch.save", "onmt.io.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.build_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.save_fields_to_vocab"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "onmt", ".", "io", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.main": [[179, 199], ["preprocess.parse_args", "print", "onmt.io.get_num_features", "onmt.io.get_num_features", "print", "print", "print", "onmt.io.get_fields", "print", "preprocess.build_save_dataset", "print", "preprocess.build_save_vocab", "print", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.parse_args", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_num_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.ImageDataset.ImageDataset.get_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.reinforcement_train.preprocess.build_save_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "\n", "print", "(", "\"Extracting features...\"", ")", "\n", "src_nfeats", "=", "onmt", ".", "io", ".", "get_num_features", "(", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "onmt", ".", "io", ".", "get_num_features", "(", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "print", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "print", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "print", "(", "\"Loading Fields object...\"", ")", "\n", "fields", "=", "onmt", ".", "io", ".", "get_fields", "(", "opt", ".", "data_type", ",", "src_nfeats", ",", "tgt_nfeats", ")", "\n", "\n", "print", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "print", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n", "print", "(", "\"Building & saving validation data...\"", ")", "\n", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter._format_usage": [[502, 504], ["None"], "methods", ["None"], ["def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.format_help": [[505, 509], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.format_help"], ["", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.start_section": [[510, 513], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter.start_section"], ["", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpFormatter._format_action": [[514, 526], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], ["", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpAction.__init__": [[529, 538], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n", "dest", "=", "dest", ",", "\n", "default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.MarkdownHelpAction.__call__": [[539, 543], ["parser.print_help", "parser.exit"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "parser", ".", "formatter_class", "=", "MarkdownHelpFormatter", "\n", "parser", ".", "print_help", "(", ")", "\n", "parser", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.DeprecateAction.__init__": [[546, 549], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "help", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DeprecateAction", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "nargs", "=", "0", ",", "\n", "help", "=", "help", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.DeprecateAction.__call__": [[550, 554], ["argparse.ArgumentTypeError"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "flag_name", ")", ":", "\n", "        ", "help", "=", "self", ".", "help", "if", "self", ".", "help", "is", "not", "None", "else", "\"\"", "\n", "msg", "=", "\"Flag '%s' is deprecated. %s\"", "%", "(", "flag_name", ",", "help", ")", "\n", "raise", "argparse", ".", "ArgumentTypeError", "(", "msg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.model_opts": [[5, 115], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# Encoder-Deocder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", ",", "'mean'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of encoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|brnn|mean|transformer|cnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'transformer'", ",", "'cnn'", "]", ",", "\n", "help", "=", "\"\"\"Type of decoder layer to use. Non-RNN layers\n                       are experimental. Options are\n                       [rnn|transformer|cnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "group", ".", "add_argument", "(", "'-brnn_merge'", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", "]", ",", "\n", "help", "=", "\"Merge action for the bidir hidden states\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "\n", "# Genenerator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'Lambda value for coverage.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.preprocess_opts": [[117, 217], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "# Data options", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training nli data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation persona data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation nli data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes.\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "\n", "help", "=", "\"Path to an existing source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "\n", "help", "=", "\"Path to an existing target vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum persona sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-per_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate persona sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "\"Maximum nli sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate nli sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.train_opts": [[219, 386], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "train_opts", "(", "parser", ")", ":", "\n", "# Model loading/saving options", "\n", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_epochN_PPL.pt where PPL is the\n                       validation perplexity\"\"\"", ")", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-start_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'The epoch from which to start'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                           path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "13", ",", "\n", "help", "=", "'Number of training epochs'", ")", "\n", "group", ".", "add_argument", "(", "'-g_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_optim'", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-g_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-d_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                           Recommended settings: sgd = 1, adagrad = 0.1,\n                           adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                               Recommended settings: sgd = 1, adagrad = 0.1,\n                               adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) epoch has gone past\n                       start_decay_at\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_at'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"\"\"Start decaying every epoch after and including this\n                       epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_checkpoint_at'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Start checkpointing every epoch after and including\n                       this epoch\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.translate_opts": [[388, 479], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-per'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Persona sentence to use (one line per\n                           personas, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-nli'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"nli sentence to use (one line per\n                           nlis, separated by </s>)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.opts.add_md_help_argument": [[481, 484], ["parser.add_argument"], "function", ["None"], ["", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "'-md'", ",", "action", "=", "MarkdownHelpAction", ",", "\n", "help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__init__": [[114, 126], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n", "\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__iter__": [[127, 133], ["train.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n", "while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.__len__": [[134, 140], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter.get_cur_dataset": [[141, 143], ["None"], "methods", ["None"], ["", "def", "get_cur_dataset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cur_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.DatasetLazyIter._next_dataset_iterator": [[144, 161], ["onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "onmt.io.OrderedIterator", "next"], "methods", ["None"], ["", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n", "# We clear `fields` when saving, restore when loading.", "\n", "", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "onmt", ".", "io", ".", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.report_func": [[76, 100], ["onmt.Statistics.output", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics", "onmt.Statistics.log"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.output", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log"], ["", "def", "report_func", "(", "epoch", ",", "batch", ",", "num_batches", ",", "\n", "start_time", ",", "lr", ",", "report_stats", ",", "report_flag", ")", ":", "\n", "    ", "\"\"\"\n    This is the user-defined batch-level traing progress\n    report function.\n\n    Args:\n        epoch(int): current epoch count.\n        batch(int): current batch count.\n        num_batches(int): total number of batches.\n        start_time(float): last report time.\n        lr(float): current learning rate.\n        report_stats(Statistics): old Statistics instance.\n    Returns:\n        report_stats(Statistics): updated Statistics instance.\n    \"\"\"", "\n", "# if batch % opt.report_every == -1 % opt.report_every:", "\n", "if", "report_flag", ":", "\n", "        ", "report_stats", ".", "output", "(", "epoch", ",", "batch", "+", "1", ",", "num_batches", ",", "start_time", ")", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "report_stats", ".", "log", "(", "\"progress\"", ",", "experiment", ",", "lr", ")", "\n", "", "report_stats", "=", "onmt", ".", "Statistics", "(", ")", "\n", "\n", "", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter": [[163, 180], ["train.DatasetLazyIter", "max", "len", "len"], "function", ["None"], ["", "", "def", "make_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over during each train epoch. We implement simple\n    ordered iterator strategy here, but more sophisticated strategy\n    like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "batch_size_fn", "=", "None", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "return", "sofar", "+", "max", "(", "len", "(", "new", ".", "tgt", ")", ",", "len", "(", "new", ".", "src", ")", ")", "+", "1", "\n", "\n", "", "", "device", "=", "opt", ".", "gpuid", "[", "0", "]", "if", "opt", ".", "gpuid", "else", "-", "1", "\n", "\n", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute": [[182, 200], ["onmt.Utils.use_gpu", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute", "onmt.Loss.NMTLossCompute.cuda"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "def", "make_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ")", "\n", "", "else", ":", "\n", "        ", "compute", "=", "onmt", ".", "Loss", ".", "NMTLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "\n", "label_smoothing", "=", "opt", ".", "label_smoothing", ")", "\n", "\n", "", "if", "use_gpu", "(", "opt", ")", ":", "\n", "        ", "compute", ".", "cuda", "(", ")", "\n", "\n", "", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.train_model": [[202, 244], ["train.make_loss_compute", "train.make_loss_compute", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "onmt.Trainer", "range", "print", "train.lazily_load_dataset", "train.make_dataset_iter", "onmt.Trainer.train", "print", "print", "train.make_dataset_iter", "onmt.Trainer.validate", "print", "print", "onmt.Trainer.epoch_step", "train.lazily_load_dataset", "trainer.train.log", "trainer.validate.log", "trainer.validate.ppl", "onmt.Trainer.drop_checkpoint", "trainer.train.ppl", "trainer.train.accuracy", "trainer.validate.ppl", "trainer.validate.accuracy"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_loss_compute", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.train", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.make_dataset_iter", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.validate", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.epoch_step", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.translate.Translation.Translation.log", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Trainer.drop_checkpoint", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.ppl", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Trainer.Statistics.accuracy"], ["", "def", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", ":", "\n", "\n", "    ", "train_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "make_loss_compute", "(", "model", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "\n", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "model", ",", "disc", ",", "nli", ",", "train_loss", ",", "valid_loss", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "\n", "trunc_size", ",", "shard_size", ",", "data_type", ",", "\n", "opt", ".", "normalization", ",", "opt", ".", "accum_count", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "start_epoch", ",", "opt", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "print", "(", "''", ")", "\n", "\n", "# 1. Train for one epoch on the training set.", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "train_iter", "=", "make_dataset_iter", "(", "train_datasets", ",", "fields", ",", "opt", ")", "\n", "train_stats", "=", "trainer", ".", "train", "(", "train_iter", ",", "epoch", ",", "report_func", ")", "\n", "print", "(", "'Train perplexity: %g'", "%", "train_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Train accuracy: %g'", "%", "train_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 2. Validate on the validation set.", "\n", "valid_iter", "=", "make_dataset_iter", "(", "lazily_load_dataset", "(", "\"valid\"", ")", ",", "\n", "fields", ",", "opt", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "valid_stats", "=", "trainer", ".", "validate", "(", "valid_iter", ")", "\n", "print", "(", "'Validation perplexity: %g'", "%", "valid_stats", ".", "ppl", "(", ")", ")", "\n", "print", "(", "'Validation accuracy: %g'", "%", "valid_stats", ".", "accuracy", "(", ")", ")", "\n", "\n", "# 3. Log to remote server.", "\n", "if", "opt", ".", "exp_host", ":", "\n", "            ", "train_stats", ".", "log", "(", "\"train\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "valid_stats", ".", "log", "(", "\"valid\"", ",", "experiment", ",", "g_optim", ".", "lr", ")", "\n", "\n", "# 4. Update the learning rate", "\n", "", "trainer", ".", "epoch_step", "(", "valid_stats", ".", "ppl", "(", ")", ",", "epoch", ")", "\n", "\n", "# 5. Drop a checkpoint if needed.", "\n", "if", "epoch", ">=", "opt", ".", "start_checkpoint_at", ":", "\n", "            ", "trainer", ".", "drop_checkpoint", "(", "model_opt", ",", "epoch", ",", "fields", ",", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.check_save_model_path": [[246, 251], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "", "def", "check_save_model_path", "(", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.tally_parameters": [[253, 265], ["sum", "print", "model.named_parameters", "print", "print", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "print", "(", "'encoder: '", ",", "enc", ")", "\n", "print", "(", "'decoder: '", ",", "dec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset": [[267, 294], ["sorted", "torch.load", "torch.load", "print", "glob.glob", "train.lazily_load_dataset.lazy_dataset_loader"], "function", ["None"], ["", "def", "lazily_load_dataset", "(", "corpus_type", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "print", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "return", "dataset", "\n", "\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one onmt.io.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.load_fields": [[296, 317], ["onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "onmt.io.load_fields_from_vocab", "dict", "torch.load", "torch.load", "print", "print", "dict.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.load_fields_from_vocab"], ["", "", "def", "load_fields", "(", "dataset", ",", "data_type", ",", "checkpoint", ")", ":", "\n", "\n", "    ", "fields", "=", "onmt", ".", "io", ".", "load_fields_from_vocab", "(", "\n", "torch", ".", "load", "(", "opt", ".", "data", "+", "'.vocab.pt'", ")", ",", "data_type", ")", "\n", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "dataset", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "fields", "[", "'per'", "]", ".", "vocab", "=", "fields", "[", "'tgt'", "]", ".", "vocab", "\n", "\n", "# if checkpoint is not None:", "\n", "#     print('Loading vocab from checkpoint at %s.' % opt.train_from)", "\n", "#     fields = onmt.io.load_fields_from_vocab(", "\n", "#                 checkpoint['vocab'], data_type)", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "print", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'src'", "]", ".", "vocab", ")", ",", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "' * vocabulary size. target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.collect_report_features": [[319, 327], ["onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "onmt.io.collect_features", "enumerate", "enumerate", "print", "print", "len", "len"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.io.IO.collect_features"], ["", "def", "collect_report_features", "(", "fields", ")", ":", "\n", "    ", "src_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'src'", ")", "\n", "tgt_features", "=", "onmt", ".", "io", ".", "collect_features", "(", "fields", ",", "side", "=", "'tgt'", ")", "\n", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "print", "(", "' * src feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "print", "(", "' * tgt feature %d size = %d'", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_model": [[329, 339], ["print", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "onmt.ModelConstructor.make_base_model", "print", "onmt.Utils.use_gpu", "len", "print", "torch.DataParallel"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.ModelConstructor.make_base_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Utils.use_gpu"], ["", "", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", ":", "\n", "    ", "print", "(", "'Building model...'", ")", "\n", "model", ",", "disc", ",", "nli", "=", "onmt", ".", "ModelConstructor", ".", "make_base_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "print", "(", "'Multi gpu training: '", ",", "opt", ".", "gpuid", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "opt", ".", "gpuid", ",", "dim", "=", "1", ")", "\n", "", "print", "(", "model", ")", "\n", "\n", "return", "model", ",", "disc", ",", "nli", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim": [[341, 362], ["onmt.Optim.set_parameters", "print", "onmt.Optim.optimizer.load_state_dict", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "onmt.Optim", "model.parameters", "checkpoint[].optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.onmt.Optim.Optim.set_parameters"], ["", "def", "build_optim", "(", "model", ",", "checkpoint", ",", "type", ",", "optim", ",", "learning_rate", ")", ":", "\n", "    ", "if", "opt", ".", "train_from", "and", "checkpoint", "and", "False", ":", "\n", "        ", "print", "(", "'Loading optimizer from checkpoint.'", ")", "\n", "optim", "=", "checkpoint", "[", "type", "]", "\n", "optim", ".", "optimizer", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "type", "]", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "onmt", ".", "Optim", "(", "\n", "optim", ",", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_at", "=", "opt", ".", "start_decay_at", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.main": [[364, 411], ["print", "train.lazily_load_dataset", "print", "next", "itertools.chain", "train.load_fields", "train.collect_report_features", "train.build_model", "train.tally_parameters", "train.check_save_model_path", "train.build_optim", "train.build_optim", "train.build_optim", "train.train_model", "print", "torch.load", "torch.load", "torch.load", "torch.load"], "function", ["home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.lazily_load_dataset", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.load_fields", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.collect_report_features", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_model", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.tally_parameters", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.check_save_model_path", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.build_optim", "home.repos.pwc.inspect_result.songhaoyu_RCDG.G_pretrain.train.train_model"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# Lazily load a list of train/validate dataset.", "\n", "    ", "print", "(", "\"Lazily loading train/validate datasets from '%s'\"", "%", "opt", ".", "data", ")", "\n", "train_datasets", "=", "lazily_load_dataset", "(", "\"train\"", ")", "\n", "print", "(", "' * maximum batch size: %d'", "%", "opt", ".", "batch_size", ")", "\n", "\n", "# Peek the fisrt dataset to determine the data_type.", "\n", "# (This will load the first dataset.)", "\n", "first_dataset", "=", "next", "(", "train_datasets", ")", "\n", "train_datasets", "=", "chain", "(", "[", "first_dataset", "]", ",", "train_datasets", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "print", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "# I don't like reassigning attributes of opt: it's not clear.", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "d_train_from", ":", "\n", "            ", "d_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "d_train_from", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "d_checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "", "fields", "=", "load_fields", "(", "first_dataset", ",", "data_type", ",", "checkpoint", ")", "\n", "\n", "# Report src/tgt features.", "\n", "collect_report_features", "(", "fields", ")", "\n", "\n", "# Build model.", "\n", "model", ",", "disc", ",", "nli", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "d_checkpoint", ")", "\n", "tally_parameters", "(", "model", ")", "\n", "check_save_model_path", "(", ")", "\n", "\n", "# Build optimizer.", "\n", "g_optim", "=", "build_optim", "(", "model", ",", "checkpoint", ",", "'g_optim'", ",", "opt", ".", "g_optim", ",", "opt", ".", "g_learning_rate", ")", "\n", "d_optim", "=", "build_optim", "(", "disc", ",", "checkpoint", ",", "'d_optim'", ",", "opt", ".", "d_optim", ",", "opt", ".", "d_learning_rate", ")", "\n", "nli_optim", "=", "build_optim", "(", "nli", ",", "checkpoint", ",", "'nli_optim'", ",", "opt", ".", "nli_optim", ",", "opt", ".", "nli_learning_rate", ")", "\n", "\n", "# Do training.", "\n", "train_model", "(", "model", ",", "disc", ",", "nli", ",", "fields", ",", "g_optim", ",", "d_optim", ",", "nli_optim", ",", "data_type", ",", "model_opt", ")", "\n", "\n"]]}