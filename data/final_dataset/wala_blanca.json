{"home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_hirerachy_examples": [[44, 87], ["random.shuffle", "math.ceil", "sentence_transformers.SentencesDataset", "torch.utils.data.DataLoader", "sentence_transformers.losses.CosineSimilarityLoss", "print", "math.ceil", "open", "json.load", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.from_input_examples", "len", "os.path.join", "train_hierarchy_samples.append", "disbn.append", "len", "sentence_transformers.InputExample", "len"], "function", ["None"], ["def", "create_hirerachy_examples", "(", "fl", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "train_hierarchy_samples", "=", "[", "]", "\n", "disbn", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fl", ")", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "max_distance", "=", "0", "\n", "for", "obj", "in", "data", ":", "\n", "            ", "if", "obj", "[", "'distance'", "]", ">", "max_distance", ":", "\n", "                ", "max_distance", "=", "obj", "[", "'distance'", "]", "\n", "", "", "for", "obj", "in", "data", ":", "\n", "# flip the meaning of similarity, since the more distant the two classes, the closer to 0 it should be", "\n", "            ", "dist", "=", "(", "max_distance", "-", "obj", "[", "'distance'", "]", ")", "/", "(", "max_distance", "-", "1", ")", "\n", "train_hierarchy_samples", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "obj", "[", "'class1'", "]", ",", "obj", "[", "'class2'", "]", "]", ",", "label", "=", "dist", ")", ")", "\n", "disbn", ".", "append", "(", "obj", "[", "'distance'", "]", ")", "\n", "", "", "random", ".", "shuffle", "(", "train_hierarchy_samples", ")", "\n", "train_hierarchy_samples", "=", "train_hierarchy_samples", "[", ":", "100000", "]", "\n", "disbn", "=", "disbn", "[", ":", "100000", "]", "\n", "\n", "if", "max_size", ":", "\n", "        ", "train_hierarchy_samples", "=", "train_hierarchy_samples", "[", ":", "max_size", "]", "\n", "disbn", "=", "disbn", "[", ":", "max_size", "]", "\n", "\n", "", "if", "is_test", ":", "\n", "        ", "return", "train_hierarchy_samples", "\n", "\n", "", "evaluator", "=", "None", "\n", "\n", "if", "hierarchy_str", "==", "validate", ":", "\n", "        ", "train_hierarchy_samples", ",", "dev_hierarchy_samples", "=", "train_test_split", "(", "train_hierarchy_samples", ",", "stratify", "=", "disbn", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "EmbeddingSimilarityEvaluator", ".", "from_input_examples", "(", "dev_hierarchy_samples", ",", "name", "=", "'hierarchy'", ")", "\n", "\n", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_hierarchy_samples", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "train_data_hierarchy", "=", "SentencesDataset", "(", "train_hierarchy_samples", ",", "model", "=", "model", ")", "\n", "train_dataloader_hierarchy", "=", "DataLoader", "(", "train_data_hierarchy", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_hierarchy", "=", "losses", ".", "CosineSimilarityLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'H: Number of training examples: '", ",", "len", "(", "train_hierarchy_samples", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_hierarchy_samples", ")", "/", "0.1", ")", "\n", "return", "train_dataloader_hierarchy", ",", "train_loss_hierarchy", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_linked_posts": [[89, 128], ["random.shuffle", "math.ceil", "sentence_transformers.SentencesDataset", "torch.utils.data.DataLoader", "sentence_transformers.losses.ContrastiveLoss", "print", "math.ceil", "open", "json.load", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.BinaryClassificationEvaluator.from_input_examples", "len", "os.path.join", "disbn.append", "train_linked_posts.append", "len", "sentence_transformers.InputExample", "len"], "function", ["None"], ["", "def", "create_linked_posts", "(", "fl", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "train_linked_posts", "=", "[", "]", "\n", "disbn", "=", "[", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fl", ")", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "obj", "in", "data", ":", "\n", "            ", "if", "obj", "[", "'class'", "]", "==", "'relevant'", ":", "\n", "                ", "label", "=", "1", "\n", "", "else", ":", "\n", "                ", "label", "=", "0", "\n", "", "disbn", ".", "append", "(", "label", ")", "\n", "\n", "train_linked_posts", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "obj", "[", "'text_1'", "]", ",", "obj", "[", "'text_2'", "]", "]", ",", "label", "=", "label", ")", ")", "\n", "", "", "random", ".", "shuffle", "(", "train_linked_posts", ")", "\n", "\n", "if", "is_test", ":", "\n", "        ", "return", "train_linked_posts", "\n", "\n", "", "if", "max_size", ":", "\n", "        ", "train_linked_posts", "=", "train_linked_posts", "[", ":", "max_size", "]", "\n", "\n", "", "evaluator", "=", "None", "\n", "if", "linked_posts_str", "==", "validate", ":", "\n", "        ", "train_linked_posts", ",", "dev_linked_posts", "=", "train_test_split", "(", "train_linked_posts", ",", "stratify", "=", "disbn", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "BinaryClassificationEvaluator", ".", "from_input_examples", "(", "dev_linked_posts", ",", "name", "=", "'linked-posts'", ")", "\n", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_linked_posts", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "train_data_linked_posts", "=", "SentencesDataset", "(", "train_linked_posts", ",", "model", "=", "model", ")", "\n", "train_dataloader_linked_posts", "=", "DataLoader", "(", "train_data_linked_posts", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_linked_posts", "=", "losses", ".", "ContrastiveLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'L: Number of training examples: '", ",", "len", "(", "train_linked_posts", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_linked_posts", ")", "/", "0.1", ")", "\n", "\n", "return", "train_dataloader_linked_posts", ",", "train_loss_linked_posts", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_train_class_posts": [[130, 162], ["random.shuffle", "math.ceil", "sentence_transformers.SentencesDataset", "torch.utils.data.DataLoader", "sentence_transformers.losses.ContrastiveLoss", "print", "math.ceil", "open", "json.load", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.BinaryClassificationEvaluator.from_input_examples", "len", "os.path.join", "train_class_posts.append", "disbn.append", "len", "sentence_transformers.InputExample", "len"], "function", ["None"], ["", "def", "create_train_class_posts", "(", "fl", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "train_class_posts", "=", "[", "]", "\n", "disbn", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fl", ")", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "obj", "in", "data", ":", "\n", "            ", "train_class_posts", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "obj", "[", "'docstring'", "]", ",", "obj", "[", "'text'", "]", "]", ",", "label", "=", "obj", "[", "'label'", "]", ")", ")", "\n", "disbn", ".", "append", "(", "obj", "[", "'label'", "]", ")", "\n", "", "", "random", ".", "shuffle", "(", "train_class_posts", ")", "\n", "\n", "if", "is_test", ":", "\n", "        ", "return", "train_class_posts", "\n", "", "if", "max_size", ":", "\n", "        ", "train_class_posts", "=", "train_class_posts", "[", ":", "max_size", "]", "\n", "\n", "", "evaluator", "=", "None", "\n", "if", "class_posts_str", "==", "validate", ":", "\n", "        ", "train_class_posts", ",", "dev_class_posts", "=", "train_test_split", "(", "train_class_posts", ",", "stratify", "=", "disbn", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "BinaryClassificationEvaluator", ".", "from_input_examples", "(", "dev_class_posts", ",", "name", "=", "'class-posts'", ")", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_class_posts", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "\n", "train_data_class_posts", "=", "SentencesDataset", "(", "train_class_posts", ",", "model", "=", "model", ")", "\n", "train_dataloader_class_posts", "=", "DataLoader", "(", "train_data_class_posts", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_class_posts", "=", "losses", ".", "ContrastiveLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'class_posts: Number of training examples: '", ",", "len", "(", "train_class_posts", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_class_posts", ")", "/", "0.1", ")", "\n", "\n", "return", "train_dataloader_class_posts", ",", "train_loss_class_posts", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_train_usage": [[164, 205], ["random.shuffle", "math.ceil", "sentence_transformers.SentencesDataset", "torch.utils.data.DataLoader", "sentence_transformers.losses.CosineSimilarityLoss", "print", "math.ceil", "open", "json.load", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.from_input_examples", "len", "os.path.join", "train_usage.append", "len", "sentence_transformers.InputExample", "len"], "function", ["None"], ["", "def", "create_train_usage", "(", "fl", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "train_usage", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fl", ")", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "min_d", "=", "10000000", "\n", "max_d", "=", "0", "\n", "for", "obj", "in", "data", ":", "\n", "            ", "dist", "=", "obj", "[", "'distance'", "]", "\n", "if", "dist", "<", "min_d", ":", "\n", "                ", "min_d", "=", "dist", "\n", "", "if", "dist", ">", "max_d", ":", "\n", "                ", "max_d", "=", "dist", "\n", "", "", "for", "obj", "in", "data", ":", "\n", "            ", "dist", "=", "(", "max_d", "-", "obj", "[", "'distance'", "]", ")", "/", "(", "max_d", "-", "min_d", ")", "\n", "train_usage", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "obj", "[", "'class1'", "]", ",", "obj", "[", "'class2'", "]", "]", ",", "label", "=", "dist", ")", ")", "\n", "\n", "", "", "random", ".", "shuffle", "(", "train_usage", ")", "\n", "\n", "if", "is_test", ":", "\n", "        ", "return", "train_usage", "\n", "\n", "", "if", "max_size", ":", "\n", "        ", "train_usage", "=", "train_usage", "[", ":", "max_size", "]", "\n", "\n", "", "evaluator", "=", "None", "\n", "\n", "if", "usage_str", "==", "validate", ":", "\n", "        ", "train_usage", ",", "dev_usage", "=", "train_test_split", "(", "train_usage", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "EmbeddingSimilarityEvaluator", ".", "from_input_examples", "(", "dev_usage", ",", "name", "=", "'usage'", ")", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_usage", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "train_data_usage", "=", "SentencesDataset", "(", "train_usage", ",", "model", "=", "model", ")", "\n", "train_dataloader_usage", "=", "DataLoader", "(", "train_data_usage", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_usage", "=", "losses", ".", "CosineSimilarityLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'U: Number of training examples: '", ",", "len", "(", "train_usage", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_usage", ")", "/", "0.1", ")", "\n", "\n", "return", "train_dataloader_usage", ",", "train_loss_usage", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_posts_ranking": [[207, 258], ["random.shuffle", "print", "math.ceil", "sentence_transformers.SentencesDataset", "torch.utils.data.DataLoader", "sentence_transformers.losses.CosineSimilarityLoss", "print", "math.ceil", "open", "json.load", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.EmbeddingSimilarityEvaluator.from_input_examples", "len", "os.path.join", "str", "len", "len", "len", "len", "filtered_answers.append", "disbn.append", "train_posts_ranking.append", "len", "len", "sentence_transformers.InputExample"], "function", ["None"], ["", "def", "create_posts_ranking", "(", "fl", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "train_posts_ranking", "=", "[", "]", "\n", "disbn", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "fl", ")", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "obj", "in", "data", ":", "\n", "            ", "answers", "=", "obj", "[", "'answers'", "]", "\n", "filtered_answers", "=", "[", "]", "\n", "votes", "=", "1000000", "\n", "for", "answer", "in", "answers", ":", "\n", "                ", "my_votes", "=", "answer", "[", "'a_votes'", "]", "\n", "if", "my_votes", "<", "votes", ":", "\n", "                    ", "votes", "=", "my_votes", "\n", "filtered_answers", ".", "append", "(", "answer", ")", "\n", "\n", "", "", "if", "len", "(", "filtered_answers", ")", ">", "1", ":", "\n", "                ", "rank", "=", "len", "(", "filtered_answers", ")", "\n", "for", "answer", "in", "filtered_answers", ":", "\n", "                    ", "dist", "=", "rank", "/", "len", "(", "filtered_answers", ")", "\n", "disbn", ".", "append", "(", "answer", "[", "'a_rank'", "]", ")", "\n", "rank", "=", "rank", "-", "1", "\n", "train_posts_ranking", ".", "append", "(", "\n", "InputExample", "(", "texts", "=", "[", "obj", "[", "'q_text'", "]", ",", "answer", "[", "'a_text'", "]", "]", ",", "label", "=", "dist", ")", ")", "\n", "\n", "", "", "", "", "random", ".", "shuffle", "(", "train_posts_ranking", ")", "\n", "\n", "print", "(", "\"data size \"", "+", "str", "(", "len", "(", "train_posts_ranking", ")", ")", ")", "\n", "\n", "if", "is_test", ":", "\n", "        ", "return", "train_posts_ranking", "\n", "\n", "", "if", "max_size", ":", "\n", "        ", "train_posts_ranking", "=", "train_posts_ranking", "[", ":", "max_size", "]", "\n", "\n", "", "evaluator", "=", "None", "\n", "if", "posts_rank_str", "==", "validate", ":", "\n", "        ", "train_posts_ranking", ",", "dev_posts_ranking", "=", "train_test_split", "(", "train_posts_ranking", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "EmbeddingSimilarityEvaluator", ".", "from_input_examples", "(", "dev_posts_ranking", ",", "name", "=", "'posts ranking'", ")", "\n", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_posts_ranking", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "train_data_posts_ranking", "=", "SentencesDataset", "(", "train_posts_ranking", ",", "model", "=", "model", ")", "\n", "train_dataloader_posts_ranking", "=", "DataLoader", "(", "train_data_posts_ranking", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_posts_ranking", "=", "losses", ".", "CosineSimilarityLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'R: Number of training examples: '", ",", "len", "(", "train_posts_ranking", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_posts_ranking", ")", "/", "0.1", ")", "\n", "\n", "return", "train_dataloader_posts_ranking", ",", "train_loss_posts_ranking", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.tasks.multi_task_train.create_search": [[260, 314], ["random.shuffle", "math.ceil", "torch.utils.data.DataLoader", "sentence_transformers.losses.ContrastiveLoss", "print", "math.ceil", "open", "open", "open", "set", "f.readlines", "sklearn.model_selection.train_test_split", "sentence_transformers.evaluation.BinaryClassificationEvaluator.from_input_examples", "len", "os.path.join", "line.strip().split", "os.path.join", "line.strip().split", "os.path.join", "line.strip().split", "train_search.append", "disbn.append", "len", "train_search.append", "disbn.append", "set.add", "sentence_transformers.InputExample", "line.strip", "line.strip", "line.strip", "sentence_transformers.InputExample", "len"], "function", ["None"], ["", "def", "create_search", "(", "collection", ",", "query_file", ",", "train", ",", "data_dir", ",", "model", ",", "validate", "=", "None", ",", "is_test", "=", "False", ")", ":", "\n", "    ", "corpus", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "collection", ")", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fIn", ":", "\n", "        ", "for", "line", "in", "fIn", ":", "\n", "            ", "pid", ",", "passage", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "corpus", "[", "pid", "]", "=", "passage", "\n", "\n", "", "", "queries", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "query_file", ")", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fIn", ":", "\n", "        ", "for", "line", "in", "fIn", ":", "\n", "            ", "qid", ",", "query", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "queries", "[", "qid", "]", "=", "query", "\n", "\n", "", "", "train_search", "=", "[", "]", "\n", "disbn", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "train", ")", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "f", ":", "\n", "        ", "added_q", "=", "set", "(", ")", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "qid", ",", "pos_id", ",", "neg_id", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "query", "=", "queries", "[", "qid", "]", "\n", "passage", "=", "corpus", "[", "pos_id", "]", "\n", "neg_passage", "=", "corpus", "[", "neg_id", "]", "\n", "if", "qid", "not", "in", "added_q", ":", "\n", "                ", "train_search", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "query", ",", "passage", "]", ",", "label", "=", "1", ")", ")", "\n", "disbn", ".", "append", "(", "1", ")", "\n", "added_q", ".", "add", "(", "qid", ")", "\n", "", "train_search", ".", "append", "(", "InputExample", "(", "texts", "=", "[", "query", ",", "neg_passage", "]", ",", "label", "=", "0", ")", ")", "\n", "disbn", ".", "append", "(", "0", ")", "\n", "", "", "random", ".", "shuffle", "(", "train_search", ")", "\n", "\n", "if", "is_test", ":", "\n", "        ", "return", "train_search", "\n", "\n", "", "if", "max_size", ":", "\n", "        ", "train_search", "=", "train_search", "[", ":", "max_size", "]", "\n", "", "evaluator", "=", "None", "\n", "\n", "if", "search_str", "==", "validate", ":", "\n", "        ", "train_search", ",", "dev_search", "=", "train_test_split", "(", "train_search", ",", "stratify", "=", "disbn", ",", "test_size", "=", "0.1", ")", "\n", "evaluator", "=", "BinaryClassificationEvaluator", ".", "from_input_examples", "(", "dev_search", ",", "name", "=", "'search'", ")", "\n", "\n", "", "warmup_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_search", ")", "*", "num_epochs", "/", "batch_size", "*", "0.1", ")", "# 10% of train data for warm-up", "\n", "\n", "# We create a DataLoader to load our train samples", "\n", "train_dataloader_search", "=", "DataLoader", "(", "train_search", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ")", "\n", "train_loss_search", "=", "losses", ".", "ContrastiveLoss", "(", "model", "=", "model", ")", "\n", "\n", "print", "(", "'S: Number of training examples: '", ",", "len", "(", "train_search", ")", ")", "\n", "\n", "global", "evaluation_steps", "\n", "evaluation_steps", "=", "math", ".", "ceil", "(", "len", "(", "train_search", ")", "/", "0.1", ")", "\n", "\n", "return", "train_dataloader_search", ",", "train_loss_search", ",", "evaluator", ",", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.test_related_questions.evaluate_classification": [[9, 55], ["utils.util.get_model", "set", "print", "print", "print", "print", "print", "print", "print", "open", "json.load", "open", "pandas.read_csv", "print", "pd.read_csv.iterrows", "print", "print", "print", "scipy.stats.ttest_ind", "scipy.stats.ttest_ind", "scipy.stats.ttest_ind", "set.add", "set.add", "utils.util.embed_sentences", "utils.util.embed_sentences", "scipy.spatial.distance.cosine", "row[].strip().replace", "label2distance[].append", "str", "numpy.mean", "len", "numpy.asarray", "row[].split", "row[].split", "row[].strip"], "function", ["home.repos.pwc.inspect_result.wala_blanca.utils.util.get_model", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences"], ["def", "evaluate_classification", "(", "embed_type", ",", "model_path", ",", "dataSetPath", ",", "otherDatasetPath", ")", ":", "\n", "    ", "model", "=", "get_model", "(", "embed_type", ",", "model_path", ")", "\n", "ids", "=", "set", "(", ")", "\n", "with", "open", "(", "dataSetPath", ",", "'r'", ",", "encoding", "=", "\"UTF-8\"", ")", "as", "data_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "for", "row", "in", "data", ":", "\n", "            ", "ids", ".", "add", "(", "row", "[", "'url_1'", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "ids", ".", "add", "(", "row", "[", "'url_2'", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "", "skipped", "=", "0", "\n", "label2distance", "=", "{", "}", "\n", "\n", "with", "open", "(", "otherDatasetPath", ",", "'r'", ",", "encoding", "=", "\"UTF-8\"", ")", "as", "other", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "other", ")", "\n", "#        df = df.sample(frac=0.05, replace=False, random_state=1)", "\n", "\n", "print", "(", "df", ".", "count", ")", "\n", "for", "_", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "            ", "if", "row", "[", "'q1_Id'", "]", "in", "ids", "or", "row", "[", "'q2_Id'", "]", "in", "ids", ":", "\n", "                ", "skipped", "+=", "1", "\n", "continue", "\n", "", "srcEmbed", "=", "embed_sentences", "(", "[", "row", "[", "'q1_AnswersBody'", "]", "]", ",", "model", ",", "embed_type", ")", "\n", "dstEmbed", "=", "embed_sentences", "(", "[", "row", "[", "'q2_AnswersBody'", "]", "]", ",", "model", ",", "embed_type", ")", "\n", "linkedDist", "=", "distance", ".", "cosine", "(", "srcEmbed", ",", "dstEmbed", ")", "\n", "lbl", "=", "row", "[", "'class'", "]", ".", "strip", "(", ")", ".", "replace", "(", "'\"'", ",", "''", ")", "\n", "if", "lbl", "not", "in", "label2distance", ":", "\n", "                ", "label2distance", "[", "lbl", "]", "=", "[", "]", "\n", "", "label2distance", "[", "lbl", "]", ".", "append", "(", "linkedDist", ")", "\n", "\n", "", "", "print", "(", "'skipped:'", "+", "str", "(", "skipped", ")", ")", "\n", "\n", "for", "key", "in", "label2distance", ":", "\n", "        ", "print", "(", "key", ")", "\n", "print", "(", "np", ".", "mean", "(", "np", ".", "asarray", "(", "label2distance", "[", "key", "]", ")", ")", ")", "\n", "print", "(", "len", "(", "label2distance", "[", "key", "]", ")", ")", "\n", "", "direct", "=", "label2distance", "[", "'direct'", "]", "\n", "duplicate", "=", "label2distance", "[", "'duplicate'", "]", "\n", "indirect", "=", "label2distance", "[", "'indirect'", "]", "\n", "isolated", "=", "label2distance", "[", "'isolated'", "]", "\n", "\n", "print", "(", "'direct-isolated'", ")", "\n", "print", "(", "stats", ".", "ttest_ind", "(", "direct", ",", "isolated", ")", ")", "\n", "print", "(", "'dup - isolated'", ")", "\n", "print", "(", "stats", ".", "ttest_ind", "(", "duplicate", ",", "isolated", ")", ")", "\n", "print", "(", "'indirect - isolated'", ")", "\n", "print", "(", "stats", ".", "ttest_ind", "(", "indirect", ",", "isolated", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.eval.get_ids": [[14, 19], ["open", "ijson.items", "ids.add", "ids.add", "int", "int"], "function", ["None"], ["def", "get_ids", "(", "testSetPath", ")", ":", "\n", "    ", "with", "open", "(", "testSetPath", ",", "'r'", ")", "as", "testSet", ":", "\n", "        ", "for", "test", "in", "ijson", ".", "items", "(", "testSet", ",", "\"item\"", ")", ":", "\n", "            ", "ids", ".", "add", "(", "int", "(", "test", "[", "0", "]", ")", ")", "\n", "ids", ".", "add", "(", "int", "(", "test", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.eval.get_embeddings": [[21, 41], ["open", "ijson.items", "print", "utils.util.embed_sentences", "len", "len", "print", "collections.Counter", "collections.Counter.items", "numpy.array", "int", "posts.append", "set", "print", "print", "int"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences"], ["", "", "", "def", "get_embeddings", "(", "dataSetPath", ")", ":", "\n", "    ", "order", "=", "{", "}", "\n", "posts", "=", "[", "]", "\n", "i", "=", "0", "\n", "with", "open", "(", "dataSetPath", ",", "'r'", ")", "as", "dataSet", ":", "\n", "        ", "for", "post", "in", "ijson", ".", "items", "(", "dataSet", ",", "\"item\"", ")", ":", "\n", "            ", "if", "int", "(", "post", "[", "'id'", "]", ")", "in", "ids", ":", "\n", "                ", "posts", ".", "append", "(", "post", "[", "'text'", "]", ")", "\n", "order", "[", "int", "(", "post", "[", "'id'", "]", ")", "]", "=", "i", "\n", "i", "=", "i", "+", "1", "\n", "", "", "print", "(", "'read posts'", ")", "\n", "if", "len", "(", "posts", ")", "!=", "len", "(", "set", "(", "posts", ")", ")", ":", "\n", "            ", "print", "(", "\"dups found\"", ")", "\n", "post2counts", "=", "collections", ".", "Counter", "(", "posts", ")", "\n", "for", "post", ",", "count", "in", "post2counts", ".", "items", "(", ")", ":", "\n", "                ", "if", "count", ">", "1", ":", "\n", "                    ", "print", "(", "'--------------'", ")", "\n", "print", "(", "post", ")", "\n", "\n", "", "", "", "", "return", "order", ",", "util", ".", "embed_sentences", "(", "np", ".", "array", "(", "posts", ")", ",", "embedType", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.eval.check": [[47, 59], ["open", "ijson.items", "numpy.linalg.norm", "trues.append", "falses.append", "int", "int"], "function", ["None"], ["def", "check", "(", "testSetPath", ",", "order", ",", "embeddings", ")", ":", "\n", "    ", "with", "open", "(", "testSetPath", ",", "'r'", ")", "as", "testSet", ":", "\n", "        ", "for", "test", "in", "ijson", ".", "items", "(", "testSet", ",", "\"item\"", ")", ":", "\n", "            ", "srcEmbed", "=", "embeddings", "[", "order", "[", "int", "(", "test", "[", "0", "]", ")", "]", "]", "\n", "dstEmbed", "=", "embeddings", "[", "order", "[", "int", "(", "test", "[", "1", "]", ")", "]", "]", "\n", "\n", "linkedDist", "=", "np", ".", "linalg", ".", "norm", "(", "srcEmbed", "-", "dstEmbed", ")", "**", "2", "\n", "\n", "if", "test", "[", "2", "]", ":", "\n", "                ", "trues", ".", "append", "(", "linkedDist", ")", "\n", "", "else", ":", "\n", "                ", "falses", ".", "append", "(", "linkedDist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.get_id": [[18, 23], ["int", "int"], "function", ["None"], ["def", "get_id", "(", "post", ")", ":", "\n", "  ", "if", "'id:'", "in", "post", ":", "\n", "      ", "return", "int", "(", "post", "[", "'id:'", "]", ")", "\n", "", "else", ":", "\n", "      ", "return", "int", "(", "post", "[", "'id'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.get_ids": [[25, 27], ["question_ids.add", "dataset.get_id"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.get_id"], ["", "", "def", "get_ids", "(", "post", ",", "postHtml", ")", ":", "\n", "    ", "question_ids", ".", "add", "(", "get_id", "(", "post", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.process": [[32, 75], ["bs4.BeautifulSoup", "set", "bs4.BeautifulSoup.find_all", "bs4.BeautifulSoup.get_text", "all_text.add", "linked_ids.update", "test_set.extend", "len", "printed_ids.add", "ds.write", "a.get", "pattern.search", "ds.write", "json.dumps", "int", "pattern.search.group", "links.append", "a.decompose", "dataset.get_id", "set.add", "set.add", "tmp_test_set.append", "int", "int"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.get_id"], ["def", "process", "(", "post", ",", "postHtml", ",", "ds", ")", ":", "\n", "    ", "global", "first", "\n", "global", "all_text", "\n", "\n", "links", "=", "[", "]", "\n", "\n", "soup", "=", "BeautifulSoup", "(", "postHtml", ",", "'html.parser'", ")", "\n", "tmp_linked_ids", "=", "set", "(", ")", "\n", "tmp_test_set", "=", "[", "]", "\n", "for", "a", "in", "soup", ".", "find_all", "(", "'a'", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "link", "=", "a", ".", "get", "(", "'href'", ")", "\n", "url", "=", "pattern", ".", "search", "(", "link", ")", "\n", "if", "url", "is", "not", "None", ":", "\n", "                ", "tid", "=", "int", "(", "url", ".", "group", "(", "1", ")", ")", "\n", "if", "(", "tid", "in", "question_ids", ")", ":", "\n", "                    ", "links", ".", "append", "(", "link", ")", "\n", "a", ".", "decompose", "(", ")", "\n", "sid", "=", "get_id", "(", "post", ")", "\n", "tmp_linked_ids", ".", "add", "(", "int", "(", "sid", ")", ")", "\n", "tmp_linked_ids", ".", "add", "(", "int", "(", "tid", ")", ")", "\n", "tmp_test_set", ".", "append", "(", "(", "sid", ",", "tid", ",", "True", ")", ")", "\n", "", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "", "newPostHtml", "=", "soup", ".", "get_text", "(", ")", "\n", "if", "newPostHtml", "in", "all_text", ":", "\n", "      ", "return", "\n", "", "all_text", ".", "add", "(", "newPostHtml", ")", "\n", "linked_ids", ".", "update", "(", "tmp_linked_ids", ")", "\n", "test_set", ".", "extend", "(", "tmp_test_set", ")", "\n", "\n", "if", "len", "(", "links", ")", ">", "0", ":", "\n", "        ", "printed_ids", ".", "add", "(", "sid", ")", "\n", "\n", "\n", "out", "=", "{", "\"id\"", ":", "sid", ",", "\"text\"", ":", "newPostHtml", ",", "\"related\"", ":", "links", "}", "\n", "\n", "if", "first", ":", "\n", "            ", "first", "=", "False", "\n", "", "else", ":", "\n", "            ", "ds", ".", "write", "(", "','", ")", "\n", "", "ds", ".", "write", "(", "json", ".", "dumps", "(", "out", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.other_ids": [[77, 89], ["dataset.get_id", "ds.write", "ds.write", "json.dumps"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.get_id"], ["", "", "def", "other_ids", "(", "post", ",", "postHtml", ",", "ds", ")", ":", "\n", "    ", "global", "first", "\n", "id", "=", "get_id", "(", "post", ")", "\n", "if", "(", "id", "in", "unlinked_ids", ")", "or", "(", "id", "in", "linked_ids", "and", "not", "id", "in", "printed_ids", ")", ":", "\n", "\n", "        ", "out", "=", "{", "\"id\"", ":", "id", ",", "\"text\"", ":", "postHtml", ",", "\"related\"", ":", "[", "]", "}", "\n", "\n", "if", "first", ":", "\n", "            ", "first", "=", "False", "\n", "", "else", ":", "\n", "            ", "ds", ".", "write", "(", "','", ")", "\n", "", "ds", ".", "write", "(", "json", ".", "dumps", "(", "out", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.dataset": [[91, 99], ["open", "enumerate", "ijson.items", "dataset.process", "dataset.process"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.process", "home.repos.pwc.inspect_result.wala_blanca.ForumLinkPrediction.dataset.process"], ["", "", "def", "dataset", "(", "postsPath", ",", "process", ")", ":", "\n", "    ", "with", "open", "(", "postsPath", ",", "'r'", ")", "as", "posts", ":", "\n", "        ", "for", "i", ",", "post", "in", "enumerate", "(", "ijson", ".", "items", "(", "posts", ",", "\"item\"", ")", ")", ":", "\n", "            ", "postHtml", "=", "post", "[", "'text:'", "]", "\n", "process", "(", "post", ",", "postHtml", ")", "\n", "\n", "for", "answer", "in", "post", "[", "'answers'", "]", ":", "\n", "                ", "process", "(", "answer", ",", "answer", "[", "'text'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.USEModel.__init__": [[20, 23], ["tensorflow_hub.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "model_path", "=", "'https://tfhub.dev/google/universal-sentence-encoder/4'", "\n", "self", ".", "model", "=", "hub", ".", "load", "(", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.USEModel.encode": [[24, 26], ["utils.util.USEModel.model"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "sentences", ",", "batch_size", "=", "None", ",", "show_progress_bar", "=", "None", ",", "convert_to_numpy", "=", "True", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "sentences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.evaluate_classification": [[28, 63], ["util.get_model", "open", "json.load", "pandas.DataFrame", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "print", "print", "print", "util.embed_sentences", "util.embed_sentences", "distance.cosine", "cos_distance.append", "numpy.mean", "numpy.mean", "len", "scipy.stats.ttest_ind", "trues.append", "labels.append", "falses.append", "labels.append", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.wala_blanca.utils.util.get_model", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences"], ["", "", "def", "evaluate_classification", "(", "embed_type", ",", "model_path", ",", "dataSetPath", ",", "text1", ",", "text2", ",", "true_label", ",", "true_value", ")", ":", "\n", "    ", "model", "=", "get_model", "(", "embed_type", ",", "model_path", ")", "\n", "with", "open", "(", "dataSetPath", ",", "'r'", ",", "encoding", "=", "\"UTF-8\"", ")", "as", "data_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "\n", "trues", "=", "[", "]", "\n", "falses", "=", "[", "]", "\n", "cos_distance", "=", "[", "]", "\n", "\n", "labels", "=", "[", "]", "\n", "\n", "for", "jsonObject", "in", "data", ":", "\n", "            ", "srcEmbed", "=", "embed_sentences", "(", "[", "jsonObject", "[", "text1", "]", "]", ",", "model", ",", "embed_type", ")", "\n", "dstEmbed", "=", "embed_sentences", "(", "[", "jsonObject", "[", "text2", "]", "]", ",", "model", ",", "embed_type", ")", "\n", "from", "scipy", ".", "spatial", "import", "distance", "\n", "linkedDist", "=", "distance", ".", "cosine", "(", "srcEmbed", ",", "dstEmbed", ")", "\n", "cos_distance", ".", "append", "(", "linkedDist", ")", "\n", "\n", "if", "jsonObject", "[", "true_label", "]", "==", "true_value", ":", "\n", "                ", "trues", ".", "append", "(", "linkedDist", ")", "\n", "labels", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "falses", ".", "append", "(", "linkedDist", ")", "\n", "labels", ".", "append", "(", "0", ")", "\n", "\n", "", "", "out_df", "=", "pd", ".", "DataFrame", "(", "labels", ",", "columns", "=", "[", "'label'", "]", ")", "\n", "\n", "out_df", "[", "'embedding_cosine_distance'", "]", "=", "cos_distance", "\n", "out_df", ".", "to_csv", "(", "embed_type", "+", "'_test_with_embeddings_distances.csv'", ")", "\n", "print", "(", "np", ".", "mean", "(", "np", ".", "asarray", "(", "trues", ")", ")", ")", "\n", "print", "(", "np", ".", "mean", "(", "np", ".", "asarray", "(", "falses", ")", ")", ")", "\n", "\n", "print", "(", "'Total number of samples = '", ",", "len", "(", "data", ")", ")", "\n", "print", "(", "scipy", ".", "stats", ".", "ttest_ind", "(", "trues", ",", "falses", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.evaluate_regression": [[66, 95], ["pandas.DataFrame", "utils.util.build_index_docs", "df[].apply", "df[].apply", "range", "sklearn.linear_model.LinearRegression", "linear_model.LinearRegression.fit", "linear_model.LinearRegression.predict", "print", "print", "print", "scipy.stats.pearsonr", "print", "print", "out_df.to_csv", "json.load", "len", "distance.append", "df[].isin", "df[].isin", "scipy.spatial.distance.cosine", "sklearn.metrics.mean_squared_error", "sklearn.metrics.r2_score", "str", "str", "classesToDocs.keys", "classesToDocs.keys"], "function", ["home.repos.pwc.inspect_result.wala_blanca.utils.util.build_index_docs"], ["", "", "def", "evaluate_regression", "(", "f", ",", "docPath", ",", "embedType", ",", "model_dir", "=", "None", ")", ":", "\n", "    ", "df", "=", "pd", ".", "DataFrame", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "(", "index", ",", "docList", ",", "docsToClasses", ",", "embeddedDocText", ",", "classesToDocs", ",", "docToEmbedding", ")", "=", "util", ".", "build_index_docs", "(", "docPath", ",", "embedType", ",", "generate_dict", "=", "True", ",", "model_dir", "=", "model_dir", ")", "\n", "df", "=", "df", "[", "df", "[", "'class1'", "]", ".", "isin", "(", "classesToDocs", ".", "keys", "(", ")", ")", "]", "\n", "df", "=", "df", "[", "df", "[", "'class2'", "]", ".", "isin", "(", "classesToDocs", ".", "keys", "(", ")", ")", "]", "\n", "df", "[", "'embedding1'", "]", "=", "df", "[", "'class1'", "]", ".", "apply", "(", "lambda", "x", ":", "docToEmbedding", "[", "classesToDocs", "[", "x", "]", "]", ")", "\n", "df", "[", "'embedding2'", "]", "=", "df", "[", "'class2'", "]", ".", "apply", "(", "lambda", "x", ":", "docToEmbedding", "[", "classesToDocs", "[", "x", "]", "]", ")", "\n", "embed1", "=", "df", "[", "'embedding1'", "]", ".", "values", "\n", "embed2", "=", "df", "[", "'embedding2'", "]", ".", "values", "\n", "distance", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "embed1", ")", ")", ":", "\n", "        ", "distance", ".", "append", "(", "scipy", ".", "spatial", ".", "distance", ".", "cosine", "(", "embed1", "[", "idx", "]", ",", "embed2", "[", "idx", "]", ")", ")", "\n", "\n", "", "model", "=", "linear_model", ".", "LinearRegression", "(", ")", "\n", "new_df", "=", "df", "[", "[", "'distance'", "]", "]", "\n", "model", ".", "fit", "(", "new_df", ".", "iloc", "[", ":", "]", ",", "distance", ")", "\n", "y_pred", "=", "model", ".", "predict", "(", "new_df", ".", "iloc", "[", ":", "]", ")", "\n", "# The coefficients", "\n", "print", "(", "'Coefficients: \\n'", ",", "model", ".", "coef_", ")", "\n", "print", "(", "'Mean squared error: %.2f'", "%", "mean_squared_error", "(", "distance", ",", "y_pred", ")", ")", "\n", "# The coefficient of determination: 1 is perfect prediction", "\n", "print", "(", "'Coefficient of determination: %.2f'", "%", "r2_score", "(", "distance", ",", "y_pred", ")", ")", "\n", "\n", "corr", ",", "p_value", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "df", "[", "'distance'", "]", ".", "values", ",", "distance", ")", "\n", "print", "(", "'correlation:'", "+", "str", "(", "corr", ")", ")", "\n", "print", "(", "'p-value:'", "+", "str", "(", "p_value", ")", ")", "\n", "out_df", "=", "df", "[", "[", "'class1'", ",", "'class2'", ",", "'distance'", "]", "]", "\n", "out_df", "[", "'embedding_cosine_distance'", "]", "=", "distance", "\n", "out_df", ".", "to_csv", "(", "embedType", "+", "'_test_with_embeddings_distances.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.get_model": [[98, 130], ["util.USEModel", "torch.cuda.is_available", "sentence_transformers.SentenceTransformer.to", "print", "sentence_transformers.models.Transformer", "sentence_transformers.models.Pooling", "sentence_transformers.SentenceTransformer", "models.Transformer.get_word_embedding_dimension", "sentence_transformers.SentenceTransformer", "sentence_transformers.SentenceTransformer", "sentence_transformers.SentenceTransformer", "sentence_transformers.SentenceTransformer", "sentence_transformers.SentenceTransformer", "sentence_transformers.SentenceTransformer"], "function", ["None"], ["", "def", "get_model", "(", "embed_type", ",", "local_model_path", "=", "'/data/BERTOverflow'", ")", ":", "\n", "    ", "global", "embed", "\n", "if", "embed", ":", "\n", "        ", "return", "embed", "\n", "", "if", "embed_type", "==", "'USE'", ":", "\n", "        ", "embed", "=", "USEModel", "(", ")", "\n", "", "elif", "embed_type", "==", "'bertoverflow'", "or", "embed_type", "==", "'finetuned'", ":", "\n", "        ", "print", "(", "'Loading model from: '", ",", "local_model_path", ")", "\n", "word_embedding_model", "=", "models", ".", "Transformer", "(", "local_model_path", ",", "max_seq_length", "=", "256", ")", "\n", "pooling_model", "=", "models", ".", "Pooling", "(", "word_embedding_model", ".", "get_word_embedding_dimension", "(", ")", ")", "\n", "embed", "=", "SentenceTransformer", "(", "modules", "=", "[", "word_embedding_model", ",", "pooling_model", "]", ")", "\n", "", "elif", "embed_type", "==", "'bert'", ":", "\n", "        ", "model_path", "=", "'bert-base-nli-stsb-mean-tokens'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "elif", "embed_type", "==", "'roberta'", ":", "\n", "        ", "model_path", "=", "'roberta-base-nli-stsb-mean-tokens'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "elif", "embed_type", "==", "'distilbert'", ":", "\n", "        ", "model_path", "=", "'distilbert-base-nli-stsb-wkpooling'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "elif", "embed_type", "==", "'distilbert_para'", ":", "\n", "        ", "model_path", "=", "'distilroberta-base-paraphrase-v1'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "elif", "embed_type", "==", "'xlm'", ":", "\n", "        ", "model_path", "=", "'xlm-r-distilroberta-base-paraphrase-v1'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "elif", "embed_type", "==", "'msmacro'", ":", "\n", "        ", "model_path", "=", "'msmarco-distilroberta-base-v2'", "\n", "embed", "=", "SentenceTransformer", "(", "model_path", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "embed_type", "!=", "'USE'", ":", "\n", "        ", "embed", "=", "embed", ".", "to", "(", "'cuda'", ")", "\n", "", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.embed_sentences": [[131, 135], ["util.get_model", "get_model.encode"], "function", ["home.repos.pwc.inspect_result.wala_blanca.utils.util.get_model", "home.repos.pwc.inspect_result.wala_blanca.utils.util.USEModel.encode"], ["", "def", "embed_sentences", "(", "sentences", ",", "embed_type", ",", "model_dir", "=", "None", ")", ":", "\n", "    ", "embed", "=", "get_model", "(", "embed_type", ",", "model_dir", ")", "\n", "sentence_embeddings", "=", "embed", ".", "encode", "(", "sentences", ")", "\n", "return", "sentence_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.build_index_docs": [[136, 184], ["numpy.array", "numpy.array", "faiss.normalize_L2", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "open", "ijson.items", "list", "util.embed_sentences", "len", "enumerate", "bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "bs4.BeautifulSoup.get_text", "docsToClasses.keys", "code.decompose", "docClasses.append"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences"], ["", "def", "build_index_docs", "(", "docPath", ",", "embedType", ",", "valid_classes", "=", "None", ",", "generate_dict", "=", "False", ",", "model_dir", "=", "None", ")", ":", "\n", "    ", "classesToDocs", "=", "{", "}", "\n", "docsToClasses", "=", "{", "}", "\n", "embedList", "=", "{", "}", "\n", "\n", "with", "open", "(", "docPath", ",", "'r'", ")", "as", "data", ":", "\n", "        ", "jsonCollect", "=", "ijson", ".", "items", "(", "data", ",", "'item'", ")", "\n", "i", "=", "0", "\n", "for", "jsonObject", "in", "jsonCollect", ":", "\n", "            ", "if", "'class_docstring'", "not", "in", "jsonObject", ":", "\n", "                ", "continue", "\n", "", "className", "=", "jsonObject", "[", "'klass'", "]", "\n", "if", "valid_classes", "and", "className", "not", "in", "valid_classes", ":", "\n", "                ", "continue", "\n", "", "docStringText", "=", "jsonObject", "[", "'class_docstring'", "]", "\n", "\n", "soup", "=", "BeautifulSoup", "(", "docStringText", ",", "'html.parser'", ")", "\n", "for", "code", "in", "soup", ".", "find_all", "(", "'code'", ")", ":", "\n", "                ", "code", ".", "decompose", "(", ")", "# this whole block might be unnecessary", "\n", "", "docStringText", "=", "soup", ".", "get_text", "(", ")", "\n", "\n", "if", "docStringText", "in", "docsToClasses", ":", "\n", "                ", "docClasses", "=", "docsToClasses", "[", "docStringText", "]", "\n", "\n", "if", "className", "in", "docClasses", ":", "\n", "                    ", "pass", "\n", "\n", "", "else", ":", "\n", "                    ", "docClasses", ".", "append", "(", "className", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "docsToClasses", "[", "docStringText", "]", "=", "[", "className", "]", "\n", "\n", "", "classesToDocs", "[", "className", "]", "=", "docStringText", "\n", "\n", "", "", "docList", "=", "np", ".", "array", "(", "list", "(", "docsToClasses", ".", "keys", "(", ")", ")", ")", "\n", "embeddedDocText", "=", "np", ".", "array", "(", "embed_sentences", "(", "docList", ",", "embedType", ",", "model_dir", ")", ")", "\n", "faiss", ".", "normalize_L2", "(", "embeddedDocText", ")", "\n", "index", "=", "faiss", ".", "IndexFlatIP", "(", "len", "(", "embeddedDocText", "[", "0", "]", ")", ")", "\n", "index", ".", "add", "(", "embeddedDocText", ")", "\n", "\n", "if", "generate_dict", ":", "\n", "        ", "doc2embedding", "=", "{", "}", "\n", "for", "index", ",", "doc", "in", "enumerate", "(", "docList", ")", ":", "\n", "            ", "doc2embedding", "[", "doc", "]", "=", "embeddedDocText", "[", "index", "]", "\n", "", "return", "(", "index", ",", "docList", ",", "docsToClasses", ",", "embeddedDocText", ",", "classesToDocs", ",", "doc2embedding", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "index", ",", "docList", ",", "docsToClasses", ",", "embeddedDocText", ",", "classesToDocs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.utils.util.compute_neighbor_docstrings": [[186, 202], ["enumerate", "neighborDocstrings.append"], "function", ["None"], ["", "", "def", "compute_neighbor_docstrings", "(", "query_neighbors", ",", "docList", ")", ":", "\n", "    ", "docstringsToNeighbors", "=", "{", "}", "\n", "\n", "for", "docStringIndex", ",", "embeddedDocStringNeighbors", "in", "enumerate", "(", "query_neighbors", ")", ":", "\n", "        ", "docString", "=", "docList", "[", "docStringIndex", "]", "\n", "\n", "i", "=", "0", "\n", "neighborDocstrings", "=", "[", "]", "\n", "for", "neighborDocStringIndex", "in", "embeddedDocStringNeighbors", ":", "\n", "            ", "if", "i", "!=", "0", ":", "\n", "                ", "neighborDocstrings", ".", "append", "(", "docList", "[", "neighborDocStringIndex", "]", ")", "\n", "", "i", "=", "i", "+", "1", "\n", "\n", "", "docstringsToNeighbors", "[", "docString", "]", "=", "neighborDocstrings", "\n", "\n", "", "return", "docstringsToNeighbors", "\n", "", ""]], "home.repos.pwc.inspect_result.wala_blanca.ForumToClassDocumentation.generate_test_train.flatten": [[16, 26], ["bs4.BeautifulSoup", "result.append", "bs4.BeautifulSoup.get_text"], "function", ["None"], ["def", "flatten", "(", "d", ",", "result", ",", "label", ")", ":", "\n", "    ", "for", "p", "in", "d", ":", "\n", "        ", "obj", "=", "d", "[", "p", "]", "\n", "docstring", "=", "obj", "[", "'docstring'", "]", "\n", "for", "post", "in", "obj", "[", "'posts'", "]", ":", "\n", "            ", "text", "=", "post", "[", "'title'", "]", "+", "' '", "+", "post", "[", "'text'", "]", "\n", "for", "answer", "in", "post", "[", "'answers'", "]", ":", "\n", "                ", "text", "=", "text", "+", "' '", "+", "answer", "[", "'answer_text'", "]", "\n", "", "soup", "=", "BeautifulSoup", "(", "text", ")", "\n", "result", ".", "append", "(", "{", "'id'", ":", "id", ",", "'docstring'", ":", "docstring", ",", "'text'", ":", "soup", ".", "get_text", "(", ")", ",", "'label'", ":", "label", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences": [[22, 28], ["model.encode", "model.encode"], "function", ["home.repos.pwc.inspect_result.wala_blanca.utils.util.USEModel.encode", "home.repos.pwc.inspect_result.wala_blanca.utils.util.USEModel.encode"], ["def", "embed_sentences", "(", "sentences", ",", "model", ",", "embed_type", ")", ":", "\n", "    ", "if", "embed_type", "==", "'USE'", ":", "\n", "        ", "sentence_embeddings", "=", "model", ".", "encode", "(", "[", "sentences", "]", ")", "\n", "", "else", ":", "\n", "        ", "sentence_embeddings", "=", "model", ".", "encode", "(", "sentences", ")", "\n", "", "return", "sentence_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.get_embedding": [[29, 34], ["rank_answers.embed_sentences"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.embed_sentences"], ["", "def", "get_embedding", "(", "content", ",", "model", ",", "embed_type", ")", ":", "\n", "    ", "if", "content", "not", "in", "q_ans_embeddings", ":", "\n", "        ", "q_ans_embeddings", "[", "content", "]", "=", "embed_sentences", "(", "content", ",", "model", ",", "embed_type", ")", "\n", "\n", "", "return", "q_ans_embeddings", "[", "content", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.evaluate_task": [[35, 57], ["open", "set", "json.load", "print", "rank_answers.evaluate_MRR", "print", "rank_answers.evaluate_NDCG", "all_questions.append", "os.path.isdir", "os.makedirs", "set.add"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.evaluate_MRR", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.evaluate_NDCG"], ["", "def", "evaluate_task", "(", "data_path", ",", "model", ",", "embed_type", ")", ":", "\n", "    ", "all_questions", "=", "[", "]", "\n", "with", "open", "(", "data_path", ",", "'r'", ",", "encoding", "=", "\"UTF-8\"", ")", "as", "data_file", ":", "\n", "        ", "encounteredPosts", "=", "set", "(", ")", "\n", "data", "=", "json", ".", "load", "(", "data_file", ")", "\n", "i", "=", "0", "\n", "for", "q_data", "in", "data", ":", "\n", "            ", "stackUrl", "=", "q_data", "[", "'q_url'", "]", "\n", "if", "stackUrl", "in", "encounteredPosts", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "encounteredPosts", ".", "add", "(", "stackUrl", ")", "\n", "", "all_questions", ".", "append", "(", "q_data", ")", "\n", "i", "+=", "1", "\n", "\n", "", "folder_name", "=", "'/tmp/stackoverflow_embed_'", "+", "embed_type", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "folder_name", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "folder_name", ")", "\n", "", "print", "(", "\"Calculating MRR with model\"", ",", "embed_type", ")", "\n", "evaluate_MRR", "(", "all_questions", ",", "model", ",", "embed_type", ")", "\n", "print", "(", "\"Calculating NDCG with model\"", ",", "embed_type", ")", "\n", "evaluate_NDCG", "(", "all_questions", ",", "model", ",", "embed_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.evaluate_MRR": [[58, 125], ["tqdm.tqdm", "print", "print", "print", "print", "rank_answers.get_embedding", "float", "float", "enumerate", "enumerate", "voteOrder.sort", "voteOrder.reverse", "distanceOrder.sort", "sum", "len", "scipy.stats.sem", "rank_answers.get_embedding", "scipy.spatial.distance.cosine", "voteOrder.append", "distanceOrder.append", "len", "range", "int", "int", "numpy.linalg.norm", "euclid_distances_to_worst_answer.append", "cosine_distances_to_worst_answer.append", "len", "statistics.mean", "statistics.mean", "statistics.mean", "statistics.mean", "euclid_distances_to_best_answer.append", "cosine_distances_to_best_answer.append", "recipRanks.append"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.get_embedding", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.get_embedding"], ["", "", "def", "evaluate_MRR", "(", "data", ",", "model", ",", "embed_type", ")", ":", "\n", "    ", "recipRanks", "=", "[", "]", "\n", "if", "sample", ":", "\n", "        ", "data", "=", "data", "[", ":", "100", "]", "\n", "", "euclid_distances_to_best_answer", "=", "[", "]", "\n", "euclid_distances_to_worst_answer", "=", "[", "]", "\n", "cosine_distances_to_best_answer", "=", "[", "]", "\n", "cosine_distances_to_worst_answer", "=", "[", "]", "\n", "\n", "for", "question_data", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "q_embedding", "=", "get_embedding", "(", "question_data", "[", "'q_text'", "]", ",", "model", ",", "embed_type", ")", "\n", "\n", "voteOrder", "=", "[", "]", "\n", "distanceOrder", "=", "[", "]", "\n", "valid", "=", "True", "\n", "answerCollection", "=", "question_data", "[", "'answers'", "]", "\n", "min_vote", "=", "float", "(", "'inf'", ")", "\n", "max_vote", "=", "float", "(", "'-inf'", ")", "\n", "min_vote_idx", "=", "-", "1", "\n", "max_vote_idx", "=", "-", "1", "\n", "\n", "for", "idx", ",", "answer", "in", "enumerate", "(", "answerCollection", ")", ":", "\n", "            ", "answerVotes", "=", "int", "(", "answer", "[", "'a_votes'", "]", ")", "if", "answer", "[", "'a_votes'", "]", "!=", "''", "else", "None", "\n", "if", "answerVotes", ":", "\n", "                ", "if", "answerVotes", "<", "min_vote", ":", "\n", "                    ", "min_vote", "=", "answerVotes", "\n", "min_vote_idx", "=", "idx", "\n", "", "if", "answerVotes", ">", "max_vote", ":", "\n", "                    ", "max_vote", "=", "answerVotes", "\n", "max_vote_idx", "=", "idx", "\n", "", "", "", "for", "idx", ",", "answer", "in", "enumerate", "(", "answerCollection", ")", ":", "\n", "            ", "answerText", "=", "answer", "[", "'a_text'", "]", "\n", "answerVotes", "=", "int", "(", "answer", "[", "'a_votes'", "]", ")", "if", "answer", "[", "'a_votes'", "]", "!=", "''", "else", "0", "\n", "ans_embedding", "=", "get_embedding", "(", "answerText", ",", "model", ",", "embed_type", ")", "\n", "dist", "=", "np", ".", "linalg", ".", "norm", "(", "ans_embedding", "-", "q_embedding", ")", "**", "2", "\n", "cosine_dist", "=", "distance", ".", "cosine", "(", "ans_embedding", ",", "q_embedding", ")", "\n", "voteOrder", ".", "append", "(", "(", "answerVotes", ",", "answerText", ")", ")", "\n", "distanceOrder", ".", "append", "(", "(", "dist", ",", "answerText", ")", ")", "\n", "if", "idx", "==", "min_vote_idx", ":", "\n", "                ", "euclid_distances_to_worst_answer", ".", "append", "(", "dist", ")", "\n", "cosine_distances_to_worst_answer", ".", "append", "(", "cosine_dist", ")", "\n", "\n", "", "elif", "idx", "==", "max_vote_idx", ":", "\n", "                ", "euclid_distances_to_best_answer", ".", "append", "(", "dist", ")", "\n", "cosine_distances_to_best_answer", ".", "append", "(", "cosine_dist", ")", "\n", "\n", "", "", "if", "not", "voteOrder", ":", "\n", "            ", "continue", "\n", "", "voteOrder", ".", "sort", "(", ")", "\n", "voteOrder", ".", "reverse", "(", ")", "\n", "distanceOrder", ".", "sort", "(", ")", "\n", "\n", "if", "len", "(", "voteOrder", ")", "!=", "1", ":", "\n", "            ", "correctAnswer", "=", "voteOrder", "[", "0", "]", "[", "1", "]", "\n", "for", "x", "in", "range", "(", "0", ",", "len", "(", "distanceOrder", ")", ")", ":", "\n", "                ", "rank", "=", "x", "+", "1", "\n", "reciprocal", "=", "1", "/", "rank", "\n", "if", "distanceOrder", "[", "x", "]", "[", "1", "]", "==", "correctAnswer", ":", "\n", "                    ", "recipRanks", ".", "append", "(", "reciprocal", ")", "\n", "break", "\n", "\n", "", "", "", "", "meanRecipRank", "=", "sum", "(", "recipRanks", ")", "/", "len", "(", "recipRanks", ")", "\n", "print", "(", "'MRR: standard error of the mean '", ",", "stat", ".", "sem", "(", "recipRanks", ")", ")", "\n", "print", "(", "\"Mean reciprocal rank is:\"", ",", "meanRecipRank", ")", "\n", "print", "(", "f\"Average distance from question to best answer (highest votes): euclid = {statistics.mean(euclid_distances_to_best_answer)}, \"", "\n", "f\"cosine = {statistics.mean(cosine_distances_to_best_answer)}\"", ")", "\n", "print", "(", "f\"Average distance from question to worst answer (lowest votes):euclid = {statistics.mean(euclid_distances_to_worst_answer)}, \"", "\n", "f\"cosine = {statistics.mean(cosine_distances_to_worst_answer)}\"", ")", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.evaluate_NDCG": [[127, 175], ["tqdm.tqdm", "print", "print", "rank_answers.get_embedding", "voteOrder.sort", "voteOrder.reverse", "distanceOrder.sort", "sum", "len", "scipy.stats.sem", "rank_answers.get_embedding", "voteOrder.append", "distanceOrder.append", "len", "int", "numpy.linalg.norm", "math.log2", "math.log2", "coefficients.append"], "function", ["home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.get_embedding", "home.repos.pwc.inspect_result.wala_blanca.ForumAnswerRanking.rank_answers.get_embedding"], ["", "def", "evaluate_NDCG", "(", "data", ",", "model", ",", "embed_type", ")", ":", "\n", "    ", "coefficients", "=", "[", "]", "\n", "if", "sample", ":", "\n", "        ", "data", "=", "data", "[", ":", "100", "]", "\n", "", "for", "question_data", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "q_embedding", "=", "get_embedding", "(", "question_data", "[", "'q_text'", "]", ",", "model", ",", "embed_type", ")", "\n", "\n", "voteOrder", "=", "[", "]", "\n", "distanceOrder", "=", "[", "]", "\n", "voteMap", "=", "{", "}", "\n", "answerCollection", "=", "question_data", "[", "'answers'", "]", "\n", "for", "answer", "in", "answerCollection", ":", "\n", "            ", "answerText", "=", "answer", "[", "'a_text'", "]", "\n", "answerVotes", "=", "int", "(", "answer", "[", "'a_votes'", "]", ")", "if", "answer", "[", "'a_votes'", "]", "!=", "''", "else", "0", "\n", "ans_embedding", "=", "get_embedding", "(", "answerText", ",", "model", ",", "embed_type", ")", "\n", "dist", "=", "np", ".", "linalg", ".", "norm", "(", "ans_embedding", "-", "q_embedding", ")", "**", "2", "\n", "voteOrder", ".", "append", "(", "(", "answerVotes", ",", "answerText", ")", ")", "\n", "distanceOrder", ".", "append", "(", "(", "dist", ",", "answerText", ")", ")", "\n", "voteMap", "[", "answerText", "]", "=", "answerVotes", "\n", "\n", "", "if", "not", "voteOrder", ":", "\n", "            ", "continue", "\n", "", "voteOrder", ".", "sort", "(", ")", "\n", "voteOrder", ".", "reverse", "(", ")", "\n", "distanceOrder", ".", "sort", "(", ")", "\n", "if", "len", "(", "voteOrder", ")", "!=", "1", ":", "\n", "            ", "i", "=", "1", "\n", "workingDCG", "=", "0", "\n", "for", "distanceAnswer", "in", "distanceOrder", ":", "\n", "                ", "rel", "=", "voteMap", "[", "distanceAnswer", "[", "1", "]", "]", "\n", "normal", "=", "math", ".", "log2", "(", "i", "+", "1", ")", "\n", "totalAdd", "=", "rel", "/", "normal", "\n", "workingDCG", "+=", "totalAdd", "\n", "i", "+=", "1", "\n", "", "i", "=", "1", "\n", "workingIDCG", "=", "0", "\n", "for", "voteAnswer", "in", "voteOrder", ":", "\n", "                ", "rel", "=", "voteAnswer", "[", "0", "]", "\n", "normal", "=", "math", ".", "log2", "(", "i", "+", "1", ")", "\n", "totalAdd", "=", "rel", "/", "normal", "\n", "workingIDCG", "+=", "totalAdd", "\n", "i", "+=", "1", "\n", "", "if", "workingIDCG", "!=", "0", ":", "\n", "                ", "nDCG", "=", "workingDCG", "/", "workingIDCG", "\n", "coefficients", ".", "append", "(", "nDCG", ")", "\n", "", "", "", "fullNDCG", "=", "sum", "(", "coefficients", ")", "/", "len", "(", "coefficients", ")", "\n", "print", "(", "'NDCG: standard error of the mean '", ",", "stat", ".", "sem", "(", "coefficients", ")", ")", "\n", "print", "(", "\"Average NDCG:\"", ",", "fullNDCG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.usageAnalysis.staticAnalysis_regression.build_class_mapping": [[12, 22], ["open", "line.rstrip().split", "len", "line.rstrip"], "function", ["None"], ["def", "build_class_mapping", "(", "mapPath", ")", ":", "\n", "    ", "classMap", "=", "{", "}", "\n", "with", "open", "(", "mapPath", ",", "'r'", ")", "as", "inputFile", ":", "\n", "        ", "for", "line", "in", "inputFile", ":", "\n", "            ", "lineComponents", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "lineComponents", ")", "<", "2", ":", "\n", "                ", "classMap", "[", "lineComponents", "[", "0", "]", "]", "=", "lineComponents", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "classMap", "[", "lineComponents", "[", "0", "]", "]", "=", "lineComponents", "[", "1", "]", "\n", "", "", "", "return", "classMap", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.usageAnalysis.staticAnalysis_regression.check": [[24, 27], ["print"], "function", ["None"], ["", "def", "check", "(", "data", ",", "v", ")", ":", "\n", "    ", "print", "(", "v", ")", "\n", "assert", "v", "in", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.usageAnalysis.dataset.histedges_equalN": [[8, 15], ["sorted", "math.ceil", "range", "len", "binned_data.append", "len"], "function", ["None"], ["question_ids", "=", "set", "(", ")", "\n", "linked_ids", "=", "set", "(", ")", "\n", "unlinked_ids", "=", "set", "(", ")", "\n", "test_set", "=", "[", "]", "\n", "all_text", "=", "set", "(", "[", "]", ")", "\n", "\n", "printed_ids", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.usageAnalysis.dataset.capture_characteristics": [[16, 21], ["numpy.asarray", "print", "print", "print", "str", "str", "str", "numpy.mean", "numpy.amin", "numpy.amax"], "function", ["None"], ["first", "=", "True", "\n", "\n", "def", "get_id", "(", "post", ")", ":", "\n", "  ", "if", "'id:'", "in", "post", ":", "\n", "      ", "return", "int", "(", "post", "[", "'id:'", "]", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.hierarchyAnalysis.correlation_eval.sample_related_classes": [[11, 55], ["open", "networkx.Graph", "print", "dict", "open", "pickle.dump", "line.split", "arr[].strip", "[].strip", "networkx.all_pairs_shortest_path", "len", "len", "arr[].strip.split", "mod2classes[].append", "nx.Graph.nodes", "nx.Graph.add_node", "nx.Graph.nodes", "nx.Graph.add_node", "nx.Graph.add_edge", "len_to_relation[].append", "[].strip.split", "len", "len"], "function", ["None"], ["def", "sample_related_classes", "(", "class2superclasses", ",", "valid_classes", ")", ":", "\n", "    ", "mod2classes", "=", "{", "}", "\n", "with", "open", "(", "class2superclasses", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "arr", "=", "line", ".", "split", "(", "','", ")", "\n", "clazz", "=", "arr", "[", "0", "]", ".", "strip", "(", ")", "\n", "if", "len", "(", "arr", "[", "1", "]", ")", "<", "len", "(", "'http://purl.org/twc/graph4code/python/'", ")", ":", "\n", "                ", "continue", "\n", "", "superclazz", "=", "arr", "[", "1", "]", "[", "len", "(", "'http://purl.org/twc/graph4code/python/'", ")", ":", "]", ".", "strip", "(", ")", "\n", "if", "clazz", "not", "in", "valid_classes", "or", "superclazz", "not", "in", "valid_classes", ":", "\n", "                ", "continue", "\n", "", "module", "=", "clazz", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "superclazz", ".", "split", "(", "'.'", ")", "[", "0", "]", "==", "module", ":", "\n", "                ", "if", "module", "not", "in", "mod2classes", ":", "\n", "                    ", "mod2classes", "[", "module", "]", "=", "[", "]", "\n", "", "mod2classes", "[", "module", "]", ".", "append", "(", "(", "clazz", ",", "superclazz", ")", ")", "\n", "\n", "", "", "", "len_to_relation", "=", "{", "}", "\n", "for", "module", "in", "mod2classes", ":", "\n", "        ", "classgraph", "=", "nx", ".", "Graph", "(", ")", "\n", "for", "edge", "in", "mod2classes", "[", "module", "]", ":", "\n", "            ", "clazz", "=", "edge", "[", "0", "]", "\n", "superclazz", "=", "edge", "[", "1", "]", "\n", "if", "clazz", "not", "in", "classgraph", ".", "nodes", "(", ")", ":", "\n", "                ", "classgraph", ".", "add_node", "(", "clazz", ")", "\n", "", "if", "superclazz", "not", "in", "classgraph", ".", "nodes", "(", ")", ":", "\n", "                ", "classgraph", ".", "add_node", "(", "superclazz", ")", "\n", "", "if", "superclazz", "!=", "'object'", ":", "\n", "                ", "classgraph", ".", "add_edge", "(", "clazz", ",", "superclazz", ")", "\n", "", "", "print", "(", "'starting sp computation:'", "+", "module", ")", "\n", "sp", "=", "dict", "(", "nx", ".", "all_pairs_shortest_path", "(", "classgraph", ",", "cutoff", "=", "10", ")", ")", "\n", "\n", "for", "source", "in", "sp", ":", "\n", "            ", "for", "target", "in", "sp", "[", "source", "]", ":", "\n", "                ", "if", "source", "==", "target", ":", "\n", "                    ", "continue", "\n", "", "dist", "=", "len", "(", "sp", "[", "source", "]", "[", "target", "]", ")", "-", "1", "\n", "if", "dist", "not", "in", "len_to_relation", ":", "\n", "                    ", "len_to_relation", "[", "dist", "]", "=", "[", "]", "\n", "", "len_to_relation", "[", "dist", "]", ".", "append", "(", "(", "source", ",", "target", ")", ")", "\n", "\n", "", "", "", "with", "open", "(", "'shortest_paths.pickle'", ",", "'wb'", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "len_to_relation", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "return", "len_to_relation", "\n", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.hierarchyAnalysis.dataset.sample_related_classes": [[14, 58], ["open", "networkx.Graph", "print", "dict", "open", "pickle.dump", "line.split", "arr[].strip", "[].strip", "networkx.all_pairs_shortest_path", "len", "len", "arr[].strip.split", "mod2classes[].append", "nx.Graph.nodes", "nx.Graph.add_node", "nx.Graph.nodes", "nx.Graph.add_node", "nx.Graph.add_edge", "len_to_relation[].append", "[].strip.split", "len", "len"], "function", ["None"], ["printed_ids", "=", "set", "(", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "def", "get_id", "(", "post", ")", ":", "\n", "  ", "if", "'id:'", "in", "post", ":", "\n", "      ", "return", "int", "(", "post", "[", "'id:'", "]", ")", "\n", "", "else", ":", "\n", "      ", "return", "int", "(", "post", "[", "'id'", "]", ")", "\n", "\n", "\n", "", "", "def", "get_ids", "(", "post", ",", "postHtml", ")", ":", "\n", "    ", "question_ids", ".", "add", "(", "get_id", "(", "post", ")", ")", "\n", "\n", "\n", "", "matchString", "=", "'stackoverflow[.]com[/]questions[/](\\d+)[/]'", "\n", "pattern", "=", "re", ".", "compile", "(", "matchString", ")", "\n", "\n", "def", "process", "(", "post", ",", "postHtml", ",", "ds", ")", ":", "\n", "    ", "global", "first", "\n", "global", "all_text", "\n", "\n", "links", "=", "[", "]", "\n", "\n", "soup", "=", "BeautifulSoup", "(", "postHtml", ",", "'html.parser'", ")", "\n", "tmp_linked_ids", "=", "set", "(", ")", "\n", "tmp_test_set", "=", "[", "]", "\n", "for", "a", "in", "soup", ".", "find_all", "(", "'a'", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "link", "=", "a", ".", "get", "(", "'href'", ")", "\n", "url", "=", "pattern", ".", "search", "(", "link", ")", "\n", "if", "url", "is", "not", "None", ":", "\n", "                ", "tid", "=", "int", "(", "url", ".", "group", "(", "1", ")", ")", "\n", "if", "(", "tid", "in", "question_ids", ")", ":", "\n", "                    ", "links", ".", "append", "(", "link", ")", "\n", "a", ".", "decompose", "(", ")", "\n", "sid", "=", "get_id", "(", "post", ")", "\n", "tmp_linked_ids", ".", "add", "(", "int", "(", "sid", ")", ")", "\n", "tmp_linked_ids", ".", "add", "(", "int", "(", "tid", ")", ")", "\n", "tmp_test_set", ".", "append", "(", "(", "sid", ",", "tid", ",", "True", ")", ")", "\n", "", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "", "newPostHtml", "=", "soup", ".", "get_text", "(", ")", "\n", "if", "newPostHtml", "in", "all_text", ":", "\n"]], "home.repos.pwc.inspect_result.wala_blanca.hierarchyAnalysis.hierarchy_stats.read_valid_classes": [[9, 21], ["set", "open", "open", "line.strip.split", "line.strip.strip", "set.add", "len", "set.add"], "function", ["None"], ["def", "read_valid_classes", "(", "classmap", ",", "classfail", ")", ":", "\n", "    ", "realclasses", "=", "set", "(", ")", "\n", "with", "open", "(", "classmap", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "arr", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "arr", ")", ">", "1", ":", "\n", "                ", "realclasses", ".", "add", "(", "arr", "[", "1", "]", ")", "\n", "", "", "", "with", "open", "(", "classfail", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "realclasses", ".", "add", "(", "line", ")", "\n", "", "", "return", "realclasses", "\n", "\n"]]}