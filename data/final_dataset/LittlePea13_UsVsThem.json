{"home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.RedditDataset.__init__": [[15, 33], ["pandas.read_csv", "dataloader_regression.RedditDataset.comments[].values.tolist", "list", "le_aux.fit", "le_aux.transform"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_csv", "=", "'file.csv'", ",", "aux_task", "=", "'group'", ",", "le", "=", "None", ",", "le_aux", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"", "\n", "self", ".", "comments", "=", "pd", ".", "read_csv", "(", "data_csv", ")", "\n", "if", "aux_task", "==", "'None'", ":", "\n", "            ", "aux_task", "=", "'group'", "\n", "", "if", "aux_task", "==", "'emotions'", ":", "\n", "#self.comments.loc[self.comments[aux_task].isna(), aux_task] = 'Neutral'", "\n", "            ", "self", ".", "comments", "[", "'label_aux'", "]", "=", "self", ".", "comments", "[", "[", "'Anger'", ",", "'Contempt'", ",", "'Disgust'", ",", "'Fear'", ",", "'Hope'", ",", "'Pride'", ",", "'Sympathy'", ",", "'Emotions_Neutral'", "]", "]", ".", "values", ".", "tolist", "(", ")", "\n", "self", ".", "columns", "=", "list", "(", "self", ".", "comments", "[", "[", "'Anger'", ",", "'Contempt'", ",", "'Disgust'", ",", "'Fear'", ",", "'Hope'", ",", "'Pride'", ",", "'Sympathy'", ",", "'Emotions_Neutral'", "]", "]", ".", "columns", ")", "\n", "", "else", ":", "\n", "            ", "le_aux", ".", "fit", "(", "self", ".", "comments", "[", "aux_task", "]", ".", "values", ")", "\n", "self", ".", "comments", "[", "'label_aux'", "]", "=", "le_aux", ".", "transform", "(", "self", ".", "comments", "[", "aux_task", "]", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.RedditDataset.__len__": [[34, 36], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "comments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.RedditDataset.__getitem__": [[37, 39], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "comments", ".", "iloc", "[", "idx", "]", "[", "[", "'body'", ",", "'label_aux'", ",", "'group'", ",", "'bias'", ",", "'usVSthem_scale'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.MyCollator.__init__": [[47, 50], ["transformers.AutoTokenizer.from_pretrained"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "max_length", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "max_length", "=", "max_length", "\n", "", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.MyCollator.__call__": [[50, 58], ["dataloader_regression.MyCollator.tokenizer", "torch.tensor", "torch.tensor", "re.sub"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "output", "=", "{", "}", "\n", "texts", "=", "[", "re", ".", "sub", "(", "r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'", ",", "'LINK'", ",", "comment", "[", "'body'", "]", ",", "\n", "flags", "=", "re", ".", "MULTILINE", ")", "for", "comment", "in", "batch", "]", "\n", "tokenized", "=", "self", ".", "tokenizer", "(", "texts", ",", "padding", "=", "'longest'", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_length", ",", "return_tensors", "=", "'pt'", ",", "add_special_tokens", "=", "True", ")", "\n", "output", "[", "'labels'", "]", "=", "torch", ".", "tensor", "(", "[", "element", "[", "'usVSthem_scale'", "]", "for", "element", "in", "batch", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "output", "[", "'labels_aux'", "]", "=", "torch", ".", "tensor", "(", "[", "element", "[", "'label_aux'", "]", "for", "element", "in", "batch", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "return", "tokenized", ".", "data", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.pad_seq": [[41, 45], ["len"], "function", ["None"], ["", "", "def", "pad_seq", "(", "seq", ",", "max_batch_len", ",", "pad_value", ")", ":", "\n", "# IRL, use pad_sequence", "\n", "# https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pad_sequence.html", "\n", "    ", "return", "seq", "+", "(", "max_batch_len", "-", "len", "(", "seq", ")", ")", "*", "[", "pad_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader_regression.sentiment_analysis_dataset": [[60, 80], ["dataloader_regression.RedditDataset", "dataloader_regression.RedditDataset", "dataloader_regression.RedditDataset"], "function", ["None"], ["", "", "def", "sentiment_analysis_dataset", "(", "\n", "hparams", ":", "HyperOptArgumentParser", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads the Dataset from the csv files passed to the parser.\n    :param hparams: HyperOptArgumentParser obj containg the path to the data files.\n    :param train: flag to return the train set.\n    :param val: flag to return the validation set.\n    :param test: flag to return the test set.\n\n    Returns:\n        - Training Dataset, Development Dataset, Testing Dataset\n    \"\"\"", "\n", "if", "train", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "train_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "if", "val", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "dev_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "if", "test", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "test_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.__init__": [[32, 51], ["pytorch_lightning.LightningModule.__init__", "bert_classifier.BERTClassifier.__build_model", "bert_classifier.BERTClassifier.__build_loss", "dataloader.MyCollator", "type", "argparse.Namespace", "bert_classifier.BERTClassifier.freeze_encoder"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_model", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_loss", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.freeze_encoder"], ["def", "__init__", "(", "self", ",", "hparams", ":", "HyperOptArgumentParser", ")", "->", "None", ":", "\n", "        ", "super", "(", "BERTClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "hparams", ")", "==", "dict", ":", "\n", "            ", "hparams", "=", "argparse", ".", "Namespace", "(", "**", "hparams", ")", "\n", "", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "\n", "# build model", "\n", "self", ".", "__build_model", "(", ")", "\n", "\n", "# Loss criterion initialization.", "\n", "self", ".", "__build_loss", "(", ")", "\n", "if", "hparams", ".", "nr_frozen_epochs", ">", "0", ":", "\n", "            ", "self", ".", "freeze_encoder", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_frozen", "=", "False", "\n", "", "self", ".", "nr_frozen_epochs", "=", "hparams", ".", "nr_frozen_epochs", "\n", "self", ".", "model_name", "=", "hparams", ".", "encoder_model", "\n", "self", ".", "prepare_sample", "=", "MyCollator", "(", "self", ".", "model_name", ",", "hparams", ".", "max_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.__build_model": [[52, 81], ["sklearn.preprocessing.LabelEncoder", "pandas.concat", "comments[].apply", "bert_classifier.BERTClassifier.hparams.le.fit", "bert_classifier.BERTClassifier.hparams.le.transform", "sklearn.preprocessing.LabelEncoder", "bert_classifier.BERTClassifier.hparams.le_aux.fit", "Transformer.RedditTransformer", "torch.Parameter", "torch.Parameter", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "len", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "Transformer.RedditTransformer", "torch.Parameter", "torch.Parameter", "sklearn.preprocessing.LabelEncoder", "Transformer.RedditTransformer", "comments[].isna", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len"], "methods", ["None"], ["", "def", "__build_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" Init BERT model + tokenizer + classification head.\"\"\"", "\n", "'''self.bert = AutoModel.from_pretrained(\n            self.hparams.encoder_model\n        )'''", "\n", "self", ".", "hparams", ".", "le", "=", "LabelEncoder", "(", ")", "\n", "\n", "comments", "=", "pd", ".", "concat", "(", "[", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "train_csv", ")", ",", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "dev_csv", ")", ",", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "test_csv", ")", "]", ")", "\n", "comments", "=", "comments", "[", "~", "comments", "[", "'is_Disc_Crit'", "]", ".", "isna", "(", ")", "]", "\n", "comments", "[", "'raw_label'", "]", "=", "comments", "[", "'is_Disc_Crit'", "]", ".", "apply", "(", "lambda", "x", ":", "'Against'", "if", "x", "==", "True", "else", "'For'", ")", "\n", "self", ".", "hparams", ".", "le", ".", "fit", "(", "comments", "[", "'raw_label'", "]", ")", "\n", "comments", "[", "'label'", "]", "=", "self", ".", "hparams", ".", "le", ".", "transform", "(", "comments", "[", "'raw_label'", "]", ")", "\n", "self", ".", "hparams", ".", "le_aux", "=", "LabelEncoder", "(", ")", "\n", "# self.class_weights = torch.tensor(class_weight.compute_class_weight('balanced',", "\n", "#                                                 np.unique(comments['Binary_populism']),", "\n", "#                                                 comments['Binary_populism']), dtype=torch.float)", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "#self.hparams.aux_task = 'group'", "\n", "            ", "self", ".", "hparams", ".", "le_aux", ".", "fit", "(", "comments", "[", "self", ".", "hparams", ".", "aux_task", "]", ".", "values", ")", "\n", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "len", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "len", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1", "+", "self", ".", "hparams", ".", "loss_aux", ",", "1", "-", "self", ".", "hparams", ".", "loss_aux", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "alpha", "=", "0.5", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "len", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "8", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1", "+", "self", ".", "hparams", ".", "loss_aux", ",", "1", "-", "self", ".", "hparams", ".", "loss_aux", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "alpha", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "self", ".", "hparams", ".", "le_aux", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "len", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.__build_loss": [[82, 91], ["torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.L1Loss", "torch.L1Loss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["None"], ["", "", "def", "__build_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initializes the loss function/s. \"\"\"", "\n", "# self._loss = nn.CrossEntropyLoss(self.class_weights)", "\n", "self", ".", "_loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "self", ".", "_loss_aux", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_loss_aux", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "self", ".", "_Gradloss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.unfreeze_encoder": [[93, 100], ["log.info", "bert_classifier.BERTClassifier.model.encoder.parameters"], "methods", ["None"], ["", "def", "unfreeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" un-freezes the encoder layer. \"\"\"", "\n", "if", "self", ".", "_frozen", ":", "\n", "            ", "log", ".", "info", "(", "f\"\\n-- Encoder model fine-tuning\"", ")", "\n", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "", "self", ".", "_frozen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.freeze_encoder": [[101, 108], ["bert_classifier.BERTClassifier.model.encoder.parameters", "bert_classifier.BERTClassifier.model.encoder.encoder.layer[].output.parameters"], "methods", ["None"], ["", "", "def", "freeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" freezes the encoder layer. \"\"\"", "\n", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "True", "\n", "", "self", ".", "_frozen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.predict": [[109, 130], ["bert_classifier.BERTClassifier.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_classifier.BERTClassifier.prepare_sample", "bert_classifier.BERTClassifier.forward", "model_out[].numpy", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward"], ["", "def", "predict", "(", "self", ",", "sample", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Predict function.\n        :param sample: dictionary with the text we want to classify.\n\n        Returns:\n            Dictionary with the input text and the predicted label.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_input", "=", "self", ".", "prepare_sample", "(", "[", "sample", "]", ")", "\n", "model_out", "=", "self", ".", "forward", "(", "model_input", ")", "\n", "logits", "=", "model_out", "[", "\"logits\"", "]", ".", "numpy", "(", ")", "\n", "predicted_labels", "=", "[", "\n", "self", ".", "label_encoder", ".", "index_to_token", "[", "prediction", "]", "\n", "for", "prediction", "in", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "]", "\n", "sample", "[", "\"predicted_label\"", "]", "=", "predicted_labels", "[", "0", "]", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.forward": [[131, 145], ["bert_classifier.BERTClassifier.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Usual pytorch forward function.\n        :param tokens: text sequences [batch_size x src_seq_len]\n        :param lengths: source lengths [batch_size]\n\n        Returns:\n            Dictionary with model outputs (e.g: logits)\n        \"\"\"", "\n", "# print('forward', tokens['input_ids'].shape)", "\n", "# print('tree_sizes', tokens['tree_sizes'])", "\n", "# print('node_order', tokens['node_order'])", "\n", "logits", ",", "logits_aux", ",", "_", "=", "self", ".", "model", "(", "tokens", ")", "\n", "\n", "return", "{", "\"logits\"", ":", "logits", ",", "\"logits_aux\"", ":", "logits_aux", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.loss": [[146, 166], ["bert_classifier.BERTClassifier._loss", "bert_classifier.BERTClassifier._loss_aux", "bert_classifier.BERTClassifier._loss_aux", "targets[].type"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "predictions", ":", "dict", ",", "targets", ":", "dict", ")", "->", "torch", ".", "tensor", ":", "\n", "        ", "\"\"\"\n        Computes Loss value according to a loss function.\n        :param predictions: model specific output. Must contain a key 'logits' with\n            a tensor [batch_size x 1] with model predictions\n        :param labels: Label values [batch_size]\n\n        Returns:\n            torch.tensor with loss value.\n        \"\"\"", "\n", "# print('targets', targets)", "\n", "# print('predictions', predictions[\"logits\"].shape)", "\n", "loss", "=", "self", ".", "_loss", "(", "predictions", "[", "\"logits\"", "]", ",", "targets", "[", "\"labels\"", "]", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ")", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_loss_aux", "(", "predictions", "[", "\"logits_aux\"", "]", ",", "targets", "[", "\"labels_aux\"", "]", ")", "\n", "return", "loss", ",", "loss_aux", "#*self.hparams.loss_aux", "\n", "", "elif", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_loss_aux", "(", "predictions", "[", "\"logits_aux\"", "]", ",", "targets", "[", "\"labels_aux\"", "]", ".", "type", "(", "torch", ".", "long", ")", ")", "\n", "return", "loss", ",", "loss_aux", "\n", "", "return", "loss", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.backward": [[167, 201], ["loss_val.sum", "loss_val.sum.backward", "list", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_classifier.BERTClassifier.model.encoder.encoder.layer[].output.parameters", "loss.flatten", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.stack.append", "torch.stack.append", "loss.detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "loss_val.sum", "loss_val.sum.backward", "loss.backward", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "loss_ratios.mean", "torch.stack.mean", "torch.stack.mean"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward"], ["", "def", "backward", "(", "self", ",", "use_amp", ",", "loss", ",", "optimizer", ",", "idx_opt", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", "and", "self", ".", "hparams", ".", "gradnorm", "==", "True", ":", "\n", "            ", "loss_val", "=", "self", ".", "weights", "*", "loss", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "total_weighted_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "weights", ".", "grad", "=", "0.0", "*", "self", ".", "weights", ".", "grad", "\n", "W", "=", "list", "(", "self", ".", "model", ".", "encoder", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "parameters", "(", ")", ")", "\n", "norms", "=", "[", "]", "\n", "for", "w_i", ",", "L_i", "in", "zip", "(", "self", ".", "weights", ",", "loss", ".", "flatten", "(", ")", ")", ":", "\n", "# gradient of L_i(t) w.r.t. W", "\n", "                ", "gLgW", "=", "torch", ".", "autograd", ".", "grad", "(", "L_i", ",", "W", ",", "retain_graph", "=", "True", ")", "\n", "\n", "# G^{(i)}_W(t)", "\n", "norms", ".", "append", "(", "torch", ".", "norm", "(", "w_i", "*", "gLgW", "[", "0", "]", ")", ")", "\n", "", "norms", "=", "torch", ".", "stack", "(", "norms", ")", "\n", "if", "self", ".", "trainer", ".", "global_step", "==", "0", ":", "\n", "                ", "self", ".", "initial_losses", "=", "loss", ".", "detach", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# loss ratios \\curl{L}(t)", "\n", "                ", "loss_ratios", "=", "loss", "/", "self", ".", "initial_losses", "\n", "\n", "# inverse training rate r(t)", "\n", "inverse_train_rates", "=", "loss_ratios", "/", "loss_ratios", ".", "mean", "(", ")", "\n", "\n", "constant_term", "=", "norms", ".", "mean", "(", ")", "*", "(", "inverse_train_rates", "**", "self", ".", "alpha", ")", "\n", "# write out the gradnorm loss L_grad and set the weight gradients", "\n", "", "grad_norm_loss", "=", "(", "norms", "-", "constant_term", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "self", ".", "weights", ".", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "grad_norm_loss", ",", "self", ".", "weights", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "loss_val", "=", "self", ".", "weights", "*", "loss", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "total_weighted_loss", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.optimizer_step": [[202, 217], ["optimizer.zero_grad", "xm.optimizer_step", "isinstance", "optimizer.step", "optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.Parameter().to", "torch.Parameter().to", "len", "bert_classifier.BERTClassifier.weights.sum", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.optimizer_step"], ["", "", "def", "optimizer_step", "(", "self", ",", "epoch", ",", "batch_idx", ",", "optimizer", ",", "optimizer_idx", ",", "lambda_closure", ",", "using_native_amp", ")", ":", "\n", "        ", "if", "self", ".", "trainer", ".", "use_tpu", "and", "XLA_AVAILABLE", ":", "\n", "            ", "xm", ".", "optimizer_step", "(", "optimizer", ")", "\n", "", "elif", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "LBFGS", ")", ":", "\n", "            ", "optimizer", ".", "step", "(", "lambda_closure", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "epoch", ">", "self", ".", "hparams", ".", "warmup_aux", ":", "\n", "                    ", "self", ".", "weights", ".", "data", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1.99", ",", "0.01", "]", ")", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "self", ".", "weights", ".", "device", ")", "\n", "", "normalize_coeff", "=", "len", "(", "self", ".", "weights", ")", "/", "self", ".", "weights", ".", "sum", "(", ")", "\n", "self", ".", "weights", ".", "data", "=", "self", ".", "weights", ".", "data", "*", "normalize_coeff", "\n", "# clear gradients", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.training_step": [[218, 265], ["bert_classifier.BERTClassifier.forward", "bert_classifier.BERTClassifier.loss", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "collections.OrderedDict", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_classifier.BERTClassifier.sum", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "val_acc.unsqueeze.unsqueeze.cuda", "total_weighted_loss.unsqueeze.unsqueeze.unsqueeze", "val_acc.unsqueeze.unsqueeze.unsqueeze", "task_losses.unsqueeze.unsqueeze.unsqueeze", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" \n        Runs one training step. This usually consists in the forward function followed\n            by the loss function.\n        \n        :param batch: The output of your dataloader. \n        :param batch_nb: Integer displaying which batch this is\n\n        Returns:\n            - dictionary containing the loss and the metrics to be added to the lightning logger.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "# print('Training', inputs['input_ids'].shape)", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "\n", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "task_losses", "=", "torch", ".", "stack", "(", "loss_val", ")", "\n", "loss_val", "=", "self", ".", "weights", "*", "task_losses", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "total_weighted_loss", "=", "loss_val", "[", "0", "]", "\n", "task_losses", "=", "loss_val", "[", "0", "]", "\n", "", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "# acc", "\n", "labels_hat", "=", "torch", ".", "argmax", "(", "y_hat", ",", "dim", "=", "1", ")", "\n", "val_acc", "=", "torch", ".", "sum", "(", "y", "==", "labels_hat", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc", "=", "torch", ".", "tensor", "(", "val_acc", ")", "\n", "\n", "if", "self", ".", "on_gpu", ":", "\n", "            ", "val_acc", "=", "val_acc", ".", "cuda", "(", "loss_val", "[", "0", "]", ".", "device", ".", "index", ")", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "total_weighted_loss", "=", "total_weighted_loss", ".", "unsqueeze", "(", "0", ")", "\n", "val_acc", "=", "val_acc", ".", "unsqueeze", "(", "0", ")", "\n", "task_losses", "=", "task_losses", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "tqdm_dict", "=", "{", "\"train_loss\"", ":", "total_weighted_loss", ",", "\"train_acc\"", ":", "val_acc", ",", "\"weight1\"", ":", "self", ".", "weights", "[", "0", "]", ",", "\"weight2\"", ":", "self", ".", "weights", "[", "1", "]", "}", "\n", "", "else", ":", "\n", "            ", "tqdm_dict", "=", "{", "\"train_loss\"", ":", "total_weighted_loss", ",", "\"train_acc\"", ":", "val_acc", "}", "\n", "", "output", "=", "OrderedDict", "(", "\n", "{", "\"loss\"", ":", "task_losses", ",", "\"progress_bar\"", ":", "tqdm_dict", ",", "\"log\"", ":", "tqdm_dict", ",", "\"acc\"", ":", "val_acc", "}", "\n", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.validation_step": [[266, 324], ["bert_classifier.BERTClassifier.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "collections.OrderedDict", "bert_classifier.BERTClassifier.loss", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "val_acc.unsqueeze.unsqueeze.cuda", "torch.tensor.cuda", "torch.tensor.cuda", "loss_val.unsqueeze.unsqueeze.unsqueeze", "val_acc.unsqueeze.unsqueeze.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "bert_classifier.BERTClassifier.hparams.le.inverse_transform", "bert_classifier.BERTClassifier.hparams.le.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "sklearn.metrics.jaccard_score", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "y.cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "bert_classifier.BERTClassifier.hparams.le_aux.inverse_transform", "bert_classifier.BERTClassifier.hparams.le_aux.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "len", "y_aux.cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.type().cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "y_aux.cpu().numpy().argmax", "torch.argmax.cpu().numpy().argmax", "torch.argmax.cpu().numpy().argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Sigmoid", "torch.Sigmoid", "y.cpu", "torch.argmax.cpu", "torch.argmax.cpu", "numpy.arange", "y_aux.type().cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "len", "y_aux.type", "y_aux.cpu", "torch.argmax.cpu", "torch.argmax.cpu"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Similar to the training step but with the model in eval mode.\n\n        Returns:\n            - dictionary passed to the validation_end function.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "[", "0", "]", "\n", "\n", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "\n", "# acc", "\n", "labels_hat", "=", "torch", ".", "argmax", "(", "y_hat", ",", "dim", "=", "1", ")", "\n", "val_acc", "=", "torch", ".", "sum", "(", "y", "==", "labels_hat", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc", "=", "torch", ".", "tensor", "(", "val_acc", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "# Auxiliary", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "\n", "# acc", "\n", "labels_hat_aux", "=", "torch", ".", "argmax", "(", "y_hat_aux", ",", "dim", "=", "1", ")", "\n", "val_acc_aux", "=", "torch", ".", "sum", "(", "y_aux", "==", "labels_hat_aux", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "labels_hat_aux", "=", "(", "nn", ".", "Sigmoid", "(", ")", "(", "y_hat_aux", ")", ">", "0.5", ")", "\n", "val_acc_aux", "=", "jaccard_score", "(", "y_aux", ".", "cpu", "(", ")", ",", "labels_hat_aux", ".", "cpu", "(", ")", ",", "average", "=", "'macro'", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "else", ":", "\n", "            ", "val_acc_aux", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "self", ".", "on_gpu", ":", "\n", "            ", "val_acc", "=", "val_acc", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "loss_val", "=", "loss_val", ".", "unsqueeze", "(", "0", ")", "\n", "val_acc", "=", "val_acc", ".", "unsqueeze", "(", "0", ")", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "unsqueeze", "(", "0", ")", "\n", "", "conf_matrix", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le", ".", "inverse_transform", "(", "y", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le", ".", "inverse_transform", "(", "labels_hat", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "conf_matrix", "=", "torch", ".", "tensor", "(", "conf_matrix", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "y_aux", ".", "type", "(", "torch", ".", "long", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "y_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_dev_dataset", ".", "columns", ")", ")", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "else", ":", "\n", "            ", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "[", "1", ",", "1", "]", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "output", "=", "OrderedDict", "(", "{", "\"val_loss\"", ":", "loss_val", ",", "\"val_acc\"", ":", "val_acc", ",", "\"conf_matrix\"", ":", "conf_matrix", ",", "\"conf_matrix_aux\"", ":", "conf_matrix_aux", ",", "\"val_acc_aux\"", ":", "val_acc_aux", "}", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "", "def", "test_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.test_step": [[324, 388], ["bert_classifier.BERTClassifier.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "collections.OrderedDict", "bert_classifier.BERTClassifier.loss", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "open", "zip", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "val_acc.unsqueeze.unsqueeze.cuda", "torch.tensor.cuda", "torch.tensor.cuda", "loss_val.unsqueeze.unsqueeze.unsqueeze", "val_acc.unsqueeze.unsqueeze.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "bert_classifier.BERTClassifier.hparams.le.inverse_transform", "bert_classifier.BERTClassifier.hparams.le.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.argmax.tolist", "torch.argmax.tolist", "y.tolist", "fd.write", "fd.write", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "sklearn.metrics.jaccard_score", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "y.cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "bert_classifier.BERTClassifier.hparams.le_aux.inverse_transform", "bert_classifier.BERTClassifier.hparams.le_aux.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "len", "y_aux.cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.type().cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "y_aux.cpu().numpy().argmax", "torch.argmax.cpu().numpy().argmax", "torch.argmax.cpu().numpy().argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Sigmoid", "torch.Sigmoid", "y.cpu", "torch.argmax.cpu", "torch.argmax.cpu", "numpy.arange", "str", "y_aux.type().cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "len", "str", "y_aux.type", "y_aux.cpu", "torch.argmax.cpu", "torch.argmax.cpu"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Similar to the training step but with the model in eval mode.\n\n        Returns:\n            - dictionary passed to the test_end function.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "[", "0", "]", "\n", "\n", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "\n", "# acc", "\n", "labels_hat", "=", "torch", ".", "argmax", "(", "y_hat", ",", "dim", "=", "1", ")", "\n", "val_acc", "=", "torch", ".", "sum", "(", "y", "==", "labels_hat", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc", "=", "torch", ".", "tensor", "(", "val_acc", ")", "\n", "\n", "with", "open", "(", "'experiments/predictions/'", "+", "str", "(", "self", ".", "hparams", ".", "seed", ")", "+", "'_'", "+", "self", ".", "hparams", ".", "aux_task", "+", "'_preds.csv'", ",", "'a'", ")", "as", "fd", ":", "\n", "            ", "for", "line", "in", "zip", "(", "labels_hat", ".", "tolist", "(", ")", ",", "y", ".", "tolist", "(", ")", ")", ":", "\n", "                ", "fd", ".", "write", "(", "','", ".", "join", "(", "str", "(", "v", ")", "for", "v", "in", "line", ")", ")", "\n", "fd", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "# Auxiliary", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "\n", "# acc", "\n", "labels_hat_aux", "=", "torch", ".", "argmax", "(", "y_hat_aux", ",", "dim", "=", "1", ")", "\n", "val_acc_aux", "=", "torch", ".", "sum", "(", "y_aux", "==", "labels_hat_aux", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "labels_hat_aux", "=", "(", "nn", ".", "Sigmoid", "(", ")", "(", "y_hat_aux", ")", ">", "0.5", ")", "\n", "val_acc_aux", "=", "jaccard_score", "(", "y_aux", ".", "cpu", "(", ")", ",", "labels_hat_aux", ".", "cpu", "(", ")", ",", "average", "=", "'macro'", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "else", ":", "\n", "            ", "val_acc_aux", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "self", ".", "on_gpu", ":", "\n", "            ", "val_acc", "=", "val_acc", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "loss_val", "=", "loss_val", ".", "unsqueeze", "(", "0", ")", "\n", "val_acc", "=", "val_acc", ".", "unsqueeze", "(", "0", ")", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "unsqueeze", "(", "0", ")", "\n", "", "conf_matrix", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le", ".", "inverse_transform", "(", "y", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le", ".", "inverse_transform", "(", "labels_hat", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "conf_matrix", "=", "torch", ".", "tensor", "(", "conf_matrix", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "y_aux", ".", "type", "(", "torch", ".", "long", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "y_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_test_dataset", ".", "columns", ")", ")", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "else", ":", "\n", "            ", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "[", "1", ",", "1", "]", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "output", "=", "OrderedDict", "(", "{", "\"val_loss\"", ":", "loss_val", ",", "\"val_acc\"", ":", "val_acc", ",", "\"conf_matrix\"", ":", "conf_matrix", ",", "\"conf_matrix_aux\"", ":", "conf_matrix_aux", ",", "\"val_acc_aux\"", ":", "val_acc_aux", "}", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "", "def", "train_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.train_epoch_end": [[388, 421], ["len", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "train_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "\n", "# reduce manually when using dp", "\n", "val_acc", "=", "output", "[", "\"val_acc\"", "]", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_acc", "=", "torch", ".", "mean", "(", "val_acc", ")", "\n", "\n", "", "val_acc_mean", "+=", "val_acc", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\"val_acc\"", ":", "val_acc_mean", "}", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"train_loss\"", ":", "val_loss_mean", ",", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.validation_epoch_end": [[423, 459], ["numpy.zeros", "len", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "conf_matrix", "=", "np", ".", "zeros", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "\n", "# reduce manually when using dp", "\n", "val_acc", "=", "output", "[", "\"val_acc\"", "]", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_acc", "=", "torch", ".", "mean", "(", "val_acc", ")", "\n", "\n", "", "val_acc_mean", "+=", "val_acc", "\n", "conf_matrix", "+=", "output", "[", "\"conf_matrix\"", "]", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\"val_acc\"", ":", "val_acc_mean", "}", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"conf_matrix\"", ":", "conf_matrix", ",", "\n", "}", "\n", "return", "result", "\n", "", "def", "validation_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.validation_end": [[459, 545], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "len", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "matplotlib.close", "matplotlib.close", "int", "int", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "sum", "sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.zeros.cpu", "torch.zeros.cpu", "int", "int"], "methods", ["None"], ["", "def", "validation_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "val_acc_aux_mean", "=", "0", "\n", "conf_matrix", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "device", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "device", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "val_acc_aux", "=", "output", "[", "\"val_acc_aux\"", "]", "\n", "conf_matrix_", "=", "output", "[", "\"conf_matrix\"", "]", "\n", "conf_matrix_aux_", "=", "output", "[", "\"conf_matrix_aux\"", "]", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "conf_matrix_", "=", "sum", "(", "torch", ".", "split", "(", "conf_matrix_", ",", "int", "(", "conf_matrix_", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ")", ")", "\n", "conf_matrix_aux_", "=", "sum", "(", "torch", ".", "split", "(", "conf_matrix_aux_", ",", "int", "(", "conf_matrix_aux_", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ")", ")", "\n", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "val_acc_aux", "=", "torch", ".", "mean", "(", "val_acc_aux", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "val_acc_aux_mean", "+=", "val_acc_aux", "\n", "\n", "\n", "# reduce manually when using dp", "\n", "val_acc", "=", "output", "[", "\"val_acc\"", "]", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_acc", "=", "torch", ".", "mean", "(", "val_acc", ")", "\n", "# val_loss_mean = torch.mean(val_loss_mean)", "\n", "", "val_acc_mean", "+=", "val_acc", "\n", "conf_matrix", "+=", "conf_matrix_", "\n", "conf_matrix_aux", "+=", "conf_matrix_aux_", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_aux_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_acc\"", ":", "val_acc_mean", ",", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", "\n", "\n", "}", "\n", "#log_dict = {\"val_loss\": val_loss_mean, \"val_acc\": val_acc_mean, \"conf_matrix\": conf_matrix}", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix'", ",", "fig", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "_dev_dataset", ".", "columns", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "_dev_dataset", ".", "columns", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "plt", ".", "close", "(", "'all'", ")", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_acc\"", ":", "val_acc_mean", ",", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", ",", "\n", "}", "\n", "return", "result", "\n", "", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.test_epoch_end": [[545, 633], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "len", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "matplotlib.close", "matplotlib.close", "int", "int", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_classifier.BERTClassifier.logger.experiment.log_image", "torch.zeros.cpu", "torch.zeros.cpu"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "val_acc_aux_mean", "=", "0", "\n", "conf_matrix", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", "[", "0", "]", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "device", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "0", "]", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "device", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "val_acc_aux", "=", "output", "[", "\"val_acc_aux\"", "]", "\n", "conf_matrix_", "=", "output", "[", "\"conf_matrix\"", "]", "\n", "conf_matrix_aux_", "=", "output", "[", "\"conf_matrix_aux\"", "]", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "# conf_matrix_ = sum(torch.split(conf_matrix_, int(conf_matrix_.shape[0]/self.hparams.gpus)))", "\n", "# if self.hparams.aux_task != 'None':", "\n", "#     conf_matrix_aux_ = sum(torch.split(conf_matrix_aux_, int(conf_matrix_aux_.shape[0]/self.hparams.gpus)))", "\n", "                ", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "val_acc_aux", "=", "torch", ".", "mean", "(", "val_acc_aux", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "val_acc_aux_mean", "+=", "val_acc_aux", "\n", "\n", "\n", "# reduce manually when using dp", "\n", "val_acc", "=", "output", "[", "\"val_acc\"", "]", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_acc", "=", "torch", ".", "mean", "(", "val_acc", ")", "\n", "# val_loss_mean = torch.mean(val_loss_mean)", "\n", "", "val_acc_mean", "+=", "val_acc", "\n", "conf_matrix", "+=", "conf_matrix_", "\n", "conf_matrix_aux", "+=", "conf_matrix_aux_", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_aux_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_acc\"", ":", "val_acc_mean", ",", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", "\n", "\n", "}", "\n", "#log_dict = {\"val_loss\": val_loss_mean, \"val_acc\": val_acc_mean, \"conf_matrix\": conf_matrix}", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le", ".", "classes_", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix'", ",", "fig", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "_test_dataset", ".", "columns", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "_test_dataset", ".", "columns", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "plt", ".", "close", "(", "'all'", ")", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_acc\"", ":", "val_acc_mean", ",", "\n", "#\"conf_matrix\": conf_matrix,", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", ",", "\n", "}", "\n", "return", "result", "\n", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.configure_optimizers": [[633, 658], ["transformers.get_linear_schedule_with_warmup", "torch.optim.Adam", "torch.optim.Adam", "len", "bert_classifier.BERTClassifier.model.named_parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "bert_classifier.BERTClassifier.train_dataloader", "int", "any", "bert_classifier.BERTClassifier.model.parameters", "aux_params.append", "params.append", "bert_classifier.BERTClassifier.model.parameters"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.train_dataloader"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\" Sets different Learning rates for different parameter groups. \"\"\"", "\n", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", "and", "self", ".", "hparams", ".", "gradnorm", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", ",", "{", "'params'", ":", "self", ".", "weights", ",", "'lr'", ":", "1e-2", "}", "]", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "params", "=", "[", "]", "\n", "aux_params", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "[", "'classification_head_aux'", ",", "'pooler.dense_right'", ",", "'layer_right'", "]", ")", ":", "\n", "                    ", "aux_params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "params", ".", "append", "(", "p", ")", "\n", "", "", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "params", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", ",", "\n", "{", "'params'", ":", "aux_params", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "*", "10", "}", "]", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", "]", ")", "\n", "", "train_steps", "=", "len", "(", "self", ".", "train_dataloader", "(", ")", ")", "*", "self", ".", "hparams", ".", "max_epochs", "\n", "#scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(self.hparams.warmup_proportion * train_steps), num_cycles =0.5, num_training_steps=train_steps)", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "int", "(", "self", ".", "hparams", ".", "warmup_proportion", "*", "train_steps", ")", ",", "num_training_steps", "=", "train_steps", ")", "\n", "scheduler", "=", "{", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'interval'", ":", "'step'", ",", "\n", "'frequency'", ":", "1", "\n", "}", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.on_epoch_end": [[659, 663], ["bert_classifier.BERTClassifier.unfreeze_encoder"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.unfreeze_encoder"], ["", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "\"\"\" Pytorch lightning hook \"\"\"", "\n", "if", "self", ".", "current_epoch", "+", "1", ">=", "self", ".", "nr_frozen_epochs", ":", "\n", "           ", "self", ".", "unfreeze_encoder", "(", ")", "\n", "", "", "def", "__retrieve_dataset", "(", "self", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.__retrieve_dataset": [[663, 666], ["dataloader.sentiment_analysis_dataset"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.sentiment_analysis_dataset"], ["", "", "def", "__retrieve_dataset", "(", "self", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", ")", ":", "\n", "        ", "\"\"\" Retrieves task specific dataset \"\"\"", "\n", "return", "sentiment_analysis_dataset", "(", "self", ".", "hparams", ",", "train", ",", "val", ",", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.train_dataloader": [[667, 677], ["bert_classifier.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the train set. \"\"\"", "\n", "self", ".", "_train_dataset", "=", "self", ".", "__retrieve_dataset", "(", "val", "=", "False", ",", "test", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_train_dataset", ",", "\n", "sampler", "=", "RandomSampler", "(", "self", ".", "_train_dataset", ")", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.val_dataloader": [[679, 688], ["bert_classifier.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "val_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the validation set. \"\"\"", "\n", "self", ".", "_dev_dataset", "=", "self", ".", "__retrieve_dataset", "(", "train", "=", "False", ",", "test", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_dev_dataset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.test_dataloader": [[690, 699], ["bert_classifier.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "test_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the validation set. \"\"\"", "\n", "self", ".", "_test_dataset", "=", "self", ".", "__retrieve_dataset", "(", "train", "=", "False", ",", "val", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_test_dataset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_classifier.BERTClassifier.add_model_specific_args": [[701, 824], ["parser.add_argument", "parser.add_argument", "parser.opt_list", "parser.add_argument", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_model_specific_args", "(", "\n", "cls", ",", "parser", ":", "HyperOptArgumentParser", "\n", ")", "->", "HyperOptArgumentParser", ":", "\n", "        ", "\"\"\" Parser for Estimator specific arguments/hyperparameters. \n        :param parser: HyperOptArgumentParser obj\n\n        Returns:\n            - updated parser\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_model\"", ",", "\n", "default", "=", "\"bert-base-uncased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Encoder model to be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradnorm\"", ",", "\n", "default", "=", "False", ",", "\n", "type", "=", "bool", ",", "\n", "help", "=", "\"Use Gradnorm for MTL.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--aux_task\"", ",", "\n", "default", "=", "'None'", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "'None'", ",", "'bias'", ",", "'group'", ",", "'emotions'", "]", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Use online logging for Neptune.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_learning_rate\"", ",", "\n", "default", "=", "1e-05", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Encoder specific learning rate.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-05", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "5e-05", ",", "3e-05", ",", "1e-05", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Classification head learning rate.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--loss_aux\"", ",", "\n", "default", "=", "0.25", ",", "\n", "tunable", "=", "True", ",", "\n", "options", "=", "[", "0.1", ",", "0.5", ",", "0.75", ",", "0.99", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add dropout to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--warmup_aux\"", ",", "\n", "default", "=", "5", ",", "\n", "tunable", "=", "True", ",", "\n", "options", "=", "[", "1", ",", "3", ",", "5", ",", "8", ",", "10", "]", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Add warmup scheduled learning.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--extra_dropout\"", ",", "\n", "default", "=", "0", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "0.05", ",", "0.1", ",", "0.15", ",", "0.2", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add dropout to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "0.1", ",", "0.2", ",", "0.3", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add warmup to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--nr_frozen_epochs\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of epochs we want to keep the encoder model frozen.\"", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_length\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Max length for text.\"", ",", "\n", ")", "\n", "# Data Args:", "\n", "parser", ".", "add_argument", "(", "\n", "\"--label_set\"", ",", "\n", "default", "=", "\"pos,neg\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Classification labels set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_csv\"", ",", "\n", "default", "=", "\"data/train_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the train data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dev_csv\"", ",", "\n", "default", "=", "\"data/valid_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the dev data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_csv\"", ",", "\n", "default", "=", "\"data/test_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the dev data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--loader_workers\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"How many subprocesses to use for data loading. 0 means that \\\n                the data will be loaded in the main process.\"", ",", "\n", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.RedditTransformer.__init__": [[6, 29], ["super().__init__", "transformers.AutoConfig.from_pretrained", "transformers.AutoModel.from_pretrained", "print", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "Transformer.BertEncoder", "Transformer.BertPooler", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "num_classes", ",", "extra_dropout", ",", "num_groups", ")", ":", "\n", "        ", "super", "(", "RedditTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "encoder", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ",", "config", "=", "config", ")", "\n", "for", "layer", "in", "self", ".", "encoder", ".", "encoder", ".", "layer", ":", "\n", "            ", "layer", ".", "attention", ".", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "encoder", ".", "config", ".", "attention_probs_dropout_prob", "+", "extra_dropout", ")", "\n", "layer", ".", "output", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "encoder", ".", "config", ".", "hidden_dropout_prob", "+", "extra_dropout", ")", "\n", "", "print", "(", "self", ".", "encoder", ".", "config", ")", "\n", "#self.encoder.embeddings.requires_grad = False", "\n", "self", ".", "classification_head", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", "+", "extra_dropout", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", ",", "\n", ")", "\n", "if", "num_groups", "!=", "None", ":", "\n", "            ", "self", ".", "encoder", ".", "encoder", "=", "BertEncoder", "(", "config", ",", "self", ".", "encoder", ".", "encoder", ".", "layer", ")", "\n", "self", ".", "encoder", ".", "pooler", "=", "BertPooler", "(", "config", ",", "self", ".", "encoder", ".", "pooler", ".", "dense", ")", "\n", "self", ".", "aux", "=", "True", "\n", "self", ".", "classification_head_aux", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", "+", "extra_dropout", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_groups", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "aux", "=", "False", "\n", "", "", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.RedditTransformer.forward": [[29, 44], ["Transformer.RedditTransformer.encoder", "Transformer.RedditTransformer.classification_head", "Transformer.RedditTransformer.classification_head_aux", "Transformer.RedditTransformer.classification_head"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "encoder", "(", "\n", "batch", "[", "'input_ids'", "]", ",", "\n", "attention_mask", "=", "batch", "[", "'attention_mask'", "]", ",", "\n", ")", "\n", "if", "self", ".", "aux", "==", "True", ":", "\n", "            ", "features_main", "=", "outputs", "[", "0", "]", "[", "0", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "features_aux", "=", "outputs", "[", "0", "]", "[", "1", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "logits_main", "=", "self", ".", "classification_head", "(", "features_main", ")", "\n", "logits_aux", "=", "self", ".", "classification_head_aux", "(", "features_aux", ")", "\n", "return", "logits_main", ",", "logits_aux", ",", "outputs", "\n", "", "else", ":", "\n", "            ", "features", "=", "outputs", "[", "0", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "logits_main", "=", "self", ".", "classification_head", "(", "features", ")", "\n", "return", "logits_main", ",", "None", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.__init__": [[46, 52], ["super().__init__", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "layers", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "layer", "=", "layers", "[", ":", "-", "1", "]", "#nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])", "\n", "self", ".", "layer_left", "=", "copy", ".", "deepcopy", "(", "layers", "[", "-", "1", "]", ")", "\n", "self", ".", "layer_right", "=", "copy", ".", "deepcopy", "(", "layers", "[", "-", "1", "]", ")", "\n", "", "def", "forward", "(", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.forward": [[52, 78], ["enumerate", "Transformer.BertEncoder.layer_loop", "Transformer.BertEncoder.layer_loop", "Transformer.BertEncoder.layer_loop", "len", "len"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.layer_loop", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.layer_loop", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.layer_loop"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "hidden_states", ",", "all_attentions", "=", "self", ".", "layer_loop", "(", "output_hidden_states", ",", "all_hidden_states", ",", "hidden_states", ",", "layer_module", ",", "head_mask", ",", "i", ",", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "output_attentions", ",", "all_attentions", ",", "attention_mask", ")", "\n", "", "hidden_states_left", ",", "all_attentions_left", "=", "self", ".", "layer_loop", "(", "output_hidden_states", ",", "all_hidden_states", ",", "hidden_states", ",", "self", ".", "layer_left", ",", "head_mask", ",", "len", "(", "self", ".", "layer", ")", ",", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "output_attentions", ",", "all_attentions", ",", "attention_mask", ")", "\n", "hidden_states_right", ",", "all_attentions_right", "=", "self", ".", "layer_loop", "(", "output_hidden_states", ",", "all_hidden_states", ",", "hidden_states", ",", "self", ".", "layer_right", ",", "head_mask", ",", "len", "(", "self", ".", "layer", ")", ",", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "output_attentions", ",", "all_attentions", ",", "attention_mask", ")", "\n", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states_left", "=", "all_hidden_states", "+", "(", "hidden_states_left", ",", ")", "\n", "all_hidden_states_right", "=", "all_hidden_states", "+", "(", "hidden_states_right", ",", ")", "\n", "\n", "", "outputs", "=", "(", "(", "hidden_states_left", ",", "hidden_states_right", ")", ",", ")", "\n", "if", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "(", "all_hidden_states_left", ",", "all_hidden_states_right", ")", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "(", "all_attentions_left", ",", "all_attentions_right", ")", ",", ")", "\n", "", "return", "outputs", "\n", "", "def", "layer_loop", "(", "self", ",", "output_hidden_states", ",", "all_hidden_states", ",", "hidden_states", ",", "layer_module", ",", "head_mask", ",", "i", ",", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "output_attentions", ",", "all_attentions", ",", "attention_mask", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertEncoder.layer_loop": [[78, 111], ["getattr", "torch.utils.checkpoint.checkpoint", "layer_module", "Transformer.BertEncoder.layer_loop.create_custom_forward"], "methods", ["None"], ["", "def", "layer_loop", "(", "self", ",", "output_hidden_states", ",", "all_hidden_states", ",", "hidden_states", ",", "layer_module", ",", "head_mask", ",", "i", ",", "encoder_hidden_states", ",", "encoder_attention_mask", ",", "output_attentions", ",", "all_attentions", ",", "attention_mask", ")", ":", "\n", "        ", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", ":", "\n", "\n", "            ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                    ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "layer_module", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "output_attentions", ":", "\n", "            ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "", "return", "hidden_states", ",", "all_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertPooler.__init__": [[114, 119], ["super().__init__", "copy.deepcopy", "copy.deepcopy", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "dense", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_left", "=", "copy", ".", "deepcopy", "(", "dense", ")", "\n", "self", ".", "dense_right", "=", "copy", ".", "deepcopy", "(", "dense", ")", "\n", "self", ".", "activation", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.Transformer.BertPooler.forward": [[120, 130], ["Transformer.BertPooler.dense_left", "Transformer.BertPooler.activation", "Transformer.BertPooler.dense_right", "Transformer.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor_left", "=", "hidden_states", "[", "0", "]", "[", ":", ",", "0", "]", "\n", "first_token_tensor_right", "=", "hidden_states", "[", "1", "]", "[", ":", ",", "0", "]", "\n", "pooled_output_left", "=", "self", ".", "dense_left", "(", "first_token_tensor_left", ")", "\n", "pooled_output_left", "=", "self", ".", "activation", "(", "pooled_output_left", ")", "\n", "pooled_output_right", "=", "self", ".", "dense_right", "(", "first_token_tensor_right", ")", "\n", "pooled_output_right", "=", "self", ".", "activation", "(", "pooled_output_right", ")", "\n", "return", "(", "pooled_output_left", ",", "pooled_output_right", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__init__": [[33, 54], ["pytorch_lightning.LightningModule.__init__", "print", "bert_regressor.BERTClassifier.__build_model", "bert_regressor.BERTClassifier.__build_loss", "dataloader_regression.MyCollator", "type", "argparse.Namespace", "type", "bert_regressor.BERTClassifier.freeze_encoder"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_model", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_loss", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.freeze_encoder"], ["def", "__init__", "(", "self", ",", "hparams", ":", "HyperOptArgumentParser", ")", "->", "None", ":", "\n", "        ", "super", "(", "BERTClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "hparams", ")", "==", "dict", ":", "\n", "            ", "hparams", "=", "argparse", ".", "Namespace", "(", "**", "hparams", ")", "\n", "", "self", ".", "hparams", "=", "hparams", "\n", "print", "(", "type", "(", "hparams", ")", ")", "\n", "\n", "self", ".", "batch_size", "=", "hparams", ".", "batch_size", "\n", "\n", "# build model", "\n", "self", ".", "__build_model", "(", ")", "\n", "\n", "# Loss criterion initialization.", "\n", "self", ".", "__build_loss", "(", ")", "\n", "if", "hparams", ".", "nr_frozen_epochs", ">", "0", ":", "\n", "            ", "self", ".", "freeze_encoder", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_frozen", "=", "False", "\n", "", "self", ".", "nr_frozen_epochs", "=", "hparams", ".", "nr_frozen_epochs", "\n", "self", ".", "model_name", "=", "hparams", ".", "encoder_model", "\n", "self", ".", "prepare_sample", "=", "MyCollator", "(", "self", ".", "model_name", ",", "hparams", ".", "max_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_model": [[55, 77], ["sklearn.preprocessing.LabelEncoder", "pandas.concat", "sklearn.preprocessing.LabelEncoder", "bert_regressor.BERTClassifier.hparams.le_aux.fit", "Transformer.RedditTransformer", "torch.Parameter", "torch.Parameter", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "Transformer.RedditTransformer", "torch.Parameter", "torch.Parameter", "sklearn.preprocessing.LabelEncoder", "Transformer.RedditTransformer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "__build_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" Init BERT model + tokenizer + classification head.\"\"\"", "\n", "'''self.bert = AutoModel.from_pretrained(\n            self.hparams.encoder_model\n        )'''", "\n", "self", ".", "hparams", ".", "le", "=", "LabelEncoder", "(", ")", "\n", "comments", "=", "pd", ".", "concat", "(", "[", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "train_csv", ")", ",", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "dev_csv", ")", ",", "pd", ".", "read_csv", "(", "self", ".", "hparams", ".", "test_csv", ")", "]", ")", "\n", "self", ".", "hparams", ".", "le_aux", "=", "LabelEncoder", "(", ")", "\n", "#self.hparams.le.fit(comments.Pop_candidate.values)", "\n", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "self", ".", "hparams", ".", "le_aux", ".", "fit", "(", "comments", "[", "self", ".", "hparams", ".", "aux_task", "]", ".", "values", ")", "\n", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "1", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "len", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1", "+", "self", ".", "hparams", ".", "loss_aux", ",", "1", "-", "self", ".", "hparams", ".", "loss_aux", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "alpha", "=", "0.5", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "1", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "8", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1", "+", "self", ".", "hparams", ".", "loss_aux", ",", "1", "-", "self", ".", "hparams", ".", "loss_aux", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "alpha", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "self", ".", "hparams", ".", "le_aux", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "model", "=", "RedditTransformer", "(", "self", ".", "hparams", ".", "encoder_model", ",", "1", ",", "self", ".", "hparams", ".", "extra_dropout", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__build_loss": [[78, 86], ["torch.MSELoss", "torch.MSELoss", "torch.L1Loss", "torch.L1Loss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["None"], ["", "", "def", "__build_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initializes the loss function/s. \"\"\"", "\n", "self", ".", "_loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "if", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "self", ".", "_loss_aux", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_loss_aux", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "self", ".", "_Gradloss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "# self.Weightloss1 = torch.tensor(torch.FloatTensor([1- self.hparams.loss_aux]), requires_grad=True, device='cuda')", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.unfreeze_encoder": [[90, 97], ["log.info", "bert_regressor.BERTClassifier.model.encoder.parameters"], "methods", ["None"], ["", "def", "unfreeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" un-freezes the encoder layer. \"\"\"", "\n", "if", "self", ".", "_frozen", ":", "\n", "            ", "log", ".", "info", "(", "f\"\\n-- Encoder model fine-tuning\"", ")", "\n", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "", "self", ".", "_frozen", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.freeze_encoder": [[98, 105], ["bert_regressor.BERTClassifier.model.encoder.parameters", "bert_regressor.BERTClassifier.model.encoder.encoder.layer[].output.parameters"], "methods", ["None"], ["", "", "def", "freeze_encoder", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" freezes the encoder layer. \"\"\"", "\n", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "model", ".", "encoder", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "True", "\n", "", "self", ".", "_frozen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.predict": [[106, 127], ["bert_regressor.BERTClassifier.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert_regressor.BERTClassifier.prepare_sample", "bert_regressor.BERTClassifier.forward", "model_out[].numpy", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward"], ["", "def", "predict", "(", "self", ",", "sample", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Predict function.\n        :param sample: dictionary with the text we want to classify.\n\n        Returns:\n            Dictionary with the input text and the predicted label.\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_input", "=", "self", ".", "prepare_sample", "(", "[", "sample", "]", ")", "\n", "model_out", "=", "self", ".", "forward", "(", "model_input", ")", "\n", "logits", "=", "model_out", "[", "\"logits\"", "]", ".", "numpy", "(", ")", "\n", "predicted_labels", "=", "[", "\n", "self", ".", "label_encoder", ".", "index_to_token", "[", "prediction", "]", "\n", "for", "prediction", "in", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "]", "\n", "sample", "[", "\"predicted_label\"", "]", "=", "predicted_labels", "[", "0", "]", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward": [[128, 142], ["bert_regressor.BERTClassifier.model", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Usual pytorch forward function.\n        :param tokens: text sequences [batch_size x src_seq_len]\n        :param lengths: source lengths [batch_size]\n\n        Returns:\n            Dictionary with model outputs (e.g: logits)\n        \"\"\"", "\n", "# print('forward', tokens['input_ids'].shape)", "\n", "# print('tree_sizes', tokens['tree_sizes'])", "\n", "# print('node_order', tokens['node_order'])", "\n", "logits", ",", "logits_aux", ",", "_", "=", "self", ".", "model", "(", "tokens", ")", "\n", "\n", "return", "{", "\"logits\"", ":", "nn", ".", "Sigmoid", "(", ")", "(", "logits", ")", ",", "\"logits_aux\"", ":", "logits_aux", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss": [[143, 163], ["bert_regressor.BERTClassifier._loss", "predictions[].flatten", "bert_regressor.BERTClassifier._loss_aux", "bert_regressor.BERTClassifier._loss_aux", "targets[].type"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "predictions", ":", "dict", ",", "targets", ":", "dict", ")", "->", "torch", ".", "tensor", ":", "\n", "        ", "\"\"\"\n        Computes Loss value according to a loss function.\n        :param predictions: model specific output. Must contain a key 'logits' with\n            a tensor [batch_size x 1] with model predictions\n        :param labels: Label values [batch_size]\n\n        Returns:\n            torch.tensor with loss value.\n        \"\"\"", "\n", "# print('targets', targets)", "\n", "# print('predictions', predictions[\"logits\"].shape)", "\n", "loss", "=", "self", ".", "_loss", "(", "predictions", "[", "\"logits\"", "]", ".", "flatten", "(", ")", ",", "targets", "[", "\"labels\"", "]", ")", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ")", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_loss_aux", "(", "predictions", "[", "\"logits_aux\"", "]", ",", "targets", "[", "\"labels_aux\"", "]", ")", "\n", "return", "loss", ",", "loss_aux", "#*self.hparams.loss_aux", "\n", "", "elif", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_loss_aux", "(", "predictions", "[", "\"logits_aux\"", "]", ",", "targets", "[", "\"labels_aux\"", "]", ".", "type", "(", "torch", ".", "long", ")", ")", "\n", "return", "loss", ",", "loss_aux", "\n", "", "return", "loss", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward": [[164, 198], ["loss_val.sum", "loss_val.sum.backward", "list", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_regressor.BERTClassifier.model.encoder.encoder.layer[].output.parameters", "loss.flatten", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.stack.append", "torch.stack.append", "loss.detach", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "loss_val.sum", "loss_val.sum.backward", "loss.backward", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "loss_ratios.mean", "torch.stack.mean", "torch.stack.mean"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.backward"], ["", "def", "backward", "(", "self", ",", "use_amp", ",", "loss", ",", "optimizer", ",", "idx_opt", ")", ":", "\n", "        ", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", "and", "self", ".", "hparams", ".", "gradnorm", "==", "True", ":", "\n", "            ", "loss_val", "=", "self", ".", "weights", "*", "loss", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "total_weighted_loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "weights", ".", "grad", "=", "0.0", "*", "self", ".", "weights", ".", "grad", "\n", "W", "=", "list", "(", "self", ".", "model", ".", "encoder", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "parameters", "(", ")", ")", "\n", "norms", "=", "[", "]", "\n", "for", "w_i", ",", "L_i", "in", "zip", "(", "self", ".", "weights", ",", "loss", ".", "flatten", "(", ")", ")", ":", "\n", "# gradient of L_i(t) w.r.t. W", "\n", "                ", "gLgW", "=", "torch", ".", "autograd", ".", "grad", "(", "L_i", ",", "W", ",", "retain_graph", "=", "True", ")", "\n", "\n", "# G^{(i)}_W(t)", "\n", "norms", ".", "append", "(", "torch", ".", "norm", "(", "w_i", "*", "gLgW", "[", "0", "]", ")", ")", "\n", "", "norms", "=", "torch", ".", "stack", "(", "norms", ")", "\n", "if", "self", ".", "trainer", ".", "global_step", "==", "0", ":", "\n", "                ", "self", ".", "initial_losses", "=", "loss", ".", "detach", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# loss ratios \\curl{L}(t)", "\n", "                ", "loss_ratios", "=", "loss", "/", "self", ".", "initial_losses", "\n", "\n", "# inverse training rate r(t)", "\n", "inverse_train_rates", "=", "loss_ratios", "/", "loss_ratios", ".", "mean", "(", ")", "\n", "\n", "constant_term", "=", "norms", ".", "mean", "(", ")", "*", "(", "inverse_train_rates", "**", "self", ".", "alpha", ")", "\n", "# write out the gradnorm loss L_grad and set the weight gradients", "\n", "", "grad_norm_loss", "=", "(", "norms", "-", "constant_term", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "\n", "self", ".", "weights", ".", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "grad_norm_loss", ",", "self", ".", "weights", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "loss_val", "=", "self", ".", "weights", "*", "loss", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "total_weighted_loss", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.optimizer_step": [[199, 214], ["optimizer.zero_grad", "xm.optimizer_step", "isinstance", "optimizer.step", "optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.Parameter().to", "torch.Parameter().to", "len", "bert_regressor.BERTClassifier.weights.sum", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.optimizer_step"], ["", "", "def", "optimizer_step", "(", "self", ",", "epoch", ",", "batch_idx", ",", "optimizer", ",", "optimizer_idx", ",", "lambda_closure", ",", "using_native_amp", ")", ":", "\n", "        ", "if", "self", ".", "trainer", ".", "use_tpu", "and", "XLA_AVAILABLE", ":", "\n", "            ", "xm", ".", "optimizer_step", "(", "optimizer", ")", "\n", "", "elif", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "LBFGS", ")", ":", "\n", "            ", "optimizer", ".", "step", "(", "lambda_closure", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "epoch", ">", "self", ".", "hparams", ".", "warmup_aux", ":", "\n", "                    ", "self", ".", "weights", ".", "data", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1.99999", ",", "0.00001", "]", ")", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "self", ".", "weights", ".", "device", ")", "\n", "", "normalize_coeff", "=", "len", "(", "self", ".", "weights", ")", "/", "self", ".", "weights", ".", "sum", "(", ")", "\n", "self", ".", "weights", ".", "data", "=", "self", ".", "weights", ".", "data", "*", "normalize_coeff", "\n", "# clear gradients", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.training_step": [[215, 257], ["bert_regressor.BERTClassifier.forward", "bert_regressor.BERTClassifier.loss", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "collections.OrderedDict", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bert_regressor.BERTClassifier.sum", "total_weighted_loss.unsqueeze.unsqueeze.unsqueeze", "task_losses.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" \n        Runs one training step. This usually consists in the forward function followed\n            by the loss function.\n        \n        :param batch: The output of your dataloader. \n        :param batch_nb: Integer displaying which batch this is\n\n        Returns:\n            - dictionary containing the loss and the metrics to be added to the lightning logger.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "# print('Training', inputs['input_ids'].shape)", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "\n", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "task_losses", "=", "torch", ".", "stack", "(", "loss_val", ")", "\n", "loss_val", "=", "self", ".", "weights", "*", "task_losses", "\n", "total_weighted_loss", "=", "loss_val", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "total_weighted_loss", "=", "loss_val", "[", "0", "]", "\n", "task_losses", "=", "loss_val", "[", "0", "]", "\n", "", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "# acc", "\n", "labels_hat", "=", "torch", ".", "argmax", "(", "y_hat", ",", "dim", "=", "1", ")", "\n", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "total_weighted_loss", "=", "total_weighted_loss", ".", "unsqueeze", "(", "0", ")", "\n", "task_losses", "=", "task_losses", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "            ", "tqdm_dict", "=", "{", "\"train_loss\"", ":", "total_weighted_loss", ",", "\"weight1\"", ":", "self", ".", "weights", "[", "0", "]", ",", "\"weight2\"", ":", "self", ".", "weights", "[", "1", "]", "}", "\n", "", "else", ":", "\n", "            ", "tqdm_dict", "=", "{", "\"train_loss\"", ":", "total_weighted_loss", "}", "\n", "\n", "", "output", "=", "OrderedDict", "(", "\n", "{", "\"loss\"", ":", "task_losses", ",", "\"progress_bar\"", ":", "tqdm_dict", ",", "\"log\"", ":", "tqdm_dict", "}", "\n", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.validation_step": [[258, 310], ["bert_regressor.BERTClassifier.forward", "collections.OrderedDict", "bert_regressor.BERTClassifier.loss", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.cuda", "torch.tensor.cuda", "loss_val.unsqueeze.unsqueeze.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "sklearn.metrics.jaccard_score", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "bert_regressor.BERTClassifier.hparams.le_aux.inverse_transform", "bert_regressor.BERTClassifier.hparams.le_aux.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "y_aux.cpu", "labels_hat.cpu", "y_aux.type().cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "y_aux.cpu().numpy().argmax", "labels_hat.cpu().numpy().argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Sigmoid", "torch.Sigmoid", "numpy.arange", "y_aux.type().cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.cpu().numpy", "labels_hat.cpu().numpy", "len", "y_aux.type", "y_aux.cpu", "labels_hat.cpu"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Similar to the training step but with the model in eval mode.\n\n        Returns:\n            - dictionary passed to the validation_end function.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "[", "0", "]", "\n", "\n", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "# Auxiliary", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "\n", "# acc", "\n", "labels_hat_aux", "=", "torch", ".", "argmax", "(", "y_hat_aux", ",", "dim", "=", "1", ")", "\n", "val_acc_aux", "=", "torch", ".", "sum", "(", "y_aux", "==", "labels_hat_aux", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "labels_hat", "=", "(", "nn", ".", "Sigmoid", "(", ")", "(", "y_hat_aux", ")", ">", "0.5", ")", "\n", "val_acc_aux", "=", "jaccard_score", "(", "y_aux", ".", "cpu", "(", ")", ",", "labels_hat", ".", "cpu", "(", ")", ",", "average", "=", "'macro'", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "else", ":", "\n", "            ", "val_acc_aux", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "self", ".", "on_gpu", ":", "\n", "            ", "val_acc_aux", "=", "val_acc_aux", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "loss_val", "=", "loss_val", ".", "unsqueeze", "(", "0", ")", "\n", "#y = y.unsqueeze(0)", "\n", "#y_hat = y_hat.unsqueeze(0)", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "y_aux", ".", "type", "(", "torch", ".", "long", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "y_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels_hat", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_dev_dataset", ".", "columns", ")", ")", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "else", ":", "\n", "            ", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "[", "1", ",", "1", "]", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "output", "=", "OrderedDict", "(", "{", "\"val_loss\"", ":", "loss_val", ",", "\"labels\"", ":", "y", ",", "\"predictions\"", ":", "y_hat", ",", "\"conf_matrix_aux\"", ":", "conf_matrix_aux", ",", "'val_acc_aux'", ":", "val_acc_aux", "}", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "", "def", "test_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.test_step": [[310, 361], ["bert_regressor.BERTClassifier.forward", "collections.OrderedDict", "bert_regressor.BERTClassifier.loss", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.cuda", "torch.tensor.cuda", "loss_val.unsqueeze.unsqueeze.unsqueeze", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "sklearn.metrics.jaccard_score", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "bert_regressor.BERTClassifier.hparams.le_aux.inverse_transform", "bert_regressor.BERTClassifier.hparams.le_aux.inverse_transform", "sklearn.metrics.confusion_matrix", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "y_aux.cpu", "labels_hat.cpu", "y_aux.type().cpu().numpy", "torch.argmax.cpu().numpy", "torch.argmax.cpu().numpy", "y_aux.cpu().numpy().argmax", "labels_hat.cpu().numpy().argmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Sigmoid", "torch.Sigmoid", "numpy.arange", "y_aux.type().cpu", "torch.argmax.cpu", "torch.argmax.cpu", "y_aux.cpu().numpy", "labels_hat.cpu().numpy", "len", "y_aux.type", "y_aux.cpu", "labels_hat.cpu"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.forward", "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.loss"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "tuple", ",", "batch_nb", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Similar to the training step but with the model in eval mode.\n\n        Returns:\n            - dictionary passed to the test_end function.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "model_out", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "loss_val", "=", "self", ".", "loss", "(", "model_out", ",", "targets", ")", "[", "0", "]", "\n", "\n", "y", "=", "targets", "[", "\"labels\"", "]", "\n", "y_hat", "=", "model_out", "[", "\"logits\"", "]", "\n", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "# Auxiliary", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "# acc", "\n", "labels_hat_aux", "=", "torch", ".", "argmax", "(", "y_hat_aux", ",", "dim", "=", "1", ")", "\n", "val_acc_aux", "=", "torch", ".", "sum", "(", "y_aux", "==", "labels_hat_aux", ")", ".", "item", "(", ")", "/", "(", "len", "(", "y", ")", "*", "1.0", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "y_aux", "=", "targets", "[", "\"labels_aux\"", "]", "\n", "y_hat_aux", "=", "model_out", "[", "\"logits_aux\"", "]", "\n", "labels_hat", "=", "(", "nn", ".", "Sigmoid", "(", ")", "(", "y_hat_aux", ")", ">", "0.5", ")", "\n", "val_acc_aux", "=", "jaccard_score", "(", "y_aux", ".", "cpu", "(", ")", ",", "labels_hat", ".", "cpu", "(", ")", ",", "average", "=", "'macro'", ")", "\n", "val_acc_aux", "=", "torch", ".", "tensor", "(", "val_acc_aux", ")", "\n", "", "else", ":", "\n", "            ", "val_acc_aux", "=", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "self", ".", "on_gpu", ":", "\n", "            ", "val_acc_aux", "=", "val_acc_aux", ".", "cuda", "(", "loss_val", ".", "device", ".", "index", ")", "\n", "\n", "# in DP mode (default) make sure if result is scalar, there's another dim in the beginning", "\n", "", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "            ", "loss_val", "=", "loss_val", ".", "unsqueeze", "(", "0", ")", "\n", "#y = y.unsqueeze(0)", "\n", "#y_hat = y_hat.unsqueeze(0)", "\n", "val_acc_aux", "=", "val_acc_aux", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "y_aux", ".", "type", "(", "torch", ".", "long", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "self", ".", "hparams", ".", "le_aux", ".", "inverse_transform", "(", "labels_hat_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "labels", "=", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "conf_matrix_aux", "=", "confusion_matrix", "(", "y_aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels_hat", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "labels", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_test_dataset", ".", "columns", ")", ")", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "tensor", "(", "conf_matrix_aux", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "else", ":", "\n", "            ", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "[", "1", ",", "1", "]", ",", "device", "=", "loss_val", ".", "device", ".", "index", ")", "\n", "", "output", "=", "OrderedDict", "(", "{", "\"val_loss\"", ":", "loss_val", ",", "\"labels\"", ":", "y", ",", "\"predictions\"", ":", "y_hat", ",", "\"conf_matrix_aux\"", ":", "conf_matrix_aux", ",", "'val_acc_aux'", ":", "val_acc_aux", "}", ")", "\n", "\n", "# can also return just a scalar instead of a dict (return loss_val)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.train_epoch_end": [[362, 388], ["len", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "train_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", "}", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"train_loss\"", ":", "val_loss_mean", ",", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.validation_epoch_end": [[390, 426], ["numpy.zeros", "len", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_mean", "=", "0", "\n", "conf_matrix", "=", "np", ".", "zeros", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix\"", "]", ".", "shape", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "\n", "# reduce manually when using dp", "\n", "val_acc", "=", "output", "[", "\"val_acc\"", "]", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "val_acc", "=", "torch", ".", "mean", "(", "val_acc", ")", "\n", "\n", "", "val_acc_mean", "+=", "val_acc", "\n", "conf_matrix", "+=", "output", "[", "\"conf_matrix\"", "]", "\n", "\n", "", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\"val_acc\"", ":", "val_acc_mean", "}", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"conf_matrix\"", ":", "conf_matrix", ",", "\n", "}", "\n", "return", "result", "\n", "", "def", "validation_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.validation_end": [[426, 496], ["torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.array().flatten", "numpy.array().flatten", "len", "len", "matplotlib.close", "matplotlib.close", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "scipy.stats.pearsonr", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_regressor.BERTClassifier.logger.experiment.log_image", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "numpy.array", "numpy.array", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "bert_regressor.BERTClassifier.logger.experiment.log_image", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "torch.zeros.cpu", "torch.zeros.cpu", "int"], "methods", ["None"], ["", "def", "validation_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_acc_aux_mean", "=", "0", "\n", "val_y", "=", "torch", ".", "Tensor", "(", ")", ".", "to", "(", "outputs", "[", "0", "]", "[", "\"predictions\"", "]", ".", "device", ")", "\n", "val_y_hat", "=", "torch", ".", "Tensor", "(", ")", ".", "to", "(", "outputs", "[", "0", "]", "[", "\"predictions\"", "]", ".", "device", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "device", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "val_acc_aux", "=", "output", "[", "\"val_acc_aux\"", "]", "\n", "conf_matrix_aux_", "=", "output", "[", "\"conf_matrix_aux\"", "]", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "conf_matrix_aux_", "=", "sum", "(", "torch", ".", "split", "(", "conf_matrix_aux_", ",", "int", "(", "conf_matrix_aux_", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ")", ")", "\n", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "val_acc_aux", "=", "torch", ".", "mean", "(", "val_acc_aux", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "val_acc_aux_mean", "+=", "val_acc_aux", "\n", "# reduce manually when using dp", "\n", "val_y", "=", "torch", ".", "cat", "(", "[", "val_y", ",", "output", "[", "\"labels\"", "]", "]", ")", "\n", "val_y_hat", "=", "torch", ".", "cat", "(", "[", "val_y_hat", ",", "output", "[", "\"predictions\"", "]", "]", ")", "\n", "\n", "conf_matrix_aux", "+=", "conf_matrix_aux_", "\n", "", "val_labels", "=", "np", ".", "array", "(", "val_y", ".", "cpu", "(", ")", ",", "dtype", "=", "np", ".", "float", ")", ".", "flatten", "(", ")", "\n", "val_preds", "=", "np", ".", "array", "(", "val_y_hat", ".", "cpu", "(", ")", ",", "dtype", "=", "np", ".", "float", ")", ".", "flatten", "(", ")", "\n", "pearsonr", "=", "stats", ".", "pearsonr", "(", "val_labels", ",", "val_preds", ")", "[", "0", "]", "\n", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "val_acc_aux_mean", "/=", "len", "(", "outputs", ")", "\n", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_pearson\"", ":", "pearsonr", ",", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", "\n", "}", "\n", "\n", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "_dev_dataset", ".", "columns", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "_dev_dataset", ".", "columns", ")", "\n", "self", ".", "logger", ".", "experiment", ".", "log_image", "(", "'confusion matrix Aux'", ",", "fig", ")", "\n", "", "plt", ".", "close", "(", "'all'", ")", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_pearson\"", ":", "pearsonr", ",", "\n", "\"val_acc_aux\"", ":", "val_acc_aux_mean", ",", "\n", "}", "\n", "return", "result", "\n", "", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.test_epoch_end": [[496, 563], ["torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.array().flatten", "numpy.array().flatten", "len", "matplotlib.close", "matplotlib.close", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "scipy.stats.pearsonr", "open", "csv.writer", "csv.writer.writerows", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "numpy.array", "numpy.array", "zip", "torch.zeros.cpu", "torch.zeros.cpu", "matplotlib.figure", "matplotlib.figure", "matplotlib.axes", "matplotlib.axes", "seaborn.heatmap", "matplotlib.axes.set_xlabel", "matplotlib.axes.set_ylabel", "matplotlib.axes.set_title", "matplotlib.axes.xaxis.set_ticklabels", "matplotlib.axes.yaxis.set_ticklabels", "sum", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "torch.cat.cpu", "torch.zeros.cpu", "torch.zeros.cpu", "torch.split", "torch.split", "torch.split", "torch.split", "int"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", "->", "dict", ":", "\n", "        ", "\"\"\" Function that takes as input a list of dictionaries returned by the validation_step\n        function and measures the model performance accross the entire validation set.\n        \n        Returns:\n            - Dictionary with metrics to be added to the lightning logger.  \n        \"\"\"", "\n", "val_loss_mean", "=", "0", "\n", "val_y", "=", "torch", ".", "Tensor", "(", ")", ".", "to", "(", "outputs", "[", "0", "]", "[", "\"predictions\"", "]", ".", "device", ")", "\n", "val_y_hat", "=", "torch", ".", "Tensor", "(", ")", ".", "to", "(", "outputs", "[", "0", "]", "[", "\"predictions\"", "]", ".", "device", ")", "\n", "conf_matrix_aux", "=", "torch", ".", "zeros", "(", "int", "(", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ",", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "shape", "[", "1", "]", ",", "device", "=", "outputs", "[", "0", "]", "[", "\"conf_matrix_aux\"", "]", ".", "device", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "            ", "val_loss", "=", "output", "[", "\"val_loss\"", "]", "\n", "conf_matrix_aux_", "=", "output", "[", "\"conf_matrix_aux\"", "]", "\n", "# reduce manually when using dp", "\n", "if", "self", ".", "trainer", ".", "use_dp", "or", "self", ".", "trainer", ".", "use_ddp2", ":", "\n", "                ", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ":", "\n", "                    ", "conf_matrix_aux_", "=", "sum", "(", "torch", ".", "split", "(", "conf_matrix_aux_", ",", "int", "(", "conf_matrix_aux_", ".", "shape", "[", "0", "]", "/", "self", ".", "hparams", ".", "gpus", ")", ")", ")", "\n", "", "val_loss", "=", "torch", ".", "mean", "(", "val_loss", ")", "\n", "", "val_loss_mean", "+=", "val_loss", "\n", "\n", "# reduce manually when using dp", "\n", "val_y", "=", "torch", ".", "cat", "(", "[", "val_y", ",", "output", "[", "\"labels\"", "]", "]", ")", "\n", "val_y_hat", "=", "torch", ".", "cat", "(", "[", "val_y_hat", ",", "output", "[", "\"predictions\"", "]", "]", ")", "\n", "\n", "conf_matrix_aux", "+=", "conf_matrix_aux_", "\n", "", "val_labels", "=", "np", ".", "array", "(", "val_y", ".", "cpu", "(", ")", ",", "dtype", "=", "np", ".", "float", ")", ".", "flatten", "(", ")", "\n", "val_preds", "=", "np", ".", "array", "(", "val_y_hat", ".", "cpu", "(", ")", ",", "dtype", "=", "np", ".", "float", ")", ".", "flatten", "(", ")", "\n", "pearsonr", "=", "stats", ".", "pearsonr", "(", "val_labels", ",", "val_preds", ")", "[", "0", "]", "\n", "val_loss_mean", "/=", "len", "(", "outputs", ")", "\n", "tqdm_dict", "=", "{", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_pearson\"", ":", "pearsonr", ",", "\n", "}", "\n", "with", "open", "(", "self", ".", "hparams", ".", "checkpoint_path", "+", "'/predictions.csv'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerows", "(", "zip", "(", "val_preds", ",", "val_labels", ")", ")", "\n", "", "if", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", ")", "&", "(", "self", ".", "hparams", ".", "aux_task", "!=", "'emotions'", ")", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "hparams", ".", "le_aux", ".", "classes_", ")", "\n", "#print(conf_matrix_aux)", "\n", "#self.logger.experiment.log_image('confusion matrix Aux', fig)", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", ")", "\n", "sn", ".", "heatmap", "(", "conf_matrix_aux", ".", "cpu", "(", ")", ",", "annot", "=", "True", ",", "ax", "=", "ax", ")", "\n", "# labels, title and ticks", "\n", "ax", ".", "set_xlabel", "(", "'Predicted labels'", ")", "\n", "ax", ".", "set_ylabel", "(", "'True labels'", ")", "\n", "ax", ".", "set_title", "(", "'Confusion Matrix'", ")", "\n", "ax", ".", "xaxis", ".", "set_ticklabels", "(", "self", ".", "_test_dataset", ".", "columns", ")", "\n", "ax", ".", "yaxis", ".", "set_ticklabels", "(", "self", ".", "_test_dataset", ".", "columns", ")", "\n", "#self.logger.experiment.log_image('confusion matrix Aux', fig)", "\n", "", "plt", ".", "close", "(", "'all'", ")", "\n", "result", "=", "{", "\n", "\"progress_bar\"", ":", "tqdm_dict", ",", "\n", "\"log\"", ":", "tqdm_dict", ",", "\n", "\"val_loss\"", ":", "val_loss_mean", ",", "\n", "\"val_pearson\"", ":", "pearsonr", ",", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.configure_optimizers": [[564, 589], ["transformers.get_linear_schedule_with_warmup", "torch.optim.Adam", "torch.optim.Adam", "len", "bert_regressor.BERTClassifier.model.named_parameters", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "bert_regressor.BERTClassifier.train_dataloader", "int", "any", "bert_regressor.BERTClassifier.model.parameters", "aux_params.append", "params.append", "bert_regressor.BERTClassifier.model.parameters"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.train_dataloader"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\" Sets different Learning rates for different parameter groups. \"\"\"", "\n", "if", "self", ".", "hparams", ".", "aux_task", "!=", "'None'", "and", "self", ".", "hparams", ".", "gradnorm", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", ",", "{", "'params'", ":", "self", ".", "weights", ",", "'lr'", ":", "1e-2", "}", "]", ")", "\n", "", "elif", "self", ".", "hparams", ".", "aux_task", "==", "'emotions'", ":", "\n", "            ", "params", "=", "[", "]", "\n", "aux_params", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "[", "'classification_head_aux'", ",", "'pooler.dense_right'", ",", "'layer_right'", "]", ")", ":", "\n", "                    ", "aux_params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "params", ".", "append", "(", "p", ")", "\n", "", "", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "params", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", ",", "\n", "{", "'params'", ":", "aux_params", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "*", "10", "}", "]", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "hparams", ".", "learning_rate", "}", "]", ")", "\n", "", "train_steps", "=", "len", "(", "self", ".", "train_dataloader", "(", ")", ")", "*", "self", ".", "hparams", ".", "max_epochs", "\n", "#scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(self.hparams.warmup_proportion * train_steps), num_cycles =0.5, num_training_steps=train_steps)", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "int", "(", "self", ".", "hparams", ".", "warmup_proportion", "*", "train_steps", ")", ",", "num_training_steps", "=", "train_steps", ")", "\n", "scheduler", "=", "{", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'interval'", ":", "'step'", ",", "\n", "'frequency'", ":", "1", "\n", "}", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.on_epoch_end": [[590, 594], ["bert_regressor.BERTClassifier.unfreeze_encoder"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.unfreeze_encoder"], ["", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "\"\"\" Pytorch lightning hook \"\"\"", "\n", "if", "self", ".", "current_epoch", "+", "1", ">=", "self", ".", "nr_frozen_epochs", ":", "\n", "           ", "self", ".", "unfreeze_encoder", "(", ")", "\n", "", "", "def", "__retrieve_dataset", "(", "self", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset": [[594, 597], ["dataloader_regression.sentiment_analysis_dataset"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.sentiment_analysis_dataset"], ["", "", "def", "__retrieve_dataset", "(", "self", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", ")", ":", "\n", "        ", "\"\"\" Retrieves task specific dataset \"\"\"", "\n", "return", "sentiment_analysis_dataset", "(", "self", ".", "hparams", ",", "train", ",", "val", ",", "test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.train_dataloader": [[598, 608], ["bert_regressor.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.RandomSampler", "torch.utils.data.RandomSampler"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the train set. \"\"\"", "\n", "self", ".", "_train_dataset", "=", "self", ".", "__retrieve_dataset", "(", "val", "=", "False", ",", "test", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_train_dataset", ",", "\n", "sampler", "=", "RandomSampler", "(", "self", ".", "_train_dataset", ")", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.val_dataloader": [[610, 619], ["bert_regressor.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "val_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the validation set. \"\"\"", "\n", "self", ".", "_dev_dataset", "=", "self", ".", "__retrieve_dataset", "(", "train", "=", "False", ",", "test", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_dev_dataset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.test_dataloader": [[621, 630], ["bert_regressor.BERTClassifier.__retrieve_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.__retrieve_dataset"], ["", "@", "pl", ".", "data_loader", "\n", "def", "test_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "\"\"\" Function that loads the validation set. \"\"\"", "\n", "self", ".", "_test_dataset", "=", "self", ".", "__retrieve_dataset", "(", "train", "=", "False", ",", "val", "=", "False", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", "=", "self", ".", "_test_dataset", ",", "\n", "batch_size", "=", "self", ".", "hparams", ".", "batch_size", ",", "\n", "collate_fn", "=", "self", ".", "prepare_sample", ",", "\n", "num_workers", "=", "self", ".", "hparams", ".", "loader_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.bert_regressor.BERTClassifier.add_model_specific_args": [[632, 755], ["parser.add_argument", "parser.add_argument", "parser.opt_list", "parser.add_argument", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.opt_list", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_model_specific_args", "(", "\n", "cls", ",", "parser", ":", "HyperOptArgumentParser", "\n", ")", "->", "HyperOptArgumentParser", ":", "\n", "        ", "\"\"\" Parser for Estimator specific arguments/hyperparameters. \n        :param parser: HyperOptArgumentParser obj\n\n        Returns:\n            - updated parser\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_model\"", ",", "\n", "default", "=", "\"bert-base-uncased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Encoder model to be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradnorm\"", ",", "\n", "default", "=", "False", ",", "\n", "type", "=", "bool", ",", "\n", "help", "=", "\"Use Gradnorm for MTL.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--aux_task\"", ",", "\n", "default", "=", "'None'", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "'None'", ",", "'bias'", ",", "'group'", ",", "'emotions'", "]", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Use online logging for Neptune.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_learning_rate\"", ",", "\n", "default", "=", "1e-05", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Encoder specific learning rate.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-05", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "5e-05", ",", "3e-05", ",", "1e-05", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Classification head learning rate.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--loss_aux\"", ",", "\n", "default", "=", "0.25", ",", "\n", "tunable", "=", "True", ",", "\n", "options", "=", "[", "-", "0.85", ",", "-", "0.25", ",", "0.25", ",", "0.85", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add dropout to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--warmup_aux\"", ",", "\n", "default", "=", "5", ",", "\n", "tunable", "=", "True", ",", "\n", "options", "=", "[", "3", ",", "5", ",", "7", ",", "10", "]", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Add warmup scheduled learning.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--extra_dropout\"", ",", "\n", "default", "=", "0", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "0.05", ",", "0.1", ",", "0.15", ",", "0.2", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add dropout to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "0.1", ",", "0.2", ",", "0.3", "]", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Add warmup to Transformer.\"", ",", "\n", ")", "\n", "parser", ".", "opt_list", "(", "\n", "\"--nr_frozen_epochs\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of epochs we want to keep the encoder model frozen.\"", ",", "\n", "tunable", "=", "False", ",", "\n", "options", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_length\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Max length for text.\"", ",", "\n", ")", "\n", "# Data Args:", "\n", "parser", ".", "add_argument", "(", "\n", "\"--label_set\"", ",", "\n", "default", "=", "\"pos,neg\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Classification labels set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_csv\"", ",", "\n", "default", "=", "\"data/train_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the train data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dev_csv\"", ",", "\n", "default", "=", "\"data/valid_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the dev data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_csv\"", ",", "\n", "default", "=", "\"data/test_usvsthem.csv\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the file containing the dev data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--loader_workers\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"How many subprocesses to use for data loading. 0 means that \\\n                the data will be loaded in the main process.\"", ",", "\n", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.testing.main": [[28, 64], ["torchnlp.random.set_seed", "os.listdir", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.test", "checkpoint.endswith", "bert_classifier.BERTClassifier.load_from_checkpoint", "utils.setup_testube_logger", "os.path.join"], "function", ["home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.utils.setup_testube_logger"], ["def", "main", "(", "hparams", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main training routine specific for this project\n    :param hparams:\n    \"\"\"", "\n", "set_seed", "(", "hparams", ".", "seed", ")", "\n", "# ------------------------", "\n", "# 1 INIT LIGHTNING MODEL", "\n", "# ------------------------", "\n", "#model = BERTClassifier(hparams)", "\n", "for", "checkpoint", "in", "os", ".", "listdir", "(", "hparams", ".", "checkpoint_path", ")", ":", "\n", "        ", "if", "checkpoint", ".", "endswith", "(", "\".ckpt\"", ")", ":", "\n", "            ", "model", "=", "BERTClassifier", ".", "load_from_checkpoint", "(", "os", ".", "path", ".", "join", "(", "hparams", ".", "checkpoint_path", ",", "checkpoint", ")", ")", "\n", "# ------------------------", "\n", "# 2 INIT EARLY STOPPING", "\n", "# ------------------------", "\n", "# 3 INIT TRAINER", "\n", "# ------------------------", "\n", "\n", "", "", "model", ".", "hparams", ".", "checkpoint_path", "=", "hparams", ".", "checkpoint_path", "\n", "trainer", "=", "Trainer", "(", "\n", "logger", "=", "setup_testube_logger", "(", ")", ",", "\n", "#default_save_path=\"experiments/\",", "\n", "gpus", "=", "hparams", ".", "gpus", ",", "\n", "distributed_backend", "=", "\"dp\"", ",", "\n", "use_amp", "=", "False", ",", "\n", "max_epochs", "=", "hparams", ".", "max_epochs", ",", "\n", "min_epochs", "=", "hparams", ".", "min_epochs", ",", "\n", "accumulate_grad_batches", "=", "hparams", ".", "accumulate_grad_batches", ",", "\n", "val_percent_check", "=", "hparams", ".", "val_percent_check", ",", "\n", ")", "\n", "\n", "# ------------------------", "\n", "# 5 START TRAINING", "\n", "# ------------------------", "\n", "trainer", ".", "test", "(", "model", ")", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.training.main": [[14, 94], ["torchnlp.random.set_seed", "bert_classifier.BERTClassifier", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.logging.neptune.NeptuneLogger", "os.path.join", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "pytorch_lightning.Trainer.test", "pytorch_lightning.logging.neptune.NeptuneLogger.experiment.stop"], "function", ["None"], ["def", "main", "(", "hparams", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main training routine specific for this project\n    :param hparams:\n    \"\"\"", "\n", "set_seed", "(", "hparams", ".", "seed", ")", "\n", "# ------------------------", "\n", "# 1 INIT LIGHTNING MODEL", "\n", "# ------------------------", "\n", "model", "=", "BERTClassifier", "(", "hparams", ")", "\n", "# ------------------------", "\n", "# 2 INIT EARLY STOPPING", "\n", "# ------------------------", "\n", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "monitor", "=", "hparams", ".", "monitor", ",", "\n", "min_delta", "=", "0.0", ",", "\n", "patience", "=", "hparams", ".", "patience", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "hparams", ".", "metric_mode", ",", "\n", ")", "\n", "# ------------------------", "\n", "# 3 INIT TRAINER", "\n", "# ------------------------", "\n", "\n", "\n", "neptune_logger", "=", "NeptuneLogger", "(", "\n", "api_key", "=", "\"add_neptune_key\"", ",", "\n", "project_name", "=", "\"project_name\"", ",", "\n", "experiment_name", "=", "\"experiment_name\"", ",", "# Optional,", "\n", "offline_mode", "=", "hparams", ".", "log_mode", ",", "\n", "params", "=", "hparams", ".", "__dict__", ",", "\n", "upload_source_files", "=", "[", "'*.py'", "]", ",", "\n", "close_after_fit", "=", "False", ",", "\n", ")", "\n", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"experiments/\"", ",", "\n", "neptune_logger", ".", "name", ",", "\n", "f\"version_{neptune_logger.version}\"", ",", "\n", "\"checkpoints\"", ",", "\n", ")", "\n", "model", ".", "hparams", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"experiments/\"", ",", "\n", "neptune_logger", ".", "name", ",", "\n", "f\"version_{neptune_logger.version}\"", ")", "\n", "# initialize Model Checkpoint Saver", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "ckpt_path", ",", "\n", "save_top_k", "=", "hparams", ".", "save_top_k", ",", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "hparams", ".", "monitor", ",", "\n", "period", "=", "1", ",", "\n", "mode", "=", "hparams", ".", "metric_mode", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "logger", "=", "neptune_logger", ",", "\n", "#logger=setup_testube_logger(),", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "early_stop_callback", "=", "early_stop_callback", ",", "\n", "#default_save_path=\"experiments/\",", "\n", "gpus", "=", "hparams", ".", "gpus", ",", "\n", "distributed_backend", "=", "\"dp\"", ",", "\n", "use_amp", "=", "False", ",", "\n", "max_epochs", "=", "hparams", ".", "max_epochs", ",", "\n", "min_epochs", "=", "hparams", ".", "min_epochs", ",", "\n", "accumulate_grad_batches", "=", "hparams", ".", "accumulate_grad_batches", ",", "\n", "val_percent_check", "=", "hparams", ".", "val_percent_check", ",", "\n", "#callbacks = [lr_logger],", "\n", "#nb_sanity_val_steps=0,", "\n", ")", "\n", "\n", "# --------------------------------", "\n", "# 4 INIT MODEL CHECKPOINT CALLBACK", "\n", "# -------------------------------", "\n", "\n", "# ------------------------", "\n", "# 5 START TRAINING", "\n", "# ------------------------", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "trainer", ".", "test", "(", ")", "\n", "neptune_logger", ".", "experiment", ".", "stop", "(", ")", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.RedditDataset.__init__": [[15, 34], ["pandas.read_csv", "dataloader.RedditDataset.comments[].apply", "le.transform", "dataloader.RedditDataset.comments[].values.tolist", "list", "le_aux.fit", "le_aux.transform"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_csv", "=", "'file.csv'", ",", "aux_task", "=", "'group'", ",", "le", "=", "None", ",", "le_aux", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"", "\n", "self", ".", "comments", "=", "pd", ".", "read_csv", "(", "data_csv", ")", "\n", "self", ".", "comments", "[", "'raw_label'", "]", "=", "self", ".", "comments", "[", "'is_Disc_Crit'", "]", ".", "apply", "(", "lambda", "x", ":", "'Against'", "if", "x", "==", "True", "else", "'For'", ")", "\n", "self", ".", "comments", "[", "'label'", "]", "=", "le", ".", "transform", "(", "self", ".", "comments", "[", "'raw_label'", "]", ")", "\n", "if", "aux_task", "==", "'None'", ":", "\n", "            ", "aux_task", "=", "'group'", "\n", "", "if", "aux_task", "==", "'emotions'", ":", "\n", "            ", "self", ".", "comments", "[", "'label_aux'", "]", "=", "self", ".", "comments", "[", "[", "'Anger'", ",", "'Contempt'", ",", "'Disgust'", ",", "'Fear'", ",", "'Hope'", ",", "'Pride'", ",", "'Sympathy'", ",", "'Emotions_Neutral'", "]", "]", ".", "values", ".", "tolist", "(", ")", "\n", "self", ".", "columns", "=", "list", "(", "self", ".", "comments", "[", "[", "'Anger'", ",", "'Contempt'", ",", "'Disgust'", ",", "'Fear'", ",", "'Hope'", ",", "'Pride'", ",", "'Sympathy'", ",", "'Emotions_Neutral'", "]", "]", ".", "columns", ")", "\n", "", "else", ":", "\n", "            ", "le_aux", ".", "fit", "(", "self", ".", "comments", "[", "aux_task", "]", ".", "values", ")", "\n", "self", ".", "comments", "[", "'label_aux'", "]", "=", "le_aux", ".", "transform", "(", "self", ".", "comments", "[", "aux_task", "]", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.RedditDataset.__len__": [[35, 37], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "comments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.RedditDataset.__getitem__": [[38, 40], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "comments", ".", "iloc", "[", "idx", "]", "[", "[", "'body'", ",", "'label'", ",", "'label_aux'", ",", "'group'", ",", "'bias'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__init__": [[48, 51], ["transformers.AutoTokenizer.from_pretrained"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "max_length", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "max_length", "=", "max_length", "\n", "", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.MyCollator.__call__": [[51, 59], ["dataloader.MyCollator.tokenizer", "torch.tensor", "torch.tensor", "re.sub"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "output", "=", "{", "}", "\n", "texts", "=", "[", "re", ".", "sub", "(", "r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*'", ",", "'LINK'", ",", "comment", "[", "'body'", "]", ",", "\n", "flags", "=", "re", ".", "MULTILINE", ")", "for", "comment", "in", "batch", "]", "\n", "tokenized", "=", "self", ".", "tokenizer", "(", "texts", ",", "padding", "=", "'longest'", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_length", ",", "return_tensors", "=", "'pt'", ",", "add_special_tokens", "=", "True", ")", "\n", "output", "[", "'labels'", "]", "=", "torch", ".", "tensor", "(", "[", "element", "[", "'label'", "]", "for", "element", "in", "batch", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "output", "[", "'labels_aux'", "]", "=", "torch", ".", "tensor", "(", "[", "element", "[", "'label_aux'", "]", "for", "element", "in", "batch", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "return", "tokenized", ".", "data", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.pad_seq": [[42, 46], ["len"], "function", ["None"], ["", "", "def", "pad_seq", "(", "seq", ",", "max_batch_len", ",", "pad_value", ")", ":", "\n", "# IRL, use pad_sequence", "\n", "# https://pytorch.org/docs/master/generated/torch.nn.utils.rnn.pad_sequence.html", "\n", "    ", "return", "seq", "+", "(", "max_batch_len", "-", "len", "(", "seq", ")", ")", "*", "[", "pad_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.dataloader.sentiment_analysis_dataset": [[60, 80], ["dataloader.RedditDataset", "dataloader.RedditDataset", "dataloader.RedditDataset"], "function", ["None"], ["", "", "def", "sentiment_analysis_dataset", "(", "\n", "hparams", ":", "HyperOptArgumentParser", ",", "train", "=", "True", ",", "val", "=", "True", ",", "test", "=", "True", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads the Dataset from the csv files passed to the parser.\n    :param hparams: HyperOptArgumentParser obj containg the path to the data files.\n    :param train: flag to return the train set.\n    :param val: flag to return the validation set.\n    :param test: flag to return the test set.\n\n    Returns:\n        - Training Dataset, Development Dataset, Testing Dataset\n    \"\"\"", "\n", "if", "train", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "train_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "if", "val", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "dev_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "if", "test", ":", "\n", "        ", "dataset", "=", "RedditDataset", "(", "hparams", ".", "test_csv", ",", "hparams", ".", "aux_task", ",", "hparams", ".", "le", ",", "hparams", ".", "le_aux", ")", "\n", "", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.training_reg.main": [[14, 94], ["torchnlp.random.set_seed", "bert_regressor.BERTClassifier", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.logging.neptune.NeptuneLogger", "os.path.join", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "pytorch_lightning.Trainer.test", "pytorch_lightning.logging.neptune.NeptuneLogger.experiment.stop"], "function", ["None"], ["def", "main", "(", "hparams", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main training routine specific for this project\n    :param hparams:\n    \"\"\"", "\n", "set_seed", "(", "hparams", ".", "seed", ")", "\n", "# ------------------------", "\n", "# 1 INIT LIGHTNING MODEL", "\n", "# ------------------------", "\n", "model", "=", "BERTClassifier", "(", "hparams", ")", "\n", "# ------------------------", "\n", "# 2 INIT EARLY STOPPING", "\n", "# ------------------------", "\n", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "monitor", "=", "hparams", ".", "monitor", ",", "\n", "min_delta", "=", "0.0", ",", "\n", "patience", "=", "hparams", ".", "patience", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "hparams", ".", "metric_mode", ",", "\n", ")", "\n", "# ------------------------", "\n", "# 3 INIT TRAINER", "\n", "# ------------------------", "\n", "\n", "# lr_logger = LearningRateLogger()", "\n", "neptune_logger", "=", "NeptuneLogger", "(", "\n", "api_key", "=", "\"add_neptune_key\"", ",", "\n", "project_name", "=", "\"project_name\"", ",", "\n", "experiment_name", "=", "\"experiment_name\"", ",", "# Optional,", "\n", "offline_mode", "=", "hparams", ".", "log_mode", ",", "\n", "params", "=", "hparams", ".", "__dict__", ",", "\n", "upload_source_files", "=", "[", "'*.py'", "]", ",", "\n", "close_after_fit", "=", "False", ",", "\n", ")", "\n", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"experiments/\"", ",", "\n", "neptune_logger", ".", "name", ",", "\n", "f\"version_{neptune_logger.version}\"", ",", "\n", "\"checkpoints\"", ",", "\n", ")", "\n", "model", ".", "hparams", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"experiments/\"", ",", "\n", "neptune_logger", ".", "name", ",", "\n", "f\"version_{neptune_logger.version}\"", ")", "\n", "# initialize Model Checkpoint Saver", "\n", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "ckpt_path", ",", "\n", "save_top_k", "=", "hparams", ".", "save_top_k", ",", "\n", "verbose", "=", "True", ",", "\n", "monitor", "=", "hparams", ".", "monitor", ",", "\n", "period", "=", "1", ",", "\n", "mode", "=", "hparams", ".", "metric_mode", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "logger", "=", "neptune_logger", ",", "\n", "#logger=setup_testube_logger(),", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "early_stop_callback", "=", "early_stop_callback", ",", "\n", "#default_save_path=\"experiments/\",", "\n", "gpus", "=", "hparams", ".", "gpus", ",", "\n", "distributed_backend", "=", "\"dp\"", ",", "\n", "use_amp", "=", "False", ",", "\n", "max_epochs", "=", "hparams", ".", "max_epochs", ",", "\n", "min_epochs", "=", "hparams", ".", "min_epochs", ",", "\n", "accumulate_grad_batches", "=", "hparams", ".", "accumulate_grad_batches", ",", "\n", "val_percent_check", "=", "hparams", ".", "val_percent_check", ",", "\n", "#callbacks = [lr_logger],", "\n", "#nb_sanity_val_steps=0,", "\n", ")", "\n", "\n", "# --------------------------------", "\n", "# 4 INIT MODEL CHECKPOINT CALLBACK", "\n", "# -------------------------------", "\n", "\n", "# ------------------------", "\n", "# 5 START TRAINING", "\n", "# ------------------------", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "trainer", ".", "test", "(", ")", "\n", "neptune_logger", ".", "experiment", ".", "stop", "(", ")", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.LittlePea13_UsVsThem.src.utils.setup_testube_logger": [[9, 22], ["datetime.datetime.now", "datetime.now.strftime", "pytorch_lightning.logging.TestTubeLogger"], "function", ["None"], ["def", "setup_testube_logger", "(", ")", "->", "TestTubeLogger", ":", "\n", "    ", "\"\"\" Function that sets the TestTubeLogger to be used. \"\"\"", "\n", "try", ":", "\n", "        ", "job_id", "=", "os", ".", "environ", "[", "\"SLURM_JOB_ID\"", "]", "\n", "", "except", "Exception", ":", "\n", "        ", "job_id", "=", "None", "\n", "\n", "", "now", "=", "datetime", ".", "now", "(", ")", "\n", "dt_string", "=", "now", ".", "strftime", "(", "\"%d-%m-%Y--%H-%M-%S\"", ")", "\n", "return", "TestTubeLogger", "(", "\n", "save_dir", "=", "\"experiments/\"", ",", "\n", "version", "=", "job_id", "+", "\"_\"", "+", "dt_string", "if", "job_id", "else", "dt_string", ",", "\n", "name", "=", "\"lightning_logs\"", ",", "\n", ")", ""]]}