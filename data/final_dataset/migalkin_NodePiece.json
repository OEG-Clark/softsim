{"home.repos.pwc.inspect_result.migalkin_NodePiece.lp_rp.run_lp.main": [[30, 257], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "nodepiece_tokenizer.NodePiece_Tokenizer", "pykeen.utils.resolve_device", "evaluator_type", "pykeen.stoppers.EarlyStopper", "evaluator_type", "evaluator_type.evaluate", "print", "print", "pykeen.datasets.FB15k237", "dict", "dict", "print", "pykeen.losses.SoftplusLoss", "pykeen.models.RotatE", "torch.optim.Adam", "print", "pykeen.training.SLCWATrainingLoop", "pykeen105.nodepiece_rotate.NodePieceRotate", "torch.optim.Adam", "print", "pykeen.trackers.WANDBResultTracker", "pykeen.trackers.WANDBResultTracker.wandb.config.update", "pykeen.training.LCWATrainingLoop.train", "pykeen.training.LCWATrainingLoop.train", "pykeen.trackers.WANDBResultTracker.log_metrics", "pykeen.datasets.WN18RR", "pykeen.losses.BCEWithLogitsLoss", "loop_type", "pykeen.training.LCWATrainingLoop", "pykeen.datasets.YAGO310", "pykeen.losses.MarginRankingLoss", "pykeen105.nodepiece_rotate.NodePieceRotate.parameters", "pykeen105.nodepiece_rotate.NodePieceRotate.parameters", "wandb.Settings", "click.get_current_context", "test_evaluator.evaluate.to_flat_dict", "datasets.codex.CoDExLarge", "pykeen.losses.NSSALoss", "sum", "sum", "p.numel", "p.numel", "pykeen105.nodepiece_rotate.NodePieceRotate.parameters", "pykeen105.nodepiece_rotate.NodePieceRotate.parameters"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.RotatE", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.to_flat_dict"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'-embedding'", ",", "'--embedding-dimension'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "# embedding dim for anchors and relations", "\n", "@", "click", ".", "option", "(", "'-loss'", ",", "'--loss_fc'", ",", "type", "=", "str", ",", "default", "=", "'nssal'", ")", "\n", "@", "click", ".", "option", "(", "'-loop'", ",", "'--loop'", ",", "type", "=", "str", ",", "default", "=", "'slcwa'", ")", "# slcwa - negative sampling, lcwa - 1-N scoring", "\n", "@", "click", ".", "option", "(", "'-trf_hidden'", ",", "'--transformer-hidden-dim'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "@", "click", ".", "option", "(", "'-trf_heads'", ",", "'--transformer-num-heads'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "@", "click", ".", "option", "(", "'-trf_layers'", ",", "'--transformer-layers'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "@", "click", ".", "option", "(", "'-trf_drop'", ",", "'--transformer-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "@", "click", ".", "option", "(", "'-b'", ",", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "@", "click", ".", "option", "(", "'-epochs'", ",", "'--num-epochs'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "@", "click", ".", "option", "(", "'-lr'", ",", "'--learning-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0005", ")", "\n", "@", "click", ".", "option", "(", "'-wandb'", ",", "'--enable_wandb'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "@", "click", ".", "option", "(", "'-anchors'", ",", "'--topk_anchors'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "# how many total anchors to use", "\n", "@", "click", ".", "option", "(", "'-data'", ",", "'--dataset_name'", ",", "type", "=", "str", ",", "default", "=", "'wn18rr'", ")", "\n", "@", "click", ".", "option", "(", "'-anc_deg'", ",", "'--strategy_degree'", ",", "type", "=", "float", ",", "default", "=", "0.4", ")", "# % of anchors selected based on top node degree", "\n", "@", "click", ".", "option", "(", "'-anc_betw'", ",", "'--strategy_betweenness'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "# disabled", "\n", "@", "click", ".", "option", "(", "'-anc_ppr'", ",", "'--strategy_pagerank'", ",", "type", "=", "float", ",", "default", "=", "0.4", ")", "# % of anchors selected based on top PPR", "\n", "@", "click", ".", "option", "(", "'-anc_rand'", ",", "'--strategy_random'", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "# % of randomly selected anchors", "\n", "@", "click", ".", "option", "(", "'-sp'", ",", "'--k_shortest_paths'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "# when mining anchors per node - keep K closest", "\n", "@", "click", ".", "option", "(", "'-rp'", ",", "'--k_random_paths'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "# when mining anchors per node - keep K random", "\n", "@", "click", ".", "option", "(", "'-eval_every'", ",", "'--eval_every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "@", "click", ".", "option", "(", "'-mtype'", ",", "'--model_type'", ",", "type", "=", "str", ",", "default", "=", "\"nodepiece\"", ")", "# or \"rotate\" for the baseline", "\n", "@", "click", ".", "option", "(", "'-ft_maxp'", ",", "'--ft_max_paths'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "# max anchor per node, should be <= total N of anchors", "\n", "@", "click", ".", "option", "(", "'-anc_dist'", ",", "'--use_anchor_distances'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "# whether to add anchor distances", "\n", "@", "click", ".", "option", "(", "'-margin'", ",", "'--margin'", ",", "type", "=", "float", ",", "default", "=", "15", ")", "\n", "@", "click", ".", "option", "(", "'-max_seq_len'", ",", "'--max_seq_len'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "@", "click", ".", "option", "(", "'-pool'", ",", "'--pooling'", ",", "type", "=", "str", ",", "default", "=", "\"cat\"", ")", "# available encoders: \"cat\" or \"trf\"", "\n", "@", "click", ".", "option", "(", "'-subbatch'", ",", "'--trf_subbatch'", ",", "type", "=", "int", ",", "default", "=", "3000", ")", "\n", "@", "click", ".", "option", "(", "'-negs'", ",", "'--num_negatives_ent'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# number of negative samples when training LP in sLCWA", "\n", "@", "click", ".", "option", "(", "'-negs-rel'", ",", "'--num_negatives-rel'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# Optional: number of negative relations when training RP in sLCWA", "\n", "@", "click", ".", "option", "(", "'-rel-prediction'", ",", "'--rel-prediction'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# swtich to the Relation Prediction task (RP)", "\n", "@", "click", ".", "option", "(", "'-smoothing'", ",", "'--lbl_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "# label smoothing in the 1-N setup", "\n", "@", "click", ".", "option", "(", "'-relpol'", ",", "'--rel_policy'", ",", "type", "=", "str", ",", "default", "=", "\"sum\"", ")", "\n", "@", "click", ".", "option", "(", "'-filtered_sampling'", ",", "'--filtered_sampling'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "@", "click", ".", "option", "(", "'-rand_hashes'", ",", "'--random_hashing'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "# for ablations: use only random numbers as hashes", "\n", "@", "click", ".", "option", "(", "'-nn'", ",", "'--nearest_neighbors'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "# use only nearest anchors per node", "\n", "@", "click", ".", "option", "(", "'-sample_rels'", ",", "'--sample_rels'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "# size of the relational context M", "\n", "@", "click", ".", "option", "(", "'-anchor_eye'", ",", "'--anchor_eye'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# anchors in their own hashes will have their index at the frist place", "\n", "@", "click", ".", "option", "(", "'-tkn_mode'", ",", "'--tkn_mode'", ",", "type", "=", "str", ",", "default", "=", "\"path\"", ")", "# mining paths in iGRAPH", "\n", "@", "click", ".", "option", "(", "'-no_anc'", ",", "'--ablate_anchors'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# don't use any anchors in hashes, keep only the relational context", "\n", "def", "main", "(", "\n", "embedding_dimension", ",", "\n", "loss_fc", ",", "\n", "loop", ",", "\n", "transformer_hidden_dim", ":", "int", ",", "\n", "transformer_num_heads", ":", "int", ",", "\n", "transformer_layers", ":", "int", ",", "\n", "transformer_dropout", ":", "float", ",", "\n", "batch_size", ":", "int", ",", "\n", "num_epochs", ":", "int", ",", "\n", "learning_rate", ":", "float", ",", "\n", "enable_wandb", ":", "bool", ",", "\n", "topk_anchors", ":", "int", ",", "\n", "dataset_name", ":", "str", ",", "\n", "strategy_degree", ":", "float", ",", "\n", "strategy_betweenness", ":", "float", ",", "\n", "strategy_pagerank", ":", "float", ",", "\n", "strategy_random", ":", "float", ",", "\n", "k_shortest_paths", ":", "int", ",", "\n", "k_random_paths", ":", "int", ",", "\n", "eval_every", ":", "int", ",", "\n", "model_type", ":", "str", ",", "\n", "ft_max_paths", ":", "int", ",", "\n", "use_anchor_distances", ":", "bool", ",", "\n", "margin", ":", "float", ",", "\n", "max_seq_len", ":", "int", ",", "\n", "pooling", ":", "str", ",", "\n", "trf_subbatch", ":", "int", ",", "\n", "num_negatives_ent", ":", "int", ",", "\n", "num_negatives_rel", ":", "int", ",", "\n", "rel_prediction", ":", "bool", ",", "\n", "lbl_smoothing", ":", "float", ",", "\n", "rel_policy", ":", "str", ",", "\n", "filtered_sampling", ":", "bool", ",", "\n", "random_hashing", ":", "int", ",", "\n", "nearest_neighbors", ":", "bool", ",", "\n", "sample_rels", ":", "int", ",", "\n", "anchor_eye", ":", "bool", ",", "\n", "tkn_mode", ":", "str", ",", "\n", "ablate_anchors", ":", "bool", ",", "\n", ")", ":", "\n", "# Standard dataset loading procedures, inverses are necessary for reachability of nodes", "\n", "    ", "if", "dataset_name", "==", "'fb15k237'", ":", "\n", "        ", "dataset", "=", "FB15k237", "(", "create_inverse_triples", "=", "True", ")", "\n", "", "elif", "dataset_name", "==", "'wn18rr'", ":", "\n", "        ", "dataset", "=", "WN18RR", "(", "create_inverse_triples", "=", "True", ")", "\n", "", "elif", "dataset_name", "==", "\"yago\"", ":", "\n", "        ", "dataset", "=", "YAGO310", "(", "create_inverse_triples", "=", "True", ")", "\n", "", "elif", "dataset_name", "==", "\"codex_l\"", ":", "\n", "        ", "dataset", "=", "CoDExLarge", "(", "create_inverse_triples", "=", "True", ")", "\n", "\n", "# if we're in the RP task - change the evaluator", "\n", "", "if", "rel_prediction", ":", "\n", "        ", "evaluator_type", "=", "RelationPredictionRankBasedEvaluator", "\n", "", "else", ":", "\n", "        ", "evaluator_type", "=", "RankBasedEvaluator", "\n", "\n", "# sampling even harder negatives - turned off by default", "\n", "", "if", "filtered_sampling", ":", "\n", "        ", "negative_sampler_cls", "=", "RelationalNegativeSampler", "\n", "negative_sampler_kwargs", "=", "dict", "(", "num_negs_per_pos", "=", "num_negatives_ent", ",", "num_negs_per_pos_rel", "=", "num_negatives_rel", ",", "\n", "dataset_name", "=", "dataset_name", ")", "\n", "loop_type", "=", "FilteredSLCWATrainingLoop", "\n", "", "else", ":", "\n", "        ", "negative_sampler_cls", "=", "BasicNegativeSampler", "\n", "negative_sampler_kwargs", "=", "dict", "(", "num_negs_per_pos", "=", "num_negatives_ent", ")", "\n", "loop_type", "=", "SLCWATrainingLoop", "\n", "\n", "\n", "", "training_triples_factory", "=", "dataset", ".", "training", "\n", "\n", "# Now let's create a NodePiece tokenizer", "\n", "kg_tokenizer", "=", "NodePiece_Tokenizer", "(", "triples", "=", "training_triples_factory", ",", "\n", "anchor_strategy", "=", "{", "\n", "\"degree\"", ":", "strategy_degree", ",", "\n", "\"betweenness\"", ":", "strategy_betweenness", ",", "\n", "\"pagerank\"", ":", "strategy_pagerank", ",", "\n", "\"random\"", ":", "strategy_random", "\n", "}", ",", "\n", "num_anchors", "=", "topk_anchors", ",", "dataset_name", "=", "dataset_name", ",", "limit_shortest", "=", "k_shortest_paths", ",", "\n", "add_identity", "=", "anchor_eye", ",", "mode", "=", "tkn_mode", ",", "limit_random", "=", "k_random_paths", ")", "\n", "\n", "device", "=", "resolve_device", "(", ")", "\n", "\n", "# cater for corner cases when user-input max seq len is incorrect", "\n", "if", "max_seq_len", "==", "0", "or", "max_seq_len", "!=", "(", "kg_tokenizer", ".", "max_seq_len", "+", "3", ")", ":", "\n", "        ", "max_seq_len", "=", "kg_tokenizer", ".", "max_seq_len", "+", "3", "# as in the PathTrfEncoder, +1 CLS, +1 PAD, +1 LP tasks", "\n", "print", "(", "f\"Set max_seq_len to{max_seq_len}\"", ")", "\n", "\n", "# for stability", "\n", "", "kg_tokenizer", ".", "token2id", "[", "kg_tokenizer", ".", "NOTHING_TOKEN", "]", "=", "kg_tokenizer", ".", "vocab_size", "\n", "\n", "# selecting the loss function", "\n", "if", "loss_fc", "==", "\"softplus\"", ":", "\n", "        ", "ft_loss", "=", "SoftplusLoss", "(", ")", "\n", "", "elif", "loss_fc", "==", "\"bce\"", ":", "\n", "        ", "ft_loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "loss_fc", "==", "\"mrl\"", ":", "\n", "        ", "ft_loss", "=", "MarginRankingLoss", "(", "margin", "=", "margin", ")", "\n", "", "elif", "loss_fc", "==", "\"nssal\"", ":", "\n", "        ", "ft_loss", "=", "NSSALoss", "(", "margin", "=", "margin", ")", "\n", "\n", "", "train_factory", "=", "dataset", ".", "training", "\n", "validation_factory", "=", "dataset", ".", "validation", "\n", "\n", "if", "model_type", "==", "\"baseline\"", ":", "\n", "        ", "finetuning_model", "=", "RotatE", "(", "embedding_dim", "=", "embedding_dimension", "//", "2", ",", "triples_factory", "=", "train_factory", ",", "\n", "loss", "=", "ft_loss", ",", "automatic_memory_optimization", "=", "False", ",", "preferred_device", "=", "device", ")", "\n", "optimizer", "=", "Adam", "(", "params", "=", "finetuning_model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ")", "\n", "print", "(", "f\"Vanilla rotate created, Number of params: {sum(p.numel() for p in finetuning_model.parameters())}\"", ")", "\n", "ft_loop", "=", "SLCWATrainingLoop", "(", "model", "=", "finetuning_model", ",", "optimizer", "=", "optimizer", ")", "\n", "\n", "", "else", ":", "\n", "        ", "finetuning_model", "=", "NodePieceRotate", "(", "embedding_dim", "=", "embedding_dimension", ",", "device", "=", "device", ",", "loss", "=", "ft_loss", ",", "\n", "triples", "=", "train_factory", ",", "max_paths", "=", "ft_max_paths", ",", "subbatch", "=", "trf_subbatch", ",", "\n", "max_seq_len", "=", "max_seq_len", ",", "tokenizer", "=", "kg_tokenizer", ",", "pooler", "=", "pooling", ",", "\n", "hid_dim", "=", "transformer_hidden_dim", ",", "num_heads", "=", "transformer_num_heads", ",", "\n", "use_distances", "=", "use_anchor_distances", ",", "num_layers", "=", "transformer_layers", ",", "drop_prob", "=", "transformer_dropout", ",", "\n", "rel_policy", "=", "rel_policy", ",", "random_hashes", "=", "random_hashing", ",", "nearest", "=", "nearest_neighbors", ",", "\n", "sample_rels", "=", "sample_rels", ",", "ablate_anchors", "=", "ablate_anchors", ",", "tkn_mode", "=", "tkn_mode", ")", "\n", "\n", "optimizer", "=", "Adam", "(", "params", "=", "finetuning_model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ")", "\n", "print", "(", "f\"Number of params: {sum(p.numel() for p in finetuning_model.parameters())}\"", ")", "\n", "\n", "if", "loop", "==", "\"slcwa\"", ":", "\n", "            ", "ft_loop", "=", "loop_type", "(", "model", "=", "finetuning_model", ",", "optimizer", "=", "optimizer", ",", "negative_sampler_cls", "=", "negative_sampler_cls", ",", "\n", "negative_sampler_kwargs", "=", "negative_sampler_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "ft_loop", "=", "LCWATrainingLoop", "(", "model", "=", "finetuning_model", ",", "optimizer", "=", "optimizer", ")", "\n", "\n", "# add the results tracker if requested", "\n", "", "", "if", "enable_wandb", ":", "\n", "        ", "project_name", "=", "\"NodePiece_LP\"", "\n", "if", "rel_prediction", ":", "\n", "            ", "project_name", "+=", "\"_RP\"", "\n", "\n", "", "tracker", "=", "WANDBResultTracker", "(", "project", "=", "project_name", ",", "group", "=", "None", ",", "settings", "=", "wandb", ".", "Settings", "(", "start_method", "=", "'fork'", ")", ")", "\n", "tracker", ".", "wandb", ".", "config", ".", "update", "(", "click", ".", "get_current_context", "(", ")", ".", "params", ")", "\n", "", "else", ":", "\n", "        ", "tracker", "=", "None", "\n", "\n", "", "valid_evaluator", "=", "evaluator_type", "(", ")", "\n", "valid_evaluator", ".", "batch_size", "=", "256", "\n", "\n", "# we don't actually use the early stopper here by setting the patience to 1000", "\n", "early_stopper", "=", "EarlyStopper", "(", "\n", "model", "=", "finetuning_model", ",", "\n", "relative_delta", "=", "0.0005", ",", "\n", "evaluation_triples_factory", "=", "validation_factory", ",", "\n", "frequency", "=", "eval_every", ",", "\n", "patience", "=", "1000", ",", "\n", "result_tracker", "=", "tracker", ",", "\n", "evaluation_batch_size", "=", "256", ",", "\n", "evaluator", "=", "valid_evaluator", ",", "\n", ")", "\n", "\n", "# Train LP / RP", "\n", "if", "loop", "==", "\"lcwa\"", ":", "\n", "        ", "ft_loop", ".", "train", "(", "num_epochs", "=", "num_epochs", ",", "batch_size", "=", "batch_size", ",", "result_tracker", "=", "tracker", ",", "\n", "stopper", "=", "early_stopper", ",", "label_smoothing", "=", "lbl_smoothing", ")", "\n", "", "else", ":", "\n", "        ", "ft_loop", ".", "train", "(", "num_epochs", "=", "num_epochs", ",", "batch_size", "=", "batch_size", ",", "result_tracker", "=", "tracker", ",", "\n", "stopper", "=", "early_stopper", ")", "\n", "\n", "# run the final test eval", "\n", "", "test_evaluator", "=", "evaluator_type", "(", ")", "\n", "test_evaluator", ".", "batch_size", "=", "256", "\n", "\n", "# test_evaluator", "\n", "metric_results", "=", "test_evaluator", ".", "evaluate", "(", "\n", "model", "=", "finetuning_model", ",", "\n", "mapped_triples", "=", "dataset", ".", "testing", ".", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "[", "dataset", ".", "training", ".", "mapped_triples", ",", "dataset", ".", "validation", ".", "mapped_triples", "]", ",", "\n", "use_tqdm", "=", "True", ",", "\n", "batch_size", "=", "256", ",", "\n", ")", "\n", "\n", "# log final results", "\n", "if", "enable_wandb", ":", "\n", "        ", "tracker", ".", "log_metrics", "(", "\n", "metrics", "=", "metric_results", ".", "to_flat_dict", "(", ")", ",", "\n", "step", "=", "num_epochs", "+", "1", ",", "\n", "prefix", "=", "'test'", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"Test results\"", ")", "\n", "print", "(", "metric_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.lp_rp.nodepiece_tokenizer.NodePiece_Tokenizer.__init__": [[21, 81], ["super().__init__", "set", "set().issubset", "nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg", "max", "Exception", "sum", "len", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.values", "set", "enumerate", "len", "enumerate", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.keys", "list", "nodepiece_tokenizer.NodePiece_Tokenizer.vocab.items", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.relation_to_id.values"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg"], ["def", "__init__", "(", "self", ",", "\n", "triples", ":", "TriplesFactory", ",", "\n", "dataset_name", ":", "str", ",", "\n", "num_anchors", ":", "int", ",", "\n", "anchor_strategy", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "limit_shortest", ":", "int", "=", "0", ",", "\n", "limit_random", ":", "int", "=", "0", ",", "\n", "add_identity", ":", "bool", "=", "True", ",", "\n", "mode", ":", "str", "=", "\"path\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "triples_factory", "=", "triples", "# original triples of the training graph, assuming inverses are added", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "num_anchors", "=", "num_anchors", "# total N anchor nodes", "\n", "self", ".", "anchor_strategy", "=", "anchor_strategy", "# ratios of strategies for sampling anchor nodes", "\n", "self", ".", "num_paths", "=", "num_anchors", "# aux variable", "\n", "self", ".", "sp_limit", "=", "limit_shortest", "# keep only K nearest anchor nodes per entity", "\n", "self", ".", "rand_limit", "=", "limit_random", "# keep only K random anchor nodes per entity", "\n", "\n", "if", "self", ".", "sp_limit", "*", "self", ".", "rand_limit", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"-sp_limit and -rand_limit are mutually exclusive\"", ")", "\n", "\n", "", "self", ".", "add_identity", "=", "add_identity", "# anchor nodes will have their own indices with distance 0  in their hashes", "\n", "self", ".", "tkn_mode", "=", "mode", "# only \"path\" mode is implemented atm", "\n", "\n", "# auxiliary tokens for the vocabulary", "\n", "self", ".", "NOTHING_TOKEN", "=", "-", "99", "# means the node is not reachable from any of anchor nodes", "\n", "self", ".", "CLS_TOKEN", "=", "-", "1", "\n", "self", ".", "MASK_TOKEN", "=", "-", "10", "\n", "self", ".", "PADDING_TOKEN", "=", "-", "100", "\n", "self", ".", "SEP_TOKEN", "=", "-", "2", "\n", "\n", "# well, betwenness is disabled", "\n", "self", ".", "AVAILABLE_STRATEGIES", "=", "set", "(", "[", "\"degree\"", ",", "\"betweenness\"", ",", "\"pagerank\"", ",", "\"random\"", "]", ")", "\n", "\n", "assert", "sum", "(", "self", ".", "anchor_strategy", ".", "values", "(", ")", ")", "==", "1.0", ",", "\"Ratios of strategies should sum up to one\"", "\n", "assert", "set", "(", "self", ".", "anchor_strategy", ".", "keys", "(", ")", ")", ".", "issubset", "(", "self", ".", "AVAILABLE_STRATEGIES", ")", "\n", "\n", "# load or create the vocabulary", "\n", "self", ".", "top_entities", ",", "self", ".", "other_entities", ",", "self", ".", "vocab", "=", "self", ".", "tokenize_kg", "(", ")", "\n", "\n", "# numerical indices for entities and relations", "\n", "self", ".", "token2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "top_entities", ")", "}", "\n", "self", ".", "rel2token", "=", "{", "t", ":", "i", "+", "len", "(", "self", ".", "top_entities", ")", "for", "i", ",", "t", "in", "\n", "enumerate", "(", "list", "(", "self", ".", "triples_factory", ".", "relation_to_id", ".", "values", "(", ")", ")", ")", "}", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "token2id", ")", "+", "len", "(", "self", ".", "rel2token", ")", "\n", "\n", "# although we don't use paths, we count their lengths for anchor distances", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", "]", ")", "\n", "\n", "if", "self", ".", "add_identity", ":", "\n", "# add identity for anchor nodes as the first / closest node", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "# last 4 are always service tokens", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "=", "[", "[", "anchor", "]", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", ":", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "=", "[", "anchor", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "[", ":", "-", "1", "]", "\n", "self", ".", "vocab", "[", "anchor", "]", "[", "'dists'", "]", "[", "0", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.lp_rp.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg": [[84, 144], ["pathlib.Path", "pathlib.Path.is_file", "igraph.Graph", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.items", "nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths", "pickle.dump", "print", "filename.split", "pickle.load", "type", "print", "int", "print", "anchors.extend", "print", "open", "open", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "zip", "numpy.ceil", "sorted", "range", "list", "NotImplementedError", "sorted", "len", "enumerate", "igraph.Graph.degree", "enumerate", "int", "numpy.random.permutation", "igraph.Graph.personalized_pagerank", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths"], ["", "", "", "", "def", "tokenize_kg", "(", "self", ")", ":", "\n", "\n", "# creating a filename", "\n", "        ", "strategy_encoding", "=", "f\"d{self.anchor_strategy['degree']}_b{self.anchor_strategy['betweenness']}_p{self.anchor_strategy['pagerank']}_r{self.anchor_strategy['random']}\"", "\n", "\n", "filename", "=", "f\"data/{self.dataset_name}_{self.num_anchors}_anchors_{self.num_paths}_paths_{strategy_encoding}_pykeen\"", "\n", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.sp_limit}sp\"", "# for separating vocabs with limited mined shortest paths", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.rand_limit}rand\"", "\n", "", "if", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "            ", "filename", "+=", "\"_bfs\"", "\n", "", "filename", "+=", "\".pkl\"", "\n", "self", ".", "model_name", "=", "filename", ".", "split", "(", "'.pkl'", ")", "[", "0", "]", "\n", "path", "=", "Path", "(", "filename", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "            ", "anchors", ",", "non_anchors", ",", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "return", "anchors", ",", "non_anchors", ",", "vocab", "\n", "\n", "", "if", "type", "(", "self", ".", "triples_factory", ".", "mapped_triples", ")", "==", "torch", ".", "Tensor", ":", "\n", "            ", "src", ",", "tgt", ",", "rels", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "0", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "2", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "1", "]", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Input triples are expected to be in the torch.Tensor format\"", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "# create an input object for iGraph - edge list with relation types, and then create a graph", "\n", "", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", ",", "r", "in", "zip", "(", "src", ",", "tgt", ",", "rels", ")", "]", "\n", "graph", "=", "Graph", "(", "n", "=", "self", ".", "triples_factory", ".", "num_entities", ",", "edges", "=", "edgelist", ",", "edge_attrs", "=", "{", "'relation'", ":", "list", "(", "rels", ")", "}", ",", "directed", "=", "True", ")", "\n", "\n", "# sampling anchor nodes", "\n", "anchors", "=", "[", "]", "\n", "for", "strategy", ",", "ratio", "in", "self", ".", "anchor_strategy", ".", "items", "(", ")", ":", "\n", "            ", "if", "ratio", "<=", "0.0", ":", "\n", "                ", "continue", "\n", "", "topK", "=", "int", "(", "np", ".", "ceil", "(", "ratio", "*", "self", ".", "num_anchors", ")", ")", "\n", "print", "(", "f\"Computing the {strategy} nodes\"", ")", "\n", "if", "strategy", "==", "\"degree\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "degree", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"betweenness\"", ":", "\n", "# This is O(V^3) - disabled", "\n", "                ", "raise", "NotImplementedError", "(", "\"Betweenness is disabled due to computational costs\"", ")", "\n", "", "elif", "strategy", "==", "\"pagerank\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "personalized_pagerank", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"random\"", ":", "\n", "                ", "top_nodes", "=", "[", "(", "int", "(", "k", ")", ",", "1", ")", "for", "k", "in", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", "]", "\n", "\n", "", "selected_nodes", "=", "[", "node", "for", "node", ",", "d", "in", "top_nodes", "if", "node", "not", "in", "anchors", "]", "[", ":", "topK", "]", "\n", "\n", "anchors", ".", "extend", "(", "selected_nodes", ")", "\n", "print", "(", "f\"Added {len(selected_nodes)} nodes under the {strategy} strategy\"", ")", "\n", "\n", "# now mine the anchors per node", "\n", "", "vocab", "=", "self", ".", "create_all_paths", "(", "graph", ",", "anchors", ")", "\n", "top_entities", "=", "anchors", "+", "[", "self", ".", "CLS_TOKEN", "]", "+", "[", "self", ".", "MASK_TOKEN", "]", "+", "[", "self", ".", "PADDING_TOKEN", "]", "+", "[", "self", ".", "SEP_TOKEN", "]", "\n", "non_core_entities", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "if", "i", "not", "in", "anchors", "]", "\n", "\n", "pickle", ".", "dump", "(", "(", "top_entities", ",", "non_core_entities", ",", "vocab", ")", ",", "open", "(", "filename", ",", "\"wb\"", ")", ")", "\n", "print", "(", "\"Vocabularized and saved!\"", ")", "\n", "\n", "return", "top_entities", ",", "non_core_entities", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.lp_rp.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths": [[146, 192], ["tqdm.tqdm.tqdm", "print", "print", "set", "range", "graph.get_shortest_paths", "len", "random.shuffle", "sorted", "len", "graph.neighborhood", "list", "nearest_ancs.extend", "anc_dists.extend", "range", "set().intersection().difference", "nearest_ancs.extend", "anc_dists.extend", "len", "set", "len", "set().intersection", "range", "len", "range", "range", "set", "len", "len"], "methods", ["None"], ["", "def", "create_all_paths", "(", "self", ",", "graph", ":", "Graph", ",", "top_entities", ":", "List", "=", "None", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "\n", "        ", "vocab", "=", "{", "}", "\n", "if", "self", ".", "rand_limit", "==", "0", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.sp_limit if self.sp_limit >0 else self.num_paths} shortest paths per node\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.rand_limit} random paths per node\"", ")", "\n", "\n", "", "if", "self", ".", "tkn_mode", ":", "\n", "            ", "anc_set", "=", "set", "(", "top_entities", ")", "\n", "\n", "# single-threaded mining is found to be as fast as multi-processing + igraph for some reason, so let's use a dummy for-loop", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", ":", "\n", "            ", "if", "self", ".", "tkn_mode", "==", "\"path\"", ":", "\n", "                ", "paths", "=", "graph", ".", "get_shortest_paths", "(", "v", "=", "i", ",", "to", "=", "top_entities", ",", "output", "=", "\"epath\"", ",", "mode", "=", "'in'", ")", "\n", "if", "len", "(", "paths", "[", "0", "]", ")", ">", "0", ":", "\n", "                    ", "relation_paths", "=", "[", "[", "graph", ".", "es", "[", "path", "[", "-", "1", "]", "]", ".", "source", "]", "+", "[", "graph", ".", "es", "[", "k", "]", "[", "'relation'", "]", "for", "k", "in", "path", "[", ":", ":", "-", "1", "]", "]", "for", "path", "in", "paths", "if", "len", "(", "path", ")", ">", "0", "]", "\n", "", "else", ":", "\n", "# if NO anchor can be reached from the node - encode with a special NOTHING_TOKEN", "\n", "                    ", "relation_paths", "=", "[", "[", "self", ".", "NOTHING_TOKEN", "]", "for", "_", "in", "range", "(", "self", ".", "num_paths", ")", "]", "\n", "", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "                    ", "relation_paths", "=", "sorted", "(", "relation_paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "self", ".", "sp_limit", "]", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "                    ", "random", ".", "shuffle", "(", "relation_paths", ")", "\n", "relation_paths", "=", "relation_paths", "[", ":", "self", ".", "rand_limit", "]", "\n", "", "vocab", "[", "i", "]", "=", "relation_paths", "\n", "", "elif", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "# overall limit of anchors per node", "\n", "                ", "limit", "=", "self", ".", "sp_limit", "if", "self", ".", "sp_limit", "!=", "0", "else", "(", "self", ".", "rand_limit", "if", "self", ".", "rand_limit", "!=", "0", "else", "self", ".", "num_paths", ")", "\n", "nearest_ancs", ",", "anc_dists", "=", "[", "]", ",", "[", "]", "\n", "hop", "=", "1", "\n", "while", "len", "(", "nearest_ancs", ")", "<", "limit", ":", "\n", "                    ", "neigbs", "=", "graph", ".", "neighborhood", "(", "vertices", "=", "i", ",", "order", "=", "hop", ",", "mode", "=", "\"in\"", ",", "mindist", "=", "hop", ")", "# get k-hop neighbors", "\n", "ancs", "=", "list", "(", "set", "(", "neigbs", ")", ".", "intersection", "(", "anc_set", ")", ".", "difference", "(", "set", "(", "nearest_ancs", ")", ")", ")", "# find anchors in this neighborhood", "\n", "nearest_ancs", ".", "extend", "(", "ancs", ")", "# update the list of anchors", "\n", "anc_dists", ".", "extend", "(", "[", "hop", "for", "_", "in", "range", "(", "len", "(", "ancs", ")", ")", "]", ")", "# update the list of anchor distances", "\n", "hop", "+=", "1", "\n", "if", "hop", ">=", "50", ":", "# hardcoded constant for a disconnected node", "\n", "                        ", "nearest_ancs", ".", "extend", "(", "[", "self", ".", "NOTHING_TOKEN", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "nearest_ancs", ")", ")", "]", ")", "\n", "anc_dists", ".", "extend", "(", "[", "0", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "anc_dists", ")", ")", "]", ")", "\n", "break", "\n", "", "", "vocab", "[", "i", "]", "=", "{", "'ancs'", ":", "nearest_ancs", "[", ":", "limit", "]", ",", "'dists'", ":", "anc_dists", "[", ":", "limit", "]", "}", "# update the vocabulary", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "return", "vocab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.__init__": [[19, 179], ["pykeen.models.Model.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Embedding", "torch.tensor", "torch.zeros", "torch.zeros", "collections.defaultdict", "print", "torch.tensor", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoder", "max", "print", "random.sample", "e2r[].add", "len", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.Linear", "NotImplementedError", "list", "range", "row[].item", "collections.defaultdict.items", "random.sample", "range", "random.sample", "max", "print", "sampled_paths.items", "sampled_paths.items", "len", "sampled_paths.items", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "range", "min", "numpy.mean", "numpy.percentile", "max", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "min", "min", "min", "sorted", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "len", "len", "len", "len", "len", "len", "row[].item", "len", "len", "len", "min", "sampled_paths.items", "len", "min", "min", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample"], ["    ", "def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "NodePiece_Tokenizer", "=", "None", ",", "\n", "triples", ":", "TriplesFactory", "=", "None", ",", "\n", "device", ":", "torch", ".", "device", "=", "None", ",", "\n", "loss", ":", "Loss", "=", "None", ",", "\n", "max_paths", ":", "int", "=", "None", ",", "# max anchors per node", "\n", "subbatch", ":", "int", "=", "32", ",", "\n", "max_seq_len", ":", "int", "=", "None", ",", "# tied with anchor distances", "\n", "embedding_dim", ":", "int", "=", "100", ",", "\n", "hid_dim", ":", "int", "=", "200", ",", "# hidden dim for the hash encoder", "\n", "num_heads", ":", "int", "=", "4", ",", "# for Trf", "\n", "num_layers", ":", "int", "=", "2", ",", "# for Trf", "\n", "pooler", ":", "str", "=", "\"cat\"", ",", "# \"cat\" or \"trf\"", "\n", "drop_prob", ":", "float", "=", "0.1", ",", "# dropout", "\n", "use_distances", ":", "bool", "=", "True", ",", "\n", "rel_policy", ":", "str", "=", "\"sum\"", ",", "\n", "random_hashes", ":", "int", "=", "0", ",", "# for ablations", "\n", "nearest", ":", "bool", "=", "True", ",", "# use only K nearest anchors per node", "\n", "sample_rels", ":", "int", "=", "0", ",", "# size of the relational context", "\n", "ablate_anchors", ":", "bool", "=", "False", ",", "# for ablations - node hashes will be constructed only from the relational context", "\n", "tkn_mode", ":", "str", "=", "\"path\"", ",", "# default NodePiece vocabularization strategy", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "triples_factory", "=", "triples", ",", "\n", "loss", "=", "loss", ",", "\n", "predict_with_sigmoid", "=", "False", ",", "\n", "automatic_memory_optimization", "=", "False", ",", "\n", "preferred_device", "=", "device", ",", "\n", ")", "\n", "\n", "self", ".", "pooler", "=", "pooler", "\n", "self", ".", "policy", "=", "rel_policy", "\n", "self", ".", "nearest", "=", "nearest", "\n", "self", ".", "sample_rels", "=", "sample_rels", "\n", "self", ".", "ablate_anchors", "=", "ablate_anchors", "\n", "self", ".", "tkn_mode", "=", "tkn_mode", "\n", "\n", "# cat pooler - concat all anchors+relations in one big vector, pass through a 2-layer MLP", "\n", "if", "pooler", "==", "\"cat\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "(", "max_paths", "+", "sample_rels", ")", ",", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "2", ",", "embedding_dim", ")", "\n", ")", "if", "not", "self", ".", "ablate_anchors", "else", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "sample_rels", ",", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "2", ",", "embedding_dim", ")", "\n", ")", "\n", "# trf pooler - vanilla transformer encoder with mean pooling on top", "\n", "", "elif", "pooler", "==", "\"trf\"", ":", "\n", "            ", "encoder_layer", "=", "TransformerEncoderLayer", "(", "\n", "d_model", "=", "embedding_dim", ",", "\n", "nhead", "=", "num_heads", ",", "\n", "dim_feedforward", "=", "hid_dim", ",", "\n", "dropout", "=", "drop_prob", ",", "\n", ")", "\n", "self", ".", "set_enc", "=", "TransformerEncoder", "(", "encoder_layer", "=", "encoder_layer", ",", "num_layers", "=", "num_layers", ")", "\n", "\n", "\n", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "triples_factory", "=", "triples", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "random_hashes", "=", "random_hashes", "\n", "\n", "self", ".", "subbatch", "=", "subbatch", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "real_embedding_dim", "=", "embedding_dim", "//", "2", "# RotatE interaction assumes vectors conists of two parts: real and imaginary", "\n", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "sample_paths", "=", "max_paths", "\n", "self", ".", "use_distances", "=", "use_distances", "\n", "\n", "# pykeen stuff", "\n", "self", ".", "automatic_memory_optimization", "=", "False", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "NOTHING_TOKEN", "]", "=", "len", "(", "tokenizer", ".", "token2id", ")", "-", "1", "# TODO this is a bugfix as PathTrfEncoder puts its own index here", "\n", "\n", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tokenizer", ".", "token2id", ")", ",", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", ")", "\n", "self", ".", "relation_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "triples_factory", ".", "num_relations", "+", "1", ",", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "self", ".", "triples_factory", ".", "num_relations", ")", "\n", "self", ".", "dist_emb", "=", "nn", ".", "Embedding", "(", "self", ".", "max_seq_len", ",", "embedding_dim", "=", "embedding_dim", ")", "\n", "self", ".", "entity_embeddings", "=", "None", "\n", "\n", "# now fix anchors per node for each node in a graph, either deterministically or randomly", "\n", "# we do it mostly for speed reasons, although this process can happen during the forward pass either", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "# DETERMINISTIC strategy", "\n", "                ", "if", "not", "self", ".", "nearest", ":", "\n", "# subsample paths, need to align them with distances", "\n", "                    ", "sampled_paths", "=", "{", "\n", "entity", ":", "random", ".", "sample", "(", "paths", ",", "k", "=", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", ")", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "self", ".", "nearest", ":", "\n", "# sort paths by length first and take K of them", "\n", "                    ", "sampled_paths", "=", "{", "\n", "entity", ":", "sorted", "(", "paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", "]", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "max_seq_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "sampled_paths", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "print", "(", "f\"Changed max seq len from {max_seq_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "path", "[", "0", "]", "]", "for", "path", "in", "paths", "]", "+", "[", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "len", "(", "path", ")", "-", "1", "for", "path", "in", "paths", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "total_paths", "=", "[", "\n", "[", "len", "(", "paths", ")", "]", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "", "else", ":", "\n", "# only nearest neighbors mode", "\n", "                ", "if", "not", "self", ".", "nearest", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"bfs mode works only with -nn True\"", ")", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "token", "]", "for", "token", "in", "vals", "[", "'ancs'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "]", "]", "+", "[", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "d", "for", "d", "in", "vals", "[", "'dists'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "]", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "total_paths", "=", "distances", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "d", "for", "row", "in", "distances", "for", "d", "in", "row", "]", ")", "\n", "print", "(", "f\"Changed max seq len from {max_seq_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "tensor", "(", "distances", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "total_paths", "=", "torch", ".", "tensor", "(", "total_paths", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "else", ":", "\n", "# RANDOM strategy", "\n", "# in this case, we bypass distances and won't use relations in the encoder", "\n", "            ", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "random_hashes", ",", "embedding_dim", "=", "embedding_dim", ")", "\n", "hashes", "=", "[", "\n", "random", ".", "sample", "(", "list", "(", "range", "(", "random_hashes", ")", ")", ",", "self", ".", "sample_paths", ")", "\n", "for", "i", "in", "range", "(", "triples", ".", "num_entities", ")", "\n", "]", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "zeros", "(", "(", "triples", ".", "num_entities", ",", "self", ".", "sample_paths", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "total_paths", "=", "torch", ".", "zeros", "(", "(", "triples", ".", "num_entities", ",", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# creating the relational context of M unique outgoing relation types for each node", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "pad_idx", "=", "self", ".", "triples_factory", ".", "num_relations", "\n", "e2r", "=", "defaultdict", "(", "set", ")", "\n", "for", "row", "in", "self", ".", "triples_factory", ".", "mapped_triples", ":", "\n", "                ", "e2r", "[", "row", "[", "0", "]", ".", "item", "(", ")", "]", ".", "add", "(", "row", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "", "len_stats", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "e2r", ".", "items", "(", ")", "]", "\n", "print", "(", "f\"Unique relations per node - min: {min(len_stats)}, avg: {np.mean(len_stats)}, 66th perc: {np.percentile(len_stats, 66)}, max: {max(len_stats)} \"", ")", "\n", "unique_1hop_relations", "=", "[", "\n", "random", ".", "sample", "(", "e2r", "[", "i", "]", ",", "k", "=", "min", "(", "self", ".", "sample_rels", ",", "len", "(", "e2r", "[", "i", "]", ")", ")", ")", "+", "[", "pad_idx", "]", "*", "(", "self", ".", "sample_rels", "-", "min", "(", "len", "(", "e2r", "[", "i", "]", ")", ",", "self", ".", "sample_rels", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "\n", "]", "\n", "self", ".", "unique_1hop_relations", "=", "torch", ".", "tensor", "(", "unique_1hop_relations", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate._reset_parameters_": [[181, 214], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.stack().detach", "torch.allclose", "torch.stack().detach.view", "torch.zeros", "nodepiece_rotate.NodePieceRotate.set_enc.modules", "torch.rand", "torch.norm", "phases.new_ones", "hasattr", "nodepiece_rotate.NodePieceRotate.set_dec.modules", "torch.no_grad", "torch.zeros", "torch.zeros", "torch.stack", "module.reset_parameters", "hasattr", "module.reset_parameters", "torch.cos", "torch.sin"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "", "def", "_reset_parameters_", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooler", "!=", "\"avg\"", ":", "\n", "            ", "for", "module", "in", "self", ".", "set_enc", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "                ", "for", "module", "in", "self", ".", "set_dec", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "module", "is", "self", ":", "\n", "                        ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                        ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "\n", "", "", "", "", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "anchor_embeddings", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dist_emb", ".", "weight", ")", "\n", "\n", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "anchor_embeddings", ".", "weight", "[", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "dist_emb", ".", "weight", "[", "0", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "\n", "\n", "# for RotatE: phases randomly between 0 and 2 pi", "\n", "", "", "phases", "=", "2", "*", "np", ".", "pi", "*", "torch", ".", "rand", "(", "self", ".", "num_relations", ",", "self", ".", "real_embedding_dim", ",", "device", "=", "self", ".", "device", ")", "\n", "relations", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cos", "(", "phases", ")", ",", "torch", ".", "sin", "(", "phases", ")", "]", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "torch", ".", "norm", "(", "relations", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", ",", "phases", ".", "new_ones", "(", "size", "=", "(", "1", ",", "1", ")", ")", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "[", ":", "-", "1", "]", "=", "relations", ".", "view", "(", "self", ".", "num_relations", ",", "self", ".", "embedding_dim", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "[", "-", "1", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.post_parameter_update": [[216, 227], ["super().post_parameter_update", "nodepiece_rotate.NodePieceRotate.relation_embeddings.weight.data.view", "torch.nn.functional.normalize", "torch.nn.functional.normalize.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.post_parameter_update", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize"], ["", "def", "post_parameter_update", "(", "self", ")", ":", "# noqa: D102", "\n", "\n", "# Make sure to call super first", "\n", "        ", "super", "(", ")", ".", "post_parameter_update", "(", ")", "\n", "\n", "# Normalize relation embeddings", "\n", "rel", "=", "self", ".", "relation_embeddings", ".", "weight", ".", "data", ".", "view", "(", "self", ".", "num_relations", "+", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "rel", "=", "functional", ".", "normalize", "(", "rel", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "=", "rel", ".", "view", "(", "self", ".", "num_relations", "+", "1", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "self", ".", "entity_embeddings", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.pool_anchors": [[229, 243], ["anc_embs.view.view.view", "nodepiece_rotate.NodePieceRotate.set_enc", "nodepiece_rotate.NodePieceRotate.set_enc", "pooled.mean.mean.mean", "anc_embs.view.view.transpose"], "methods", ["None"], ["", "def", "pool_anchors", "(", "self", ",", "anc_embs", ":", "torch", ".", "FloatTensor", ",", "mask", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        input shape: (bs, num_anchors + relational_context, emb_dim)\n        output shape: (bs, emb_dim)\n        \"\"\"", "\n", "\n", "if", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "anc_embs", "=", "anc_embs", ".", "view", "(", "anc_embs", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "if", "self", ".", "sample_paths", "!=", "1", "else", "anc_embs", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ".", "transpose", "(", "1", ",", "0", ")", ")", "# output shape: (seq_len, bs, dim)", "\n", "pooled", "=", "pooled", ".", "mean", "(", "dim", "=", "0", ")", "# output shape: (bs, dim)", "\n", "\n", "", "return", "pooled", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.encode_by_index": [[245, 271], ["nodepiece_rotate.NodePieceRotate.anchor_embeddings", "nodepiece_rotate.NodePieceRotate.pool_anchors", "nodepiece_rotate.NodePieceRotate.dist_emb", "torch.tensor", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors"], ["", "def", "encode_by_index", "(", "self", ",", "entities", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "# take a node index and find its NodePiece hash", "\n", "\n", "        ", "hashes", ",", "dists", ",", "ids", "=", "self", ".", "hashes", "[", "entities", "]", ",", "self", ".", "distances", "[", "entities", "]", ",", "self", ".", "total_paths", "[", "entities", "]", "\n", "\n", "anc_embs", "=", "self", ".", "anchor_embeddings", "(", "hashes", ")", "\n", "mask", "=", "None", "\n", "\n", "if", "self", ".", "use_distances", ":", "\n", "            ", "dist_embs", "=", "self", ".", "dist_emb", "(", "dists", ")", "\n", "anc_embs", "+=", "dist_embs", "\n", "\n", "# for ablations: drop anchors entirely", "\n", "", "if", "self", ".", "ablate_anchors", ":", "\n", "            ", "anc_embs", "=", "torch", ".", "tensor", "(", "[", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# add relational context (if its size > 0 )", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "rels", "=", "self", ".", "unique_1hop_relations", "[", "entities", "]", "# (bs, rel_sample_size)", "\n", "rels", "=", "self", ".", "relation_embeddings", "(", "rels", ")", "# (bs, rel_sample_size, dim)", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "rels", "]", ",", "dim", "=", "1", ")", "# (bs, ancs+rel_sample_size, dim)", "\n", "\n", "", "anc_embs", "=", "self", ".", "pool_anchors", "(", "anc_embs", ",", "mask", "=", "mask", ")", "# (bs, dim)", "\n", "\n", "return", "anc_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.get_all_representations": [[273, 286], ["torch.zeros", "list", "tqdm.tqdm.tqdm", "range", "range", "torch.tensor", "nodepiece_rotate.NodePieceRotate.encode_by_index", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], ["", "def", "get_all_representations", "(", "self", ")", ":", "\n", "\n", "# materialize embeddings for all nodes in a graph for scoring", "\n", "\n", "        ", "temp_embs", "=", "torch", ".", "zeros", "(", "(", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "embedding_dim", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "vocab_keys", "=", "list", "(", "range", "(", "len", "(", "self", ".", "hashes", ")", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "            ", "entities", "=", "torch", ".", "tensor", "(", "vocab_keys", "[", "i", ":", "i", "+", "self", ".", "subbatch", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "embs", "=", "self", ".", "encode_by_index", "(", "entities", ")", "\n", "temp_embs", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", "]", "=", "embs", "\n", "\n", "", "return", "temp_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.pairwise_interaction_function": [[288, 310], ["torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pairwise_interaction_function", "(", "\n", "h", ":", "torch", ".", "FloatTensor", ",", "\n", "r", ":", "torch", ".", "FloatTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "# Decompose into real and imaginary part", "\n", "        ", "h_re", "=", "h", "[", "...", ",", "0", "]", "\n", "h_im", "=", "h", "[", "...", ",", "1", "]", "\n", "r_re", "=", "r", "[", "...", ",", "0", "]", "\n", "r_im", "=", "r", "[", "...", ",", "1", "]", "\n", "\n", "# Rotate (=Hadamard product in complex space).", "\n", "rot_h", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "h_re", "*", "r_re", "-", "h_im", "*", "r_im", ",", "\n", "h_re", "*", "r_im", "+", "h_im", "*", "r_re", ",", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "\n", "return", "rot_h", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.interaction_function": [[311, 337], ["torch.stack", "torch.norm", "diff.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "interaction_function", "(", "\n", "h", ":", "torch", ".", "FloatTensor", ",", "\n", "r", ":", "torch", ".", "FloatTensor", ",", "\n", "t", ":", "torch", ".", "FloatTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "# Decompose into real and imaginary part", "\n", "        ", "h_re", "=", "h", "[", "...", ",", "0", "]", "\n", "h_im", "=", "h", "[", "...", ",", "1", "]", "\n", "r_re", "=", "r", "[", "...", ",", "0", "]", "\n", "r_im", "=", "r", "[", "...", ",", "1", "]", "\n", "\n", "# Rotate (=Hadamard product in complex space).", "\n", "rot_h", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "h_re", "*", "r_re", "-", "h_im", "*", "r_im", ",", "\n", "h_re", "*", "r_im", "+", "h_im", "*", "r_re", ",", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "# Workaround until https://github.com/pytorch/pytorch/issues/30704 is fixed", "\n", "diff", "=", "rot_h", "-", "t", "\n", "scores", "=", "-", "torch", ".", "norm", "(", "diff", ".", "view", "(", "diff", ".", "shape", "[", ":", "-", "2", "]", "+", "(", "-", "1", ",", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.score_hrt": [[338, 362], ["nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.interaction_function().view", "torch.zeros", "range", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.interaction_function().view", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.interaction_function", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.interaction_function"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function"], ["", "def", "score_hrt", "(", "self", ",", "hrt_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "\n", "# when training with large # of neg samples the hrt_batch size can be too big to fit into memory, so chunk it", "\n", "        ", "if", "hrt_batch", ".", "shape", "[", "0", "]", "<=", "self", ".", "subbatch", "or", "self", ".", "subbatch", "==", "0", ":", "\n", "# Get embeddings", "\n", "            ", "h", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hrt_batch", "[", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "t", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", ":", ",", "2", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "hrt_batch", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "hrt_batch", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "hrt_batch", ".", "shape", "[", "0", "]", ",", "self", ".", "subbatch", ")", ":", "\n", "                ", "h", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "t", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "2", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "scores", "[", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.score_t": [[364, 383], ["nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.get_all_representations().view", "nodepiece_rotate.NodePieceRotate.interaction_function", "torch.zeros", "tqdm.tqdm.tqdm", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.get_all_representations", "range", "nodepiece_rotate.NodePieceRotate.interaction_function"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function"], ["", "def", "score_t", "(", "self", ",", "hr_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "# Get embeddings", "\n", "        ", "h", "=", "self", ".", "encode_by_index", "(", "hr_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hr_batch", "[", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Rank against all entities, don't use hard negs, EXPENSIVE", "\n", "t", "=", "self", ".", "get_all_representations", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "if", "self", ".", "subbatch", "==", "0", ":", "\n", "            ", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "hr_batch", ".", "shape", "[", "0", "]", ",", "t", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "hr_batch", ".", "device", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "t", ".", "shape", "[", "1", "]", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "                ", "temp_scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", ",", ":", "]", ")", "\n", "scores", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "temp_scores", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.nodepiece_rotate.NodePieceRotate.score_h": [[384, 406], ["nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "torch.stack", "nodepiece_rotate.NodePieceRotate.get_all_representations().view", "nodepiece_rotate.NodePieceRotate.interaction_function", "torch.zeros", "tqdm.tqdm.tqdm", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.get_all_representations", "range", "nodepiece_rotate.NodePieceRotate.interaction_function"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function"], ["", "def", "score_h", "(", "self", ",", "rt_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "# Get embeddings", "\n", "        ", "r", "=", "self", ".", "relation_embeddings", "(", "rt_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "t", "=", "self", ".", "encode_by_index", "(", "rt_batch", "[", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "r_inv", "=", "torch", ".", "stack", "(", "[", "r", "[", ":", ",", ":", ",", ":", ",", "0", "]", ",", "-", "r", "[", ":", ",", ":", ",", ":", ",", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Rank against all entities", "\n", "h", "=", "self", ".", "get_all_representations", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "if", "self", ".", "subbatch", "==", "0", ":", "\n", "            ", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "t", ",", "r", "=", "r_inv", ",", "t", "=", "h", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "rt_batch", ".", "shape", "[", "0", "]", ",", "t", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "rt_batch", ".", "device", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "t", ".", "shape", "[", "1", "]", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "                ", "temp_scores", "=", "self", ".", "interaction_function", "(", "h", "=", "t", ",", "r", "=", "r_inv", ",", "t", "=", "h", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", ",", ":", "]", ")", "\n", "scores", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "temp_scores", "\n", "\n", "\n", "", "", "return", "scores", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.FilteredNegativeSampler.__init__": [[37, 59], ["pykeen.sampling.NegativeSampler.__init__", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.makedirs", "negative_sampler.get_true_subject_and_object_per_graph", "open", "pickle.load", "open", "pickle.load", "open", "pickle.load", "os.path.join", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.get_true_subject_and_object_per_graph"], ["    ", "def", "__init__", "(", "self", ",", "triples_factory", ",", "num_negs_per_pos", "=", "None", ",", "dataset_name", "=", "'fb15k237'", ")", ":", "\n", "        ", "super", "(", "FilteredNegativeSampler", ",", "self", ")", ".", "__init__", "(", "triples_factory", ",", "num_negs_per_pos", ")", "\n", "true_head_path", "=", "os", ".", "path", ".", "join", "(", "\"cached_input\"", ",", "dataset_name", ",", "\"true_heads.pt\"", ")", "\n", "true_tail_path", "=", "os", ".", "path", ".", "join", "(", "\"cached_input\"", ",", "dataset_name", ",", "\"true_tails.pt\"", ")", "\n", "true_relations_path", "=", "os", ".", "path", ".", "join", "(", "\"cached_input\"", ",", "dataset_name", ",", "\"true_relations.pt\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "true_head_path", ")", "and", "os", ".", "path", ".", "exists", "(", "true_tail_path", ")", "and", "os", ".", "path", ".", "exists", "(", "true_relations_path", ")", ":", "\n", "            ", "with", "open", "(", "true_head_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "true_head", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "true_tail_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "true_tail", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "with", "open", "(", "true_relations_path", ",", "'rb'", ")", "as", "handle", ":", "\n", "                ", "self", ".", "true_relations", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "", "else", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "\"cached_input\"", ",", "dataset_name", ")", ")", "\n", "self", ".", "true_head", ",", "self", ".", "true_tail", ",", "self", ".", "true_relations", "=", "get_true_subject_and_object_per_graph", "(", "triples_factory", ".", "mapped_triples", ")", "\n", "with", "open", "(", "true_head_path", ",", "'wb'", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "true_head", ",", "handle", ")", "\n", "", "with", "open", "(", "true_tail_path", ",", "'wb'", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "true_tail", ",", "handle", ")", "\n", "", "with", "open", "(", "true_relations_path", ",", "'wb'", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "true_relations", ",", "handle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.FilteredNegativeSampler.sample_entities": [[60, 77], ["numpy.random.choice", "numpy.in1d", "negative_sample_list.append", "numpy.concatenate"], "methods", ["None"], ["", "", "", "def", "sample_entities", "(", "self", ",", "h", ",", "r", ",", "t", ",", "corrput_head", "=", "True", ")", ":", "\n", "        ", "true_entities", "=", "self", ".", "true_head", "[", "t", "]", "[", "r", "]", "if", "corrput_head", "else", "self", ".", "true_tail", "[", "h", "]", "[", "r", "]", "\n", "negative_sample_list", "=", "[", "]", "\n", "negative_sample_size", "=", "0", "\n", "\n", "while", "negative_sample_size", "<", "self", ".", "num_negs_per_pos", ":", "\n", "            ", "negative_sample", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "num_entities", "-", "1", ",", "size", "=", "self", ".", "num_negs_per_pos", ")", "\n", "mask", "=", "np", ".", "in1d", "(", "\n", "negative_sample", ",", "\n", "true_entities", ",", "\n", "assume_unique", "=", "True", ",", "\n", "invert", "=", "True", "\n", ")", "\n", "negative_sample", "=", "negative_sample", "[", "mask", "]", "\n", "negative_sample_list", ".", "append", "(", "negative_sample", ")", "\n", "negative_sample_size", "+=", "negative_sample", ".", "size", "\n", "", "return", "np", ".", "concatenate", "(", "negative_sample_list", ")", "[", ":", "self", ".", "num_negs_per_pos", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.FilteredNegativeSampler.sample": [[78, 97], ["positive_batch.repeat().view", "range", "positive_batch.repeat().view.view", "len", "positive_batch.repeat", "h.item", "r.item", "t.item", "torch.from_numpy", "torch.from_numpy", "negative_sampler.FilteredNegativeSampler.sample_entities", "negative_sampler.FilteredNegativeSampler.sample_entities"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.FilteredNegativeSampler.sample_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.FilteredNegativeSampler.sample_entities"], ["", "def", "sample", "(", "self", ",", "positive_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "\"\"\"Generate negative samples from the positive batch.\"\"\"", "\n", "half", "=", "positive_batch", ".", "shape", "[", "0", "]", "//", "2", "\n", "negative_batch_entity", "=", "positive_batch", ".", "repeat", "(", "self", ".", "num_negs_per_pos", ",", "1", ")", ".", "view", "(", "-", "1", ",", "positive_batch", ".", "shape", "[", "0", "]", ",", "3", ")", "\n", "\n", "# Sample random entities as replacement", "\n", "for", "i", "in", "range", "(", "len", "(", "positive_batch", ")", ")", ":", "\n", "            ", "h", ",", "r", ",", "t", "=", "positive_batch", "[", "i", "]", "\n", "h", ",", "r", ",", "t", "=", "h", ".", "item", "(", ")", ",", "r", ".", "item", "(", ")", ",", "t", ".", "item", "(", ")", "\n", "\n", "if", "i", "<", "half", ":", "\n", "                ", "negative_head", "=", "torch", ".", "from_numpy", "(", "self", ".", "sample_entities", "(", "h", ",", "r", ",", "t", ",", "corrput_head", "=", "True", ")", ")", "\n", "negative_batch_entity", "[", ":", ",", "i", ",", "0", "]", "=", "negative_head", "\n", "", "else", ":", "\n", "                ", "negative_tail", "=", "torch", ".", "from_numpy", "(", "self", ".", "sample_entities", "(", "h", ",", "r", ",", "t", ",", "corrput_head", "=", "False", ")", ")", "\n", "negative_batch_entity", "[", ":", ",", "i", ",", "2", "]", "=", "negative_tail", "\n", "# pdb.set_trace()", "\n", "\n", "", "", "return", "negative_batch_entity", ".", "view", "(", "-", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.__init__": [[101, 104], ["negative_sampler.FilteredNegativeSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "triples_factory", ",", "num_negs_per_pos", "=", "None", ",", "num_negs_per_pos_rel", "=", "None", ",", "dataset_name", "=", "None", ")", ":", "\n", "        ", "super", "(", "RelationalNegativeSampler", ",", "self", ")", ".", "__init__", "(", "triples_factory", ",", "num_negs_per_pos", ",", "dataset_name", ")", "\n", "self", ".", "num_negs_per_pos_rel", "=", "num_negs_per_pos_rel", "if", "num_negs_per_pos_rel", "is", "not", "None", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.num_relations": [[105, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_relations", "(", "self", ")", "->", "int", ":", "# noqa: D401", "\n", "        ", "\"\"\"The number of entities to sample from.\"\"\"", "\n", "return", "self", ".", "triples_factory", ".", "num_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample_relations": [[110, 128], ["numpy.random.choice", "numpy.in1d", "negative_sample_list.append", "numpy.concatenate"], "methods", ["None"], ["", "def", "sample_relations", "(", "self", ",", "h", ",", "t", ")", ":", "\n", "        ", "true_relations", "=", "self", ".", "true_relations", "[", "h", "]", "[", "t", "]", "\n", "negative_sample_list", "=", "[", "]", "\n", "negative_sample_size", "=", "0", "\n", "\n", "while", "negative_sample_size", "<", "self", ".", "num_negs_per_pos_rel", ":", "\n", "            ", "negative_sample", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "num_relations", "-", "1", ",", "size", "=", "self", ".", "num_negs_per_pos_rel", ")", "\n", "mask", "=", "np", ".", "in1d", "(", "\n", "negative_sample", ",", "\n", "true_relations", ",", "\n", "assume_unique", "=", "True", ",", "\n", "invert", "=", "True", "\n", ")", "\n", "negative_sample", "=", "negative_sample", "[", "mask", "]", "\n", "negative_sample_list", ".", "append", "(", "negative_sample", ")", "\n", "negative_sample_size", "+=", "negative_sample", ".", "size", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "negative_sample_list", ")", "[", ":", "self", ".", "num_negs_per_pos_rel", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample": [[129, 141], ["negative_sampler.FilteredNegativeSampler.sample", "positive_batch.repeat().view", "range", "torch.cat", "len", "torch.from_numpy", "positive_batch.repeat", "h.item", "r.item", "t.item", "negative_sampler.RelationalNegativeSampler.sample_relations", "positive_batch.repeat().view.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample_relations"], ["", "def", "sample", "(", "self", ",", "positive_batch", ")", ":", "\n", "        ", "bsz", "=", "positive_batch", ".", "shape", "[", "0", "]", "\n", "negative_entities", "=", "super", "(", ")", ".", "sample", "(", "positive_batch", ")", "\n", "negative_relations", "=", "positive_batch", ".", "repeat", "(", "self", ".", "num_negs_per_pos_rel", ",", "1", ")", ".", "view", "(", "-", "1", ",", "bsz", ",", "3", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "positive_batch", ")", ")", ":", "\n", "            ", "h", ",", "r", ",", "t", "=", "positive_batch", "[", "i", "]", "\n", "h", ",", "r", ",", "t", "=", "h", ".", "item", "(", ")", ",", "r", ".", "item", "(", ")", ",", "t", ".", "item", "(", ")", "\n", "negative_relation", "=", "torch", ".", "from_numpy", "(", "self", ".", "sample_relations", "(", "h", ",", "t", ")", ")", "\n", "negative_relations", "[", ":", ",", "i", ",", "1", "]", "=", "negative_relation", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "negative_entities", ",", "negative_relations", ".", "view", "(", "-", "1", ",", "3", ")", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.get_true_subject_and_object_per_graph": [[10, 34], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "[].append", "[].append", "[].append", "dict", "dict", "dict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "head.item", "relation.item", "tail.item", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["def", "get_true_subject_and_object_per_graph", "(", "triples", ")", ":", "\n", "    ", "true_head", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "list", ")", ")", "\n", "true_tail", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "list", ")", ")", "\n", "true_relations", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "list", ")", ")", "\n", "for", "head", ",", "relation", ",", "tail", "in", "triples", ":", "\n", "        ", "head", ",", "relation", ",", "tail", "=", "head", ".", "item", "(", ")", ",", "relation", ".", "item", "(", ")", ",", "tail", ".", "item", "(", ")", "\n", "true_tail", "[", "head", "]", "[", "relation", "]", ".", "append", "(", "tail", ")", "\n", "true_head", "[", "tail", "]", "[", "relation", "]", ".", "append", "(", "head", ")", "\n", "true_relations", "[", "head", "]", "[", "tail", "]", ".", "append", "(", "relation", ")", "\n", "\n", "# this is correct", "\n", "", "for", "head", "in", "true_tail", ":", "\n", "        ", "for", "relation", "in", "true_tail", "[", "head", "]", ":", "\n", "            ", "true_tail", "[", "head", "]", "[", "relation", "]", "=", "np", ".", "array", "(", "true_tail", "[", "head", "]", "[", "relation", "]", ")", "\n", "\n", "", "", "for", "tail", "in", "true_head", ":", "\n", "        ", "for", "relation", "in", "true_head", "[", "tail", "]", ":", "\n", "            ", "true_head", "[", "tail", "]", "[", "relation", "]", "=", "np", ".", "array", "(", "true_head", "[", "tail", "]", "[", "relation", "]", ")", "\n", "\n", "", "", "for", "head", "in", "true_relations", ":", "\n", "        ", "for", "tail", "in", "true_relations", "[", "head", "]", ":", "\n", "            ", "true_relations", "[", "head", "]", "[", "tail", "]", "=", "np", ".", "array", "(", "true_relations", "[", "head", "]", "[", "tail", "]", ")", "\n", "\n", "", "", "return", "dict", "(", "true_head", ")", ",", "dict", "(", "true_tail", ")", ",", "dict", "(", "true_relations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.get_metric": [[39, 67], ["name.count", "ValueError", "ValueError", "name.split", "ValueError", "ValueError", "getattr", "getattr", "metric.startswith", "int", "len"], "methods", ["None"], ["def", "get_metric", "(", "self", ",", "name", ":", "str", ")", "->", "float", ":", "# noqa: D102", "\n", "        ", "dot_count", "=", "name", ".", "count", "(", "'.'", ")", "\n", "if", "0", "==", "dot_count", ":", "# assume average by default", "\n", "            ", "rank_type", ",", "metric", "=", "'avg'", ",", "name", "\n", "", "elif", "1", "==", "dot_count", ":", "\n", "            ", "rank_type", ",", "metric", "=", "name", ".", "split", "(", "'.'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Malformed metric name: {name}'", ")", "\n", "\n", "", "if", "rank_type", "not", "in", "RANK_AVERAGE", "and", "metric", "in", "{", "'adjusted_mean_rank'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid rank type for adjusted mean rank: {rank_type}. Allowed type: {RANK_AVERAGE}'", ")", "\n", "", "elif", "rank_type", "not", "in", "RANK_TYPES", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid rank type: {rank_type}. Allowed types: {RANK_TYPES}'", ")", "\n", "\n", "", "if", "metric", "in", "{", "'mean_rank'", ",", "'mean_reciprocal_rank'", "}", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "metric", ")", "[", "rank_type", "]", "\n", "", "elif", "metric", "in", "{", "'adjusted_mean_rank'", "}", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "metric", ")", "\n", "\n", "", "rank_type_hits_at_k", "=", "self", ".", "hits_at_k", "[", "rank_type", "]", "\n", "for", "prefix", "in", "(", "'hits_at_'", ",", "'hits@'", ")", ":", "\n", "            ", "if", "not", "metric", ".", "startswith", "(", "prefix", ")", ":", "\n", "                ", "continue", "\n", "", "k", "=", "metric", "[", "len", "(", "prefix", ")", ":", "]", "\n", "k", "=", "10", "if", "k", "==", "'k'", "else", "int", "(", "k", ")", "\n", "return", "rank_type_hits_at_k", "[", "k", "]", "\n", "\n", "", "raise", "ValueError", "(", "f'Invalid metric name: {name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.to_flat_dict": [[68, 76], ["relation_rank_evaluator.RelationPredictionRankBasedMetricResults.hits_at_k[].items"], "methods", ["None"], ["", "def", "to_flat_dict", "(", "self", ")", ":", "# noqa: D102", "\n", "        ", "r", "=", "{", "'avg.adjusted_mean_rank'", ":", "self", ".", "adjusted_mean_rank", "}", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "r", "[", "f'{rank_type}.mean_rank'", "]", "=", "self", ".", "mean_rank", "[", "rank_type", "]", "\n", "r", "[", "f'{rank_type}.mean_reciprocal_rank'", "]", "=", "self", ".", "mean_reciprocal_rank", "[", "rank_type", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "hits_at_k", "[", "rank_type", "]", ".", "items", "(", ")", ":", "\n", "                ", "r", "[", "f'{rank_type}.hits_at_{k}'", "]", "=", "v", "\n", "", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.to_df": [[77, 88], ["pykeen.evaluation.rank_based_evaluator.pd.DataFrame", "rows.append", "rows.append", "relation_rank_evaluator.RelationPredictionRankBasedMetricResults.hits_at_k[].items", "rows.append"], "methods", ["None"], ["", "def", "to_df", "(", "self", ")", ":", "\n", "        ", "\"\"\"Output the metrics as a pandas dataframe.\"\"\"", "\n", "rows", "=", "[", "\n", "(", "'avg'", ",", "'adjusted_mean_rank'", ",", "self", ".", "adjusted_mean_rank", ")", "\n", "]", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "rows", ".", "append", "(", "(", "rank_type", ",", "'mean_rank'", ",", "self", ".", "mean_rank", "[", "rank_type", "]", ")", ")", "\n", "rows", ".", "append", "(", "(", "rank_type", ",", "'mean_reciprocal_rank'", ",", "self", ".", "mean_reciprocal_rank", "[", "rank_type", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "hits_at_k", "[", "rank_type", "]", ".", "items", "(", ")", ":", "\n", "                ", "rows", ".", "append", "(", "(", "rank_type", ",", "f'hits_at_{k}'", ",", "v", ")", ")", "\n", "", "", "return", "pd", ".", "DataFrame", "(", "rows", ",", "columns", "=", "[", "'Type'", ",", "'Metric'", ",", "'Value'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.__init__": [[91, 105], ["pykeen.evaluation.Evaluator.__init__", "collections.defaultdict", "tuple", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "ks", "=", "None", ",", "\n", "filtered", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "filtered", "=", "filtered", ")", "\n", "self", ".", "ks", "=", "tuple", "(", "ks", ")", "if", "ks", "is", "not", "None", "else", "(", "1", ",", "3", ",", "5", ",", "10", ")", "\n", "for", "k", "in", "self", ".", "ks", ":", "\n", "            ", "if", "isinstance", "(", "k", ",", "float", ")", "and", "not", "(", "0", "<", "k", "<", "1", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'If k is a float, it should represent a relative rank, i.e. a value between 0 and 1 (excl.)'", ",", "\n", ")", "\n", "", "", "self", ".", "ranks", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "num_relations", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_tail_scores_": [[106, 114], ["None"], "methods", ["None"], ["", "def", "process_tail_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_head_scores_": [[115, 123], ["None"], "methods", ["None"], ["", "def", "process_head_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_": [[124, 132], ["pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores", "pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores.items", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks[].extend", "v.detach().cpu().tolist", "v.detach().cpu", "v.detach"], "methods", ["None"], ["", "def", "_update_ranks_", "(", "self", ",", "true_scores", ",", "all_scores", ")", ":", "\n", "        ", "batch_ranks", "=", "compute_rank_from_scores", "(", "\n", "true_score", "=", "true_scores", ",", "\n", "all_scores", "=", "all_scores", ",", "\n", ")", "\n", "self", ".", "num_relations", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "for", "k", ",", "v", "in", "batch_ranks", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "ranks", "[", "k", "]", ".", "extend", "(", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.evaluate": [[133, 171], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate"], ["", "", "def", "evaluate", "(", "\n", "self", ",", "model", ",", "mapped_triples", "=", "None", ",", "batch_size", "=", "None", ",", "slice_size", "=", "None", ",", "device", "=", "None", ",", "\n", "use_tqdm", "=", "True", ",", "tqdm_kwargs", "=", "None", ",", "restrict_entities_to", "=", "None", ",", "do_time_consuming_checks", "=", "True", ",", "\n", "additional_filter_triples", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "mapped_triples", "is", "None", ":", "\n", "            ", "mapped_triples", "=", "model", ".", "triples_factory", ".", "mapped_triples", "\n", "\n", "", "if", "batch_size", "is", "None", "and", "model", ".", "automatic_memory_optimization", ":", "\n", "            ", "batch_size", ",", "slice_size", "=", "self", ".", "batch_and_slice", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", ",", "\n", "use_tqdm", "=", "False", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n", "# The batch_size and slice_size should be accessible to outside objects for re-use, e.g. early stoppers.", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "slice_size", "=", "slice_size", "\n", "\n", "# Clear the ranks from the current evaluator", "\n", "self", ".", "finalize", "(", ")", "\n", "\n", "", "return", "evaluate", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filtered_triples", "=", "additional_filter_triples", ",", "\n", "evaluators", "=", "self", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "device", "=", "device", ",", "\n", "squeeze", "=", "True", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "tqdm_kwargs", "=", "tqdm_kwargs", ",", "\n", "restrict_relations_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks": [[173, 175], ["numpy.asarray", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks.get"], "methods", ["None"], ["", "def", "_get_ranks", "(", "self", ",", "rank_type", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "self", ".", "ranks", ".", "get", "(", "rank_type", ",", "[", "]", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.finalize": [[176, 204], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks.clear", "relation_rank_evaluator.RelationPredictionRankBasedMetricResults", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "numpy.mean", "numpy.mean", "len", "float", "len", "numpy.reciprocal", "numpy.mean", "dict", "dict", "dict", "isinstance", "numpy.mean", "numpy.mean", "int"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks"], ["", "def", "finalize", "(", "self", ")", "->", "MetricResults", ":", "\n", "        ", "mean_rank", "=", "{", "}", "\n", "mean_reciprocal_rank", "=", "{", "}", "\n", "hits_at_k", "=", "{", "}", "\n", "adjusted_mean_rank", "=", "{", "}", "\n", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "ranks", "=", "self", ".", "_get_ranks", "(", "rank_type", "=", "rank_type", ")", "\n", "if", "len", "(", "ranks", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "hits_at_k", "[", "rank_type", "]", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "ranks", "<=", "k", ")", "if", "isinstance", "(", "k", ",", "int", ")", "else", "np", ".", "mean", "(", "ranks", "<=", "int", "(", "self", ".", "num_relations", "*", "k", ")", ")", "\n", "for", "k", "in", "self", ".", "ks", "\n", "}", "\n", "mean_rank", "[", "rank_type", "]", "=", "np", ".", "mean", "(", "ranks", ")", "\n", "mean_reciprocal_rank", "[", "rank_type", "]", "=", "np", ".", "mean", "(", "np", ".", "reciprocal", "(", "ranks", ")", ")", "\n", "\n", "", "adjusted_ranks", "=", "self", ".", "_get_ranks", "(", "rank_type", "=", "RANK_AVERAGE_ADJUSTED", ")", "\n", "if", "len", "(", "adjusted_ranks", ")", ">=", "1", ":", "\n", "            ", "adjusted_mean_rank", "=", "float", "(", "np", ".", "mean", "(", "adjusted_ranks", ")", ")", "\n", "\n", "", "self", ".", "ranks", ".", "clear", "(", ")", "\n", "\n", "return", "RelationPredictionRankBasedMetricResults", "(", "\n", "mean_rank", "=", "dict", "(", "mean_rank", ")", ",", "\n", "mean_reciprocal_rank", "=", "dict", "(", "mean_reciprocal_rank", ")", ",", "\n", "hits_at_k", "=", "dict", "(", "hits_at_k", ")", ",", "\n", "adjusted_mean_rank", "=", "adjusted_mean_rank", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_": [[206, 214], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_"], ["", "def", "process_relation_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "# noqa: D102", "\n", "        ", "self", ".", "_update_ranks_", "(", "true_scores", "=", "true_scores", ",", "all_scores", "=", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor": [[216, 219], ["mapped_triples[].unique"], "function", ["None"], ["", "", "def", "get_unique_relation_ids_from_triples_tensor", "(", "mapped_triples", ":", "MappedTriples", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "\"\"\"Return the unique entity IDs used in a tensor of triples.\"\"\"", "\n", "return", "mapped_triples", "[", ":", ",", "1", "]", ".", "unique", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.evaluate": [[220, 386], ["isinstance", "pykeen.evaluation.evaluator.timeit.default_timer", "model.to.eval", "list", "list", "any", "mapped_triples.to.to", "pykeen.evaluation.evaluator.split_list_in_batches_iter", "dict", "pykeen.evaluation.evaluator.timeit.default_timer", "set", "set.difference", "model.to.to", "filter", "filter", "len", "torch.cat.to", "dict.update", "pykeen.evaluation.evaluator.optional_context_manager", "torch.no_grad", "pykeen.evaluation.evaluator.logger.debug", "pykeen.evaluation.evaluator.logger.info", "get_unique_relation_ids_from_triples_tensor().tolist", "restrict_relations_to.tolist", "len", "ValueError", "pykeen.evaluation.evaluator.logger.warning", "isinstance", "pykeen.evaluation.evaluator.tqdm", "relation_rank_evaluator._evaluate_batch", "evaluator.finalize", "len", "torch.cat", "torch.cat", "progress_bar.update", "relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.optional_context_manager", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator._evaluate_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.finalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor"], ["", "def", "evaluate", "(", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "MappedTriples", ",", "\n", "evaluators", ":", "Union", "[", "Evaluator", ",", "Collection", "[", "Evaluator", "]", "]", ",", "\n", "additional_filtered_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "only_size_probing", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "squeeze", ":", "bool", "=", "True", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "tqdm_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "restrict_relations_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "Union", "[", "MetricResults", ",", "List", "[", "MetricResults", "]", "]", ":", "\n", "    ", "\"\"\"Evaluate metrics for model on mapped triples.\n\n    The model is used to predict scores for all tails and all heads for each triple. Subsequently, each abstract\n    evaluator is applied to the scores, also receiving the batch itself (e.g. to compute entity-specific metrics).\n    Thereby, the (potentially) expensive score computation against all entities is done only once. The metric evaluators\n    are expected to maintain their own internal buffers. They are returned after running the evaluation, and should\n    offer a possibility to extract some final metrics.\n\n    :param model:\n        The model to evaluate.\n    :param mapped_triples:\n        The triples on which to evaluate.\n    :param evaluators:\n        An evaluator or a list of evaluators working on batches of triples and corresponding scores.\n    :param only_size_probing:\n        The evaluation is only performed for two batches to test the memory footprint, especially on GPUs.\n    :param batch_size: >0\n        A positive integer used as batch size. Generally chosen as large as possible. Defaults to 1 if None.\n    :param slice_size: >0\n        The divisor for the scoring function when using slicing.\n    :param device:\n        The device on which the evaluation shall be run. If None is given, use the model's device.\n    :param squeeze:\n        Return a single instance of :class:`MetricResults` if only one evaluator was given.\n    :param use_tqdm:\n        Should a progress bar be displayed?\n    :param restrict_relations_to:\n        Optionally restrict the evaluation to the given relations IDs. This may be useful if one is only interested in a\n        part of the relations, e.g. due to type constraints, but wants to train on all available data. For ranking the\n        entities, we still compute all scores for all possible replacement entities to avoid irregular access patterns\n        which might decrease performance, but the scores with afterwards be filtered to only keep those of interest.\n        If provided, we assume that the triples are already filtered, such that it only contains the entities of\n        interest.\n    :param do_time_consuming_checks:\n        Whether to perform some time consuming checks on the provided arguments. Currently, this encompasses:\n        - If restrict_entities_to is not None, check whether the triples have been filtered.\n        Disabling this option can accelerate the method.\n    \"\"\"", "\n", "if", "isinstance", "(", "evaluators", ",", "Evaluator", ")", ":", "# upgrade a single evaluator to a list", "\n", "        ", "evaluators", "=", "[", "evaluators", "]", "\n", "\n", "", "start", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "# verify that the triples have been filtered", "\n", "if", "restrict_relations_to", "is", "not", "None", "and", "do_time_consuming_checks", ":", "\n", "        ", "present_relation_ids", "=", "set", "(", "get_unique_relation_ids_from_triples_tensor", "(", "mapped_triples", "=", "mapped_triples", ")", ".", "tolist", "(", ")", ")", "\n", "unwanted", "=", "present_relation_ids", ".", "difference", "(", "restrict_relations_to", ".", "tolist", "(", ")", ")", "\n", "if", "len", "(", "unwanted", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f'mapped_triples contains IDs of entities which are not contained in restrict_relations_to:'", "\n", "f'{unwanted}. This will invalidate the evaluation results.'", ")", "\n", "\n", "# Send to device", "\n", "", "", "if", "device", "is", "not", "None", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "", "device", "=", "model", ".", "device", "\n", "\n", "# Ensure evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Split evaluators into those which need unfiltered results, and those which require filtered ones", "\n", "filtered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "unfiltered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "not", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "\n", "# Check whether we need to be prepared for filtering", "\n", "filtering_necessary", "=", "len", "(", "filtered_evaluators", ")", ">", "0", "\n", "\n", "# Check whether an evaluator needs access to the masks", "\n", "# This can only be an unfiltered evaluator.", "\n", "positive_masks_required", "=", "any", "(", "e", ".", "requires_positive_mask", "for", "e", "in", "unfiltered_evaluators", ")", "\n", "\n", "# Prepare for result filtering", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "#all_pos_triples = torch.cat([model.triples_factory.mapped_triples, mapped_triples], dim=0)", "\n", "        ", "if", "additional_filtered_triples", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"The filtered setting was enabled, but there were no `additional_filtered_triples\"", "\n", "\"given. This means you probably forgot to pass (at least) the training triples. Try:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples]\"", "\n", "\"Or if you want to use the Bordes et al. (2013) approach to filtering, do:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples,dataset.validation.mapped_triples,]\"", ")", "\n", "all_pos_triples", "=", "mapped_triples", "\n", "", "elif", "isinstance", "(", "additional_filtered_triples", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "*", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "all_pos_triples", "=", "all_pos_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "all_pos_triples", "=", "None", "\n", "\n", "# Send tensors to device", "\n", "", "mapped_triples", "=", "mapped_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "# Prepare batches", "\n", "if", "batch_size", "is", "None", ":", "\n", "        ", "batch_size", "=", "1", "\n", "", "batches", "=", "split_list_in_batches_iter", "(", "input_list", "=", "mapped_triples", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Show progressbar", "\n", "num_triples", "=", "mapped_triples", ".", "shape", "[", "0", "]", "\n", "\n", "# Flag to check when to quit the size probing", "\n", "evaluated_once", "=", "False", "\n", "\n", "# Disable gradient tracking", "\n", "_tqdm_kwargs", "=", "dict", "(", "\n", "desc", "=", "f'Evaluating on {model.device}'", ",", "\n", "total", "=", "num_triples", ",", "\n", "unit", "=", "'triple'", ",", "\n", "unit_scale", "=", "True", ",", "\n", "# Choosing no progress bar (use_tqdm=False) would still show the initial progress bar without disable=True", "\n", "disable", "=", "not", "use_tqdm", ",", "\n", ")", "\n", "if", "tqdm_kwargs", ":", "\n", "        ", "_tqdm_kwargs", ".", "update", "(", "tqdm_kwargs", ")", "\n", "", "with", "optional_context_manager", "(", "use_tqdm", ",", "tqdm", "(", "**", "_tqdm_kwargs", ")", ")", "as", "progress_bar", ",", "torch", ".", "no_grad", "(", ")", ":", "\n", "# batch-wise processing", "\n", "        ", "for", "batch", "in", "batches", ":", "\n", "            ", "batch_size", "=", "batch", ".", "shape", "[", "0", "]", "\n", "_evaluate_batch", "(", "\n", "batch", "=", "batch", ",", "\n", "model", "=", "model", ",", "\n", "filtered_evaluators", "=", "filtered_evaluators", ",", "\n", "unfiltered_evaluators", "=", "unfiltered_evaluators", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", "restrict_relations_to", "=", "restrict_relations_to", ",", "\n", "positive_masks_required", "=", "positive_masks_required", ",", "\n", "filtering_necessary", "=", "filtering_necessary", ",", "\n", ")", "\n", "\n", "# If we only probe sizes we do not need more than one batch", "\n", "if", "only_size_probing", "and", "evaluated_once", ":", "\n", "                ", "break", "\n", "\n", "", "evaluated_once", "=", "True", "\n", "\n", "if", "use_tqdm", ":", "\n", "                ", "progress_bar", ".", "update", "(", "batch_size", ")", "\n", "\n", "# Finalize", "\n", "", "", "results", "=", "[", "evaluator", ".", "finalize", "(", ")", "for", "evaluator", "in", "evaluators", "]", "\n", "\n", "", "stop", "=", "timeit", ".", "default_timer", "(", ")", "\n", "if", "only_size_probing", ":", "\n", "        ", "logger", ".", "debug", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "\n", "", "if", "squeeze", "and", "len", "(", "results", ")", "==", "1", ":", "\n", "        ", "return", "results", "[", "0", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator._evaluate_batch": [[389, 498], ["model.predict_scores_all_relations", "relation_rank_evaluator.create_sparse_positive_filter_", "pykeen.evaluation.evaluator.create_dense_positive_mask_", "unfiltered_evaluator.process_relation_scores_", "pykeen.evaluation.evaluator.filter_scores_", "ValueError", "filtered_evaluator.process_relation_scores_", "torch.arange", "torch.zeros_like", "torch.arange"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_sparse_positive_filter_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_dense_positive_mask_", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.filter_scores_", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_"], ["", "def", "_evaluate_batch", "(", "\n", "batch", ",", "\n", "model", ",", "\n", "filtered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "unfiltered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", ",", "\n", "all_pos_triples", ":", "Optional", "[", "MappedTriples", "]", ",", "\n", "restrict_relations_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", ",", "\n", "positive_masks_required", ":", "bool", ",", "\n", "filtering_necessary", ":", "bool", ",", "\n", ")", "->", "torch", ".", "BoolTensor", ":", "\n", "    ", "\"\"\"\n    Evaluate batch for all head predictions(column=0), or all tail predictions (column=2).\n\n    :param batch: shape: (batch_size, 3)\n        The batch of currently evaluated triples.\n    :param model:\n        The model to evaluate.\n    :param column:\n        The column which to evaluate. Either 0 for head prediction, or 2 for tail prediction.\n    :param filtered_evaluators:\n        The evaluators which work on filtered scores.\n    :param unfiltered_evaluators:\n        The evaluators which work on unfiltered scores.\n    :param slice_size:\n        An optional slice size for computing the scores.\n    :param all_pos_triples:\n        All positive triples (required if filtering is necessary).\n    :param restrict_relations_to:\n        Restriction to evaluate only for these relations.\n    :param positive_masks_required:\n        Whether dense positive masks are required (by any unfiltered evaluator).\n    :param filtering_necessary:\n        Whether filtering is necessary.\n\n    :return:\n        The relation filter, which can be re-used for the same batch.\n    \"\"\"", "\n", "\n", "# Predict scores once", "\n", "batch_scores_of_corrupted", "=", "model", ".", "predict_scores_all_relations", "(", "batch", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "slice_size", "=", "slice_size", ")", "\n", "\n", "# Select scores of true", "\n", "batch_scores_of_true", "=", "batch_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "1", "]", ",", "\n", "]", "\n", "\n", "# Create positive filter for all corrupted", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "# Needs all positive triples", "\n", "        ", "if", "all_pos_triples", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'If filtering_necessary of positive_masks_required is True, all_pos_triples has to be '", "\n", "'provided, but is None.'", ")", "\n", "\n", "# Create filter", "\n", "", "positive_filter", "=", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", ")", "\n", "\n", "# Create a positive mask with the size of the scores from the positive filter", "\n", "", "if", "positive_masks_required", ":", "\n", "        ", "positive_mask", "=", "create_dense_positive_mask_", "(", "\n", "zero_tensor", "=", "torch", ".", "zeros_like", "(", "batch_scores_of_corrupted", ")", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "positive_mask", "=", "None", "\n", "\n", "# Restrict to entities of interest", "\n", "", "if", "restrict_relations_to", "is", "not", "None", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "[", ":", ",", "restrict_relations_to", "]", "\n", "positive_mask", "=", "positive_mask", "[", ":", ",", "restrict_relations_to", "]", "\n", "", "else", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "\n", "\n", "# Evaluate metrics on these *unfiltered* scores", "\n", "", "for", "unfiltered_evaluator", "in", "unfiltered_evaluators", ":", "\n", "        ", "unfiltered_evaluator", ".", "process_relation_scores_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_scores_of_corrupted_", ",", "\n", "dense_positive_mask", "=", "positive_mask", ",", "\n", ")", "\n", "\n", "# Filter", "\n", "", "if", "filtering_necessary", ":", "\n", "        ", "batch_filtered_scores_of_corrupted", "=", "filter_scores_", "(", "\n", "scores", "=", "batch_scores_of_corrupted", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "\n", "# The scores for the true triples have to be rewritten to the scores tensor", "\n", "batch_filtered_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "1", "]", ",", "\n", "]", "=", "batch_scores_of_true", "\n", "\n", "# Restrict to entities of interest", "\n", "if", "restrict_relations_to", "is", "not", "None", ":", "\n", "            ", "batch_filtered_scores_of_corrupted", "=", "batch_filtered_scores_of_corrupted", "[", ":", ",", "restrict_relations_to", "]", "\n", "\n", "# Evaluate metrics on these *filtered* scores", "\n", "", "for", "filtered_evaluator", "in", "filtered_evaluators", ":", "\n", "            ", "filtered_evaluator", ".", "process_relation_scores_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_filtered_scores_of_corrupted", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.relation_rank_evaluator.create_sparse_positive_filter_": [[500, 512], ["all_pos_triples[].view", "all_pos_triples[].view", "all_pos_triples[].view"], "function", ["None"], ["", "", "", "def", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "all_pos_triples", ":", "torch", ".", "LongTensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "torch", ".", "BoolTensor", "]", ":", "\n", "# Split batch", "\n", "    ", "batch_heads", ",", "batch_tails", "=", "hrt_batch", "[", ":", ",", "0", ":", "1", "]", ",", "hrt_batch", "[", ":", ",", "2", ":", "3", "]", "\n", "head_filter", "=", "(", "all_pos_triples", "[", ":", ",", "0", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "batch_heads", "\n", "tail_filter", "=", "(", "all_pos_triples", "[", ":", ",", "2", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "batch_tails", "\n", "filter_batch", "=", "(", "head_filter", "&", "tail_filter", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "filter_batch", "[", ":", ",", "1", "]", "=", "all_pos_triples", "[", ":", ",", "1", "]", ".", "view", "(", "1", ",", "-", "1", ")", "[", ":", ",", "filter_batch", "[", ":", ",", "1", "]", "]", "\n", "\n", "return", "filter_batch", "\n", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.UnpackedRemoteDataset.__init__": [[73, 124], ["codex.UnpackedRemoteDataset._help_cache", "os.path.join", "os.path.join", "os.path.join", "pykeen.datasets.base.PathDataSet.__init__", "pystow.utils.name_from_url", "pystow.utils.name_from_url", "pystow.utils.name_from_url", "codex._urlretrieve", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.UnpackedRemoteDataset._help_cache", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex._urlretrieve"], ["def", "__init__", "(", "\n", "self", ",", "\n", "training_url", ":", "str", ",", "\n", "testing_url", ":", "str", ",", "\n", "validation_url", ":", "str", ",", "\n", "cache_root", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "stream", ":", "bool", "=", "True", ",", "\n", "force", ":", "bool", "=", "False", ",", "\n", "eager", ":", "bool", "=", "False", ",", "\n", "create_inverse_triples", ":", "bool", "=", "False", ",", "\n", "load_triples_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize dataset.\n        :param training_url: The URL of the training file\n        :param testing_url: The URL of the testing file\n        :param validation_url: The URL of the validation file\n        :param cache_root:\n            An optional directory to store the extracted files. Is none is given, the default PyKEEN directory is used.\n            This is defined either by the environment variable ``PYKEEN_HOME`` or defaults to ``~/.pykeen``.\n        :param stream: Use :mod:`requests` be used for download if true otherwise use :mod:`urllib`\n        :param force: If true, redownload any cached files\n        :param eager: Should the data be loaded eagerly? Defaults to false.\n        :param create_inverse_triples: Should inverse triples be created? Defaults to false.\n        :param load_triples_kwargs: Arguments to pass through to :func:`TriplesFactory.from_path`\n            and ultimately through to :func:`pykeen.triples.utils.load_triples`.\n        \"\"\"", "\n", "self", ".", "cache_root", "=", "self", ".", "_help_cache", "(", "cache_root", ")", "\n", "\n", "self", ".", "training_url", "=", "training_url", "\n", "self", ".", "testing_url", "=", "testing_url", "\n", "self", ".", "validation_url", "=", "validation_url", "\n", "\n", "training_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_root", ",", "name_from_url", "(", "self", ".", "training_url", ")", ")", "\n", "testing_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_root", ",", "name_from_url", "(", "self", ".", "testing_url", ")", ")", "\n", "validation_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_root", ",", "name_from_url", "(", "self", ".", "validation_url", ")", ")", "\n", "\n", "for", "url", ",", "path", "in", "[", "\n", "(", "self", ".", "training_url", ",", "training_path", ")", ",", "\n", "(", "self", ".", "testing_url", ",", "testing_path", ")", ",", "\n", "(", "self", ".", "validation_url", ",", "validation_path", ")", ",", "\n", "]", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "not", "force", ":", "\n", "                ", "continue", "\n", "", "_urlretrieve", "(", "url", ",", "path", ",", "stream", "=", "stream", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "training_path", "=", "training_path", ",", "\n", "testing_path", "=", "testing_path", ",", "\n", "validation_path", "=", "validation_path", ",", "\n", "eager", "=", "eager", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ",", "\n", "#load_triples_kwargs=load_triples_kwargs,", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.UnpackedRemoteDataset._help_cache": [[127, 141], ["cache_root.mkdir", "logger.debug", "pathlib.Path", "codex.UnpackedRemoteDataset.__class__.__name__.lower"], "methods", ["None"], ["", "def", "_help_cache", "(", "self", ",", "cache_root", ":", "Union", "[", "None", ",", "str", ",", "pathlib", ".", "Path", "]", ")", "->", "pathlib", ".", "Path", ":", "\n", "        ", "\"\"\"Get the appropriate cache root directory.\n        :param cache_root: If none is passed, defaults to a subfolder of the\n            PyKEEN home directory defined in :data:`pykeen.constants.PYKEEN_HOME`.\n            The subfolder is named based on the class inheriting from\n            :class:`pykeen.datasets.base.Dataset`.\n        :returns: A path object for the calculated cache root directory\n        \"\"\"", "\n", "if", "cache_root", "is", "None", ":", "\n", "            ", "cache_root", "=", "PYKEEN_DATASETS", "\n", "", "cache_root", "=", "pathlib", ".", "Path", "(", "cache_root", ")", "/", "self", ".", "__class__", ".", "__name__", ".", "lower", "(", ")", "\n", "cache_root", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "debug", "(", "'using cache root at %s'", ",", "cache_root", ")", "\n", "return", "cache_root", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.CoDExSmall.__init__": [[163, 178], ["kwargs.setdefault", "codex.UnpackedRemoteDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "create_inverse_triples", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize the `CoDEx <https://github.com/tsafavi/codex>`_ small dataset from [safavi2020]_.\n\n        :param create_inverse_triples: Should inverse triples be created? Defaults to false.\n        :param kwargs: keyword arguments passed to :class:`pykeen.datasets.base.UnpackedRemoteDataset`.\n        \"\"\"", "\n", "# GitHub's raw.githubusercontent.com service rejects requests that are streamable. This is", "\n", "# normally the default for all of PyKEEN's remote datasets, so just switch the default here.", "\n", "kwargs", ".", "setdefault", "(", "'stream'", ",", "False", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "training_url", "=", "SMALL_TRAIN_URL", ",", "\n", "testing_url", "=", "SMALL_TEST_URL", ",", "\n", "validation_url", "=", "SMALL_VALID_URL", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.CoDExMedium.__init__": [[202, 215], ["kwargs.setdefault", "codex.UnpackedRemoteDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "create_inverse_triples", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize the `CoDEx <https://github.com/tsafavi/codex>`_ medium dataset from [safavi2020]_.\n\n        :param create_inverse_triples: Should inverse triples be created? Defaults to false.\n        :param kwargs: keyword arguments passed to :class:`pykeen.datasets.base.UnpackedRemoteDataset`.\n        \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'stream'", ",", "False", ")", "# See comment in CoDExSmall", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "training_url", "=", "MEDIUM_TRAIN_URL", ",", "\n", "testing_url", "=", "MEDIUM_TEST_URL", ",", "\n", "validation_url", "=", "MEDIUM_VALID_URL", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex.CoDExLarge.__init__": [[239, 252], ["kwargs.setdefault", "codex.UnpackedRemoteDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "create_inverse_triples", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize the `CoDEx <https://github.com/tsafavi/codex>`_ large dataset from [safavi2020]_.\n\n        :param create_inverse_triples: Should inverse triples be created? Defaults to false.\n        :param kwargs: keyword arguments passed to :class:`pykeen.datasets.base.UnpackedRemoteDataset`.\n        \"\"\"", "\n", "kwargs", ".", "setdefault", "(", "'stream'", ",", "False", ")", "# See comment in CoDExSmall", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "training_url", "=", "LARGE_TRAIN_URL", ",", "\n", "testing_url", "=", "LARGE_TEST_URL", ",", "\n", "validation_url", "=", "LARGE_VALID_URL", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex._urlretrieve": [[45, 69], ["logger.info", "urllib.request.urlretrieve", "requests.get", "open", "logger.info", "shutil.copyfileobj", "os.remove"], "function", ["None"], ["def", "_urlretrieve", "(", "url", ":", "str", ",", "path", ":", "str", ",", "clean_on_failure", ":", "bool", "=", "True", ",", "stream", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "    ", "\"\"\"Download a file from a given URL.\n    :param url: URL to download\n    :param path: Path to download the file to\n    :param clean_on_failure: If true, will delete the file on any exception raised during download\n    :param stream: If true, use :func:`requests.get`. By default, use ``urlretrieve``.\n    :raises Exception: If there's a problem wih downloading via :func:`requests.get` or copying\n        the data with :func:`shutil.copyfileobj`\n    :raises KeyboardInterrupt: If the user quits during download\n    \"\"\"", "\n", "if", "not", "stream", ":", "\n", "        ", "logger", ".", "info", "(", "'downloading from %s to %s'", ",", "url", ",", "path", ")", "\n", "urlretrieve", "(", "url", ",", "path", ")", "# noqa:S310", "\n", "", "else", ":", "\n", "# see https://requests.readthedocs.io/en/master/user/quickstart/#raw-response-content", "\n", "# pattern from https://stackoverflow.com/a/39217788/5775947", "\n", "        ", "try", ":", "\n", "            ", "with", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "as", "response", ",", "open", "(", "path", ",", "'wb'", ")", "as", "file", ":", "\n", "                ", "logger", ".", "info", "(", "'downloading (streaming) from %s to %s'", ",", "url", ",", "path", ")", "\n", "shutil", ".", "copyfileobj", "(", "response", ".", "raw", ",", "file", ")", "\n", "", "", "except", "(", "Exception", ",", "KeyboardInterrupt", ")", ":", "\n", "            ", "if", "clean_on_failure", ":", "\n", "                ", "os", ".", "remove", "(", "path", ")", "\n", "", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.codex._main": [[256, 260], ["cls", "cls.summarize"], "function", ["None"], ["", "", "def", "_main", "(", ")", ":", "\n", "    ", "for", "cls", "in", "[", "CoDExSmall", ",", "CoDExMedium", ",", "CoDExLarge", "]", ":", "\n", "        ", "d", "=", "cls", "(", ")", "\n", "d", ".", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.ind_dataset.InductiveDataset.__init__": [[5, 34], ["pykeen.datasets.TriplesFactory", "pykeen.datasets.TriplesFactory", "pykeen.datasets.TriplesFactory", "pykeen.datasets.TriplesFactory"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "transductive", ":", "str", ",", "\n", "inductive", ":", "str", ",", "\n", "create_inverse_triples", ":", "bool", "=", "True", ",", ")", ":", "\n", "\n", "        ", "self", ".", "cache_root", "=", "\"./data/\"", "\n", "\n", "self", ".", "transductive_part", "=", "TriplesFactory", "(", "\n", "path", "=", "self", ".", "cache_root", "+", "transductive", "+", "\"/train.txt\"", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", "\n", ")", "\n", "self", ".", "inductive_part", "=", "inductive", "\n", "\n", "self", ".", "inductive_inference", "=", "TriplesFactory", "(", "\n", "path", "=", "self", ".", "cache_root", "+", "inductive", "+", "\"/train.txt\"", ",", "\n", "relation_to_id", "=", "self", ".", "transductive_part", ".", "relation_to_id", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", "\n", ")", "\n", "\n", "self", ".", "inductive_val", "=", "TriplesFactory", "(", "\n", "path", "=", "self", ".", "cache_root", "+", "inductive", "+", "\"/valid.txt\"", ",", "\n", "entity_to_id", "=", "self", ".", "inductive_inference", ".", "entity_to_id", ",", "\n", "relation_to_id", "=", "self", ".", "transductive_part", ".", "relation_to_id", "\n", ")", "\n", "\n", "self", ".", "inductive_test", "=", "TriplesFactory", "(", "\n", "path", "=", "self", ".", "cache_root", "+", "inductive", "+", "\"/test.txt\"", ",", "\n", "entity_to_id", "=", "self", ".", "inductive_inference", ".", "entity_to_id", ",", "\n", "relation_to_id", "=", "self", ".", "transductive_part", ".", "relation_to_id", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.ind_dataset.Ind_FB15k237.__init__": [[39, 46], ["ind_dataset.InductiveDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "version", ":", "int", "=", "1", ",", "\n", "create_inverse_triples", ":", "bool", "=", "True", ",", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "transductive", "=", "f\"fb237_v{version}\"", ",", "\n", "inductive", "=", "f\"fb237_v{version}_ind\"", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.ind_dataset.Ind_WN18RR.__init__": [[50, 56], ["ind_dataset.InductiveDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "version", ":", "int", "=", "1", ",", "\n", "create_inverse_triples", ":", "bool", "=", "True", ",", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "transductive", "=", "f\"WN18RR_v{version}\"", ",", "\n", "inductive", "=", "f\"WN18RR_v{version}_ind\"", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.datasets.ind_dataset.Ind_NELL.__init__": [[60, 66], ["ind_dataset.InductiveDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "version", ":", "int", "=", "1", ",", "\n", "create_inverse_triples", ":", "bool", "=", "True", ",", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "transductive", "=", "f\"nell_v{version}\"", ",", "\n", "inductive", "=", "f\"nell_v{version}_ind\"", ",", "\n", "create_inverse_triples", "=", "create_inverse_triples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.filtered_sampling_loop.FilteredSLCWATrainingLoop.num_negs_per_pos_rel": [[6, 13], ["None"], "methods", ["None"], ["    ", "@", "property", "\n", "def", "num_negs_per_pos_rel", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Return number of negatives per positive from the sampler.\n\n        Property for API compatibility\n        \"\"\"", "\n", "return", "self", ".", "negative_sampler", ".", "num_negs_per_pos_rel", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.filtered_sampling_loop.FilteredSLCWATrainingLoop._mr_loss_helper": [[14, 21], ["filtered_sampling_loop.FilteredSLCWATrainingLoop.model.compute_mr_loss", "positive_scores.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "_mr_loss_helper", "(", "self", ",", "positive_scores", ",", "negative_scores", ",", "_label_smoothing", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "num_negs_per_pos", "+", "self", ".", "num_negs_per_pos_rel", ">", "1", ":", "\n", "            ", "positive_scores", "=", "positive_scores", ".", "repeat", "(", "self", ".", "num_negs_per_pos", "+", "self", ".", "num_negs_per_pos_rel", ",", "1", ")", "\n", "\n", "", "return", "self", ".", "model", ".", "compute_mr_loss", "(", "\n", "positive_scores", "=", "positive_scores", ",", "\n", "negative_scores", "=", "negative_scores", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.loops.training_loop_pyg_nc": [[12, 185], ["torch.device", "tqdm.autonotebook.tqdm", "range", "print", "train_loss.append", "Timer", "data_fn", "model.train", "opt.zero_grad", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model", "criterion", "criterion.item", "criterion.backward", "opt.step", "hasattr", "print", "scheduler.step", "train_graph.to", "torch.nn.utils.clip_grad_norm_", "model.post_parameter_update", "torch.no_grad", "model.eval", "torch.sigmoid", "eval_fn", "valid_rocauc.append", "valid_prcauc.append", "valid_ap.append", "valid_hard_acc.append", "wandb.log", "model.parameters", "model", "torch.sigmoid", "eval_fn", "train_rocauc.append", "train_prcauc.append", "train_ap.append", "train_hard_acc.append", "print", "print", "mt_save", "val_graph.to", "model", "wandb.log", "wandb.log", "float", "float", "train_graph.to", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "tosave", "tosave", "tosave", "numpy.mean", "save_content[].state_dict"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.post_parameter_update", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.mt_save"], ["def", "training_loop_pyg_nc", "(", "epochs", ":", "int", ",", "\n", "opt", ":", "torch", ".", "optim", ",", "\n", "model", ":", "Callable", ",", "\n", "train_graph", ":", "Data", ",", "\n", "val_graph", ":", "Data", ",", "\n", "device", ":", "torch", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ",", "\n", "data_fn", ":", "Callable", "=", "NodeClSampler", ",", "\n", "eval_fn", ":", "Callable", "=", "None", ",", "\n", "eval_every", ":", "int", "=", "1", ",", "\n", "log_wandb", ":", "bool", "=", "True", ",", "\n", "run_trn_testbench", ":", "bool", "=", "True", ",", "\n", "savedir", ":", "str", "=", "None", ",", "\n", "save_content", ":", "Dict", "[", "str", ",", "list", "]", "=", "None", ",", "\n", "grad_clipping", ":", "bool", "=", "True", ",", "\n", "scheduler", ":", "Callable", "=", "None", ",", "\n", "criterion", ":", "Callable", "=", "None", ",", "\n", "**", "kwargs", ")", "->", "(", "list", ",", "list", ",", "list", ")", ":", "\n", "    ", "train_loss", "=", "[", "]", "\n", "train_rocauc", ",", "train_prcauc", ",", "train_ap", ",", "train_hard_acc", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "valid_rocauc", ",", "valid_prcauc", ",", "valid_ap", ",", "valid_hard_acc", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "\n", "# Epoch level", "\n", "for", "e", "in", "tqdm", "(", "range", "(", "epochs", ")", ")", ":", "\n", "\n", "# Train", "\n", "        ", "with", "Timer", "(", ")", "as", "timer", ":", "\n", "\n", "# Get masks and labels", "\n", "            ", "train_mask", ",", "train_y", ",", "val_mask", ",", "val_y", "=", "data_fn", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "train_mask_", "=", "torch", ".", "tensor", "(", "train_mask", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "train_y_", "=", "torch", ".", "tensor", "(", "train_y", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "val_mask_", "=", "torch", ".", "tensor", "(", "val_mask", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "val_y_", "=", "torch", ".", "tensor", "(", "val_y", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "pred", "=", "model", "(", "train_graph", ".", "to", "(", "device", "=", "device", ")", ",", "train_mask_", ")", "\n", "\n", "loss", "=", "criterion", "(", "pred", ",", "train_y_", ")", "\n", "\n", "per_epoch_loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "grad_clipping", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "", "opt", ".", "step", "(", ")", "\n", "\n", "if", "hasattr", "(", "model", ",", "\"post_parameter_update\"", ")", ":", "\n", "                ", "model", ".", "post_parameter_update", "(", ")", "\n", "\n", "# Log this stuff", "\n", "", "", "print", "(", "f\"[Epoch: {e} ] Loss: {per_epoch_loss}\"", ")", "\n", "train_loss", ".", "append", "(", "per_epoch_loss", ")", "\n", "\n", "if", "e", "%", "eval_every", "==", "0", "and", "e", ">=", "1", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "val_preds", "=", "torch", ".", "sigmoid", "(", "model", "(", "val_graph", ".", "to", "(", "device", "=", "device", ")", ",", "val_mask_", ")", ")", "\n", "val_res", "=", "eval_fn", "(", "val_y_", ",", "val_preds", ")", "\n", "valid_rocauc", ".", "append", "(", "val_res", "[", "\"rocauc\"", "]", ")", "\n", "valid_prcauc", ".", "append", "(", "val_res", "[", "\"prcauc\"", "]", ")", "\n", "valid_ap", ".", "append", "(", "val_res", "[", "\"ap\"", "]", ")", "\n", "valid_hard_acc", ".", "append", "(", "val_res", "[", "\"hard_acc\"", "]", ")", "\n", "\n", "if", "run_trn_testbench", ":", "\n", "# Also run train testbench", "\n", "                    ", "train_preds", "=", "torch", ".", "sigmoid", "(", "model", "(", "train_graph", ".", "to", "(", "device", "=", "device", ")", ",", "train_mask_", ")", ")", "\n", "unsmoothed_labels", "=", "(", "train_y_", ">", "0.5", ")", ".", "float", "(", ")", "\n", "tr_res", "=", "eval_fn", "(", "unsmoothed_labels", ",", "train_preds", ")", "\n", "train_rocauc", ".", "append", "(", "tr_res", "[", "\"rocauc\"", "]", ")", "\n", "train_prcauc", ".", "append", "(", "tr_res", "[", "\"prcauc\"", "]", ")", "\n", "train_ap", ".", "append", "(", "tr_res", "[", "\"ap\"", "]", ")", "\n", "train_hard_acc", ".", "append", "(", "tr_res", "[", "\"hard_acc\"", "]", ")", "\n", "\n", "# Print statement here", "\n", "print", "(", "\"Epoch: %(epo)03d | Loss: %(loss).5f | Tr_rocauc: %(tr_rocauc)0.5f | \"", "\n", "\"Tr_prcauc: %(tr_prcauc)0.5f | Tr_AP: %(tr_ap)0.5f | Tr_hard_acc: %(tr_hard_acc)0.5f |\"", "\n", "\"Vl_rocauc: %(val_rocauc)0.5f | Vl_prcauc: %(val_prcauc)0.5f | Vl_AP: %(val_ap)0.5f | \"", "\n", "\"Vl_hard_acc: %(val_hard_acc)0.5f | Time_trn: %(time).3f min\"", "\n", "%", "{", "'epo'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "per_epoch_loss", ")", ",", "\n", "'tr_rocauc'", ":", "float", "(", "tr_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'tr_prcauc'", ":", "float", "(", "tr_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'tr_ap'", ":", "float", "(", "tr_res", "[", "\"ap\"", "]", ")", ",", "\n", "'tr_hard_acc'", ":", "float", "(", "tr_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "'val_rocauc'", ":", "float", "(", "val_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'val_prcauc'", ":", "float", "(", "val_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'val_ap'", ":", "float", "(", "val_res", "[", "\"ap\"", "]", ")", ",", "\n", "'val_hard_acc'", ":", "float", "(", "val_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "'time'", ":", "timer", ".", "interval", "/", "60.0", "}", ")", "\n", "\n", "if", "log_wandb", ":", "\n", "# Wandb stuff", "\n", "                        ", "wandb", ".", "log", "(", "{", "\n", "'epoch'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "np", ".", "mean", "(", "per_epoch_loss", ")", ")", ",", "\n", "'tr_rocauc'", ":", "float", "(", "tr_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'tr_prcauc'", ":", "float", "(", "tr_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'tr_ap'", ":", "float", "(", "tr_res", "[", "\"ap\"", "]", ")", ",", "\n", "'tr_hard_acc'", ":", "float", "(", "tr_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "'val_rocauc'", ":", "float", "(", "val_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'val_prcauc'", ":", "float", "(", "val_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'val_ap'", ":", "float", "(", "val_res", "[", "\"ap\"", "]", ")", ",", "\n", "'val_hard_acc'", ":", "float", "(", "val_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "}", ")", "\n", "\n", "", "", "else", ":", "\n", "# Don't benchmark over train", "\n", "# Print Statement here", "\n", "                    ", "print", "(", "\"Epoch: %(epo)03d | Loss: %(loss).5f | \"", "\n", "\"Vl_rocauc: %(val_rocauc)0.5f | Vl_prcauc: %(val_prcauc)0.5f | Vl_AP: %(val_ap)0.5f | \"", "\n", "\"Vl_hard_acc: %(val_hard_acc)0.5f | time_trn: %(time).3f min\"", "\n", "%", "{", "'epo'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "per_epoch_loss", ")", ",", "\n", "'val_rocauc'", ":", "float", "(", "val_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'val_prcauc'", ":", "float", "(", "val_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'val_ap'", ":", "float", "(", "val_res", "[", "\"ap\"", "]", ")", ",", "\n", "'val_hard_acc'", ":", "float", "(", "val_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "'time'", ":", "timer", ".", "interval", "/", "60.0", "}", ")", "\n", "\n", "if", "log_wandb", ":", "\n", "# Wandb stuff", "\n", "                        ", "wandb", ".", "log", "(", "{", "\n", "'epoch'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "per_epoch_loss", ")", ",", "\n", "'val_rocauc'", ":", "float", "(", "val_res", "[", "\"rocauc\"", "]", ")", ",", "\n", "'val_prcauc'", ":", "float", "(", "val_res", "[", "\"prcauc\"", "]", ")", ",", "\n", "'val_ap'", ":", "float", "(", "val_res", "[", "\"ap\"", "]", ")", ",", "\n", "'val_hard_acc'", ":", "float", "(", "val_res", "[", "\"hard_acc\"", "]", ")", ",", "\n", "}", ")", "\n", "\n", "# We might wanna save the model, too", "\n", "", "", "if", "savedir", "is", "not", "None", ":", "\n", "                    ", "mt_save", "(", "\n", "savedir", ",", "\n", "torch_stuff", "=", "[", "tosave", "(", "obj", "=", "save_content", "[", "'model'", "]", ".", "state_dict", "(", ")", ",", "fname", "=", "'model.torch'", ")", "]", ",", "\n", "pickle_stuff", "=", "[", "tosave", "(", "fname", "=", "'traces.pkl'", ",", "\n", "obj", "=", "[", "train_loss", ",", "valid_rocauc", "]", ")", "]", ",", "\n", "json_stuff", "=", "[", "tosave", "(", "obj", "=", "save_content", "[", "'config'", "]", ",", "fname", "=", "'config.json'", ")", "]", ")", "\n", "", "", "", "else", ":", "\n", "# No test benches this time around", "\n", "            ", "print", "(", "\"Epoch: %(epo)03d | Loss: %(loss).5f |  \"", "\n", "\"Time_Train: %(time).3f min\"", "\n", "%", "{", "'epo'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "per_epoch_loss", ")", ",", "\n", "# 'tracc': float(np.mean(per_epoch_tr_acc)),", "\n", "'time'", ":", "timer", ".", "interval", "/", "60.0", "}", ")", "\n", "\n", "if", "log_wandb", ":", "\n", "# Wandb stuff", "\n", "                ", "wandb", ".", "log", "(", "{", "\n", "'epoch'", ":", "e", ",", "\n", "'loss'", ":", "float", "(", "per_epoch_loss", ")", ",", "\n", "# 'trn_acc': float(np.mean(per_epoch_tr_acc))", "\n", "}", ")", "\n", "\n", "", "", "if", "scheduler", "is", "not", "None", ":", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "return", "{", "\n", "\"loss\"", ":", "train_loss", ",", "\n", "\"train_rocauc\"", ":", "train_rocauc", ",", "\n", "\"train_prcauc\"", ":", "train_prcauc", ",", "\n", "\"train_ap\"", ":", "train_ap", ",", "\n", "\"train_hard_acc\"", ":", "train_hard_acc", ",", "\n", "\"valid_rocauc\"", ":", "valid_rocauc", ",", "\n", "\"valid_prcauc\"", ":", "valid_prcauc", ",", "\n", "\"valid_ap\"", ":", "valid_ap", ",", "\n", "\"valid_hard_acc\"", ":", "valid_hard_acc", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.__init__": [[12, 29], ["sampler.NodeClSampler.generate_labels"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.generate_labels"], ["def", "__init__", "(", "self", ",", "data", ":", "Union", "[", "np", ".", "array", ",", "dict", "]", ",", "num_labels", ":", "int", ",", "\n", "label2id", ":", "dict", ",", "lbl_smooth", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n\n        :param data: data as an array of statements of STATEMENT_LEN, e.g., [0,0,0] or [0,1,0,2,4]\n        :param n_entities: total number of entities\n        :param lbl_smooth: whether to apply label smoothing used later in the BCE loss\n        :param bs: batch size\n        :param with_q: whether indexing will consider qualifiers or not, default: FALSE\n        \"\"\"", "\n", "\n", "self", ".", "data", "=", "data", "\n", "self", ".", "lbl_smooth", "=", "lbl_smooth", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "label2id", "=", "label2id", "\n", "\n", "self", ".", "train_mask", ",", "self", ".", "train_y", ",", "self", ".", "eval_mask", ",", "self", ".", "eval_y", "=", "self", ".", "generate_labels", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.generate_labels": [[30, 59], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "sampler.NodeClSampler.compute_weights", "enumerate", "len", "len", "train.items", "numpy.zeros", "eval.items", "numpy.zeros", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.compute_weights"], ["", "def", "generate_labels", "(", "self", ")", ":", "\n", "        ", "train", "=", "self", ".", "data", "[", "\"train\"", "]", "# node_id: [lab1, lab2, lab3]", "\n", "eval", "=", "self", ".", "data", "[", "\"eval\"", "]", "\n", "\n", "train_y", "=", "np", ".", "zeros", "(", "(", "len", "(", "train", ")", ",", "self", ".", "num_labels", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "eval_y", "=", "np", ".", "zeros", "(", "(", "len", "(", "eval", ")", ",", "self", ".", "num_labels", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "train_mask", "=", "np", ".", "zeros", "(", "len", "(", "train", ")", ",", "dtype", "=", "np", ".", "long", ")", "\n", "eval_mask", "=", "np", ".", "zeros", "(", "len", "(", "eval", ")", ",", "dtype", "=", "np", ".", "long", ")", "\n", "\n", "for", "i", ",", "(", "node", ",", "labels", ")", "in", "enumerate", "(", "train", ".", "items", "(", ")", ")", ":", "\n", "            ", "lbls", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "num_labels", ")", ")", "\n", "for", "l", "in", "labels", ":", "\n", "                ", "lbls", "[", "0", ",", "l", "]", "=", "1.0", "\n", "", "train_y", "[", "i", "]", "=", "lbls", "\n", "train_mask", "[", "i", "]", "=", "node", "\n", "\n", "", "self", ".", "pos_weights", "=", "self", ".", "compute_weights", "(", "train_y", ")", "\n", "\n", "if", "self", ".", "lbl_smooth", "!=", "0.0", ":", "\n", "            ", "train_y", "=", "(", "1.0", "-", "self", ".", "lbl_smooth", ")", "*", "train_y", "+", "(", "1.0", "/", "len", "(", "train", ")", ")", "\n", "\n", "", "for", "i", ",", "(", "node", ",", "labels", ")", "in", "enumerate", "(", "eval", ".", "items", "(", ")", ")", ":", "\n", "            ", "lbls", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "num_labels", ")", ")", "\n", "for", "l", "in", "labels", ":", "\n", "                ", "lbls", "[", "0", ",", "l", "]", "=", "1.0", "\n", "", "eval_y", "[", "i", "]", "=", "lbls", "\n", "eval_mask", "[", "i", "]", "=", "node", "\n", "\n", "", "return", "train_mask", ",", "train_y", ",", "eval_mask", ",", "eval_y", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.compute_weights": [[60, 68], ["data.sum", "numpy.ones_like", "numpy.array", "enumerate", "torch.as_tensor", "zip", "len"], "methods", ["None"], ["", "def", "compute_weights", "(", "self", ",", "data", ")", ":", "\n", "        ", "class_counts", "=", "data", ".", "sum", "(", "axis", "=", "0", ")", "\n", "pos_weights", "=", "np", ".", "ones_like", "(", "class_counts", ")", "\n", "neg_counts", "=", "np", ".", "array", "(", "[", "len", "(", "data", ")", "-", "pos_count", "for", "pos_count", "in", "class_counts", "]", ")", "# <-- HERE", "\n", "for", "cdx", ",", "(", "pos_count", ",", "neg_count", ")", "in", "enumerate", "(", "zip", "(", "class_counts", ",", "neg_counts", ")", ")", ":", "\n", "            ", "pos_weights", "[", "cdx", "]", "=", "neg_count", "/", "(", "pos_count", "+", "1e-5", ")", "\n", "\n", "", "return", "torch", ".", "as_tensor", "(", "pos_weights", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.sampler.NodeClSampler.get_data": [[69, 71], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "train_mask", ",", "self", ".", "train_y", ",", "self", ".", "eval_mask", ",", "self", ".", "eval_y", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_roc_auc": [[9, 25], ["y_true.detach().cpu().numpy.detach().cpu().numpy", "y_pred.detach().cpu().numpy.detach().cpu().numpy", "range", "y_true.detach().cpu().numpy.detach().cpu", "y_pred.detach().cpu().numpy.detach().cpu", "rocauc_list.append", "len", "sum", "len", "numpy.sum", "numpy.sum", "sklearn.metrics.roc_auc_score", "y_true.detach().cpu().numpy.detach", "y_pred.detach().cpu().numpy.detach"], "function", ["None"], ["def", "compute_roc_auc", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\"\n\n    :param y_true: true labels, shape (n_samples, n_classes)\n    :param y_pred: predicted values, shape (n_samples, n_classes)\n    :return: roc_auc_score\n    \"\"\"", "\n", "y_true", "=", "y_true", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rocauc_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y_true", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "if", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "1", ")", ">", "0", "and", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "0", ")", ">", "0", ":", "\n", "            ", "is_labeled", "=", "y_true", "[", ":", ",", "i", "]", "==", "y_true", "[", ":", ",", "i", "]", "\n", "rocauc_list", ".", "append", "(", "roc_auc_score", "(", "y_true", "[", "is_labeled", ",", "i", "]", ",", "y_pred", "[", "is_labeled", ",", "i", "]", ")", ")", "\n", "#score = roc_auc_score(y_true, y_pred)", "\n", "", "", "return", "sum", "(", "rocauc_list", ")", "/", "len", "(", "rocauc_list", ")", "if", "len", "(", "rocauc_list", ")", ">", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_prcauc": [[27, 39], ["y_true.detach().cpu().numpy.detach().cpu().numpy", "y_pred.detach().cpu().numpy.detach().cpu().numpy", "range", "y_true.detach().cpu().numpy.detach().cpu", "y_pred.detach().cpu().numpy.detach().cpu", "sklearn.metrics.precision_recall_curve", "sklearn.metrics.auc", "prcauc_list.append", "len", "sum", "len", "numpy.sum", "numpy.sum", "y_true.detach().cpu().numpy.detach", "y_pred.detach().cpu().numpy.detach"], "function", ["None"], ["", "def", "compute_prcauc", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "y_true", "=", "y_true", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "prcauc_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y_true", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "if", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "1", ")", ">", "0", "and", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "0", ")", ">", "0", ":", "\n", "            ", "is_labeled", "=", "y_true", "[", ":", ",", "i", "]", "==", "y_true", "[", ":", ",", "i", "]", "\n", "precision", ",", "recall", ",", "_", "=", "precision_recall_curve", "(", "y_true", "[", "is_labeled", ",", "i", "]", ",", "y_pred", "[", "is_labeled", ",", "i", "]", ")", "\n", "prcauc", "=", "auc", "(", "recall", ",", "precision", ")", "\n", "prcauc_list", ".", "append", "(", "prcauc", ")", "\n", "\n", "", "", "return", "sum", "(", "prcauc_list", ")", "/", "len", "(", "prcauc_list", ")", "if", "len", "(", "prcauc_list", ")", ">", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_average_precision": [[41, 52], ["y_true.detach().cpu().numpy.detach().cpu().numpy", "y_pred.detach().cpu().numpy.detach().cpu().numpy", "range", "y_true.detach().cpu().numpy.detach().cpu", "y_pred.detach().cpu().numpy.detach().cpu", "sklearn.metrics.average_precision_score", "ap_list.append", "len", "sum", "len", "numpy.sum", "numpy.sum", "y_true.detach().cpu().numpy.detach", "y_pred.detach().cpu().numpy.detach"], "function", ["None"], ["", "def", "compute_average_precision", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "y_true", "=", "y_true", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ap_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y_true", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "if", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "1", ")", ">", "0", "and", "np", ".", "sum", "(", "y_true", "[", ":", ",", "i", "]", "==", "0", ")", ">", "0", ":", "\n", "            ", "is_labeled", "=", "y_true", "[", ":", ",", "i", "]", "==", "y_true", "[", ":", ",", "i", "]", "\n", "ap", "=", "average_precision_score", "(", "y_true", "[", "is_labeled", ",", "i", "]", ",", "y_pred", "[", "is_labeled", ",", "i", "]", ")", "\n", "ap_list", ".", "append", "(", "ap", ")", "\n", "\n", "", "", "return", "sum", "(", "ap_list", ")", "/", "len", "(", "ap_list", ")", "if", "len", "(", "ap_list", ")", ">", "0", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.hard_accuracy": [[54, 58], ["y_true.detach().cpu().numpy.detach().cpu().numpy", "y_pred.detach().cpu().numpy().round.detach().cpu().numpy().round", "sklearn.metrics.accuracy_score", "y_true.detach().cpu().numpy.detach().cpu", "y_pred.detach().cpu().numpy().round.detach().cpu().numpy", "y_true.detach().cpu().numpy.detach", "y_pred.detach().cpu().numpy().round.detach().cpu", "y_pred.detach().cpu().numpy().round.detach"], "function", ["None"], ["", "def", "hard_accuracy", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "y_true", "=", "y_true", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_pred", "=", "y_pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "round", "(", ")", "\n", "return", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.eval_classification": [[60, 67], ["evaluation.compute_roc_auc", "evaluation.compute_prcauc", "evaluation.compute_average_precision", "evaluation.hard_accuracy"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_roc_auc", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_prcauc", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.compute_average_precision", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.evaluation.hard_accuracy"], ["", "def", "eval_classification", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "rocauc", "=", "compute_roc_auc", "(", "y_true", ",", "y_pred", ")", "\n", "prcauc", "=", "compute_prcauc", "(", "y_true", ",", "y_pred", ")", "\n", "ap", "=", "compute_average_precision", "(", "y_true", ",", "y_pred", ")", "\n", "hard_acc", "=", "hard_accuracy", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "return", "{", "\"rocauc\"", ":", "rocauc", ",", "\"prcauc\"", ":", "prcauc", ",", "\"ap\"", ":", "ap", ",", "\"hard_acc\"", ":", "hard_acc", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.ilp_evaluator.ILPRankBasedEvaluator.__init__": [[11, 38], ["pykeen.evaluation.RankBasedEvaluator.__init__", "collections.defaultdict", "tuple", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "ks", ":", "Optional", "[", "Iterable", "[", "Union", "[", "int", ",", "float", "]", "]", "]", "=", "None", ",", "\n", "filtered", ":", "bool", "=", "True", ",", "\n", "head_samples", ":", "torch", ".", "Tensor", "=", "None", ",", "# shape: [num_valid_triples, n]", "\n", "tail_samples", ":", "torch", ".", "Tensor", "=", "None", ",", "# shape: [num_valid_triples, n]", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize rank-based evaluator.\n\n        :param ks:\n            The values for which to calculate hits@k. Defaults to {1,3,5,10}.\n        :param filtered:\n            Whether to use the filtered evaluation protocol. If enabled, ranking another true triple higher than the\n            currently considered one will not decrease the score.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "filtered", "=", "filtered", ")", "\n", "self", ".", "ks", "=", "tuple", "(", "ks", ")", "if", "ks", "is", "not", "None", "else", "(", "1", ",", "3", ",", "5", ",", "10", ")", "\n", "for", "k", "in", "self", ".", "ks", ":", "\n", "            ", "if", "isinstance", "(", "k", ",", "float", ")", "and", "not", "(", "0", "<", "k", "<", "1", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'If k is a float, it should represent a relative rank, i.e. a value between 0 and 1 (excl.)'", ",", "\n", ")", "\n", "", "", "self", ".", "ranks", ":", "Dict", "[", "Tuple", "[", "str", ",", "str", "]", ",", "List", "[", "float", "]", "]", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "num_entities", "=", "None", "\n", "\n", "self", ".", "head_samples", "=", "head_samples", "\n", "self", ".", "tail_samples", "=", "tail_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.ilp_evaluator.ILPRankBasedEvaluator._update_ranks_": [[40, 59], ["pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores", "pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores.items", "ilp_evaluator.ILPRankBasedEvaluator.ranks[].extend", "all_scores.gather", "v.detach().cpu().tolist", "sampled_entities.to", "v.detach().cpu", "v.detach"], "methods", ["None"], ["", "def", "_update_ranks_", "(", "\n", "self", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "all_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "side", ":", "str", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Shared code for updating the stored ranks for head/tail scores.\n\n        :param true_scores: shape: (batch_size,)\n        :param all_scores: shape: (batch_size, num_entities)\n        \"\"\"", "\n", "sampled_entities", "=", "self", ".", "head_samples", "if", "side", "==", "\"head\"", "else", "self", ".", "tail_samples", "\n", "batch_ranks", "=", "compute_rank_from_scores", "(", "\n", "true_score", "=", "true_scores", ",", "\n", "all_scores", "=", "all_scores", ".", "gather", "(", "1", ",", "sampled_entities", ".", "to", "(", "all_scores", ".", "device", ")", ")", ",", "\n", ")", "\n", "self", ".", "num_entities", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "for", "k", ",", "v", "in", "batch_ranks", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "ranks", "[", "side", ",", "k", "]", ".", "extend", "(", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop.__init__": [[33, 59], ["pykeen.training.training_loop.TrainingLoop.__init__", "negative_sampler_cls"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "Model", ",", "\n", "optimizer", ":", "Optional", "[", "Optimizer", "]", "=", "None", ",", "\n", "negative_sampler_cls", ":", "Optional", "[", "Type", "[", "NegativeSampler", "]", "]", "=", "None", ",", "\n", "negative_sampler_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize the training loop.\n\n        :param model: The model to train\n        :param optimizer: The optimizer to use while training the model\n        :param negative_sampler_cls: The class of the negative sampler\n        :param negative_sampler_kwargs: Keyword arguments to pass to the negative sampler class on instantiation\n         for every positive one\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", ")", "\n", "\n", "if", "negative_sampler_cls", "is", "None", ":", "\n", "            ", "negative_sampler_cls", "=", "BasicNegativeSampler", "\n", "\n", "", "self", ".", "negative_sampler", "=", "negative_sampler_cls", "(", "\n", "triples_factory", "=", "self", ".", "triples_factory", ",", "\n", "**", "(", "negative_sampler_kwargs", "or", "{", "}", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop.triples_factory": [[61, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "triples_factory", "(", "self", ")", "->", "TriplesFactory", ":", "# noqa: D401", "\n", "        ", "\"\"\"The triples factory in the model.\"\"\"", "\n", "return", "self", ".", "model", ".", "transductive_triples_factory", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop.num_negs_per_pos": [[66, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_negs_per_pos", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Return number of negatives per positive from the sampler.\n\n        Property for API compatibility\n        \"\"\"", "\n", "return", "self", ".", "negative_sampler", ".", "num_negs_per_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._create_instances": [[74, 76], ["inductive_slcwa.InductiveSLCWATrainingLoop.triples_factory.create_slcwa_instances"], "methods", ["None"], ["", "def", "_create_instances", "(", "self", ",", "use_tqdm", ":", "Optional", "[", "bool", "]", "=", "None", ")", "->", "SLCWAInstances", ":", "# noqa: D102", "\n", "        ", "return", "self", ".", "triples_factory", ".", "create_slcwa_instances", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._get_batch_size": [[77, 80], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_batch_size", "(", "batch", ":", "MappedTriples", ")", "->", "int", ":", "# noqa: D102", "\n", "        ", "return", "batch", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._process_batch": [[81, 116], ["batch[].to", "inductive_slcwa.InductiveSLCWATrainingLoop.negative_sampler.sample", "inductive_slcwa.InductiveSLCWATrainingLoop.to", "negative_batch.view.view.view", "inductive_slcwa.InductiveSLCWATrainingLoop.model.score_hrt", "inductive_slcwa.InductiveSLCWATrainingLoop.model.score_hrt", "inductive_slcwa.InductiveSLCWATrainingLoop._loss_helper", "AttributeError"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.score_hrt", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.score_hrt"], ["", "def", "_process_batch", "(", "\n", "self", ",", "\n", "batch", ":", "MappedTriples", ",", "\n", "start", ":", "int", ",", "\n", "stop", ":", "int", ",", "\n", "label_smoothing", ":", "float", "=", "0.0", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "# Slicing is not possible in sLCWA training loops", "\n", "        ", "if", "slice_size", "is", "not", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "'Slicing is not possible for sLCWA training loops.'", ")", "\n", "\n", "# Send positive batch to device", "\n", "", "positive_batch", "=", "batch", "[", "start", ":", "stop", "]", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "# Create negative samples", "\n", "neg_samples", "=", "self", ".", "negative_sampler", ".", "sample", "(", "positive_batch", "=", "positive_batch", ")", "\n", "\n", "# Ensure they reside on the device (should hold already for most simple negative samplers, e.g.", "\n", "# BasicNegativeSampler, BernoulliNegativeSampler", "\n", "negative_batch", "=", "neg_samples", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Make it negative batch broadcastable (required for num_negs_per_pos > 1).", "\n", "negative_batch", "=", "negative_batch", ".", "view", "(", "-", "1", ",", "3", ")", "\n", "\n", "# Compute negative and positive scores", "\n", "positive_scores", "=", "self", ".", "model", ".", "score_hrt", "(", "positive_batch", ")", "\n", "negative_scores", "=", "self", ".", "model", ".", "score_hrt", "(", "negative_batch", ")", "\n", "\n", "loss", "=", "self", ".", "_loss_helper", "(", "\n", "positive_scores", ",", "\n", "negative_scores", ",", "\n", "label_smoothing", ",", "\n", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._mr_loss_helper": [[117, 130], ["inductive_slcwa.InductiveSLCWATrainingLoop.model.compute_mr_loss", "positive_scores.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "_mr_loss_helper", "(", "\n", "self", ",", "\n", "positive_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "negative_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "_label_smoothing", "=", "None", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "# Repeat positives scores (necessary for more than one negative per positive)", "\n", "        ", "if", "self", ".", "num_negs_per_pos", ">", "1", ":", "\n", "            ", "positive_scores", "=", "positive_scores", ".", "repeat", "(", "self", ".", "num_negs_per_pos", ",", "1", ")", "\n", "\n", "", "return", "self", ".", "model", ".", "compute_mr_loss", "(", "\n", "positive_scores", "=", "positive_scores", ",", "\n", "negative_scores", "=", "negative_scores", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._self_adversarial_negative_sampling_loss_helper": [[132, 142], ["inductive_slcwa.InductiveSLCWATrainingLoop.model.compute_self_adversarial_negative_sampling_loss"], "methods", ["None"], ["", "def", "_self_adversarial_negative_sampling_loss_helper", "(", "\n", "self", ",", "\n", "positive_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "negative_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "_label_smoothing", "=", "None", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Compute self adversarial negative sampling loss.\"\"\"", "\n", "return", "self", ".", "model", ".", "compute_self_adversarial_negative_sampling_loss", "(", "\n", "positive_scores", "=", "positive_scores", ",", "\n", "negative_scores", "=", "negative_scores", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._label_loss_helper": [[144, 169], ["torch.cat", "torch.ones_like", "torch.zeros_like", "torch.cat", "inductive_slcwa.InductiveSLCWATrainingLoop.model.compute_label_loss", "pykeen.training.utils.apply_label_smoothing"], "methods", ["None"], ["", "def", "_label_loss_helper", "(", "\n", "self", ",", "\n", "positive_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "negative_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "label_smoothing", ":", "float", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "# Stack predictions", "\n", "        ", "predictions", "=", "torch", ".", "cat", "(", "[", "positive_scores", ",", "negative_scores", "]", ",", "dim", "=", "0", ")", "\n", "# Create target", "\n", "ones", "=", "torch", ".", "ones_like", "(", "positive_scores", ",", "device", "=", "self", ".", "device", ")", "\n", "zeros", "=", "torch", ".", "zeros_like", "(", "negative_scores", ",", "device", "=", "self", ".", "device", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "ones", ",", "zeros", "]", ",", "dim", "=", "0", ")", "\n", "\n", "if", "label_smoothing", ">", "0.", ":", "\n", "            ", "labels", "=", "apply_label_smoothing", "(", "\n", "labels", "=", "labels", ",", "\n", "epsilon", "=", "label_smoothing", ",", "\n", "num_classes", "=", "self", ".", "model", ".", "num_entities", ",", "\n", ")", "\n", "\n", "# Normalize the loss to have the average loss per positive triple", "\n", "# This allows comparability of sLCWA and LCWA losses", "\n", "", "return", "self", ".", "model", ".", "compute_label_loss", "(", "\n", "predictions", "=", "predictions", ",", "\n", "labels", "=", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.inductive_slcwa.InductiveSLCWATrainingLoop._slice_size_search": [[171, 184], ["logger.warning", "MemoryError"], "methods", ["None"], ["", "def", "_slice_size_search", "(", "\n", "self", ",", "\n", "batch_size", ":", "int", ",", "\n", "sub_batch_size", ":", "int", ",", "\n", "supports_sub_batching", ":", "bool", ",", "\n", ")", "->", "None", ":", "# noqa: D102", "\n", "# Slicing is not possible for sLCWA", "\n", "        ", "if", "supports_sub_batching", ":", "\n", "            ", "report", "=", "\"This model supports sub-batching, but it also requires slicing, which is not possible for sLCWA\"", "\n", "", "else", ":", "\n", "            ", "report", "=", "\"This model doesn't support sub-batching and slicing is not possible for sLCWA\"", "\n", "", "logger", ".", "warning", "(", "report", ")", "\n", "raise", "MemoryError", "(", "\"The current model can't be trained on this hardware with these parameters.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.get_metric": [[39, 67], ["name.count", "ValueError", "ValueError", "name.split", "ValueError", "ValueError", "getattr", "getattr", "metric.startswith", "int", "len"], "methods", ["None"], ["def", "get_metric", "(", "self", ",", "name", ":", "str", ")", "->", "float", ":", "# noqa: D102", "\n", "        ", "dot_count", "=", "name", ".", "count", "(", "'.'", ")", "\n", "if", "0", "==", "dot_count", ":", "# assume average by default", "\n", "            ", "rank_type", ",", "metric", "=", "'avg'", ",", "name", "\n", "", "elif", "1", "==", "dot_count", ":", "\n", "            ", "rank_type", ",", "metric", "=", "name", ".", "split", "(", "'.'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Malformed metric name: {name}'", ")", "\n", "\n", "", "if", "rank_type", "not", "in", "RANK_AVERAGE", "and", "metric", "in", "{", "'adjusted_mean_rank'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid rank type for adjusted mean rank: {rank_type}. Allowed type: {RANK_AVERAGE}'", ")", "\n", "", "elif", "rank_type", "not", "in", "RANK_TYPES", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid rank type: {rank_type}. Allowed types: {RANK_TYPES}'", ")", "\n", "\n", "", "if", "metric", "in", "{", "'mean_rank'", ",", "'mean_reciprocal_rank'", "}", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "metric", ")", "[", "rank_type", "]", "\n", "", "elif", "metric", "in", "{", "'adjusted_mean_rank'", "}", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "metric", ")", "\n", "\n", "", "rank_type_hits_at_k", "=", "self", ".", "hits_at_k", "[", "rank_type", "]", "\n", "for", "prefix", "in", "(", "'hits_at_'", ",", "'hits@'", ")", ":", "\n", "            ", "if", "not", "metric", ".", "startswith", "(", "prefix", ")", ":", "\n", "                ", "continue", "\n", "", "k", "=", "metric", "[", "len", "(", "prefix", ")", ":", "]", "\n", "k", "=", "10", "if", "k", "==", "'k'", "else", "int", "(", "k", ")", "\n", "return", "rank_type_hits_at_k", "[", "k", "]", "\n", "\n", "", "raise", "ValueError", "(", "f'Invalid metric name: {name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.to_flat_dict": [[68, 76], ["relation_rank_evaluator.RelationPredictionRankBasedMetricResults.hits_at_k[].items"], "methods", ["None"], ["", "def", "to_flat_dict", "(", "self", ")", ":", "# noqa: D102", "\n", "        ", "r", "=", "{", "'avg.adjusted_mean_rank'", ":", "self", ".", "adjusted_mean_rank", "}", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "r", "[", "f'{rank_type}.mean_rank'", "]", "=", "self", ".", "mean_rank", "[", "rank_type", "]", "\n", "r", "[", "f'{rank_type}.mean_reciprocal_rank'", "]", "=", "self", ".", "mean_reciprocal_rank", "[", "rank_type", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "hits_at_k", "[", "rank_type", "]", ".", "items", "(", ")", ":", "\n", "                ", "r", "[", "f'{rank_type}.hits_at_{k}'", "]", "=", "v", "\n", "", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedMetricResults.to_df": [[77, 88], ["pykeen.evaluation.rank_based_evaluator.pd.DataFrame", "rows.append", "rows.append", "relation_rank_evaluator.RelationPredictionRankBasedMetricResults.hits_at_k[].items", "rows.append"], "methods", ["None"], ["", "def", "to_df", "(", "self", ")", ":", "\n", "        ", "\"\"\"Output the metrics as a pandas dataframe.\"\"\"", "\n", "rows", "=", "[", "\n", "(", "'avg'", ",", "'adjusted_mean_rank'", ",", "self", ".", "adjusted_mean_rank", ")", "\n", "]", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "rows", ".", "append", "(", "(", "rank_type", ",", "'mean_rank'", ",", "self", ".", "mean_rank", "[", "rank_type", "]", ")", ")", "\n", "rows", ".", "append", "(", "(", "rank_type", ",", "'mean_reciprocal_rank'", ",", "self", ".", "mean_reciprocal_rank", "[", "rank_type", "]", ")", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "hits_at_k", "[", "rank_type", "]", ".", "items", "(", ")", ":", "\n", "                ", "rows", ".", "append", "(", "(", "rank_type", ",", "f'hits_at_{k}'", ",", "v", ")", ")", "\n", "", "", "return", "pd", ".", "DataFrame", "(", "rows", ",", "columns", "=", "[", "'Type'", ",", "'Metric'", ",", "'Value'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.__init__": [[91, 105], ["pykeen.evaluation.Evaluator.__init__", "collections.defaultdict", "tuple", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "ks", "=", "None", ",", "\n", "filtered", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "filtered", "=", "filtered", ")", "\n", "self", ".", "ks", "=", "tuple", "(", "ks", ")", "if", "ks", "is", "not", "None", "else", "(", "1", ",", "3", ",", "5", ",", "10", ")", "\n", "for", "k", "in", "self", ".", "ks", ":", "\n", "            ", "if", "isinstance", "(", "k", ",", "float", ")", "and", "not", "(", "0", "<", "k", "<", "1", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'If k is a float, it should represent a relative rank, i.e. a value between 0 and 1 (excl.)'", ",", "\n", ")", "\n", "", "", "self", ".", "ranks", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "num_relations", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_tail_scores_": [[106, 114], ["None"], "methods", ["None"], ["", "def", "process_tail_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_head_scores_": [[115, 123], ["None"], "methods", ["None"], ["", "def", "process_head_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_": [[124, 132], ["pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores", "pykeen.evaluation.rank_based_evaluator.compute_rank_from_scores.items", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks[].extend", "v.detach().cpu().tolist", "v.detach().cpu", "v.detach"], "methods", ["None"], ["", "def", "_update_ranks_", "(", "self", ",", "true_scores", ",", "all_scores", ")", ":", "\n", "        ", "batch_ranks", "=", "compute_rank_from_scores", "(", "\n", "true_score", "=", "true_scores", ",", "\n", "all_scores", "=", "all_scores", ",", "\n", ")", "\n", "self", ".", "num_relations", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "for", "k", ",", "v", "in", "batch_ranks", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "ranks", "[", "k", "]", ".", "extend", "(", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.evaluate": [[133, 171], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate"], ["", "", "def", "evaluate", "(", "\n", "self", ",", "model", ",", "mapped_triples", "=", "None", ",", "batch_size", "=", "None", ",", "slice_size", "=", "None", ",", "device", "=", "None", ",", "\n", "use_tqdm", "=", "True", ",", "tqdm_kwargs", "=", "None", ",", "restrict_entities_to", "=", "None", ",", "do_time_consuming_checks", "=", "True", ",", "\n", "additional_filter_triples", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "mapped_triples", "is", "None", ":", "\n", "            ", "mapped_triples", "=", "model", ".", "triples_factory", ".", "mapped_triples", "\n", "\n", "", "if", "batch_size", "is", "None", "and", "model", ".", "automatic_memory_optimization", ":", "\n", "            ", "batch_size", ",", "slice_size", "=", "self", ".", "batch_and_slice", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", ",", "\n", "use_tqdm", "=", "False", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n", "# The batch_size and slice_size should be accessible to outside objects for re-use, e.g. early stoppers.", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "slice_size", "=", "slice_size", "\n", "\n", "# Clear the ranks from the current evaluator", "\n", "self", ".", "finalize", "(", ")", "\n", "\n", "", "return", "evaluate", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filtered_triples", "=", "additional_filter_triples", ",", "\n", "evaluators", "=", "self", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "device", "=", "device", ",", "\n", "squeeze", "=", "True", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "tqdm_kwargs", "=", "tqdm_kwargs", ",", "\n", "restrict_relations_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks": [[173, 175], ["numpy.asarray", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks.get"], "methods", ["None"], ["", "def", "_get_ranks", "(", "self", ",", "rank_type", ")", ":", "\n", "        ", "return", "np", ".", "asarray", "(", "self", ".", "ranks", ".", "get", "(", "rank_type", ",", "[", "]", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.finalize": [[176, 204], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator.ranks.clear", "relation_rank_evaluator.RelationPredictionRankBasedMetricResults", "relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "numpy.mean", "numpy.mean", "len", "float", "len", "numpy.reciprocal", "numpy.mean", "dict", "dict", "dict", "isinstance", "numpy.mean", "numpy.mean", "int"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._get_ranks"], ["", "def", "finalize", "(", "self", ")", "->", "MetricResults", ":", "\n", "        ", "mean_rank", "=", "{", "}", "\n", "mean_reciprocal_rank", "=", "{", "}", "\n", "hits_at_k", "=", "{", "}", "\n", "adjusted_mean_rank", "=", "{", "}", "\n", "\n", "for", "rank_type", "in", "RANK_TYPES", ":", "\n", "            ", "ranks", "=", "self", ".", "_get_ranks", "(", "rank_type", "=", "rank_type", ")", "\n", "if", "len", "(", "ranks", ")", "<", "1", ":", "\n", "                ", "continue", "\n", "", "hits_at_k", "[", "rank_type", "]", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "ranks", "<=", "k", ")", "if", "isinstance", "(", "k", ",", "int", ")", "else", "np", ".", "mean", "(", "ranks", "<=", "int", "(", "self", ".", "num_relations", "*", "k", ")", ")", "\n", "for", "k", "in", "self", ".", "ks", "\n", "}", "\n", "mean_rank", "[", "rank_type", "]", "=", "np", ".", "mean", "(", "ranks", ")", "\n", "mean_reciprocal_rank", "[", "rank_type", "]", "=", "np", ".", "mean", "(", "np", ".", "reciprocal", "(", "ranks", ")", ")", "\n", "\n", "", "adjusted_ranks", "=", "self", ".", "_get_ranks", "(", "rank_type", "=", "RANK_AVERAGE_ADJUSTED", ")", "\n", "if", "len", "(", "adjusted_ranks", ")", ">=", "1", ":", "\n", "            ", "adjusted_mean_rank", "=", "float", "(", "np", ".", "mean", "(", "adjusted_ranks", ")", ")", "\n", "\n", "", "self", ".", "ranks", ".", "clear", "(", ")", "\n", "\n", "return", "RelationPredictionRankBasedMetricResults", "(", "\n", "mean_rank", "=", "dict", "(", "mean_rank", ")", ",", "\n", "mean_reciprocal_rank", "=", "dict", "(", "mean_reciprocal_rank", ")", ",", "\n", "hits_at_k", "=", "dict", "(", "hits_at_k", ")", ",", "\n", "adjusted_mean_rank", "=", "adjusted_mean_rank", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_": [[206, 214], ["relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator._update_ranks_"], ["", "def", "process_relation_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "# noqa: D102", "\n", "        ", "self", ".", "_update_ranks_", "(", "true_scores", "=", "true_scores", ",", "all_scores", "=", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor": [[216, 219], ["mapped_triples[].unique"], "function", ["None"], ["", "", "def", "get_unique_relation_ids_from_triples_tensor", "(", "mapped_triples", ":", "MappedTriples", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "\"\"\"Return the unique entity IDs used in a tensor of triples.\"\"\"", "\n", "return", "mapped_triples", "[", ":", ",", "1", "]", ".", "unique", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.evaluate": [[220, 386], ["isinstance", "pykeen.evaluation.evaluator.timeit.default_timer", "model.to.eval", "list", "list", "any", "mapped_triples.to.to", "pykeen.evaluation.evaluator.split_list_in_batches_iter", "dict", "pykeen.evaluation.evaluator.timeit.default_timer", "set", "set.difference", "model.to.to", "filter", "filter", "len", "torch.cat.to", "dict.update", "pykeen.evaluation.evaluator.optional_context_manager", "torch.no_grad", "pykeen.evaluation.evaluator.logger.debug", "pykeen.evaluation.evaluator.logger.info", "get_unique_relation_ids_from_triples_tensor().tolist", "restrict_relations_to.tolist", "len", "ValueError", "pykeen.evaluation.evaluator.logger.warning", "isinstance", "pykeen.evaluation.evaluator.tqdm", "relation_rank_evaluator._evaluate_batch", "evaluator.finalize", "len", "torch.cat", "torch.cat", "progress_bar.update", "relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.optional_context_manager", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator._evaluate_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.finalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.get_unique_relation_ids_from_triples_tensor"], ["", "def", "evaluate", "(", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "MappedTriples", ",", "\n", "evaluators", ":", "Union", "[", "Evaluator", ",", "Collection", "[", "Evaluator", "]", "]", ",", "\n", "additional_filtered_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "only_size_probing", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "squeeze", ":", "bool", "=", "True", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "tqdm_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "restrict_relations_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "Union", "[", "MetricResults", ",", "List", "[", "MetricResults", "]", "]", ":", "\n", "    ", "\"\"\"Evaluate metrics for model on mapped triples.\n\n    The model is used to predict scores for all tails and all heads for each triple. Subsequently, each abstract\n    evaluator is applied to the scores, also receiving the batch itself (e.g. to compute entity-specific metrics).\n    Thereby, the (potentially) expensive score computation against all entities is done only once. The metric evaluators\n    are expected to maintain their own internal buffers. They are returned after running the evaluation, and should\n    offer a possibility to extract some final metrics.\n\n    :param model:\n        The model to evaluate.\n    :param mapped_triples:\n        The triples on which to evaluate.\n    :param evaluators:\n        An evaluator or a list of evaluators working on batches of triples and corresponding scores.\n    :param only_size_probing:\n        The evaluation is only performed for two batches to test the memory footprint, especially on GPUs.\n    :param batch_size: >0\n        A positive integer used as batch size. Generally chosen as large as possible. Defaults to 1 if None.\n    :param slice_size: >0\n        The divisor for the scoring function when using slicing.\n    :param device:\n        The device on which the evaluation shall be run. If None is given, use the model's device.\n    :param squeeze:\n        Return a single instance of :class:`MetricResults` if only one evaluator was given.\n    :param use_tqdm:\n        Should a progress bar be displayed?\n    :param restrict_relations_to:\n        Optionally restrict the evaluation to the given relations IDs. This may be useful if one is only interested in a\n        part of the relations, e.g. due to type constraints, but wants to train on all available data. For ranking the\n        entities, we still compute all scores for all possible replacement entities to avoid irregular access patterns\n        which might decrease performance, but the scores with afterwards be filtered to only keep those of interest.\n        If provided, we assume that the triples are already filtered, such that it only contains the entities of\n        interest.\n    :param do_time_consuming_checks:\n        Whether to perform some time consuming checks on the provided arguments. Currently, this encompasses:\n        - If restrict_entities_to is not None, check whether the triples have been filtered.\n        Disabling this option can accelerate the method.\n    \"\"\"", "\n", "if", "isinstance", "(", "evaluators", ",", "Evaluator", ")", ":", "# upgrade a single evaluator to a list", "\n", "        ", "evaluators", "=", "[", "evaluators", "]", "\n", "\n", "", "start", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "# verify that the triples have been filtered", "\n", "if", "restrict_relations_to", "is", "not", "None", "and", "do_time_consuming_checks", ":", "\n", "        ", "present_relation_ids", "=", "set", "(", "get_unique_relation_ids_from_triples_tensor", "(", "mapped_triples", "=", "mapped_triples", ")", ".", "tolist", "(", ")", ")", "\n", "unwanted", "=", "present_relation_ids", ".", "difference", "(", "restrict_relations_to", ".", "tolist", "(", ")", ")", "\n", "if", "len", "(", "unwanted", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f'mapped_triples contains IDs of entities which are not contained in restrict_relations_to:'", "\n", "f'{unwanted}. This will invalidate the evaluation results.'", ")", "\n", "\n", "# Send to device", "\n", "", "", "if", "device", "is", "not", "None", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "", "device", "=", "model", ".", "device", "\n", "\n", "# Ensure evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Split evaluators into those which need unfiltered results, and those which require filtered ones", "\n", "filtered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "unfiltered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "not", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "\n", "# Check whether we need to be prepared for filtering", "\n", "filtering_necessary", "=", "len", "(", "filtered_evaluators", ")", ">", "0", "\n", "\n", "# Check whether an evaluator needs access to the masks", "\n", "# This can only be an unfiltered evaluator.", "\n", "positive_masks_required", "=", "any", "(", "e", ".", "requires_positive_mask", "for", "e", "in", "unfiltered_evaluators", ")", "\n", "\n", "# Prepare for result filtering", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "#all_pos_triples = torch.cat([model.triples_factory.mapped_triples, mapped_triples], dim=0)", "\n", "        ", "if", "additional_filtered_triples", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"The filtered setting was enabled, but there were no `additional_filtered_triples\"", "\n", "\"given. This means you probably forgot to pass (at least) the training triples. Try:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples]\"", "\n", "\"Or if you want to use the Bordes et al. (2013) approach to filtering, do:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples,dataset.validation.mapped_triples,]\"", ")", "\n", "all_pos_triples", "=", "mapped_triples", "\n", "", "elif", "isinstance", "(", "additional_filtered_triples", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "*", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "all_pos_triples", "=", "all_pos_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "all_pos_triples", "=", "None", "\n", "\n", "# Send tensors to device", "\n", "", "mapped_triples", "=", "mapped_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "# Prepare batches", "\n", "if", "batch_size", "is", "None", ":", "\n", "        ", "batch_size", "=", "1", "\n", "", "batches", "=", "split_list_in_batches_iter", "(", "input_list", "=", "mapped_triples", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Show progressbar", "\n", "num_triples", "=", "mapped_triples", ".", "shape", "[", "0", "]", "\n", "\n", "# Flag to check when to quit the size probing", "\n", "evaluated_once", "=", "False", "\n", "\n", "# Disable gradient tracking", "\n", "_tqdm_kwargs", "=", "dict", "(", "\n", "desc", "=", "f'Evaluating on {model.device}'", ",", "\n", "total", "=", "num_triples", ",", "\n", "unit", "=", "'triple'", ",", "\n", "unit_scale", "=", "True", ",", "\n", "# Choosing no progress bar (use_tqdm=False) would still show the initial progress bar without disable=True", "\n", "disable", "=", "not", "use_tqdm", ",", "\n", ")", "\n", "if", "tqdm_kwargs", ":", "\n", "        ", "_tqdm_kwargs", ".", "update", "(", "tqdm_kwargs", ")", "\n", "", "with", "optional_context_manager", "(", "use_tqdm", ",", "tqdm", "(", "**", "_tqdm_kwargs", ")", ")", "as", "progress_bar", ",", "torch", ".", "no_grad", "(", ")", ":", "\n", "# batch-wise processing", "\n", "        ", "for", "batch", "in", "batches", ":", "\n", "            ", "batch_size", "=", "batch", ".", "shape", "[", "0", "]", "\n", "_evaluate_batch", "(", "\n", "batch", "=", "batch", ",", "\n", "model", "=", "model", ",", "\n", "filtered_evaluators", "=", "filtered_evaluators", ",", "\n", "unfiltered_evaluators", "=", "unfiltered_evaluators", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", "restrict_relations_to", "=", "restrict_relations_to", ",", "\n", "positive_masks_required", "=", "positive_masks_required", ",", "\n", "filtering_necessary", "=", "filtering_necessary", ",", "\n", ")", "\n", "\n", "# If we only probe sizes we do not need more than one batch", "\n", "if", "only_size_probing", "and", "evaluated_once", ":", "\n", "                ", "break", "\n", "\n", "", "evaluated_once", "=", "True", "\n", "\n", "if", "use_tqdm", ":", "\n", "                ", "progress_bar", ".", "update", "(", "batch_size", ")", "\n", "\n", "# Finalize", "\n", "", "", "results", "=", "[", "evaluator", ".", "finalize", "(", ")", "for", "evaluator", "in", "evaluators", "]", "\n", "\n", "", "stop", "=", "timeit", ".", "default_timer", "(", ")", "\n", "if", "only_size_probing", ":", "\n", "        ", "logger", ".", "debug", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "\n", "", "if", "squeeze", "and", "len", "(", "results", ")", "==", "1", ":", "\n", "        ", "return", "results", "[", "0", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator._evaluate_batch": [[389, 498], ["model.predict_scores_all_relations", "relation_rank_evaluator.create_sparse_positive_filter_", "pykeen.evaluation.evaluator.create_dense_positive_mask_", "unfiltered_evaluator.process_relation_scores_", "pykeen.evaluation.evaluator.filter_scores_", "ValueError", "filtered_evaluator.process_relation_scores_", "torch.arange", "torch.zeros_like", "torch.arange"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_sparse_positive_filter_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_dense_positive_mask_", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.filter_scores_", "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator.process_relation_scores_"], ["", "def", "_evaluate_batch", "(", "\n", "batch", ",", "\n", "model", ",", "\n", "filtered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "unfiltered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", ",", "\n", "all_pos_triples", ":", "Optional", "[", "MappedTriples", "]", ",", "\n", "restrict_relations_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", ",", "\n", "positive_masks_required", ":", "bool", ",", "\n", "filtering_necessary", ":", "bool", ",", "\n", ")", "->", "torch", ".", "BoolTensor", ":", "\n", "    ", "\"\"\"\n    Evaluate batch for all head predictions(column=0), or all tail predictions (column=2).\n\n    :param batch: shape: (batch_size, 3)\n        The batch of currently evaluated triples.\n    :param model:\n        The model to evaluate.\n    :param column:\n        The column which to evaluate. Either 0 for head prediction, or 2 for tail prediction.\n    :param filtered_evaluators:\n        The evaluators which work on filtered scores.\n    :param unfiltered_evaluators:\n        The evaluators which work on unfiltered scores.\n    :param slice_size:\n        An optional slice size for computing the scores.\n    :param all_pos_triples:\n        All positive triples (required if filtering is necessary).\n    :param restrict_relations_to:\n        Restriction to evaluate only for these relations.\n    :param positive_masks_required:\n        Whether dense positive masks are required (by any unfiltered evaluator).\n    :param filtering_necessary:\n        Whether filtering is necessary.\n\n    :return:\n        The relation filter, which can be re-used for the same batch.\n    \"\"\"", "\n", "\n", "# Predict scores once", "\n", "batch_scores_of_corrupted", "=", "model", ".", "predict_scores_all_relations", "(", "batch", "[", ":", ",", "[", "0", ",", "2", "]", "]", ",", "slice_size", "=", "slice_size", ")", "\n", "\n", "# Select scores of true", "\n", "batch_scores_of_true", "=", "batch_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "1", "]", ",", "\n", "]", "\n", "\n", "# Create positive filter for all corrupted", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "# Needs all positive triples", "\n", "        ", "if", "all_pos_triples", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'If filtering_necessary of positive_masks_required is True, all_pos_triples has to be '", "\n", "'provided, but is None.'", ")", "\n", "\n", "# Create filter", "\n", "", "positive_filter", "=", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", ")", "\n", "\n", "# Create a positive mask with the size of the scores from the positive filter", "\n", "", "if", "positive_masks_required", ":", "\n", "        ", "positive_mask", "=", "create_dense_positive_mask_", "(", "\n", "zero_tensor", "=", "torch", ".", "zeros_like", "(", "batch_scores_of_corrupted", ")", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "positive_mask", "=", "None", "\n", "\n", "# Restrict to entities of interest", "\n", "", "if", "restrict_relations_to", "is", "not", "None", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "[", ":", ",", "restrict_relations_to", "]", "\n", "positive_mask", "=", "positive_mask", "[", ":", ",", "restrict_relations_to", "]", "\n", "", "else", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "\n", "\n", "# Evaluate metrics on these *unfiltered* scores", "\n", "", "for", "unfiltered_evaluator", "in", "unfiltered_evaluators", ":", "\n", "        ", "unfiltered_evaluator", ".", "process_relation_scores_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_scores_of_corrupted_", ",", "\n", "dense_positive_mask", "=", "positive_mask", ",", "\n", ")", "\n", "\n", "# Filter", "\n", "", "if", "filtering_necessary", ":", "\n", "        ", "batch_filtered_scores_of_corrupted", "=", "filter_scores_", "(", "\n", "scores", "=", "batch_scores_of_corrupted", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "\n", "# The scores for the true triples have to be rewritten to the scores tensor", "\n", "batch_filtered_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "1", "]", ",", "\n", "]", "=", "batch_scores_of_true", "\n", "\n", "# Restrict to entities of interest", "\n", "if", "restrict_relations_to", "is", "not", "None", ":", "\n", "            ", "batch_filtered_scores_of_corrupted", "=", "batch_filtered_scores_of_corrupted", "[", ":", ",", "restrict_relations_to", "]", "\n", "\n", "# Evaluate metrics on these *filtered* scores", "\n", "", "for", "filtered_evaluator", "in", "filtered_evaluators", ":", "\n", "            ", "filtered_evaluator", ".", "process_relation_scores_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_filtered_scores_of_corrupted", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.loops.relation_rank_evaluator.create_sparse_positive_filter_": [[500, 512], ["all_pos_triples[].view", "all_pos_triples[].view", "all_pos_triples[].view"], "function", ["None"], ["", "", "", "def", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "all_pos_triples", ":", "torch", ".", "LongTensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "torch", ".", "BoolTensor", "]", ":", "\n", "# Split batch", "\n", "    ", "batch_heads", ",", "batch_tails", "=", "hrt_batch", "[", ":", ",", "0", ":", "1", "]", ",", "hrt_batch", "[", ":", ",", "2", ":", "3", "]", "\n", "head_filter", "=", "(", "all_pos_triples", "[", ":", ",", "0", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "batch_heads", "\n", "tail_filter", "=", "(", "all_pos_triples", "[", ":", ",", "2", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "batch_tails", "\n", "filter_batch", "=", "(", "head_filter", "&", "tail_filter", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "filter_batch", "[", ":", ",", "1", "]", "=", "all_pos_triples", "[", ":", ",", "1", "]", ".", "view", "(", "1", ",", "-", "1", ")", "[", ":", ",", "filter_batch", "[", ":", ",", "1", "]", "]", "\n", "\n", "return", "filter_batch", "\n", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.EarlyStopper.__post_init__": [[101, 114], ["ValueError", "trackers.ResultTracker"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run after initialization and check the metric is valid.\"\"\"", "\n", "# TODO: Fix this", "\n", "# if all(f.name != self.metric for f in dataclasses.fields(self.evaluator.__class__)):", "\n", "#     raise ValueError(f'Invalid metric name: {self.metric}')", "\n", "if", "self", ".", "evaluation_triples_factory", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Must specify a validation_triples_factory or a dataset for using early stopping.'", ")", "\n", "\n", "", "self", ".", "remaining_patience", "=", "self", ".", "patience", "\n", "\n", "# Dummy result tracker", "\n", "if", "self", ".", "result_tracker", "is", "None", ":", "\n", "            ", "self", ".", "result_tracker", "=", "ResultTracker", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.EarlyStopper.should_evaluate": [[115, 118], ["None"], "methods", ["None"], ["", "", "def", "should_evaluate", "(", "self", ",", "epoch", ":", "int", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Decide if evaluation should be done based on the current epoch and the internal frequency.\"\"\"", "\n", "return", "epoch", ">", "0", "and", "epoch", "%", "self", ".", "frequency", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.EarlyStopper.number_results": [[119, 123], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "number_results", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"Count the number of results stored in the early stopper.\"\"\"", "\n", "return", "len", "(", "self", ".", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.EarlyStopper.should_stop": [[124, 181], ["early_stopping.EarlyStopper.evaluator.evaluate", "early_stopping.EarlyStopper.result_tracker.log_metrics", "early_stopping.EarlyStopper.get_metric", "early_stopping.EarlyStopper.results.append", "result_callback", "early_stopping.is_improvement", "logger.info", "continue_callback", "early_stopping.EarlyStopper.to_flat_dict", "stopped_callback"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.get_metric", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.is_improvement", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.to_flat_dict"], ["", "def", "should_stop", "(", "self", ",", "epoch", ":", "int", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Evaluate on a metric and compare to past evaluations to decide if training should stop.\"\"\"", "\n", "# Evaluate", "\n", "metric_results", "=", "self", ".", "evaluator", ".", "evaluate", "(", "\n", "model", "=", "self", ".", "model", ",", "\n", "mapped_triples", "=", "self", ".", "evaluation_triples_factory", ".", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "self", ".", "model", ".", "triples_factory", ".", "mapped_triples", ",", "\n", "use_tqdm", "=", "False", ",", "\n", "batch_size", "=", "self", ".", "evaluation_batch_size", ",", "\n", "slice_size", "=", "self", ".", "evaluation_slice_size", ",", "\n", "# Only perform time consuming checks for the first call.", "\n", "do_time_consuming_checks", "=", "self", ".", "evaluation_batch_size", "is", "None", ",", "\n", ")", "\n", "# After the first evaluation pass the optimal batch and slice size is obtained and saved for re-use", "\n", "self", ".", "evaluation_batch_size", "=", "self", ".", "evaluator", ".", "batch_size", "\n", "self", ".", "evaluation_slice_size", "=", "self", ".", "evaluator", ".", "slice_size", "\n", "\n", "self", ".", "result_tracker", ".", "log_metrics", "(", "\n", "metrics", "=", "metric_results", ".", "to_flat_dict", "(", ")", ",", "\n", "step", "=", "epoch", ",", "\n", "prefix", "=", "'validation'", ",", "\n", ")", "\n", "result", "=", "metric_results", ".", "get_metric", "(", "self", ".", "metric", ")", "\n", "\n", "# Append to history", "\n", "self", ".", "results", ".", "append", "(", "result", ")", "\n", "\n", "for", "result_callback", "in", "self", ".", "result_callbacks", ":", "\n", "            ", "result_callback", "(", "self", ",", "result", ",", "epoch", ")", "\n", "\n", "# check for improvement", "\n", "", "if", "self", ".", "best_metric", "is", "None", "or", "is_improvement", "(", "\n", "best_value", "=", "self", ".", "best_metric", ",", "\n", "current_value", "=", "result", ",", "\n", "larger_is_better", "=", "self", ".", "larger_is_better", ",", "\n", "relative_delta", "=", "self", ".", "relative_delta", ",", "\n", ")", ":", "\n", "            ", "self", ".", "best_epoch", "=", "epoch", "\n", "self", ".", "best_metric", "=", "result", "\n", "self", ".", "remaining_patience", "=", "self", ".", "patience", "\n", "", "else", ":", "\n", "            ", "self", ".", "remaining_patience", "-=", "1", "\n", "\n", "# Stop if the result did not improve more than delta for patience evaluations", "\n", "", "if", "self", ".", "remaining_patience", "<=", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f'Stopping early after {self.number_results} evaluations at epoch {epoch}. The best result '", "\n", "f'{self.metric}={self.best_metric} occurred at epoch {self.best_epoch}.'", ",", "\n", ")", "\n", "for", "stopped_callback", "in", "self", ".", "stopped_callbacks", ":", "\n", "                ", "stopped_callback", "(", "self", ",", "result", ",", "epoch", ")", "\n", "", "self", ".", "stopped", "=", "True", "\n", "return", "True", "\n", "\n", "", "for", "continue_callback", "in", "self", ".", "continue_callbacks", ":", "\n", "            ", "continue_callback", "(", "self", ",", "result", ",", "epoch", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.EarlyStopper.get_summary_dict": [[182, 194], ["dict"], "methods", ["None"], ["", "def", "get_summary_dict", "(", "self", ")", "->", "Mapping", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Get a summary dict.\"\"\"", "\n", "return", "dict", "(", "\n", "frequency", "=", "self", ".", "frequency", ",", "\n", "patience", "=", "self", ".", "patience", ",", "\n", "relative_delta", "=", "self", ".", "relative_delta", ",", "\n", "metric", "=", "self", ".", "metric", ",", "\n", "larger_is_better", "=", "self", ".", "larger_is_better", ",", "\n", "results", "=", "self", ".", "results", ",", "\n", "stopped", "=", "self", ".", "stopped", ",", "\n", "best_epoch", "=", "self", ".", "best_epoch", ",", "\n", "best_metric", "=", "self", ".", "best_metric", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.early_stopping.is_improvement": [[28, 54], ["None"], "function", ["None"], ["def", "is_improvement", "(", "\n", "best_value", ":", "float", ",", "\n", "current_value", ":", "float", ",", "\n", "larger_is_better", ":", "bool", ",", "\n", "relative_delta", ":", "float", "=", "0.0", ",", "\n", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Decide whether the current value is an improvement over the best value.\n\n    :param best_value:\n        The best value so far.\n    :param current_value:\n        The current value.\n    :param larger_is_better:\n        Whether a larger value is better.\n    :param relative_delta:\n        A minimum relative improvement until it is considered as an improvement.\n\n    :return:\n        Whether the current value is better.\n    \"\"\"", "\n", "if", "larger_is_better", ":", "\n", "        ", "return", "current_value", ">", "(", "1.0", "+", "relative_delta", ")", "*", "best_value", "\n", "\n", "# now: smaller is better", "\n", "", "return", "current_value", "<", "(", "1.0", "-", "relative_delta", ")", "*", "best_value", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.get_metric": [[47, 50], ["None"], "methods", ["None"], ["def", "get_metric", "(", "self", ",", "name", ":", "str", ")", "->", "float", ":", "\n", "        ", "\"\"\"Get the given metric from the results.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.to_flat_dict": [[51, 54], ["evaluator.MetricResults.to_dict"], "methods", ["None"], ["", "def", "to_flat_dict", "(", "self", ")", "->", "Mapping", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"Get the results as a flattened dictionary.\"\"\"", "\n", "return", "self", ".", "to_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.__init__": [[64, 75], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "filtered", ":", "bool", "=", "False", ",", "\n", "requires_positive_mask", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "None", ",", "\n", "slice_size", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "filtered", "=", "filtered", "\n", "self", ".", "requires_positive_mask", "=", "requires_positive_mask", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "slice_size", "=", "slice_size", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.get_normalized_name": [[76, 80], ["utils.normalize_string"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_normalized_name", "(", "cls", ")", "->", "str", ":", "\n", "        ", "\"\"\"Get the normalized name of the evaluator.\"\"\"", "\n", "return", "normalize_string", "(", "cls", ".", "__name__", ",", "suffix", "=", "Evaluator", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.process_tail_scores_": [[81, 98], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "process_tail_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Process a batch of triples with their computed tail scores for all entities.\n\n        :param hrt_batch: shape: (batch_size, 3)\n        :param true_scores: shape: (batch_size)\n        :param scores: shape: (batch_size, num_entities)\n        :param dense_positive_mask: shape: (batch_size, num_entities)\n            An optional binary (0/1) tensor indicating other true entities.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.process_head_scores_": [[99, 116], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "process_head_scores_", "(", "\n", "self", ",", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "true_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "dense_positive_mask", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Process a batch of triples with their computed head scores for all entities.\n\n        :param hrt_batch: shape: (batch_size, 3)\n        :param true_scores: shape: (batch_size)\n        :param scores: shape: (batch_size, num_entities)\n        :param dense_positive_mask: shape: (batch_size, num_entities)\n            An optional binary (0/1) tensor indicating other true entities.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.finalize": [[117, 121], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "finalize", "(", "self", ")", "->", "MetricResults", ":", "\n", "        ", "\"\"\"Compute the final results, and clear buffers.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.evaluate": [[122, 170], ["evaluator.Evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate"], ["", "def", "evaluate", "(", "\n", "self", ",", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "Optional", "[", "MappedTriples", "]", "=", "None", ",", "\n", "additional_filter_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "tqdm_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "restrict_entities_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "MetricResults", ":", "\n", "        ", "\"\"\"Run :func:`pykeen.evaluation.evaluate` with this evaluator.\"\"\"", "\n", "if", "mapped_triples", "is", "None", ":", "\n", "            ", "mapped_triples", "=", "model", ".", "triples_factory", ".", "mapped_triples", "\n", "\n", "", "if", "batch_size", "is", "None", "and", "model", ".", "automatic_memory_optimization", ":", "\n", "            ", "batch_size", ",", "slice_size", "=", "self", ".", "batch_and_slice", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "additional_filter_triples", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", ",", "\n", "use_tqdm", "=", "False", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n", "# The batch_size and slice_size should be accessible to outside objects for re-use, e.g. early stoppers.", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "slice_size", "=", "slice_size", "\n", "\n", "# Clear the ranks from the current evaluator", "\n", "self", ".", "finalize", "(", ")", "\n", "\n", "", "return", "evaluate", "(", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filtered_triples", "=", "additional_filter_triples", ",", "\n", "evaluators", "=", "self", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "device", "=", "device", ",", "\n", "squeeze", "=", "True", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "tqdm_kwargs", "=", "tqdm_kwargs", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.batch_and_slice": [[172, 245], ["evaluator.Evaluator._param_size_search", "evaluator.Evaluator._param_size_search", "MemoryError", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator._param_size_search", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator._param_size_search"], ["", "def", "batch_and_slice", "(", "\n", "self", ",", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "MappedTriples", ",", "\n", "additional_filter_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "use_tqdm", ":", "bool", "=", "False", ",", "\n", "restrict_entities_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "Tuple", "[", "int", ",", "Optional", "[", "int", "]", "]", ":", "\n", "        ", "\"\"\"Find the maximum possible batch_size and slice_size for evaluation with the current setting.\n\n        The speed of evaluation can be greatly increased when the batch_size is increased, therefore this function\n        estimates the maximal possible batch_size for the evaluation by starting with the batch_size given as argument\n        and increasing it until the hardware runs out-of-memory(OOM). In some cases, i.e. with very large models or very\n        large datasets, even the batch_size 1 is too big for the hardware at hand. In these cases, this function will\n        check if the model at hand allows slicing (this needs to be implemented for the affected scoring functions) and,\n        if possible, will search the maximum possible slice_size that would still allow to calculate the model with the\n        given parameters on the hardware at hand.\n\n        :param model:\n            The model to evaluate.\n        :param mapped_triples:\n            The triples on which to evaluate.\n        :param batch_size:\n            The initial batch size to start with. None defaults to number_of_triples.\n        :param device:\n            The device on which the evaluation shall be run. If None is given, use the model's device.\n        :param use_tqdm:\n            Should a progress bar be displayed?\n        :param restrict_entities_to:\n            Whether to restrict the evaluation to certain entities of interest.\n\n        :return:\n            Maximum possible batch size and, if necessary, the slice_size, which defaults to None.\n\n        :raises MemoryError:\n            If it is not possible to evaluate the model on the hardware at hand with the given parameters.\n        \"\"\"", "\n", "batch_size", ",", "evaluated_once", "=", "self", ".", "_param_size_search", "(", "\n", "key", "=", "'batch_size'", ",", "\n", "start_value", "=", "batch_size", ",", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "additional_filter_triples", ",", "\n", "device", "=", "device", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n", "\n", "if", "evaluated_once", ":", "# slice_size = None", "\n", "            ", "return", "batch_size", ",", "None", "\n", "\n", "# We need to try slicing, if the evaluation for the batch_size search never succeeded", "\n", "", "slice_size", ",", "evaluated_once", "=", "self", ".", "_param_size_search", "(", "\n", "key", "=", "'slice_size'", ",", "\n", "# Since the batch_size search with size 1, i.e. one tuple ((h, r) or (r, t)) scored on all entities,", "\n", "# must have failed to start slice_size search, we start with trying half the entities.", "\n", "start_value", "=", "ceil", "(", "model", ".", "num_entities", "/", "2", ")", ",", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "additional_filter_triples", ",", "\n", "device", "=", "device", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "False", ",", "\n", ")", "\n", "if", "not", "evaluated_once", ":", "\n", "            ", "raise", "MemoryError", "(", "\"The current model can't be trained on this hardware with these parameters.\"", ")", "\n", "\n", "", "return", "batch_size", ",", "slice_size", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator._param_size_search": [[246, 330], ["logger.info", "logger.debug", "evaluator.Evaluator._check_slicing_availability", "AttributeError", "gc.collect", "torch.cuda.empty_cache", "evaluator.Evaluator.evaluate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator._check_slicing_availability", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate"], ["", "def", "_param_size_search", "(", "\n", "self", ",", "\n", "key", ":", "str", ",", "\n", "start_value", ":", "int", ",", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "MappedTriples", ",", "\n", "additional_filter_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "use_tqdm", ":", "bool", "=", "False", ",", "\n", "restrict_entities_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "Tuple", "[", "int", ",", "bool", "]", ":", "\n", "        ", "values_dict", "=", "{", "}", "\n", "maximum_triples", "=", "mapped_triples", ".", "shape", "[", "0", "]", "\n", "if", "key", "==", "'batch_size'", ":", "\n", "            ", "if", "start_value", "is", "None", ":", "\n", "                ", "start_value", "=", "256", "\n", "", "if", "start_value", ">", "maximum_triples", ":", "\n", "                ", "start_value", "=", "maximum_triples", "\n", "", "values_dict", "[", "key", "]", "=", "start_value", "\n", "values_dict", "[", "'slice_size'", "]", "=", "None", "\n", "", "elif", "key", "==", "'slice_size'", ":", "\n", "            ", "self", ".", "_check_slicing_availability", "(", "model", ",", "batch_size", "=", "1", ")", "\n", "values_dict", "[", "key", "]", "=", "start_value", "\n", "values_dict", "[", "'batch_size'", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "(", "f'The parameter {key} is unknown.'", ")", "\n", "", "reached_max", "=", "False", "\n", "evaluated_once", "=", "False", "\n", "logger", ".", "info", "(", "f'Starting {key} search for evaluation now...'", ")", "\n", "while", "True", ":", "\n", "            ", "logger", ".", "debug", "(", "f'Trying {key}={values_dict[key]}'", ")", "\n", "try", ":", "\n", "# The cache of the previous run has to be freed to allow accurate memory availability estimates", "\n", "                ", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "evaluate", "(", "\n", "**", "values_dict", ",", "\n", "model", "=", "model", ",", "\n", "mapped_triples", "=", "mapped_triples", ",", "\n", "additional_filtered_triples", "=", "additional_filter_triples", ",", "\n", "evaluators", "=", "self", ",", "\n", "only_size_probing", "=", "True", ",", "\n", "device", "=", "device", ",", "\n", "squeeze", "=", "True", ",", "\n", "use_tqdm", "=", "use_tqdm", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "do_time_consuming_checks", "=", "do_time_consuming_checks", ",", "\n", ")", "\n", "evaluated_once", "=", "True", "\n", "", "except", "RuntimeError", "as", "runtime_error", ":", "\n", "# Due to the caused OOM Runtime Error, the failed model has to be cleared to avoid memory leakage", "\n", "                ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "del", "p", ".", "grad", "# free some memory", "\n", "# The cache of the previous run has to be freed to allow accurate memory availability estimates", "\n", "", "", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "not", "is_cudnn_error", "(", "runtime_error", ")", "and", "not", "is_cuda_oom_error", "(", "runtime_error", ")", ":", "\n", "                    ", "raise", "runtime_error", "\n", "", "if", "values_dict", "[", "key", "]", "==", "1", ":", "\n", "                    ", "logger", ".", "debug", "(", "\n", "f\"Even {key} {values_dict[key]} does not fit into your memory with these parameters.\"", ",", "\n", ")", "\n", "break", "\n", "\n", "", "values_dict", "[", "key", "]", "//=", "2", "\n", "reached_max", "=", "True", "\n", "if", "evaluated_once", ":", "\n", "                    ", "logger", ".", "info", "(", "f'Concluded {key} search with batch_size={values_dict[key]}.'", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "debug", "(", "f'The {key} {values_dict[key]} was too big, trying less now'", ")", "\n", "", "", "else", ":", "\n", "# The cache of the previous run has to be freed to allow accurate memory availability estimates", "\n", "                ", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "not", "reached_max", "and", "values_dict", "[", "'batch_size'", "]", "<", "maximum_triples", ":", "\n", "                    ", "values_dict", "[", "key", "]", "*=", "2", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "info", "(", "f'Concluded {key} search with batch_size={values_dict[key]}.'", ")", "\n", "break", "\n", "\n", "", "", "", "return", "values_dict", "[", "key", "]", ",", "evaluated_once", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator._check_slicing_availability": [[331, 341], ["MemoryError", "MemoryError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_check_slicing_availability", "(", "model", ":", "Model", ",", "batch_size", ":", "int", ")", "->", "None", ":", "\n", "# Test if slicing is implemented for the required functions of this model", "\n", "        ", "if", "model", ".", "triples_factory", ".", "create_inverse_triples", ":", "\n", "            ", "if", "not", "model", ".", "can_slice_t", ":", "\n", "                ", "raise", "MemoryError", "(", "f\"The current model can't be evaluated on this hardware with these parameters, as \"", "\n", "f\"evaluation batch_size={batch_size} is too big and slicing is not implemented for \"", "\n", "f\"this model yet.\"", ")", "\n", "", "", "elif", "not", "model", ".", "can_slice_t", "or", "not", "model", ".", "can_slice_h", ":", "\n", "            ", "raise", "MemoryError", "(", "f\"The current model can't be evaluated on this hardware with these parameters, as \"", "\n", "f\"evaluation batch_size={batch_size} is too big and slicing is not implemented for this \"", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.optional_context_manager": [[33, 40], ["None"], "function", ["None"], ["@", "contextmanager", "\n", "def", "optional_context_manager", "(", "condition", ",", "context_manager", ")", ":", "\n", "    ", "if", "condition", ":", "\n", "        ", "with", "context_manager", ":", "\n", "            ", "yield", "context_manager", "\n", "", "", "else", ":", "\n", "        ", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_sparse_positive_filter_": [[345, 393], ["NotImplementedError", "all_pos_triples[].view", "all_pos_triples[].view", "all_pos_triples[].view"], "function", ["None"], ["", "", "", "def", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", ":", "MappedTriples", ",", "\n", "all_pos_triples", ":", "torch", ".", "LongTensor", ",", "\n", "relation_filter", ":", "torch", ".", "BoolTensor", "=", "None", ",", "\n", "filter_col", ":", "int", "=", "0", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "LongTensor", ",", "torch", ".", "BoolTensor", "]", ":", "\n", "    ", "\"\"\"Compute indices of all positives.\n\n    For simplicity, only the head-side is described, i.e. filter_col=0. The tail-side is processed alike.\n\n    For each (h, r, t) triple in the batch, the entity identifiers are computed such that (h', r, t) exists in all\n    positive triples.\n\n    :param hrt_batch: shape: (batch_size, 3)\n        A batch of triples.\n    :param all_pos_triples: shape: (num_positive_triples, 3)\n        All positive triples to base the filtering on.\n    :param relation_filter: shape: (batch_size, num_positive_triples)\n        A boolean mask R[i, j] which is True iff the j-th positive triple contains the same relation as the i-th triple\n        in the batch.\n    :param filter_col:\n        The column along which to filter. Allowed are {0, 2}, where 0 corresponds to filtering head-based and 2\n        corresponds to filtering tail-based.\n\n    :return:\n        - positives, shape: (2, m)\n            The indices of positives in format [(batch_index, entity_id)].\n        - the relation filter for re-usage.\n    \"\"\"", "\n", "if", "filter_col", "not", "in", "{", "0", ",", "2", "}", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "'This code has only been written for updating head (filter_col=0) or '", "\n", "f'tail (filter_col=2) mask, but filter_col={filter_col} was given.'", ",", "\n", ")", "\n", "\n", "", "if", "relation_filter", "is", "None", ":", "\n", "        ", "relations", "=", "hrt_batch", "[", ":", ",", "1", ":", "2", "]", "\n", "relation_filter", "=", "(", "all_pos_triples", "[", ":", ",", "1", ":", "2", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "relations", "\n", "\n", "# Split batch", "\n", "", "other_col", "=", "2", "-", "filter_col", "\n", "entities", "=", "hrt_batch", "[", ":", ",", "other_col", ":", "other_col", "+", "1", "]", "\n", "\n", "entity_filter_test", "=", "(", "all_pos_triples", "[", ":", ",", "other_col", ":", "other_col", "+", "1", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", "==", "entities", "\n", "filter_batch", "=", "(", "entity_filter_test", "&", "relation_filter", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "filter_batch", "[", ":", ",", "1", "]", "=", "all_pos_triples", "[", ":", ",", "filter_col", ":", "filter_col", "+", "1", "]", ".", "view", "(", "1", ",", "-", "1", ")", "[", ":", ",", "filter_batch", "[", ":", ",", "1", "]", "]", "\n", "\n", "return", "filter_batch", ",", "relation_filter", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_dense_positive_mask_": [[395, 411], ["None"], "function", ["None"], ["", "def", "create_dense_positive_mask_", "(", "\n", "zero_tensor", ":", "torch", ".", "FloatTensor", ",", "\n", "filter_batch", ":", "torch", ".", "LongTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"Construct dense positive mask.\n\n    :param zero_tensor: shape: (batch_size, num_entities)\n        A tensor of zeros of suitable shape.\n    :param filter_batch: shape: (m, 2)\n        The indices of all positives in format (batch_index, entity_id)\n    :return:\n        The dense positive mask with x[b, i] = 1 iff (b, i) in filter_batch.\n    \"\"\"", "\n", "zero_tensor", "[", "filter_batch", "[", ":", ",", "0", "]", ",", "filter_batch", "[", ":", ",", "1", "]", "]", "=", "1", "\n", "\n", "return", "zero_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.filter_scores_": [[413, 442], ["float", "logger.warning"], "function", ["None"], ["", "def", "filter_scores_", "(", "\n", "scores", ":", "torch", ".", "FloatTensor", ",", "\n", "filter_batch", ":", "torch", ".", "LongTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"Filter scores by setting true scores to NaN.\n\n    :param scores: shape: (batch_size, num_entities)\n        The scores for all corrupted triples (including the currently considered true triple). Are modified *in-place*.\n    :param filter_batch: (m, 2)\n        The indices of all positives.\n\n    :return:\n        A reference to the scores, which have been updated in-place.\n    \"\"\"", "\n", "# Bind shape", "\n", "batch_size", ",", "num_entities", "=", "scores", ".", "shape", "\n", "\n", "# Set all filtered triples to NaN to ensure their exclusion in subsequent calculations", "\n", "scores", "[", "filter_batch", "[", ":", ",", "0", "]", ",", "filter_batch", "[", ":", ",", "1", "]", "]", "=", "float", "(", "'nan'", ")", "\n", "\n", "# Warn if all entities will be filtered", "\n", "# (scores != scores) yields true for all NaN instances (IEEE 754), thus allowing to count the filtered triples.", "\n", "if", "(", "(", "scores", "!=", "scores", ")", ".", "sum", "(", "dim", "=", "1", ")", "==", "num_entities", ")", ".", "any", "(", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"User selected filtered metric computation, but all corrupted triples exists also as positive \"", "\n", "\"triples\"", ",", "\n", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate": [[444, 614], ["isinstance", "timeit.default_timer", "model.to.eval", "list", "list", "any", "mapped_triples.to.to", "utils.split_list_in_batches_iter", "dict", "timeit.default_timer", "set", "set.difference", "model.to.to", "filter", "filter", "len", "torch.cat.to", "dict.update", "evaluator.optional_context_manager", "torch.no_grad", "logger.debug", "logger.info", "triples.triples_factory.get_unique_entity_ids_from_triples_tensor().tolist", "restrict_entities_to.tolist", "len", "ValueError", "logger.warning", "isinstance", "tqdmw.tqdm", "evaluator.finalize", "len", "torch.cat", "torch.cat", "evaluator._evaluate_batch", "progress_bar.update", "triples.triples_factory.get_unique_entity_ids_from_triples_tensor"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.optional_context_manager", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.Evaluator.finalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator._evaluate_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["", "def", "evaluate", "(", "\n", "model", ":", "Model", ",", "\n", "mapped_triples", ":", "MappedTriples", ",", "\n", "evaluators", ":", "Union", "[", "Evaluator", ",", "Collection", "[", "Evaluator", "]", "]", ",", "\n", "additional_filtered_triples", ":", "Union", "[", "None", ",", "MappedTriples", ",", "List", "[", "MappedTriples", "]", "]", "=", "None", ",", "\n", "only_size_probing", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "squeeze", ":", "bool", "=", "True", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "tqdm_kwargs", ":", "Optional", "[", "Mapping", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "restrict_entities_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "do_time_consuming_checks", ":", "bool", "=", "True", ",", "\n", ")", "->", "Union", "[", "MetricResults", ",", "List", "[", "MetricResults", "]", "]", ":", "\n", "    ", "\"\"\"Evaluate metrics for model on mapped triples.\n\n    The model is used to predict scores for all tails and all heads for each triple. Subsequently, each abstract\n    evaluator is applied to the scores, also receiving the batch itself (e.g. to compute entity-specific metrics).\n    Thereby, the (potentially) expensive score computation against all entities is done only once. The metric evaluators\n    are expected to maintain their own internal buffers. They are returned after running the evaluation, and should\n    offer a possibility to extract some final metrics.\n\n    :param model:\n        The model to evaluate.\n    :param mapped_triples:\n        The triples on which to evaluate.\n    :param evaluators:\n        An evaluator or a list of evaluators working on batches of triples and corresponding scores.\n    :param only_size_probing:\n        The evaluation is only performed for two batches to test the memory footprint, especially on GPUs.\n    :param batch_size: >0\n        A positive integer used as batch size. Generally chosen as large as possible. Defaults to 1 if None.\n    :param slice_size: >0\n        The divisor for the scoring function when using slicing.\n    :param device:\n        The device on which the evaluation shall be run. If None is given, use the model's device.\n    :param squeeze:\n        Return a single instance of :class:`MetricResults` if only one evaluator was given.\n    :param use_tqdm:\n        Should a progress bar be displayed?\n    :param restrict_entities_to:\n        Optionally restrict the evaluation to the given entity IDs. This may be useful if one is only interested in a\n        part of the entities, e.g. due to type constraints, but wants to train on all available data. For ranking the\n        entities, we still compute all scores for all possible replacement entities to avoid irregular access patterns\n        which might decrease performance, but the scores with afterwards be filtered to only keep those of interest.\n        If provided, we assume that the triples are already filtered, such that it only contains the entities of\n        interest.\n    :param do_time_consuming_checks:\n        Whether to perform some time consuming checks on the provided arguments. Currently, this encompasses:\n        - If restrict_entities_to is not None, check whether the triples have been filtered.\n        Disabling this option can accelerate the method.\n    \"\"\"", "\n", "if", "isinstance", "(", "evaluators", ",", "Evaluator", ")", ":", "# upgrade a single evaluator to a list", "\n", "        ", "evaluators", "=", "[", "evaluators", "]", "\n", "\n", "", "start", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "# verify that the triples have been filtered", "\n", "if", "restrict_entities_to", "is", "not", "None", "and", "do_time_consuming_checks", ":", "\n", "        ", "present_entity_ids", "=", "set", "(", "get_unique_entity_ids_from_triples_tensor", "(", "mapped_triples", "=", "mapped_triples", ")", ".", "tolist", "(", ")", ")", "\n", "unwanted", "=", "present_entity_ids", ".", "difference", "(", "restrict_entities_to", ".", "tolist", "(", ")", ")", "\n", "if", "len", "(", "unwanted", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f'mapped_triples contains IDs of entities which are not contained in restrict_entities_to:'", "\n", "f'{unwanted}. This will invalidate the evaluation results.'", ")", "\n", "\n", "# Send to device", "\n", "", "", "if", "device", "is", "not", "None", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "", "device", "=", "model", ".", "device", "\n", "\n", "# Ensure evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Split evaluators into those which need unfiltered results, and those which require filtered ones", "\n", "filtered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "unfiltered_evaluators", "=", "list", "(", "filter", "(", "lambda", "e", ":", "not", "e", ".", "filtered", ",", "evaluators", ")", ")", "\n", "\n", "# Check whether we need to be prepared for filtering", "\n", "filtering_necessary", "=", "len", "(", "filtered_evaluators", ")", ">", "0", "\n", "\n", "# Check whether an evaluator needs access to the masks", "\n", "# This can only be an unfiltered evaluator.", "\n", "positive_masks_required", "=", "any", "(", "e", ".", "requires_positive_mask", "for", "e", "in", "unfiltered_evaluators", ")", "\n", "\n", "# Prepare for result filtering", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "#all_pos_triples = torch.cat([model.triples_factory.mapped_triples, mapped_triples], dim=0)", "\n", "        ", "if", "additional_filtered_triples", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\"The filtered setting was enabled, but there were no `additional_filtered_triples\"", "\n", "\"given. This means you probably forgot to pass (at least) the training triples. Try:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples]\"", "\n", "\"Or if you want to use the Bordes et al. (2013) approach to filtering, do:\"", "\n", "\"additional_filtered_triples=[dataset.training.mapped_triples,dataset.validation.mapped_triples,]\"", ")", "\n", "all_pos_triples", "=", "mapped_triples", "\n", "", "elif", "isinstance", "(", "additional_filtered_triples", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "*", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "all_pos_triples", "=", "torch", ".", "cat", "(", "[", "additional_filtered_triples", ",", "mapped_triples", "]", ",", "dim", "=", "0", ")", "\n", "", "all_pos_triples", "=", "all_pos_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "all_pos_triples", "=", "None", "\n", "\n", "# Send tensors to device", "\n", "", "mapped_triples", "=", "mapped_triples", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "# Prepare batches", "\n", "if", "batch_size", "is", "None", ":", "\n", "        ", "batch_size", "=", "1", "\n", "", "batches", "=", "split_list_in_batches_iter", "(", "input_list", "=", "mapped_triples", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# Show progressbar", "\n", "num_triples", "=", "mapped_triples", ".", "shape", "[", "0", "]", "\n", "\n", "# Flag to check when to quit the size probing", "\n", "evaluated_once", "=", "False", "\n", "\n", "# Disable gradient tracking", "\n", "_tqdm_kwargs", "=", "dict", "(", "\n", "desc", "=", "f'Evaluating on {model.device}'", ",", "\n", "total", "=", "num_triples", ",", "\n", "unit", "=", "'triple'", ",", "\n", "unit_scale", "=", "True", ",", "\n", "# Choosing no progress bar (use_tqdm=False) would still show the initial progress bar without disable=True", "\n", "disable", "=", "not", "use_tqdm", ",", "\n", ")", "\n", "if", "tqdm_kwargs", ":", "\n", "        ", "_tqdm_kwargs", ".", "update", "(", "tqdm_kwargs", ")", "\n", "", "with", "optional_context_manager", "(", "use_tqdm", ",", "tqdm", "(", "**", "_tqdm_kwargs", ")", ")", "as", "progress_bar", ",", "torch", ".", "no_grad", "(", ")", ":", "\n", "# batch-wise processing", "\n", "        ", "for", "batch", "in", "batches", ":", "\n", "            ", "batch_size", "=", "batch", ".", "shape", "[", "0", "]", "\n", "relation_filter", "=", "None", "\n", "for", "column", "in", "(", "0", ",", "2", ")", ":", "\n", "                ", "relation_filter", "=", "_evaluate_batch", "(", "\n", "batch", "=", "batch", ",", "\n", "model", "=", "model", ",", "\n", "column", "=", "column", ",", "\n", "filtered_evaluators", "=", "filtered_evaluators", ",", "\n", "unfiltered_evaluators", "=", "unfiltered_evaluators", ",", "\n", "slice_size", "=", "slice_size", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", "relation_filter", "=", "relation_filter", ",", "\n", "restrict_entities_to", "=", "restrict_entities_to", ",", "\n", "positive_masks_required", "=", "positive_masks_required", ",", "\n", "filtering_necessary", "=", "filtering_necessary", ",", "\n", ")", "\n", "\n", "# If we only probe sizes we do not need more than one batch", "\n", "", "if", "only_size_probing", "and", "evaluated_once", ":", "\n", "                ", "break", "\n", "\n", "", "evaluated_once", "=", "True", "\n", "\n", "if", "use_tqdm", ":", "\n", "                ", "progress_bar", ".", "update", "(", "batch_size", ")", "\n", "\n", "# Finalize", "\n", "", "", "results", "=", "[", "evaluator", ".", "finalize", "(", ")", "for", "evaluator", "in", "evaluators", "]", "\n", "\n", "", "stop", "=", "timeit", ".", "default_timer", "(", ")", "\n", "if", "only_size_probing", ":", "\n", "        ", "logger", ".", "debug", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Evaluation took %.2fs seconds\"", ",", "stop", "-", "start", ")", "\n", "\n", "", "if", "squeeze", "and", "len", "(", "results", ")", "==", "1", ":", "\n", "        ", "return", "results", "[", "0", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator._evaluate_batch": [[616, 747], ["ValueError", "model.predict_scores_all_tails", "model.predict_scores_all_heads", "evaluator.create_sparse_positive_filter_", "evaluator.create_dense_positive_mask_", "process", "evaluator.filter_scores_", "ValueError", "process", "torch.arange", "torch.zeros_like", "torch.arange"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_sparse_positive_filter_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.create_dense_positive_mask_", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.filter_scores_"], ["", "def", "_evaluate_batch", "(", "\n", "batch", ":", "MappedTriples", ",", "\n", "model", ":", "Model", ",", "\n", "column", ":", "int", ",", "\n", "filtered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "unfiltered_evaluators", ":", "Collection", "[", "Evaluator", "]", ",", "\n", "slice_size", ":", "Optional", "[", "int", "]", ",", "\n", "all_pos_triples", ":", "Optional", "[", "MappedTriples", "]", ",", "\n", "relation_filter", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", ",", "\n", "restrict_entities_to", ":", "Optional", "[", "torch", ".", "LongTensor", "]", ",", "\n", "positive_masks_required", ":", "bool", ",", "\n", "filtering_necessary", ":", "bool", ",", "\n", ")", "->", "torch", ".", "BoolTensor", ":", "\n", "    ", "\"\"\"\n    Evaluate batch for all head predictions(column=0), or all tail predictions (column=2).\n\n    :param batch: shape: (batch_size, 3)\n        The batch of currently evaluated triples.\n    :param model:\n        The model to evaluate.\n    :param column:\n        The column which to evaluate. Either 0 for head prediction, or 2 for tail prediction.\n    :param filtered_evaluators:\n        The evaluators which work on filtered scores.\n    :param unfiltered_evaluators:\n        The evaluators which work on unfiltered scores.\n    :param slice_size:\n        An optional slice size for computing the scores.\n    :param all_pos_triples:\n        All positive triples (required if filtering is necessary).\n    :param relation_filter:\n        The relation filter. Can be re-used.\n    :param restrict_entities_to:\n        Restriction to evaluate only for these entities.\n    :param positive_masks_required:\n        Whether dense positive masks are required (by any unfiltered evaluator).\n    :param filtering_necessary:\n        Whether filtering is necessary.\n\n    :return:\n        The relation filter, which can be re-used for the same batch.\n    \"\"\"", "\n", "if", "column", "not", "in", "{", "0", ",", "2", "}", ":", "\n", "        ", "raise", "ValueError", "(", "f'column must be either 0 or 2, but is column={column}'", ")", "\n", "\n", "# Predict scores once", "\n", "", "if", "column", "==", "2", ":", "# tail scores", "\n", "        ", "batch_scores_of_corrupted", "=", "model", ".", "predict_scores_all_tails", "(", "batch", "[", ":", ",", "0", ":", "2", "]", ",", "slice_size", "=", "slice_size", ")", "\n", "", "else", ":", "\n", "        ", "batch_scores_of_corrupted", "=", "model", ".", "predict_scores_all_heads", "(", "batch", "[", ":", ",", "1", ":", "3", "]", ",", "slice_size", "=", "slice_size", ")", "\n", "\n", "# Select scores of true", "\n", "", "batch_scores_of_true", "=", "batch_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "column", "]", ",", "\n", "]", "\n", "\n", "# Create positive filter for all corrupted", "\n", "if", "filtering_necessary", "or", "positive_masks_required", ":", "\n", "# Needs all positive triples", "\n", "        ", "if", "all_pos_triples", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'If filtering_necessary of positive_masks_required is True, all_pos_triples has to be '", "\n", "'provided, but is None.'", ")", "\n", "\n", "# Create filter", "\n", "", "positive_filter", ",", "relation_filter", "=", "create_sparse_positive_filter_", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "all_pos_triples", "=", "all_pos_triples", ",", "\n", "relation_filter", "=", "relation_filter", ",", "\n", "filter_col", "=", "column", ",", "\n", ")", "\n", "\n", "# Create a positive mask with the size of the scores from the positive filter", "\n", "", "if", "positive_masks_required", ":", "\n", "        ", "positive_mask", "=", "create_dense_positive_mask_", "(", "\n", "zero_tensor", "=", "torch", ".", "zeros_like", "(", "batch_scores_of_corrupted", ")", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "positive_mask", "=", "None", "\n", "\n", "# Restrict to entities of interest", "\n", "", "if", "restrict_entities_to", "is", "not", "None", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "[", ":", ",", "restrict_entities_to", "]", "\n", "positive_mask", "=", "positive_mask", "[", ":", ",", "restrict_entities_to", "]", "\n", "", "else", ":", "\n", "        ", "batch_scores_of_corrupted_", "=", "batch_scores_of_corrupted", "\n", "\n", "# Evaluate metrics on these *unfiltered* scores", "\n", "", "for", "unfiltered_evaluator", "in", "unfiltered_evaluators", ":", "\n", "        ", "if", "column", "==", "2", ":", "# tail scores", "\n", "            ", "process", "=", "unfiltered_evaluator", ".", "process_tail_scores_", "\n", "", "else", ":", "\n", "            ", "process", "=", "unfiltered_evaluator", ".", "process_head_scores_", "\n", "", "process", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_scores_of_corrupted_", ",", "\n", "dense_positive_mask", "=", "positive_mask", ",", "\n", ")", "\n", "\n", "# Filter", "\n", "", "if", "filtering_necessary", ":", "\n", "        ", "batch_filtered_scores_of_corrupted", "=", "filter_scores_", "(", "\n", "scores", "=", "batch_scores_of_corrupted", ",", "\n", "filter_batch", "=", "positive_filter", ",", "\n", ")", "\n", "\n", "# The scores for the true triples have to be rewritten to the scores tensor", "\n", "batch_filtered_scores_of_corrupted", "[", "\n", "torch", ".", "arange", "(", "0", ",", "batch", ".", "shape", "[", "0", "]", ")", ",", "\n", "batch", "[", ":", ",", "column", "]", ",", "\n", "]", "=", "batch_scores_of_true", "\n", "\n", "# Restrict to entities of interest", "\n", "if", "restrict_entities_to", "is", "not", "None", ":", "\n", "            ", "batch_filtered_scores_of_corrupted", "=", "batch_filtered_scores_of_corrupted", "[", ":", ",", "restrict_entities_to", "]", "\n", "\n", "# Evaluate metrics on these *filtered* scores", "\n", "", "for", "filtered_evaluator", "in", "filtered_evaluators", ":", "\n", "            ", "if", "column", "==", "2", ":", "# tail scores", "\n", "                ", "process", "=", "filtered_evaluator", ".", "process_tail_scores_", "\n", "", "else", ":", "\n", "                ", "process", "=", "filtered_evaluator", ".", "process_head_scores_", "\n", "", "process", "(", "\n", "hrt_batch", "=", "batch", ",", "\n", "true_scores", "=", "batch_scores_of_true", "[", ":", ",", "None", "]", ",", "\n", "scores", "=", "batch_filtered_scores_of_corrupted", ",", "\n", ")", "\n", "\n", "", "", "return", "relation_filter", "\n", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.parse_args": [[31, 108], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.parse_args"], ["def", "parse_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Training and Testing Knowledge Graph Embedding Models'", ",", "\n", "usage", "=", "'train.py [<args>] [-h | --help]'", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--cuda'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use GPU'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--do_train'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_valid'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do_test'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--evaluate_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Evaluate on training data'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'ogbl-wikikg2'", ",", "help", "=", "'dataset name, default to wikikg2'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'RotatE'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'-de'", ",", "'--double_entity_embedding'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-dr'", ",", "'--double_relation_embedding'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n'", ",", "'--negative_sample_size'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "'--hidden_dim'", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'-g'", ",", "'--gamma'", ",", "default", "=", "12.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'-adv'", ",", "'--negative_adversarial_sampling'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-a'", ",", "'--adversarial_temperature'", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "'--batch_size'", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "'--regularization'", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'valid/test batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--uni_weight'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Otherwise use subsampling weighting like in word2vec'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-lr'", ",", "'--learning_rate'", ",", "default", "=", "0.0005", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'-cpu'", ",", "'--cpu_num'", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'-randomSeed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'-init'", ",", "'--init_checkpoint'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'-save'", ",", "'--save_path'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--max_steps'", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--warm_up_steps'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save_checkpoint_steps'", ",", "default", "=", "1000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--valid_steps'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--log_steps'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'train log every xx steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_log_steps'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'valid/test log every xx steps'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--nentity'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'DO NOT MANUALLY SET'", ")", "\n", "parser", ".", "add_argument", "(", "'--nrelation'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'DO NOT MANUALLY SET'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--print_on_screen'", ",", "action", "=", "'store_true'", ",", "help", "=", "'log on screen or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--ntriples_eval_train'", ",", "type", "=", "int", ",", "default", "=", "200000", ",", "\n", "help", "=", "'number of training triples to evaluate eventually'", ")", "\n", "parser", ".", "add_argument", "(", "'--neg_size_eval_train'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'number of negative samples when evaluating training triples'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--anchors'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "'Number of anchors to mine and use'", ")", "\n", "parser", ".", "add_argument", "(", "'--ancs_sp'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Limit to topK of shortest paths per entity'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--st_deg'", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "help", "=", "'Anchors: ratio of top degree nodes'", ")", "\n", "parser", ".", "add_argument", "(", "'--st_ppr'", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "help", "=", "'Anchors: ratio of top ppr nodes'", ")", "\n", "parser", ".", "add_argument", "(", "'--st_rand'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'Anchors: ratio of randomly selected nodes'", ")", "\n", "parser", ".", "add_argument", "(", "'--tkn_batch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'Batch size for iGraph anchor mining'", ")", "\n", "parser", ".", "add_argument", "(", "'--inverses'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to add inverse edges'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_inverses'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to add inverse edges to the validation set'", ")", "\n", "parser", ".", "add_argument", "(", "'--tkn_dir'", ",", "type", "=", "str", ",", "default", "=", "\"all\"", ",", "help", "=", "'neighbors direction for igraph'", ")", "\n", "parser", ".", "add_argument", "(", "'--part'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'tokenization on METIS graph partitions (for large graphs)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--pooler'", ",", "type", "=", "str", ",", "default", "=", "\"cat\"", ",", "help", "=", "'Set encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--rel_hash'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Path encoder: avg or gru'", ")", "\n", "parser", ".", "add_argument", "(", "'--policy'", ",", "type", "=", "str", ",", "default", "=", "\"sum\"", ",", "help", "=", "'Sum or cat anchors and aggregated paths'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_paths'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'How many paths per anchor to retain'", ")", "\n", "parser", ".", "add_argument", "(", "'--trf_layers'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Num of transformer layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--trf_heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'Num of transformer heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--trf_hidden'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'Transformer FC size and REL encoder size'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'Dropout in layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_dists'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "help", "=", "'use path lengths as pos enc'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_rels'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'number of relations in the relational context'", ")", "\n", "parser", ".", "add_argument", "(", "'--noanc'", ",", "action", "=", "'store_true'", ",", "help", "=", "'ablation: no anchors'", ")", "\n", "\n", "\n", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.override_config": [[110, 124], ["open", "json.load", "os.path.join"], "function", ["None"], ["", "def", "override_config", "(", "args", ")", ":", "\n", "    ", "'''\n    Override model and data configuration\n    '''", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "init_checkpoint", ",", "'config.json'", ")", ",", "'r'", ")", "as", "fjson", ":", "\n", "        ", "argparse_dict", "=", "json", ".", "load", "(", "fjson", ")", "\n", "\n", "", "args", ".", "dataset", "=", "argparse_dict", "[", "'dataset'", "]", "\n", "args", ".", "model", "=", "argparse_dict", "[", "'model'", "]", "\n", "args", ".", "double_entity_embedding", "=", "argparse_dict", "[", "'double_entity_embedding'", "]", "\n", "args", ".", "double_relation_embedding", "=", "argparse_dict", "[", "'double_relation_embedding'", "]", "\n", "args", ".", "hidden_dim", "=", "argparse_dict", "[", "'hidden_dim'", "]", "\n", "args", ".", "test_batch_size", "=", "argparse_dict", "[", "'test_batch_size'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.save_model": [[126, 153], ["vars", "torch.save", "model.anchor_embeddings.detach().cpu().numpy", "numpy.save", "model.relation_embedding.detach().cpu().numpy", "numpy.save", "open", "json.dump", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "model.state_dict", "optimizer.state_dict", "model.anchor_embeddings.detach().cpu", "model.relation_embedding.detach().cpu", "model.anchor_embeddings.detach", "model.relation_embedding.detach"], "function", ["None"], ["", "def", "save_model", "(", "model", ",", "optimizer", ",", "save_variable_list", ",", "args", ")", ":", "\n", "    ", "'''\n    Save the parameters of the model and the optimizer,\n    as well as some other variables such as step and learning_rate\n    '''", "\n", "\n", "argparse_dict", "=", "vars", "(", "args", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'config.json'", ")", ",", "'w'", ")", "as", "fjson", ":", "\n", "        ", "json", ".", "dump", "(", "argparse_dict", ",", "fjson", ")", "\n", "\n", "", "torch", ".", "save", "(", "{", "\n", "**", "save_variable_list", ",", "\n", "'model_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", "}", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'checkpoint'", ")", "\n", ")", "\n", "\n", "entity_embedding", "=", "model", ".", "anchor_embeddings", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'anchor_embedding'", ")", ",", "\n", "entity_embedding", "\n", ")", "\n", "\n", "relation_embedding", "=", "model", ".", "relation_embedding", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "'relation_embedding'", ")", ",", "\n", "relation_embedding", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.set_logger": [[156, 180], ["logging.basicConfig", "os.path.join", "os.path.join", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger().addHandler", "logging.getLogger"], "function", ["None"], ["", "def", "set_logger", "(", "args", ")", ":", "\n", "    ", "'''\n    Write logs to checkpoint and console\n    '''", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", "or", "args", ".", "init_checkpoint", ",", "'train.log'", ")", "\n", "", "else", ":", "\n", "        ", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", "or", "args", ".", "init_checkpoint", ",", "'test.log'", ")", "\n", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "'%(asctime)s %(levelname)-8s %(message)s'", ",", "\n", "level", "=", "logging", ".", "INFO", ",", "\n", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ",", "\n", "filename", "=", "log_file", ",", "\n", "filemode", "=", "'w'", "\n", ")", "\n", "\n", "if", "args", ".", "print_on_screen", ":", "\n", "        ", "console", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s %(levelname)-8s %(message)s'", ")", "\n", "console", ".", "setFormatter", "(", "formatter", ")", "\n", "logging", ".", "getLogger", "(", "''", ")", ".", "addHandler", "(", "console", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics": [[182, 189], ["logging.info", "writer.add_scalar"], "function", ["None"], ["", "", "def", "log_metrics", "(", "mode", ",", "step", ",", "metrics", ",", "writer", ")", ":", "\n", "    ", "'''\n    Print the evaluation logs\n    '''", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "logging", ".", "info", "(", "'%s %s at step %d: %f'", "%", "(", "mode", ",", "metric", ",", "step", ",", "metrics", "[", "metric", "]", ")", ")", "\n", "writer", ".", "add_scalar", "(", "\"_\"", ".", "join", "(", "[", "mode", ",", "metric", "]", ")", ",", "metrics", "[", "metric", "]", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.main": [[191, 488], ["tensorboardX.SummaryWriter", "run_ogb.set_logger", "logging.info", "torch.manual_seed", "numpy.random.seed", "ogb.linkproppred.LinkPropPredDataset", "ogb.linkproppred.LinkPropPredDataset.get_edge_split", "ogb.linkproppred.Evaluator", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "print", "ogb_tokenizer.NodePiece_OGB", "print", "len", "tqdm.tqdm", "ogb_wikikg2.model.KGEModel", "logging.info", "kge_model.cuda.named_parameters", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "ValueError", "run_ogb.override_config", "int", "print", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "print", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "range", "train_true_head[].append", "train_true_tail[].append", "logging.info", "kge_model.cuda.cuda", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "ogb_wikikg2.dataloader.BidirectionalOneShotIterator", "torch.optim.Adam", "logging.info", "torch.load", "kge_model.cuda.load_state_dict", "logging.info", "logging.info", "logging.info", "tqdm.tqdm", "run_ogb.save_model", "logging.info", "kge_model.cuda.test_step", "run_ogb.log_metrics", "logging.info", "kge_model.cuda.test_step", "run_ogb.log_metrics", "logging.info", "numpy.random.choice", "kge_model.cuda.test_step", "run_ogb.log_metrics", "len", "len", "len", "logging.info", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "logging.info", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "ogb_wikikg2.dummy_factory.DummyTripleFactory", "len", "ogb_wikikg2.dataloader.TrainDataset", "ogb_wikikg2.dataloader.TrainDataset", "filter", "os.path.join", "torch.optim.Adam.load_state_dict", "str", "range", "kge_model.cuda.train_step", "training_logs.append", "run_ogb.log_metrics", "run_ogb.log_metrics", "len", "time.time", "max", "torch.device", "torch.device", "sum", "max", "max", "kge_model.cuda.parameters", "logging.info", "torch.optim.Adam", "run_ogb.save_model", "training_logs[].keys", "run_ogb.log_metrics", "logging.info", "kge_model.cuda.test_step", "run_ogb.log_metrics", "str", "str", "filter", "param.size", "p.numel", "kge_model.cuda.parameters", "sum", "len", "logging.info", "kge_model.cuda.test_step", "run_ogb.log_metrics", "kge_model.cuda.parameters"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.set_logger", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.override_config", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.save_model", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.train_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.save_model", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "(", "not", "args", ".", "do_train", ")", "and", "(", "not", "args", ".", "do_valid", ")", "and", "(", "not", "args", ".", "do_test", ")", "and", "(", "not", "args", ".", "evaluate_train", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'one of train/val/test mode must be choosed.'", ")", "\n", "\n", "", "if", "args", ".", "init_checkpoint", ":", "\n", "        ", "override_config", "(", "args", ")", "\n", "\n", "", "args", ".", "save_path", "=", "'log/%s/%s/%s-%s/%s'", "%", "(", "\n", "args", ".", "dataset", ",", "args", ".", "model", ",", "args", ".", "hidden_dim", ",", "args", ".", "gamma", ",", "time", ".", "time", "(", ")", ")", "if", "args", ".", "save_path", "==", "None", "else", "args", ".", "save_path", "\n", "writer", "=", "SummaryWriter", "(", "args", ".", "save_path", ")", "\n", "\n", "# Write logs to checkpoint and console", "\n", "set_logger", "(", "args", ")", "\n", "\n", "logging", ".", "info", "(", "'Random seed: {}'", ".", "format", "(", "args", ".", "randomSeed", ")", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "randomSeed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "randomSeed", ")", "\n", "\n", "dataset", "=", "LinkPropPredDataset", "(", "name", "=", "args", ".", "dataset", ")", "\n", "split_dict", "=", "dataset", ".", "get_edge_split", "(", ")", "\n", "nentity", "=", "dataset", ".", "graph", "[", "'num_nodes'", "]", "\n", "nrelation", "=", "int", "(", "max", "(", "dataset", ".", "graph", "[", "'edge_reltype'", "]", ")", "[", "0", "]", ")", "+", "1", "\n", "\n", "evaluator", "=", "Evaluator", "(", "name", "=", "args", ".", "dataset", ")", "\n", "\n", "args", ".", "nentity", "=", "nentity", "\n", "args", ".", "nrelation", "=", "nrelation", "\n", "\n", "logging", ".", "info", "(", "'Model: %s'", "%", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "'Dataset: %s'", "%", "args", ".", "dataset", ")", "\n", "logging", ".", "info", "(", "'#entity: %d'", "%", "nentity", ")", "\n", "logging", ".", "info", "(", "'#relation: %d'", "%", "nrelation", ")", "\n", "\n", "train_triples", "=", "split_dict", "[", "'train'", "]", "\n", "logging", ".", "info", "(", "'#train: %d'", "%", "len", "(", "train_triples", "[", "'head'", "]", ")", ")", "\n", "valid_triples", "=", "split_dict", "[", "'valid'", "]", "\n", "logging", ".", "info", "(", "'#valid: %d'", "%", "len", "(", "valid_triples", "[", "'head'", "]", ")", ")", "\n", "test_triples", "=", "split_dict", "[", "'test'", "]", "\n", "logging", ".", "info", "(", "'#test: %d'", "%", "len", "(", "test_triples", "[", "'head'", "]", ")", ")", "\n", "\n", "if", "args", ".", "inverses", ":", "\n", "# add inverse triples", "\n", "        ", "print", "(", "\"Adding inverse edges\"", ")", "\n", "orig_head", ",", "orig_tail", "=", "train_triples", "[", "'head'", "]", ",", "train_triples", "[", "'tail'", "]", "\n", "train_triples", "[", "'head'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_head", ",", "orig_tail", "]", ")", "\n", "train_triples", "[", "'tail'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_tail", ",", "orig_head", "]", ")", "\n", "train_triples", "[", "'relation'", "]", "=", "np", ".", "concatenate", "(", "[", "train_triples", "[", "'relation'", "]", ",", "train_triples", "[", "'relation'", "]", "+", "nrelation", "]", ")", "\n", "\n", "# let's add inverses to the validation", "\n", "if", "args", ".", "val_inverses", ":", "\n", "            ", "logging", ".", "info", "(", "\"Adding inverses to the validation set\"", ")", "\n", "orig_head", ",", "orig_tail", "=", "valid_triples", "[", "'head'", "]", ",", "valid_triples", "[", "'tail'", "]", "\n", "orig_head_negs", ",", "orig_tail_negs", "=", "valid_triples", "[", "'head_neg'", "]", ",", "valid_triples", "[", "'tail_neg'", "]", "\n", "valid_triples", "[", "'head'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_head", ",", "orig_tail", "]", ")", "\n", "valid_triples", "[", "'tail'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_tail", ",", "orig_head", "]", ")", "\n", "valid_triples", "[", "'relation'", "]", "=", "np", ".", "concatenate", "(", "[", "valid_triples", "[", "'relation'", "]", ",", "valid_triples", "[", "'relation'", "]", "+", "nrelation", "]", ")", "\n", "valid_triples", "[", "'head_neg'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_head_negs", ",", "orig_tail_negs", "]", ",", "axis", "=", "0", ")", "\n", "valid_triples", "[", "'tail_neg'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_tail_negs", ",", "orig_head_negs", "]", ",", "axis", "=", "0", ")", "\n", "\n", "logging", ".", "info", "(", "\"Adding inverses to the test set\"", ")", "\n", "orig_head", ",", "orig_tail", "=", "test_triples", "[", "'head'", "]", ",", "test_triples", "[", "'tail'", "]", "\n", "orig_head_negs", ",", "orig_tail_negs", "=", "test_triples", "[", "'head_neg'", "]", ",", "test_triples", "[", "'tail_neg'", "]", "\n", "test_triples", "[", "'head'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_head", ",", "orig_tail", "]", ")", "\n", "test_triples", "[", "'tail'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_tail", ",", "orig_head", "]", ")", "\n", "test_triples", "[", "'relation'", "]", "=", "np", ".", "concatenate", "(", "[", "test_triples", "[", "'relation'", "]", ",", "test_triples", "[", "'relation'", "]", "+", "nrelation", "]", ")", "\n", "test_triples", "[", "'head_neg'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_head_negs", ",", "orig_tail_negs", "]", ",", "axis", "=", "0", ")", "\n", "test_triples", "[", "'tail_neg'", "]", "=", "np", ".", "concatenate", "(", "[", "orig_tail_negs", ",", "orig_head_negs", "]", ",", "axis", "=", "0", ")", "\n", "\n", "del", "orig_head", ",", "orig_tail", ",", "orig_head_negs", ",", "orig_tail_negs", "\n", "\n", "\n", "", "nrelation", "=", "nrelation", "*", "2", "+", "1", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"No inverse edges\"", ")", "\n", "nrelation", "+=", "1", "\n", "", "print", "(", "f\"Total num relations: {nrelation}\"", ")", "\n", "# create a tokenizer based on train triples", "\n", "tokenizer", "=", "NodePiece_OGB", "(", "\n", "triples", "=", "DummyTripleFactory", "(", "train_triples", ",", "ne", "=", "nentity", ",", "nr", "=", "nrelation", ")", ",", "\n", "anchor_strategy", "=", "{", "\n", "\"degree\"", ":", "args", ".", "st_deg", ",", "\n", "\"betweenness\"", ":", "0.0", ",", "\n", "\"pagerank\"", ":", "args", ".", "st_ppr", ",", "\n", "\"random\"", ":", "args", ".", "st_rand", "\n", "}", ",", "\n", "num_anchors", "=", "args", ".", "anchors", ",", "\n", "num_paths", "=", "args", ".", "anchors", ",", "\n", "dataset_name", "=", "args", ".", "dataset", ",", "\n", "limit_shortest", "=", "args", ".", "ancs_sp", ",", "\n", "add_identity", "=", "False", ",", "\n", "mode", "=", "\"bfs\"", ",", "\n", "tkn_batch", "=", "args", ".", "tkn_batch", ",", "\n", "inv", "=", "args", ".", "inverses", ",", "\n", "dir", "=", "args", ".", "tkn_dir", ",", "\n", "partition", "=", "args", ".", "part", ",", "\n", "cpus", "=", "args", ".", "cpu_num", "\n", ")", "\n", "\n", "#if args.max_seq_len == 0 or args.max_seq_len != (tokenizer.max_seq_len + 3):", "\n", "max_seq_len", "=", "tokenizer", ".", "max_seq_len", "+", "3", "# as in the PathTrfEncoder, +1 CLS, +1 PAD, +1 LP tasks", "\n", "print", "(", "f\"Set max_seq_len to {max_seq_len}\"", ")", "\n", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "NOTHING_TOKEN", "]", "=", "len", "(", "tokenizer", ".", "token2id", ")", "\n", "\n", "\n", "train_count", ",", "train_true_head", ",", "train_true_tail", "=", "defaultdict", "(", "lambda", ":", "4", ")", ",", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "train_triples", "[", "'head'", "]", ")", ")", ")", ":", "\n", "        ", "head", ",", "relation", ",", "tail", "=", "train_triples", "[", "'head'", "]", "[", "i", "]", ",", "train_triples", "[", "'relation'", "]", "[", "i", "]", ",", "train_triples", "[", "'tail'", "]", "[", "i", "]", "\n", "train_count", "[", "(", "head", ",", "relation", ")", "]", "+=", "1", "\n", "if", "not", "args", ".", "inverses", ":", "\n", "            ", "train_count", "[", "(", "tail", ",", "-", "relation", "-", "1", ")", "]", "+=", "1", "\n", "", "train_true_head", "[", "(", "relation", ",", "tail", ")", "]", ".", "append", "(", "head", ")", "\n", "train_true_tail", "[", "(", "head", ",", "relation", ")", "]", ".", "append", "(", "tail", ")", "\n", "\n", "", "kge_model", "=", "KGEModel", "(", "\n", "model_name", "=", "args", ".", "model", ",", "\n", "nentity", "=", "nentity", ",", "\n", "nrelation", "=", "nrelation", ",", "\n", "hidden_dim", "=", "args", ".", "hidden_dim", ",", "\n", "gamma", "=", "args", ".", "gamma", ",", "\n", "double_entity_embedding", "=", "args", ".", "double_entity_embedding", ",", "\n", "double_relation_embedding", "=", "args", ".", "double_relation_embedding", ",", "\n", "evaluator", "=", "evaluator", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "pooler", "=", "args", ".", "pooler", ",", "\n", "use_rels", "=", "args", ".", "rel_hash", ",", "\n", "rel_policy", "=", "args", ".", "policy", ",", "\n", "sample_paths", "=", "args", ".", "max_paths", ",", "\n", "trf_layers", "=", "args", ".", "trf_layers", ",", "\n", "trf_heads", "=", "args", ".", "trf_heads", ",", "\n", "trf_hidden", "=", "args", ".", "trf_hidden", ",", "\n", "drop", "=", "args", ".", "drop", ",", "\n", "use_distances", "=", "args", ".", "use_dists", ",", "\n", "max_seq_len", "=", "max_seq_len", ",", "\n", "sample_rels", "=", "args", ".", "sample_rels", ",", "\n", "triples", "=", "train_triples", ",", "\n", "ablate_anchors", "=", "args", ".", "noanc", ",", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "args", ".", "cuda", "else", "torch", ".", "device", "(", "'cpu'", ")", ",", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "'Model Parameter Configuration:'", ")", "\n", "for", "name", ",", "param", "in", "kge_model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Parameter %s: %s, require_grad = %s'", "%", "(", "name", ",", "str", "(", "param", ".", "size", "(", ")", ")", ",", "str", "(", "param", ".", "requires_grad", ")", ")", ")", "\n", "", "logging", ".", "info", "(", "f\"Total number of params: {sum(p.numel() for p in kge_model.parameters())}\"", ")", "\n", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "kge_model", "=", "kge_model", ".", "cuda", "(", ")", "\n", "\n", "", "if", "args", ".", "do_train", ":", "\n", "# Set training dataloader iterator", "\n", "        ", "train_dataloader_head", "=", "DataLoader", "(", "\n", "TrainDataset", "(", "train_triples", ",", "nentity", ",", "nrelation", ",", "\n", "args", ".", "negative_sample_size", ",", "'head-batch'", ",", "\n", "train_count", ",", "train_true_head", ",", "train_true_tail", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "max", "(", "1", ",", "args", ".", "cpu_num", "//", "2", ")", ",", "\n", "collate_fn", "=", "TrainDataset", ".", "collate_fn", "\n", ")", "\n", "\n", "train_dataloader_tail", "=", "DataLoader", "(", "\n", "TrainDataset", "(", "train_triples", ",", "nentity", ",", "nrelation", ",", "\n", "args", ".", "negative_sample_size", ",", "'tail-batch'", ",", "\n", "train_count", ",", "train_true_head", ",", "train_true_tail", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "max", "(", "1", ",", "args", ".", "cpu_num", "//", "2", ")", ",", "\n", "collate_fn", "=", "TrainDataset", ".", "collate_fn", "\n", ")", "\n", "\n", "train_iterator", "=", "BidirectionalOneShotIterator", "(", "train_dataloader_head", ",", "train_dataloader_tail", ")", "\n", "\n", "# Set training configuration", "\n", "current_learning_rate", "=", "args", ".", "learning_rate", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "kge_model", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "current_learning_rate", "\n", ")", "\n", "if", "args", ".", "warm_up_steps", ":", "\n", "            ", "warm_up_steps", "=", "args", ".", "warm_up_steps", "\n", "", "else", ":", "\n", "            ", "warm_up_steps", "=", "args", ".", "max_steps", "//", "2", "\n", "\n", "", "", "if", "args", ".", "init_checkpoint", ":", "\n", "# Restore model from checkpoint directory", "\n", "        ", "logging", ".", "info", "(", "'Loading checkpoint %s...'", "%", "args", ".", "init_checkpoint", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "init_checkpoint", ",", "'checkpoint'", ")", ")", "\n", "init_step", "=", "checkpoint", "[", "'step'", "]", "\n", "kge_model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "if", "args", ".", "do_train", ":", "\n", "            ", "current_learning_rate", "=", "checkpoint", "[", "'current_learning_rate'", "]", "\n", "warm_up_steps", "=", "checkpoint", "[", "'warm_up_steps'", "]", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer_state_dict'", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "'Ramdomly Initializing %s Model...'", "%", "args", ".", "model", ")", "\n", "init_step", "=", "0", "\n", "\n", "", "step", "=", "init_step", "\n", "\n", "logging", ".", "info", "(", "'Start Training...'", ")", "\n", "logging", ".", "info", "(", "'init_step = %d'", "%", "init_step", ")", "\n", "logging", ".", "info", "(", "'batch_size = %d'", "%", "args", ".", "batch_size", ")", "\n", "logging", ".", "info", "(", "'negative_adversarial_sampling = %d'", "%", "args", ".", "negative_adversarial_sampling", ")", "\n", "logging", ".", "info", "(", "'hidden_dim = %d'", "%", "args", ".", "hidden_dim", ")", "\n", "logging", ".", "info", "(", "'gamma = %f'", "%", "args", ".", "gamma", ")", "\n", "logging", ".", "info", "(", "'negative_adversarial_sampling = %s'", "%", "str", "(", "args", ".", "negative_adversarial_sampling", ")", ")", "\n", "if", "args", ".", "negative_adversarial_sampling", ":", "\n", "        ", "logging", ".", "info", "(", "'adversarial_temperature = %f'", "%", "args", ".", "adversarial_temperature", ")", "\n", "\n", "# Set valid dataloader as it would be evaluated during training", "\n", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "logging", ".", "info", "(", "'learning_rate = %d'", "%", "current_learning_rate", ")", "\n", "training_logs", "=", "[", "]", "\n", "max_val_mrr", "=", "0", "\n", "best_val_metrics", "=", "None", "\n", "best_test_metrics", "=", "None", "\n", "best_metrics_step", "=", "0", "\n", "\n", "# Training Loop", "\n", "for", "step", "in", "tqdm", "(", "range", "(", "init_step", ",", "args", ".", "max_steps", ")", ")", ":", "\n", "\n", "            ", "log", "=", "kge_model", ".", "train_step", "(", "kge_model", ",", "optimizer", ",", "train_iterator", ",", "args", ")", "\n", "training_logs", ".", "append", "(", "log", ")", "\n", "\n", "if", "step", ">=", "warm_up_steps", ":", "\n", "                ", "current_learning_rate", "=", "current_learning_rate", "/", "10", "\n", "logging", ".", "info", "(", "'Change learning_rate to %f at step %d'", "%", "(", "current_learning_rate", ",", "step", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "kge_model", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "current_learning_rate", "\n", ")", "\n", "warm_up_steps", "=", "warm_up_steps", "*", "3", "\n", "\n", "", "if", "step", "%", "args", ".", "save_checkpoint_steps", "==", "0", "and", "step", ">", "0", ":", "# ~ 41 seconds/saving", "\n", "                ", "save_variable_list", "=", "{", "\n", "'step'", ":", "step", ",", "\n", "'current_learning_rate'", ":", "current_learning_rate", ",", "\n", "'warm_up_steps'", ":", "warm_up_steps", "\n", "}", "\n", "save_model", "(", "kge_model", ",", "optimizer", ",", "save_variable_list", ",", "args", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "log_steps", "==", "0", ":", "\n", "                ", "metrics", "=", "{", "}", "\n", "for", "metric", "in", "training_logs", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "metrics", "[", "metric", "]", "=", "sum", "(", "[", "log", "[", "metric", "]", "for", "log", "in", "training_logs", "]", ")", "/", "len", "(", "training_logs", ")", "\n", "", "log_metrics", "(", "'Train'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "training_logs", "=", "[", "]", "\n", "\n", "", "if", "args", ".", "do_valid", "and", "step", "%", "args", ".", "valid_steps", "==", "0", "and", "step", ">", "0", ":", "\n", "                ", "logging", ".", "info", "(", "'Evaluating on Valid Dataset...'", ")", "\n", "metrics", "=", "kge_model", ".", "test_step", "(", "kge_model", ",", "valid_triples", ",", "args", ")", "\n", "log_metrics", "(", "'Valid'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "val_mrr", "=", "metrics", "[", "'mrr_list'", "]", "\n", "\n", "# evaluate on test set", "\n", "if", "val_mrr", ">", "max_val_mrr", ":", "\n", "                    ", "max_val_mrr", "=", "val_mrr", "\n", "best_val_metrics", "=", "metrics", "\n", "best_metrics_step", "=", "step", "\n", "\n", "if", "args", ".", "do_test", ":", "\n", "                        ", "logging", ".", "info", "(", "'Evaluating on Test Dataset...'", ")", "\n", "metrics", "=", "kge_model", ".", "test_step", "(", "kge_model", ",", "test_triples", ",", "args", ")", "\n", "log_metrics", "(", "'Test'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "best_test_metrics", "=", "metrics", "\n", "\n", "# record best metrics on validate and test set", "\n", "", "", "", "", "if", "args", ".", "do_valid", "and", "best_val_metrics", "!=", "None", ":", "\n", "            ", "log_metrics", "(", "'Best Val  Metrics'", ",", "best_metrics_step", ",", "best_val_metrics", ",", "writer", ")", "\n", "", "if", "args", ".", "do_test", "and", "best_test_metrics", "!=", "None", ":", "\n", "            ", "log_metrics", "(", "'Best Test Metrics'", ",", "best_metrics_step", ",", "best_test_metrics", ",", "writer", ")", "\n", "\n", "", "save_variable_list", "=", "{", "\n", "'step'", ":", "step", ",", "\n", "'current_learning_rate'", ":", "current_learning_rate", ",", "\n", "'warm_up_steps'", ":", "warm_up_steps", "\n", "}", "\n", "save_model", "(", "kge_model", ",", "optimizer", ",", "save_variable_list", ",", "args", ")", "\n", "\n", "", "if", "args", ".", "do_valid", ":", "\n", "        ", "logging", ".", "info", "(", "'Evaluating on Valid Dataset...'", ")", "\n", "metrics", "=", "kge_model", ".", "test_step", "(", "kge_model", ",", "valid_triples", ",", "args", ")", "\n", "log_metrics", "(", "'Valid'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "\n", "", "if", "args", ".", "do_test", ":", "\n", "        ", "logging", ".", "info", "(", "'Evaluating on Test Dataset...'", ")", "\n", "metrics", "=", "kge_model", ".", "test_step", "(", "kge_model", ",", "test_triples", ",", "args", ")", "\n", "log_metrics", "(", "'Test'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "\n", "", "if", "args", ".", "evaluate_train", ":", "\n", "        ", "logging", ".", "info", "(", "'Evaluating on Training Dataset...'", ")", "\n", "small_train_triples", "=", "{", "}", "\n", "indices", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "train_triples", "[", "'head'", "]", ")", ",", "args", ".", "ntriples_eval_train", ",", "replace", "=", "False", ")", "\n", "for", "i", "in", "train_triples", ":", "\n", "            ", "small_train_triples", "[", "i", "]", "=", "train_triples", "[", "i", "]", "[", "indices", "]", "\n", "", "metrics", "=", "kge_model", ".", "test_step", "(", "kge_model", ",", "small_train_triples", ",", "args", ",", "random_sampling", "=", "True", ")", "\n", "log_metrics", "(", "'Train'", ",", "step", ",", "metrics", ",", "writer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.__init__": [[25, 94], ["super().__init__", "set", "set().issubset", "ogb_tokenizer.NodePiece_OGB.tokenize_kg", "max", "Exception", "sum", "len", "len", "ogb_tokenizer.NodePiece_OGB.anchor_strategy.values", "set", "enumerate", "len", "enumerate", "len", "ogb_tokenizer.NodePiece_OGB.anchor_strategy.keys", "list", "ogb_tokenizer.NodePiece_OGB.vocab.items", "ogb_tokenizer.NodePiece_OGB.triples_factory.relation_to_id.values"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg"], ["def", "__init__", "(", "self", ",", "\n", "triples", ":", "TriplesFactory", ",", "\n", "dataset_name", ":", "str", ",", "\n", "num_anchors", ":", "int", ",", "\n", "anchor_strategy", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "num_paths", ":", "int", ",", "\n", "limit_shortest", ":", "int", "=", "0", ",", "\n", "limit_random", ":", "int", "=", "0", ",", "\n", "add_identity", ":", "bool", "=", "False", ",", "\n", "mode", ":", "str", "=", "\"bfs\"", ",", "\n", "tkn_batch", ":", "int", "=", "100", ",", "\n", "inv", ":", "bool", "=", "False", ",", "\n", "dir", ":", "str", "=", "\"in\"", ",", "\n", "partition", ":", "int", "=", "1", ",", "\n", "cpus", ":", "int", "=", "1", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "triples_factory", "=", "triples", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "num_anchors", "=", "num_anchors", "\n", "self", ".", "anchor_strategy", "=", "anchor_strategy", "\n", "self", ".", "num_paths", "=", "num_paths", "\n", "self", ".", "sp_limit", "=", "limit_shortest", "\n", "self", ".", "rand_limit", "=", "limit_random", "\n", "self", ".", "partition", "=", "partition", "\n", "self", ".", "cpus", "=", "cpus", "\n", "\n", "if", "self", ".", "sp_limit", "*", "self", ".", "rand_limit", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"-sp_limit and -rand_limit are mutually exclusive\"", ")", "\n", "\n", "", "self", ".", "add_identity", "=", "add_identity", "\n", "self", ".", "tkn_mode", "=", "mode", "\n", "\n", "self", ".", "NOTHING_TOKEN", "=", "-", "99", "\n", "self", ".", "CLS_TOKEN", "=", "-", "1", "\n", "self", ".", "MASK_TOKEN", "=", "-", "10", "\n", "self", ".", "PADDING_TOKEN", "=", "-", "100", "\n", "self", ".", "SEP_TOKEN", "=", "-", "2", "\n", "\n", "self", ".", "batch_size", "=", "tkn_batch", "\n", "self", ".", "use_inv", "=", "inv", "\n", "self", ".", "dir", "=", "dir", "\n", "\n", "\n", "self", ".", "AVAILABLE_STRATEGIES", "=", "set", "(", "[", "\"degree\"", ",", "\"betweenness\"", ",", "\"pagerank\"", ",", "\"random\"", "]", ")", "\n", "\n", "assert", "sum", "(", "self", ".", "anchor_strategy", ".", "values", "(", ")", ")", "==", "1.0", ",", "\"Ratios of strategies should sum up to one\"", "\n", "assert", "set", "(", "self", ".", "anchor_strategy", ".", "keys", "(", ")", ")", ".", "issubset", "(", "self", ".", "AVAILABLE_STRATEGIES", ")", "\n", "\n", "self", ".", "top_entities", ",", "self", ".", "other_entities", ",", "self", ".", "vocab", "=", "self", ".", "tokenize_kg", "(", ")", "\n", "\n", "self", ".", "token2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "top_entities", ")", "}", "\n", "self", ".", "rel2token", "=", "{", "t", ":", "i", "+", "len", "(", "self", ".", "top_entities", ")", "for", "i", ",", "t", "in", "\n", "enumerate", "(", "list", "(", "self", ".", "triples_factory", ".", "relation_to_id", ".", "values", "(", ")", ")", ")", "}", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "token2id", ")", "+", "len", "(", "self", ".", "rel2token", ")", "\n", "\n", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", "]", ")", "\n", "\n", "if", "self", ".", "add_identity", ":", "\n", "# add identity for anchor nodes as the first / closest node", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "# last 4 are always service tokens", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "=", "[", "[", "anchor", "]", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", ":", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "=", "[", "anchor", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "[", ":", "-", "1", "]", "\n", "self", ".", "vocab", "[", "anchor", "]", "[", "'dists'", "]", "[", "0", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.tokenize_kg": [[97, 164], ["pathlib.Path", "pathlib.Path.is_file", "igraph.Graph", "ogb_tokenizer.NodePiece_OGB.anchor_strategy.items", "pickle.dump", "print", "filename.split", "pickle.load", "type", "int", "print", "anchors.extend", "print", "ogb_tokenizer.NodePiece_OGB.create_all_paths", "ogb_tokenizer.NodePiece_OGB.mine_parallel", "open", "open", "ogb_tokenizer.NodePiece_OGB.triples_factory.mapped_triples[].numpy", "ogb_tokenizer.NodePiece_OGB.triples_factory.mapped_triples[].numpy", "ogb_tokenizer.NodePiece_OGB.triples_factory.mapped_triples[].numpy", "zip", "numpy.ceil", "sorted", "tops.pop", "range", "list", "NotImplementedError", "sorted", "tops.items", "len", "enumerate", "igraph.Graph.degree", "enumerate", "int", "numpy.random.permutation", "igraph.Graph.personalized_pagerank", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.mine_parallel"], ["", "", "", "", "def", "tokenize_kg", "(", "self", ")", ":", "\n", "\n", "        ", "strategy_encoding", "=", "f\"d{self.anchor_strategy['degree']}_b{self.anchor_strategy['betweenness']}_p{self.anchor_strategy['pagerank']}_r{self.anchor_strategy['random']}\"", "\n", "\n", "filename", "=", "f\"data/{self.dataset_name}_{self.num_anchors}_anchors_{self.num_paths}_paths_{strategy_encoding}_pykeen\"", "\n", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.sp_limit}sp\"", "# for separating vocabs with limited mined shortest paths", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.rand_limit}rand\"", "\n", "", "if", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "            ", "filename", "+=", "\"_bfs\"", "\n", "", "if", "self", ".", "partition", ">", "1", ":", "\n", "            ", "filename", "+=", "f\"_metis{self.partition}\"", "\n", "", "filename", "+=", "\".pkl\"", "\n", "self", ".", "model_name", "=", "filename", ".", "split", "(", "'.pkl'", ")", "[", "0", "]", "\n", "path", "=", "Path", "(", "filename", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "            ", "anchors", ",", "non_anchors", ",", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "return", "anchors", ",", "non_anchors", ",", "vocab", "\n", "\n", "", "if", "type", "(", "self", ".", "triples_factory", ".", "mapped_triples", ")", "==", "torch", ".", "Tensor", ":", "\n", "            ", "src", ",", "tgt", ",", "rels", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "0", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "2", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "1", "]", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "# dummy triple factory for OGB", "\n", "            ", "src", ",", "tgt", ",", "rels", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'head'", "]", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'tail'", "]", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'relation'", "]", "\n", "", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", ",", "r", "in", "zip", "(", "src", ",", "tgt", ",", "rels", ")", "]", "\n", "graph", "=", "Graph", "(", "n", "=", "self", ".", "triples_factory", ".", "num_entities", ",", "edges", "=", "edgelist", ",", "edge_attrs", "=", "{", "'relation'", ":", "list", "(", "rels", ")", "}", ",", "directed", "=", "True", ")", "\n", "\n", "\n", "anchors", "=", "[", "]", "\n", "for", "strategy", ",", "ratio", "in", "self", ".", "anchor_strategy", ".", "items", "(", ")", ":", "\n", "            ", "if", "ratio", "<=", "0.0", ":", "\n", "                ", "continue", "\n", "", "topK", "=", "int", "(", "np", ".", "ceil", "(", "ratio", "*", "self", ".", "num_anchors", ")", ")", "\n", "print", "(", "f\"Computing the {strategy} nodes\"", ")", "\n", "if", "strategy", "==", "\"degree\"", ":", "\n", "# top_nodes = sorted(graph.degree(), key=lambda x: x[1], reverse=True) # OLD NetworkX", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "degree", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"betweenness\"", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Betweenness is disabled due to computational costs\"", ")", "\n", "", "elif", "strategy", "==", "\"pagerank\"", ":", "\n", "#top_nodes = sorted(nx.pagerank(nx.DiGraph(graph)).items(), key=lambda x: x[1], reverse=True)", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "personalized_pagerank", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"random\"", ":", "\n", "                ", "top_nodes", "=", "[", "(", "int", "(", "k", ")", ",", "1", ")", "for", "k", "in", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", "]", "\n", "\n", "# slow version", "\n", "# selected_nodes = [node for node, d in top_nodes if node not in anchors][:topK]", "\n", "\n", "# faster version", "\n", "", "tops", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "top_nodes", "}", "\n", "# remove ancs", "\n", "for", "a", "in", "anchors", ":", "\n", "                ", "tops", ".", "pop", "(", "a", ",", "None", ")", "\n", "", "selected_nodes", "=", "[", "k", "for", "k", ",", "v", "in", "tops", ".", "items", "(", ")", "]", "[", ":", "topK", "]", "# dict is ordered so the sorted order is preserved", "\n", "\n", "anchors", ".", "extend", "(", "selected_nodes", ")", "\n", "print", "(", "f\"Added {len(selected_nodes)} nodes under the {strategy} strategy\"", ")", "\n", "\n", "", "vocab", "=", "self", ".", "create_all_paths", "(", "graph", ",", "anchors", ")", "if", "self", ".", "partition", "==", "1", "else", "self", ".", "mine_parallel", "(", "anchors", ")", "# self.mine_partitions(anchors)", "\n", "top_entities", "=", "anchors", "+", "[", "self", ".", "CLS_TOKEN", "]", "+", "[", "self", ".", "MASK_TOKEN", "]", "+", "[", "self", ".", "PADDING_TOKEN", "]", "+", "[", "self", ".", "SEP_TOKEN", "]", "\n", "non_core_entities", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "if", "i", "not", "in", "anchors", "]", "\n", "\n", "pickle", ".", "dump", "(", "(", "top_entities", ",", "non_core_entities", ",", "vocab", ")", ",", "open", "(", "filename", ",", "\"wb\"", ")", ")", "\n", "print", "(", "\"Vocabularized and saved!\"", ")", "\n", "\n", "return", "top_entities", ",", "non_core_entities", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.create_all_paths": [[166, 211], ["tqdm.tqdm.tqdm", "print", "print", "numpy.array", "set", "range", "any", "enumerate", "list", "graph.neighborhood", "enumerate", "range", "list", "nearest_ancs[].extend", "anc_dists[].extend", "range", "range", "len", "range", "set().intersection().difference", "enumerate", "nearest_ancs[].extend", "anc_dists[].extend", "len", "len", "len", "len", "set", "set().intersection", "range", "len", "range", "range", "set", "len", "len"], "methods", ["None"], ["", "def", "create_all_paths", "(", "self", ",", "graph", ":", "Graph", ",", "top_entities", ":", "List", "=", "None", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "\n", "        ", "vocab", "=", "{", "}", "\n", "if", "self", ".", "rand_limit", "==", "0", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.sp_limit if self.sp_limit >0 else self.num_paths} shortest paths per node\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.rand_limit} random paths per node\"", ")", "\n", "\n", "", "if", "self", ".", "tkn_mode", ":", "\n", "            ", "top_np", "=", "np", ".", "array", "(", "top_entities", ")", "\n", "anc_set", "=", "set", "(", "top_entities", ")", "\n", "\n", "# igraph_mode = \"in\" if self.use_inv else \"all\"", "\n", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "self", ".", "triples_factory", ".", "num_entities", ",", "self", ".", "batch_size", ")", ")", ":", "\n", "\n", "            ", "batch_verts", "=", "list", "(", "range", "(", "0", ",", "self", ".", "triples_factory", ".", "num_entities", ")", ")", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "\n", "limit", "=", "self", ".", "sp_limit", "if", "self", ".", "sp_limit", "!=", "0", "else", "(", "self", ".", "rand_limit", "if", "self", ".", "rand_limit", "!=", "0", "else", "self", ".", "num_paths", ")", "\n", "nearest_ancs", ",", "anc_dists", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "]", ",", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "]", "\n", "hop", "=", "1", "\n", "while", "any", "(", "[", "len", "(", "lst", ")", "<", "limit", "for", "lst", "in", "nearest_ancs", "]", ")", ":", "\n", "                ", "tgt_idx", "=", "[", "k", "for", "k", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "if", "len", "(", "nearest_ancs", "[", "k", "]", ")", "<", "limit", "]", "\n", "verts", "=", "[", "batch_verts", "[", "idx", "]", "for", "idx", "in", "tgt_idx", "]", "\n", "neigbs_list", "=", "graph", ".", "neighborhood", "(", "vertices", "=", "verts", ",", "order", "=", "hop", ",", "mode", "=", "self", ".", "dir", ",", "mindist", "=", "hop", ")", "# list of lists", "\n", "ancs", "=", "[", "list", "(", "set", "(", "neigbs", ")", ".", "intersection", "(", "anc_set", ")", ".", "difference", "(", "set", "(", "nearest_ancs", "[", "id", "]", ")", ")", ")", "for", "id", ",", "neigbs", "in", "enumerate", "(", "neigbs_list", ")", "]", "\n", "# updating anchor lists", "\n", "for", "local_idx", ",", "global_idx", "in", "enumerate", "(", "tgt_idx", ")", ":", "\n", "                    ", "nearest_ancs", "[", "global_idx", "]", ".", "extend", "(", "ancs", "[", "local_idx", "]", ")", "\n", "anc_dists", "[", "global_idx", "]", ".", "extend", "(", "[", "hop", "for", "_", "in", "range", "(", "len", "(", "ancs", "[", "local_idx", "]", ")", ")", "]", ")", "\n", "# nearest_ancs.extend(ancs)", "\n", "# anc_dists.extend([hop for _ in range(len(ancs))])", "\n", "", "hop", "+=", "1", "\n", "if", "hop", ">=", "50", ":", "# hardcoded constant for a disconnected node", "\n", "                    ", "for", "idx", "in", "tgt_idx", ":", "\n", "                        ", "nearest_ancs", "[", "idx", "]", ".", "extend", "(", "[", "self", ".", "NOTHING_TOKEN", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "nearest_ancs", "[", "idx", "]", ")", ")", "]", ")", "\n", "anc_dists", "[", "idx", "]", ".", "extend", "(", "[", "0", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "anc_dists", "[", "idx", "]", ")", ")", "]", ")", "\n", "break", "\n", "\n", "# update the vocab", "\n", "", "", "", "for", "idx", ",", "v", "in", "enumerate", "(", "batch_verts", ")", ":", "\n", "                ", "vocab", "[", "v", "]", "=", "{", "'ancs'", ":", "nearest_ancs", "[", "idx", "]", "[", ":", "limit", "]", ",", "'dists'", ":", "anc_dists", "[", "idx", "]", "[", ":", "limit", "]", "}", "\n", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.mine_partitions": [[213, 255], ["torch_geometric.data.Data", "print", "torch_geometric.data.cluster.ClusterData", "range", "dict", "len", "print", "int", "int", "list", "enumerate", "ogb_tokenizer.NodePiece_OGB.bfs_cluster", "dict.update", "sorted", "zip", "set().intersection", "local_anchor_ids.append", "n.item", "dict.items", "torch.tensor", "set", "local_id.item", "enumerate", "zip", "ogb_tokenizer.NodePiece_OGB.items", "set", "cluster_nodes.cpu().numpy", "cluster_nodes.cpu"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.bfs_cluster", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["", "def", "mine_partitions", "(", "self", ",", "anchors", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "# let's try splitting the graph into connected components with METIS and run mining on them", "\n", "\n", "        ", "src", ",", "tgt", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'head'", "]", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'tail'", "]", "\n", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", "in", "zip", "(", "src", ",", "tgt", ")", "]", "\n", "pyg_graph", "=", "Data", "(", "edge_index", "=", "torch", ".", "tensor", "(", "edgelist", ")", ".", "T", ",", "num_nodes", "=", "self", ".", "triples_factory", ".", "num_entities", ")", "\n", "print", "(", "f\"Using METIS to partition the graph into {self.partition} partitions\"", ")", "\n", "clusters", "=", "ClusterData", "(", "pyg_graph", ",", "num_parts", "=", "self", ".", "partition", ")", "\n", "\n", "vocab", "=", "{", "}", "\n", "\n", "# now find anchors in each cluster and tokenize clusters one by one", "\n", "for", "cluster_id", "in", "range", "(", "len", "(", "clusters", ")", ")", ":", "\n", "            ", "print", "(", "f\"Processing cluster {cluster_id}\"", ")", "\n", "start", "=", "int", "(", "clusters", ".", "partptr", "[", "cluster_id", "]", ")", "\n", "end", "=", "int", "(", "clusters", ".", "partptr", "[", "cluster_id", "+", "1", "]", ")", "\n", "cluster_nodes", "=", "clusters", ".", "perm", "[", "start", ":", "end", "]", "\n", "cluster_anchors", "=", "list", "(", "set", "(", "cluster_nodes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ".", "intersection", "(", "set", "(", "anchors", ")", ")", ")", "\n", "\n", "# map global anchor IDs to local ids [they start from 0 to num_nodes in cluster]", "\n", "local_anchor_ids", "=", "[", "]", "\n", "for", "anc_idx", ",", "anc", "in", "enumerate", "(", "cluster_anchors", ")", ":", "\n", "                ", "local_id", "=", "(", "cluster_nodes", "==", "anc", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "local_anchor_ids", ".", "append", "(", "local_id", ".", "item", "(", ")", ")", "\n", "\n", "", "node_mapping", "=", "{", "i", ":", "n", ".", "item", "(", ")", "for", "i", ",", "n", "in", "enumerate", "(", "cluster_nodes", ")", "}", "\n", "anchor_mapping", "=", "{", "loc_id", ":", "glob_id", "for", "loc_id", ",", "glob_id", "in", "zip", "(", "local_anchor_ids", ",", "cluster_anchors", ")", "}", "\n", "anchor_mapping", "[", "-", "99", "]", "=", "-", "99", "\n", "\n", "cluster", "=", "clusters", "[", "cluster_id", "]", "\n", "cl_vocab", "=", "self", ".", "bfs_cluster", "(", "cluster", ",", "local_anchor_ids", ")", "\n", "\n", "# re-map back to global ids", "\n", "cl_vocab", "=", "{", "node_mapping", "[", "k", "]", ":", "{", "\n", "'ancs'", ":", "[", "anchor_mapping", "[", "a", "]", "for", "a", "in", "v", "[", "'ancs'", "]", "]", ",", "\n", "'dists'", ":", "v", "[", "'dists'", "]", "\n", "}", "for", "k", ",", "v", "in", "cl_vocab", ".", "items", "(", ")", "}", "\n", "vocab", ".", "update", "(", "cl_vocab", ")", "\n", "\n", "# sort vocab by key - need it to be in the ascending order 0 - n", "\n", "", "vocab", "=", "dict", "(", "sorted", "(", "vocab", ".", "items", "(", ")", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.bfs_cluster": [[257, 313], ["set", "igraph.Graph", "tqdm.tqdm.tqdm", "cluster.edge_index.max", "range", "any", "enumerate", "s.item", "t.item", "zip", "list", "igraph.Graph.neighborhood", "enumerate", "range", "list", "nearest_ancs[].extend", "anc_dists[].extend", "range", "range", "len", "range", "set().intersection().difference", "enumerate", "nearest_ancs[].extend", "anc_dists[].extend", "len", "len", "len", "len", "set", "set().intersection", "range", "len", "range", "range", "set", "len", "len"], "methods", ["None"], ["", "def", "bfs_cluster", "(", "self", ",", "cluster", ":", "Data", ",", "anchors", ":", "List", ",", "tqdm_pos", "=", "None", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "\n", "        ", "num_nodes", "=", "cluster", ".", "edge_index", ".", "max", "(", ")", "+", "1", "\n", "edge_index", "=", "cluster", ".", "edge_index", "\n", "anc_set", "=", "set", "(", "anchors", ")", "\n", "vocab", "=", "{", "}", "\n", "\n", "edgelist", "=", "[", "[", "s", ".", "item", "(", ")", ",", "t", ".", "item", "(", ")", "]", "for", "s", ",", "t", "in", "zip", "(", "edge_index", "[", "0", "]", ",", "edge_index", "[", "1", "]", ")", "]", "\n", "graph", "=", "Graph", "(", "n", "=", "num_nodes", ",", "edges", "=", "edgelist", ",", "directed", "=", "False", ")", "\n", "\n", "# for i in tqdm(range(num_nodes)):", "\n", "#     limit = self.sp_limit if self.sp_limit != 0 else (self.rand_limit if self.rand_limit != 0 else self.num_paths)", "\n", "#     nearest_ancs, anc_dists = [], []", "\n", "#     hop = 1", "\n", "#     while len(nearest_ancs) < limit:", "\n", "#         neigbs = graph.neighborhood(vertices=i, order=hop, mode=\"all\", mindist=hop)", "\n", "#         ancs = list(set(neigbs).intersection(anc_set).difference(set(nearest_ancs)))", "\n", "#         nearest_ancs.extend(ancs)", "\n", "#         anc_dists.extend([hop for _ in range(len(ancs))])", "\n", "#         hop += 1", "\n", "#         if hop >= 50:  # hardcoded constant for a disconnected node", "\n", "#             nearest_ancs.extend([self.NOTHING_TOKEN for _ in range(limit - len(nearest_ancs))])", "\n", "#             anc_dists.extend([0 for _ in range(limit - len(anc_dists))])", "\n", "#             break", "\n", "#     vocab[i] = {'ancs': nearest_ancs[:limit], 'dists': anc_dists[:limit]}", "\n", "\n", "## BATCH version", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "num_nodes", ",", "self", ".", "batch_size", ")", ",", "position", "=", "tqdm_pos", ")", ":", "\n", "\n", "            ", "batch_verts", "=", "list", "(", "range", "(", "0", ",", "num_nodes", ")", ")", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "\n", "limit", "=", "self", ".", "sp_limit", "if", "self", ".", "sp_limit", "!=", "0", "else", "(", "self", ".", "rand_limit", "if", "self", ".", "rand_limit", "!=", "0", "else", "self", ".", "num_paths", ")", "\n", "nearest_ancs", ",", "anc_dists", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "]", ",", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "]", "\n", "hop", "=", "1", "\n", "while", "any", "(", "[", "len", "(", "lst", ")", "<", "limit", "for", "lst", "in", "nearest_ancs", "]", ")", ":", "\n", "                ", "tgt_idx", "=", "[", "k", "for", "k", "in", "range", "(", "len", "(", "batch_verts", ")", ")", "if", "len", "(", "nearest_ancs", "[", "k", "]", ")", "<", "limit", "]", "\n", "verts", "=", "[", "batch_verts", "[", "idx", "]", "for", "idx", "in", "tgt_idx", "]", "\n", "neigbs_list", "=", "graph", ".", "neighborhood", "(", "vertices", "=", "verts", ",", "order", "=", "hop", ",", "mode", "=", "self", ".", "dir", ",", "mindist", "=", "hop", ")", "# list of lists", "\n", "ancs", "=", "[", "list", "(", "set", "(", "neigbs", ")", ".", "intersection", "(", "anc_set", ")", ".", "difference", "(", "set", "(", "nearest_ancs", "[", "id", "]", ")", ")", ")", "for", "id", ",", "neigbs", "in", "enumerate", "(", "neigbs_list", ")", "]", "\n", "# updating anchor lists", "\n", "for", "local_idx", ",", "global_idx", "in", "enumerate", "(", "tgt_idx", ")", ":", "\n", "                    ", "nearest_ancs", "[", "global_idx", "]", ".", "extend", "(", "ancs", "[", "local_idx", "]", ")", "\n", "anc_dists", "[", "global_idx", "]", ".", "extend", "(", "[", "hop", "for", "_", "in", "range", "(", "len", "(", "ancs", "[", "local_idx", "]", ")", ")", "]", ")", "\n", "\n", "", "hop", "+=", "1", "\n", "if", "hop", ">=", "50", ":", "# hardcoded constant for a disconnected node", "\n", "                    ", "for", "idx", "in", "tgt_idx", ":", "\n", "                        ", "nearest_ancs", "[", "idx", "]", ".", "extend", "(", "[", "self", ".", "NOTHING_TOKEN", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "nearest_ancs", "[", "idx", "]", ")", ")", "]", ")", "\n", "anc_dists", "[", "idx", "]", ".", "extend", "(", "[", "0", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "anc_dists", "[", "idx", "]", ")", ")", "]", ")", "\n", "break", "\n", "\n", "# update the vocab", "\n", "", "", "", "for", "idx", ",", "v", "in", "enumerate", "(", "batch_verts", ")", ":", "\n", "                ", "vocab", "[", "v", "]", "=", "{", "'ancs'", ":", "nearest_ancs", "[", "idx", "]", "[", ":", "limit", "]", ",", "'dists'", ":", "anc_dists", "[", "idx", "]", "[", ":", "limit", "]", "}", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.mine_parallel": [[314, 360], ["torch_geometric.data.Data", "print", "torch_geometric.data.cluster.ClusterData", "range", "tqdm.tqdm.contrib.concurrent.process_map", "dict", "len", "int", "int", "list", "enumerate", "data_points.append", "dict.update", "sorted", "zip", "set().intersection", "local_anchor_ids.append", "n.item", "dict.items", "torch.tensor", "set", "local_id.item", "enumerate", "zip", "set", "cluster_nodes.cpu().numpy", "cluster_nodes.cpu"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["", "def", "mine_parallel", "(", "self", ",", "anchors", ")", ":", "\n", "        ", "from", "tqdm", ".", "contrib", ".", "concurrent", "import", "process_map", "\n", "# let's try splitting the graph into connected components with METIS and run mining on them", "\n", "src", ",", "tgt", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'head'", "]", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", "'tail'", "]", "\n", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", "in", "zip", "(", "src", ",", "tgt", ")", "]", "\n", "pyg_graph", "=", "Data", "(", "edge_index", "=", "torch", ".", "tensor", "(", "edgelist", ")", ".", "T", ",", "num_nodes", "=", "self", ".", "triples_factory", ".", "num_entities", ")", "\n", "print", "(", "f\"Using METIS to partition the graph into {self.partition} partitions\"", ")", "\n", "clusters", "=", "ClusterData", "(", "pyg_graph", ",", "num_parts", "=", "self", ".", "partition", ")", "\n", "\n", "vocab", "=", "{", "}", "\n", "data_points", "=", "[", "]", "\n", "\n", "# now find anchors in each cluster and tokenize clusters one by one", "\n", "for", "cluster_id", "in", "range", "(", "len", "(", "clusters", ")", ")", ":", "\n", "            ", "start", "=", "int", "(", "clusters", ".", "partptr", "[", "cluster_id", "]", ")", "\n", "end", "=", "int", "(", "clusters", ".", "partptr", "[", "cluster_id", "+", "1", "]", ")", "\n", "cluster_nodes", "=", "clusters", ".", "perm", "[", "start", ":", "end", "]", "\n", "cluster_anchors", "=", "list", "(", "set", "(", "cluster_nodes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ".", "intersection", "(", "set", "(", "anchors", ")", ")", ")", "\n", "\n", "# map global anchor IDs to local ids [they start from 0 to num_nodes in cluster]", "\n", "local_anchor_ids", "=", "[", "]", "\n", "for", "anc_idx", ",", "anc", "in", "enumerate", "(", "cluster_anchors", ")", ":", "\n", "                ", "local_id", "=", "(", "cluster_nodes", "==", "anc", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "\n", "local_anchor_ids", ".", "append", "(", "local_id", ".", "item", "(", ")", ")", "\n", "\n", "", "node_mapping", "=", "{", "i", ":", "n", ".", "item", "(", ")", "for", "i", ",", "n", "in", "enumerate", "(", "cluster_nodes", ")", "}", "\n", "anchor_mapping", "=", "{", "loc_id", ":", "glob_id", "for", "loc_id", ",", "glob_id", "in", "zip", "(", "local_anchor_ids", ",", "cluster_anchors", ")", "}", "\n", "anchor_mapping", "[", "-", "99", "]", "=", "-", "99", "\n", "\n", "#cluster = clusters[cluster_id]", "\n", "\n", "data_points", ".", "append", "(", "{", "\n", "'clusters'", ":", "clusters", ",", "\n", "'node_mapping'", ":", "node_mapping", ",", "\n", "'anchor_mapping'", ":", "anchor_mapping", ",", "\n", "'local_anchor_id'", ":", "local_anchor_ids", ",", "\n", "'tqdm_pos'", ":", "cluster_id", "+", "1", ",", "# we have an outer loop that starts with 0", "\n", "}", ")", "\n", "\n", "", "all_batches", "=", "process_map", "(", "self", ".", "mining_subp", ",", "data_points", ",", "max_workers", "=", "self", ".", "cpus", ")", "\n", "for", "d", "in", "all_batches", ":", "\n", "            ", "vocab", ".", "update", "(", "d", ")", "\n", "\n", "# sort vocab by key - need it to be in the ascending order 0 - n", "\n", "", "vocab", "=", "dict", "(", "sorted", "(", "vocab", ".", "items", "(", ")", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.mining_subp": [[361, 373], ["data_point.values", "ogb_tokenizer.NodePiece_OGB.bfs_cluster", "ogb_tokenizer.NodePiece_OGB.items"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.ogb_tokenizer.NodePiece_OGB.bfs_cluster"], ["", "def", "mining_subp", "(", "self", ",", "data_point", ")", ":", "\n", "        ", "clusters", ",", "node_mapping", ",", "anchor_mapping", ",", "local_anchor_ids", ",", "tqdm_pos", "=", "data_point", ".", "values", "(", ")", "\n", "cluster", "=", "clusters", "[", "tqdm_pos", "-", "1", "]", "\n", "cl_vocab", "=", "self", ".", "bfs_cluster", "(", "cluster", ",", "local_anchor_ids", ",", "tqdm_pos", ")", "\n", "\n", "# re-map back to global ids", "\n", "cl_vocab", "=", "{", "node_mapping", "[", "k", "]", ":", "{", "\n", "'ancs'", ":", "[", "anchor_mapping", "[", "a", "]", "for", "a", "in", "v", "[", "'ancs'", "]", "]", ",", "\n", "'dists'", ":", "v", "[", "'dists'", "]", "\n", "}", "for", "k", ",", "v", "in", "cl_vocab", ".", "items", "(", ")", "}", "\n", "\n", "return", "cl_vocab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dummy_factory.DummyTripleFactory.__init__": [[7, 14], ["range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "triples", ",", "ne", ",", "nr", ")", ":", "\n", "\n", "        ", "self", ".", "mapped_triples", "=", "triples", "\n", "self", ".", "num_entities", "=", "ne", "\n", "self", ".", "num_relations", "=", "nr", "\n", "\n", "self", ".", "relation_to_id", "=", "{", "i", ":", "i", "for", "i", "in", "range", "(", "nr", ")", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.__init__": [[26, 157], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model.KGEModel.set_enc.modules", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "print", "max", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "hasattr", "ValueError", "ValueError", "ValueError", "ValueError", "collections.defaultdict", "tqdm.tqdm.tqdm", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "module.reset_parameters", "model.KGEModel.embedding_range.item", "model.KGEModel.embedding_range.item", "tokenizer.vocab.items", "tokenizer.vocab.items", "range", "e2r[].add", "len", "len", "model.KGEModel.embedding_range.item", "model.KGEModel.embedding_range.item", "len", "collections.defaultdict.items", "random.sample", "range", "len", "len", "min", "numpy.mean", "numpy.percentile", "max", "model.KGEModel.gamma.item", "min", "min", "min", "min", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "nentity", ",", "nrelation", ",", "hidden_dim", ",", "gamma", ",", "evaluator", ",", "\n", "tokenizer", ",", "pooler", ",", "use_rels", ",", "rel_policy", ",", "sample_paths", ",", "\n", "trf_layers", ",", "trf_heads", ",", "trf_hidden", ",", "drop", ",", "use_distances", ",", "max_seq_len", ",", "\n", "sample_rels", ",", "triples", ",", "ablate_anchors", ",", "device", ",", "\n", "double_entity_embedding", "=", "False", ",", "double_relation_embedding", "=", "False", ")", ":", "\n", "        ", "super", "(", "KGEModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "nentity", "=", "nentity", "\n", "self", ".", "nrelation", "=", "nrelation", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "epsilon", "=", "2.0", "\n", "\n", "self", ".", "pooler", "=", "pooler", "\n", "self", ".", "use_rels", "=", "use_rels", "\n", "self", ".", "policy", "=", "rel_policy", "\n", "self", ".", "sample_paths", "=", "sample_paths", "\n", "self", ".", "use_distances", "=", "use_distances", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "sample_rels", "=", "sample_rels", "\n", "self", ".", "drop", "=", "drop", "\n", "self", ".", "triples", "=", "triples", "\n", "self", ".", "ablate_anchors", "=", "ablate_anchors", "\n", "self", ".", "device", "=", "device", "\n", "\n", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "[", "gamma", "]", ")", ",", "\n", "requires_grad", "=", "False", "\n", ")", "\n", "\n", "self", ".", "embedding_range", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "gamma", ".", "item", "(", ")", "+", "self", ".", "epsilon", ")", "/", "hidden_dim", "]", ")", ",", "\n", "requires_grad", "=", "False", "\n", ")", "\n", "\n", "self", ".", "entity_dim", "=", "hidden_dim", "*", "2", "if", "double_entity_embedding", "else", "hidden_dim", "\n", "self", ".", "relation_dim", "=", "hidden_dim", "*", "2", "if", "double_relation_embedding", "else", "hidden_dim", "\n", "\n", "# anchors hashing mechanism", "\n", "\n", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "entity_dim", "*", "(", "self", ".", "sample_paths", "+", "self", ".", "sample_rels", ")", ",", "self", ".", "entity_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "entity_dim", "*", "2", ",", "self", ".", "entity_dim", ")", "\n", ")", "if", "not", "self", ".", "ablate_anchors", "else", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "entity_dim", "*", "sample_rels", ",", "self", ".", "entity_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "entity_dim", "*", "2", ",", "self", ".", "entity_dim", ")", "\n", ")", "\n", "\n", "# init", "\n", "for", "module", "in", "self", ".", "set_enc", ".", "modules", "(", ")", ":", "\n", "            ", "if", "module", "is", "self", ":", "\n", "                ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "len", "(", "tokenizer", ".", "token2id", ")", "+", "1", ",", "embedding_dim", "=", "self", ".", "entity_dim", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "\n", "tensor", "=", "self", ".", "anchor_embeddings", ".", "weight", ",", "# .weight for Embedding", "\n", "a", "=", "-", "self", ".", "embedding_range", ".", "item", "(", ")", ",", "\n", "b", "=", "self", ".", "embedding_range", ".", "item", "(", ")", "\n", ")", "\n", "\n", "# back to normal relation embs, +1 for the padding relation", "\n", "self", ".", "relation_embedding", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "nrelation", ",", "embedding_dim", "=", "self", ".", "relation_dim", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "\n", "tensor", "=", "self", ".", "relation_embedding", ".", "weight", ",", "\n", "a", "=", "-", "self", ".", "embedding_range", ".", "item", "(", ")", ",", "\n", "b", "=", "self", ".", "embedding_range", ".", "item", "(", ")", "\n", ")", "\n", "\n", "\n", "\n", "# Do not forget to modify this line when you add a new model in the \"forward\" function", "\n", "if", "model_name", "not", "in", "[", "'TransE'", ",", "'DistMult'", ",", "'ComplEx'", ",", "'RotatE'", ",", "'AutoSF'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'model %s not supported'", "%", "model_name", ")", "\n", "\n", "", "if", "model_name", "==", "'RotatE'", "and", "(", "not", "double_entity_embedding", "or", "double_relation_embedding", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'RotatE should use --double_entity_embedding'", ")", "\n", "\n", "", "if", "model_name", "==", "'ComplEx'", "and", "(", "not", "double_entity_embedding", "or", "not", "double_relation_embedding", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'ComplEx should use --double_entity_embedding and --double_relation_embedding'", ")", "\n", "\n", "", "if", "model_name", "==", "'PairRE'", "and", "(", "not", "double_relation_embedding", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'PairRE should use --double_relation_embedding'", ")", "\n", "\n", "", "self", ".", "evaluator", "=", "evaluator", "\n", "\n", "print", "(", "\"Creating hashes\"", ")", "\n", "\n", "hashes", "=", "[", "\n", "[", "tokenizer", ".", "token2id", "[", "token", "]", "for", "token", "in", "vals", "[", "'ancs'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "]", "]", "+", "[", "\n", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "d", "for", "d", "in", "vals", "[", "'dists'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "]", "]", "+", "[", "0", "]", "*", "(", "\n", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "d", "for", "row", "in", "distances", "for", "d", "in", "row", "]", ")", "\n", "print", "(", "\n", "f\"Changed max seq len from {max_seq_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "tensor", "(", "distances", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "print", "(", "\"Creating relational context\"", ")", "\n", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "pad_idx", "=", "nrelation", "-", "1", "\n", "e2r", "=", "defaultdict", "(", "set", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "triples", "[", "'head'", "]", ")", ")", ")", ":", "\n", "                ", "e2r", "[", "self", ".", "triples", "[", "'head'", "]", "[", "i", "]", "]", ".", "add", "(", "self", ".", "triples", "[", "'relation'", "]", "[", "i", "]", ")", "\n", "\n", "", "len_stats", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "e2r", ".", "items", "(", ")", "]", "\n", "print", "(", "f\"Unique relations per node - min: {min(len_stats)}, avg: {np.mean(len_stats)}, 66th perc: {np.percentile(len_stats, 66)}, max: {max(len_stats)} \"", ")", "\n", "unique_1hop_relations", "=", "[", "\n", "random", ".", "sample", "(", "e2r", "[", "i", "]", ",", "k", "=", "min", "(", "self", ".", "sample_rels", ",", "len", "(", "e2r", "[", "i", "]", ")", ")", ")", "+", "[", "pad_idx", "]", "*", "(", "self", ".", "sample_rels", "-", "min", "(", "len", "(", "e2r", "[", "i", "]", ")", ",", "self", ".", "sample_rels", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "nentity", ")", "\n", "]", "\n", "self", ".", "unique_1hop_relations", "=", "torch", ".", "tensor", "(", "unique_1hop_relations", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "# distance integer to denote path lengths", "\n", "", "self", ".", "dist_emb", "=", "nn", ".", "Embedding", "(", "self", ".", "max_seq_len", "+", "1", ",", "embedding_dim", "=", "self", ".", "entity_dim", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dist_emb", ".", "weight", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "anchor_embeddings", ".", "weight", "[", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "=", "torch", ".", "zeros", "(", "self", ".", "entity_dim", ")", "\n", "self", ".", "relation_embedding", ".", "weight", ".", "data", "[", "-", "1", "]", "=", "torch", ".", "zeros", "(", "self", ".", "relation_dim", ")", "\n", "self", ".", "dist_emb", ".", "weight", "[", "0", "]", "=", "torch", ".", "zeros", "(", "self", ".", "entity_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.pool_anchors": [[159, 176], ["model.KGEModel.set_enc", "anc_embs.view.view.view", "model.KGEModel.set_enc", "model.KGEModel.set_enc", "model.KGEModel.mean", "anc_embs.view.view.transpose", "model.KGEModel.linear"], "methods", ["None"], ["", "", "def", "pool_anchors", "(", "self", ",", "anc_embs", ":", "torch", ".", "FloatTensor", ",", "mask", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        input shape: (bs, num_anchors, emb_dim)\n        output shape: (bs, emb_dim)\n        \"\"\"", "\n", "if", "self", ".", "pooler", "==", "\"set\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "anc_embs", "=", "anc_embs", ".", "view", "(", "anc_embs", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "if", "self", ".", "sample_paths", "!=", "1", "else", "anc_embs", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", "or", "self", ".", "pooler", "==", "\"moe\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ".", "transpose", "(", "1", ",", "0", ")", ")", "# output shape: (seq_len, bs, dim)", "\n", "pooled", "=", "pooled", ".", "mean", "(", "dim", "=", "0", ")", "# output shape: (bs, dim)", "\n", "if", "self", ".", "policy", "==", "\"cat\"", ":", "\n", "                ", "pooled", "=", "self", ".", "linear", "(", "pooled", ")", "\n", "\n", "", "", "return", "pooled", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.encode_by_index": [[178, 198], ["model.KGEModel.anchor_embeddings", "model.KGEModel.pool_anchors", "model.KGEModel.dist_emb", "model.KGEModel.relation_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors"], ["", "def", "encode_by_index", "(", "self", ",", "entities", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "        ", "hashes", ",", "dists", "=", "self", ".", "hashes", "[", "entities", "]", ",", "self", ".", "distances", "[", "entities", "]", "\n", "\n", "#anc_embs = torch.index_select(self.anchor_embeddings, dim=0, index=hashes)", "\n", "anc_embs", "=", "self", ".", "anchor_embeddings", "(", "hashes", ")", "\n", "mask", "=", "None", "\n", "\n", "if", "self", ".", "use_distances", ":", "\n", "            ", "dist_embs", "=", "self", ".", "dist_emb", "(", "dists", ")", "\n", "anc_embs", "+=", "dist_embs", "\n", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "rels", "=", "self", ".", "unique_1hop_relations", "[", "entities", "]", "# (bs, rel_sample_size)", "\n", "#rels = torch.index_select(self.relation_embedding, dim=0, index=rels)   # (bs, rel_sample_size, dim)", "\n", "rels", "=", "self", ".", "relation_embedding", "(", "rels", ")", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "rels", "]", ",", "dim", "=", "1", ")", "# (bs, ancs+rel_sample_size, dim)", "\n", "\n", "", "anc_embs", "=", "self", ".", "pool_anchors", "(", "anc_embs", ",", "mask", "=", "mask", ")", "\n", "return", "anc_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.forward": [[200, 273], ["model.KGEModel.encode_by_index().unsqueeze", "model.KGEModel.relation_embedding().unsqueeze", "model.KGEModel.encode_by_index().unsqueeze", "ValueError", "sample.size", "model.KGEModel.encode_by_index().view", "model.KGEModel.relation_embedding().unsqueeze", "model.KGEModel.encode_by_index().unsqueeze", "model.KGEModel.encode_by_index", "model.KGEModel.relation_embedding", "model.KGEModel.encode_by_index", "head_part.size", "head_part.size", "model.KGEModel.encode_by_index().unsqueeze", "model.KGEModel.relation_embedding().unsqueeze", "model.KGEModel.encode_by_index().view", "ValueError", "model.KGEModel.encode_by_index", "model.KGEModel.relation_embedding", "model.KGEModel.encode_by_index", "tail_part.size", "tail_part.size", "head_part.view", "model.KGEModel.encode_by_index", "model.KGEModel.relation_embedding", "model.KGEModel.encode_by_index", "tail_part.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], ["", "def", "forward", "(", "self", ",", "sample", ",", "mode", "=", "'single'", ")", ":", "\n", "        ", "'''\n        Forward function that calculate the score of a batch of triples.\n        In the 'single' mode, sample is a batch of triple.\n        In the 'head-batch' or 'tail-batch' mode, sample consists two part.\n        The first part is usually the positive sample.\n        And the second part is the entities in the negative samples.\n        Because negative samples and positive samples usually share two elements\n        in their triple ((head, relation) or (relation, tail)).\n        '''", "\n", "\n", "if", "mode", "==", "'single'", ":", "\n", "            ", "batch_size", ",", "negative_sample_size", "=", "sample", ".", "size", "(", "0", ")", ",", "1", "\n", "\n", "head", "=", "self", ".", "encode_by_index", "(", "sample", "[", ":", ",", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "relation", "=", "self", ".", "relation_embedding", "(", "sample", "[", ":", ",", "1", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# relation = torch.index_select(", "\n", "#     self.relation_embedding,", "\n", "#     dim=0,", "\n", "#     index=sample[:, 1]", "\n", "# ).unsqueeze(1)", "\n", "\n", "tail", "=", "self", ".", "encode_by_index", "(", "sample", "[", ":", ",", "2", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "mode", "==", "'head-batch'", ":", "\n", "            ", "tail_part", ",", "head_part", "=", "sample", "\n", "batch_size", ",", "negative_sample_size", "=", "head_part", ".", "size", "(", "0", ")", ",", "head_part", ".", "size", "(", "1", ")", "\n", "\n", "head", "=", "self", ".", "encode_by_index", "(", "head_part", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "batch_size", ",", "negative_sample_size", ",", "-", "1", ")", "\n", "\n", "relation", "=", "self", ".", "relation_embedding", "(", "tail_part", "[", ":", ",", "1", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# relation = torch.index_select(", "\n", "#     self.relation_embedding,", "\n", "#     dim=0,", "\n", "#     index=tail_part[:, 1]", "\n", "# ).unsqueeze(1)", "\n", "\n", "tail", "=", "self", ".", "encode_by_index", "(", "tail_part", "[", ":", ",", "2", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "mode", "==", "'tail-batch'", ":", "\n", "            ", "head_part", ",", "tail_part", "=", "sample", "\n", "batch_size", ",", "negative_sample_size", "=", "tail_part", ".", "size", "(", "0", ")", ",", "tail_part", ".", "size", "(", "1", ")", "\n", "\n", "head", "=", "self", ".", "encode_by_index", "(", "head_part", "[", ":", ",", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "relation", "=", "self", ".", "relation_embedding", "(", "head_part", "[", ":", ",", "1", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# relation = torch.index_select(", "\n", "#     self.relation_embedding,", "\n", "#     dim=0,", "\n", "#     index=head_part[:, 1]", "\n", "# ).unsqueeze(1)", "\n", "\n", "tail", "=", "self", ".", "encode_by_index", "(", "tail_part", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "batch_size", ",", "negative_sample_size", ",", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'mode %s not supported'", "%", "mode", ")", "\n", "\n", "", "model_func", "=", "{", "\n", "'TransE'", ":", "self", ".", "TransE", ",", "\n", "'DistMult'", ":", "self", ".", "DistMult", ",", "\n", "'ComplEx'", ":", "self", ".", "ComplEx", ",", "\n", "'RotatE'", ":", "self", ".", "RotatE", ",", "\n", "'AutoSF'", ":", "self", ".", "AutoSF", ",", "\n", "'PairRE'", ":", "self", ".", "PairRE", ",", "\n", "}", "\n", "\n", "if", "self", ".", "model_name", "in", "model_func", ":", "\n", "            ", "score", "=", "model_func", "[", "self", ".", "model_name", "]", "(", "head", ",", "relation", ",", "tail", ",", "mode", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'model %s not supported'", "%", "self", ".", "model_name", ")", "\n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.AutoSF": [[274, 297], ["torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "AutoSF", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'head-batch'", ":", "\n", "            ", "rs", "=", "torch", ".", "chunk", "(", "relation", ",", "4", ",", "dim", "=", "-", "1", ")", "\n", "ts", "=", "torch", ".", "chunk", "(", "tail", ",", "4", ",", "dim", "=", "-", "1", ")", "\n", "rt0", "=", "rs", "[", "0", "]", "*", "ts", "[", "0", "]", "\n", "rt1", "=", "rs", "[", "1", "]", "*", "ts", "[", "1", "]", "+", "rs", "[", "2", "]", "*", "ts", "[", "3", "]", "\n", "rt2", "=", "rs", "[", "0", "]", "*", "ts", "[", "2", "]", "+", "rs", "[", "2", "]", "*", "ts", "[", "3", "]", "\n", "rt3", "=", "-", "rs", "[", "1", "]", "*", "ts", "[", "1", "]", "+", "rs", "[", "3", "]", "*", "ts", "[", "2", "]", "\n", "rts", "=", "torch", ".", "cat", "(", "[", "rt0", ",", "rt1", ",", "rt2", ",", "rt3", "]", ",", "dim", "=", "-", "1", ")", "\n", "score", "=", "torch", ".", "sum", "(", "head", "*", "rts", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "hs", "=", "torch", ".", "chunk", "(", "head", ",", "4", ",", "dim", "=", "-", "1", ")", "\n", "rs", "=", "torch", ".", "chunk", "(", "relation", ",", "4", ",", "dim", "=", "-", "1", ")", "\n", "hr0", "=", "hs", "[", "0", "]", "*", "rs", "[", "0", "]", "\n", "hr1", "=", "hs", "[", "1", "]", "*", "rs", "[", "1", "]", "-", "hs", "[", "3", "]", "*", "rs", "[", "1", "]", "\n", "hr2", "=", "hs", "[", "2", "]", "*", "rs", "[", "0", "]", "+", "hs", "[", "3", "]", "*", "rs", "[", "3", "]", "\n", "hr3", "=", "hs", "[", "1", "]", "*", "rs", "[", "2", "]", "+", "hs", "[", "2", "]", "*", "rs", "[", "2", "]", "\n", "hrs", "=", "torch", ".", "cat", "(", "[", "hr0", ",", "hr1", ",", "hr2", ",", "hr3", "]", ",", "dim", "=", "-", "1", ")", "\n", "score", "=", "torch", ".", "sum", "(", "hrs", "*", "tail", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.PairRE": [[298, 307], ["torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "model.KGEModel.gamma.item", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize"], ["", "def", "PairRE", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "        ", "re_head", ",", "re_tail", "=", "torch", ".", "chunk", "(", "relation", ",", "2", ",", "dim", "=", "2", ")", "\n", "\n", "head", "=", "F", ".", "normalize", "(", "head", ",", "2", ",", "-", "1", ")", "\n", "tail", "=", "F", ".", "normalize", "(", "tail", ",", "2", ",", "-", "1", ")", "\n", "\n", "score", "=", "head", "*", "re_head", "-", "tail", "*", "re_tail", "\n", "score", "=", "self", ".", "gamma", ".", "item", "(", ")", "-", "torch", ".", "norm", "(", "score", ",", "p", "=", "1", ",", "dim", "=", "2", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.TransE": [[308, 316], ["model.KGEModel.gamma.item", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "TransE", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "'head-batch'", ":", "\n", "            ", "score", "=", "head", "+", "(", "relation", "-", "tail", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "(", "head", "+", "relation", ")", "-", "tail", "\n", "\n", "", "score", "=", "self", ".", "gamma", ".", "item", "(", ")", "-", "torch", ".", "norm", "(", "score", ",", "p", "=", "1", ",", "dim", "=", "2", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.DistMult": [[317, 325], ["score.sum.sum.sum"], "methods", ["None"], ["", "def", "DistMult", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "'head-batch'", ":", "\n", "            ", "score", "=", "head", "*", "(", "relation", "*", "tail", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "(", "head", "*", "relation", ")", "*", "tail", "\n", "\n", "", "score", "=", "score", ".", "sum", "(", "dim", "=", "2", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.ComplEx": [[326, 342], ["torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "score.sum.sum.sum"], "methods", ["None"], ["", "def", "ComplEx", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "        ", "re_head", ",", "im_head", "=", "torch", ".", "chunk", "(", "head", ",", "2", ",", "dim", "=", "2", ")", "\n", "re_relation", ",", "im_relation", "=", "torch", ".", "chunk", "(", "relation", ",", "2", ",", "dim", "=", "2", ")", "\n", "re_tail", ",", "im_tail", "=", "torch", ".", "chunk", "(", "tail", ",", "2", ",", "dim", "=", "2", ")", "\n", "\n", "if", "mode", "==", "'head-batch'", ":", "\n", "            ", "re_score", "=", "re_relation", "*", "re_tail", "+", "im_relation", "*", "im_tail", "\n", "im_score", "=", "re_relation", "*", "im_tail", "-", "im_relation", "*", "re_tail", "\n", "score", "=", "re_head", "*", "re_score", "+", "im_head", "*", "im_score", "\n", "", "else", ":", "\n", "            ", "re_score", "=", "re_head", "*", "re_relation", "-", "im_head", "*", "im_relation", "\n", "im_score", "=", "re_head", "*", "im_relation", "+", "im_head", "*", "re_relation", "\n", "score", "=", "re_score", "*", "re_tail", "+", "im_score", "*", "im_tail", "\n", "\n", "", "score", "=", "score", ".", "sum", "(", "dim", "=", "2", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.RotatE": [[343, 372], ["torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "score.norm.norm.norm", "model.KGEModel.gamma.item", "score.norm.norm.sum", "model.KGEModel.embedding_range.item"], "methods", ["None"], ["", "def", "RotatE", "(", "self", ",", "head", ",", "relation", ",", "tail", ",", "mode", ")", ":", "\n", "        ", "pi", "=", "3.14159265358979323846", "\n", "\n", "re_head", ",", "im_head", "=", "torch", ".", "chunk", "(", "head", ",", "2", ",", "dim", "=", "2", ")", "\n", "re_tail", ",", "im_tail", "=", "torch", ".", "chunk", "(", "tail", ",", "2", ",", "dim", "=", "2", ")", "\n", "\n", "# Make phases of relations uniformly distributed in [-pi, pi]", "\n", "\n", "phase_relation", "=", "relation", "/", "(", "self", ".", "embedding_range", ".", "item", "(", ")", "/", "pi", ")", "\n", "\n", "re_relation", "=", "torch", ".", "cos", "(", "phase_relation", ")", "\n", "im_relation", "=", "torch", ".", "sin", "(", "phase_relation", ")", "\n", "\n", "if", "mode", "==", "'head-batch'", ":", "\n", "            ", "re_score", "=", "re_relation", "*", "re_tail", "+", "im_relation", "*", "im_tail", "\n", "im_score", "=", "re_relation", "*", "im_tail", "-", "im_relation", "*", "re_tail", "\n", "re_score", "=", "re_score", "-", "re_head", "\n", "im_score", "=", "im_score", "-", "im_head", "\n", "", "else", ":", "\n", "            ", "re_score", "=", "re_head", "*", "re_relation", "-", "im_head", "*", "im_relation", "\n", "im_score", "=", "re_head", "*", "im_relation", "+", "im_head", "*", "re_relation", "\n", "re_score", "=", "re_score", "-", "re_tail", "\n", "im_score", "=", "im_score", "-", "im_tail", "\n", "\n", "", "score", "=", "torch", ".", "stack", "(", "[", "re_score", ",", "im_score", "]", ",", "dim", "=", "0", ")", "\n", "score", "=", "score", ".", "norm", "(", "dim", "=", "0", ")", "\n", "\n", "score", "=", "self", ".", "gamma", ".", "item", "(", ")", "-", "score", ".", "sum", "(", "dim", "=", "2", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.train_step": [[373, 431], ["model.train", "optimizer.zero_grad", "next", "model", "model", "torch.logsigmoid().squeeze", "torch.logsigmoid().squeeze", "torch.logsigmoid().squeeze", "loss.backward", "optimizer.step", "positive_sample.cuda.cuda.cuda", "negative_sample.cuda.cuda.cuda", "subsampling_weight.cuda.cuda.cuda", "torch.logsigmoid().mean", "torch.logsigmoid().mean", "torch.logsigmoid().mean", "positive_sample_loss.item", "negative_sample_loss.item", "loss.item", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid().squeeze.mean", "torch.logsigmoid().mean.mean", "subsampling_weight.cuda.cuda.sum", "subsampling_weight.cuda.cuda.sum", "regularization.item", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.logsigmoid", "torch.logsigmoid", "torch.logsigmoid", "model.entity_embedding.norm", "model.relation_embedding.norm().norm", "torch.softmax", "torch.softmax", "torch.softmax", "model.relation_embedding.norm"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax"], ["", "@", "staticmethod", "\n", "def", "train_step", "(", "model", ",", "optimizer", ",", "train_iterator", ",", "args", ")", ":", "\n", "        ", "'''\n        A single train step. Apply back-propation and return the loss\n        '''", "\n", "\n", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "positive_sample", ",", "negative_sample", ",", "subsampling_weight", ",", "mode", "=", "next", "(", "train_iterator", ")", "\n", "\n", "if", "args", ".", "cuda", ":", "\n", "            ", "positive_sample", "=", "positive_sample", ".", "cuda", "(", ")", "\n", "negative_sample", "=", "negative_sample", ".", "cuda", "(", ")", "\n", "subsampling_weight", "=", "subsampling_weight", ".", "cuda", "(", ")", "\n", "\n", "", "negative_score", "=", "model", "(", "(", "positive_sample", ",", "negative_sample", ")", ",", "mode", "=", "mode", ")", "\n", "if", "args", ".", "negative_adversarial_sampling", ":", "\n", "# In self-adversarial sampling, we do not apply back-propagation on the sampling weight", "\n", "            ", "negative_score", "=", "(", "F", ".", "softmax", "(", "negative_score", "*", "args", ".", "adversarial_temperature", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "*", "F", ".", "logsigmoid", "(", "-", "negative_score", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "negative_score", "=", "F", ".", "logsigmoid", "(", "-", "negative_score", ")", ".", "mean", "(", "dim", "=", "1", ")", "\n", "\n", "", "positive_score", "=", "model", "(", "positive_sample", ")", "\n", "positive_score", "=", "F", ".", "logsigmoid", "(", "positive_score", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n", "if", "args", ".", "uni_weight", ":", "\n", "            ", "positive_sample_loss", "=", "-", "positive_score", ".", "mean", "(", ")", "\n", "negative_sample_loss", "=", "-", "negative_score", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "            ", "positive_sample_loss", "=", "-", "(", "subsampling_weight", "*", "positive_score", ")", ".", "sum", "(", ")", "/", "subsampling_weight", ".", "sum", "(", ")", "\n", "negative_sample_loss", "=", "-", "(", "subsampling_weight", "*", "negative_score", ")", ".", "sum", "(", ")", "/", "subsampling_weight", ".", "sum", "(", ")", "\n", "\n", "", "loss", "=", "(", "positive_sample_loss", "+", "negative_sample_loss", ")", "/", "2", "\n", "\n", "if", "args", ".", "regularization", "!=", "0.0", ":", "\n", "# Use L3 regularization for ComplEx and DistMult", "\n", "            ", "regularization", "=", "args", ".", "regularization", "*", "(", "\n", "model", ".", "entity_embedding", ".", "norm", "(", "p", "=", "3", ")", "**", "3", "+", "\n", "model", ".", "relation_embedding", ".", "norm", "(", "p", "=", "3", ")", ".", "norm", "(", "p", "=", "3", ")", "**", "3", "\n", ")", "\n", "loss", "=", "loss", "+", "regularization", "\n", "regularization_log", "=", "{", "'regularization'", ":", "regularization", ".", "item", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "regularization_log", "=", "{", "}", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "log", "=", "{", "\n", "**", "regularization_log", ",", "\n", "'positive_sample_loss'", ":", "positive_sample_loss", ".", "item", "(", ")", ",", "\n", "'negative_sample_loss'", ":", "negative_sample_loss", ".", "item", "(", ")", ",", "\n", "'loss'", ":", "loss", ".", "item", "(", ")", "\n", "}", "\n", "\n", "return", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.model.KGEModel.test_step": [[432, 497], ["model.eval", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "collections.defaultdict", "sum", "ogb_wikikg2.dataloader.TestDataset", "ogb_wikikg2.dataloader.TestDataset", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "max", "len", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "torch.cat().mean().item", "positive_sample.cuda.cuda.size", "model", "model.evaluator.eval", "positive_sample.cuda.cuda.cuda", "negative_sample.cuda.cuda.cuda", "test_logs[].append", "logging.info", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_step", "(", "model", ",", "test_triples", ",", "args", ",", "random_sampling", "=", "False", ")", ":", "\n", "        ", "'''\n        Evaluate the model on test or valid datasets\n        '''", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Prepare dataloader for evaluation", "\n", "test_dataloader_head", "=", "DataLoader", "(", "\n", "TestDataset", "(", "\n", "test_triples", ",", "\n", "args", ",", "\n", "'head-batch'", ",", "\n", "random_sampling", "\n", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "\n", "num_workers", "=", "max", "(", "1", ",", "args", ".", "cpu_num", "//", "2", ")", ",", "\n", "collate_fn", "=", "TestDataset", ".", "collate_fn", "\n", ")", "\n", "\n", "test_dataloader_tail", "=", "DataLoader", "(", "\n", "TestDataset", "(", "\n", "test_triples", ",", "\n", "args", ",", "\n", "'tail-batch'", ",", "\n", "random_sampling", "\n", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "\n", "num_workers", "=", "max", "(", "1", ",", "args", ".", "cpu_num", "//", "2", ")", ",", "\n", "collate_fn", "=", "TestDataset", ".", "collate_fn", "\n", ")", "\n", "\n", "test_dataset_list", "=", "[", "test_dataloader_head", ",", "test_dataloader_tail", "]", "\n", "\n", "test_logs", "=", "defaultdict", "(", "list", ")", "\n", "\n", "step", "=", "0", "\n", "total_steps", "=", "sum", "(", "[", "len", "(", "dataset", ")", "for", "dataset", "in", "test_dataset_list", "]", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "test_dataset", "in", "test_dataset_list", ":", "\n", "                ", "for", "positive_sample", ",", "negative_sample", ",", "mode", "in", "test_dataset", ":", "\n", "                    ", "if", "args", ".", "cuda", ":", "\n", "                        ", "positive_sample", "=", "positive_sample", ".", "cuda", "(", ")", "\n", "negative_sample", "=", "negative_sample", ".", "cuda", "(", ")", "\n", "\n", "", "batch_size", "=", "positive_sample", ".", "size", "(", "0", ")", "\n", "score", "=", "model", "(", "(", "positive_sample", ",", "negative_sample", ")", ",", "mode", ")", "\n", "\n", "batch_results", "=", "model", ".", "evaluator", ".", "eval", "(", "{", "'y_pred_pos'", ":", "score", "[", ":", ",", "0", "]", ",", "\n", "'y_pred_neg'", ":", "score", "[", ":", ",", "1", ":", "]", "}", ")", "\n", "for", "metric", "in", "batch_results", ":", "\n", "                        ", "test_logs", "[", "metric", "]", ".", "append", "(", "batch_results", "[", "metric", "]", ")", "\n", "\n", "", "if", "step", "%", "args", ".", "test_log_steps", "==", "0", ":", "\n", "                        ", "logging", ".", "info", "(", "'Evaluating the model... (%d/%d)'", "%", "(", "step", ",", "total_steps", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "", "metrics", "=", "{", "}", "\n", "for", "metric", "in", "test_logs", ":", "\n", "                ", "metrics", "[", "metric", "]", "=", "torch", ".", "cat", "(", "test_logs", "[", "metric", "]", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "return", "metrics", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TrainDataset.__init__": [[12, 22], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "triples", ",", "nentity", ",", "nrelation", ",", "negative_sample_size", ",", "mode", ",", "count", ",", "true_head", ",", "true_tail", ")", ":", "\n", "        ", "self", ".", "len", "=", "len", "(", "triples", "[", "'head'", "]", ")", "\n", "self", ".", "triples", "=", "triples", "\n", "self", ".", "nentity", "=", "nentity", "\n", "self", ".", "nrelation", "=", "nrelation", "\n", "self", ".", "negative_sample_size", "=", "negative_sample_size", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "count", "=", "count", "\n", "self", ".", "true_head", "=", "true_head", "\n", "self", ".", "true_tail", "=", "true_tail", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TrainDataset.__len__": [[23, 25], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TrainDataset.__getitem__": [[26, 66], ["torch.sqrt", "torch.randint", "torch.LongTensor", "torch.Tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "head", ",", "relation", ",", "tail", "=", "self", ".", "triples", "[", "'head'", "]", "[", "idx", "]", ",", "self", ".", "triples", "[", "'relation'", "]", "[", "idx", "]", ",", "self", ".", "triples", "[", "'tail'", "]", "[", "idx", "]", "\n", "positive_sample", "=", "[", "head", ",", "relation", ",", "tail", "]", "\n", "\n", "subsampling_weight", "=", "self", ".", "count", "[", "(", "head", ",", "relation", ")", "]", "+", "self", ".", "count", "[", "(", "tail", ",", "-", "relation", "-", "1", ")", "]", "\n", "subsampling_weight", "=", "torch", ".", "sqrt", "(", "1", "/", "torch", ".", "Tensor", "(", "[", "subsampling_weight", "]", ")", ")", "\n", "\n", "# negative_sample_list = []", "\n", "# negative_sample_size = 0", "\n", "\n", "# while negative_sample_size < self.negative_sample_size:", "\n", "#     negative_sample = np.random.randint(self.nentity, size=self.negative_sample_size*2)", "\n", "#     if self.mode == 'head-batch':", "\n", "#         mask = np.in1d(", "\n", "#             negative_sample,", "\n", "#             self.true_head[(relation, tail)],", "\n", "#             assume_unique=True,", "\n", "#             invert=True", "\n", "#         )", "\n", "#     elif self.mode == 'tail-batch':", "\n", "#         mask = np.in1d(", "\n", "#             negative_sample,", "\n", "#             self.true_tail[(head, relation)],", "\n", "#             assume_unique=True,", "\n", "#             invert=True", "\n", "#         )", "\n", "#     else:", "\n", "#         raise ValueError('Training batch mode %s not supported' % self.mode)", "\n", "#     negative_sample = negative_sample[mask]", "\n", "#     negative_sample_list.append(negative_sample)", "\n", "#     negative_sample_size += negative_sample.size", "\n", "\n", "# negative_sample = np.concatenate(negative_sample_list)[:self.negative_sample_size]", "\n", "\n", "# negative_sample = torch.from_numpy(negative_sample)", "\n", "# negative_sample = torch.from_numpy(np.random.randint(self.nentity, size=self.negative_sample_size))", "\n", "negative_sample", "=", "torch", ".", "randint", "(", "0", ",", "self", ".", "nentity", ",", "(", "self", ".", "negative_sample_size", ",", ")", ")", "\n", "positive_sample", "=", "torch", ".", "LongTensor", "(", "positive_sample", ")", "\n", "\n", "return", "positive_sample", ",", "negative_sample", ",", "subsampling_weight", ",", "self", ".", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TrainDataset.collate_fn": [[67, 74], ["torch.stack", "torch.stack", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "positive_sample", "=", "torch", ".", "stack", "(", "[", "_", "[", "0", "]", "for", "_", "in", "data", "]", ",", "dim", "=", "0", ")", "\n", "negative_sample", "=", "torch", ".", "stack", "(", "[", "_", "[", "1", "]", "for", "_", "in", "data", "]", ",", "dim", "=", "0", ")", "\n", "subsample_weight", "=", "torch", ".", "cat", "(", "[", "_", "[", "2", "]", "for", "_", "in", "data", "]", ",", "dim", "=", "0", ")", "\n", "mode", "=", "data", "[", "0", "]", "[", "3", "]", "\n", "return", "positive_sample", ",", "negative_sample", ",", "subsample_weight", ",", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TestDataset.__init__": [[77, 86], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "triples", ",", "args", ",", "mode", ",", "random_sampling", ")", ":", "\n", "        ", "self", ".", "len", "=", "len", "(", "triples", "[", "'head'", "]", ")", "\n", "self", ".", "triples", "=", "triples", "\n", "self", ".", "nentity", "=", "args", ".", "nentity", "\n", "self", ".", "nrelation", "=", "args", ".", "nrelation", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "random_sampling", "=", "random_sampling", "\n", "if", "random_sampling", ":", "\n", "            ", "self", ".", "neg_size", "=", "args", ".", "neg_size_eval_train", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TestDataset.__len__": [[87, 89], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TestDataset.__getitem__": [[90, 108], ["torch.LongTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor", "torch.from_numpy", "torch.LongTensor", "torch.randint", "torch.LongTensor", "torch.from_numpy", "torch.LongTensor", "torch.randint"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "head", ",", "relation", ",", "tail", "=", "self", ".", "triples", "[", "'head'", "]", "[", "idx", "]", ",", "self", ".", "triples", "[", "'relation'", "]", "[", "idx", "]", ",", "self", ".", "triples", "[", "'tail'", "]", "[", "idx", "]", "\n", "positive_sample", "=", "torch", ".", "LongTensor", "(", "(", "head", ",", "relation", ",", "tail", ")", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'head-batch'", ":", "\n", "            ", "if", "not", "self", ".", "random_sampling", ":", "\n", "                ", "negative_sample", "=", "torch", ".", "cat", "(", "[", "torch", ".", "LongTensor", "(", "[", "head", "]", ")", ",", "torch", ".", "from_numpy", "(", "self", ".", "triples", "[", "'head_neg'", "]", "[", "idx", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "negative_sample", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "LongTensor", "(", "[", "head", "]", ")", ",", "torch", ".", "randint", "(", "0", ",", "self", ".", "nentity", ",", "size", "=", "(", "self", ".", "neg_size", ",", ")", ")", "]", ")", "\n", "", "", "elif", "self", ".", "mode", "==", "'tail-batch'", ":", "\n", "            ", "if", "not", "self", ".", "random_sampling", ":", "\n", "                ", "negative_sample", "=", "torch", ".", "cat", "(", "[", "torch", ".", "LongTensor", "(", "[", "tail", "]", ")", ",", "torch", ".", "from_numpy", "(", "self", ".", "triples", "[", "'tail_neg'", "]", "[", "idx", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "negative_sample", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "LongTensor", "(", "[", "tail", "]", ")", ",", "torch", ".", "randint", "(", "0", ",", "self", ".", "nentity", ",", "size", "=", "(", "self", ".", "neg_size", ",", ")", ")", "]", ")", "\n", "\n", "", "", "return", "positive_sample", ",", "negative_sample", ",", "self", ".", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.TestDataset.collate_fn": [[109, 116], ["torch.stack", "torch.stack"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "data", ")", ":", "\n", "        ", "positive_sample", "=", "torch", ".", "stack", "(", "[", "_", "[", "0", "]", "for", "_", "in", "data", "]", ",", "dim", "=", "0", ")", "\n", "negative_sample", "=", "torch", ".", "stack", "(", "[", "_", "[", "1", "]", "for", "_", "in", "data", "]", ",", "dim", "=", "0", ")", "\n", "mode", "=", "data", "[", "0", "]", "[", "2", "]", "\n", "\n", "return", "positive_sample", ",", "negative_sample", ",", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.BidirectionalOneShotIterator.__init__": [[119, 123], ["dataloader.BidirectionalOneShotIterator.one_shot_iterator", "dataloader.BidirectionalOneShotIterator.one_shot_iterator"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.BidirectionalOneShotIterator.one_shot_iterator", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.BidirectionalOneShotIterator.one_shot_iterator"], ["    ", "def", "__init__", "(", "self", ",", "dataloader_head", ",", "dataloader_tail", ")", ":", "\n", "        ", "self", ".", "iterator_head", "=", "self", ".", "one_shot_iterator", "(", "dataloader_head", ")", "\n", "self", ".", "iterator_tail", "=", "self", ".", "one_shot_iterator", "(", "dataloader_tail", ")", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.BidirectionalOneShotIterator.__next__": [[124, 131], ["next", "next"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "step", "+=", "1", "\n", "if", "self", ".", "step", "%", "2", "==", "0", ":", "\n", "            ", "data", "=", "next", "(", "self", ".", "iterator_head", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "next", "(", "self", ".", "iterator_tail", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb_wikikg2.dataloader.BidirectionalOneShotIterator.one_shot_iterator": [[132, 140], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "one_shot_iterator", "(", "dataloader", ")", ":", "\n", "        ", "'''\n        Transform a PyTorch Dataloader into python iterator\n        '''", "\n", "while", "True", ":", "\n", "            ", "for", "data", "in", "dataloader", ":", "\n", "                ", "yield", "data", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.nc.models_nc.StarE_PyG_NC.__init__": [[16, 30], ["models.gnn_encoder.StarE_PyG_Encoder.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "dict", ",", "tokenizer", ":", "NodePiece_Tokenizer", "=", "None", ",", "graph", ":", "Data", "=", "None", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "config", ",", "tokenizer", "=", "tokenizer", ",", "graph", "=", "graph", ")", "\n", "\n", "self", ".", "model_name", "=", "'StarE_PyG'", "\n", "self", ".", "hid_drop2", "=", "config", "[", "'STAREARGS'", "]", "[", "'HID_DROP2'", "]", "\n", "self", ".", "feat_drop", "=", "config", "[", "'STAREARGS'", "]", "[", "'FEAT_DROP'", "]", "\n", "self", ".", "hidden_dim", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "\n", "self", ".", "num_classes", "=", "config", "[", "'NUM_CLASSES'", "]", "\n", "\n", "self", ".", "hidden_drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "hid_drop", ")", "\n", "self", ".", "hidden_drop2", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "hid_drop2", ")", "\n", "self", ".", "feature_drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "feat_drop", ")", "\n", "\n", "self", ".", "to_classes", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.nc.models_nc.StarE_PyG_NC.reset_parameters": [[31, 34], ["super().reset_parameters", "models_nc.StarE_PyG_NC.to_classes.apply"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", "StarE_PyG_NC", ",", "self", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "to_classes", ".", "apply", "(", "weight_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.nc.models_nc.StarE_PyG_NC.forward": [[35, 47], ["models_nc.StarE_PyG_NC.forward_base", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "models_nc.StarE_PyG_NC.hidden_drop2", "models_nc.StarE_PyG_NC.to_classes"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.comp_gcn.StarE_PyG_Encoder.forward_base"], ["", "def", "forward", "(", "self", ",", "graph", ",", "train_mask", ")", ":", "\n", "        ", "'''\n        :param graph: pyg data object\n        :param train_mask: nodes for classification\n        :return: class probabilities (logits)\n        '''", "\n", "all_ent", ",", "rels", "=", "self", ".", "forward_base", "(", "graph", ",", "self", ".", "hidden_drop", ",", "self", ".", "feature_drop", ")", "\n", "nodes", "=", "torch", ".", "index_select", "(", "all_ent", ",", "0", ",", "train_mask", ")", "\n", "\n", "nodes", "=", "self", ".", "hidden_drop2", "(", "nodes", ")", "\n", "probs", "=", "self", ".", "to_classes", "(", "nodes", ")", "\n", "return", "probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.__init__": [[31, 39], ["super().__init__", "inspect.getargspec", "inspect.getargspec"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "aggr", "=", "'add'", ")", ":", "\n", "        ", "super", "(", "MessagePassing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# In the defined message function: get the list of arguments as list of string|", "\n", "# For eg. in r-gcn this will be ['x_j', 'edge_type', 'edge_norm'] (args of message fn)", "\n", "self", ".", "message_args", "=", "inspect", ".", "getargspec", "(", "self", ".", "message", ")", "[", "0", "]", "[", "1", ":", "]", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate": [[40, 72], ["utils_gcn.MessagePassing.message", "utils_gcn.scatter_", "utils_gcn.MessagePassing.update", "tmp.size", "message_args.append", "tmp.size", "message_args.append", "message_args.append"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.message", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.scatter_", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["# Same for update function starting from 3rd argument | first=self, second=out", "\n", "self", ".", "update_args", "=", "inspect", ".", "getargspec", "(", "self", ".", "update", ")", "[", "0", "]", "[", "2", ":", "]", "\n", "\n", "", "def", "propagate", "(", "self", ",", "aggr", ",", "edge_index", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"The initial call to start propagating messages.\n        Takes in an aggregation scheme (:obj:`\"add\"`, :obj:`\"mean\"` or\n        :obj:`\"max\"`), the edge indices, and all additional data which is\n        needed to construct messages and to update node embeddings.\"\"\"", "\n", "\n", "assert", "aggr", "in", "[", "'add'", ",", "'mean'", ",", "'max'", "]", "\n", "kwargs", "[", "'edge_index'", "]", "=", "edge_index", "\n", "\n", "size", "=", "None", "\n", "message_args", "=", "[", "]", "\n", "for", "arg", "in", "self", ".", "message_args", ":", "\n", "            ", "if", "arg", "[", "-", "2", ":", "]", "==", "'_i'", ":", "# If arguments ends with _i then include indic", "\n", "                ", "tmp", "=", "kwargs", "[", "\n", "arg", "[", ":", "-", "2", "]", "]", "# Take the front part of the variable | Mostly it will be 'x',", "\n", "size", "=", "tmp", ".", "size", "(", "0", ")", "\n", "message_args", ".", "append", "(", "tmp", "[", "edge_index", "[", "0", "]", "]", ")", "# Lookup for head entities in edges", "\n", "", "elif", "arg", "[", "-", "2", ":", "]", "==", "'_j'", ":", "\n", "                ", "tmp", "=", "kwargs", "[", "arg", "[", ":", "-", "2", "]", "]", "# tmp = kwargs['x']", "\n", "size", "=", "tmp", ".", "size", "(", "0", ")", "\n", "message_args", ".", "append", "(", "tmp", "[", "edge_index", "[", "1", "]", "]", ")", "# Lookup for tail entities in edges", "\n", "", "else", ":", "\n", "                ", "message_args", ".", "append", "(", "kwargs", "[", "arg", "]", ")", "# Take things from kwargs", "\n", "\n", "", "", "update_args", "=", "[", "kwargs", "[", "arg", "]", "for", "arg", "in", "self", ".", "update_args", "]", "# Take update args from kwargs", "\n", "\n", "out", "=", "self", ".", "message", "(", "*", "message_args", ")", "\n", "out", "=", "scatter_", "(", "aggr", ",", "out", ",", "edge_index", "[", "0", "]", ",", "\n", "dim_size", "=", "size", ")", "# Aggregated neighbors for each vertex", "\n", "out", "=", "self", ".", "update", "(", "out", ",", "*", "update_args", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.message": [[73, 82], ["None"], "methods", ["None"], ["\n", "return", "out", "\n", "\n", "", "def", "message", "(", "self", ",", "x_j", ")", ":", "# pragma: no cover", "\n", "        ", "r\"\"\"Constructs messages in analogy to :math:`\\phi_{\\mathbf{\\Theta}}`\n        for each edge in :math:`(i,j) \\in \\mathcal{E}`.\n        Can take any argument which was initially passed to :meth:`propagate`.\n        In addition, features can be lifted to the source node :math:`i` and\n        target node :math:`j` by appending :obj:`_i` or :obj:`_j` to the\n        variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.update": [[83, 91], ["None"], "methods", ["None"], ["\n", "return", "x_j", "\n", "\n", "", "def", "update", "(", "self", ",", "aggr_out", ")", ":", "# pragma: no cover", "\n", "        ", "r\"\"\"Updates node embeddings in analogy to\n        :math:`\\gamma_{\\mathbf{\\Theta}}` for each node\n        :math:`i \\in \\mathcal{V}`.\n        Takes in the output of aggregation as first argument and any argument\n        which was initially passed to :meth:`propagate`.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.maybe_num_nodes": [[92, 94], ["index.max().item", "index.max"], "function", ["None"], ["\n", "return", "aggr_out", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax": [[95, 118], ["utils_gcn.maybe_num_nodes", "out.exp.exp", "torch_scatter.scatter_max", "torch_scatter.scatter_add"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.maybe_num_nodes"], ["", "", "def", "maybe_num_nodes", "(", "index", ",", "num_nodes", "=", "None", ")", ":", "\n", "    ", "return", "index", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", "if", "num_nodes", "is", "None", "else", "num_nodes", "\n", "\n", "", "def", "softmax", "(", "src", ",", "index", ",", "num_nodes", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Computes a sparsely evaluated softmax.\n    Given a value tensor :attr:`src`, this function first groups the values\n    along the first dimension based on the indices specified in :attr:`index`,\n    and then proceeds to compute the softmax individually for each group.\n\n    Args:\n        src (Tensor): The source tensor.\n        index (LongTensor): The indices of elements for applying the softmax.\n        num_nodes (int, optional): The number of nodes, *i.e.*\n            :obj:`max_val + 1` of :attr:`index`. (default: :obj:`None`)\n\n    :rtype: :class:`Tensor`\n    \"\"\"", "\n", "\n", "num_nodes", "=", "maybe_num_nodes", "(", "index", ",", "num_nodes", ")", "\n", "\n", "out", "=", "src", "-", "scatter_max", "(", "src", ",", "index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_nodes", ")", "[", "0", "]", "[", "index", "]", "\n", "out", "=", "out", ".", "exp", "(", ")", "\n", "out", "=", "out", "/", "(", "\n", "scatter_add", "(", "out", ",", "index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_nodes", ")", "[", "index", "]", "+", "1e-16", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param": [[119, 123], ["torch.nn.Parameter", "torch.nn.init.xavier_normal_", "torch.Tensor"], "function", ["None"], ["\n", "return", "out", "\n", "\n", "", "def", "get_param", "(", "shape", ")", ":", "\n", "    ", "param", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "shape", ")", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.weight_init": [[124, 130], ["type", "torch.nn.init.xavier_normal_", "torch.nn.init.constant_"], "function", ["None"], ["xavier_normal_", "(", "param", ".", "data", ")", "\n", "return", "param", "\n", "\n", "", "def", "weight_init", "(", "layer", ")", ":", "\n", "    ", "if", "type", "(", "layer", ")", "==", "torch", ".", "nn", ".", "Linear", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.com_mult": [[132, 136], ["torch.stack"], "function", ["None"], ["", "", "return", "\n", "\n", "\n", "", "def", "com_mult", "(", "a", ",", "b", ")", ":", "\n", "    ", "r1", ",", "i1", "=", "a", "[", "...", ",", "0", "]", ",", "a", "[", "...", ",", "1", "]", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.conj": [[138, 141], ["None"], "function", ["None"], ["return", "torch", ".", "stack", "(", "[", "r1", "*", "r2", "-", "i1", "*", "i2", ",", "r1", "*", "i2", "+", "i1", "*", "r2", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "\n", "", "def", "conj", "(", "a", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.cconv": [[143, 146], ["torch.irfft", "utils_gcn.com_mult", "torch.rfft", "torch.rfft"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.com_mult"], ["return", "a", "\n", "\n", "\n", "", "def", "cconv", "(", "a", ",", "b", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.ccorr": [[148, 151], ["torch.irfft", "utils_gcn.com_mult", "utils_gcn.conj", "torch.rfft", "torch.rfft"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.com_mult", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.conj"], ["signal_sizes", "=", "(", "a", ".", "shape", "[", "-", "1", "]", ",", ")", ")", "\n", "\n", "\n", "", "def", "ccorr", "(", "a", ",", "b", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.rotate": [[152, 160], ["torch.split", "torch.split", "torch.cat"], "function", ["None"], ["    ", "return", "torch", ".", "irfft", "(", "com_mult", "(", "conj", "(", "torch", ".", "rfft", "(", "a", ",", "1", ")", ")", ",", "torch", ".", "rfft", "(", "b", ",", "1", ")", ")", ",", "1", ",", "\n", "signal_sizes", "=", "(", "a", ".", "shape", "[", "-", "1", "]", ",", ")", ")", "\n", "\n", "", "def", "rotate", "(", "h", ",", "r", ")", ":", "\n", "# re: first half, im: second half", "\n", "# assume embedding dim is the last dimension", "\n", "    ", "d", "=", "h", ".", "shape", "[", "-", "1", "]", "\n", "h_re", ",", "h_im", "=", "torch", ".", "split", "(", "h", ",", "d", "//", "2", ",", "-", "1", ")", "\n", "r_re", ",", "r_im", "=", "torch", ".", "split", "(", "r", ",", "d", "//", "2", ",", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.scatter_": [[162, 193], ["getattr", "getattr.", "isinstance"], "function", ["None"], ["h_re", "*", "r_im", "+", "h_im", "*", "r_re", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "\n", "", "def", "scatter_", "(", "name", ",", "src", ",", "index", ",", "dim_size", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Aggregates all values from the :attr:`src` tensor at the indices\n    specified in the :attr:`index` tensor along the first dimension.\n    If multiple indices reference the same location, their contributions\n    are aggregated according to :attr:`name` (either :obj:`\"add\"`,\n    :obj:`\"mean\"` or :obj:`\"max\"`).\n\n    Args:\n        name (string): The aggregation to use (:obj:`\"add\"`, :obj:`\"mean\"`,\n            :obj:`\"max\"`).\n        src (Tensor): The source tensor.\n        index (LongTensor): The indices of elements to scatter.\n        dim_size (int, optional): Automatically create output tensor with size\n            :attr:`dim_size` in the first dimension. If set to :attr:`None`, a\n            minimal sized output tensor is returned. (default: :obj:`None`)\n\n    :rtype: :class:`Tensor`\n    \"\"\"", "\n", "\n", "assert", "name", "in", "[", "'add'", ",", "'mean'", ",", "'max'", "]", "\n", "\n", "op", "=", "getattr", "(", "torch_scatter", ",", "'scatter_{}'", ".", "format", "(", "name", ")", ")", "\n", "fill_value", "=", "-", "1e38", "if", "name", "==", "'max'", "else", "0", "\n", "out", "=", "op", "(", "src", ",", "index", ",", "0", ",", "None", ",", "dim_size", ",", "fill_value", ")", "\n", "if", "isinstance", "(", "out", ",", "tuple", ")", ":", "\n", "        ", "out", "=", "out", "[", "0", "]", "\n", "\n", "", "if", "name", "==", "'max'", ":", "\n", "        ", "out", "[", "out", "==", "fill_value", "]", "=", "0", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.BadParameters.__init___": [[16, 19], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init___", "(", "self", ",", "dErrorArguments", ")", ":", "\n", "        ", "Exception", ".", "__init__", "(", "self", ",", "\"Unexpected value of parameter {0}\"", ".", "format", "(", "dErrorArguments", ")", ")", "\n", "self", ".", "dErrorArguments", "=", "dErrorArguments", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.FancyDict.__init__": [[23, 26], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.Timer.__enter__": [[29, 32], ["time.perf_counter"], "methods", ["None"], ["def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.Timer.__exit__": [[33, 36], ["time.perf_counter"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "interval", "=", "self", ".", "end", "-", "self", ".", "start", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.SimplestSampler.__init__": [[259, 271], ["len", "len", "len", "utils_mytorch.MismatchedDataError", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "bs", ":", "int", "=", "64", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "assert", "len", "(", "data", "[", "\"x\"", "]", ")", "==", "len", "(", "data", "[", "\"y\"", "]", ")", "\n", "", "except", "AssertionError", ":", "\n", "\n", "            ", "raise", "MismatchedDataError", "(", "f\"Length of x is {len(data['x'])} while of y is {len(data['y'])}\"", ")", "\n", "\n", "", "self", ".", "x", "=", "data", "[", "\"x\"", "]", "\n", "self", ".", "y", "=", "data", "[", "\"y\"", "]", "\n", "self", ".", "n", "=", "len", "(", "self", ".", "x", ")", "\n", "self", ".", "bs", "=", "bs", "# Batch Size", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.SimplestSampler.__len__": [[272, 274], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n", "//", "self", ".", "bs", "-", "(", "1", "if", "self", ".", "n", "%", "self", ".", "bs", "else", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.SimplestSampler.__iter__": [[275, 278], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "i", ",", "self", ".", "iter", "=", "0", ",", "0", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.SimplestSampler.__next__": [[279, 287], ["None"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "i", "+", "self", ".", "bs", ">=", "self", ".", "n", ":", "\n", "            ", "raise", "StopIteration", "\n", "\n", "", "_x", ",", "_y", "=", "self", ".", "x", "[", "self", ".", "i", ":", "self", ".", "i", "+", "self", ".", "bs", "]", ",", "self", ".", "y", "[", "self", ".", "i", ":", "self", ".", "i", "+", "self", ".", "bs", "]", "\n", "self", ".", "i", "+=", "self", ".", "bs", "\n", "\n", "return", "_x", ",", "_y", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.default_eval": [[37, 45], ["torch.mean", "torch.argmax"], "function", ["None"], ["", "", "def", "default_eval", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "\"\"\"\n        Expects a batch of input\n\n        :param y_pred: tensor of shape (b, nc)\n        :param y_true: tensor of shape (b, 1)\n    \"\"\"", "\n", "return", "torch", ".", "mean", "(", "(", "torch", ".", "argmax", "(", "y_pred", ",", "dim", "=", "1", ")", "==", "y_true", ")", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.compute_mask": [[46, 58], ["type", "torch.ne().float", "numpy.not_equal", "torch.ne"], "function", ["None"], ["", "def", "compute_mask", "(", "t", ":", "Union", "[", "torch", ".", "Tensor", ",", "np", ".", "array", "]", ",", "padding_idx", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    compute mask on given tensor t\n    :param t: either a tensor or a nparry\n    :param padding_idx: the ID used to represented padded data\n    :return: a mask of the same shape as t\n    \"\"\"", "\n", "if", "type", "(", "t", ")", "is", "np", ".", "ndarray", ":", "\n", "        ", "mask", "=", "np", ".", "not_equal", "(", "t", ",", "padding_idx", ")", "*", "1.0", "\n", "", "else", ":", "\n", "        ", "mask", "=", "torch", ".", "ne", "(", "t", ",", "padding_idx", ")", ".", "float", "(", ")", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.convert_nicely": [[60, 78], ["warnings.warn", "data_type"], "function", ["None"], ["", "def", "convert_nicely", "(", "arg", ",", "possible_types", "=", "(", "bool", ",", "float", ",", "int", ",", "str", ")", ")", ":", "\n", "    ", "\"\"\" Try and see what sticks. Possible types can be changed. \"\"\"", "\n", "for", "data_type", "in", "possible_types", ":", "\n", "        ", "try", ":", "\n", "\n", "            ", "if", "data_type", "is", "bool", ":", "\n", "# Hard code this shit", "\n", "                ", "if", "arg", "in", "[", "'T'", ",", "'True'", ",", "'true'", "]", ":", "return", "True", "\n", "if", "arg", "in", "[", "'F'", ",", "'False'", ",", "'false'", "]", ":", "return", "False", "\n", "raise", "ValueError", "\n", "", "else", ":", "\n", "                ", "proper_arg", "=", "data_type", "(", "arg", ")", "\n", "return", "proper_arg", "\n", "", "", "except", "ValueError", ":", "\n", "            ", "continue", "\n", "# Here, i.e. no data type really stuck", "\n", "", "", "warnings", ".", "warn", "(", "f\"None of the possible datatypes matched for {arg}. Returning as-is\"", ")", "\n", "return", "arg", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.parse_args": [[80, 139], ["raw_args.pop", "raw_args.pop", "utils_mytorch.convert_nicely", "utils_mytorch.ImproperCMDArguments", "utils_mytorch.ImproperCMDArguments", "utils_mytorch.ImproperCMDArguments", "utils_mytorch.convert_nicely", "parsed.keys"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.convert_nicely", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.convert_nicely"], ["", "def", "parse_args", "(", "raw_args", ":", "List", "[", "str", "]", ",", "compulsory", ":", "List", "[", "str", "]", "=", "(", ")", ",", "compulsory_msg", ":", "str", "=", "\"\"", ",", "\n", "types", ":", "Dict", "[", "str", ",", "type", "]", "=", "None", ",", "discard_unspecified", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        I don't like argparse.\n        Don't like specifying a complex two liner for each every config flag/macro.\n\n        If you maintain a dict of default arguments, and want to just overwrite it based on command args,\n        call this function, specify some stuff like\n\n    :param raw_args: unparsed sys.argv[1:]\n    :param compulsory: if some flags must be there\n    :param compulsory_msg: what if some compulsory flags weren't there\n    :param types: a dict of confignm: type(configvl)\n    :param discard_unspecified: flag so that if something doesn't appear in config it is not returned.\n    :return:\n    \"\"\"", "\n", "\n", "# parsed_args = _parse_args_(raw_args, compulsory=compulsory, compulsory_msg=compulsory_msg)", "\n", "#", "\n", "# # Change the \"type\" of arg, anyway", "\n", "\n", "parsed", "=", "{", "}", "\n", "\n", "while", "True", ":", "\n", "\n", "        ", "try", ":", "# Get next value", "\n", "            ", "nm", "=", "raw_args", ".", "pop", "(", "0", ")", "\n", "", "except", "IndexError", ":", "# We emptied the list", "\n", "            ", "break", "\n", "\n", "# Get value", "\n", "", "try", ":", "\n", "            ", "vl", "=", "raw_args", ".", "pop", "(", "0", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "raise", "ImproperCMDArguments", "(", "f\"A value was expected for {nm} parameter. Not found.\"", ")", "\n", "\n", "# Get type of value", "\n", "", "if", "types", ":", "\n", "            ", "try", ":", "\n", "                ", "parsed", "[", "nm", "]", "=", "types", "[", "nm", "]", "(", "vl", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "raise", "ImproperCMDArguments", "(", "f\"The value for {nm}: {vl} can not take the type {types[nm]}! \"", ")", "\n", "", "except", "KeyError", ":", "# This name was not included in the types dict", "\n", "                ", "if", "not", "discard_unspecified", ":", "# Add it nonetheless", "\n", "                    ", "parsed", "[", "nm", "]", "=", "convert_nicely", "(", "vl", ")", "\n", "", "else", ":", "# Discard it.", "\n", "                    ", "continue", "\n", "", "", "", "else", ":", "\n", "            ", "parsed", "[", "nm", "]", "=", "convert_nicely", "(", "vl", ")", "\n", "\n", "# Check if all the compulsory things are in here.", "\n", "", "", "for", "key", "in", "compulsory", ":", "\n", "        ", "try", ":", "\n", "            ", "assert", "key", "in", "parsed", "\n", "", "except", "AssertionError", ":", "\n", "            ", "raise", "ImproperCMDArguments", "(", "compulsory_msg", "+", "f\"Found keys include {[k for k in parsed.keys()]}\"", ")", "\n", "\n", "# Finally check if something unwanted persists here", "\n", "", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.mt_save_dir": [[141, 187], ["sorted", "parentdir.exists", "parentdir.mkdir", "parentdir.mkdir", "int", "parentdir.mkdir", "os.listdir", "x.isdigit", "str", "str"], "function", ["None"], ["", "def", "mt_save_dir", "(", "parentdir", ":", "Path", ",", "_newdir", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n            Function which returns the last filled/or newest unfilled folder in a particular dict.\n            Eg.1\n                parentdir is empty dir\n                    -> mkdir 0\n                    -> cd 0\n                    -> return parentdir/0\n\n            Eg.2\n                ls savedir -> 0, 1, 2, ... 9, 10, 11\n                    -> mkdir 12 && cd 12 (if newdir is True) else 11\n                    -> return parentdir/11 (or 12)\n\n            ** Usage **\n            Get a path using this function like so:\n                parentdir = Path('runs')\n                savedir = save_dir(parentdir, _newdir=True)\n\n        :param parentdir: pathlib.Path object of the parent directory\n        :param _newdir: bool flag to save in the last dir or make a new one\n        :return: None\n    \"\"\"", "\n", "\n", "# Check if the dir exits", "\n", "try", ":", "\n", "        ", "assert", "parentdir", ".", "exists", "(", ")", ",", "f'{parentdir} does not exist. Making it'", "\n", "", "except", "AssertionError", ":", "\n", "        ", "parentdir", ".", "mkdir", "(", "parents", "=", "False", ")", "\n", "\n", "# List all folders within, and convert them to ints", "\n", "", "existing", "=", "sorted", "(", "[", "int", "(", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "parentdir", ")", "if", "x", ".", "isdigit", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "if", "not", "existing", ":", "\n", "# If no subfolder exists", "\n", "        ", "parentdir", "=", "parentdir", "/", "'0'", "\n", "parentdir", ".", "mkdir", "(", ")", "\n", "", "elif", "_newdir", ":", "\n", "# If there are subfolders and we want to make a new dir", "\n", "        ", "parentdir", "=", "parentdir", "/", "str", "(", "existing", "[", "0", "]", "+", "1", ")", "\n", "parentdir", ".", "mkdir", "(", ")", "\n", "", "else", ":", "\n", "# There are other folders and we dont wanna make a new folder", "\n", "        ", "parentdir", "=", "parentdir", "/", "str", "(", "existing", "[", "0", "]", ")", "\n", "\n", "", "return", "parentdir", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.mt_save": [[189, 250], ["savedir.is_dir", "open", "f.write", "torch.save", "pickle.dump", "numpy.save", "json.dump", "traceback.print_exc", "open", "traceback.print_exc", "traceback.print_exc", "data.obj.items", "open", "traceback.print_exc", "type"], "function", ["None"], ["", "def", "mt_save", "(", "savedir", ":", "Path", ",", "message", ":", "str", "=", "None", ",", "message_fname", ":", "str", "=", "None", ",", "torch_stuff", ":", "list", "=", "None", ",", "pickle_stuff", ":", "list", "=", "None", ",", "\n", "numpy_stuff", ":", "list", "=", "None", ",", "json_stuff", ":", "list", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n        Saves bunch of diff stuff in a particular dict.\n\n        NOTE: all the stuff to save should also have an accompanying filename, and so we use tosave named tuple defined above as\n            tosave = namedtuple('ObjectsToSave','fname obj')\n\n        ** Usage **\n        # say `encoder` is torch module, and `traces` is a python obj (dont care what)\n        parentdir = Path('runs')\n        savedir = save_dir(parentdir, _newdir=True)\n        save(\n                savedir,\n                torch_stuff = [tosave(fname='model.torch', obj=encoder)],\n                pickle_stuff = [tosave('traces.pkl', traces)]\n            )\n\n\n    :param savedir: pathlib.Path object of the parent directory\n    :param message: a message to be saved in the folder alongwith (as text)\n    :param torch_stuff: list of tosave tuples to be saved with torch.save functions\n    :param pickle_stuff: list of tosave tuples to be saved with pickle.dump\n    :param numpy_stuff: list of tosave tuples to be saved with numpy.save\n    :param json_stuff: list of tosave tuples to be saved with json.dump\n    :return: None\n    \"\"\"", "\n", "\n", "assert", "savedir", ".", "is_dir", "(", ")", ",", "f'{savedir} is not a directory!'", "\n", "\n", "# Commence saving shit!", "\n", "if", "message", ":", "\n", "        ", "with", "open", "(", "savedir", "/", "'message.txt'", "if", "message_fname", "is", "None", "else", "savedir", "/", "message_fname", ",", "'w+'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "message", ")", "\n", "\n", "", "", "for", "data", "in", "torch_stuff", "or", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "torch", ".", "save", "(", "data", ".", "obj", ",", "savedir", "/", "data", ".", "fname", ")", "\n", "", "except", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "for", "data", "in", "pickle_stuff", "or", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "pickle", ".", "dump", "(", "data", ".", "obj", ",", "open", "(", "savedir", "/", "data", ".", "fname", ",", "'wb+'", ")", ")", "\n", "", "except", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "for", "data", "in", "numpy_stuff", "or", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "np", ".", "save", "(", "savedir", "/", "data", ".", "fname", ",", "data", ".", "obj", ")", "\n", "", "except", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "", "for", "data", "in", "json_stuff", "or", "(", ")", ":", "\n", "# Filter out: only things belonging to specific types should be saved.", "\n", "        ", "saving_data", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "data", ".", "obj", ".", "items", "(", ")", "if", "type", "(", "v", ")", "in", "[", "str", ",", "int", ",", "float", ",", "np", ".", "int", ",", "np", ".", "float", ",", "np", ".", "long", ",", "bool", "]", "}", "\n", "try", ":", "\n", "            ", "json", ".", "dump", "(", "saving_data", ",", "open", "(", "savedir", "/", "data", ".", "fname", ",", "'w+'", ")", ")", "\n", "", "except", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_tokenizer.NodePiece_Tokenizer.__init__": [[20, 78], ["super().__init__", "set", "set().issubset", "nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg", "max", "Exception", "sum", "len", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.values", "set", "enumerate", "len", "enumerate", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.keys", "list", "nodepiece_tokenizer.NodePiece_Tokenizer.vocab.items", "nodepiece_tokenizer.NodePiece_Tokenizer.r2id.values"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg"], ["\n", "def", "__init__", "(", "self", ",", "\n", "triples", ":", "TriplesFactory", ",", "\n", "dataset_name", ":", "str", ",", "\n", "num_anchors", ":", "int", ",", "\n", "anchor_strategy", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "limit_shortest", ":", "int", "=", "0", ",", "\n", "limit_random", ":", "int", "=", "0", ",", "\n", "add_identity", ":", "bool", "=", "True", ",", "\n", "mode", ":", "str", "=", "\"path\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "triples_factory", "=", "triples", "# original triples of the training graph, assuming inverses are added", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "num_anchors", "=", "num_anchors", "# total N anchor nodes", "\n", "self", ".", "anchor_strategy", "=", "anchor_strategy", "# ratios of strategies for sampling anchor nodes", "\n", "self", ".", "num_paths", "=", "num_anchors", "# aux variable", "\n", "self", ".", "sp_limit", "=", "limit_shortest", "# keep only K nearest anchor nodes per entity", "\n", "self", ".", "rand_limit", "=", "limit_random", "# keep only K random anchor nodes per entity", "\n", "\n", "if", "self", ".", "sp_limit", "*", "self", ".", "rand_limit", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"-sp_limit and -rand_limit are mutually exclusive\"", ")", "\n", "\n", "", "self", ".", "add_identity", "=", "add_identity", "# anchor nodes will have their own indices with distance 0  in their hashes", "\n", "self", ".", "tkn_mode", "=", "mode", "# only \"path\" mode is implemented atm", "\n", "\n", "# auxiliary tokens for the vocabulary", "\n", "self", ".", "NOTHING_TOKEN", "=", "-", "99", "# means the node is not reachable from any of anchor nodes", "\n", "self", ".", "CLS_TOKEN", "=", "-", "1", "\n", "self", ".", "MASK_TOKEN", "=", "-", "10", "\n", "self", ".", "PADDING_TOKEN", "=", "-", "100", "\n", "self", ".", "SEP_TOKEN", "=", "-", "2", "\n", "\n", "# well, betwenness is disabled", "\n", "self", ".", "AVAILABLE_STRATEGIES", "=", "set", "(", "[", "\"degree\"", ",", "\"betweenness\"", ",", "\"pagerank\"", ",", "\"random\"", "]", ")", "\n", "\n", "assert", "sum", "(", "self", ".", "anchor_strategy", ".", "values", "(", ")", ")", "==", "1.0", ",", "\"Ratios of strategies should sum up to one\"", "\n", "assert", "set", "(", "self", ".", "anchor_strategy", ".", "keys", "(", ")", ")", ".", "issubset", "(", "self", ".", "AVAILABLE_STRATEGIES", ")", "\n", "\n", "# load or create the vocabulary", "\n", "self", ".", "top_entities", ",", "self", ".", "other_entities", ",", "self", ".", "vocab", "=", "self", ".", "tokenize_kg", "(", ")", "\n", "\n", "# numerical indices for entities and relations", "\n", "self", ".", "token2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "top_entities", ")", "}", "\n", "self", ".", "rel2token", "=", "{", "t", ":", "i", "+", "len", "(", "self", ".", "top_entities", ")", "for", "i", ",", "t", "in", "\n", "enumerate", "(", "list", "(", "self", ".", "triples_factory", ".", "relation_to_id", ".", "values", "(", ")", ")", ")", "}", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "token2id", ")", "+", "len", "(", "self", ".", "rel2token", ")", "\n", "\n", "# although we don't use paths, we count their lengths for anchor distances", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", "]", ")", "\n", "\n", "if", "self", ".", "add_identity", ":", "\n", "# add identity for anchor nodes as the first / closest node", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "# last 4 are always service tokens", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "=", "[", "[", "anchor", "]", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", ":", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg": [[81, 135], ["pathlib.Path", "pathlib.Path.is_file", "igraph.Graph", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.items", "nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths", "pickle.dump", "print", "filename.split", "pickle.load", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.edge_index[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.edge_index[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.edge_type.numpy", "int", "print", "anchors.extend", "print", "open", "open", "zip", "numpy.ceil", "sorted", "range", "list", "NotImplementedError", "sorted", "len", "enumerate", "igraph.Graph.degree", "enumerate", "int", "numpy.random.permutation", "igraph.Graph.personalized_pagerank", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths"], ["\n", "\n", "\n", "", "", "", "", "def", "tokenize_kg", "(", "self", ")", ":", "\n", "\n", "# creating a filename", "\n", "        ", "strategy_encoding", "=", "f\"d{self.anchor_strategy['degree']}_b{self.anchor_strategy['betweenness']}_p{self.anchor_strategy['pagerank']}_r{self.anchor_strategy['random']}\"", "\n", "\n", "filename", "=", "f\"data/{self.dataset_name}_{self.num_anchors}_anchors_{self.num_paths}_paths_{strategy_encoding}_pykeen\"", "\n", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.sp_limit}sp\"", "# for separating vocabs with limited mined shortest paths", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.rand_limit}rand\"", "\n", "", "if", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "            ", "filename", "+=", "\"_bfs\"", "\n", "", "filename", "+=", "\".pkl\"", "\n", "self", ".", "model_name", "=", "filename", ".", "split", "(", "'.pkl'", ")", "[", "0", "]", "\n", "path", "=", "Path", "(", "filename", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "            ", "anchors", ",", "non_anchors", ",", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "return", "anchors", ",", "non_anchors", ",", "vocab", "\n", "\n", "", "if", "type", "(", "self", ".", "triples_factory", ".", "mapped_triples", ")", "==", "torch", ".", "Tensor", ":", "\n", "            ", "src", ",", "tgt", ",", "rels", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "0", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "2", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "1", "]", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Input triples are expected to be in the torch.Tensor format\"", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "# create an input object for iGraph - edge list with relation types, and then create a graph", "\n", "", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", ",", "r", "in", "zip", "(", "src", ",", "tgt", ",", "rels", ")", "]", "\n", "graph", "=", "Graph", "(", "n", "=", "self", ".", "triples_factory", ".", "num_entities", ",", "edges", "=", "edgelist", ",", "edge_attrs", "=", "{", "'relation'", ":", "list", "(", "rels", ")", "}", ",", "directed", "=", "True", ")", "\n", "\n", "# sampling anchor nodes", "\n", "anchors", "=", "[", "]", "\n", "for", "strategy", ",", "ratio", "in", "self", ".", "anchor_strategy", ".", "items", "(", ")", ":", "\n", "            ", "if", "ratio", "<=", "0.0", ":", "\n", "                ", "continue", "\n", "", "topK", "=", "int", "(", "np", ".", "ceil", "(", "ratio", "*", "self", ".", "num_anchors", ")", ")", "\n", "print", "(", "f\"Computing the {strategy} nodes\"", ")", "\n", "if", "strategy", "==", "\"degree\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "degree", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"betweenness\"", ":", "\n", "# This is O(V^3) - disabled", "\n", "                ", "raise", "NotImplementedError", "(", "\"Betweenness is disabled due to computational costs\"", ")", "\n", "", "elif", "strategy", "==", "\"pagerank\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "personalized_pagerank", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"random\"", ":", "\n", "                ", "top_nodes", "=", "[", "(", "int", "(", "k", ")", ",", "1", ")", "for", "k", "in", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", "]", "\n", "\n", "", "selected_nodes", "=", "[", "node", "for", "node", ",", "d", "in", "top_nodes", "if", "node", "not", "in", "anchors", "]", "[", ":", "topK", "]", "\n", "\n", "anchors", ".", "extend", "(", "selected_nodes", ")", "\n", "print", "(", "f\"Added {len(selected_nodes)} nodes under the {strategy} strategy\"", ")", "\n", "\n", "# now mine the anchors per node", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths": [[137, 164], ["tqdm.tqdm.tqdm", "print", "print", "range", "graph.get_shortest_paths", "len", "random.shuffle", "sorted", "range", "len", "len"], "methods", ["None"], ["top_entities", "=", "anchors", "+", "[", "self", ".", "CLS_TOKEN", "]", "+", "[", "self", ".", "MASK_TOKEN", "]", "+", "[", "self", ".", "PADDING_TOKEN", "]", "+", "[", "self", ".", "SEP_TOKEN", "]", "\n", "non_core_entities", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "if", "i", "not", "in", "anchors", "]", "\n", "\n", "pickle", ".", "dump", "(", "(", "top_entities", ",", "non_core_entities", ",", "vocab", ")", ",", "open", "(", "filename", ",", "\"wb\"", ")", ")", "\n", "print", "(", "\"Vocabularized and saved!\"", ")", "\n", "\n", "return", "top_entities", ",", "non_core_entities", ",", "vocab", "\n", "\n", "\n", "", "def", "create_all_paths", "(", "self", ",", "graph", ":", "Graph", ",", "top_entities", ":", "List", "=", "None", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "\n", "        ", "vocab", "=", "{", "}", "\n", "if", "self", ".", "rand_limit", "==", "0", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.sp_limit if self.sp_limit >0 else self.num_paths} shortest paths per node\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.rand_limit} random paths per node\"", ")", "\n", "\n", "", "if", "self", ".", "tkn_mode", ":", "\n", "            ", "anc_set", "=", "set", "(", "top_entities", ")", "\n", "\n", "# single-threaded mining is found to be as fast as multi-processing + igraph for some reason, so let's use a dummy for-loop", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", ":", "\n", "            ", "if", "self", ".", "tkn_mode", "==", "\"path\"", ":", "\n", "                ", "paths", "=", "graph", ".", "get_shortest_paths", "(", "v", "=", "i", ",", "to", "=", "top_entities", ",", "output", "=", "\"epath\"", ",", "mode", "=", "'in'", ")", "\n", "if", "len", "(", "paths", "[", "0", "]", ")", ">", "0", ":", "\n", "                    ", "relation_paths", "=", "[", "[", "graph", ".", "es", "[", "path", "[", "-", "1", "]", "]", ".", "source", "]", "+", "[", "graph", ".", "es", "[", "k", "]", "[", "'relation'", "]", "for", "k", "in", "path", "[", ":", ":", "-", "1", "]", "]", "for", "path", "in", "paths", "if", "len", "(", "path", ")", ">", "0", "]", "\n", "", "else", ":", "\n", "# if NO anchor can be reached from the node - encode with a special NOTHING_TOKEN", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.__init__": [[17, 190], ["torch.nn.Module.__init__", "len", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Embedding", "torch.nn.Embedding", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "nodepiece_encoder.NodePieceEncoder.triples_factory.mapped_triples[].unique", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.Sequential", "torch.nn.Sequential", "collections.defaultdict", "enumerate", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "random.sample", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "e2r[].add", "len", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "random.sample", "max", "max", "print", "sampled_paths.items", "sampled_paths.items", "list", "range", "edge_type[].item", "collections.defaultdict.items", "random.sample", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "range", "min", "numpy.mean", "numpy.percentile", "max", "min", "len", "sorted", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "len", "len", "len", "len", "sorted", "min", "min", "len", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "min", "sampled_paths.items", "src_node.item", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "dict", ",", "tokenizer", ":", "NodePiece_Tokenizer", ",", "rel_embs", ":", "nn", ".", "Embedding", ",", "graph", ":", "Data", ")", ":", "\n", "\n", "        ", "super", "(", "NodePieceEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pooler", "=", "config", "[", "'POOLER'", "]", "\n", "self", ".", "policy", "=", "\"sum\"", "\n", "self", ".", "use_rels", "=", "False", "\n", "self", ".", "nearest", "=", "config", "[", "'NEAREST'", "]", "\n", "self", ".", "use_neighbor_rels", "=", "False", "\n", "self", ".", "sample_rels", "=", "config", "[", "'SAMPLE_RELS'", "]", "\n", "self", ".", "graph", "=", "graph", "\n", "\n", "if", "not", "self", ".", "use_rels", ":", "\n", "            ", "self", ".", "policy", "=", "\"sum\"", "\n", "\n", "", "self", ".", "random_hashes", "=", "config", "[", "'RANDOM_HASHES'", "]", "\n", "\n", "self", ".", "subbatch", "=", "config", "[", "'SUBBATCH'", "]", "\n", "self", ".", "embedding_dim", "=", "config", "[", "'EMBEDDING_DIM'", "]", "\n", "self", ".", "real_embedding_dim", "=", "self", ".", "embedding_dim", "//", "2", "\n", "\n", "self", ".", "max_seq_len", "=", "config", "[", "'MAX_PATH_LEN'", "]", "\n", "self", ".", "sample_paths", "=", "config", "[", "'MAX_PATHS'", "]", "\n", "self", ".", "use_distances", "=", "config", "[", "'USE_DISTANCES'", "]", "\n", "self", ".", "hid_dim", "=", "config", "[", "'T_HIDDEN'", "]", "\n", "self", ".", "drop_prob", "=", "config", "[", "'T_DROP'", "]", "\n", "self", ".", "num_heads", "=", "config", "[", "'T_HEADS'", "]", "\n", "self", ".", "num_layers", "=", "config", "[", "'T_LAYERS'", "]", "\n", "self", ".", "num_entities", "=", "config", "[", "'NUM_ENTITIES'", "]", "\n", "self", ".", "num_relations", "=", "config", "[", "'NUM_RELATIONS'", "]", "\n", "self", ".", "device", "=", "config", "[", "'DEVICE'", "]", "\n", "self", ".", "no_anc", "=", "config", "[", "'NO_ANC'", "]", "\n", "\n", "\n", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "embedding_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "\n", ")", "\n", "self", ".", "set_dec", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "embedding_dim", ")", "\n", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "(", "self", ".", "sample_paths", "+", "self", ".", "sample_rels", ")", ",", "self", ".", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# nn.Linear(embedding_dim * 4, embedding_dim * 2), nn.Dropout(drop_prob), nn.ReLU(),", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "2", ",", "self", ".", "embedding_dim", ")", "\n", ")", "if", "not", "self", ".", "no_anc", "else", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "self", ".", "sample_rels", ",", "self", ".", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "2", ",", "self", ".", "embedding_dim", ")", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", ":", "\n", "            ", "encoder_layer", "=", "TransformerEncoderLayer", "(", "\n", "d_model", "=", "self", ".", "embedding_dim", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "embedding_dim", ",", "\n", "nhead", "=", "self", ".", "num_heads", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "num_heads", ",", "\n", "dim_feedforward", "=", "self", ".", "hid_dim", ",", "\n", "dropout", "=", "self", ".", "drop_prob", ",", "\n", ")", "\n", "self", ".", "set_enc", "=", "TransformerEncoder", "(", "encoder_layer", "=", "encoder_layer", ",", "num_layers", "=", "self", ".", "num_layers", ")", "\n", "if", "self", ".", "policy", "==", "\"cat\"", ":", "\n", "                ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "embedding_dim", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "\n", "\n", "\n", "", "", "self", ".", "rel_gnn", "=", "False", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "NOTHING_TOKEN", "]", "=", "len", "(", "tokenizer", ".", "token2id", ")", "\n", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tokenizer", ".", "token2id", ")", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "padding_idx", "=", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", ")", "\n", "self", ".", "relation_embeddings", "=", "rel_embs", "\n", "self", ".", "dist_emb", "=", "nn", ".", "Embedding", "(", "self", ".", "max_seq_len", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ")", "\n", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "if", "not", "self", ".", "nearest", ":", "\n", "# subsample paths, need to align them with distances", "\n", "                ", "sampled_paths", "=", "{", "\n", "entity", ":", "random", ".", "sample", "(", "paths", ",", "k", "=", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", ")", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "self", ".", "nearest", ":", "\n", "# sort paths by length first and take K of them", "\n", "                ", "prev_max_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "sampled_paths", "=", "{", "\n", "entity", ":", "sorted", "(", "paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", "]", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "max_seq_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "sampled_paths", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "print", "(", "\n", "f\"Changed max seq len from {prev_max_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "path", "[", "0", "]", "]", "for", "path", "in", "paths", "]", "+", "[", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "len", "(", "path", ")", "-", "1", "for", "path", "in", "paths", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "tensor", "(", "distances", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "", "else", ":", "\n", "# in this case, we bypass distances and won't use relations in the encoder", "\n", "            ", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "random_hashes", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ")", "\n", "hashes", "=", "[", "\n", "random", ".", "sample", "(", "list", "(", "range", "(", "self", ".", "random_hashes", ")", ")", ",", "self", ".", "sample_paths", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_entities", ")", "\n", "]", "\n", "# _PRIMES = [", "\n", "#     31, 43, 59, 61, 73, 97, 103, 113, 137, 149, 157, 173, 181, 193, 211, 223", "\n", "# ]", "\n", "# self.num_buckets = self.random_hashes", "\n", "\n", "# self.anchor_embeddings = nn.Embedding(self.num_buckets * self.num_hashes, embedding_dim=embedding_dim // self.num_hashes)", "\n", "\n", "# self.hash_projector = nn.Sequential(", "\n", "#     nn.Linear(self.embedding_dim, self.embedding_dim),", "\n", "#     nn.ReLU(),", "\n", "#     nn.Linear(self.embedding_dim, self.embedding_dim)", "\n", "# )", "\n", "\n", "# primes = _PRIMES[:self.num_hashes]", "\n", "# hashes = [", "\n", "#     [(((i+1) * prime) % self.num_buckets) + k*self.num_buckets for k, prime in enumerate(primes)]", "\n", "#     for i in range(triples.num_entities)", "\n", "# ]", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_entities", ",", "self", ".", "sample_paths", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "", "if", "self", ".", "use_neighbor_rels", ":", "\n", "# create a feature matrix where rows are used relations in a 1-hop neighbourhood around each node", "\n", "            ", "unique_sp", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "[", "0", ",", "1", "]", "]", ".", "unique", "(", "dim", "=", "0", ",", "return_counts", "=", "False", ")", "\n", "self", ".", "relation_features", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_entities", ",", "self", ".", "num_relations", "*", "2", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ")", "# features matrix", "\n", "self", ".", "relation_features", "[", "unique_sp", "[", ":", ",", "0", "]", ",", "unique_sp", "[", ":", ",", "1", "]", "]", "=", "1.0", "# counts.float().to(self.device)", "\n", "# self.relation_features = torch.nn.functional.normalize(self.relation_features, p=1, dim=1)", "\n", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "+", "self", ".", "num_relations", ",", "self", ".", "hid_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "embedding_dim", ")", "\n", ")", "\n", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "pad_idx", "=", "self", ".", "num_relations", "*", "2", "\n", "e2r", "=", "defaultdict", "(", "set", ")", "\n", "edge_index", "=", "self", ".", "graph", ".", "edge_index", "\n", "edge_type", "=", "self", ".", "graph", ".", "edge_type", "\n", "for", "i", ",", "src_node", "in", "enumerate", "(", "edge_index", "[", "0", "]", ")", ":", "\n", "                ", "e2r", "[", "src_node", ".", "item", "(", ")", "]", ".", "add", "(", "edge_type", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "", "len_stats", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "e2r", ".", "items", "(", ")", "]", "\n", "print", "(", "\n", "f\"Unique relations per node - min: {min(len_stats)}, avg: {np.mean(len_stats)}, 66th perc: {np.percentile(sorted(len_stats), 66)}, max: {max(len_stats)} \"", ")", "\n", "unique_1hop_relations", "=", "[", "\n", "random", ".", "sample", "(", "e2r", "[", "i", "]", ",", "k", "=", "min", "(", "self", ".", "sample_rels", ",", "len", "(", "e2r", "[", "i", "]", ")", ")", ")", "+", "[", "pad_idx", "]", "*", "(", "\n", "self", ".", "sample_rels", "-", "min", "(", "len", "(", "e2r", "[", "i", "]", ")", ",", "self", ".", "sample_rels", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_entities", ")", "\n", "]", "\n", "self", ".", "unique_1hop_relations", "=", "torch", ".", "tensor", "(", "unique_1hop_relations", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.reset_parameters": [[191, 231], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "nodepiece_encoder.NodePieceEncoder.set_enc.modules", "nodepiece_encoder.NodePieceEncoder.projection.modules", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "hasattr", "nodepiece_encoder.NodePieceEncoder.set_dec.modules", "hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "module.reset_parameters", "hasattr", "module.reset_parameters", "module.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooler", "!=", "\"avg\"", ":", "\n", "            ", "for", "module", "in", "self", ".", "set_enc", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "                ", "for", "module", "in", "self", ".", "set_dec", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "module", "is", "self", ":", "\n", "                        ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                        ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "\n", "", "", "", "", "if", "self", ".", "use_neighbor_rels", ":", "\n", "            ", "for", "module", "in", "self", ".", "projection", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "# if self.random_hashes != 0:", "\n", "#     for module in self.hash_projector.modules():", "\n", "#         if module is self:", "\n", "#             continue", "\n", "#         if hasattr(module, \"reset_parameters\"):", "\n", "#             module.reset_parameters()", "\n", "\n", "", "", "", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "anchor_embeddings", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dist_emb", ".", "weight", ")", "\n", "if", "self", ".", "use_rels", "==", "\"joint\"", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "node_types", ".", "weight", ")", "\n", "\n", "", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "anchor_embeddings", ".", "weight", "[", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "dist_emb", ".", "weight", "[", "0", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "# if self.use_rels == \"trf\":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.pool_anchors": [[241, 268], ["nodepiece_encoder.NodePieceEncoder.set_enc", "anc_embs.view.view.view", "nodepiece_encoder.NodePieceEncoder.set_enc", "anc_embs.view.mean.mean", "nodepiece_encoder.NodePieceEncoder.set_enc", "nodepiece_encoder.NodePieceEncoder.set_enc", "nodepiece_encoder.NodePieceEncoder.linear", "nodepiece_encoder.NodePieceEncoder.set_enc", "anc_embs.view.view.transpose", "anc_embs.view.view.transpose", "nodepiece_encoder.NodePieceEncoder.set_dec", "anc_embs.view.view.mean", "nodepiece_encoder.NodePieceEncoder.set_enc().mean", "nodepiece_encoder.NodePieceEncoder.set_enc"], "methods", ["None"], ["", "", "", "def", "pool_anchors", "(", "self", ",", "anc_embs", ":", "torch", ".", "FloatTensor", ",", "mask", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        input shape: (bs, num_anchors, emb_dim)\n        output shape: (bs, emb_dim)\n        \"\"\"", "\n", "\n", "if", "self", ".", "pooler", "==", "\"set\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "anc_embs", "=", "anc_embs", ".", "view", "(", "anc_embs", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "if", "self", ".", "sample_paths", "!=", "1", "else", "anc_embs", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", "or", "self", ".", "pooler", "==", "\"moe\"", ":", "\n", "            ", "if", "self", ".", "use_rels", "!=", "\"joint\"", ":", "\n", "                ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ".", "transpose", "(", "1", ",", "0", ")", ")", "# output shape: (seq_len, bs, dim)", "\n", "", "else", ":", "\n", "                ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ".", "transpose", "(", "1", ",", "0", ")", ",", "src_key_padding_mask", "=", "mask", ")", "\n", "", "pooled", "=", "pooled", ".", "mean", "(", "dim", "=", "0", ")", "# output shape: (bs, dim)", "\n", "if", "self", ".", "policy", "==", "\"cat\"", ":", "\n", "                ", "pooled", "=", "self", ".", "linear", "(", "pooled", ")", "\n", "", "", "elif", "self", ".", "pooler", "==", "\"perc\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_dec", "(", "self", ".", "set_enc", "(", "anc_embs", ")", ".", "mean", "(", "-", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "pooled", "=", "anc_embs", ".", "mean", "(", "dim", "=", "1", ")", "\n", "\n", "", "return", "pooled", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.encode_rels": [[269, 324], ["nodepiece_encoder.NodePieceEncoder.view", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "nodepiece_encoder.NodePieceEncoder.view", "weights.view.view.view", "nodepiece_encoder.NodePieceEncoder.rel_enc", "nodepiece_encoder.NodePieceEncoder.rel_proj", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "dec", "rel_hashes[].view", "enc", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "nodepiece_encoder.NodePieceEncoder.rel_pos", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nodepiece_encoder.NodePieceEncoder.rel_enc", "pad_mask.float().sum().clamp_min().unsqueeze", "pad_mask.float().sum().clamp_min().unsqueeze", "pad_mask.float().sum().clamp_min().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "nodepiece_encoder.NodePieceEncoder.rel_pos", "nodepiece_encoder.NodePieceEncoder.rel_enc", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "nodepiece_encoder.NodePieceEncoder.transpose", "pad_mask.float().sum().clamp_min().unsqueeze", "range", "pad_mask.float().sum().clamp_min", "pad_mask.float().sum().clamp_min", "pad_mask.float().sum().clamp_min", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "nodepiece_encoder.NodePieceEncoder.pairwise_interaction_function", "pad_mask.float().unsqueeze", "weights.view.view.unsqueeze", "pad_mask.float().unsqueeze", "pad_mask.sum", "pad_mask.float().sum().clamp_min", "start.view", "target.view", "pad_mask.float().sum", "pad_mask.float().sum", "pad_mask.float().sum", "pad_mask.sum", "pad_mask.t().float().unsqueeze", "pad_mask.float", "pad_mask.float", "pad_mask.float().sum", "pad_mask.float", "pad_mask.float", "pad_mask.float", "pad_mask.sum", "pad_mask.t().float", "pad_mask.float", "pad_mask.t"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.pairwise_interaction_function"], ["", "def", "encode_rels", "(", "self", ",", "rel_hashes", ":", "torch", ".", "LongTensor", ",", "weights", ":", "Optional", "[", "torch", ".", "FloatTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "# input: (bs, num_anchors, max_seq_len)", "\n", "        ", "bs", ",", "num_paths", ",", "seq_len", "=", "rel_hashes", ".", "shape", "\n", "rel_hashes", "=", "rel_hashes", ".", "view", "(", "bs", "*", "num_paths", ",", "seq_len", ")", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", ".", "view", "(", "bs", "*", "num_paths", ",", "seq_len", ")", "\n", "", "pad_mask", "=", "rel_hashes", "!=", "self", ".", "triples_factory", ".", "num_relations", "\n", "rel_hashes", "=", "self", ".", "relation_embeddings", "(", "rel_hashes", ")", "# (bs*num_paths, seq_len, hid_dim)", "\n", "if", "self", ".", "use_rels", "==", "\"lstm\"", "or", "self", ".", "use_rels", "==", "\"gru\"", ":", "\n", "            ", "rel_hashes", ",", "_", "=", "self", ".", "rel_enc", "(", "rel_hashes", ")", "# (bs, seq_len, hid_dim)", "\n", "rel_hashes", "=", "self", ".", "rel_proj", "(", "rel_hashes", "[", ":", ",", "-", "1", ",", ":", "]", ")", "# (bs, emb_dim)", "\n", "", "elif", "self", ".", "use_rels", "==", "\"mlp\"", ":", "\n", "            ", "accumulator", "=", "torch", ".", "zeros", "(", "(", "rel_hashes", ".", "shape", "[", "0", "]", ",", "rel_hashes", ".", "shape", "[", "-", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "rel_hashes", ".", "device", ")", "\n", "enc", ",", "dec", "=", "self", ".", "rel_enc", "[", "0", "]", ",", "self", ".", "rel_enc", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "seq_len", "-", "1", ")", ":", "\n", "                ", "pair", "=", "rel_hashes", "[", ":", ",", "i", ":", "i", "+", "2", "]", ".", "view", "(", "-", "1", ",", "2", "*", "self", ".", "embedding_dim", ")", "# (bs*num_anc, 2 * 100)", "\n", "pair", "=", "enc", "(", "pair", ")", "\n", "accumulator", "+=", "pair", "\n", "", "rel_hashes", "=", "dec", "(", "accumulator", ")", "\n", "", "elif", "self", ".", "use_rels", "==", "\"avg\"", ":", "\n", "            ", "if", "weights", "is", "None", ":", "\n", "                ", "rel_hashes", "=", "(", "rel_hashes", "*", "pad_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "-", "2", ")", "/", "pad_mask", ".", "float", "(", ")", ".", "sum", "(", "-", "1", ")", ".", "clamp_min", "(", "1.0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "rel_hashes", "=", "(", "rel_hashes", "*", "weights", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "-", "2", ")", "/", "pad_mask", ".", "float", "(", ")", ".", "sum", "(", "-", "1", ")", ".", "clamp_min", "(", "1.0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "", "elif", "self", ".", "use_rels", "==", "\"avg+\"", ":", "\n", "            ", "pos", "=", "torch", ".", "arange", "(", "seq_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "rel_hashes", ".", "device", ")", ".", "repeat", "(", "bs", "*", "num_paths", ",", "1", ")", "\n", "pos", "=", "self", ".", "rel_pos", "(", "pos", ")", "\n", "rel_hashes", "=", "torch", ".", "cat", "(", "[", "rel_hashes", ",", "pos", "]", ",", "dim", "=", "-", "1", ")", "\n", "rel_hashes", "=", "self", ".", "rel_enc", "(", "rel_hashes", ")", "\n", "rel_hashes", "=", "(", "rel_hashes", "*", "pad_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "-", "2", ")", "/", "pad_mask", ".", "float", "(", ")", ".", "sum", "(", "-", "1", ")", ".", "clamp_min", "(", "1.0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "elif", "self", ".", "use_rels", "==", "\"trf\"", ":", "\n", "            ", "temp", "=", "torch", ".", "zeros", "(", "(", "rel_hashes", ".", "shape", "[", "1", "]", ",", "rel_hashes", ".", "shape", "[", "0", "]", ",", "rel_hashes", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "rel_hashes", ".", "device", ")", "\n", "positions", "=", "torch", ".", "arange", "(", "0", ",", "seq_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "positions", "=", "self", ".", "rel_pos", "(", "positions", ")", "\n", "nnz_paths", "=", "rel_hashes", "[", "pad_mask", ".", "sum", "(", "1", ")", ">", "0", "]", "\n", "nnz_paths", "+=", "positions", "\n", "nnz_paths", "=", "self", ".", "rel_enc", "(", "nnz_paths", ".", "transpose", "(", "1", ",", "0", ")", ",", "src_key_padding_mask", "=", "~", "pad_mask", "[", "pad_mask", ".", "sum", "(", "1", ")", ">", "0", "]", ")", "# (seq_len, bs, dim)", "\n", "nnz_paths", "[", "torch", ".", "isnan", "(", "nnz_paths", ")", "]", "=", "1.0", "# for numerical stability of empty paths with NOTHING tokens", "\n", "nnz_paths", "[", "torch", ".", "isinf", "(", "nnz_paths", ")", "]", "=", "1.0", "# for numerical stability of empty paths with NOTHING tokens", "\n", "temp", "[", ":", ",", "pad_mask", ".", "sum", "(", "1", ")", ">", "0", ",", ":", "]", "=", "nnz_paths", "\n", "rel_hashes", "=", "temp", "\n", "rel_hashes", "=", "(", "rel_hashes", "*", "pad_mask", ".", "t", "(", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "0", ")", "/", "pad_mask", ".", "float", "(", ")", ".", "sum", "(", "1", ")", ".", "clamp_min", "(", "1.0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "#rel_hashes = rel_hashes.mean(0)", "\n", "", "elif", "self", ".", "use_rels", "==", "\"int\"", ":", "\n", "# replace padding 0's with 1's to prevent nans in the rotate computation", "\n", "            ", "rel_hashes", "[", "~", "pad_mask", "]", "=", "1.0", "\n", "start", "=", "rel_hashes", "[", ":", ",", "0", ",", ":", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "target", "=", "rel_hashes", "[", ":", ",", "i", ",", ":", "]", "\n", "interaction", "=", "self", ".", "pairwise_interaction_function", "(", "start", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", ",", "target", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", ")", "\n", "start", "=", "interaction", "\n", "", "rel_hashes", "=", "interaction", "\n", "\n", "\n", "", "return", "rel_hashes", ".", "view", "(", "bs", ",", "num_paths", ",", "self", ".", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.encode_by_index": [[326, 379], ["nodepiece_encoder.NodePieceEncoder.anchor_embeddings", "nodepiece_encoder.NodePieceEncoder.pool_anchors", "nodepiece_encoder.NodePieceEncoder.dist_emb", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nodepiece_encoder.NodePieceEncoder.projection", "nodepiece_encoder.NodePieceEncoder.encode_rels", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nodepiece_encoder.NodePieceEncoder.node_types", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat().to.to", "torch.cat().to.to"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.encode_rels"], ["", "def", "encode_by_index", "(", "self", ",", "entities", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "        ", "hashes", ",", "dists", "=", "self", ".", "hashes", "[", "entities", "]", ",", "self", ".", "distances", "[", "entities", "]", "\n", "\n", "anc_embs", "=", "self", ".", "anchor_embeddings", "(", "hashes", ")", "\n", "mask", "=", "None", "\n", "\n", "if", "self", ".", "use_distances", ":", "\n", "            ", "dist_embs", "=", "self", ".", "dist_emb", "(", "dists", ")", "\n", "anc_embs", "+=", "dist_embs", "\n", "\n", "", "if", "self", ".", "no_anc", ":", "\n", "            ", "anc_embs", "=", "torch", ".", "tensor", "(", "[", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "if", "self", ".", "use_rels", ":", "\n", "            ", "rel_hashes", "=", "self", ".", "rel_hash", "[", "entities", "]", "# (bs, num_relations)", "\n", "path_weights", "=", "self", ".", "path_weights", "[", "entities", "]", "if", "self", ".", "use_mc", "else", "None", "\n", "# if self.rel_gnn:", "\n", "#     self.relation_embeddings.weight.data = self.gnn_encoder(self.relation_embeddings.weight, self.edge_index)", "\n", "if", "self", ".", "use_rels", "!=", "\"joint\"", ":", "\n", "                ", "path_embs", "=", "self", ".", "encode_rels", "(", "rel_hashes", ",", "path_weights", ")", "\n", "if", "self", ".", "policy", "!=", "\"cat\"", ":", "\n", "                    ", "anc_embs", "+=", "path_embs", "\n", "", "else", ":", "\n", "                    ", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "path_embs", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "path_embs", "=", "self", ".", "relation_embeddings", "(", "rel_hashes", ")", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "path_embs", "]", ",", "dim", "=", "1", ")", "\n", "node_types", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros_like", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "torch", ".", "ones_like", "(", "rel_hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "]", ",", "dim", "=", "1", ")", "\n", "node_type_embs", "=", "self", ".", "node_types", "(", "node_types", ")", "\n", "anc_embs", "+=", "node_type_embs", "\n", "mask", "=", "rel_hashes", "==", "self", ".", "num_relations", "\n", "mask", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros_like", "(", "hashes", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "mask", ".", "to", "(", "self", ".", "device", ")", "\n", "]", ",", "dim", "=", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "#set_input[mask] = anc_embs.view(-1, 1)", "\n", "", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "rels", "=", "self", ".", "unique_1hop_relations", "[", "entities", "]", "# (bs, rel_sample_size)", "\n", "rels", "=", "self", ".", "relation_embeddings", "(", "rels", ")", "# (bs, rel_sample_size, dim)", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "rels", "]", ",", "dim", "=", "1", ")", "# (bs, ancs+rel_sample_size, dim)", "\n", "\n", "", "anc_embs", "=", "self", ".", "pool_anchors", "(", "anc_embs", ",", "mask", "=", "mask", ")", "# (bs, dim)", "\n", "\n", "if", "self", ".", "use_neighbor_rels", ":", "\n", "            ", "rels_one_hot", "=", "self", ".", "relation_features", "[", "entities", "]", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "rels_one_hot", "]", ",", "dim", "=", "-", "1", ")", "# (dim + num_relations)", "\n", "anc_embs", "=", "self", ".", "projection", "(", "anc_embs", ")", "# (bs, dim)", "\n", "", "return", "anc_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.get_all_representations": [[381, 426], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "list", "tqdm.tqdm.tqdm", "nodepiece_encoder.NodePieceEncoder.anchor_embeddings", "nodepiece_encoder.NodePieceEncoder.pool_anchors", "range", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "nodepiece_encoder.NodePieceEncoder.encode_by_index", "nodepiece_encoder.NodePieceEncoder.dist_emb", "len", "len", "len", "nodepiece_encoder.NodePieceEncoder.encode_rels", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nodepiece_encoder.NodePieceEncoder.node_types", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat().to.to", "torch.cat().to.to"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.nodepiece_encoder.NodePieceEncoder.encode_rels"], ["", "def", "get_all_representations", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "subbatch", "!=", "0", ":", "\n", "            ", "temp_embs", "=", "torch", ".", "zeros", "(", "(", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "embedding_dim", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "vocab_keys", "=", "list", "(", "range", "(", "len", "(", "self", ".", "hashes", ")", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "                ", "entities", "=", "torch", ".", "tensor", "(", "vocab_keys", "[", "i", ":", "i", "+", "self", ".", "subbatch", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "embs", "=", "self", ".", "encode_by_index", "(", "entities", ")", "\n", "temp_embs", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", "]", "=", "embs", "\n", "\n", "", "return", "temp_embs", "\n", "\n", "", "else", ":", "\n", "            ", "anc_embs", "=", "self", ".", "anchor_embeddings", "(", "self", ".", "hashes", ")", "\n", "mask", "=", "None", "\n", "if", "self", ".", "use_distances", ":", "\n", "                ", "dist_embs", "=", "self", ".", "dist_emb", "(", "self", ".", "distances", ")", "\n", "anc_embs", "+=", "dist_embs", "\n", "", "if", "self", ".", "use_rels", ":", "\n", "\n", "                ", "if", "self", ".", "use_rels", "!=", "\"joint\"", ":", "\n", "                    ", "path_embs", "=", "self", ".", "encode_rels", "(", "self", ".", "rel_hash", ")", "\n", "if", "self", ".", "policy", "!=", "\"cat\"", ":", "\n", "                        ", "anc_embs", "+=", "path_embs", "\n", "", "else", ":", "\n", "                        ", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "path_embs", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "                    ", "path_embs", "=", "self", ".", "relation_embeddings", "(", "self", ".", "rel_hash", ")", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "path_embs", "]", ",", "dim", "=", "1", ")", "\n", "node_types", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros_like", "(", "self", ".", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "torch", ".", "ones_like", "(", "self", ".", "rel_hash", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "]", ",", "dim", "=", "1", ")", "\n", "node_type_embs", "=", "self", ".", "node_types", "(", "node_types", ")", "\n", "anc_embs", "+=", "node_type_embs", "\n", "mask", "=", "self", ".", "rel_hash", "==", "self", ".", "num_relations", "\n", "mask", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros_like", "(", "self", ".", "hashes", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "mask", ".", "to", "(", "self", ".", "device", ")", "\n", "]", ",", "dim", "=", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "", "", "res", "=", "self", ".", "pool_anchors", "(", "anc_embs", ",", "mask", "=", "mask", ")", "\n", "return", "res", "", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils.masked_softmax": [[10, 26], ["torch.exp", "m.float.float", "torch.sum", "torch.max"], "function", ["None"], ["def", "masked_softmax", "(", "x", ",", "m", "=", "None", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"\n    Softmax with mask\n    :param x:\n    :param m:\n    :param dim:\n    :return:\n    \"\"\"", "\n", "if", "m", "is", "not", "None", ":", "\n", "        ", "m", "=", "m", ".", "float", "(", ")", "\n", "x", "=", "x", "*", "m", "\n", "", "e_x", "=", "torch", ".", "exp", "(", "x", "-", "torch", ".", "max", "(", "x", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "        ", "e_x", "=", "e_x", "*", "m", "\n", "", "softmax", "=", "e_x", "/", "(", "torch", ".", "sum", "(", "e_x", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "\n", "return", "softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils.combine": [[28, 64], ["numpy.array", "numpy.concatenate", "args[].keys", "len", "type", "len", "type", "type", "type", "type", "numpy.concatenate", "type", "type"], "function", ["None"], ["", "def", "combine", "(", "*", "args", ":", "Union", "[", "np", ".", "ndarray", ",", "list", ",", "tuple", "]", ")", ":", "\n", "    ", "\"\"\"\n        Used to semi-intelligently combine data splits\n\n        Case A)\n            args is a single element, an ndarray. Return as is.\n        Case B)\n            args are multiple ndarray. Numpy concat them.\n        Case C)\n            args is a single dict. Return as is.\n        Case D)\n            args is multiple dicts. Concat individual elements\n\n    :param args: (see above)\n    :return: A nd array or a dict\n    \"\"\"", "\n", "\n", "# Case A, C", "\n", "if", "len", "(", "args", ")", "==", "1", "and", "type", "(", "args", "[", "0", "]", ")", "is", "not", "dict", ":", "\n", "        ", "return", "np", ".", "array", "(", "args", "[", "0", "]", ")", "\n", "\n", "", "if", "len", "(", "args", ")", "==", "1", "and", "type", "(", "args", ")", "is", "dict", ":", "\n", "        ", "return", "args", "\n", "\n", "# Case B", "\n", "", "if", "type", "(", "args", ")", "is", "tuple", "and", "(", "type", "(", "args", "[", "0", "]", ")", "is", "np", ".", "ndarray", "or", "type", "(", "args", "[", "0", "]", ")", "is", "list", ")", ":", "\n", "# Expected shape will be a x n, b x n. Simple concat will do.", "\n", "        ", "return", "np", ".", "concatenate", "(", "args", ")", "\n", "\n", "# Case D", "\n", "", "if", "type", "(", "args", ")", "is", "tuple", "and", "type", "(", "args", "[", "0", "]", ")", "is", "dict", ":", "\n", "        ", "keys", "=", "args", "[", "0", "]", ".", "keys", "(", ")", "\n", "combined", "=", "{", "}", "\n", "for", "k", "in", "keys", ":", "\n", "            ", "combined", "[", "k", "]", "=", "np", ".", "concatenate", "(", "[", "arg", "[", "k", "]", "for", "arg", "in", "args", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "combined", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils.print_results": [[66, 82], ["numpy.array", "print", "numpy.mean", "numpy.std"], "function", ["None"], ["", "", "def", "print_results", "(", "traces", ":", "List", ")", ":", "\n", "    ", "\"\"\" traces: List of Dicts of\n    \"loss\": train_loss,\n    \"train_rocauc:\": train_rocauc,\n    \"train_prcauc\": train_prcauc,\n    \"train_ap\": train_ap,\n    \"train_hard_acc\": train_hard_acc,\n    \"valid_rocauc\": valid_rocauc,\n    \"valid_prcauc\": valid_prcauc,\n    \"valid_ap\": valid_ap,\n    \"valid_hard_acc\": valid_hard_acc\n    \"\"\"", "\n", "for", "key", "in", "[", "\"train_rocauc\"", ",", "\"train_prcauc\"", ",", "\"train_ap\"", ",", "\"train_hard_acc\"", ",", "\n", "\"valid_rocauc\"", ",", "\"valid_prcauc\"", ",", "\"valid_ap\"", ",", "\"valid_hard_acc\"", "]", ":", "\n", "        ", "result", "=", "np", ".", "array", "(", "[", "t", "[", "key", "]", "[", "-", "1", "]", "for", "t", "in", "traces", "]", ")", "\n", "print", "(", "f\"Avg {key}: {np.mean(result): .3f}, std dev: {np.std(result):.3f}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.sample_negatives.sample_negatives": [[8, 46], ["collections.defaultdict", "collections.defaultdict", "enumerate", "torch.tensor", "torch.tensor", "tail_index[].append", "head_index[].append", "head_samples[].append", "tail_samples[].append", "triple[].item", "triple[].item", "triple[].item", "row[].item", "row[].item", "row[].item", "len", "numpy.random.choice", "len", "numpy.random.choice", "range", "range", "head_samples[].append", "tail_samples[].append", "len", "len"], "function", ["None"], ["def", "sample_negatives", "(", "valid_triples", ":", "TriplesFactory", ",", "all_pos", ":", "TriplesFactory", ",", "num_samples", ":", "int", "=", "50", ")", ":", "\n", "\n", "    ", "val_triples", "=", "valid_triples", ".", "mapped_triples", "\n", "all_pos_triples", "=", "all_pos", ".", "mapped_triples", "\n", "num_entities", "=", "all_pos", ".", "num_entities", "\n", "\n", "head_samples", ",", "tail_samples", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "val_triples", ")", ")", "]", ",", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "val_triples", ")", ")", "]", "\n", "\n", "head_index", "=", "defaultdict", "(", "list", ")", "\n", "tail_index", "=", "defaultdict", "(", "list", ")", "\n", "for", "triple", "in", "all_pos_triples", ":", "\n", "        ", "h", ",", "r", ",", "t", "=", "triple", "[", "0", "]", ".", "item", "(", ")", ",", "triple", "[", "1", "]", ".", "item", "(", ")", ",", "triple", "[", "2", "]", ".", "item", "(", ")", "\n", "tail_index", "[", "(", "h", ",", "r", ")", "]", ".", "append", "(", "t", ")", "\n", "head_index", "[", "(", "r", ",", "t", ")", "]", ".", "append", "(", "h", ")", "\n", "\n", "", "for", "i", ",", "row", "in", "enumerate", "(", "val_triples", ")", ":", "\n", "        ", "head", ",", "rel", ",", "tail", "=", "row", "[", "0", "]", ".", "item", "(", ")", ",", "row", "[", "1", "]", ".", "item", "(", ")", ",", "row", "[", "2", "]", ".", "item", "(", ")", "\n", "\n", "head_samples", "[", "i", "]", ".", "append", "(", "head", ")", "\n", "while", "len", "(", "head_samples", "[", "i", "]", ")", "<", "num_samples", ":", "\n", "\n", "            ", "neg_head", "=", "np", ".", "random", ".", "choice", "(", "num_entities", ")", "\n", "\n", "if", "neg_head", "!=", "head", "and", "neg_head", "not", "in", "head_index", "[", "(", "rel", ",", "tail", ")", "]", ":", "\n", "                ", "head_samples", "[", "i", "]", ".", "append", "(", "neg_head", ")", "\n", "\n", "", "", "tail_samples", "[", "i", "]", ".", "append", "(", "tail", ")", "\n", "\n", "while", "len", "(", "tail_samples", "[", "i", "]", ")", "<", "num_samples", ":", "\n", "\n", "            ", "neg_tail", "=", "np", ".", "random", ".", "choice", "(", "num_entities", ")", "\n", "if", "neg_tail", "!=", "tail", "and", "neg_tail", "not", "in", "tail_index", "[", "(", "head", ",", "rel", ")", "]", ":", "\n", "                ", "tail_samples", "[", "i", "]", ".", "append", "(", "neg_tail", ")", "\n", "\n", "", "", "", "head_samples", "=", "torch", ".", "tensor", "(", "head_samples", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "tail_samples", "=", "torch", ".", "tensor", "(", "tail_samples", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "head_samples", ",", "tail_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.data_loaders.clean_datasets.to_sparse_graph": [[14, 40], ["enumerate", "numpy.zeros", "numpy.zeros", "numpy.stack", "len", "range", "len", "numpy.array", "numpy.array", "qualifier_rel.append", "qualifier_ent.append", "qualifier_edge.append"], "function", ["None"], ["def", "to_sparse_graph", "(", "edges", ",", "subtype", ",", "entoid", ",", "prtoid", ",", "maxlen", ")", ":", "\n", "\n", "    ", "edge_index", ",", "edge_type", "=", "np", ".", "zeros", "(", "(", "2", ",", "len", "(", "edges", ")", ")", ",", "dtype", "=", "'int64'", ")", ",", "np", ".", "zeros", "(", "(", "len", "(", "edges", ")", ")", ",", "dtype", "=", "'int64'", ")", "\n", "qualifier_rel", "=", "[", "]", "\n", "qualifier_ent", "=", "[", "]", "\n", "qualifier_edge", "=", "[", "]", "\n", "quals", "=", "None", "\n", "\n", "for", "i", ",", "st", "in", "enumerate", "(", "edges", ")", ":", "\n", "        ", "edge_index", "[", ":", ",", "i", "]", "=", "[", "entoid", "[", "st", "[", "0", "]", "]", ",", "entoid", "[", "st", "[", "2", "]", "]", "]", "\n", "edge_type", "[", "i", "]", "=", "prtoid", "[", "st", "[", "1", "]", "]", "\n", "\n", "if", "subtype", "==", "'statements'", ":", "\n", "            ", "qual_rel", "=", "np", ".", "array", "(", "[", "prtoid", "[", "r", "]", "for", "r", "in", "st", "[", "3", ":", ":", "2", "]", "]", ")", "[", "\n", ":", "(", "maxlen", "-", "3", ")", "//", "2", "]", "# cut to the max allowed qualifiers per statement", "\n", "qual_ent", "=", "np", ".", "array", "(", "[", "entoid", "[", "e", "]", "for", "e", "in", "st", "[", "4", ":", ":", "2", "]", "]", ")", "[", "\n", ":", "(", "maxlen", "-", "3", ")", "//", "2", "]", "# cut to the max allowed qualifiers per statement", "\n", "for", "j", "in", "range", "(", "qual_ent", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "qualifier_rel", ".", "append", "(", "qual_rel", "[", "j", "]", ")", "\n", "qualifier_ent", ".", "append", "(", "qual_ent", "[", "j", "]", ")", "\n", "qualifier_edge", ".", "append", "(", "i", ")", "\n", "\n", "", "", "", "if", "subtype", "==", "'statements'", ":", "\n", "        ", "quals", "=", "np", ".", "stack", "(", "(", "qualifier_rel", ",", "qualifier_ent", ",", "qualifier_edge", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "edge_index", ",", "edge_type", ",", "quals", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.data_loaders.clean_datasets.load_clean_pyg": [[42, 160], ["numpy.load", "numpy.array", "print", "print", "clean_datasets.to_sparse_graph", "sorted", "print", "torch_geometric.data.Data", "pathlib.Path", "print", "pathlib.Path", "print", "print", "print", "l.strip", "l.strip", "open", "json.load", "open", "json.load", "open", "json.load", "line.strip", "numpy.random.permutation", "clean_datasets.to_sparse_graph", "clean_datasets.to_sparse_graph", "print", "list", "torch_geometric.data.Data", "torch_geometric.data.Data", "len", "len", "line.strip().split", "line.strip().split", "line.strip().split", "line.strip().split", "open().readlines", "open().readlines", "enumerate", "enumerate", "enumerate", "set", "enumerate", "label2id.items", "json.load.items", "json.load.items", "json.load.items", "torch.tensor", "torch.tensor", "torch.tensor", "open().readlines", "open().readlines", "open().readlines", "open().readlines", "open().readlines", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "line.strip", "len", "len", "round", "line.strip", "line.strip", "line.strip", "len", "len", "round", "len", "len", "round", "len", "len", "round", "open", "open", "len", "len", "len", "torch.tensor", "torch.tensor", "open", "open", "open", "open", "open", "len", "len", "len", "len", "len", "len", "len", "len", "list", "list", "list", "json.load.values", "len", "len", "len", "len", "json.load.values", "json.load.values", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.data_loaders.clean_datasets.to_sparse_graph", "home.repos.pwc.inspect_result.migalkin_NodePiece.data_loaders.clean_datasets.to_sparse_graph", "home.repos.pwc.inspect_result.migalkin_NodePiece.data_loaders.clean_datasets.to_sparse_graph"], ["", "def", "load_clean_pyg", "(", "name", ",", "subtype", ",", "task", ",", "inductive", "=", "\"transductive\"", ",", "ind_v", "=", "None", ",", "maxlen", "=", "43", ",", "permute", "=", "False", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"\n    :param name: dataset name wd50k/wd50k_33/wd50k_66/wd50k_100\n    :param subtype: triples/statements\n    :param task: so/full predict entities at sub/obj positions (for triples/statements) or all nodes incl quals\n    :param inductive: whether to load transductive dataset (one graph for train/val/test) or inductive\n    :param ind_v: v1 / v2 for the inductive dataset\n    :param maxlen: max statement length\n    :return: train/valid/test splits for the wd50k datasets suitable for loading into TORCH GEOMETRIC dataset\n    no reciprocal edges (as will be added in the gnn layer), create directly the edge index\n    \"\"\"", "\n", "assert", "name", "in", "[", "'wd50k'", ",", "'wd50k_100'", ",", "'wd50k_33'", ",", "'wd50k_66'", "]", ",", "\"Incorrect dataset\"", "\n", "assert", "subtype", "in", "[", "\"triples\"", ",", "\"statements\"", "]", ",", "\"Incorrect subtype: triples/statements\"", "\n", "assert", "inductive", "in", "[", "\"transductive\"", ",", "\"inductive\"", "]", ",", "\"Incorrect ds type: only transductive and inductive accepted\"", "\n", "if", "inductive", "==", "\"inductive\"", ":", "\n", "        ", "assert", "ind_v", "in", "[", "\"v1\"", ",", "\"v2\"", "]", ",", "\"Only v1 and v2 are allowed versions for the inductive task\"", "\n", "\n", "", "if", "inductive", "==", "\"transductive\"", ":", "\n", "        ", "DIRNAME", "=", "Path", "(", "f'./data/clean/{name}/{subtype}'", ")", "\n", "train_edges", "=", "[", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\",\"", ")", "for", "line", "in", "open", "(", "DIRNAME", "/", "'nc_edges.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "print", "(", "f\"Transductive: With quals: {len([t for t in train_edges if len(t)>3])} / {len(train_edges)}, Ratio: {round((len([t for t in train_edges if len(t)>3]) / len(train_edges)),2)}\"", ")", "\n", "", "else", ":", "\n", "        ", "DIRNAME", "=", "Path", "(", "f'./data/clean/{name}/inductive/nc/{subtype}/{ind_v}'", ")", "\n", "train_edges", "=", "[", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\",\"", ")", "for", "line", "in", "open", "(", "DIRNAME", "/", "'nc_train_edges.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "val_edges", "=", "[", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\",\"", ")", "for", "line", "in", "open", "(", "DIRNAME", "/", "'nc_val_edges.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "test_edges", "=", "[", "line", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\",\"", ")", "for", "line", "in", "open", "(", "DIRNAME", "/", "'nc_test_edges.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "print", "(", "\n", "f\"Inductive train: With quals: {len([t for t in train_edges if len(t) > 3])} / {len(train_edges)}, Ratio: {round((len([t for t in train_edges if len(t) > 3]) / len(train_edges)), 2)}\"", ")", "\n", "print", "(", "\n", "f\"Inductive val: With quals: {len([t for t in val_edges if len(t) > 3])} / {len(val_edges)}, Ratio: {round((len([t for t in val_edges if len(t) > 3]) / len(val_edges)), 2)}\"", ")", "\n", "print", "(", "\n", "f\"Inductive test: With quals: {len([t for t in test_edges if len(t) > 3])} / {len(test_edges)}, Ratio: {round((len([t for t in test_edges if len(t) > 3]) / len(test_edges)), 2)}\"", ")", "\n", "\n", "", "statement_entities", "=", "[", "l", ".", "strip", "(", "\"\\n\"", ")", "for", "l", "in", "open", "(", "DIRNAME", "/", "'nc_entities.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "statement_predicates", "=", "[", "l", ".", "strip", "(", "\"\\n\"", ")", "for", "l", "in", "open", "(", "DIRNAME", "/", "'nc_rels.txt'", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "\n", "if", "subtype", "==", "\"triples\"", ":", "\n", "        ", "task", "=", "\"so\"", "\n", "\n", "", "with", "open", "(", "DIRNAME", "/", "f'nc_train_{task}_labels.json'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "train_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "DIRNAME", "/", "f'nc_val_{task}_labels.json'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "val_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "DIRNAME", "/", "f'nc_test_{task}_labels.json'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "test_labels", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# load node features with the total index", "\n", "", "entity_index", "=", "{", "line", ".", "strip", "(", "'\\n'", ")", ":", "i", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "f'./data/clean/{name}/statements/{name}_entity_index.txt'", ")", ".", "readlines", "(", ")", ")", "}", "\n", "total_node_features", "=", "np", ".", "load", "(", "f'./data/clean/{name}/statements/{name}_embs.pkl'", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "idx", "=", "np", ".", "array", "(", "[", "entity_index", "[", "key", "]", "for", "key", "in", "statement_entities", "]", ",", "dtype", "=", "'int32'", ")", "\n", "node_features", "=", "total_node_features", "[", "idx", "]", "\n", "\n", "if", "permute", ":", "\n", "        ", "node_features", "=", "np", ".", "random", ".", "permutation", "(", "node_features", ")", "\n", "\n", "", "entoid", "=", "{", "pred", ":", "i", "for", "i", ",", "pred", "in", "enumerate", "(", "statement_entities", ")", "}", "\n", "prtoid", "=", "{", "pred", ":", "i", "for", "i", ",", "pred", "in", "enumerate", "(", "statement_predicates", ")", "}", "\n", "\n", "print", "(", "f\"Total Entities: {len(entoid)}\"", ")", "\n", "print", "(", "f\"Total Rels: {len(prtoid)}\"", ")", "\n", "\n", "train_edge_index", ",", "train_edge_type", ",", "train_quals", "=", "to_sparse_graph", "(", "train_edges", ",", "subtype", ",", "entoid", ",", "prtoid", ",", "maxlen", ")", "\n", "if", "inductive", "==", "\"inductive\"", ":", "\n", "        ", "val_edge_index", ",", "val_edge_type", ",", "val_quals", "=", "to_sparse_graph", "(", "val_edges", ",", "subtype", ",", "entoid", ",", "prtoid", ",", "maxlen", ")", "\n", "test_edge_index", ",", "test_edge_type", ",", "test_quals", "=", "to_sparse_graph", "(", "test_edges", ",", "subtype", ",", "entoid", ",", "prtoid", ",", "maxlen", ")", "\n", "\n", "\n", "", "train_mask", "=", "[", "entoid", "[", "e", "]", "for", "e", "in", "train_labels", "]", "\n", "val_mask", "=", "[", "entoid", "[", "e", "]", "for", "e", "in", "val_labels", "]", "\n", "test_mask", "=", "[", "entoid", "[", "e", "]", "for", "e", "in", "test_labels", "]", "\n", "\n", "if", "inductive", "==", "\"inductive\"", ":", "\n", "        ", "print", "(", "f\"Train Ents: {len(train_labels)}, Val Ents: {len(val_labels)}, Test Ents: {len(test_labels)}\"", ")", "\n", "\n", "", "all_labels", "=", "sorted", "(", "list", "(", "set", "(", "[", "\n", "label", "for", "v", "in", "list", "(", "train_labels", ".", "values", "(", ")", ")", "+", "list", "(", "val_labels", ".", "values", "(", ")", ")", "+", "list", "(", "test_labels", ".", "values", "(", ")", ")", "for", "label", "in", "\n", "v", "]", ")", ")", ")", "\n", "label2id", "=", "{", "l", ":", "i", "for", "i", ",", "l", "in", "enumerate", "(", "all_labels", ")", "}", "\n", "id2label", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "label2id", ".", "items", "(", ")", "}", "\n", "print", "(", "f\"Total labels: {len(label2id)}\"", ")", "\n", "\n", "train_y", "=", "{", "entoid", "[", "k", "]", ":", "[", "label2id", "[", "vi", "]", "for", "vi", "in", "v", "]", "for", "k", ",", "v", "in", "train_labels", ".", "items", "(", ")", "}", "\n", "val_y", "=", "{", "entoid", "[", "k", "]", ":", "[", "label2id", "[", "vi", "]", "for", "vi", "in", "v", "]", "for", "k", ",", "v", "in", "val_labels", ".", "items", "(", ")", "}", "\n", "test_y", "=", "{", "entoid", "[", "k", "]", ":", "[", "label2id", "[", "vi", "]", "for", "vi", "in", "v", "]", "for", "k", ",", "v", "in", "test_labels", ".", "items", "(", ")", "}", "\n", "\n", "train_graph", "=", "Data", "(", "x", "=", "torch", ".", "tensor", "(", "node_features", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "edge_index", "=", "torch", ".", "tensor", "(", "train_edge_index", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "edge_type", "=", "torch", ".", "tensor", "(", "train_edge_type", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "quals", "=", "torch", ".", "tensor", "(", "train_quals", ",", "dtype", "=", "torch", ".", "long", ")", "if", "train_quals", "is", "not", "None", "else", "None", ",", "y", "=", "train_y", ")", "\n", "\n", "# explicit fix for PyG > 2.0 as its new data creation procedure uses setattr(obj, key, value) which does not", "\n", "# assign None values, such that quals=None does not lead to creating the `quals` with value None", "\n", "# so we explicitly set it to 0 - it won't affect any code execution whatsoever", "\n", "if", "train_quals", "is", "None", ":", "\n", "        ", "train_graph", ".", "quals", "=", "0", "\n", "", "val_graph", ",", "test_graph", "=", "None", ",", "None", "\n", "\n", "\n", "\n", "if", "inductive", "==", "\"inductive\"", ":", "\n", "        ", "val_graph", "=", "Data", "(", "x", "=", "torch", ".", "tensor", "(", "node_features", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "edge_index", "=", "torch", ".", "tensor", "(", "val_edge_index", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "edge_type", "=", "torch", ".", "tensor", "(", "val_edge_type", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "quals", "=", "torch", ".", "tensor", "(", "val_quals", ",", "dtype", "=", "torch", ".", "long", ")", "if", "val_quals", "is", "not", "None", "else", "None", ",", "y", "=", "val_y", ")", "\n", "test_graph", "=", "Data", "(", "x", "=", "torch", ".", "tensor", "(", "node_features", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "edge_index", "=", "torch", ".", "tensor", "(", "test_edge_index", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "edge_type", "=", "torch", ".", "tensor", "(", "test_edge_type", ",", "dtype", "=", "torch", ".", "long", ")", ",", "\n", "quals", "=", "torch", ".", "tensor", "(", "test_quals", ",", "dtype", "=", "torch", ".", "long", ")", "if", "test_quals", "is", "not", "None", "else", "None", ",", "y", "=", "test_y", ")", "\n", "\n", "", "return", "{", "\"train_graph\"", ":", "train_graph", ",", "\"val_graph\"", ":", "val_graph", ",", "\"test_graph\"", ":", "test_graph", ",", "\n", "\"train_mask\"", ":", "train_mask", ",", "\"valid_mask\"", ":", "val_mask", ",", "\"test_mask\"", ":", "test_mask", ",", "\n", "\"train_y\"", ":", "train_y", ",", "\"val_y\"", ":", "val_y", ",", "\"test_y\"", ":", "test_y", ",", "\n", "\"all_labels\"", ":", "all_labels", ",", "\"label2id\"", ":", "label2id", ",", "\"id2label\"", ":", "id2label", ",", "\n", "\"n_entities\"", ":", "len", "(", "statement_entities", ")", ",", "\"n_relations\"", ":", "len", "(", "statement_predicates", ")", ",", "\n", "\"e2id\"", ":", "entoid", ",", "\"r2id\"", ":", "prtoid", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.nc_baselines.MLP.__init__": [[11, 33], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "utils.utils_gcn.get_param", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "range"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param"], ["def", "__init__", "(", "self", ",", "initial_features", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "initial_features", ".", "shape", "[", "1", "]", "\n", "self", ".", "hidden", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "\n", "self", ".", "num_layers", "=", "config", "[", "'STAREARGS'", "]", "[", "'LAYERS'", "]", "\n", "self", ".", "num_classes", "=", "config", "[", "'NUM_CLASSES'", "]", "\n", "self", ".", "dropout", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DROP'", "]", "\n", "self", ".", "use_features", "=", "config", "[", "'USE_FEATURES'", "]", "\n", "self", ".", "device", "=", "config", "[", "'DEVICE'", "]", "\n", "\n", "if", "not", "config", "[", "'USE_FEATURES'", "]", ":", "\n", "            ", "self", ".", "entity_embeddings", "=", "get_param", "(", "(", "config", "[", "'NUM_ENTITIES'", "]", ",", "config", "[", "'EMBEDDING_DIM'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_features", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros", "(", "(", "1", ",", "initial_features", ".", "shape", "[", "1", "]", ")", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "torch", ".", "tensor", "(", "initial_features", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "hidden", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", ",", "\n", "*", "[", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hidden", ",", "self", ".", "hidden", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "2", ")", "]", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hidden", ",", "self", ".", "num_classes", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.nc_baselines.MLP.forward": [[35, 47], ["torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "train_mask", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_features", ":", "\n", "            ", "x", "=", "self", ".", "entity_embeddings", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "node_features", "\n", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "\n", "", "probs", "=", "torch", ".", "index_select", "(", "x", ",", "0", ",", "train_mask", ")", "\n", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.nc_baselines.MLP_PyG.__init__": [[53, 80], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "utils.utils_gcn.get_param", "torch.Embedding", "torch.Embedding", "utils.nodepiece_encoder.NodePieceEncoder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "range"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param"], ["def", "__init__", "(", "self", ",", "config", ",", "tokenizer", ",", "graph", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "#self.input_dim = config['FEATURE_DIM']", "\n", "self", ".", "hidden", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "\n", "self", ".", "num_layers", "=", "config", "[", "'STAREARGS'", "]", "[", "'LAYERS'", "]", "\n", "self", ".", "num_classes", "=", "config", "[", "'NUM_CLASSES'", "]", "\n", "self", ".", "dropout", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DROP'", "]", "\n", "self", ".", "use_features", "=", "config", "[", "'USE_FEATURES'", "]", "\n", "self", ".", "device", "=", "config", "[", "'DEVICE'", "]", "\n", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "if", "not", "config", "[", "'USE_FEATURES'", "]", ":", "\n", "            ", "self", ".", "input_dim", "=", "config", "[", "'EMBEDDING_DIM'", "]", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "self", ".", "entity_embeddings", "=", "get_param", "(", "(", "config", "[", "'NUM_ENTITIES'", "]", ",", "self", ".", "input_dim", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "init_rel", "=", "nn", ".", "Embedding", "(", "config", "[", "'NUM_RELATIONS'", "]", "*", "2", "+", "1", ",", "self", ".", "input_dim", ")", "\n", "self", ".", "embedder", "=", "NodePieceEncoder", "(", "config", ",", "tokenizer", ",", "rel_embs", "=", "self", ".", "init_rel", ",", "graph", "=", "graph", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "input_dim", "=", "config", "[", "'FEATURE_DIM'", "]", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "hidden", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", ",", "\n", "*", "[", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hidden", ",", "self", ".", "hidden", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "2", ")", "]", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hidden", ",", "self", ".", "num_classes", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.nc_baselines.MLP_PyG.reset_parameters": [[82, 91], ["layer.apply", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "nc_baselines.MLP_PyG.embedder.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "layer", ".", "apply", "(", "weight_init", ")", "\n", "", "if", "not", "self", ".", "use_features", ":", "\n", "            ", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "entity_embeddings", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "init_rel", ".", "weight", ".", "data", ")", "\n", "self", ".", "embedder", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.nc_baselines.MLP_PyG.forward": [[92, 108], ["torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "layer", "nc_baselines.MLP_PyG.embedder.get_all_representations"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations"], ["", "", "", "def", "forward", "(", "self", ",", "graph", ",", "train_mask", ")", ":", "\n", "\n", "        ", "if", "not", "self", ".", "use_features", ":", "\n", "            ", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "x", "=", "self", ".", "entity_embeddings", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "embedder", ".", "get_all_representations", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "x", "=", "graph", "[", "'x'", "]", "\n", "\n", "", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "\n", "", "probs", "=", "torch", ".", "index_select", "(", "x", ",", "0", ",", "train_mask", ")", "\n", "\n", "return", "probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_encoder.StarE_PyG_Encoder.__init__": [[17, 88], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "gnn_encoder.StarE_PyG_Encoder.init_rel.to", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "gnn_encoder.StarE_PyG_Encoder.convs.append", "range", "gnn_encoder.StarE_PyG_Encoder.register_parameter", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "gnn_layer.StarEConvLayer", "gnn_encoder.StarE_PyG_Encoder.attention.append", "gnn_encoder.StarE_PyG_Encoder.dim_reduction.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "gnn_encoder.StarE_PyG_Encoder.convs.append", "torch.nn.Parameter", "torch.nn.Parameter", "utils.utils_gcn.get_param", "utils.nodepiece_encoder.NodePieceEncoder", "lrga_model.LowRankAttention", "torch.nn.Sequential", "torch.nn.Sequential", "gnn_layer.StarEConvLayer", "gnn_encoder.StarE_PyG_Encoder.attention.append", "gnn_encoder.StarE_PyG_Encoder.dim_reduction.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "lrga_model.LowRankAttention", "torch.nn.Sequential", "torch.nn.Sequential", "range", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "dict", ",", "tokenizer", ":", "NodePiece_Tokenizer", "=", "None", ",", "graph", ":", "Data", "=", "None", ")", ":", "\n", "        ", "super", "(", "StarE_PyG_Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "torch", ".", "relu", "# was tanh before", "\n", "self", ".", "model_nm", "=", "config", "[", "'MODEL_NAME'", "]", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "emb_dim", "=", "config", "[", "'EMBEDDING_DIM'", "]", "\n", "self", ".", "num_rel", "=", "config", "[", "'NUM_RELATIONS'", "]", "\n", "self", ".", "num_ent", "=", "config", "[", "'NUM_ENTITIES'", "]", "\n", "self", ".", "gcn_dim", "=", "config", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "\n", "self", ".", "hid_drop", "=", "config", "[", "'STAREARGS'", "]", "[", "'HID_DROP'", "]", "\n", "# self.bias = config['STAREARGS']['BIAS']", "\n", "self", ".", "triple_mode", "=", "config", "[", "'STATEMENT_LEN'", "]", "==", "3", "\n", "self", ".", "qual_mode", "=", "config", "[", "'STAREARGS'", "]", "[", "'QUAL_REPR'", "]", "\n", "\n", "self", ".", "device", "=", "config", "[", "'DEVICE'", "]", "\n", "\n", "self", ".", "num_layers", "=", "config", "[", "'STAREARGS'", "]", "[", "'LAYERS'", "]", "\n", "\n", "# self.gcn_dim = self.emb_dim if self.n_layer == 1 else self.gcn_dim", "\n", "\n", "\"\"\"\n            LRGA params\n        \"\"\"", "\n", "self", ".", "use_lrga", "=", "config", "[", "'STAREARGS'", "]", "[", "'LRGA'", "]", "\n", "self", ".", "lrga_k", "=", "config", "[", "'STAREARGS'", "]", "[", "'LRGA_K'", "]", "\n", "self", ".", "lrga_drop", "=", "config", "[", "'STAREARGS'", "]", "[", "'LRGA_DROP'", "]", "\n", "\n", "# if self.model_nm.endswith('transe'):", "\n", "#     self.init_rel = get_param((self.num_rel, self.emb_dim))", "\n", "# elif config['STAREARGS']['OPN'] == 'rotate' or config['STAREARGS']['QUAL_OPN'] == 'rotate':", "\n", "#     phases = 2 * np.pi * torch.rand(self.num_rel, self.emb_dim // 2)", "\n", "#     self.init_rel = nn.Parameter(torch.cat([", "\n", "#         torch.cat([torch.cos(phases), torch.sin(phases)], dim=-1),", "\n", "#         torch.cat([torch.cos(phases), -torch.sin(phases)], dim=-1)", "\n", "#     ], dim=0))", "\n", "# else:", "\n", "#     self.init_rel = get_param((self.num_rel * 2, self.emb_dim))", "\n", "self", ".", "init_rel", "=", "nn", ".", "Embedding", "(", "self", ".", "num_rel", "*", "2", "+", "1", ",", "self", ".", "emb_dim", ",", "padding_idx", "=", "self", ".", "num_rel", "*", "2", ")", "\n", "\n", "self", ".", "init_rel", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "if", "not", "config", "[", "'USE_FEATURES'", "]", ":", "\n", "            ", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "self", ".", "entity_embeddings", "=", "get_param", "(", "(", "self", ".", "num_ent", ",", "self", ".", "emb_dim", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "embedder", "=", "NodePieceEncoder", "(", "config", ",", "tokenizer", ",", "rel_embs", "=", "self", ".", "init_rel", ",", "graph", "=", "graph", ")", "\n", "\n", "\n", "", "", "self", ".", "feature_reduction", "=", "nn", ".", "Linear", "(", "config", "[", "'FEATURE_DIM'", "]", ",", "self", ".", "emb_dim", ")", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "self", ".", "attention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dim_reduction", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# populating manually first and last layers, otherwise in a loop", "\n", "", "self", ".", "convs", ".", "append", "(", "StarEConvLayer", "(", "self", ".", "emb_dim", ",", "self", ".", "gcn_dim", ",", "self", ".", "num_rel", ",", "act", "=", "self", ".", "act", ",", "config", "=", "config", ")", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "self", ".", "attention", ".", "append", "(", "LowRankAttention", "(", "self", ".", "lrga_k", ",", "self", ".", "emb_dim", ",", "self", ".", "lrga_drop", ")", ")", "\n", "self", ".", "dim_reduction", ".", "append", "(", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2", "*", "self", ".", "lrga_k", "+", "self", ".", "gcn_dim", "+", "self", ".", "emb_dim", ",", "self", ".", "gcn_dim", ")", ")", ")", "\n", "self", ".", "bns", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "BatchNorm1d", "(", "self", ".", "gcn_dim", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", "]", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "convs", ".", "append", "(", "StarEConvLayer", "(", "self", ".", "gcn_dim", ",", "self", ".", "gcn_dim", ",", "self", ".", "num_rel", ",", "act", "=", "self", ".", "act", ",", "config", "=", "config", ")", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "                ", "self", ".", "attention", ".", "append", "(", "LowRankAttention", "(", "self", ".", "lrga_k", ",", "self", ".", "gcn_dim", ",", "self", ".", "lrga_drop", ")", ")", "\n", "self", ".", "dim_reduction", ".", "append", "(", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2", "*", "(", "self", ".", "lrga_k", "+", "self", ".", "gcn_dim", ")", ",", "self", ".", "gcn_dim", ")", ")", ")", "\n", "\n", "", "", "self", ".", "register_parameter", "(", "'bias'", ",", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "num_ent", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_encoder.StarE_PyG_Encoder.reset_parameters": [[89, 119], ["gnn_encoder.StarE_PyG_Encoder.feature_reduction.apply", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.stack().detach", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.stack().detach.view", "torch.stack().detach.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "conv.reset_parameters", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "phases.new_ones", "att.apply", "dim_r.apply", "bnorm.reset_parameters", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "gnn_encoder.StarE_PyG_Encoder.embedder.reset_parameters", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.sin", "torch.sin", "torch.sin", "torch.sin"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'rotate'", "or", "self", ".", "config", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'rotate'", ":", "\n", "# phases = 2 * np.pi * torch.rand(self.num_rel, self.emb_dim // 2)", "\n", "# self.init_rel = nn.Parameter(torch.cat([", "\n", "#     torch.cat([torch.cos(phases), torch.sin(phases)], dim=-1),", "\n", "#     torch.cat([torch.cos(phases), -torch.sin(phases)], dim=-1)", "\n", "# ], dim=0))", "\n", "            ", "phases", "=", "2", "*", "np", ".", "pi", "*", "torch", ".", "rand", "(", "self", ".", "num_rel", "*", "2", ",", "self", ".", "emb_dim", "//", "2", ",", "device", "=", "self", ".", "device", ")", "\n", "relations", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cos", "(", "phases", ")", ",", "torch", ".", "sin", "(", "phases", ")", "]", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "torch", ".", "norm", "(", "relations", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", ",", "phases", ".", "new_ones", "(", "size", "=", "(", "1", ",", "1", ")", ")", ")", "\n", "self", ".", "init_rel", ".", "weight", ".", "data", "[", ":", "-", "1", "]", "=", "relations", ".", "view", "(", "self", ".", "num_rel", "*", "2", ",", "self", ".", "emb_dim", ")", "\n", "self", ".", "init_rel", ".", "weight", ".", "data", "[", "-", "1", "]", "=", "torch", ".", "zeros", "(", "self", ".", "emb_dim", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "init_rel", ".", "weight", ".", "data", ")", "\n", "", "self", ".", "feature_reduction", ".", "apply", "(", "weight_init", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ".", "data", ",", "0", ")", "\n", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "conv", ".", "reset_parameters", "(", ")", "\n", "", "if", "self", ".", "use_lrga", ":", "\n", "            ", "for", "att", "in", "self", ".", "attention", ":", "\n", "                ", "att", ".", "apply", "(", "weight_init", ")", "\n", "", "for", "dim_r", "in", "self", ".", "dim_reduction", ":", "\n", "                ", "dim_r", ".", "apply", "(", "weight_init", ")", "\n", "", "for", "bnorm", "in", "self", ".", "bns", ":", "\n", "                ", "bnorm", ".", "reset_parameters", "(", ")", "\n", "", "", "if", "not", "self", ".", "config", "[", "'USE_FEATURES'", "]", ":", "\n", "            ", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "entity_embeddings", ".", "data", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "embedder", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_encoder.StarE_PyG_Encoder.post_parameter_update": [[121, 125], ["gnn_encoder.StarE_PyG_Encoder.init_rel.weight.data.view", "torch.normalize", "torch.normalize", "torch.normalize.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize"], ["", "", "", "def", "post_parameter_update", "(", "self", ")", ":", "\n", "        ", "rel", "=", "self", ".", "init_rel", ".", "weight", ".", "data", ".", "view", "(", "self", ".", "num_rel", "*", "2", "+", "1", ",", "self", ".", "emb_dim", "//", "2", ",", "2", ")", "\n", "rel", "=", "F", ".", "normalize", "(", "rel", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "self", ".", "init_rel", ".", "weight", ".", "data", "=", "rel", ".", "view", "(", "self", ".", "num_rel", "*", "2", "+", "1", ",", "self", ".", "emb_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_encoder.StarE_PyG_Encoder.forward_base": [[127, 176], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "drop2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gnn_encoder.StarE_PyG_Encoder.feature_reduction", "conv", "drop1", "gnn_encoder.StarE_PyG_Encoder.model_nm.endswith", "gnn_encoder.StarE_PyG_Encoder.embedder.get_all_representations", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations"], ["", "def", "forward_base", "(", "self", ",", "graph", ",", "drop1", ",", "drop2", ")", ":", "\n", "\n", "        ", "x", ",", "edge_index", ",", "edge_type", ",", "quals", "=", "graph", "[", "'x'", "]", ",", "graph", "[", "'edge_index'", "]", ",", "graph", "[", "'edge_type'", "]", ",", "graph", "[", "'quals'", "]", "\n", "\n", "# Add reverse stuff", "\n", "reverse_index", "=", "torch", ".", "zeros_like", "(", "edge_index", ")", "\n", "reverse_index", "[", "1", ",", ":", "]", "=", "edge_index", "[", "0", ",", ":", "]", "\n", "reverse_index", "[", "0", ",", ":", "]", "=", "edge_index", "[", "1", ",", ":", "]", "\n", "rev_edge_type", "=", "edge_type", "+", "self", ".", "num_rel", "\n", "\n", "edge_index", "=", "torch", ".", "cat", "(", "[", "edge_index", ",", "reverse_index", "]", ",", "dim", "=", "1", ")", "\n", "edge_type", "=", "torch", ".", "cat", "(", "[", "edge_type", ",", "rev_edge_type", "]", ",", "dim", "=", "0", ")", "\n", "\n", "if", "not", "self", ".", "triple_mode", ":", "\n", "            ", "quals", "=", "torch", ".", "cat", "(", "[", "quals", ",", "quals", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "r", "=", "self", ".", "init_rel", ".", "weight", "if", "not", "self", ".", "model_nm", ".", "endswith", "(", "'transe'", ")", "else", "torch", ".", "cat", "(", "[", "self", ".", "init_rel", ".", "weight", ",", "-", "self", ".", "init_rel", ".", "weight", "]", ",", "dim", "=", "0", ")", "\n", "\n", "if", "self", ".", "config", "[", "'USE_FEATURES'", "]", ":", "\n", "            ", "x", "=", "self", ".", "feature_reduction", "(", "x", ")", "# TODO find a way to perform attention without dim reduction beforehand", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "                ", "x", "=", "self", ".", "entity_embeddings", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "embedder", ".", "get_all_representations", "(", ")", "\n", "\n", "\n", "", "", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convs", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "x_local", ",", "r", "=", "conv", "(", "x", "=", "x", ",", "edge_index", "=", "edge_index", ",", "edge_type", "=", "edge_type", ",", "rel_embed", "=", "r", ",", "quals", "=", "quals", ")", "\n", "x_local", "=", "drop1", "(", "x_local", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "                ", "x_global", "=", "self", ".", "attention", "[", "i", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "dim_reduction", "[", "i", "]", "(", "torch", ".", "cat", "(", "(", "x_global", ",", "x_local", ",", "x", ")", ",", "dim", "=", "1", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "bns", "[", "i", "]", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "x_local", "\n", "\n", "# last layer", "\n", "", "", "x_local", ",", "r", "=", "self", ".", "convs", "[", "-", "1", "]", "(", "x", "=", "x", ",", "edge_index", "=", "edge_index", ",", "edge_type", "=", "edge_type", ",", "rel_embed", "=", "r", ",", "quals", "=", "quals", ")", "\n", "x_local", "=", "drop2", "(", "x_local", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "x_global", "=", "self", ".", "attention", "[", "-", "1", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "dim_reduction", "[", "-", "1", "]", "(", "torch", ".", "cat", "(", "(", "x_global", ",", "x_local", ",", "x", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x_local", "\n", "\n", "", "return", "x", ",", "r", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.__init__": [[14, 66], ["torch_geometric.nn.MessagePassing.__init__", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "gnn_layer.StarEConvLayer.register_parameter", "utils.utils_gcn.get_param", "torch.nn.Parameter", "torch.nn.Parameter", "utils.utils_gcn.get_param", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "num_rels", ",", "act", "=", "lambda", "x", ":", "x", ",", "\n", "config", "=", "None", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "flow", "=", "'target_to_source'", ",", "\n", "aggr", "=", "'add'", ")", "\n", "\n", "self", ".", "p", "=", "config", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_rels", "=", "num_rels", "\n", "self", ".", "act", "=", "act", "\n", "self", ".", "device", "=", "None", "\n", "\n", "self", ".", "w_loop", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_in", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_out", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_rel", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'sum'", "or", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'mul'", "or", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "                ", "self", ".", "w_q", "=", "get_param", "(", "(", "in_channels", ",", "in_channels", ")", ")", "# new for quals setup", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'concat'", ":", "\n", "                ", "self", ".", "w_q", "=", "get_param", "(", "(", "2", "*", "in_channels", ",", "in_channels", ")", ")", "# need 2x size due to the concat operation", "\n", "\n", "", "", "self", ".", "loop_rel", "=", "get_param", "(", "(", "1", ",", "in_channels", ")", ")", "# (1,100)", "\n", "self", ".", "loop_ent", "=", "get_param", "(", "(", "1", ",", "in_channels", ")", ")", "# new", "\n", "\n", "self", ".", "drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DROP'", "]", ")", "\n", "self", ".", "bn", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "out_channels", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "            ", "assert", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "==", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", ",", "\"Current attn implementation requires those tto be identical\"", "\n", "assert", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", "%", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "==", "0", ",", "\"should be divisible\"", "\n", "self", ".", "heads", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "\n", "self", ".", "attn_dim", "=", "self", ".", "out_channels", "//", "self", ".", "heads", "\n", "self", ".", "negative_slope", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_SLOPE'", "]", "\n", "self", ".", "attn_drop", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_DROP'", "]", "\n", "self", ".", "att", "=", "get_param", "(", "(", "1", ",", "self", ".", "heads", ",", "2", "*", "self", ".", "attn_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "            ", "assert", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "==", "self", ".", "p", "[", "\n", "'EMBEDDING_DIM'", "]", ",", "\"Current attn implementation requires those tto be identical\"", "\n", "assert", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", "%", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "==", "0", ",", "\"should be divisible\"", "\n", "if", "not", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "                ", "self", ".", "heads", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "\n", "self", ".", "attn_dim", "=", "self", ".", "out_channels", "//", "self", ".", "heads", "\n", "self", ".", "negative_slope", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_SLOPE'", "]", "\n", "self", ".", "attn_drop", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_DROP'", "]", "\n", "", "self", ".", "att_qual", "=", "get_param", "(", "(", "1", ",", "self", ".", "heads", ",", "2", "*", "self", ".", "attn_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'BIAS'", "]", ":", "self", ".", "register_parameter", "(", "'bias'", ",", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "out_channels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.reset_parameters": [[67, 81], ["torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "gnn_layer.StarEConvLayer.bn.reset_parameters", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_loop", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_in", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_out", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_rel", ".", "data", ")", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_q", ".", "data", ")", "\n", "", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "loop_rel", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "loop_ent", ".", "data", ")", "\n", "self", ".", "bn", ".", "reset_parameters", "(", ")", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "att", ".", "data", ")", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "att_qual", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.forward": [[82, 216], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "gnn_layer.StarEConvLayer.compute_norm", "gnn_layer.StarEConvLayer.compute_norm", "gnn_layer.StarEConvLayer.bn", "edge_index.size", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.act", "quals.size", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.full", "torch.full", "torch.full", "torch.full", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "gnn_layer.StarEConvLayer.drop", "gnn_layer.StarEConvLayer.drop", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.compute_norm", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.compute_norm", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "edge_index", ",", "edge_type", ",", "rel_embed", ",", "\n", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "quals", "=", "None", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        See end of doc string for explaining.\n\n        :param x: all entities*dim_of_entities (for jf17k -> 28646*200)\n        :param edge_index: COO matrix (2 list each having nodes with index\n        [1,2,3,4,5]\n        [3,4,2,5,4]\n\n        Here node 1 and node 3 are connected with edge.\n        And the type of edge can be found using edge_type.\n\n        Note that there are twice the number of edges as each edge is also reversed.\n        )\n        :param edge_type: The type of edge connecting the COO matrix\n        :param rel_embed: 2 Times Total relation * emb_dim (200 in our case and 2 Times because of inverse relations)\n        :param qualifier_ent:\n        :param qualifier_rel:\n        :param quals: Another sparse matrix\n\n        where\n            quals[0] --> qualifier relations type\n            quals[1] --> qualifier entity\n            quals[2] --> index of the original COO matrix that states for which edge this qualifier exists ()\n\n\n        For argument sake if a knowledge graph has following statements\n\n        [e1,p1,e4,qr1,qe1,qr2,qe2]\n        [e1,p1,e2,qr1,qe1,qr2,qe3]\n        [e1,p2,e3,qr3,qe3,qr2,qe2]\n        [e1,p2,e5,qr1,qe1]\n        [e2,p1,e4]\n        [e4,p3,e3,qr4,qe1,qr2,qe4]\n        [e1,p1,e5]\n                                                 (incoming)         (outgoing)\n                                            <----(regular)------><---(inverse)------->\n        Edge index would be             :   [e1,e1,e1,e1,e2,e4,e1,e4,e2,e3,e5,e4,e3,e5]\n                                            [e4,e2,e3,e5,e4,e3,e5,e1,e1,e1,e1,e2,e4,e1]\n\n        Edge Type would be              :   [p1,p1,p2,p2,p1,p3,p1,p1_inv,p1_inv,p2_inv,p2_inv,p1_inv,p3_inv,p1_inv]\n\n                                            <-------on incoming-----------------><---------on outgoing-------------->\n        quals would be                  :   [qr1,qr2,qr1,qr2,qr3,qr2,qr1,qr4,qr2,qr1,qr2,qr1,qr2,qr3,qr2,qr1,qr4,qr2]\n                                            [qe1,qe2,qe1,qe3,qe3,qe2,qe1,qe1,qe4,qe1,qe2,qe1,qe3,qe3,qe2,qe1,qe1,qe4]\n                                            [0,0,1,1,2,2,3,5,5,0,0,1,1,2,2,3,5,5]\n                                            <--on incoming---><--outgoing------->\n\n        Note that qr1,qr2... and qe1, qe2, ... all belong to the same space\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "device", "is", "None", ":", "\n", "            ", "self", ".", "device", "=", "edge_index", ".", "device", "\n", "\n", "", "rel_embed", "=", "torch", ".", "cat", "(", "[", "rel_embed", ",", "self", ".", "loop_rel", "]", ",", "dim", "=", "0", ")", "\n", "num_edges", "=", "edge_index", ".", "size", "(", "1", ")", "//", "2", "\n", "num_ent", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "self", ".", "in_index", ",", "self", ".", "out_index", "=", "edge_index", "[", ":", ",", ":", "num_edges", "]", ",", "edge_index", "[", ":", ",", "num_edges", ":", "]", "\n", "self", ".", "in_type", ",", "self", ".", "out_type", "=", "edge_type", "[", ":", "num_edges", "]", ",", "edge_type", "[", "num_edges", ":", "]", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "num_quals", "=", "quals", ".", "size", "(", "1", ")", "//", "2", "\n", "self", ".", "in_index_qual_ent", ",", "self", ".", "out_index_qual_ent", "=", "quals", "[", "1", ",", ":", "num_quals", "]", ",", "quals", "[", "1", ",", "num_quals", ":", "]", "\n", "self", ".", "in_index_qual_rel", ",", "self", ".", "out_index_qual_rel", "=", "quals", "[", "0", ",", ":", "num_quals", "]", ",", "quals", "[", "0", ",", "num_quals", ":", "]", "\n", "self", ".", "quals_index_in", ",", "self", ".", "quals_index_out", "=", "quals", "[", "2", ",", ":", "num_quals", "]", ",", "quals", "[", "2", ",", "num_quals", ":", "]", "\n", "\n", "", "'''\n            Adding self loop by creating a COO matrix. Thus \\\n             loop index [1,2,3,4,5]\n                        [1,2,3,4,5]\n             loop type [10,10,10,10,10] --> assuming there are 9 relations\n\n\n        '''", "\n", "# Self edges between all the nodes", "\n", "self", ".", "loop_index", "=", "torch", ".", "stack", "(", "[", "torch", ".", "arange", "(", "num_ent", ")", ",", "torch", ".", "arange", "(", "num_ent", ")", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "loop_type", "=", "torch", ".", "full", "(", "(", "num_ent", ",", ")", ",", "rel_embed", ".", "size", "(", "0", ")", "-", "1", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "# if rel meb is 500, the index of the self emb is", "\n", "# 499 .. which is just added here", "\n", "\n", "self", ".", "in_norm", "=", "self", ".", "compute_norm", "(", "self", ".", "in_index", ",", "num_ent", ")", "\n", "self", ".", "out_norm", "=", "self", ".", "compute_norm", "(", "self", ".", "out_index", ",", "num_ent", ")", "\n", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "\n", "            ", "in_res", "=", "self", ".", "propagate", "(", "self", ".", "in_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "in_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "in_norm", ",", "mode", "=", "'in'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "self", ".", "in_index_qual_ent", ",", "\n", "qualifier_rel", "=", "self", ".", "in_index_qual_rel", ",", "\n", "qual_index", "=", "self", ".", "quals_index_in", ",", "\n", "source_index", "=", "self", ".", "in_index", "[", "0", "]", ")", "\n", "\n", "loop_res", "=", "self", ".", "propagate", "(", "self", ".", "loop_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "loop_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "None", ",", "mode", "=", "'loop'", ",", "\n", "ent_embed", "=", "None", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", "\n", "\n", "out_res", "=", "self", ".", "propagate", "(", "self", ".", "out_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "out_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "out_norm", ",", "mode", "=", "'out'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "self", ".", "out_index_qual_ent", ",", "\n", "qualifier_rel", "=", "self", ".", "out_index_qual_rel", ",", "\n", "qual_index", "=", "self", ".", "quals_index_out", ",", "\n", "source_index", "=", "self", ".", "out_index", "[", "0", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "in_res", "=", "self", ".", "propagate", "(", "self", ".", "in_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "in_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "in_norm", ",", "mode", "=", "'in'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "self", ".", "in_index", "[", "0", "]", ")", "\n", "\n", "loop_res", "=", "self", ".", "propagate", "(", "self", ".", "loop_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "loop_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "None", ",", "mode", "=", "'loop'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", "\n", "\n", "out_res", "=", "self", ".", "propagate", "(", "self", ".", "out_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "out_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "out_norm", ",", "mode", "=", "'out'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "self", ".", "out_index", "[", "0", "]", ")", "\n", "\n", "\n", "", "out", "=", "self", ".", "drop", "(", "in_res", ")", "*", "(", "1", "/", "3", ")", "+", "self", ".", "drop", "(", "out_res", ")", "*", "(", "1", "/", "3", ")", "+", "loop_res", "*", "(", "1", "/", "3", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'BIAS'", "]", ":", "\n", "            ", "out", "=", "out", "+", "self", ".", "bias", "\n", "", "out", "=", "self", ".", "bn", "(", "out", ")", "\n", "\n", "# Ignoring the self loop inserted, return.", "\n", "return", "self", ".", "act", "(", "out", ")", ",", "torch", ".", "matmul", "(", "rel_embed", ",", "self", ".", "w_rel", ")", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.rel_transform": [[217, 230], ["utils.utils_gcn.ccorr", "utils.utils_gcn.rotate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.ccorr", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.rotate"], ["", "def", "rel_transform", "(", "self", ",", "ent_embed", ",", "rel_embed", ")", ":", "\n", "        ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'corr'", ":", "\n", "            ", "trans_embed", "=", "ccorr", "(", "ent_embed", ",", "rel_embed", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'sub'", ":", "\n", "            ", "trans_embed", "=", "ent_embed", "-", "rel_embed", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'mult'", ":", "\n", "            ", "trans_embed", "=", "ent_embed", "*", "rel_embed", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'rotate'", ":", "\n", "            ", "trans_embed", "=", "rotate", "(", "ent_embed", ",", "rel_embed", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "trans_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.qual_transform": [[231, 248], ["utils.utils_gcn.ccorr", "utils.utils_gcn.rotate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.ccorr", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.rotate"], ["", "def", "qual_transform", "(", "self", ",", "qualifier_ent", ",", "qualifier_rel", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'corr'", ":", "\n", "            ", "trans_embed", "=", "ccorr", "(", "qualifier_ent", ",", "qualifier_rel", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'sub'", ":", "\n", "            ", "trans_embed", "=", "qualifier_ent", "-", "qualifier_rel", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'mult'", ":", "\n", "            ", "trans_embed", "=", "qualifier_ent", "*", "qualifier_rel", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'rotate'", ":", "\n", "            ", "trans_embed", "=", "rotate", "(", "qualifier_ent", ",", "qualifier_rel", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "trans_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.qualifier_aggregate": [[249, 311], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "gnn_layer.StarEConvLayer.coalesce_quals", "gnn_layer.StarEConvLayer.coalesce_quals", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "gnn_layer.StarEConvLayer.coalesce_quals", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "expanded_rels.view.view.view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.leaky_relu", "torch.leaky_relu", "utils.utils_gcn.softmax", "torch.dropout", "torch.dropout", "torch_scatter.scatter_add", "rel_part_emb.size", "torch_scatter.scatter_add.sum", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rel_part_emb.size", "torch.dropout.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax"], ["", "def", "qualifier_aggregate", "(", "self", ",", "qualifier_emb", ",", "rel_part_emb", ",", "alpha", "=", "0.5", ",", "qual_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            In qualifier_aggregate method following steps are performed\n\n            qualifier_emb looks like -\n            qualifier_emb      :   [a,b,c,d,e,f,g,......]               (here a,b,c ... are of 200 dim)\n            rel_part_emb       :   [qq,ww,ee,rr,tt, .....]                      (here qq, ww, ee .. are of 200 dim)\n\n            Note that rel_part_emb for jf17k would be around 61k*200\n\n            Step1 : Pass the qualifier_emb to self.coalesce_quals and multiply the returned output with a weight.\n            qualifier_emb   : [aa,bb,cc,dd,ee, ...... ]                 (here aa, bb, cc are of 200 dim each)\n            Note that now qualifier_emb has the same shape as rel_part_emb around 61k*200\n\n            Step2 : Combine the updated qualifier_emb (see Step1) with rel_part_emb based on defined aggregation strategy.\n\n\n\n            Aggregates the qualifier matrix (3, edge_index, emb_dim)\n        :param qualifier_emb:\n        :param rel_part_emb:\n        :param type:\n        :param alpha\n        :return:\n\n        self.coalesce_quals    returns   :  [q+a+b+d,w+c+e+g,e'+f,......]        (here each element in the list is of 200 dim)\n\n        \"\"\"", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'sum'", ":", "\n", "            ", "qualifier_emb", "=", "torch", ".", "einsum", "(", "'ij,jk -> ik'", ",", "\n", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ")", ",", "\n", "self", ".", "w_q", ")", "\n", "return", "alpha", "*", "rel_part_emb", "+", "(", "1", "-", "alpha", ")", "*", "qualifier_emb", "# [N_EDGES / 2 x EMB_DIM]", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'concat'", ":", "\n", "            ", "qualifier_emb", "=", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ")", "\n", "agg_rel", "=", "torch", ".", "cat", "(", "(", "rel_part_emb", ",", "qualifier_emb", ")", ",", "dim", "=", "1", ")", "# [N_EDGES / 2 x 2 * EMB_DIM]", "\n", "return", "torch", ".", "mm", "(", "agg_rel", ",", "self", ".", "w_q", ")", "# [N_EDGES / 2 x EMB_DIM]", "\n", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'mul'", ":", "\n", "            ", "qualifier_emb", "=", "torch", ".", "mm", "(", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ",", "fill", "=", "1", ")", ",", "self", ".", "w_q", ")", "\n", "return", "rel_part_emb", "*", "qualifier_emb", "\n", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "# only for sparse mode", "\n", "            ", "expanded_rels", "=", "torch", ".", "index_select", "(", "rel_part_emb", ",", "0", ",", "qual_index", ")", "# Nquals x D", "\n", "expanded_rels", "=", "expanded_rels", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "# Nquals x heads x h_dim", "\n", "qualifier_emb", "=", "torch", ".", "mm", "(", "qualifier_emb", ",", "self", ".", "w_q", ")", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "\n", "self", ".", "attn_dim", ")", "# Nquals x heads x h_dim", "\n", "\n", "alpha_r", "=", "torch", ".", "einsum", "(", "'bij,kij -> bi'", ",", "[", "torch", ".", "cat", "(", "[", "expanded_rels", ",", "qualifier_emb", "]", ",", "dim", "=", "-", "1", ")", ",", "self", ".", "att_qual", "]", ")", "\n", "alpha_r", "=", "F", ".", "leaky_relu", "(", "alpha_r", ",", "self", ".", "negative_slope", ")", "# Nquals x heads", "\n", "alpha_r", "=", "softmax", "(", "alpha_r", ",", "qual_index", ",", "rel_part_emb", ".", "size", "(", "0", ")", ")", "# Nquals x heads", "\n", "alpha_r", "=", "F", ".", "dropout", "(", "alpha_r", ",", "p", "=", "self", ".", "attn_drop", ")", "# Nquals x heads", "\n", "expanded_rels", "=", "(", "expanded_rels", "*", "alpha_r", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "\n", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "# Nquals x D", "\n", "single_rels", "=", "scatter_add", "(", "expanded_rels", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "rel_part_emb", ".", "size", "(", "0", ")", ")", "# Nedges x D", "\n", "copy_mask", "=", "single_rels", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0.0", "\n", "rel_part_emb", "[", "copy_mask", "]", "=", "single_rels", "[", "copy_mask", "]", "# Nedges x D", "\n", "return", "rel_part_emb", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier": [[312, 365], ["gnn_layer.StarEConvLayer.qual_transform", "gnn_layer.StarEConvLayer.qualifier_aggregate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qual_transform", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qualifier_aggregate"], ["", "", "def", "update_rel_emb_with_qualifier", "(", "self", ",", "ent_embed", ",", "rel_embed", ",", "\n", "qualifier_ent", ",", "qualifier_rel", ",", "edge_type", ",", "qual_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        The update_rel_emb_with_qualifier method performs following functions:\n\n        Input is the secondary COO matrix (QE (qualifier entity), QR (qualifier relation), edge index (Connection to the primary COO))\n\n        Step1 : Embed all the input\n            Step1a : Embed the qualifier entity via ent_embed (So QE shape is 33k,1 -> 33k,200)\n            Step1b : Embed the qualifier relation via rel_embed (So QR shape is 33k,1 -> 33k,200)\n            Step1c : Embed the main statement edge_type via rel_embed (So edge_type shape is 61k,1 -> 61k,200)\n\n        Step2 : Combine qualifier entity emb and qualifier relation emb to create qualifier emb (See self.qual_transform).\n            This is generally just summing up. But can be more any pair-wise function that returns one vector for a (qe,qr) vector\n\n        Step3 : Update the edge_type embedding with qualifier information. This uses scatter_add/scatter_mean.\n\n\n        before:\n            qualifier_emb      :   [a,b,c,d,e,f,g,......]               (here a,b,c ... are of 200 dim)\n            qual_index         :   [1,1,2,1,2,3,2,......]               (here 1,2,3 .. are edge index of Main COO)\n            edge_type          :   [q,w,e',r,t,y,u,i,o,p, .....]        (here q,w,e' .. are of 200 dim each)\n\n        After:\n            edge_type          :   [q+(a+b+d),w+(c+e+g),e'+f,......]        (here each element in the list is of 200 dim)\n\n\n        :param ent_embed: essentially x (28k*200 in case of Jf17k)\n        :param rel_embed: essentially relation embedding matrix\n\n        For secondary COO matrix (QE, QR, edge index)\n        :param qualifier_ent:  QE\n        :param qualifier_rel: QR\n        edge_type:\n        :return:\n\n        index select from embedding\n        phi operation between qual_ent, qual_rel\n        \"\"\"", "\n", "\n", "# Step 1: embedding", "\n", "qualifier_emb_rel", "=", "rel_embed", "[", "qualifier_rel", "]", "\n", "qualifier_emb_ent", "=", "ent_embed", "[", "qualifier_ent", "]", "\n", "\n", "rel_part_emb", "=", "rel_embed", "[", "edge_type", "]", "\n", "\n", "# Step 2: pass it through qual_transform", "\n", "qualifier_emb", "=", "self", ".", "qual_transform", "(", "qualifier_ent", "=", "qualifier_emb_ent", ",", "\n", "qualifier_rel", "=", "qualifier_emb_rel", ")", "\n", "\n", "# Pass it through a aggregate layer", "\n", "return", "self", ".", "qualifier_aggregate", "(", "qualifier_emb", ",", "rel_part_emb", ",", "alpha", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'TRIPLE_QUAL_WEIGHT'", "]", ",", "\n", "qual_index", "=", "qual_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.message": [[367, 422], ["getattr", "gnn_layer.StarEConvLayer.rel_transform", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "out.view.view.view", "x_i.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.leaky_relu", "torch.leaky_relu", "utils.utils_gcn.softmax", "torch.dropout", "torch.dropout", "gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "ent_embed.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "edge_norm.view", "torch.dropout.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.rel_transform", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier"], ["", "def", "message", "(", "self", ",", "x_j", ",", "x_i", ",", "edge_type", ",", "rel_embed", ",", "edge_norm", ",", "mode", ",", "ent_embed", "=", "None", ",", "qualifier_ent", "=", "None", ",", "\n", "qualifier_rel", "=", "None", ",", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", ":", "\n", "\n", "        ", "\"\"\"\n\n        The message method performs following functions\n\n        Step1 : get updated relation representation (rel_embed) [edge_type] by aggregating qualifier information (self.update_rel_emb_with_qualifier).\n        Step2 : Obtain edge message by transforming the node embedding with updated relation embedding (self.rel_transform).\n        Step3 : Multiply edge embeddings (transform) by weight\n        Step4 : Return the messages. They will be sent to subjects (1st line in the edge index COO)\n        Over here the node embedding [the first list in COO matrix] is representing the message which will be sent on each edge\n\n\n        More information about updating relation representation please refer to self.update_rel_emb_with_qualifier\n\n        :param x_j: objects of the statements (2nd line in the COO)\n        :param x_i: subjects of the statements (1st line in the COO)\n        :param edge_type: relation types\n        :param rel_embed: embedding matrix of all relations\n        :param edge_norm:\n        :param mode: in (direct) / out (inverse) / loop\n        :param ent_embed: embedding matrix of all entities\n        :param qualifier_ent:\n        :param qualifier_rel:\n        :param qual_index:\n        :param source_index:\n        :return:\n        \"\"\"", "\n", "weight", "=", "getattr", "(", "self", ",", "'w_{}'", ".", "format", "(", "mode", ")", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "# add code here", "\n", "            ", "if", "mode", "!=", "'loop'", ":", "\n", "                ", "rel_emb", "=", "self", ".", "update_rel_emb_with_qualifier", "(", "ent_embed", ",", "rel_embed", ",", "qualifier_ent", ",", "\n", "qualifier_rel", ",", "edge_type", ",", "qual_index", ")", "\n", "", "else", ":", "\n", "                ", "rel_emb", "=", "torch", ".", "index_select", "(", "rel_embed", ",", "0", ",", "edge_type", ")", "\n", "", "", "else", ":", "\n", "            ", "rel_emb", "=", "torch", ".", "index_select", "(", "rel_embed", ",", "0", ",", "edge_type", ")", "\n", "\n", "", "xj_rel", "=", "self", ".", "rel_transform", "(", "x_j", ",", "rel_emb", ")", "\n", "out", "=", "torch", ".", "einsum", "(", "'ij,jk->ik'", ",", "xj_rel", ",", "weight", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", "and", "mode", "!=", "'loop'", ":", "\n", "            ", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "\n", "x_i", "=", "x_i", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "\n", "\n", "alpha", "=", "torch", ".", "einsum", "(", "'bij,kij -> bi'", ",", "[", "torch", ".", "cat", "(", "[", "x_i", ",", "out", "]", ",", "dim", "=", "-", "1", ")", ",", "self", ".", "att", "]", ")", "\n", "alpha", "=", "F", ".", "leaky_relu", "(", "alpha", ",", "self", ".", "negative_slope", ")", "\n", "alpha", "=", "softmax", "(", "alpha", ",", "source_index", ",", "ent_embed", ".", "size", "(", "0", ")", ")", "\n", "alpha", "=", "F", ".", "dropout", "(", "alpha", ",", "p", "=", "self", ".", "attn_drop", ")", "\n", "return", "(", "out", "*", "alpha", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "\n", "", "else", ":", "\n", "            ", "return", "out", "if", "edge_norm", "is", "None", "else", "out", "*", "edge_norm", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.update": [[423, 428], ["aggr_out.view.view.view"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "aggr_out", ",", "mode", ")", ":", "\n", "        ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", "and", "mode", "!=", "'loop'", ":", "\n", "            ", "aggr_out", "=", "aggr_out", ".", "view", "(", "-", "1", ",", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "\n", "\n", "", "return", "aggr_out", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.compute_norm": [[429, 456], ["torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch_scatter.scatter_add", "torch_scatter.scatter_add.pow", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "compute_norm", "(", "edge_index", ",", "num_ent", ")", ":", "\n", "        ", "\"\"\"\n        Re-normalization trick used by GCN-based architectures without attention.\n\n        Yet another torch scatter functionality. See coalesce_quals for a rough idea.\n\n        row         :      [1,1,2,3,3,4,4,4,4, .....]        (about 61k for Jf17k)\n        edge_weight :      [1,1,1,1,1,1,1,1,1,  ....] (same as row. So about 61k for Jf17k)\n        deg         :      [2,1,2,4,.....]            (same as num_ent about 28k in case of Jf17k)\n\n        :param edge_index:\n        :param num_ent:\n        :return:\n        \"\"\"", "\n", "row", ",", "col", "=", "edge_index", "\n", "edge_weight", "=", "torch", ".", "ones_like", "(", "\n", "row", ")", ".", "float", "(", ")", "# Identity matrix where we know all entities are there", "\n", "deg", "=", "scatter_add", "(", "edge_weight", ",", "row", ",", "dim", "=", "0", ",", "\n", "dim_size", "=", "num_ent", ")", "# Summing number of weights of", "\n", "# the edges, D = A + I", "\n", "deg_inv", "=", "deg", ".", "pow", "(", "-", "0.5", ")", "# D^{-0.5}", "\n", "deg_inv", "[", "deg_inv", "==", "float", "(", "'inf'", ")", "]", "=", "0", "# for numerical stability", "\n", "norm", "=", "deg_inv", "[", "row", "]", "*", "edge_weight", "*", "deg_inv", "[", "\n", "col", "]", "# Norm parameter D^{-0.5} *", "\n", "\n", "return", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.coalesce_quals": [[457, 487], ["torch_scatter.scatter_add", "torch_scatter.scatter_mean", "torch_scatter.scatter_mean.sum"], "methods", ["None"], ["", "def", "coalesce_quals", "(", "self", ",", "qual_embeddings", ",", "qual_index", ",", "num_edges", ",", "fill", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n\n        before:\n            qualifier_emb      :   [a,b,c,d,e,f,g,......]               (here a,b,c ... are of 200 dim)\n            qual_index         :   [1,1,2,1,2,3,2,......]               (here 1,2,3 .. are edge index of Main COO)\n            edge_type          :   [0,0,0,0,0,0,0, .....]               (empty array of size num_edges)\n\n        After:\n            edge_type          :   [a+b+d,c+e+g,f ......]        (here each element in the list is of 200 dim)\n\n        :param qual_embeddings: shape of [1, N_QUALS]\n        :param qual_index: shape of [1, N_QUALS] which states which quals belong to which main relation from the index,\n            that is, all qual_embeddings that have the same index have to be summed up\n        :param num_edges: num_edges to return the appropriate tensor\n        :param fill: fill value for the output matrix - should be 0 for sum/concat and 1 for mul qual aggregation strat\n        :return: [1, N_EDGES]\n        \"\"\"", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_N'", "]", "==", "'sum'", ":", "\n", "            ", "output", "=", "scatter_add", "(", "qual_embeddings", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_edges", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_N'", "]", "==", "'mean'", ":", "\n", "            ", "output", "=", "scatter_mean", "(", "qual_embeddings", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_edges", ")", "\n", "\n", "", "if", "fill", "!=", "0", ":", "\n", "# by default scatter_ functions assign zeros to the output, so we assign them 1's for correct mult", "\n", "            ", "mask", "=", "output", ".", "sum", "(", "dim", "=", "-", "1", ")", "==", "0", "\n", "output", "[", "mask", "]", "=", "fill", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.gnn_layer.StarEConvLayer.__repr__": [[488, 492], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{}({}, {}, num_rels={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "self", ".", "num_rels", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.lrga_model.LowRankAttention.__init__": [[26, 33], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "lrga_model.LowRankAttention.apply", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "k", ",", "d", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "d", ",", "4", "*", "k", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "apply", "(", "weight_init", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.lrga_model.LowRankAttention.forward": [[34, 46], ["lrga_model.LowRankAttention.w", "torch.t", "torch.t", "torch.t", "torch.t", "lrga_model.joint_normalize2", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lrga_model.LowRankAttention.dropout", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.joint_normalize2"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "tmp", "=", "self", ".", "w", "(", "x", ")", "# B x D", "\n", "U", "=", "tmp", "[", ":", ",", ":", "self", ".", "k", "]", "# B x K", "\n", "V", "=", "tmp", "[", ":", ",", "self", ".", "k", ":", "2", "*", "self", ".", "k", "]", "# B x K", "\n", "Z", "=", "tmp", "[", ":", ",", "2", "*", "self", ".", "k", ":", "3", "*", "self", ".", "k", "]", "# B x K", "\n", "T", "=", "tmp", "[", ":", ",", "3", "*", "self", ".", "k", ":", "]", "# B x K", "\n", "V_T", "=", "torch", ".", "t", "(", "V", ")", "# K x B", "\n", "# normalization", "\n", "D", "=", "joint_normalize2", "(", "U", ",", "V_T", ")", "# scalar", "\n", "res", "=", "torch", ".", "mm", "(", "U", ",", "torch", ".", "mm", "(", "V_T", ",", "Z", ")", ")", "# (B x K) mm (K x K) -> B x K", "\n", "res", "=", "torch", ".", "cat", "(", "(", "res", "*", "D", ",", "T", ")", ",", "dim", "=", "1", ")", "# B x 2K", "\n", "return", "self", ".", "dropout", "(", "res", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.lrga_model.joint_normalize2": [[7, 15], ["torch.ones", "torch.ones", "torch.cuda.is_available", "torch.cuda.is_available", "torch.mm", "torch.mm", "tmp_ones.to.to", "torch.mm", "torch.mm", "torch.device", "torch.device", "torch.sum", "torch.sum"], "function", ["None"], ["def", "joint_normalize2", "(", "U", ",", "V_T", ")", ":", "\n", "# U and V_T are in block diagonal form", "\n", "    ", "tmp_ones", "=", "torch", ".", "ones", "(", "(", "V_T", ".", "shape", "[", "1", "]", ",", "1", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "tmp_ones", "=", "tmp_ones", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "", "norm_factor", "=", "torch", ".", "mm", "(", "U", ",", "torch", ".", "mm", "(", "V_T", ",", "tmp_ones", ")", ")", "\n", "norm_factor", "=", "(", "torch", ".", "sum", "(", "norm_factor", ")", "/", "U", ".", "shape", "[", "0", "]", ")", "+", "1e-6", "\n", "return", "1", "/", "norm_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.models.lrga_model.weight_init": [[17, 23], ["type", "torch.init.xavier_normal_", "torch.init.constant"], "function", ["None"], ["", "def", "weight_init", "(", "layer", ")", ":", "\n", "    ", "if", "type", "(", "layer", ")", "==", "nn", ".", "Linear", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant", "(", "layer", ".", "bias", ".", "data", ",", "0", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.inductive_lp.run_ilp.main": [[31, 233], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "dict", "pykeen.utils.resolve_device", "model.nodepiece_rotate.NodePieceRotate", "torch.optim.Adam", "print", "pykeen.stoppers.EarlyStopper", "loops.ilp_evaluator.ILPRankBasedEvaluator.evaluate", "print", "print", "datasets.ind_dataset.Ind_FB15k237", "pykeen.losses.SoftplusLoss", "loop_type", "pykeen.training.LCWATrainingLoop", "pykeen.trackers.WANDBResultTracker", "pykeen.trackers.WANDBResultTracker.wandb.config.update", "loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator", "pykeen.training.LCWATrainingLoop.train", "pykeen.training.LCWATrainingLoop.train", "loops.relation_rank_evaluator.RelationPredictionRankBasedEvaluator", "pykeen.trackers.WANDBResultTracker.log_metrics", "datasets.ind_dataset.Ind_WN18RR", "pykeen.losses.BCEWithLogitsLoss", "model.nodepiece_rotate.NodePieceRotate.parameters", "utils.sample_negatives.sample_negatives", "loops.ilp_evaluator.ILPRankBasedEvaluator", "utils.sample_negatives.sample_negatives", "loops.ilp_evaluator.ILPRankBasedEvaluator", "datasets.ind_dataset.Ind_NELL", "pykeen.losses.MarginRankingLoss", "sum", "wandb.Settings", "click.get_current_context", "test_evaluator.evaluate.to_flat_dict", "pykeen.losses.NSSALoss", "p.numel", "model.nodepiece_rotate.NodePieceRotate.parameters"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.evaluate", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.ogb.run_ogb.log_metrics", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.sample_negatives.sample_negatives", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.sample_negatives.sample_negatives", "home.repos.pwc.inspect_result.migalkin_NodePiece.patch.evaluator.MetricResults.to_flat_dict"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'-embedding'", ",", "'--embedding-dimension'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "# embedding dim for anchors and relations", "\n", "@", "click", ".", "option", "(", "'-loss'", ",", "'--loss_fc'", ",", "type", "=", "str", ",", "default", "=", "'nssal'", ")", "\n", "@", "click", ".", "option", "(", "'-loop'", ",", "'--loop'", ",", "type", "=", "str", ",", "default", "=", "'slcwa'", ")", "# slcwa - negative sampling, lcwa - 1-N scoring", "\n", "@", "click", ".", "option", "(", "'-trf_hidden'", ",", "'--transformer-hidden-dim'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "@", "click", ".", "option", "(", "'-trf_heads'", ",", "'--transformer-num-heads'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "@", "click", ".", "option", "(", "'-trf_layers'", ",", "'--transformer-layers'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "@", "click", ".", "option", "(", "'-trf_drop'", ",", "'--transformer-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "@", "click", ".", "option", "(", "'-b'", ",", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "@", "click", ".", "option", "(", "'-eval_bs'", ",", "'--eval_bs'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "@", "click", ".", "option", "(", "'-epochs'", ",", "'--num-epochs'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "@", "click", ".", "option", "(", "'-lr'", ",", "'--learning-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0005", ")", "\n", "@", "click", ".", "option", "(", "'-wandb'", ",", "'--enable_wandb'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "@", "click", ".", "option", "(", "'-data'", ",", "'--dataset_name'", ",", "type", "=", "str", ",", "default", "=", "'wn18rr'", ")", "\n", "@", "click", ".", "option", "(", "'-eval_every'", ",", "'--eval_every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "@", "click", ".", "option", "(", "'-ft_maxp'", ",", "'--ft_max_paths'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "# max anchor per node, should be <= total N of anchors", "\n", "@", "click", ".", "option", "(", "'-anc_dist'", ",", "'--use_anchor_distances'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# whether to add anchor distances", "\n", "@", "click", ".", "option", "(", "'-margin'", ",", "'--margin'", ",", "type", "=", "float", ",", "default", "=", "15", ")", "\n", "@", "click", ".", "option", "(", "'-max_seq_len'", ",", "'--max_seq_len'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "@", "click", ".", "option", "(", "'-pool'", ",", "'--pooling'", ",", "type", "=", "str", ",", "default", "=", "\"cat\"", ")", "# available encoders: \"cat\" or \"trf\"", "\n", "@", "click", ".", "option", "(", "'-subbatch'", ",", "'--trf_subbatch'", ",", "type", "=", "int", ",", "default", "=", "3000", ")", "\n", "@", "click", ".", "option", "(", "'-negs'", ",", "'--num_negatives_ent'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# number of negative samples when training LP in sLCWA", "\n", "@", "click", ".", "option", "(", "'-smoothing'", ",", "'--lbl_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "# label smoothing in the 1-N setup", "\n", "@", "click", ".", "option", "(", "'-relpol'", ",", "'--rel_policy'", ",", "type", "=", "str", ",", "default", "=", "\"sum\"", ")", "\n", "@", "click", ".", "option", "(", "'-rand_hashes'", ",", "'--random_hashing'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "# for ablations: use only random numbers as hashes", "\n", "@", "click", ".", "option", "(", "'-nn'", ",", "'--nearest_neighbors'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "# use only nearest anchors per node", "\n", "@", "click", ".", "option", "(", "'-sample_rels'", ",", "'--sample_rels'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "# size of the relational context M", "\n", "@", "click", ".", "option", "(", "'-tkn_mode'", ",", "'--tkn_mode'", ",", "type", "=", "str", ",", "default", "=", "\"bfs\"", ")", "# mining paths in iGRAPH,", "\n", "@", "click", ".", "option", "(", "'-no_anc'", ",", "'--ablate_anchors'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "# don't use any anchors in hashes, keep only the relational context", "\n", "@", "click", ".", "option", "(", "'-ind_v'", ",", "'--ind_v'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# 1 / 2 / 3 / 4 - which version of GraIL splits to use", "\n", "@", "click", ".", "option", "(", "'-rp'", ",", "'--rp'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# turn on for the relation prediction task", "\n", "@", "click", ".", "option", "(", "'-gnn'", ",", "'--gnn'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# whether to use a GNN encoder on top of NodePiece features", "\n", "@", "click", ".", "option", "(", "'-gnn_att'", ",", "'--gnn_att'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# GNN with attentional aggregation", "\n", "@", "click", ".", "option", "(", "'-gnn_lrga'", ",", "'--gnn_lrga'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# Low-Rank Global Attention", "\n", "@", "click", ".", "option", "(", "'-gnn_layers'", ",", "'--gnn_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "@", "click", ".", "option", "(", "'-gnn_att_drop'", ",", "'--gnn_att_drop'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "@", "click", ".", "option", "(", "'-ilp_eval'", ",", "'--ilp_eval'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "# True stands for evaluation of 50 random samples to replicate the Teru et al setup, otherwise eval against all entities", "\n", "@", "click", ".", "option", "(", "'-pna'", ",", "'--pna'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# whether to use Principal Neighborhood Aggregation", "\n", "@", "click", ".", "option", "(", "'-residual'", ",", "'--residual'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# whether to use residual connections for deep GNNs", "\n", "@", "click", ".", "option", "(", "'-jk'", ",", "'--jk'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "# JK connections for GNN", "\n", "def", "main", "(", "\n", "embedding_dimension", ",", "\n", "loss_fc", ",", "\n", "loop", ",", "\n", "transformer_hidden_dim", ":", "int", ",", "\n", "transformer_num_heads", ":", "int", ",", "\n", "transformer_layers", ":", "int", ",", "\n", "transformer_dropout", ":", "float", ",", "\n", "batch_size", ":", "int", ",", "\n", "eval_bs", ":", "int", ",", "\n", "num_epochs", ":", "int", ",", "\n", "learning_rate", ":", "float", ",", "\n", "enable_wandb", ":", "bool", ",", "\n", "dataset_name", ":", "str", ",", "\n", "eval_every", ":", "int", ",", "\n", "ft_max_paths", ":", "int", ",", "\n", "use_anchor_distances", ":", "bool", ",", "\n", "margin", ":", "float", ",", "\n", "max_seq_len", ":", "int", ",", "\n", "pooling", ":", "str", ",", "\n", "trf_subbatch", ":", "int", ",", "\n", "num_negatives_ent", ":", "int", ",", "\n", "lbl_smoothing", ":", "float", ",", "\n", "rel_policy", ":", "str", ",", "\n", "random_hashing", ":", "int", ",", "\n", "nearest_neighbors", ":", "bool", ",", "\n", "sample_rels", ":", "int", ",", "\n", "tkn_mode", ":", "str", ",", "\n", "ablate_anchors", ":", "bool", ",", "\n", "ind_v", ":", "int", ",", "\n", "rp", ":", "bool", ",", "\n", "gnn", ":", "bool", ",", "\n", "gnn_att", ":", "bool", ",", "\n", "gnn_lrga", ":", "bool", ",", "\n", "gnn_layers", ":", "int", ",", "\n", "gnn_att_drop", ":", "float", ",", "\n", "ilp_eval", ":", "bool", ",", "\n", "pna", ":", "bool", ",", "\n", "residual", ":", "bool", ",", "\n", "jk", ":", "bool", ",", "\n", ")", ":", "\n", "# Standard dataset loading procedures, inverses are necessary for reachability of nodes", "\n", "    ", "if", "dataset_name", "==", "'fb15k237'", ":", "\n", "        ", "dataset", "=", "Ind_FB15k237", "(", "create_inverse_triples", "=", "True", ",", "version", "=", "ind_v", ")", "\n", "", "elif", "dataset_name", "==", "'wn18rr'", ":", "\n", "        ", "dataset", "=", "Ind_WN18RR", "(", "create_inverse_triples", "=", "True", ",", "version", "=", "ind_v", ")", "\n", "", "elif", "dataset_name", "==", "\"nell\"", ":", "\n", "        ", "dataset", "=", "Ind_NELL", "(", "create_inverse_triples", "=", "True", ",", "version", "=", "ind_v", ")", "\n", "\n", "", "negative_sampler_cls", "=", "BasicNegativeSampler", "\n", "negative_sampler_kwargs", "=", "dict", "(", "num_negs_per_pos", "=", "num_negatives_ent", ")", "\n", "loop_type", "=", "InductiveSLCWATrainingLoop", "\n", "\n", "training_triples_factory", "=", "dataset", ".", "transductive_part", "\n", "inference_triples_factory", "=", "dataset", ".", "inductive_inference", "\n", "\n", "# No need for anchor tokenization in inductive datasets", "\n", "# We will do relation-only tokenization inside the model", "\n", "kg_tokenizer", "=", "None", "\n", "device", "=", "resolve_device", "(", ")", "\n", "\n", "# selecting the loss function", "\n", "if", "loss_fc", "==", "\"softplus\"", ":", "\n", "        ", "ft_loss", "=", "SoftplusLoss", "(", ")", "\n", "", "elif", "loss_fc", "==", "\"bce\"", ":", "\n", "        ", "ft_loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "loss_fc", "==", "\"mrl\"", ":", "\n", "        ", "ft_loss", "=", "MarginRankingLoss", "(", "margin", "=", "margin", ")", "\n", "", "elif", "loss_fc", "==", "\"nssal\"", ":", "\n", "        ", "ft_loss", "=", "NSSALoss", "(", "margin", "=", "margin", ")", "\n", "\n", "# Create the model", "\n", "", "finetuning_model", "=", "NodePieceRotate", "(", "embedding_dim", "=", "embedding_dimension", ",", "device", "=", "device", ",", "loss", "=", "ft_loss", ",", "\n", "triples", "=", "training_triples_factory", ",", "inference_triples", "=", "inference_triples_factory", ",", "max_paths", "=", "ft_max_paths", ",", "subbatch", "=", "trf_subbatch", ",", "\n", "max_seq_len", "=", "max_seq_len", ",", "tokenizer", "=", "kg_tokenizer", ",", "pooler", "=", "pooling", ",", "\n", "hid_dim", "=", "transformer_hidden_dim", ",", "num_heads", "=", "transformer_num_heads", ",", "\n", "use_distances", "=", "use_anchor_distances", ",", "num_layers", "=", "transformer_layers", ",", "drop_prob", "=", "transformer_dropout", ",", "\n", "rel_policy", "=", "rel_policy", ",", "random_hashes", "=", "random_hashing", ",", "nearest", "=", "nearest_neighbors", ",", "\n", "sample_rels", "=", "sample_rels", ",", "ablate_anchors", "=", "ablate_anchors", ",", "tkn_mode", "=", "tkn_mode", ",", "gnn", "=", "gnn", ",", "gnn_att", "=", "gnn_att", ",", "\n", "use_lrga", "=", "gnn_lrga", ",", "gnn_layers", "=", "gnn_layers", ",", "gnn_att_drop", "=", "gnn_att_drop", ",", "pna", "=", "pna", ",", "residual", "=", "residual", ",", "jk", "=", "jk", ")", "\n", "\n", "optimizer", "=", "Adam", "(", "params", "=", "finetuning_model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ")", "\n", "print", "(", "f\"Number of params: {sum(p.numel() for p in finetuning_model.parameters())}\"", ")", "\n", "\n", "if", "loop", "==", "\"slcwa\"", ":", "\n", "        ", "ft_loop", "=", "loop_type", "(", "model", "=", "finetuning_model", ",", "optimizer", "=", "optimizer", ",", "negative_sampler_cls", "=", "negative_sampler_cls", ",", "\n", "negative_sampler_kwargs", "=", "negative_sampler_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "ft_loop", "=", "LCWATrainingLoop", "(", "model", "=", "finetuning_model", ",", "optimizer", "=", "optimizer", ")", "\n", "\n", "# add the results tracker if requested", "\n", "", "if", "enable_wandb", ":", "\n", "        ", "project_name", "=", "\"NodePiece_ILP\"", "\n", "\n", "tracker", "=", "WANDBResultTracker", "(", "project", "=", "project_name", ",", "group", "=", "None", ",", "settings", "=", "wandb", ".", "Settings", "(", "start_method", "=", "'fork'", ")", ")", "\n", "tracker", ".", "wandb", ".", "config", ".", "update", "(", "click", ".", "get_current_context", "(", ")", ".", "params", ")", "\n", "", "else", ":", "\n", "        ", "tracker", "=", "None", "\n", "\n", "", "if", "rp", ":", "\n", "        ", "valid_evaluator", "=", "RelationPredictionRankBasedEvaluator", "(", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "ilp_eval", ":", "\n", "            ", "valid_evaluator", "=", "RankBasedEvaluator", "\n", "", "else", ":", "\n", "# GraIL-style evaluation against 50 random negatives", "\n", "            ", "head_samples", ",", "tail_samples", "=", "sample_negatives", "(", "valid_triples", "=", "dataset", ".", "inductive_val", ",", "all_pos", "=", "dataset", ".", "inductive_inference", ")", "\n", "valid_evaluator", "=", "ILPRankBasedEvaluator", "(", "head_samples", "=", "head_samples", ",", "tail_samples", "=", "tail_samples", ")", "\n", "", "", "valid_evaluator", ".", "batch_size", "=", "eval_bs", "\n", "\n", "# we don't actually use the early stopper here by setting the patience to 100000", "\n", "early_stopper", "=", "EarlyStopper", "(", "\n", "model", "=", "finetuning_model", ",", "\n", "relative_delta", "=", "0.0005", ",", "\n", "evaluation_triples_factory", "=", "dataset", ".", "inductive_val", ",", "\n", "frequency", "=", "eval_every", ",", "\n", "patience", "=", "100000", ",", "\n", "result_tracker", "=", "tracker", ",", "\n", "evaluation_batch_size", "=", "eval_bs", ",", "\n", "evaluator", "=", "valid_evaluator", ",", "\n", ")", "\n", "\n", "# Train LP / RP", "\n", "if", "loop", "==", "\"lcwa\"", ":", "\n", "        ", "ft_loop", ".", "train", "(", "num_epochs", "=", "num_epochs", ",", "batch_size", "=", "batch_size", ",", "result_tracker", "=", "tracker", ",", "\n", "stopper", "=", "early_stopper", ",", "label_smoothing", "=", "lbl_smoothing", ")", "\n", "", "else", ":", "\n", "        ", "ft_loop", ".", "train", "(", "num_epochs", "=", "num_epochs", ",", "batch_size", "=", "batch_size", ",", "result_tracker", "=", "tracker", ",", "\n", "stopper", "=", "early_stopper", ")", "\n", "\n", "# run the final test eval", "\n", "", "if", "rp", ":", "\n", "        ", "test_evaluator", "=", "RelationPredictionRankBasedEvaluator", "(", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "ilp_eval", ":", "\n", "            ", "test_evaluator", "=", "RankBasedEvaluator", "\n", "", "else", ":", "\n", "# test evaluator", "\n", "            ", "head_samples", ",", "tail_samples", "=", "sample_negatives", "(", "valid_triples", "=", "dataset", ".", "inductive_test", ",", "\n", "all_pos", "=", "dataset", ".", "inductive_inference", ")", "\n", "test_evaluator", "=", "ILPRankBasedEvaluator", "(", "head_samples", "=", "head_samples", ",", "tail_samples", "=", "tail_samples", ")", "\n", "", "", "test_evaluator", ".", "batch_size", "=", "eval_bs", "\n", "\n", "# test_evaluator", "\n", "metric_results", "=", "test_evaluator", ".", "evaluate", "(", "\n", "model", "=", "finetuning_model", ",", "\n", "mapped_triples", "=", "dataset", ".", "inductive_test", ".", "mapped_triples", ",", "\n", "additional_filter_triples", "=", "[", "dataset", ".", "inductive_inference", ".", "mapped_triples", ",", "dataset", ".", "inductive_val", ".", "mapped_triples", "]", ",", "\n", "use_tqdm", "=", "True", ",", "\n", "batch_size", "=", "eval_bs", ",", "\n", ")", "\n", "\n", "# log final results", "\n", "if", "enable_wandb", ":", "\n", "        ", "tracker", ".", "log_metrics", "(", "\n", "metrics", "=", "metric_results", ".", "to_flat_dict", "(", ")", ",", "\n", "step", "=", "num_epochs", "+", "1", ",", "\n", "prefix", "=", "'test'", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"Test results\"", ")", "\n", "print", "(", "metric_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.inductive_lp.nodepiece_tokenizer.NodePiece_Tokenizer.__init__": [[21, 81], ["super().__init__", "set", "set().issubset", "nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg", "max", "Exception", "sum", "len", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.values", "set", "enumerate", "len", "enumerate", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.keys", "list", "nodepiece_tokenizer.NodePiece_Tokenizer.vocab.items", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.relation_to_id.values"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg"], ["def", "__init__", "(", "self", ",", "\n", "triples", ":", "TriplesFactory", ",", "\n", "dataset_name", ":", "str", ",", "\n", "num_anchors", ":", "int", ",", "\n", "anchor_strategy", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "limit_shortest", ":", "int", "=", "0", ",", "\n", "limit_random", ":", "int", "=", "0", ",", "\n", "add_identity", ":", "bool", "=", "True", ",", "\n", "mode", ":", "str", "=", "\"path\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "triples_factory", "=", "triples", "# original triples of the training graph, assuming inverses are added", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "num_anchors", "=", "num_anchors", "# total N anchor nodes", "\n", "self", ".", "anchor_strategy", "=", "anchor_strategy", "# ratios of strategies for sampling anchor nodes", "\n", "self", ".", "num_paths", "=", "num_anchors", "# aux variable", "\n", "self", ".", "sp_limit", "=", "limit_shortest", "# keep only K nearest anchor nodes per entity", "\n", "self", ".", "rand_limit", "=", "limit_random", "# keep only K random anchor nodes per entity", "\n", "\n", "if", "self", ".", "sp_limit", "*", "self", ".", "rand_limit", "!=", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"-sp_limit and -rand_limit are mutually exclusive\"", ")", "\n", "\n", "", "self", ".", "add_identity", "=", "add_identity", "# anchor nodes will have their own indices with distance 0  in their hashes", "\n", "self", ".", "tkn_mode", "=", "mode", "# only \"path\" mode is implemented atm", "\n", "\n", "# auxiliary tokens for the vocabulary", "\n", "self", ".", "NOTHING_TOKEN", "=", "-", "99", "# means the node is not reachable from any of anchor nodes", "\n", "self", ".", "CLS_TOKEN", "=", "-", "1", "\n", "self", ".", "MASK_TOKEN", "=", "-", "10", "\n", "self", ".", "PADDING_TOKEN", "=", "-", "100", "\n", "self", ".", "SEP_TOKEN", "=", "-", "2", "\n", "\n", "# well, betwenness is disabled", "\n", "self", ".", "AVAILABLE_STRATEGIES", "=", "set", "(", "[", "\"degree\"", ",", "\"betweenness\"", ",", "\"pagerank\"", ",", "\"random\"", "]", ")", "\n", "\n", "assert", "sum", "(", "self", ".", "anchor_strategy", ".", "values", "(", ")", ")", "==", "1.0", ",", "\"Ratios of strategies should sum up to one\"", "\n", "assert", "set", "(", "self", ".", "anchor_strategy", ".", "keys", "(", ")", ")", ".", "issubset", "(", "self", ".", "AVAILABLE_STRATEGIES", ")", "\n", "\n", "# load or create the vocabulary", "\n", "self", ".", "top_entities", ",", "self", ".", "other_entities", ",", "self", ".", "vocab", "=", "self", ".", "tokenize_kg", "(", ")", "\n", "\n", "# numerical indices for entities and relations", "\n", "self", ".", "token2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "top_entities", ")", "}", "\n", "self", ".", "rel2token", "=", "{", "t", ":", "i", "+", "len", "(", "self", ".", "top_entities", ")", "for", "i", ",", "t", "in", "\n", "enumerate", "(", "list", "(", "self", ".", "triples_factory", ".", "relation_to_id", ".", "values", "(", ")", ")", ")", "}", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "token2id", ")", "+", "len", "(", "self", ".", "rel2token", ")", "\n", "\n", "# although we don't use paths, we count their lengths for anchor distances", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", "]", ")", "\n", "\n", "if", "self", ".", "add_identity", ":", "\n", "# add identity for anchor nodes as the first / closest node", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "# last 4 are always service tokens", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "=", "[", "[", "anchor", "]", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", ":", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "anchor", "in", "self", ".", "top_entities", "[", ":", "-", "4", "]", ":", "\n", "                    ", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "=", "[", "anchor", "]", "+", "self", ".", "vocab", "[", "anchor", "]", "[", "'ancs'", "]", "[", ":", "-", "1", "]", "\n", "self", ".", "vocab", "[", "anchor", "]", "[", "'dists'", "]", "[", "0", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.inductive_lp.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg": [[84, 144], ["pathlib.Path", "pathlib.Path.is_file", "igraph.Graph", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.items", "nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths", "pickle.dump", "print", "filename.split", "pickle.load", "type", "print", "int", "print", "anchors.extend", "print", "open", "open", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory.mapped_triples[].numpy", "zip", "numpy.ceil", "sorted", "range", "list", "NotImplementedError", "sorted", "len", "enumerate", "igraph.Graph.degree", "enumerate", "int", "numpy.random.permutation", "igraph.Graph.personalized_pagerank", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths"], ["", "", "", "", "def", "tokenize_kg", "(", "self", ")", ":", "\n", "\n", "# creating a filename", "\n", "        ", "strategy_encoding", "=", "f\"d{self.anchor_strategy['degree']}_b{self.anchor_strategy['betweenness']}_p{self.anchor_strategy['pagerank']}_r{self.anchor_strategy['random']}\"", "\n", "\n", "filename", "=", "f\"data/{self.dataset_name}_{self.num_anchors}_anchors_{self.num_paths}_paths_{strategy_encoding}_pykeen\"", "\n", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.sp_limit}sp\"", "# for separating vocabs with limited mined shortest paths", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "            ", "filename", "+=", "f\"_{self.rand_limit}rand\"", "\n", "", "if", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "            ", "filename", "+=", "\"_bfs\"", "\n", "", "filename", "+=", "\".pkl\"", "\n", "self", ".", "model_name", "=", "filename", ".", "split", "(", "'.pkl'", ")", "[", "0", "]", "\n", "path", "=", "Path", "(", "filename", ")", "\n", "if", "path", ".", "is_file", "(", ")", ":", "\n", "            ", "anchors", ",", "non_anchors", ",", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "return", "anchors", ",", "non_anchors", ",", "vocab", "\n", "\n", "", "if", "type", "(", "self", ".", "triples_factory", ".", "mapped_triples", ")", "==", "torch", ".", "Tensor", ":", "\n", "            ", "src", ",", "tgt", ",", "rels", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "0", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "2", "]", ".", "numpy", "(", ")", ",", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "1", "]", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Input triples are expected to be in the torch.Tensor format\"", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "# create an input object for iGraph - edge list with relation types, and then create a graph", "\n", "", "edgelist", "=", "[", "[", "s", ",", "t", "]", "for", "s", ",", "t", ",", "r", "in", "zip", "(", "src", ",", "tgt", ",", "rels", ")", "]", "\n", "graph", "=", "Graph", "(", "n", "=", "self", ".", "triples_factory", ".", "num_entities", ",", "edges", "=", "edgelist", ",", "edge_attrs", "=", "{", "'relation'", ":", "list", "(", "rels", ")", "}", ",", "directed", "=", "True", ")", "\n", "\n", "# sampling anchor nodes", "\n", "anchors", "=", "[", "]", "\n", "for", "strategy", ",", "ratio", "in", "self", ".", "anchor_strategy", ".", "items", "(", ")", ":", "\n", "            ", "if", "ratio", "<=", "0.0", ":", "\n", "                ", "continue", "\n", "", "topK", "=", "int", "(", "np", ".", "ceil", "(", "ratio", "*", "self", ".", "num_anchors", ")", ")", "\n", "print", "(", "f\"Computing the {strategy} nodes\"", ")", "\n", "if", "strategy", "==", "\"degree\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "degree", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"betweenness\"", ":", "\n", "# This is O(V^3) - disabled", "\n", "                ", "raise", "NotImplementedError", "(", "\"Betweenness is disabled due to computational costs\"", ")", "\n", "", "elif", "strategy", "==", "\"pagerank\"", ":", "\n", "                ", "top_nodes", "=", "sorted", "(", "[", "(", "i", ",", "n", ")", "for", "i", ",", "n", "in", "enumerate", "(", "graph", ".", "personalized_pagerank", "(", ")", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "", "elif", "strategy", "==", "\"random\"", ":", "\n", "                ", "top_nodes", "=", "[", "(", "int", "(", "k", ")", ",", "1", ")", "for", "k", "in", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", "]", "\n", "\n", "", "selected_nodes", "=", "[", "node", "for", "node", ",", "d", "in", "top_nodes", "if", "node", "not", "in", "anchors", "]", "[", ":", "topK", "]", "\n", "\n", "anchors", ".", "extend", "(", "selected_nodes", ")", "\n", "print", "(", "f\"Added {len(selected_nodes)} nodes under the {strategy} strategy\"", ")", "\n", "\n", "# now mine the anchors per node", "\n", "", "vocab", "=", "self", ".", "create_all_paths", "(", "graph", ",", "anchors", ")", "\n", "top_entities", "=", "anchors", "+", "[", "self", ".", "CLS_TOKEN", "]", "+", "[", "self", ".", "MASK_TOKEN", "]", "+", "[", "self", ".", "PADDING_TOKEN", "]", "+", "[", "self", ".", "SEP_TOKEN", "]", "\n", "non_core_entities", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "if", "i", "not", "in", "anchors", "]", "\n", "\n", "pickle", ".", "dump", "(", "(", "top_entities", ",", "non_core_entities", ",", "vocab", ")", ",", "open", "(", "filename", ",", "\"wb\"", ")", ")", "\n", "print", "(", "\"Vocabularized and saved!\"", ")", "\n", "\n", "return", "top_entities", ",", "non_core_entities", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.inductive_lp.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths": [[146, 192], ["tqdm.tqdm.tqdm", "print", "print", "set", "range", "graph.get_shortest_paths", "len", "random.shuffle", "sorted", "len", "graph.neighborhood", "list", "nearest_ancs.extend", "anc_dists.extend", "range", "set().intersection().difference", "nearest_ancs.extend", "anc_dists.extend", "len", "set", "len", "set().intersection", "range", "len", "range", "range", "set", "len", "len"], "methods", ["None"], ["", "def", "create_all_paths", "(", "self", ",", "graph", ":", "Graph", ",", "top_entities", ":", "List", "=", "None", ")", "->", "Dict", "[", "int", ",", "List", "]", ":", "\n", "\n", "        ", "vocab", "=", "{", "}", "\n", "if", "self", ".", "rand_limit", "==", "0", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.sp_limit if self.sp_limit >0 else self.num_paths} shortest paths per node\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Computing the entity vocabulary - paths, retaining {self.rand_limit} random paths per node\"", ")", "\n", "\n", "", "if", "self", ".", "tkn_mode", ":", "\n", "            ", "anc_set", "=", "set", "(", "top_entities", ")", "\n", "\n", "# single-threaded mining is found to be as fast as multi-processing + igraph for some reason, so let's use a dummy for-loop", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", ")", ":", "\n", "            ", "if", "self", ".", "tkn_mode", "==", "\"path\"", ":", "\n", "                ", "paths", "=", "graph", ".", "get_shortest_paths", "(", "v", "=", "i", ",", "to", "=", "top_entities", ",", "output", "=", "\"epath\"", ",", "mode", "=", "'in'", ")", "\n", "if", "len", "(", "paths", "[", "0", "]", ")", ">", "0", ":", "\n", "                    ", "relation_paths", "=", "[", "[", "graph", ".", "es", "[", "path", "[", "-", "1", "]", "]", ".", "source", "]", "+", "[", "graph", ".", "es", "[", "k", "]", "[", "'relation'", "]", "for", "k", "in", "path", "[", ":", ":", "-", "1", "]", "]", "for", "path", "in", "paths", "if", "len", "(", "path", ")", ">", "0", "]", "\n", "", "else", ":", "\n", "# if NO anchor can be reached from the node - encode with a special NOTHING_TOKEN", "\n", "                    ", "relation_paths", "=", "[", "[", "self", ".", "NOTHING_TOKEN", "]", "for", "_", "in", "range", "(", "self", ".", "num_paths", ")", "]", "\n", "", "if", "self", ".", "sp_limit", ">", "0", ":", "\n", "                    ", "relation_paths", "=", "sorted", "(", "relation_paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "self", ".", "sp_limit", "]", "\n", "", "if", "self", ".", "rand_limit", ">", "0", ":", "\n", "                    ", "random", ".", "shuffle", "(", "relation_paths", ")", "\n", "relation_paths", "=", "relation_paths", "[", ":", "self", ".", "rand_limit", "]", "\n", "", "vocab", "[", "i", "]", "=", "relation_paths", "\n", "", "elif", "self", ".", "tkn_mode", "==", "\"bfs\"", ":", "\n", "# overall limit of anchors per node", "\n", "                ", "limit", "=", "self", ".", "sp_limit", "if", "self", ".", "sp_limit", "!=", "0", "else", "(", "self", ".", "rand_limit", "if", "self", ".", "rand_limit", "!=", "0", "else", "self", ".", "num_paths", ")", "\n", "nearest_ancs", ",", "anc_dists", "=", "[", "]", ",", "[", "]", "\n", "hop", "=", "1", "\n", "while", "len", "(", "nearest_ancs", ")", "<", "limit", ":", "\n", "                    ", "neigbs", "=", "graph", ".", "neighborhood", "(", "vertices", "=", "i", ",", "order", "=", "hop", ",", "mode", "=", "\"in\"", ",", "mindist", "=", "hop", ")", "# get k-hop neighbors", "\n", "ancs", "=", "list", "(", "set", "(", "neigbs", ")", ".", "intersection", "(", "anc_set", ")", ".", "difference", "(", "set", "(", "nearest_ancs", ")", ")", ")", "# find anchors in this neighborhood", "\n", "nearest_ancs", ".", "extend", "(", "ancs", ")", "# update the list of anchors", "\n", "anc_dists", ".", "extend", "(", "[", "hop", "for", "_", "in", "range", "(", "len", "(", "ancs", ")", ")", "]", ")", "# update the list of anchor distances", "\n", "hop", "+=", "1", "\n", "if", "hop", ">=", "50", ":", "# hardcoded constant for a disconnected node", "\n", "                        ", "nearest_ancs", ".", "extend", "(", "[", "self", ".", "NOTHING_TOKEN", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "nearest_ancs", ")", ")", "]", ")", "\n", "anc_dists", ".", "extend", "(", "[", "0", "for", "_", "in", "range", "(", "limit", "-", "len", "(", "anc_dists", ")", ")", "]", ")", "\n", "break", "\n", "", "", "vocab", "[", "i", "]", "=", "{", "'ancs'", ":", "nearest_ancs", "[", ":", "limit", "]", ",", "'dists'", ":", "anc_dists", "[", ":", "limit", "]", "}", "# update the vocabulary", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "return", "vocab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.__init__": [[21, 239], ["pykeen.models.Model.__init__", "torch.nn.Embedding", "collections.defaultdict", "collections.defaultdict", "print", "print", "torch.tensor", "torch.tensor", "comp_gcn.StarE_PyG_Encoder", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoder", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Embedding", "torch.tensor", "torch.zeros", "torch.zeros", "e2r[].add", "ind_e2r[].add", "len", "len", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.Linear", "max", "print", "random.sample", "row[].item", "row[].item", "collections.defaultdict.items", "collections.defaultdict.items", "random.sample", "range", "len", "NotImplementedError", "list", "range", "min", "numpy.mean", "numpy.percentile", "max", "min", "numpy.mean", "numpy.percentile", "max", "random.sample", "range", "random.sample", "max", "print", "sampled_paths.items", "sampled_paths.items", "len", "sampled_paths.items", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "range", "min", "min", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "row[].item", "row[].item", "len", "len", "min", "min", "min", "sorted", "nodepiece_rotate.NodePieceRotate.tokenizer.vocab.items", "len", "len", "len", "len", "len", "len", "len", "len", "len", "min", "sampled_paths.items", "len", "min", "min", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample"], ["triples", ":", "TriplesFactory", "=", "None", ",", "\n", "device", ":", "torch", ".", "device", "=", "None", ",", "\n", "loss", ":", "Loss", "=", "None", ",", "\n", "max_paths", ":", "int", "=", "None", ",", "# max anchors per node", "\n", "subbatch", ":", "int", "=", "32", ",", "\n", "max_seq_len", ":", "int", "=", "None", ",", "# tied with anchor distances", "\n", "embedding_dim", ":", "int", "=", "100", ",", "\n", "hid_dim", ":", "int", "=", "200", ",", "# hidden dim for the hash encoder", "\n", "num_heads", ":", "int", "=", "4", ",", "# for Trf", "\n", "num_layers", ":", "int", "=", "2", ",", "# for Trf", "\n", "pooler", ":", "str", "=", "\"cat\"", ",", "# \"cat\" or \"trf\"", "\n", "drop_prob", ":", "float", "=", "0.1", ",", "# dropout", "\n", "use_distances", ":", "bool", "=", "True", ",", "\n", "rel_policy", ":", "str", "=", "\"sum\"", ",", "\n", "random_hashes", ":", "int", "=", "0", ",", "# for ablations", "\n", "nearest", ":", "bool", "=", "True", ",", "# use only K nearest anchors per node", "\n", "sample_rels", ":", "int", "=", "0", ",", "# size of the relational context", "\n", "ablate_anchors", ":", "bool", "=", "False", ",", "# for ablations - node hashes will be constructed only from the relational context", "\n", "tkn_mode", ":", "str", "=", "\"path\"", ",", "# default NodePiece vocabularization strategy", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "triples_factory", "=", "triples", ",", "\n", "loss", "=", "loss", ",", "\n", "predict_with_sigmoid", "=", "False", ",", "\n", "automatic_memory_optimization", "=", "False", ",", "\n", "preferred_device", "=", "device", ",", "\n", ")", "\n", "\n", "self", ".", "pooler", "=", "pooler", "\n", "self", ".", "policy", "=", "rel_policy", "\n", "self", ".", "nearest", "=", "nearest", "\n", "self", ".", "sample_rels", "=", "sample_rels", "\n", "self", ".", "ablate_anchors", "=", "ablate_anchors", "\n", "self", ".", "tkn_mode", "=", "tkn_mode", "\n", "\n", "# cat pooler - concat all anchors+relations in one big vector, pass through a 2-layer MLP", "\n", "if", "pooler", "==", "\"cat\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "(", "max_paths", "+", "sample_rels", ")", ",", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "2", ",", "embedding_dim", ")", "\n", ")", "if", "not", "self", ".", "ablate_anchors", "else", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "sample_rels", ",", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "embedding_dim", "*", "2", ",", "embedding_dim", ")", "\n", ")", "\n", "# trf pooler - vanilla transformer encoder with mean pooling on top", "\n", "", "elif", "pooler", "==", "\"trf\"", ":", "\n", "            ", "encoder_layer", "=", "TransformerEncoderLayer", "(", "\n", "d_model", "=", "embedding_dim", ",", "\n", "nhead", "=", "num_heads", ",", "\n", "dim_feedforward", "=", "hid_dim", ",", "\n", "dropout", "=", "drop_prob", ",", "\n", ")", "\n", "self", ".", "set_enc", "=", "TransformerEncoder", "(", "encoder_layer", "=", "encoder_layer", ",", "num_layers", "=", "num_layers", ")", "\n", "\n", "\n", "\n", "", "self", ".", "device", "=", "device", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "triples_factory", "=", "triples", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "random_hashes", "=", "random_hashes", "\n", "\n", "self", ".", "subbatch", "=", "subbatch", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "real_embedding_dim", "=", "embedding_dim", "//", "2", "# RotatE interaction assumes vectors conists of two parts: real and imaginary", "\n", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "sample_paths", "=", "max_paths", "\n", "self", ".", "use_distances", "=", "use_distances", "\n", "\n", "# pykeen stuff", "\n", "self", ".", "automatic_memory_optimization", "=", "False", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "NOTHING_TOKEN", "]", "=", "len", "(", "tokenizer", ".", "token2id", ")", "-", "1", "# TODO this is a bugfix as PathTrfEncoder puts its own index here", "\n", "\n", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tokenizer", ".", "token2id", ")", ",", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", ")", "\n", "self", ".", "relation_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "triples_factory", ".", "num_relations", "+", "1", ",", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "self", ".", "triples_factory", ".", "num_relations", ")", "\n", "self", ".", "dist_emb", "=", "nn", ".", "Embedding", "(", "self", ".", "max_seq_len", ",", "embedding_dim", "=", "embedding_dim", ")", "\n", "self", ".", "entity_embeddings", "=", "None", "\n", "\n", "# now fix anchors per node for each node in a graph, either deterministically or randomly", "\n", "# we do it mostly for speed reasons, although this process can happen during the forward pass either", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "if", "self", ".", "tkn_mode", "!=", "\"bfs\"", ":", "\n", "# DETERMINISTIC strategy", "\n", "                ", "if", "not", "self", ".", "nearest", ":", "\n", "# subsample paths, need to align them with distances", "\n", "                    ", "sampled_paths", "=", "{", "\n", "entity", ":", "random", ".", "sample", "(", "paths", ",", "k", "=", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", ")", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "self", ".", "nearest", ":", "\n", "# sort paths by length first and take K of them", "\n", "                    ", "sampled_paths", "=", "{", "\n", "entity", ":", "sorted", "(", "paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", "]", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "max_seq_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "sampled_paths", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "print", "(", "f\"Changed max seq len from {max_seq_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "path", "[", "0", "]", "]", "for", "path", "in", "paths", "]", "+", "[", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "len", "(", "path", ")", "-", "1", "for", "path", "in", "paths", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "total_paths", "=", "[", "\n", "[", "len", "(", "paths", ")", "]", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "", "else", ":", "\n", "# only nearest neighbors mode", "\n", "                ", "if", "not", "self", ".", "nearest", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"bfs mode works only with -nn True\"", ")", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "token", "]", "for", "token", "in", "vals", "[", "'ancs'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "]", "]", "+", "[", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'ancs'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "d", "for", "d", "in", "vals", "[", "'dists'", "]", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "]", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "vals", "[", "'dists'", "]", ")", ")", "\n", "for", "entity", ",", "vals", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "]", "\n", "total_paths", "=", "distances", "\n", "self", ".", "max_seq_len", "=", "max", "(", "[", "d", "for", "row", "in", "distances", "for", "d", "in", "row", "]", ")", "\n", "print", "(", "f\"Changed max seq len from {max_seq_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "tensor", "(", "distances", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "total_paths", "=", "torch", ".", "tensor", "(", "total_paths", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "else", ":", "\n", "# RANDOM strategy", "\n", "# in this case, we bypass distances and won't use relations in the encoder", "\n", "            ", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "random_hashes", ",", "embedding_dim", "=", "embedding_dim", ")", "\n", "hashes", "=", "[", "\n", "random", ".", "sample", "(", "list", "(", "range", "(", "random_hashes", ")", ")", ",", "self", ".", "sample_paths", ")", "\n", "for", "i", "in", "range", "(", "triples", ".", "num_entities", ")", "\n", "]", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "zeros", "(", "(", "triples", ".", "num_entities", ",", "self", ".", "sample_paths", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "total_paths", "=", "torch", ".", "zeros", "(", "(", "triples", ".", "num_entities", ",", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# creating the relational context of M unique outgoing relation types for each node", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "pad_idx", "=", "self", ".", "triples_factory", ".", "num_relations", "\n", "e2r", "=", "defaultdict", "(", "set", ")", "\n", "for", "row", "in", "self", ".", "triples_factory", ".", "mapped_triples", ":", "\n", "                ", "e2r", "[", "row", "[", "0", "]", ".", "item", "(", ")", "]", ".", "add", "(", "row", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "", "len_stats", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "e2r", ".", "items", "(", ")", "]", "\n", "print", "(", "f\"Unique relations per node - min: {min(len_stats)}, avg: {np.mean(len_stats)}, 66th perc: {np.percentile(len_stats, 66)}, max: {max(len_stats)} \"", ")", "\n", "unique_1hop_relations", "=", "[", "\n", "random", ".", "sample", "(", "e2r", "[", "i", "]", ",", "k", "=", "min", "(", "self", ".", "sample_rels", ",", "len", "(", "e2r", "[", "i", "]", ")", ")", ")", "+", "[", "pad_idx", "]", "*", "(", "self", ".", "sample_rels", "-", "min", "(", "len", "(", "e2r", "[", "i", "]", ")", ",", "self", ".", "sample_rels", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "triples_factory", ".", "num_entities", ")", "\n", "]", "\n", "self", ".", "unique_1hop_relations", "=", "torch", ".", "tensor", "(", "unique_1hop_relations", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "", "", "def", "_reset_parameters_", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooler", "!=", "\"avg\"", ":", "\n", "            ", "for", "module", "in", "self", ".", "set_enc", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "                ", "for", "module", "in", "self", ".", "set_dec", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "module", "is", "self", ":", "\n", "                        ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                        ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "\n", "", "", "", "", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "anchor_embeddings", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dist_emb", ".", "weight", ")", "\n", "\n", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "anchor_embeddings", ".", "weight", "[", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "dist_emb", ".", "weight", "[", "0", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "\n", "\n", "# for RotatE: phases randomly between 0 and 2 pi", "\n", "", "", "phases", "=", "2", "*", "np", ".", "pi", "*", "torch", ".", "rand", "(", "self", ".", "num_relations", ",", "self", ".", "real_embedding_dim", ",", "device", "=", "self", ".", "device", ")", "\n", "relations", "=", "torch", ".", "stack", "(", "[", "torch", ".", "cos", "(", "phases", ")", ",", "torch", ".", "sin", "(", "phases", ")", "]", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "torch", ".", "norm", "(", "relations", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", ",", "phases", ".", "new_ones", "(", "size", "=", "(", "1", ",", "1", ")", ")", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "[", ":", "-", "1", "]", "=", "relations", ".", "view", "(", "self", ".", "num_relations", ",", "self", ".", "embedding_dim", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "[", "-", "1", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "\n", "\n", "", "def", "post_parameter_update", "(", "self", ")", ":", "# noqa: D102", "\n", "\n", "# Make sure to call super first", "\n", "        ", "super", "(", ")", ".", "post_parameter_update", "(", ")", "\n", "\n", "# Normalize relation embeddings", "\n", "rel", "=", "self", ".", "relation_embeddings", ".", "weight", ".", "data", ".", "view", "(", "self", ".", "num_relations", "+", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "rel", "=", "functional", ".", "normalize", "(", "rel", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "self", ".", "relation_embeddings", ".", "weight", ".", "data", "=", "rel", ".", "view", "(", "self", ".", "num_relations", "+", "1", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "self", ".", "entity_embeddings", "=", "None", "\n", "\n", "\n", "", "def", "pool_anchors", "(", "self", ",", "anc_embs", ":", "torch", ".", "FloatTensor", ",", "mask", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        input shape: (bs, num_anchors + relational_context, emb_dim)\n        output shape: (bs, emb_dim)\n        \"\"\"", "\n", "\n", "if", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "anc_embs", "=", "anc_embs", ".", "view", "(", "anc_embs", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ")", "if", "self", ".", "sample_paths", "!=", "1", "else", "anc_embs", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", ":", "\n", "            ", "pooled", "=", "self", ".", "set_enc", "(", "anc_embs", ".", "transpose", "(", "1", ",", "0", ")", ")", "# output shape: (seq_len, bs, dim)", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate._reset_parameters_": [[244, 280], ["torch.stack().detach", "torch.allclose", "torch.stack().detach.view", "torch.zeros", "nodepiece_rotate.NodePieceRotate.set_enc.modules", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.rand", "torch.norm", "phases.new_ones", "nodepiece_rotate.NodePieceRotate.gnn_encoder.reset_parameters", "hasattr", "nodepiece_rotate.NodePieceRotate.set_dec.modules", "torch.stack", "module.reset_parameters", "hasattr", "torch.no_grad", "torch.zeros", "torch.zeros", "module.reset_parameters", "torch.cos", "torch.sin"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["\n", "", "def", "encode_by_index", "(", "self", ",", "entities", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "# take a node index and find its NodePiece hash", "\n", "\n", "        ", "hashes", ",", "dists", ",", "ids", "=", "self", ".", "hashes", "[", "entities", "]", ",", "self", ".", "distances", "[", "entities", "]", ",", "self", ".", "total_paths", "[", "entities", "]", "\n", "\n", "anc_embs", "=", "self", ".", "anchor_embeddings", "(", "hashes", ")", "\n", "mask", "=", "None", "\n", "\n", "if", "self", ".", "use_distances", ":", "\n", "            ", "dist_embs", "=", "self", ".", "dist_emb", "(", "dists", ")", "\n", "anc_embs", "+=", "dist_embs", "\n", "\n", "# for ablations: drop anchors entirely", "\n", "", "if", "self", ".", "ablate_anchors", ":", "\n", "            ", "anc_embs", "=", "torch", ".", "tensor", "(", "[", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# add relational context (if its size > 0 )", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "rels", "=", "self", ".", "unique_1hop_relations", "[", "entities", "]", "# (bs, rel_sample_size)", "\n", "rels", "=", "self", ".", "relation_embeddings", "(", "rels", ")", "# (bs, rel_sample_size, dim)", "\n", "anc_embs", "=", "torch", ".", "cat", "(", "[", "anc_embs", ",", "rels", "]", ",", "dim", "=", "1", ")", "# (bs, ancs+rel_sample_size, dim)", "\n", "\n", "", "anc_embs", "=", "self", ".", "pool_anchors", "(", "anc_embs", ",", "mask", "=", "mask", ")", "# (bs, dim)", "\n", "\n", "return", "anc_embs", "\n", "\n", "\n", "", "def", "get_all_representations", "(", "self", ")", ":", "\n", "\n", "# materialize embeddings for all nodes in a graph for scoring", "\n", "\n", "        ", "temp_embs", "=", "torch", ".", "zeros", "(", "(", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "embedding_dim", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "vocab_keys", "=", "list", "(", "range", "(", "len", "(", "self", ".", "hashes", ")", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "self", ".", "hashes", ")", ",", "self", ".", "subbatch", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.post_parameter_update": [[282, 293], ["super().post_parameter_update", "nodepiece_rotate.NodePieceRotate.relation_embeddings.weight.data.view", "torch.nn.functional.normalize", "torch.nn.functional.normalize.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.post_parameter_update", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize"], ["embs", "=", "self", ".", "encode_by_index", "(", "entities", ")", "\n", "temp_embs", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", "]", "=", "embs", "\n", "\n", "", "return", "temp_embs", "\n", "\n", "\n", "", "@", "staticmethod", "\n", "def", "pairwise_interaction_function", "(", "\n", "h", ":", "torch", ".", "FloatTensor", ",", "\n", "r", ":", "torch", ".", "FloatTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.pool_anchors": [[295, 309], ["anc_embs.view.view.view", "nodepiece_rotate.NodePieceRotate.set_enc", "nodepiece_rotate.NodePieceRotate.set_enc", "pooled.mean.mean.mean", "anc_embs.view.view.transpose"], "methods", ["None"], ["        ", "h_re", "=", "h", "[", "...", ",", "0", "]", "\n", "h_im", "=", "h", "[", "...", ",", "1", "]", "\n", "r_re", "=", "r", "[", "...", ",", "0", "]", "\n", "r_im", "=", "r", "[", "...", ",", "1", "]", "\n", "\n", "# Rotate (=Hadamard product in complex space).", "\n", "rot_h", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "h_re", "*", "r_re", "-", "h_im", "*", "r_im", ",", "\n", "h_re", "*", "r_im", "+", "h_im", "*", "r_re", ",", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "\n", "return", "rot_h", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_by_index": [[311, 341], ["torch.tensor", "nodepiece_rotate.NodePieceRotate.pool_anchors", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "torch.cat", "mask.to"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors"], ["", "@", "staticmethod", "\n", "def", "interaction_function", "(", "\n", "h", ":", "torch", ".", "FloatTensor", ",", "\n", "r", ":", "torch", ".", "FloatTensor", ",", "\n", "t", ":", "torch", ".", "FloatTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "# Decompose into real and imaginary part", "\n", "        ", "h_re", "=", "h", "[", "...", ",", "0", "]", "\n", "h_im", "=", "h", "[", "...", ",", "1", "]", "\n", "r_re", "=", "r", "[", "...", ",", "0", "]", "\n", "r_im", "=", "r", "[", "...", ",", "1", "]", "\n", "\n", "# Rotate (=Hadamard product in complex space).", "\n", "rot_h", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "h_re", "*", "r_re", "-", "h_im", "*", "r_im", ",", "\n", "h_re", "*", "r_im", "+", "h_im", "*", "r_re", ",", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "# Workaround until https://github.com/pytorch/pytorch/issues/30704 is fixed", "\n", "diff", "=", "rot_h", "-", "t", "\n", "scores", "=", "-", "torch", ".", "norm", "(", "diff", ".", "view", "(", "diff", ".", "shape", "[", ":", "-", "2", "]", "+", "(", "-", "1", ",", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "scores", "\n", "\n", "", "def", "score_hrt", "(", "self", ",", "hrt_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "\n", "# when training with large # of neg samples the hrt_batch size can be too big to fit into memory, so chunk it", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.get_all_representations": [[343, 362], ["torch.zeros", "list", "range", "len", "len", "range", "torch.tensor", "nodepiece_rotate.NodePieceRotate.encode_by_index"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], ["# Get embeddings", "\n", "            ", "h", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hrt_batch", "[", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "t", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", ":", ",", "2", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "hrt_batch", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "hrt_batch", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "hrt_batch", ".", "shape", "[", "0", "]", ",", "self", ".", "subbatch", ")", ":", "\n", "                ", "h", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "t", "=", "self", ".", "encode_by_index", "(", "hrt_batch", "[", "i", ":", "i", "+", "self", ".", "subbatch", ",", "2", "]", ")", ".", "view", "(", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "scores", "[", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn": [[363, 383], ["torch_geometric.data.Data", "nodepiece_rotate.NodePieceRotate.get_all_representations", "torch.cat", "torch.cat", "nodepiece_rotate.NodePieceRotate.gnn_encoder.forward_base", "torch_geometric.data.Data.to"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.comp_gcn.StarE_PyG_Encoder.forward_base"], ["\n", "", "def", "score_t", "(", "self", ",", "hr_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "# Get embeddings", "\n", "        ", "h", "=", "self", ".", "encode_by_index", "(", "hr_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "r", "=", "self", ".", "relation_embeddings", "(", "hr_batch", "[", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Rank against all entities, don't use hard negs, EXPENSIVE", "\n", "t", "=", "self", ".", "get_all_representations", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "if", "self", ".", "subbatch", "==", "0", ":", "\n", "            ", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "hr_batch", ".", "shape", "[", "0", "]", ",", "t", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "hr_batch", ".", "device", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "t", ".", "shape", "[", "1", "]", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "                ", "temp_scores", "=", "self", ".", "interaction_function", "(", "h", "=", "h", ",", "r", "=", "r", ",", "t", "=", "t", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", ",", ":", "]", ")", "\n", "scores", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "temp_scores", "\n", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn_entities": [[384, 387], ["nodepiece_rotate.NodePieceRotate.encode_gnn"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn"], ["", "def", "score_h", "(", "self", ",", "rt_batch", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "# noqa: D102", "\n", "\n", "# Get embeddings", "\n", "        ", "r", "=", "self", ".", "relation_embeddings", "(", "rt_batch", "[", ":", ",", "0", "]", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.pairwise_interaction_function": [[389, 411], ["torch.cat"], "methods", ["None"], ["\n", "r_inv", "=", "torch", ".", "stack", "(", "[", "r", "[", ":", ",", ":", ",", ":", ",", "0", "]", ",", "-", "r", "[", ":", ",", ":", ",", ":", ",", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Rank against all entities", "\n", "h", "=", "self", ".", "get_all_representations", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "real_embedding_dim", ",", "2", ")", "\n", "\n", "# Compute scores", "\n", "if", "self", ".", "subbatch", "==", "0", ":", "\n", "            ", "scores", "=", "self", ".", "interaction_function", "(", "h", "=", "t", ",", "r", "=", "r_inv", ",", "t", "=", "h", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "zeros", "(", "(", "rt_batch", ".", "shape", "[", "0", "]", ",", "t", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "rt_batch", ".", "device", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "t", ".", "shape", "[", "1", "]", ",", "self", ".", "subbatch", ")", ")", ":", "\n", "                ", "temp_scores", "=", "self", ".", "interaction_function", "(", "h", "=", "t", ",", "r", "=", "r_inv", ",", "t", "=", "h", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", ",", ":", ",", ":", "]", ")", "\n", "scores", "[", ":", ",", "i", ":", "i", "+", "self", ".", "subbatch", "]", "=", "temp_scores", "\n", "\n", "\n", "", "", "return", "scores", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function": [[412, 438], ["torch.stack", "torch.norm", "diff.view"], "methods", ["None"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.score_hrt": [[439, 471], ["nodepiece_rotate.NodePieceRotate.interaction_function().view", "torch.zeros", "range", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "nodepiece_rotate.NodePieceRotate.interaction_function().view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.interaction_function", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.interaction_function", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.score_t": [[473, 496], ["nodepiece_rotate.NodePieceRotate.encode_by_index().view", "nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.get_all_representations().view", "nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "nodepiece_rotate.NodePieceRotate.interaction_function", "torch.zeros", "tqdm.tqdm.tqdm", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "range", "nodepiece_rotate.NodePieceRotate.interaction_function", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.get_all_representations"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.score_h": [[497, 524], ["nodepiece_rotate.NodePieceRotate.relation_embeddings().view", "nodepiece_rotate.NodePieceRotate.encode_by_index().view", "torch.stack", "nodepiece_rotate.NodePieceRotate.get_all_representations().view", "nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "torch.stack", "nodepiece_rotate.NodePieceRotate.interaction_function", "torch.zeros", "tqdm.tqdm.tqdm", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "nodepiece_rotate.NodePieceRotate.view", "range", "nodepiece_rotate.NodePieceRotate.interaction_function", "nodepiece_rotate.NodePieceRotate.relation_embeddings", "nodepiece_rotate.NodePieceRotate.encode_by_index", "nodepiece_rotate.NodePieceRotate.get_all_representations"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.encode_gnn_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.nodepiece_rotate.NodePieceRotate.interaction_function", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.__init__": [[18, 75], ["torch_geometric.nn.MessagePassing.__init__", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "utils.utils_gcn.get_param", "utils.utils_gcn.get_param", "gnn_layer.StarEConvLayer.register_parameter", "torch.nn.Linear", "torch.nn.Linear", "utils.utils_gcn.get_param", "torch.nn.Parameter", "torch.nn.Parameter", "utils.utils_gcn.get_param", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.get_param"], ["\n", "self", ".", "p", "=", "config", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_rels", "=", "num_rels", "\n", "self", ".", "act", "=", "act", "\n", "self", ".", "device", "=", "None", "\n", "\n", "self", ".", "w_loop", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_in", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_out", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "self", ".", "w_rel", "=", "get_param", "(", "(", "in_channels", ",", "out_channels", ")", ")", "# (100,200)", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'sum'", "or", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'mul'", "or", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "                ", "self", ".", "w_q", "=", "get_param", "(", "(", "in_channels", ",", "in_channels", ")", ")", "# new for quals setup", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'concat'", ":", "\n", "                ", "self", ".", "w_q", "=", "get_param", "(", "(", "2", "*", "in_channels", ",", "in_channels", ")", ")", "# need 2x size due to the concat operation", "\n", "\n", "", "", "self", ".", "loop_rel", "=", "get_param", "(", "(", "1", ",", "in_channels", ")", ")", "# (1,100)", "\n", "self", ".", "loop_ent", "=", "get_param", "(", "(", "1", ",", "in_channels", ")", ")", "# new", "\n", "\n", "self", ".", "drop", "=", "torch", ".", "nn", ".", "Dropout", "(", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DROP'", "]", ")", "\n", "self", ".", "bn", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "out_channels", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "            ", "assert", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "==", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", ",", "\"Current attn implementation requires those tto be identical\"", "\n", "assert", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", "%", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "==", "0", ",", "\"should be divisible\"", "\n", "self", ".", "heads", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "\n", "self", ".", "attn_dim", "=", "self", ".", "out_channels", "//", "self", ".", "heads", "\n", "self", ".", "negative_slope", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_SLOPE'", "]", "\n", "self", ".", "attn_drop", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_DROP'", "]", "\n", "self", ".", "att", "=", "get_param", "(", "(", "1", ",", "self", ".", "heads", ",", "2", "*", "self", ".", "attn_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "            ", "assert", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'GCN_DIM'", "]", "==", "self", ".", "p", "[", "\n", "'EMBEDDING_DIM'", "]", ",", "\"Current attn implementation requires those tto be identical\"", "\n", "assert", "self", ".", "p", "[", "'EMBEDDING_DIM'", "]", "%", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "==", "0", ",", "\"should be divisible\"", "\n", "if", "not", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "                ", "self", ".", "heads", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_HEADS'", "]", "\n", "self", ".", "attn_dim", "=", "self", ".", "out_channels", "//", "self", ".", "heads", "\n", "self", ".", "negative_slope", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_SLOPE'", "]", "\n", "self", ".", "attn_drop", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION_DROP'", "]", "\n", "", "self", ".", "att_qual", "=", "get_param", "(", "(", "1", ",", "self", ".", "heads", ",", "2", "*", "self", ".", "attn_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'BIAS'", "]", ":", "self", ".", "register_parameter", "(", "'bias'", ",", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "out_channels", ")", ")", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_loop", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_in", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_out", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_rel", ".", "data", ")", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_q", ".", "data", ")", "\n", "", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "loop_rel", ".", "data", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "loop_ent", ".", "data", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.reset_parameters": [[76, 92], ["torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "gnn_layer.StarEConvLayer.bn.reset_parameters", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "gnn_layer.StarEConvLayer.linear.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["self", ".", "bn", ".", "reset_parameters", "(", ")", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "att", ".", "data", ")", "\n", "", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "att_qual", ".", "data", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "edge_index", ",", "edge_type", ",", "rel_embed", ",", "\n", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "quals", "=", "None", ")", ":", "\n", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.forward": [[93, 230], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "gnn_layer.StarEConvLayer.compute_norm", "gnn_layer.StarEConvLayer.compute_norm", "gnn_layer.StarEConvLayer.bn", "edge_index.size", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.propagate", "gnn_layer.StarEConvLayer.linear", "gnn_layer.StarEConvLayer.act", "quals.size", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.full", "torch.full", "torch.full", "torch.full", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "gnn_layer.StarEConvLayer.drop", "gnn_layer.StarEConvLayer.drop", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.compute_norm", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.compute_norm", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.MessagePassing.propagate"], ["\n", "if", "self", ".", "device", "is", "None", ":", "\n", "            ", "self", ".", "device", "=", "edge_index", ".", "device", "\n", "\n", "", "rel_embed", "=", "torch", ".", "cat", "(", "[", "rel_embed", ",", "self", ".", "loop_rel", "]", ",", "dim", "=", "0", ")", "\n", "num_edges", "=", "edge_index", ".", "size", "(", "1", ")", "//", "2", "\n", "num_ent", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "self", ".", "in_index", ",", "self", ".", "out_index", "=", "edge_index", "[", ":", ",", ":", "num_edges", "]", ",", "edge_index", "[", ":", ",", "num_edges", ":", "]", "\n", "self", ".", "in_type", ",", "self", ".", "out_type", "=", "edge_type", "[", ":", "num_edges", "]", ",", "edge_type", "[", "num_edges", ":", "]", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "            ", "num_quals", "=", "quals", ".", "size", "(", "1", ")", "//", "2", "\n", "self", ".", "in_index_qual_ent", ",", "self", ".", "out_index_qual_ent", "=", "quals", "[", "1", ",", ":", "num_quals", "]", ",", "quals", "[", "1", ",", "num_quals", ":", "]", "\n", "self", ".", "in_index_qual_rel", ",", "self", ".", "out_index_qual_rel", "=", "quals", "[", "0", ",", ":", "num_quals", "]", ",", "quals", "[", "0", ",", "num_quals", ":", "]", "\n", "self", ".", "quals_index_in", ",", "self", ".", "quals_index_out", "=", "quals", "[", "2", ",", ":", "num_quals", "]", ",", "quals", "[", "2", ",", "num_quals", ":", "]", "\n", "\n", "", "'''\n            Adding self loop by creating a COO matrix. Thus \\\n             loop index [1,2,3,4,5]\n                        [1,2,3,4,5]\n             loop type [10,10,10,10,10] --> assuming there are 9 relations\n\n\n        '''", "\n", "# Self edges between all the nodes", "\n", "self", ".", "loop_index", "=", "torch", ".", "stack", "(", "[", "torch", ".", "arange", "(", "num_ent", ")", ",", "torch", ".", "arange", "(", "num_ent", ")", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "loop_type", "=", "torch", ".", "full", "(", "(", "num_ent", ",", ")", ",", "rel_embed", ".", "size", "(", "0", ")", "-", "1", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "# if rel meb is 500, the index of the self emb is", "\n", "# 499 .. which is just added here", "\n", "\n", "self", ".", "in_norm", "=", "self", ".", "compute_norm", "(", "self", ".", "in_index", ",", "num_ent", ")", "\n", "self", ".", "out_norm", "=", "self", ".", "compute_norm", "(", "self", ".", "out_index", ",", "num_ent", ")", "\n", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "\n", "            ", "in_res", "=", "self", ".", "propagate", "(", "self", ".", "in_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "in_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "in_norm", ",", "mode", "=", "'in'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "self", ".", "in_index_qual_ent", ",", "\n", "qualifier_rel", "=", "self", ".", "in_index_qual_rel", ",", "\n", "qual_index", "=", "self", ".", "quals_index_in", ",", "\n", "source_index", "=", "self", ".", "in_index", "[", "0", "]", ")", "\n", "\n", "loop_res", "=", "self", ".", "propagate", "(", "self", ".", "loop_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "loop_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "None", ",", "mode", "=", "'loop'", ",", "\n", "ent_embed", "=", "None", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", "\n", "\n", "out_res", "=", "self", ".", "propagate", "(", "self", ".", "out_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "out_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "out_norm", ",", "mode", "=", "'out'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "self", ".", "out_index_qual_ent", ",", "\n", "qualifier_rel", "=", "self", ".", "out_index_qual_rel", ",", "\n", "qual_index", "=", "self", ".", "quals_index_out", ",", "\n", "source_index", "=", "self", ".", "out_index", "[", "0", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "in_res", "=", "self", ".", "propagate", "(", "self", ".", "in_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "in_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "in_norm", ",", "mode", "=", "'in'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "self", ".", "in_index", "[", "0", "]", ")", "\n", "\n", "loop_res", "=", "self", ".", "propagate", "(", "self", ".", "loop_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "loop_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "None", ",", "mode", "=", "'loop'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", "\n", "\n", "out_res", "=", "self", ".", "propagate", "(", "self", ".", "out_index", ",", "x", "=", "x", ",", "edge_type", "=", "self", ".", "out_type", ",", "\n", "rel_embed", "=", "rel_embed", ",", "edge_norm", "=", "self", ".", "out_norm", ",", "mode", "=", "'out'", ",", "\n", "ent_embed", "=", "x", ",", "qualifier_ent", "=", "None", ",", "qualifier_rel", "=", "None", ",", "\n", "qual_index", "=", "None", ",", "source_index", "=", "self", ".", "out_index", "[", "0", "]", ")", "\n", "\n", "\n", "", "out", "=", "self", ".", "drop", "(", "in_res", ")", "*", "(", "1", "/", "3", ")", "+", "self", ".", "drop", "(", "out_res", ")", "*", "(", "1", "/", "3", ")", "+", "loop_res", "*", "(", "1", "/", "3", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'BIAS'", "]", ":", "\n", "            ", "out", "=", "out", "+", "self", ".", "bias", "\n", "", "out", "=", "self", ".", "bn", "(", "out", ")", "\n", "\n", "# Ignoring the self loop inserted, return.", "\n", "return", "self", ".", "act", "(", "out", ")", ",", "torch", ".", "matmul", "(", "rel_embed", ",", "self", ".", "w_rel", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "def", "rel_transform", "(", "self", ",", "ent_embed", ",", "rel_embed", ")", ":", "\n", "        ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'corr'", ":", "\n", "            ", "trans_embed", "=", "ccorr", "(", "ent_embed", ",", "rel_embed", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'sub'", ":", "\n", "            ", "trans_embed", "=", "ent_embed", "-", "rel_embed", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'mult'", ":", "\n", "            ", "trans_embed", "=", "ent_embed", "*", "rel_embed", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'OPN'", "]", "==", "'rotate'", ":", "\n", "            ", "trans_embed", "=", "rotate", "(", "ent_embed", ",", "rel_embed", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "trans_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.rel_transform": [[231, 244], ["utils.utils_gcn.ccorr", "utils.utils_gcn.rotate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.ccorr", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.rotate"], ["", "def", "qual_transform", "(", "self", ",", "qualifier_ent", ",", "qualifier_rel", ")", ":", "\n", "        ", "\"\"\"\n\n        :return:\n        \"\"\"", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'corr'", ":", "\n", "            ", "trans_embed", "=", "ccorr", "(", "qualifier_ent", ",", "qualifier_rel", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'sub'", ":", "\n", "            ", "trans_embed", "=", "qualifier_ent", "-", "qualifier_rel", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'mult'", ":", "\n", "            ", "trans_embed", "=", "qualifier_ent", "*", "qualifier_rel", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_OPN'", "]", "==", "'rotate'", ":", "\n", "            ", "trans_embed", "=", "rotate", "(", "qualifier_ent", ",", "qualifier_rel", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qual_transform": [[245, 262], ["utils.utils_gcn.ccorr", "utils.utils_gcn.rotate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.ccorr", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.rotate"], ["            ", "raise", "NotImplementedError", "\n", "\n", "", "return", "trans_embed", "\n", "\n", "", "def", "qualifier_aggregate", "(", "self", ",", "qualifier_emb", ",", "rel_part_emb", ",", "alpha", "=", "0.5", ",", "qual_index", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qualifier_aggregate": [[263, 325], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "gnn_layer.StarEConvLayer.coalesce_quals", "gnn_layer.StarEConvLayer.coalesce_quals", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "gnn_layer.StarEConvLayer.coalesce_quals", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "expanded_rels.view.view.view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.leaky_relu", "torch.leaky_relu", "utils.utils_gcn.softmax", "torch.dropout", "torch.dropout", "torch_scatter.scatter_add", "rel_part_emb.size", "torch_scatter.scatter_add.sum", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rel_part_emb.size", "torch.dropout.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax"], ["\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'sum'", ":", "\n", "            ", "qualifier_emb", "=", "torch", ".", "einsum", "(", "'ij,jk -> ik'", ",", "\n", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ")", ",", "\n", "self", ".", "w_q", ")", "\n", "return", "alpha", "*", "rel_part_emb", "+", "(", "1", "-", "alpha", ")", "*", "qualifier_emb", "# [N_EDGES / 2 x EMB_DIM]", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'concat'", ":", "\n", "            ", "qualifier_emb", "=", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ")", "\n", "agg_rel", "=", "torch", ".", "cat", "(", "(", "rel_part_emb", ",", "qualifier_emb", ")", ",", "dim", "=", "1", ")", "# [N_EDGES / 2 x 2 * EMB_DIM]", "\n", "return", "torch", ".", "mm", "(", "agg_rel", ",", "self", ".", "w_q", ")", "# [N_EDGES / 2 x EMB_DIM]", "\n", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'mul'", ":", "\n", "            ", "qualifier_emb", "=", "torch", ".", "mm", "(", "self", ".", "coalesce_quals", "(", "qualifier_emb", ",", "qual_index", ",", "rel_part_emb", ".", "shape", "[", "0", "]", ",", "fill", "=", "1", ")", ",", "self", ".", "w_q", ")", "\n", "return", "rel_part_emb", "*", "qualifier_emb", "\n", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_AGGREGATE'", "]", "==", "'attn'", ":", "\n", "# only for sparse mode", "\n", "            ", "expanded_rels", "=", "torch", ".", "index_select", "(", "rel_part_emb", ",", "0", ",", "qual_index", ")", "# Nquals x D", "\n", "expanded_rels", "=", "expanded_rels", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "# Nquals x heads x h_dim", "\n", "qualifier_emb", "=", "torch", ".", "mm", "(", "qualifier_emb", ",", "self", ".", "w_q", ")", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "\n", "self", ".", "attn_dim", ")", "# Nquals x heads x h_dim", "\n", "\n", "alpha_r", "=", "torch", ".", "einsum", "(", "'bij,kij -> bi'", ",", "[", "torch", ".", "cat", "(", "[", "expanded_rels", ",", "qualifier_emb", "]", ",", "dim", "=", "-", "1", ")", ",", "self", ".", "att_qual", "]", ")", "\n", "alpha_r", "=", "F", ".", "leaky_relu", "(", "alpha_r", ",", "self", ".", "negative_slope", ")", "# Nquals x heads", "\n", "alpha_r", "=", "softmax", "(", "alpha_r", ",", "qual_index", ",", "rel_part_emb", ".", "size", "(", "0", ")", ")", "# Nquals x heads", "\n", "alpha_r", "=", "F", ".", "dropout", "(", "alpha_r", ",", "p", "=", "self", ".", "attn_drop", ")", "# Nquals x heads", "\n", "expanded_rels", "=", "(", "expanded_rels", "*", "alpha_r", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "\n", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "# Nquals x D", "\n", "single_rels", "=", "scatter_add", "(", "expanded_rels", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "rel_part_emb", ".", "size", "(", "0", ")", ")", "# Nedges x D", "\n", "copy_mask", "=", "single_rels", ".", "sum", "(", "dim", "=", "1", ")", "!=", "0.0", "\n", "rel_part_emb", "[", "copy_mask", "]", "=", "single_rels", "[", "copy_mask", "]", "# Nedges x D", "\n", "return", "rel_part_emb", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "def", "update_rel_emb_with_qualifier", "(", "self", ",", "ent_embed", ",", "rel_embed", ",", "\n", "qualifier_ent", ",", "qualifier_rel", ",", "edge_type", ",", "qual_index", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier": [[326, 379], ["gnn_layer.StarEConvLayer.qual_transform", "gnn_layer.StarEConvLayer.qualifier_aggregate"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qual_transform", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.qualifier_aggregate"], ["\n", "\n", "# Step 1: embedding", "\n", "qualifier_emb_rel", "=", "rel_embed", "[", "qualifier_rel", "]", "\n", "qualifier_emb_ent", "=", "ent_embed", "[", "qualifier_ent", "]", "\n", "\n", "rel_part_emb", "=", "rel_embed", "[", "edge_type", "]", "\n", "\n", "# Step 2: pass it through qual_transform", "\n", "qualifier_emb", "=", "self", ".", "qual_transform", "(", "qualifier_ent", "=", "qualifier_emb_ent", ",", "\n", "qualifier_rel", "=", "qualifier_emb_rel", ")", "\n", "\n", "# Pass it through a aggregate layer", "\n", "return", "self", ".", "qualifier_aggregate", "(", "qualifier_emb", ",", "rel_part_emb", ",", "alpha", "=", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'TRIPLE_QUAL_WEIGHT'", "]", ",", "\n", "qual_index", "=", "qual_index", ")", "\n", "\n", "# return qualifier_emb", "\n", "", "def", "message", "(", "self", ",", "x_j", ",", "x_i", ",", "edge_type", ",", "rel_embed", ",", "edge_norm", ",", "mode", ",", "ent_embed", "=", "None", ",", "qualifier_ent", "=", "None", ",", "\n", "qualifier_rel", "=", "None", ",", "qual_index", "=", "None", ",", "source_index", "=", "None", ")", ":", "\n", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.message": [[381, 436], ["getattr", "gnn_layer.StarEConvLayer.rel_transform", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "out.view.view.view", "x_i.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.leaky_relu", "torch.leaky_relu", "utils.utils_gcn.softmax", "torch.dropout", "torch.dropout", "gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "ent_embed.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "edge_norm.view", "torch.dropout.view"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.rel_transform", "home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_gcn.softmax", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.update_rel_emb_with_qualifier"], ["\n", "weight", "=", "getattr", "(", "self", ",", "'w_{}'", ".", "format", "(", "mode", ")", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STATEMENT_LEN'", "]", "!=", "3", ":", "\n", "# add code here", "\n", "            ", "if", "mode", "!=", "'loop'", ":", "\n", "                ", "rel_emb", "=", "self", ".", "update_rel_emb_with_qualifier", "(", "ent_embed", ",", "rel_embed", ",", "qualifier_ent", ",", "\n", "qualifier_rel", ",", "edge_type", ",", "qual_index", ")", "\n", "", "else", ":", "\n", "                ", "rel_emb", "=", "torch", ".", "index_select", "(", "rel_embed", ",", "0", ",", "edge_type", ")", "\n", "", "", "else", ":", "\n", "            ", "rel_emb", "=", "torch", ".", "index_select", "(", "rel_embed", ",", "0", ",", "edge_type", ")", "\n", "\n", "", "xj_rel", "=", "self", ".", "rel_transform", "(", "x_j", ",", "rel_emb", ")", "\n", "out", "=", "torch", ".", "einsum", "(", "'ij,jk->ik'", ",", "xj_rel", ",", "weight", ")", "\n", "\n", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", "and", "mode", "!=", "'loop'", ":", "\n", "            ", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "\n", "x_i", "=", "x_i", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "self", ".", "attn_dim", ")", "\n", "\n", "alpha", "=", "torch", ".", "einsum", "(", "'bij,kij -> bi'", ",", "[", "torch", ".", "cat", "(", "[", "x_i", ",", "out", "]", ",", "dim", "=", "-", "1", ")", ",", "self", ".", "att", "]", ")", "\n", "alpha", "=", "F", ".", "leaky_relu", "(", "alpha", ",", "self", ".", "negative_slope", ")", "\n", "alpha", "=", "softmax", "(", "alpha", ",", "source_index", ",", "ent_embed", ".", "size", "(", "0", ")", ")", "\n", "alpha", "=", "F", ".", "dropout", "(", "alpha", ",", "p", "=", "self", ".", "attn_drop", ")", "\n", "return", "(", "out", "*", "alpha", ".", "view", "(", "-", "1", ",", "self", ".", "heads", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "\n", "", "else", ":", "\n", "            ", "return", "out", "if", "edge_norm", "is", "None", "else", "out", "*", "edge_norm", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "", "def", "update", "(", "self", ",", "aggr_out", ",", "mode", ")", ":", "\n", "        ", "if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'ATTENTION'", "]", "and", "mode", "!=", "'loop'", ":", "\n", "            ", "aggr_out", "=", "aggr_out", ".", "view", "(", "-", "1", ",", "self", ".", "heads", "*", "self", ".", "attn_dim", ")", "\n", "\n", "", "return", "aggr_out", "\n", "\n", "", "@", "staticmethod", "\n", "def", "compute_norm", "(", "edge_index", ",", "num_ent", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.update": [[437, 443], ["aggr_out.view.view.view"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.aggregate": [[444, 473], ["super().aggregate", "torch_scatter.scatter", "torch_scatter.scatter", "torch_scatter.scatter", "torch_scatter.scatter", "torch_scatter.scatter", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch_geometric.utils.degree", "deg.clamp_().view.clamp_().view.mean().item", "deg.clamp_().view.clamp_().view.clamp_().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "deg.clamp_().view.clamp_().view.mean", "deg.clamp_().view.clamp_().view.clamp_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.aggregate"], ["row", ",", "col", "=", "edge_index", "\n", "edge_weight", "=", "torch", ".", "ones_like", "(", "\n", "row", ")", ".", "float", "(", ")", "# Identity matrix where we know all entities are there", "\n", "deg", "=", "scatter_add", "(", "edge_weight", ",", "row", ",", "dim", "=", "0", ",", "\n", "dim_size", "=", "num_ent", ")", "# Summing number of weights of", "\n", "# the edges, D = A + I", "\n", "deg_inv", "=", "deg", ".", "pow", "(", "-", "0.5", ")", "# D^{-0.5}", "\n", "deg_inv", "[", "deg_inv", "==", "float", "(", "'inf'", ")", "]", "=", "0", "# for numerical stability", "\n", "norm", "=", "deg_inv", "[", "row", "]", "*", "edge_weight", "*", "deg_inv", "[", "\n", "col", "]", "# Norm parameter D^{-0.5} *", "\n", "\n", "return", "norm", "\n", "\n", "", "def", "coalesce_quals", "(", "self", ",", "qual_embeddings", ",", "qual_index", ",", "num_edges", ",", "fill", "=", "0", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.compute_norm": [[476, 500], ["torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch.ones_like().float", "torch_scatter.scatter_add", "torch_scatter.scatter_add.pow", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "float"], "methods", ["None"], ["if", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_N'", "]", "==", "'sum'", ":", "\n", "            ", "output", "=", "scatter_add", "(", "qual_embeddings", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_edges", ")", "\n", "", "elif", "self", ".", "p", "[", "'STAREARGS'", "]", "[", "'QUAL_N'", "]", "==", "'mean'", ":", "\n", "            ", "output", "=", "scatter_mean", "(", "qual_embeddings", ",", "qual_index", ",", "dim", "=", "0", ",", "dim_size", "=", "num_edges", ")", "\n", "\n", "", "if", "fill", "!=", "0", ":", "\n", "# by default scatter_ functions assign zeros to the output, so we assign them 1's for correct mult", "\n", "            ", "mask", "=", "output", ".", "sum", "(", "dim", "=", "-", "1", ")", "==", "0", "\n", "output", "[", "mask", "]", "=", "fill", "\n", "\n", "", "return", "output", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{}({}, {}, num_rels={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "self", ".", "num_rels", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.coalesce_quals": [[501, 531], ["torch_scatter.scatter_add", "torch_scatter.scatter_mean", "torch_scatter.scatter_mean.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.gnn_layer.StarEConvLayer.__repr__": [[532, 536], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.comp_gcn.StarE_PyG_Encoder.__init__": [[14, 80], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ModuleList", "torch.nn.ModuleList", "comp_gcn.StarE_PyG_Encoder.convs.append", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "gnn_layer.StarEConvLayer", "comp_gcn.StarE_PyG_Encoder.attention.append", "comp_gcn.StarE_PyG_Encoder.dim_reduction.append", "torch.nn.ModuleList", "torch.nn.ModuleList", "comp_gcn.StarE_PyG_Encoder.convs.append", "torch.nn.Sequential", "torch.nn.Sequential", "lrga_model.LowRankAttention", "torch.nn.Sequential", "torch.nn.Sequential", "gnn_layer.StarEConvLayer", "comp_gcn.StarE_PyG_Encoder.attention.append", "comp_gcn.StarE_PyG_Encoder.dim_reduction.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "lrga_model.LowRankAttention", "torch.nn.Sequential", "torch.nn.Sequential", "range", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "emb_dim", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "\n", "num_rel", ":", "int", ",", "\n", "layer_config", ":", "dict", ",", "\n", "num_layers", ":", "int", "=", "2", ",", "\n", "use_lrga", ":", "bool", "=", "False", ",", "\n", "lrga_k", ":", "int", "=", "50", ",", "\n", "lrga_drop", ":", "float", "=", "0.1", ",", "\n", "hid_drop", ":", "float", "=", "0.1", ",", "\n", "drop1", ":", "float", "=", "0.1", ",", "\n", "triple_mode", ":", "bool", "=", "True", ",", "\n", "residual", ":", "bool", "=", "False", ",", "\n", "jk", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "StarE_PyG_Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "act", "=", "torch", ".", "relu", "# was tanh before", "\n", "\n", "self", ".", "layer_config", "=", "layer_config", "\n", "\n", "self", ".", "emb_dim", "=", "emb_dim", "\n", "self", ".", "gcn_dim", "=", "emb_dim", "\n", "self", ".", "hid_drop", "=", "hid_drop", "\n", "self", ".", "drop1", "=", "nn", ".", "Dropout", "(", "drop1", ")", "\n", "self", ".", "triple_mode", "=", "triple_mode", "\n", "self", ".", "num_rel", "=", "num_rel", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "residual", "=", "residual", "\n", "self", ".", "jk", "=", "jk", "\n", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "\n", "\"\"\"\n            LRGA params\n        \"\"\"", "\n", "self", ".", "use_lrga", "=", "use_lrga", "\n", "self", ".", "lrga_k", "=", "lrga_k", "\n", "self", ".", "lrga_drop", "=", "lrga_drop", "\n", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "self", ".", "attention", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dim_reduction", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# populating manually first and last layers, otherwise in a loop", "\n", "", "self", ".", "convs", ".", "append", "(", "StarEConvLayer", "(", "self", ".", "emb_dim", ",", "self", ".", "gcn_dim", ",", "self", ".", "num_rel", ",", "act", "=", "self", ".", "act", ",", "config", "=", "layer_config", ")", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "self", ".", "attention", ".", "append", "(", "LowRankAttention", "(", "self", ".", "lrga_k", ",", "self", ".", "emb_dim", ",", "self", ".", "lrga_drop", ")", ")", "\n", "self", ".", "dim_reduction", ".", "append", "(", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2", "*", "self", ".", "lrga_k", "+", "self", ".", "gcn_dim", "+", "self", ".", "emb_dim", ",", "self", ".", "gcn_dim", ")", ")", ")", "\n", "self", ".", "bns", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "BatchNorm1d", "(", "self", ".", "gcn_dim", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", "]", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "convs", ".", "append", "(", "StarEConvLayer", "(", "self", ".", "gcn_dim", ",", "self", ".", "gcn_dim", ",", "self", ".", "num_rel", ",", "act", "=", "self", ".", "act", ",", "config", "=", "layer_config", ")", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "                ", "self", ".", "attention", ".", "append", "(", "LowRankAttention", "(", "self", ".", "lrga_k", ",", "self", ".", "gcn_dim", ",", "self", ".", "lrga_drop", ")", ")", "\n", "self", ".", "dim_reduction", ".", "append", "(", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2", "*", "(", "self", ".", "lrga_k", "+", "self", ".", "gcn_dim", ")", ",", "self", ".", "gcn_dim", ")", ")", ")", "\n", "\n", "# self.register_parameter('bias', Parameter(torch.zeros(self.num_ent)))", "\n", "", "", "if", "self", ".", "jk", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "gcn_dim", "*", "self", ".", "num_layers", ",", "self", ".", "gcn_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "gcn_dim", ",", "self", ".", "gcn_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.comp_gcn.StarE_PyG_Encoder.reset_parameters": [[82, 101], ["conv.reset_parameters", "att.apply", "dim_r.apply", "bnorm.reset_parameters", "hasattr", "module.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\n", "#torch.nn.init.constant_(self.bias.data, 0)", "\n", "        ", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "conv", ".", "reset_parameters", "(", ")", "\n", "", "if", "self", ".", "use_lrga", ":", "\n", "            ", "for", "att", "in", "self", ".", "attention", ":", "\n", "                ", "att", ".", "apply", "(", "weight_init", ")", "\n", "", "for", "dim_r", "in", "self", ".", "dim_reduction", ":", "\n", "                ", "dim_r", ".", "apply", "(", "weight_init", ")", "\n", "", "for", "bnorm", "in", "self", ".", "bns", ":", "\n", "                ", "bnorm", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "if", "self", ".", "jk", ":", "\n", "            ", "for", "module", "in", "self", ".", "linear", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.comp_gcn.StarE_PyG_Encoder.forward_base": [[103, 156], ["enumerate", "comp_gcn.StarE_PyG_Encoder.drop1", "conv", "comp_gcn.StarE_PyG_Encoder.drop1", "outputs.append", "comp_gcn.StarE_PyG_Encoder.linear", "torch.relu", "torch.relu", "outputs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "", "", "def", "forward_base", "(", "self", ",", "graph", ")", ":", "\n", "\n", "        ", "x", ",", "edge_index", ",", "edge_type", ",", "r", "=", "graph", "[", "'x'", "]", ",", "graph", "[", "'edge_index'", "]", ",", "graph", "[", "'edge_type'", "]", ",", "graph", "[", "'rels'", "]", "\n", "\n", "# Add reverse stuff", "\n", "# reverse_index = torch.zeros_like(edge_index)", "\n", "# reverse_index[1, :] = edge_index[0, :]", "\n", "# reverse_index[0, :] = edge_index[1, :]", "\n", "# rev_edge_type = edge_type + self.num_rel", "\n", "#", "\n", "# edge_index = torch.cat([edge_index, reverse_index], dim=1)", "\n", "# edge_type = torch.cat([edge_type, rev_edge_type], dim=0)", "\n", "\n", "if", "not", "self", ".", "triple_mode", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "jk", ":", "\n", "            ", "outputs", "=", "[", "]", "\n", "\n", "", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convs", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "x_local", ",", "r", "=", "conv", "(", "x", "=", "x", ",", "edge_index", "=", "edge_index", ",", "edge_type", "=", "edge_type", ",", "rel_embed", "=", "r", ",", "quals", "=", "None", ")", "\n", "x_local", "=", "self", ".", "drop1", "(", "x_local", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "                ", "x_global", "=", "self", ".", "attention", "[", "i", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "dim_reduction", "[", "i", "]", "(", "torch", ".", "cat", "(", "(", "x_global", ",", "x_local", ",", "x", ")", ",", "dim", "=", "1", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "bns", "[", "i", "]", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "residual", ":", "\n", "                    ", "x", "=", "x", "+", "x_local", "\n", "", "else", ":", "\n", "                    ", "x", "=", "x_local", "\n", "", "", "if", "self", ".", "jk", ":", "\n", "                ", "outputs", ".", "append", "(", "x", ")", "\n", "\n", "# last layer", "\n", "", "", "x_local", ",", "r", "=", "self", ".", "convs", "[", "-", "1", "]", "(", "x", "=", "x", ",", "edge_index", "=", "edge_index", ",", "edge_type", "=", "edge_type", ",", "rel_embed", "=", "r", ",", "quals", "=", "None", ")", "\n", "x_local", "=", "self", ".", "drop1", "(", "x_local", ")", "\n", "if", "self", ".", "use_lrga", ":", "\n", "            ", "x_global", "=", "self", ".", "attention", "[", "-", "1", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "dim_reduction", "[", "-", "1", "]", "(", "torch", ".", "cat", "(", "(", "x_global", ",", "x_local", ",", "x", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "residual", ":", "\n", "                ", "x", "=", "x", "+", "x_local", "\n", "", "else", ":", "\n", "                ", "x", "=", "x_local", "\n", "\n", "", "", "if", "self", ".", "jk", ":", "\n", "            ", "outputs", ".", "append", "(", "x", ")", "\n", "x", "=", "self", ".", "linear", "(", "torch", ".", "cat", "(", "outputs", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n", "\n", "", "return", "x", ",", "r", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.LowRankAttention.__init__": [[26, 33], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "lrga_model.LowRankAttention.apply", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "k", ",", "d", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "d", ",", "4", "*", "k", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "apply", "(", "weight_init", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.LowRankAttention.forward": [[34, 46], ["lrga_model.LowRankAttention.w", "torch.t", "torch.t", "torch.t", "torch.t", "lrga_model.joint_normalize2", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lrga_model.LowRankAttention.dropout", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.joint_normalize2"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "tmp", "=", "self", ".", "w", "(", "x", ")", "# B x D", "\n", "U", "=", "tmp", "[", ":", ",", ":", "self", ".", "k", "]", "# B x K", "\n", "V", "=", "tmp", "[", ":", ",", "self", ".", "k", ":", "2", "*", "self", ".", "k", "]", "# B x K", "\n", "Z", "=", "tmp", "[", ":", ",", "2", "*", "self", ".", "k", ":", "3", "*", "self", ".", "k", "]", "# B x K", "\n", "T", "=", "tmp", "[", ":", ",", "3", "*", "self", ".", "k", ":", "]", "# B x K", "\n", "V_T", "=", "torch", ".", "t", "(", "V", ")", "# K x B", "\n", "# normalization", "\n", "D", "=", "joint_normalize2", "(", "U", ",", "V_T", ")", "# scalar", "\n", "res", "=", "torch", ".", "mm", "(", "U", ",", "torch", ".", "mm", "(", "V_T", ",", "Z", ")", ")", "# (B x K) mm (K x K) -> B x K", "\n", "res", "=", "torch", ".", "cat", "(", "(", "res", "*", "D", ",", "T", ")", ",", "dim", "=", "1", ")", "# B x 2K", "\n", "return", "self", ".", "dropout", "(", "res", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.joint_normalize2": [[7, 15], ["torch.ones", "torch.ones", "torch.cuda.is_available", "torch.cuda.is_available", "torch.mm", "torch.mm", "tmp_ones.to.to", "torch.mm", "torch.mm", "torch.device", "torch.device", "torch.sum", "torch.sum"], "function", ["None"], ["def", "joint_normalize2", "(", "U", ",", "V_T", ")", ":", "\n", "# U and V_T are in block diagonal form", "\n", "    ", "tmp_ones", "=", "torch", ".", "ones", "(", "(", "V_T", ".", "shape", "[", "1", "]", ",", "1", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "tmp_ones", "=", "tmp_ones", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "", "norm_factor", "=", "torch", ".", "mm", "(", "U", ",", "torch", ".", "mm", "(", "V_T", ",", "tmp_ones", ")", ")", "\n", "norm_factor", "=", "(", "torch", ".", "sum", "(", "norm_factor", ")", "/", "U", ".", "shape", "[", "0", "]", ")", "+", "1e-6", "\n", "return", "1", "/", "norm_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.lrga_model.weight_init": [[17, 23], ["type", "torch.init.xavier_normal_", "torch.init.constant"], "function", ["None"], ["", "def", "weight_init", "(", "layer", ")", ":", "\n", "    ", "if", "type", "(", "layer", ")", "==", "nn", ".", "Linear", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "layer", ".", "weight", ".", "data", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant", "(", "layer", ".", "bias", ".", "data", ",", "0", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.build_model": [[15, 27], ["DisMultOutKG.DisMultOutKG.dataset.num_rel", "torch.nn.Embedding().to", "torch.nn.Embedding().to", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_rel"], ["    ", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_ent", "=", "self", ".", "dataset", ".", "init_num_ent", "\n", "self", ".", "num_rel", "=", "self", ".", "dataset", ".", "num_rel", "(", ")", "\n", "\n", "self", ".", "ent_embs", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "num_ent", "+", "1", ",", "self", ".", "emb_dim", ",", "padding_idx", "=", "self", ".", "num_ent", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "rel_embs", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "num_rel", "+", "1", ",", "self", ".", "emb_dim", ",", "padding_idx", "=", "self", ".", "num_rel", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "ent_embs", ".", "weight", "[", ":", "-", "1", "]", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "rel_embs", ".", "weight", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.get_ent_embs": [[28, 31], ["DisMultOutKG.DisMultOutKG.ent_embs"], "methods", ["None"], ["", "def", "get_ent_embs", "(", "self", ",", "ent_id", ")", ":", "\n", "# lookup the embedding", "\n", "        ", "return", "self", ".", "ent_embs", "(", "ent_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.get_rel_embs": [[32, 34], ["DisMultOutKG.DisMultOutKG.rel_embs"], "methods", ["None"], ["", "def", "get_rel_embs", "(", "self", ",", "rel_id", ")", ":", "\n", "        ", "return", "self", ".", "rel_embs", "(", "rel_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.get_new_ent_embs": [[35, 55], ["DisMultOutKG.DisMultOutKG.dataset.adj_list[].to", "DisMultOutKG.DisMultOutKG.get_ent_embs().view", "DisMultOutKG.DisMultOutKG.get_rel_embs().view", "DisMultOutKG.DisMultOutKG.infer_emb", "ent_mask.unsqueeze().expand().to", "ent_mask.unsqueeze().expand().to", "DisMultOutKG.DisMultOutKG.get_ent_embs", "DisMultOutKG.DisMultOutKG.get_rel_embs", "DisMultOutKG.DisMultOutKG.obs_ents_id.unsqueeze", "torch.arange", "ent_neighbors[].view", "ent_neighbors[].view", "ent_mask.unsqueeze().expand", "ent_mask.unsqueeze().expand", "ent_mask.unsqueeze", "ent_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.infer_emb", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_rel_embs"], ["", "def", "get_new_ent_embs", "(", "self", ",", "triples", ",", "mask", ")", ":", "\n", "# find the embedding for the unobserved entities", "\n", "        ", "new_ents_id", "=", "triples", "[", "torch", ".", "arange", "(", "triples", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "mask", "]", "\n", "ent_neighbors", "=", "self", ".", "dataset", ".", "adj_list", "[", "new_ents_id", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "neighbors_ent_embs", "=", "self", ".", "get_ent_embs", "(", "ent_neighbors", "[", ":", ",", ":", ",", "0", "]", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "\n", "ent_neighbors", ".", "shape", "[", "0", "]", ",", "ent_neighbors", ".", "shape", "[", "1", "]", ",", "self", ".", "emb_dim", "\n", ")", "\n", "neighbors_rel_embs", "=", "self", ".", "get_rel_embs", "(", "ent_neighbors", "[", ":", ",", ":", ",", "1", "]", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "\n", "ent_neighbors", ".", "shape", "[", "0", "]", ",", "ent_neighbors", ".", "shape", "[", "1", "]", ",", "self", ".", "emb_dim", "\n", ")", "\n", "ent_mask", "=", "(", "ent_neighbors", "[", ":", ",", ":", ",", "0", "]", "!=", "self", ".", "obs_ents_id", ".", "unsqueeze", "(", "1", ")", ")", "*", "(", "\n", "ent_neighbors", "[", ":", ",", ":", ",", "0", "]", "!=", "self", ".", "num_ent", "\n", ")", "\n", "neighbors_ent_embs", "=", "neighbors_ent_embs", "*", "ent_mask", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "neighbors_ent_embs", ".", "shape", "\n", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "neighbors_rel_embs", "=", "neighbors_rel_embs", "*", "ent_mask", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "neighbors_rel_embs", ".", "shape", "\n", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "return", "self", ".", "infer_emb", "(", "neighbors_ent_embs", ",", "neighbors_rel_embs", ",", "mask", "=", "ent_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.l2_loss": [[56, 61], ["torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "l2_loss", "(", "self", ")", ":", "\n", "        ", "emb_reg", "=", "(", "torch", ".", "norm", "(", "self", ".", "ent_embs", ".", "weight", ",", "p", "=", "2", ")", "**", "2", ")", "+", "(", "\n", "torch", ".", "norm", "(", "self", ".", "rel_embs", ".", "weight", ",", "p", "=", "2", ")", "**", "2", "\n", ")", "\n", "return", "emb_reg", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.get_ent_exc_ids": [[62, 76], ["numpy.zeros", "numpy.zeros", "numpy.zeros.fill", "numpy.expand_dims", "numpy.concatenate", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "obs_ent[].astype", "numpy.where", "numpy.where", "len", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "get_ent_exc_ids", "(", "self", ",", "obs_triples", ",", "new_ent", ")", ":", "\n", "        ", "heads", "=", "np", ".", "where", "(", "obs_triples", "[", ":", ",", "0", "]", "!=", "new_ent", ")", "[", "0", "]", "\n", "h1", "=", "np", ".", "zeros", "(", "(", "len", "(", "heads", ")", ",", "1", ")", ")", "\n", "tails", "=", "np", ".", "where", "(", "obs_triples", "[", ":", ",", "2", "]", "!=", "new_ent", ")", "[", "0", "]", "\n", "t1", "=", "np", ".", "zeros", "(", "(", "len", "(", "tails", ")", ",", "1", ")", ")", "\n", "t1", ".", "fill", "(", "2", ")", "\n", "heads", "=", "np", ".", "expand_dims", "(", "heads", ",", "axis", "=", "1", ")", "\n", "heads", "=", "np", ".", "concatenate", "(", "(", "heads", ",", "h1", ")", ",", "axis", "=", "1", ")", "\n", "tails", "=", "np", ".", "expand_dims", "(", "tails", ",", "axis", "=", "1", ")", "\n", "tails", "=", "np", ".", "concatenate", "(", "(", "tails", ",", "t1", ")", ",", "axis", "=", "1", ")", "\n", "obs_ent", "=", "np", ".", "concatenate", "(", "(", "heads", ",", "tails", ")", ")", "\n", "obs_ent", "=", "obs_ent", "[", "np", ".", "argsort", "(", "obs_ent", "[", ":", ",", "0", "]", ")", "]", ".", "astype", "(", "int", ")", "\n", "obs_ent_ids", "=", "obs_triples", "[", "obs_ent", "[", ":", ",", "0", "]", ",", "obs_ent", "[", ":", ",", "1", "]", "]", "\n", "return", "obs_ent_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.find_embedding": [[77, 87], ["DisMultOutKG.DisMultOutKG.get_ent_exc_ids", "DisMultOutKG.DisMultOutKG.get_ent_embs().unsqueeze", "DisMultOutKG.DisMultOutKG.get_rel_embs().unsqueeze", "DisMultOutKG.DisMultOutKG.infer_emb().squeeze", "DisMultOutKG.DisMultOutKG.get_ent_embs", "DisMultOutKG.DisMultOutKG.get_rel_embs", "DisMultOutKG.DisMultOutKG.infer_emb", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.get_ent_exc_ids", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_rel_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.infer_emb"], ["", "def", "find_embedding", "(", "self", ",", "new_ent", ",", "obs_triples", ")", ":", "\n", "        ", "obs_ent_ids", "=", "self", ".", "get_ent_exc_ids", "(", "obs_triples", ",", "new_ent", ")", "\n", "obs_rel_ids", "=", "obs_triples", "[", ":", ",", "1", "]", "\n", "obs_ent_embs", "=", "self", ".", "get_ent_embs", "(", "\n", "torch", ".", "tensor", "(", "obs_ent_ids", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "obs_rel_embs", "=", "self", ".", "get_rel_embs", "(", "\n", "torch", ".", "tensor", "(", "obs_rel_ids", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "return", "self", ".", "infer_emb", "(", "obs_ent_embs", ",", "obs_rel_embs", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.infer_emb": [[88, 129], ["DisMultOutKG.DisMultOutKG.find_neighbors_avg", "DisMultOutKG.DisMultOutKG.find_neighbors_avg", "torch.ones().to", "torch.nn.functional.normalize", "torch.nn.functional.normalize.permute", "torch.inverse", "torch.bmm().squeeze", "torch.ones().to", "torch.nn.functional.normalize.permute", "torch.inverse", "torch.bmm().squeeze", "torch.ones", "mask.to", "torch.bmm", "torch.bmm", "torch.eye().unsqueeze().expand().to", "torch.bmm", "torch.ones().to.unsqueeze", "torch.ones", "mask.to", "torch.bmm", "torch.bmm", "torch.eye().unsqueeze().expand().to", "torch.bmm", "torch.ones().to.unsqueeze", "torch.eye().unsqueeze().expand", "torch.eye().unsqueeze().expand", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.find_neighbors_avg", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.find_neighbors_avg", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize"], ["", "def", "infer_emb", "(", "self", ",", "ent_emb", ",", "rel_emb", ",", "mask", "=", "None", ")", ":", "\n", "# infers embedding of unobserved entities based on the emb_method (aggregation function)", "\n", "        ", "if", "self", ".", "emb_method", "==", "\"ERAverage\"", ":", "\n", "            ", "return", "self", ".", "find_neighbors_avg", "(", "ent_emb", ",", "rel_emb", "=", "rel_emb", ",", "mask", "=", "mask", ")", "\n", "", "elif", "self", ".", "emb_method", "==", "\"Average\"", ":", "\n", "            ", "return", "self", ".", "find_neighbors_avg", "(", "ent_emb", ",", "mask", "=", "mask", ")", "\n", "", "elif", "self", ".", "emb_method", "==", "\"LS\"", ":", "\n", "            ", "labels", "=", "torch", ".", "ones", "(", "ent_emb", ".", "shape", "[", "0", "]", ",", "ent_emb", ".", "shape", "[", "1", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "labels", "=", "labels", "*", "mask", ".", "to", "(", "torch", ".", "float", ")", "\n", "\n", "", "A", "=", "nn", ".", "functional", ".", "normalize", "(", "ent_emb", "*", "rel_emb", ",", "dim", "=", "2", ")", "\n", "A_t", "=", "A", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "c", "=", "torch", ".", "inverse", "(", "\n", "torch", ".", "bmm", "(", "A_t", ",", "A", ")", "\n", "+", "self", ".", "args", ".", "reg_ls", "\n", "*", "(", "\n", "torch", ".", "eye", "(", "A", ".", "shape", "[", "2", "]", ")", "\n", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "A", ".", "shape", "[", "0", "]", ",", "A", ".", "shape", "[", "2", "]", ",", "A", ".", "shape", "[", "2", "]", ")", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "return", "torch", ".", "bmm", "(", "torch", ".", "bmm", "(", "c", ",", "A_t", ")", ",", "labels", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", ")", "\n", "\n", "", "elif", "self", ".", "emb_method", "==", "\"LS_unnorm\"", ":", "\n", "            ", "labels", "=", "torch", ".", "ones", "(", "ent_emb", ".", "shape", "[", "0", "]", ",", "ent_emb", ".", "shape", "[", "1", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "labels", "=", "labels", "*", "mask", ".", "to", "(", "torch", ".", "float", ")", "\n", "\n", "", "A", "=", "ent_emb", "*", "rel_emb", "\n", "A_t", "=", "A", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "c", "=", "torch", ".", "inverse", "(", "\n", "torch", ".", "bmm", "(", "A_t", ",", "A", ")", "\n", "+", "self", ".", "args", ".", "reg_ls", "\n", "*", "(", "\n", "torch", ".", "eye", "(", "A", ".", "shape", "[", "2", "]", ")", "\n", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "A", ".", "shape", "[", "0", "]", ",", "A", ".", "shape", "[", "2", "]", ",", "A", ".", "shape", "[", "2", "]", ")", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "return", "torch", ".", "bmm", "(", "torch", ".", "bmm", "(", "c", ",", "A_t", ")", ",", "labels", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.DisMultOutKG.DisMultOutKG.find_neighbors_avg": [[130, 144], ["torch.sum", "torch.mean", "torch.mean", "torch.sum", "torch.sum.unsqueeze().to", "torch.sum", "torch.sum.unsqueeze().to", "torch.sum.unsqueeze", "torch.sum.unsqueeze"], "methods", ["None"], ["", "", "def", "find_neighbors_avg", "(", "self", ",", "ent_emb", ",", "rel_emb", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "        ", "if", "mask", "is", "None", ":", "\n", "            ", "if", "rel_emb", "is", "None", ":", "\n", "                ", "return", "torch", ".", "mean", "(", "ent_emb", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "torch", ".", "mean", "(", "ent_emb", "*", "rel_emb", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "mask_sum", "=", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", "\n", "mask_sum", "[", "mask_sum", "==", "0", "]", "=", "1.0", "\n", "if", "rel_emb", "is", "None", ":", "\n", "                ", "return", "torch", ".", "sum", "(", "ent_emb", ",", "dim", "=", "1", ")", "/", "mask_sum", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "", "else", ":", "\n", "                ", "return", "torch", ".", "sum", "(", "ent_emb", "*", "rel_emb", ",", "dim", "=", "1", ")", "/", "mask_sum", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "\n", "torch", ".", "float", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.__init__": [[12, 27], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.init.xavier_uniform_", "vocab.nodepiece_encoder.NodePieceEncoder", "dm_tokenized.TokenizedDistMult.embedder.reset_parameters", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "\n", "args", ":", "dict", ",", "\n", "device", ":", "torch", ".", "device", ",", "\n", "dataset", ":", "Dataset", ",", "\n", "tokenizer", ":", "NodePiece_Tokenizer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rel_embs", "=", "nn", ".", "Embedding", "(", "len", "(", "dataset", ".", "rel2id", ")", "+", "1", ",", "args", ".", "emb_dim", ",", "padding_idx", "=", "len", "(", "dataset", ".", "rel2id", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "rel_embs", ".", "weight", "[", ":", "-", "1", "]", ")", "\n", "\n", "self", ".", "embedder", "=", "NodePieceEncoder", "(", "args", ",", "tokenizer", ",", "rel_embs", "=", "self", ".", "rel_embs", ",", "graph", "=", "dataset", ",", "device", "=", "device", ")", "\n", "self", ".", "embedder", ".", "reset_parameters", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "num_direct_rels", "=", "len", "(", "dataset", ".", "rel2id", ")", "//", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.forward": [[29, 40], ["dm_tokenized.TokenizedDistMult.embedder.encode_by_index", "dm_tokenized.TokenizedDistMult.rel_embs", "dm_tokenized.TokenizedDistMult.embedder.encode_by_index", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], ["", "def", "forward", "(", "self", ",", "triples", ",", "mask", ")", ":", "\n", "\n", "# don't do anythign with the mask, just compute embs and scoring function", "\n", "\n", "        ", "subs", "=", "self", ".", "embedder", ".", "encode_by_index", "(", "triples", "[", ":", ",", "0", "]", ")", "\n", "rels", "=", "self", ".", "rel_embs", "(", "triples", "[", ":", ",", "1", "]", ")", "\n", "objs", "=", "self", ".", "embedder", ".", "encode_by_index", "(", "triples", "[", ":", ",", "2", "]", ")", "\n", "\n", "score", "=", "torch", ".", "sum", "(", "subs", "*", "rels", "*", "objs", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.get_rel_embs": [[42, 44], ["dm_tokenized.TokenizedDistMult.rel_embs"], "methods", ["None"], ["", "def", "get_rel_embs", "(", "self", ",", "rels", ":", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "return", "self", ".", "rel_embs", "(", "rels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.get_ent_embs": [[45, 49], ["dm_tokenized.TokenizedDistMult.embedder.get_all_representations"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations"], ["", "def", "get_ent_embs", "(", "self", ",", "entities", ":", "torch", ".", "LongTensor", ")", ":", "\n", "        ", "if", "self", ".", "all", "is", "None", ":", "\n", "            ", "self", ".", "all", "=", "self", ".", "embedder", ".", "get_all_representations", "(", ")", "\n", "", "return", "self", ".", "all", "[", "entities", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.reset": [[50, 52], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "all", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.cal_score": [[53, 57], ["torch.sum"], "methods", ["None"], ["", "def", "cal_score", "(", "self", ",", "obs_ents", ",", "new_ents", ",", "rels", ")", ":", "\n", "        ", "scores", "=", "(", "obs_ents", "*", "new_ents", ")", "*", "rels", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "1", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.get_ent_exc_ids": [[58, 72], ["numpy.zeros", "numpy.zeros", "numpy.zeros.fill", "numpy.expand_dims", "numpy.concatenate", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "obs_ent[].astype", "numpy.where", "numpy.where", "len", "len", "numpy.argsort"], "methods", ["None"], ["", "def", "get_ent_exc_ids", "(", "self", ",", "obs_triples", ",", "new_ent", ")", ":", "\n", "        ", "heads", "=", "np", ".", "where", "(", "obs_triples", "[", ":", ",", "0", "]", "!=", "new_ent", ")", "[", "0", "]", "\n", "h1", "=", "np", ".", "zeros", "(", "(", "len", "(", "heads", ")", ",", "1", ")", ")", "\n", "tails", "=", "np", ".", "where", "(", "obs_triples", "[", ":", ",", "2", "]", "!=", "new_ent", ")", "[", "0", "]", "\n", "t1", "=", "np", ".", "zeros", "(", "(", "len", "(", "tails", ")", ",", "1", ")", ")", "\n", "t1", ".", "fill", "(", "2", ")", "\n", "heads", "=", "np", ".", "expand_dims", "(", "heads", ",", "axis", "=", "1", ")", "\n", "heads", "=", "np", ".", "concatenate", "(", "(", "heads", ",", "h1", ")", ",", "axis", "=", "1", ")", "\n", "tails", "=", "np", ".", "expand_dims", "(", "tails", ",", "axis", "=", "1", ")", "\n", "tails", "=", "np", ".", "concatenate", "(", "(", "tails", ",", "t1", ")", ",", "axis", "=", "1", ")", "\n", "obs_ent", "=", "np", ".", "concatenate", "(", "(", "heads", ",", "tails", ")", ")", "\n", "obs_ent", "=", "obs_ent", "[", "np", ".", "argsort", "(", "obs_ent", "[", ":", ",", "0", "]", ")", "]", ".", "astype", "(", "int", ")", "\n", "obs_ent_ids", "=", "obs_triples", "[", "obs_ent", "[", ":", ",", "0", "]", ",", "obs_ent", "[", ":", ",", "1", "]", "]", "\n", "return", "obs_ent_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.prune_tokens": [[73, 90], ["zip", "len", "unique_ancs.append", "unique_dists.append", "anchor.item", "anchor.item", "anchor.item", "dist.item", "len", "len"], "methods", ["None"], ["", "def", "prune_tokens", "(", "self", ",", "temp_hashes", ":", "torch", ".", "LongTensor", ",", "temp_dist", ":", "torch", ".", "LongTensor", ")", ":", "\n", "# this function selects self.sample_paths number of UNIQUE and NEAREST anchors from the list of anchors and their distances", "\n", "        ", "nothing_token", "=", "self", ".", "embedder", ".", "tokenizer", ".", "token2id", "[", "self", ".", "embedder", ".", "tokenizer", ".", "NOTHING_TOKEN", "]", "\n", "unique_ancs", ",", "unique_dists", "=", "[", "]", ",", "[", "]", "\n", "for", "anchor", ",", "dist", "in", "zip", "(", "temp_hashes", ",", "temp_dist", ")", ":", "\n", "            ", "if", "anchor", ".", "item", "(", ")", "not", "in", "unique_ancs", "and", "anchor", ".", "item", "(", ")", "!=", "nothing_token", ":", "\n", "                ", "unique_ancs", ".", "append", "(", "anchor", ".", "item", "(", ")", ")", "\n", "unique_dists", ".", "append", "(", "dist", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "\n", "# in case we stuck with the disconnected node w/o anchors, add only NOTHING tokens", "\n", "", "", "if", "len", "(", "unique_ancs", ")", "<", "self", ".", "embedder", ".", "sample_paths", ":", "\n", "            ", "unique_ancs", "+=", "[", "nothing_token", "]", "*", "(", "self", ".", "embedder", ".", "sample_paths", "-", "len", "(", "unique_ancs", ")", ")", "\n", "unique_dists", "+=", "[", "0", "]", "*", "(", "self", ".", "embedder", ".", "sample_paths", "-", "len", "(", "unique_dists", ")", ")", "\n", "\n", "", "return", "unique_ancs", ",", "unique_dists", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.find_embedding": [[91, 127], ["numpy.unique", "numpy.unique", "numpy.unique", "torch.tensor", "dm_tokenized.TokenizedDistMult.embedder.hashes[].flatten", "dm_tokenized.TokenizedDistMult.embedder.distances[].flatten", "torch.argsort", "dm_tokenized.TokenizedDistMult.prune_tokens", "torch.tensor", "torch.tensor", "dm_tokenized.TokenizedDistMult.embedder.encode_by_hash", "numpy.array", "numpy.array", "len", "numpy.concatenate", "dm_tokenized.TokenizedDistMult.get_ent_exc_ids", "list", "set", "set", "list", "list"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.prune_tokens", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_hash", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.get_ent_exc_ids"], ["", "def", "find_embedding", "(", "self", ",", "ent_id", ":", "int", ",", "observed_triples", ":", "np", ".", "ndarray", ")", ":", "\n", "# tokenizing unseen nodes using the nodepiece vocab and relational context", "\n", "\n", "        ", "all_relations", "=", "np", ".", "unique", "(", "observed_triples", "[", ":", ",", "1", "]", ")", "\n", "\n", "# build a relational context - get only outgoing edges and inverses of incoming", "\n", "outgoing_rels", "=", "observed_triples", "[", "observed_triples", "[", ":", ",", "0", "]", "==", "ent_id", "]", "[", ":", ",", "1", "]", "\n", "incoming_rels", "=", "np", ".", "unique", "(", "np", ".", "array", "(", "list", "(", "set", "(", "list", "(", "all_relations", ")", ")", "-", "set", "(", "list", "(", "outgoing_rels", ")", ")", ")", ")", ")", "\n", "outgoing_rels", "=", "np", ".", "unique", "(", "np", ".", "array", "(", "outgoing_rels", ")", ")", "\n", "if", "len", "(", "incoming_rels", ")", ">", "0", ":", "\n", "            ", "incoming_inv", "=", "incoming_rels", "+", "self", ".", "num_direct_rels", "\n", "relational_context", "=", "np", ".", "concatenate", "(", "[", "outgoing_rels", ",", "incoming_inv", "]", ")", "\n", "", "else", ":", "\n", "            ", "relational_context", "=", "outgoing_rels", "# unique for sorting as we do in pre-processing in training", "\n", "\n", "# first, get hashes (and anchor distances) of seen nodes in the neighborhood", "\n", "", "seen_nodes", "=", "torch", ".", "tensor", "(", "self", ".", "get_ent_exc_ids", "(", "observed_triples", ",", "ent_id", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "hashes", "=", "self", ".", "embedder", ".", "hashes", "[", "seen_nodes", "]", ".", "flatten", "(", ")", "\n", "distances", "=", "self", ".", "embedder", ".", "distances", "[", "seen_nodes", "]", ".", "flatten", "(", ")", "\n", "\n", "# get topK closest anchors from the given hashes", "\n", "topk_idx", "=", "torch", ".", "argsort", "(", "distances", ",", "descending", "=", "False", ")", "\n", "\n", "temp_hashes", "=", "hashes", "[", "topk_idx", "]", "\n", "temp_dist", "=", "distances", "[", "topk_idx", "]", "\n", "\n", "unique_ancs", ",", "unique_dists", "=", "self", ".", "prune_tokens", "(", "temp_hashes", ",", "temp_dist", ")", "\n", "\n", "# build a full hash of the unseen node using nodepiece anchors, distances, and relational context", "\n", "top_hashes", "=", "torch", ".", "tensor", "(", "unique_ancs", "[", ":", "self", ".", "embedder", ".", "sample_paths", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "top_distances", "=", "torch", ".", "tensor", "(", "unique_dists", "[", ":", "self", ".", "embedder", ".", "sample_paths", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "top_distances", "=", "top_distances", "+", "1", "# as we are 1 hop away", "\n", "\n", "# return the encoded hash", "\n", "return", "self", ".", "embedder", ".", "encode_by_hash", "(", "top_hashes", ",", "top_distances", ",", "relational_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.__init__": [[12, 20], ["torch.nn.Module.__init__", "BaseOutKG.BaseOutKG.build_model"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.build_model"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "args", ",", "device", ")", ":", "\n", "        ", "super", "(", "BaseOutKG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "emb_method", "=", "self", ".", "args", ".", "emb_method", "\n", "self", ".", "emb_dim", "=", "self", ".", "args", ".", "emb_dim", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "build_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.build_model": [[21, 23], ["None"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.forward": [[24, 45], ["torch.zeros().to", "torch.zeros().to", "BaseOutKG.BaseOutKG.get_ent_embs", "BaseOutKG.BaseOutKG.get_ent_embs", "BaseOutKG.BaseOutKG.get_rel_embs", "BaseOutKG.BaseOutKG.cal_score", "len", "torch.add", "BaseOutKG.BaseOutKG.get_ent_embs", "BaseOutKG.BaseOutKG.get_new_ent_embs", "torch.zeros", "torch.zeros", "torch.mul"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_rel_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.cal_score", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_new_ent_embs"], ["", "def", "forward", "(", "self", ",", "triples", ",", "mask", ")", ":", "\n", "        ", "new_ent_embs", "=", "torch", ".", "zeros", "(", "mask", ".", "shape", "[", "0", "]", ",", "self", ".", "emb_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "obs_ent_embs", "=", "torch", ".", "zeros", "(", "mask", ".", "shape", "[", "0", "]", ",", "self", ".", "emb_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# get embeddings for unobserved entities (entity mask = 0 or 2)", "\n", "deep_mask", "=", "mask", "[", "mask", "!=", "1", "]", "\n", "if", "len", "(", "deep_mask", ")", ">", "0", ":", "\n", "            ", "obs_ents_mask", "=", "torch", ".", "add", "(", "torch", ".", "mul", "(", "deep_mask", ",", "-", "1", ")", ",", "2", ")", "\n", "self", ".", "obs_ents_id", "=", "triples", "[", "mask", "!=", "1", ",", "obs_ents_mask", "]", "\n", "obs_ent_embs", "[", "mask", "!=", "1", "]", "=", "self", ".", "get_ent_embs", "(", "self", ".", "obs_ents_id", ")", "\n", "new_ent_embs", "[", "mask", "!=", "1", "]", "=", "self", ".", "get_new_ent_embs", "(", "\n", "triples", "[", "mask", "!=", "1", "]", ",", "deep_mask", "\n", ")", "\n", "\n", "# get embeddings for observed entities (entity mask = 1)", "\n", "", "obs_ent_embs", "[", "mask", "==", "1", "]", "=", "self", ".", "get_ent_embs", "(", "triples", "[", "mask", "==", "1", ",", "0", "]", ")", "\n", "new_ent_embs", "[", "mask", "==", "1", "]", "=", "self", ".", "get_ent_embs", "(", "triples", "[", "mask", "==", "1", ",", "2", "]", ")", "\n", "\n", "rel_embs", "=", "self", ".", "get_rel_embs", "(", "triples", "[", ":", ",", "1", "]", ")", "\n", "scores", "=", "self", ".", "cal_score", "(", "obs_ent_embs", ",", "new_ent_embs", ",", "rel_embs", ")", "\n", "return", "scores", ",", "new_ent_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.cal_score": [[46, 50], ["torch.sum"], "methods", ["None"], ["", "def", "cal_score", "(", "self", ",", "obs_ents", ",", "new_ents", ",", "rels", ")", ":", "\n", "        ", "scores", "=", "(", "obs_ents", "*", "new_ents", ")", "*", "rels", "\n", "scores", "=", "torch", ".", "sum", "(", "scores", ",", "dim", "=", "1", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs": [[51, 53], ["None"], "methods", ["None"], ["", "def", "get_ent_embs", "(", "self", ",", "ent_id", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_new_ent_embs": [[54, 56], ["None"], "methods", ["None"], ["", "def", "get_new_ent_embs", "(", "self", ",", "triples", ",", "mask", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_rel_embs": [[57, 59], ["None"], "methods", ["None"], ["", "def", "get_rel_embs", "(", "self", ",", "rel_id", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.l2_loss": [[60, 62], ["None"], "methods", ["None"], ["", "def", "l2_loss", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.find_embedding": [[63, 65], ["None"], "methods", ["None"], ["", "def", "find_embedding", "(", "self", ",", "new_ent", ",", "obs_triples", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.main.str2bool": [[28, 37], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "       ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.main.get_parameters": [[38, 128], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.migalkin_NodePiece.utils.utils_mytorch.parse_args"], ["", "", "def", "get_parameters", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-dataset\"", ",", "default", "=", "\"WN18RR\"", ",", "type", "=", "str", ",", "help", "=", "\"dataset name\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-model_name\"", ",", "default", "=", "\"DisMult\"", ",", "type", "=", "str", ",", "help", "=", "\"initial embedding model\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-opt\"", ",", "\n", "default", "=", "\"adagrad\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"optimizer. Currenty only adagrad and adam are supported\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-emb_method\"", ",", "\n", "default", "=", "\"ERAverage\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"method to find new enitity's embedding\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"-emb_dim\"", ",", "default", "=", "200", ",", "type", "=", "int", ",", "help", "=", "\"embedding dimension\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-neg_ratio\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"number of negative examples per positive example\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"-batch_size\"", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "help", "=", "\"batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-simulated_batch_size\"", ",", "\n", "default", "=", "1000", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"batch size to be simulated\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-save_each\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"validate every k epochs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"-ne\"", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "help", "=", "\"number of epochs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-lr\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-reg_lambda\"", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "help", "=", "\"l2 regularization parameter\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-reg_ls\"", ",", "\n", "default", "=", "0.01", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"l2 regularization parameter (for Least Squares)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-val\"", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "help", "=", "\"start validation after training\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-use_custom_reg\"", ",", "default", "=", "False", ",", "type", "=", "str2bool", ",", "help", "=", "\"use custom regularisation\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"-use_acc\"", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "help", "=", "\"use_acc flag\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-cons_mask\"", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "help", "=", "\"Use consistent masking\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-mask_prob\"", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The probability of observed entities\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-tokenize\"", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "help", "=", "\"Use tokenizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-anchors\"", ",", "default", "=", "500", ",", "type", "=", "int", ",", "help", "=", "\"Num anchors\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-sample_size\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "help", "=", "\"Num anchors per node\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-pooler\"", ",", "default", "=", "\"cat\"", ",", "type", "=", "str", ",", "help", "=", "\"Pooler for anchors\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-sample_rels\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"Num unique relations from 1-hop neighborhood\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-random_hashes\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Number of random hashes as a baseline\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-t_hidden\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "\"Hidden size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-t_drop\"", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"Default dropout\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-t_heads\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Num attn heads for trf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-t_layers\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"Num layers for trf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-subbatch\"", ",", "default", "=", "5000", ",", "type", "=", "int", ",", "help", "=", "\"Subbatch for 1-N scoring\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-max_path_len\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"automatic inf of max path len\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-anc_dist\"", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"use anchor distances\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-no_anc\"", ",", "default", "=", "False", ",", "type", "=", "bool", ",", "help", "=", "\"Turn off any anchors\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-nearest_ancs\"", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Use closest or random anchors\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-loss_fc\"", ",", "default", "=", "\"spl\"", ",", "type", "=", "str", ",", "help", "=", "\"loss function - spl or nssal\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-margin\"", ",", "default", "=", "15", ",", "type", "=", "int", ",", "help", "=", "\"margin for nssal loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"-wandb\"", ",", "default", "=", "False", ",", "type", "=", "str2bool", ",", "help", "=", "\"whether to use wandb for logging\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-eval_every\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"how often to eval, -1 to turn off\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.__init__": [[21, 39], ["torch.device", "model.dm_tokenized.TokenizedDistMult", "model.DisMultOutKG.DisMultOutKG", "torch.nn.Softplus", "pykeen.losses.NSSALoss", "wandb.init", "wandb.config.update", "torch.cuda.is_available", "vars", "wandb.Settings"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "args", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "if", "self", ".", "args", ".", "tokenize", ":", "\n", "            ", "self", ".", "model", "=", "TokenizedDistMult", "(", "self", ".", "args", ",", "self", ".", "device", ",", "dataset", ",", "tokenizer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "DisMultOutKG", "(", "self", ".", "dataset", ",", "self", ".", "args", ",", "self", ".", "device", ")", "\n", "#self.model = nn.DataParallel(self.model)", "\n", "\n", "", "if", "self", ".", "args", ".", "loss_fc", "==", "\"spl\"", ":", "\n", "            ", "self", ".", "predict_loss", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "predict_loss", "=", "NSSALoss", "(", "margin", "=", "args", ".", "margin", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "wandb", ":", "\n", "            ", "wandb", ".", "init", "(", "project", "=", "\"oog_token\"", ",", "entity", "=", "'lilbert'", ",", "reinit", "=", "True", ",", "settings", "=", "wandb", ".", "Settings", "(", "start_method", "=", "'fork'", ")", ")", "\n", "wandb", ".", "config", ".", "update", "(", "vars", "(", "self", ".", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.l2_loss": [[43, 45], ["trainer.OutKGTrainer.model.l2_loss"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.l2_loss"], ["", "", "def", "l2_loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "l2_loss", "(", ")", "# removed model.module", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train": [[46, 207], ["trainer.OutKGTrainer.model.to", "trainer.OutKGTrainer.model.train", "print", "tqdm.tqdm.tqdm", "print", "tester.OutKGTester.OutKGTester", "print", "torch.optim.Adagrad", "print", "torch.optim.Adam", "print", "range", "torch.optim.Adam.zero_grad", "tqdm.tqdm.tqdm", "print", "torch.no_grad", "tester.OutKGTester.OutKGTester.test", "wandb.log", "trainer.OutKGTrainer.model.parameters", "trainer.OutKGTrainer.model.parameters", "trainer.OutKGTrainer.dataset.next_batch", "trainer.OutKGTrainer.dataset.was_last_batch", "loss.backward", "tqdm.tqdm.tqdm.update", "tester.OutKGTester.OutKGTester", "wandb.log", "print", "utils.save_model", "float", "tester.OutKGTester.test.item", "mr.item", "sum", "trainer.OutKGTrainer.dataset.num_batch", "trainer.OutKGTrainer.model", "torch.sum", "trainer.OutKGTrainer.model", "trainer.OutKGTrainer.model", "trainer.OutKGTrainer.predict_loss", "torch.optim.Adam.step", "torch.optim.Adam.zero_grad", "torch.no_grad", "tester.OutKGTester.OutKGTester.test", "float", "tester.OutKGTester.test.item", "mr.item", "float", "trainer.OutKGTrainer.predict_loss", "positive_scores.repeat_interleave.repeat_interleave.repeat_interleave", "print", "print", "total_loss.item", "p.numel", "trainer.OutKGTrainer.dataset.num_batch_simulated", "total_loss.item", "total_loss.item", "trainer.OutKGTrainer.model.parameters", "trainer.OutKGTrainer.l2_loss", "str", "str", "total_loss.item"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.train", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.test", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.next_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.was_last_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.save_model", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.test", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_batch_simulated", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.trainer.OutKGTrainer.l2_loss"], ["", "def", "train", "(", "self", ",", "save", "=", "True", ")", ":", "\n", "        ", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "# for bypassing torch DataParallel", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "self", ".", "args", ".", "use_acc", ":", "\n", "            ", "initial_accumulator_value", "=", "0.1", "\n", "", "else", ":", "\n", "            ", "initial_accumulator_value", "=", "0.0", "\n", "\n", "", "if", "self", ".", "args", ".", "use_custom_reg", ":", "\n", "            ", "weight_decay", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "weight_decay", "=", "self", ".", "args", ".", "reg_lambda", "\n", "\n", "", "if", "self", ".", "args", ".", "opt", "==", "\"adagrad\"", ":", "\n", "            ", "print", "(", "\"using adagrad\"", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "args", ".", "lr", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "initial_accumulator_value", "=", "initial_accumulator_value", ",", "\n", "# this is added because of the consistency to the original tensorflow code", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"using adam\"", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "args", ".", "lr", ",", "\n", "weight_decay", "=", "self", ".", "args", ".", "reg_lambda", ",", "\n", ")", "\n", "", "print", "(", "f\"Number of params: {sum(p.numel() for p in self.model.parameters())}\"", ")", "\n", "iters_per_update", "=", "self", ".", "args", ".", "simulated_batch_size", "//", "self", ".", "args", ".", "batch_size", "\n", "\n", "if", "iters_per_update", "<", "1", ":", "\n", "            ", "raise", "(", "\"Actual batch size smaller than batch size to be simulated.\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"iterations before the gradient step : \"", ",", "iters_per_update", ")", "\n", "\n", "", "for", "epoch", "in", "tqdm", "(", "range", "(", "self", ".", "args", ".", "ne", ")", ")", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "last_batch", "=", "False", "\n", "total_loss", "=", "0.0", "\n", "pbar", "=", "tqdm", "(", "total", "=", "self", ".", "dataset", ".", "num_batch", "(", "self", ".", "args", ".", "batch_size", ")", ")", "\n", "num_iters", "=", "1", "\n", "while", "not", "last_batch", ":", "\n", "\n", "                ", "triples", ",", "l", ",", "new_ent_mask", "=", "self", ".", "dataset", ".", "next_batch", "(", "\n", "self", ".", "args", ".", "batch_size", ",", "\n", "neg_ratio", "=", "self", ".", "args", ".", "neg_ratio", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", ")", "\n", "last_batch", "=", "self", ".", "dataset", ".", "was_last_batch", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "loss_fc", "==", "\"spl\"", ":", "\n", "                    ", "scores", ",", "predicted_emb", "=", "self", ".", "model", "(", "triples", ",", "new_ent_mask", ")", "\n", "predict_loss", "=", "torch", ".", "sum", "(", "self", ".", "predict_loss", "(", "-", "l", "*", "scores", ")", ")", "\n", "", "else", ":", "\n", "                    ", "pos_batch", "=", "triples", "[", ":", "self", ".", "args", ".", "batch_size", ",", "...", "]", "\n", "neg_batch", "=", "triples", "[", "self", ".", "args", ".", "batch_size", ":", ",", "...", "]", "\n", "positive_scores", ",", "_", "=", "self", ".", "model", "(", "pos_batch", ",", "None", ")", "\n", "negative_scores", ",", "_", "=", "self", ".", "model", "(", "neg_batch", ",", "None", ")", "\n", "if", "self", ".", "args", ".", "neg_ratio", ">", "1", ":", "\n", "                        ", "positive_scores", "=", "positive_scores", ".", "repeat_interleave", "(", "self", ".", "args", ".", "neg_ratio", ")", "\n", "", "predict_loss", "=", "self", ".", "predict_loss", "(", "positive_scores", ",", "negative_scores", ")", "\n", "", "if", "self", ".", "args", ".", "use_custom_reg", ":", "\n", "                    ", "if", "num_iters", "%", "iters_per_update", "==", "0", "or", "last_batch", "==", "True", ":", "\n", "                        ", "l2_loss", "=", "(", "\n", "self", ".", "args", ".", "reg_lambda", "\n", "*", "self", ".", "l2_loss", "(", ")", "\n", "/", "(", "\n", "self", ".", "dataset", ".", "num_batch_simulated", "(", "\n", "self", ".", "args", ".", "simulated_batch_size", "\n", ")", "\n", ")", "\n", ")", "\n", "loss", "=", "predict_loss", "+", "l2_loss", "\n", "\n", "", "else", ":", "\n", "                        ", "loss", "=", "predict_loss", "\n", "", "", "else", ":", "\n", "                    ", "loss", "=", "predict_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "if", "num_iters", "%", "iters_per_update", "==", "0", "or", "last_batch", "==", "True", ":", "\n", "                    ", "if", "last_batch", ":", "\n", "                        ", "print", "(", "\"last batch triggered gradient update.\"", ")", "\n", "print", "(", "\n", "\"remaining iters for gradient update :\"", ",", "\n", "num_iters", "%", "iters_per_update", ",", "\n", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "total_loss", "+=", "loss", "\n", "#print(num_iters)", "\n", "num_iters", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "\n", "", "print", "(", "\n", "\"Loss in iteration \"", "\n", "+", "str", "(", "epoch", ")", "\n", "+", "\": \"", "\n", "+", "str", "(", "total_loss", ".", "item", "(", ")", "/", "num_iters", ")", "\n", "+", "\"(\"", "\n", "+", "self", ".", "dataset", ".", "dataset_name", "\n", "+", "\")\"", "\n", ")", "\n", "\n", "if", "self", ".", "args", ".", "eval_every", ">", "0", "and", "epoch", "%", "self", ".", "args", ".", "eval_every", "==", "0", ":", "\n", "                ", "tester", "=", "OutKGTester", "(", "self", ".", "dataset", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "mrr", "=", "tester", ".", "test", "(", "self", ".", "model", ",", "valid_or_test", "=", "\"valid\"", ")", "\n", "", "mrr", ",", "mr", ",", "hits_1", ",", "hits_3", ",", "hits_10", "=", "tester", ".", "measure", ".", "mrr", ",", "tester", ".", "measure", ".", "mr", ",", "tester", ".", "measure", ".", "hit1", ",", "tester", ".", "measure", ".", "hit3", ",", "tester", ".", "measure", ".", "hit10", "\n", "\n", "wandb_log_dict", "=", "{", "\n", "'step'", ":", "epoch", ",", "\n", "'loss'", ":", "float", "(", "total_loss", ".", "item", "(", ")", "/", "num_iters", ")", ",", "\n", "'val.mrr'", ":", "mrr", ".", "item", "(", ")", ",", "\n", "'val.mr'", ":", "mr", ".", "item", "(", ")", ",", "\n", "'val.hits_1'", ":", "hits_1", ",", "\n", "'val.hits_3'", ":", "hits_3", ",", "\n", "'val.hits_10'", ":", "hits_10", "\n", "}", "\n", "", "else", ":", "\n", "                ", "wandb_log_dict", "=", "{", "'step'", ":", "epoch", ",", "'loss'", ":", "float", "(", "total_loss", ".", "item", "(", ")", "/", "num_iters", ")", "}", "\n", "\n", "# log to wandb", "\n", "", "if", "self", ".", "args", ".", "wandb", ":", "\n", "                ", "wandb", ".", "log", "(", "wandb_log_dict", ")", "\n", "\n", "\n", "", "if", "epoch", ">", "0", "and", "epoch", "%", "self", ".", "args", ".", "save_each", "==", "0", "and", "save", ":", "\n", "                ", "print", "(", "'save model...'", ")", "\n", "save_model", "(", "\n", "self", ".", "model", ",", "\n", "self", ".", "args", ".", "model_name", ",", "\n", "self", ".", "args", ".", "emb_method", ",", "\n", "self", ".", "dataset", ".", "dataset_name", ",", "\n", "epoch", ",", "\n", "self", ".", "args", ".", "lr", ",", "\n", "self", ".", "args", ".", "reg_lambda", ",", "\n", "self", ".", "args", ".", "neg_ratio", ",", "\n", "self", ".", "args", ".", "emb_dim", ",", "\n", ")", "\n", "\n", "", "", "print", "(", "\"===== TEST ======\"", ")", "\n", "test_tester", "=", "OutKGTester", "(", "self", ".", "dataset", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "mrr", "=", "test_tester", ".", "test", "(", "self", ".", "model", ",", "valid_or_test", "=", "\"test\"", ")", "\n", "", "mrr", ",", "mr", ",", "hits_1", ",", "hits_3", ",", "hits_10", "=", "test_tester", ".", "measure", ".", "mrr", ",", "test_tester", ".", "measure", ".", "mr", ",", "test_tester", ".", "measure", ".", "hit1", ",", "test_tester", ".", "measure", ".", "hit3", ",", "test_tester", ".", "measure", ".", "hit10", "\n", "\n", "if", "self", ".", "args", ".", "wandb", ":", "\n", "            ", "wandb_log_dict", "=", "{", "\n", "'loss'", ":", "float", "(", "total_loss", ".", "item", "(", ")", "/", "num_iters", ")", ",", "\n", "'test.mrr'", ":", "mrr", ".", "item", "(", ")", ",", "\n", "'test.mr'", ":", "mr", ".", "item", "(", ")", ",", "\n", "'test.hits_1'", ":", "hits_1", ",", "\n", "'test.hits_3'", ":", "hits_3", ",", "\n", "'test.hits_10'", ":", "hits_10", "\n", "}", "\n", "wandb", ".", "log", "(", "wandb_log_dict", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.__init__": [[15, 21], ["common.measure.Measure", "torch.device", "tester.OutKGTester.get_unseen_entities", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.get_unseen_entities"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "measure", "=", "Measure", "(", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "unseen_ent", "=", "self", ".", "get_unseen_entities", "(", ")", "\n", "self", ".", "new_node_init", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.test": [[22, 45], ["tester.OutKGTester.model.to", "tester.OutKGTester.model.eval", "hasattr", "enumerate", "tester.OutKGTester.measure.normalize", "tester.OutKGTester.measure.print_", "torch.load", "tester.OutKGTester.model.reset", "tqdm.tqdm.tqdm", "tester.OutKGTester.get_ent_triples", "range", "type", "type", "tester.OutKGTester.dataset.val_test_data[].keys", "len", "numpy.delete", "tester.OutKGTester.predict"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.print_", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.dm_tokenized.TokenizedDistMult.reset", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.predict"], ["", "def", "test", "(", "self", ",", "model_path", ",", "valid_or_test", ")", ":", "\n", "        ", "if", "type", "(", "model_path", ")", "==", "\"tuple\"", "or", "type", "(", "model_path", ")", "==", "\"str\"", ":", "\n", "            ", "self", ".", "model", "=", "torch", ".", "load", "(", "model_path", ")", "# removed module", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "model_path", "# removed module", "\n", "\n", "", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "# for bypassing torch DP", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "hasattr", "(", "self", ".", "model", ",", "\"reset\"", ")", ":", "\n", "            ", "self", ".", "model", ".", "reset", "(", ")", "\n", "\n", "", "for", "i", ",", "new_ent", "in", "enumerate", "(", "tqdm", "(", "self", ".", "dataset", ".", "val_test_data", "[", "valid_or_test", "]", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "self", ".", "new_node_init", "=", "None", "\n", "ent_triples", "=", "self", ".", "get_ent_triples", "(", "new_ent", ",", "valid_or_test", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "ent_triples", ")", ")", ":", "\n", "                ", "obs_triples", "=", "np", ".", "delete", "(", "ent_triples", ",", "[", "j", "]", ",", "axis", "=", "0", ")", "\n", "target_triple", "=", "ent_triples", "[", "j", "]", "\n", "new_ent_id", "=", "self", ".", "dataset", ".", "init_num_ent", "\n", "self", ".", "predict", "(", "target_triple", ",", "new_ent_id", ",", "obs_triples", ")", "\n", "\n", "", "", "self", ".", "measure", ".", "normalize", "(", ")", "\n", "self", ".", "measure", ".", "print_", "(", ")", "\n", "return", "self", ".", "measure", ".", "mrr", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.predict": [[46, 61], ["tester.OutKGTester.create_queries", "tester.OutKGTester.model.get_rel_embs", "tester.OutKGTester.model.find_embedding", "tester.OutKGTester.model.get_ent_embs", "tester.OutKGTester.model.cal_score", "tester.OutKGTester.get_rank", "tester.OutKGTester.measure.update", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.create_queries", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_rel_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.find_embedding", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.get_ent_embs", "home.repos.pwc.inspect_result.migalkin_NodePiece.model.BaseOutKG.BaseOutKG.cal_score", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.get_rank", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update"], ["", "def", "predict", "(", "self", ",", "target_triple", ",", "new_ent", ",", "obs_triples", ")", ":", "\n", "        ", "head_or_tail", "=", "\"tail\"", "if", "target_triple", "[", "0", "]", "==", "new_ent", "else", "\"head\"", "\n", "queries_ent", ",", "rel_id", "=", "self", ".", "create_queries", "(", "\n", "target_triple", ",", "head_or_tail", ",", "obs_triples", "\n", ")", "\n", "rel_emb", "=", "self", ".", "model", ".", "get_rel_embs", "(", "\n", "torch", ".", "tensor", "(", "rel_id", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "new_ent_emb", "=", "self", ".", "model", ".", "find_embedding", "(", "new_ent", ",", "obs_triples", ")", "\n", "queries_ent_emb", "=", "self", ".", "model", ".", "get_ent_embs", "(", "\n", "torch", ".", "tensor", "(", "queries_ent", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "scores", "=", "self", ".", "model", ".", "cal_score", "(", "queries_ent_emb", ",", "new_ent_emb", ",", "rel_emb", ")", "\n", "rank", "=", "self", ".", "get_rank", "(", "scores", ")", "\n", "self", ".", "measure", ".", "update", "(", "rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.filter_entities": [[62, 68], ["numpy.where"], "methods", ["None"], ["", "def", "filter_entities", "(", "self", ",", "obs_triples", ",", "rel_id", ",", "head_or_tail", ")", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "obs_triples", "[", ":", ",", "1", "]", "==", "rel_id", ")", "[", "0", "]", "\n", "if", "head_or_tail", "==", "\"head\"", ":", "\n", "            ", "return", "obs_triples", "[", "idx", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "obs_triples", "[", "idx", ",", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.create_queries": [[69, 82], ["list", "tester.OutKGTester.filter_entities().tolist", "range", "set", "set", "list", "tester.OutKGTester.filter_entities", "list", "set", "set"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.filter_entities"], ["", "", "def", "create_queries", "(", "self", ",", "target_triple", ",", "head_or_tail", ",", "obs_triples", ")", ":", "\n", "        ", "head_id", ",", "rel_id", ",", "tail_id", "=", "target_triple", "\n", "ent_list", "=", "list", "(", "range", "(", "self", ".", "dataset", ".", "init_num_ent", ")", ")", "\n", "filtered_ent_list", "=", "self", ".", "filter_entities", "(", "\n", "obs_triples", ",", "rel_id", ",", "head_or_tail", "\n", ")", ".", "tolist", "(", ")", "\n", "ent_list", "=", "set", "(", "ent_list", ")", "-", "set", "(", "filtered_ent_list", ")", "\n", "if", "head_or_tail", "==", "\"head\"", ":", "\n", "            ", "ent_list", "=", "list", "(", "ent_list", "-", "set", "(", "[", "head_id", "]", ")", ")", "\n", "return", "[", "head_id", "]", "+", "ent_list", ",", "rel_id", "\n", "", "elif", "head_or_tail", "==", "\"tail\"", ":", "\n", "            ", "ent_list", "=", "list", "(", "ent_list", "-", "set", "(", "[", "tail_id", "]", ")", ")", "\n", "return", "[", "tail_id", "]", "+", "ent_list", ",", "rel_id", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.get_rank": [[83, 89], ["None"], "methods", ["None"], ["", "", "def", "get_rank", "(", "self", ",", "sim_scores", ")", ":", "\n", "# assuming the test fact is the first one", "\n", "        ", "equals", "=", "(", "(", "sim_scores", "==", "sim_scores", "[", "0", "]", ")", ".", "sum", "(", ")", "-", "1", ")", "//", "2", "\n", "higher", "=", "(", "sim_scores", ">", "sim_scores", "[", "0", "]", ")", ".", "sum", "(", ")", "\n", "rank", "=", "(", "equals", "+", "higher", "+", "1.0", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "return", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.get_unseen_entities": [[90, 94], ["set", "set", "set.union", "tester.OutKGTester.dataset.val_test_data[].keys", "tester.OutKGTester.dataset.val_test_data[].keys"], "methods", ["None"], ["", "def", "get_unseen_entities", "(", "self", ")", ":", "\n", "        ", "valid_ent", "=", "set", "(", "self", ".", "dataset", ".", "val_test_data", "[", "\"valid\"", "]", ".", "keys", "(", ")", ")", "\n", "test_ent", "=", "set", "(", "self", ".", "dataset", ".", "val_test_data", "[", "\"test\"", "]", ".", "keys", "(", ")", ")", "\n", "return", "valid_ent", ".", "union", "(", "test_ent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.tester.OutKGTester.get_ent_triples": [[95, 102], ["numpy.asarray", "numpy.where", "numpy.where", "numpy.asarray.astype"], "methods", ["None"], ["", "def", "get_ent_triples", "(", "self", ",", "ent", ",", "valid_or_test", ")", ":", "\n", "        ", "triples", "=", "np", ".", "asarray", "(", "self", ".", "dataset", ".", "val_test_data", "[", "valid_or_test", "]", "[", "ent", "]", ")", "\n", "h", "=", "np", ".", "where", "(", "triples", "[", ":", ",", "0", "]", "==", "ent", ")", "\n", "triples", "[", "h", ",", "0", "]", "=", "self", ".", "dataset", ".", "init_num_ent", "\n", "t", "=", "np", ".", "where", "(", "triples", "[", ":", ",", "2", "]", "==", "ent", ")", "\n", "triples", "[", "t", ",", "2", "]", "=", "self", ".", "dataset", ".", "init_num_ent", "\n", "return", "triples", ".", "astype", "(", "int", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.save_model": [[13, 40], ["print", "os.makedirs", "torch.save", "str", "str", "str", "str", "str"], "function", ["None"], ["\n", "if", "m", "is", "not", "None", ":", "\n", "        ", "m", "=", "m", ".", "float", "(", ")", "\n", "x", "=", "x", "*", "m", "\n", "", "e_x", "=", "torch", ".", "exp", "(", "x", "-", "torch", ".", "max", "(", "x", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "        ", "e_x", "=", "e_x", "*", "m", "\n", "", "softmax", "=", "e_x", "/", "(", "torch", ".", "sum", "(", "e_x", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "\n", "return", "softmax", "\n", "\n", "\n", "", "def", "combine", "(", "*", "args", ":", "Union", "[", "np", ".", "ndarray", ",", "list", ",", "tuple", "]", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.random_new_ent_mask": [[43, 53], ["numpy.random.choice"], "function", ["None"], ["\n", "\n", "# Case A, C", "\n", "if", "len", "(", "args", ")", "==", "1", "and", "type", "(", "args", "[", "0", "]", ")", "is", "not", "dict", ":", "\n", "        ", "return", "np", ".", "array", "(", "args", "[", "0", "]", ")", "\n", "\n", "", "if", "len", "(", "args", ")", "==", "1", "and", "type", "(", "args", ")", "is", "dict", ":", "\n", "        ", "return", "args", "\n", "\n", "# Case B", "\n", "", "if", "type", "(", "args", ")", "is", "tuple", "and", "(", "type", "(", "args", "[", "0", "]", ")", "is", "np", ".", "ndarray", "or", "type", "(", "args", "[", "0", "]", ")", "is", "list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.__init__": [[219, 279], ["super().__init__", "set", "set().issubset", "nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg", "max", "Exception", "sum", "len", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.values", "set", "enumerate", "len", "enumerate", "len", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.keys", "list", "nodepiece_tokenizer.NodePiece_Tokenizer.vocab.items", "nodepiece_tokenizer.NodePiece_Tokenizer.r2id.values"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.tokenize_kg": [[282, 336], ["pathlib.Path", "pathlib.Path.is_file", "igraph.Graph", "nodepiece_tokenizer.NodePiece_Tokenizer.anchor_strategy.items", "nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths", "pickle.dump", "print", "filename.split", "pickle.load", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory[].astype", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory[].astype", "nodepiece_tokenizer.NodePiece_Tokenizer.triples_factory[].astype", "int", "print", "anchors.extend", "print", "open", "open", "zip", "numpy.ceil", "sorted", "range", "list", "NotImplementedError", "sorted", "len", "enumerate", "igraph.Graph.degree", "enumerate", "int", "numpy.random.permutation", "igraph.Graph.personalized_pagerank", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_tokenizer.NodePiece_Tokenizer.create_all_paths": [[338, 365], ["tqdm.tqdm.tqdm", "print", "print", "range", "graph.get_shortest_paths", "len", "random.shuffle", "sorted", "range", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.__init__": [[21, 138], ["torch.nn.Module.__init__", "len", "len", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Embedding", "torch.nn.Embedding", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "collections.defaultdict", "print", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoderLayer", "torch.nn.TransformerEncoder", "torch.nn.TransformerEncoder", "random.sample", "e2r[].add", "len", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "random.sample", "max", "max", "print", "sampled_paths.items", "sampled_paths.items", "list", "range", "int", "collections.defaultdict.items", "random.sample", "range", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "range", "min", "numpy.mean", "numpy.percentile", "max", "min", "len", "sorted", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "len", "len", "len", "len", "sorted", "min", "min", "len", "nodepiece_encoder.NodePieceEncoder.tokenizer.vocab.items", "min", "sampled_paths.items", "int", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample"], ["self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pooler", "=", "config", "[", "'POOLER'", "]", "\n", "self", ".", "policy", "=", "\"sum\"", "\n", "self", ".", "use_rels", "=", "False", "\n", "self", ".", "nearest", "=", "config", "[", "'NEAREST'", "]", "\n", "self", ".", "use_neighbor_rels", "=", "False", "\n", "self", ".", "sample_rels", "=", "config", "[", "'SAMPLE_RELS'", "]", "\n", "self", ".", "graph", "=", "graph", "\n", "\n", "if", "not", "self", ".", "use_rels", ":", "\n", "            ", "self", ".", "policy", "=", "\"sum\"", "\n", "\n", "", "self", ".", "random_hashes", "=", "config", "[", "'RANDOM_HASHES'", "]", "\n", "\n", "self", ".", "subbatch", "=", "config", "[", "'SUBBATCH'", "]", "\n", "self", ".", "embedding_dim", "=", "config", "[", "'EMBEDDING_DIM'", "]", "\n", "self", ".", "real_embedding_dim", "=", "self", ".", "embedding_dim", "//", "2", "\n", "\n", "self", ".", "max_seq_len", "=", "config", "[", "'MAX_PATH_LEN'", "]", "\n", "self", ".", "sample_paths", "=", "config", "[", "'MAX_PATHS'", "]", "\n", "self", ".", "use_distances", "=", "config", "[", "'USE_DISTANCES'", "]", "\n", "self", ".", "hid_dim", "=", "config", "[", "'T_HIDDEN'", "]", "\n", "self", ".", "drop_prob", "=", "config", "[", "'T_DROP'", "]", "\n", "self", ".", "num_heads", "=", "config", "[", "'T_HEADS'", "]", "\n", "self", ".", "num_layers", "=", "config", "[", "'T_LAYERS'", "]", "\n", "self", ".", "num_entities", "=", "config", "[", "'NUM_ENTITIES'", "]", "\n", "self", ".", "num_relations", "=", "config", "[", "'NUM_RELATIONS'", "]", "\n", "self", ".", "device", "=", "config", "[", "'DEVICE'", "]", "\n", "self", ".", "no_anc", "=", "config", "[", "'NO_ANC'", "]", "\n", "\n", "\n", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "embedding_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "\n", ")", "\n", "self", ".", "set_dec", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "hid_dim", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "embedding_dim", ")", "\n", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"cat\"", ":", "\n", "            ", "self", ".", "set_enc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "(", "self", ".", "sample_paths", "+", "self", ".", "sample_rels", ")", ",", "self", ".", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# nn.Linear(embedding_dim * 4, embedding_dim * 2), nn.Dropout(drop_prob), nn.ReLU(),", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "2", ",", "self", ".", "embedding_dim", ")", "\n", ")", "if", "not", "self", ".", "no_anc", "else", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "self", ".", "sample_rels", ",", "self", ".", "embedding_dim", "*", "2", ")", ",", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "*", "2", ",", "self", ".", "embedding_dim", ")", ")", "\n", "", "elif", "self", ".", "pooler", "==", "\"trf\"", ":", "\n", "            ", "encoder_layer", "=", "TransformerEncoderLayer", "(", "\n", "d_model", "=", "self", ".", "embedding_dim", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "embedding_dim", ",", "\n", "nhead", "=", "self", ".", "num_heads", "if", "self", ".", "policy", "!=", "\"cat\"", "else", "2", "*", "self", ".", "num_heads", ",", "\n", "dim_feedforward", "=", "self", ".", "hid_dim", ",", "\n", "dropout", "=", "self", ".", "drop_prob", ",", "\n", ")", "\n", "self", ".", "set_enc", "=", "TransformerEncoder", "(", "encoder_layer", "=", "encoder_layer", ",", "num_layers", "=", "self", ".", "num_layers", ")", "\n", "if", "self", ".", "policy", "==", "\"cat\"", ":", "\n", "                ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "embedding_dim", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "\n", "\n", "\n", "", "", "self", ".", "rel_gnn", "=", "False", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "NOTHING_TOKEN", "]", "=", "len", "(", "tokenizer", ".", "token2id", ")", "\n", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tokenizer", ".", "token2id", ")", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ",", "\n", "padding_idx", "=", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", ")", "\n", "self", ".", "relation_embeddings", "=", "rel_embs", "\n", "self", ".", "dist_emb", "=", "nn", ".", "Embedding", "(", "self", ".", "max_seq_len", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ")", "\n", "\n", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "if", "not", "self", ".", "nearest", ":", "\n", "# subsample paths, need to align them with distances", "\n", "                ", "sampled_paths", "=", "{", "\n", "entity", ":", "random", ".", "sample", "(", "paths", ",", "k", "=", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", ")", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "", "elif", "self", ".", "nearest", ":", "\n", "# sort paths by length first and take K of them", "\n", "                ", "prev_max_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "sampled_paths", "=", "{", "\n", "entity", ":", "sorted", "(", "paths", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "[", ":", "min", "(", "self", ".", "sample_paths", ",", "len", "(", "paths", ")", ")", "]", "\n", "for", "entity", ",", "paths", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "max_seq_len", "=", "max", "(", "len", "(", "path", ")", "for", "k", ",", "v", "in", "sampled_paths", ".", "items", "(", ")", "for", "path", "in", "v", ")", "\n", "print", "(", "\n", "f\"Changed max seq len from {prev_max_len} to {self.max_seq_len} after keeping {self.sample_paths} shortest paths\"", ")", "\n", "\n", "", "hashes", "=", "[", "\n", "[", "self", ".", "tokenizer", ".", "token2id", "[", "path", "[", "0", "]", "]", "for", "path", "in", "paths", "]", "+", "[", "\n", "self", ".", "tokenizer", ".", "token2id", "[", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "distances", "=", "[", "\n", "[", "len", "(", "path", ")", "-", "1", "for", "path", "in", "paths", "]", "+", "[", "0", "]", "*", "(", "self", ".", "sample_paths", "-", "len", "(", "paths", ")", ")", "\n", "for", "entity", ",", "paths", "in", "sampled_paths", ".", "items", "(", ")", "\n", "]", "\n", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "tensor", "(", "distances", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "", "else", ":", "\n", "# in this case, we bypass distances and won't use relations in the encoder", "\n", "            ", "self", ".", "anchor_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "random_hashes", ",", "embedding_dim", "=", "self", ".", "embedding_dim", ")", "\n", "hashes", "=", "[", "\n", "random", ".", "sample", "(", "list", "(", "range", "(", "self", ".", "random_hashes", ")", ")", ",", "self", ".", "sample_paths", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_entities", ")", "\n", "]", "\n", "# _PRIMES = [", "\n", "#     31, 43, 59, 61, 73, 97, 103, 113, 137, 149, 157, 173, 181, 193, 211, 223", "\n", "# ]", "\n", "# self.num_buckets = self.random_hashes", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters": [[139, 163], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "nodepiece_encoder.NodePieceEncoder.set_enc.modules", "hasattr", "nodepiece_encoder.NodePieceEncoder.set_dec.modules", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "module.reset_parameters", "hasattr", "module.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters", "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.reset_parameters"], ["\n", "# self.anchor_embeddings = nn.Embedding(self.num_buckets * self.num_hashes, embedding_dim=embedding_dim // self.num_hashes)", "\n", "\n", "# self.hash_projector = nn.Sequential(", "\n", "#     nn.Linear(self.embedding_dim, self.embedding_dim),", "\n", "#     nn.ReLU(),", "\n", "#     nn.Linear(self.embedding_dim, self.embedding_dim)", "\n", "# )", "\n", "\n", "# primes = _PRIMES[:self.num_hashes]", "\n", "# hashes = [", "\n", "#     [(((i+1) * prime) % self.num_buckets) + k*self.num_buckets for k, prime in enumerate(primes)]", "\n", "#     for i in range(triples.num_entities)", "\n", "# ]", "\n", "\n", "self", ".", "hashes", "=", "torch", ".", "tensor", "(", "hashes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "distances", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_entities", ",", "self", ".", "sample_paths", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "\n", "", "if", "self", ".", "use_neighbor_rels", ":", "\n", "# create a feature matrix where rows are used relations in a 1-hop neighbourhood around each node", "\n", "            ", "unique_sp", "=", "self", ".", "triples_factory", ".", "mapped_triples", "[", ":", ",", "[", "0", ",", "1", "]", "]", ".", "unique", "(", "dim", "=", "0", ",", "return_counts", "=", "False", ")", "\n", "self", ".", "relation_features", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_entities", ",", "self", ".", "num_relations", "*", "2", ")", ",", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors": [[165, 179], ["anc_embs.view.view.view", "nodepiece_encoder.NodePieceEncoder.set_enc", "nodepiece_encoder.NodePieceEncoder.set_enc", "pooled.mean.mean.mean", "anc_embs.view.view.transpose"], "methods", ["None"], ["device", "=", "self", ".", "device", ")", "# features matrix", "\n", "self", ".", "relation_features", "[", "unique_sp", "[", ":", ",", "0", "]", ",", "unique_sp", "[", ":", ",", "1", "]", "]", "=", "1.0", "# counts.float().to(self.device)", "\n", "# self.relation_features = torch.nn.functional.normalize(self.relation_features, p=1, dim=1)", "\n", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "embedding_dim", "+", "self", ".", "num_relations", ",", "self", ".", "hid_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "embedding_dim", ")", "\n", ")", "\n", "\n", "", "if", "self", ".", "sample_rels", ">", "0", ":", "\n", "            ", "pad_idx", "=", "self", ".", "num_relations", "*", "2", "\n", "e2r", "=", "defaultdict", "(", "set", ")", "\n", "edge_index", "=", "self", ".", "graph", ".", "edge_index", "\n", "edge_type", "=", "self", ".", "graph", ".", "edge_type", "\n", "for", "i", ",", "src_node", "in", "enumerate", "(", "edge_index", "[", "0", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index": [[180, 202], ["nodepiece_encoder.NodePieceEncoder.anchor_embeddings", "nodepiece_encoder.NodePieceEncoder.pool_anchors", "nodepiece_encoder.NodePieceEncoder.dist_emb", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors"], ["                ", "e2r", "[", "src_node", ".", "item", "(", ")", "]", ".", "add", "(", "edge_type", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "", "len_stats", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "e2r", ".", "items", "(", ")", "]", "\n", "print", "(", "\n", "f\"Unique relations per node - min: {min(len_stats)}, avg: {np.mean(len_stats)}, 66th perc: {np.percentile(sorted(len_stats), 66)}, max: {max(len_stats)} \"", ")", "\n", "unique_1hop_relations", "=", "[", "\n", "random", ".", "sample", "(", "e2r", "[", "i", "]", ",", "k", "=", "min", "(", "self", ".", "sample_rels", ",", "len", "(", "e2r", "[", "i", "]", ")", ")", ")", "+", "[", "pad_idx", "]", "*", "(", "\n", "self", ".", "sample_rels", "-", "min", "(", "len", "(", "e2r", "[", "i", "]", ")", ",", "self", ".", "sample_rels", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_entities", ")", "\n", "]", "\n", "self", ".", "unique_1hop_relations", "=", "torch", ".", "tensor", "(", "unique_1hop_relations", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooler", "!=", "\"avg\"", ":", "\n", "            ", "for", "module", "in", "self", ".", "set_enc", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "", "", "if", "self", ".", "pooler", "==", "\"mlp\"", ":", "\n", "                ", "for", "module", "in", "self", ".", "set_dec", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "module", "is", "self", ":", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.get_all_representations": [[204, 215], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "list", "tqdm.tqdm.tqdm", "range", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "nodepiece_encoder.NodePieceEncoder.encode_by_index", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_index"], ["", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                        ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "\n", "", "", "", "", "if", "self", ".", "use_neighbor_rels", ":", "\n", "            ", "for", "module", "in", "self", ".", "projection", ".", "modules", "(", ")", ":", "\n", "                ", "if", "module", "is", "self", ":", "\n", "                    ", "continue", "\n", "", "if", "hasattr", "(", "module", ",", "\"reset_parameters\"", ")", ":", "\n", "                    ", "module", ".", "reset_parameters", "(", ")", "\n", "\n", "# if self.random_hashes != 0:", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.encode_by_hash": [[217, 243], ["nodepiece_encoder.NodePieceEncoder.anchor_embeddings", "nodepiece_encoder.NodePieceEncoder.pool_anchors", "hashes.unsqueeze", "nodepiece_encoder.NodePieceEncoder.dist_emb", "nodepiece_encoder.NodePieceEncoder.relation_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor.unsqueeze", "torch.tensor.unsqueeze", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.random.permutation", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.vocab.nodepiece_encoder.NodePieceEncoder.pool_anchors"], ["#         if module is self:", "\n", "#             continue", "\n", "#         if hasattr(module, \"reset_parameters\"):", "\n", "#             module.reset_parameters()", "\n", "\n", "", "", "", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "anchor_embeddings", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dist_emb", ".", "weight", ")", "\n", "if", "self", ".", "use_rels", "==", "\"joint\"", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "node_types", ".", "weight", ")", "\n", "\n", "", "if", "self", ".", "random_hashes", "==", "0", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "anchor_embeddings", ".", "weight", "[", "self", ".", "tokenizer", ".", "token2id", "[", "self", ".", "tokenizer", ".", "PADDING_TOKEN", "]", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "self", ".", "dist_emb", ".", "weight", "[", "0", "]", "=", "torch", ".", "zeros", "(", "self", ".", "embedding_dim", ")", "\n", "# if self.use_rels == \"trf\":", "\n", "#     self.rel_pos.weight[0] = torch.zeros(self.embedding_dim)", "\n", "\n", "# phases randomly between 0 and 2 pi", "\n", "# phases = 2 * np.pi * torch.rand(self.num_relations, self.real_embedding_dim, device=self.device)", "\n", "# relations = torch.stack([torch.cos(phases), torch.sin(phases)], dim=-1).detach()", "\n", "# assert torch.allclose(torch.norm(relations, p=2, dim=-1), phases.new_ones(size=(1, 1)))", "\n", "# self.relation_embeddings.weight.data[:-1] = relations.view(self.num_relations, self.embedding_dim)", "\n", "# self.relation_embeddings.weight.data[-1] = torch.zeros(self.embedding_dim)", "\n", "\n", "", "", "", "def", "pool_anchors", "(", "self", ",", "anc_embs", ":", "torch", ".", "FloatTensor", ",", "mask", ":", "Optional", "[", "torch", ".", "BoolTensor", "]", "=", "None", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        "]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.__init__": [[20, 30], ["dataset_prep.DatasetPreprocess.read_all"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.read_all"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "smpl_ratio", "=", "0.2", ",", "spl_ratio", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "data_path", "=", "\"datasets/\"", "+", "dataset_name", "+", "\"/\"", "\n", "self", ".", "ent2id", "=", "{", "}", "\n", "self", ".", "rel2id", "=", "{", "}", "\n", "self", ".", "all_triples", "=", "self", ".", "read_all", "(", ")", "\n", "self", ".", "smpl_ratio", "=", "smpl_ratio", "\n", "self", ".", "spl_ratio", "=", "spl_ratio", "\n", "self", ".", "old_ent", "=", "[", "]", "\n", "self", ".", "new_ent", "=", "[", "]", "\n", "self", ".", "test_triples", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.read_all": [[31, 43], ["numpy.zeros", "enumerate", "numpy.array", "open", "f.readlines", "len", "dataset_prep.DatasetPreprocess.triple2ids", "all_lines.append", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.triple2ids"], ["", "def", "read_all", "(", "self", ")", ":", "\n", "        ", "all_lines", "=", "[", "]", "\n", "for", "spl", "in", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ":", "\n", "            ", "file_path", "=", "self", ".", "data_path", "+", "spl", "+", "\".txt\"", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                    ", "all_lines", ".", "append", "(", "line", ")", "\n", "", "", "", "triples", "=", "np", ".", "zeros", "(", "(", "len", "(", "all_lines", ")", ",", "3", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "all_lines", ")", ":", "\n", "            ", "triples", "[", "i", "]", "=", "np", ".", "array", "(", "self", ".", "triple2ids", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", ")", ")", "\n", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.make_dataset": [[44, 53], ["dataset_prep.DatasetPreprocess.single_triple_ent", "dataset_prep.DatasetPreprocess.split_entities", "dataset_prep.DatasetPreprocess.separate_triples", "dataset_prep.DatasetPreprocess.find_dangling_ent", "dataset_prep.DatasetPreprocess.find_dangling_rel", "dataset_prep.DatasetPreprocess.explore_split_dataset", "dataset_prep.DatasetPreprocess.constraint_check", "dataset_prep.DatasetPreprocess.save_dataset"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.single_triple_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.split_entities", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.separate_triples", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.find_dangling_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.find_dangling_rel", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.explore_split_dataset", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.constraint_check", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.save_dataset"], ["", "def", "make_dataset", "(", "self", ")", ":", "\n", "        ", "self", ".", "single_triple_ent", "(", ")", "\n", "self", ".", "split_entities", "(", ")", "\n", "self", ".", "separate_triples", "(", ")", "\n", "self", ".", "find_dangling_ent", "(", ")", "\n", "self", ".", "find_dangling_rel", "(", ")", "\n", "self", ".", "explore_split_dataset", "(", ")", "\n", "self", ".", "constraint_check", "(", ")", "\n", "self", ".", "save_dataset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.single_triple_ent": [[54, 66], ["numpy.zeros", "range", "dataset_prep.DatasetPreprocess.old_ent.extend", "dataset_prep.DatasetPreprocess.num_ent", "dataset_prep.DatasetPreprocess.num_ent", "numpy.where", "list", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent"], ["", "def", "single_triple_ent", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        find those entities that are participated in only one triple \n        add them to self.old_ent\n        \"\"\"", "\n", "ent_triple_count", "=", "np", ".", "zeros", "(", "self", ".", "num_ent", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_ent", "(", ")", ")", ":", "\n", "            ", "ent_triple_count", "[", "i", "]", "=", "np", ".", "sum", "(", "self", ".", "all_triples", "[", ":", ",", "0", "]", "==", "i", ")", "+", "np", ".", "sum", "(", "\n", "self", ".", "all_triples", "[", ":", ",", "2", "]", "==", "i", "\n", ")", "\n", "", "single_triple_ent", "=", "np", ".", "where", "(", "ent_triple_count", "==", "1", ")", "[", "0", "]", "\n", "self", ".", "old_ent", ".", "extend", "(", "list", "(", "single_triple_ent", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.split_entities": [[67, 72], ["set", "random.sample", "dataset_prep.DatasetPreprocess.old_ent.extend", "range", "set", "list", "int", "list", "dataset_prep.DatasetPreprocess.num_ent", "len", "set"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent"], ["", "def", "split_entities", "(", "self", ")", ":", "\n", "        ", "all_ent", "=", "set", "(", "range", "(", "self", ".", "num_ent", "(", ")", ")", ")", "\n", "all_ent", "=", "all_ent", "-", "set", "(", "self", ".", "old_ent", ")", "\n", "self", ".", "new_ent", "=", "random", ".", "sample", "(", "list", "(", "all_ent", ")", ",", "int", "(", "len", "(", "all_ent", ")", "*", "self", ".", "smpl_ratio", ")", ")", "\n", "self", ".", "old_ent", ".", "extend", "(", "list", "(", "all_ent", "-", "set", "(", "self", ".", "new_ent", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.save_dataset": [[73, 90], ["print", "open", "open.writelines", "open.close", "print", "os.path.isdir", "os.makedirs", "dataset_prep.DatasetPreprocess.ids2triple", "open", "json.dump", "open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.ids2triple"], ["", "def", "save_dataset", "(", "self", ")", ":", "\n", "# save train", "\n", "        ", "new_dir", "=", "self", ".", "data_path", "+", "\"processed/\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "new_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "new_dir", ")", "\n", "", "print", "(", "\"Saving old triples\"", ")", "\n", "old_triples_seq", "=", "[", "self", ".", "ids2triple", "(", "t", ")", "for", "t", "in", "self", ".", "old_triples", "]", "\n", "out_f", "=", "open", "(", "new_dir", "+", "\"train.txt\"", ",", "\"w\"", ")", "\n", "out_f", ".", "writelines", "(", "old_triples_seq", ")", "\n", "out_f", ".", "close", "(", ")", "\n", "\n", "# split new triples to [val, test] and save", "\n", "print", "(", "\"Saving new triples\"", ")", "\n", "with", "open", "(", "new_dir", "+", "\"valid.json\"", ",", "\"w\"", ")", "as", "json_file", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "valid_dict", ",", "json_file", ")", "\n", "", "with", "open", "(", "new_dir", "+", "\"test.json\"", ",", "\"w\"", ")", "as", "json_file", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "test_dict", ",", "json_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.constraint_check": [[91, 119], ["numpy.union1d", "set().union", "print", "print", "print", "print", "print", "set", "len", "len", "dataset_prep.DatasetPreprocess.num_ent", "len", "len", "len", "set", "dataset_prep.DatasetPreprocess.valid_dict.keys", "len", "dataset_prep.DatasetPreprocess.num_ent", "len", "len", "len", "len", "dataset_prep.DatasetPreprocess.test_dict.keys", "dataset_prep.DatasetPreprocess.num_ent", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent"], ["", "", "def", "constraint_check", "(", "self", ")", ":", "\n", "        ", "old_ent", "=", "np", ".", "union1d", "(", "self", ".", "old_triples", "[", ":", ",", "0", "]", ",", "self", ".", "old_triples", "[", ":", ",", "2", "]", ")", "\n", "new_ent", "=", "set", "(", "self", ".", "test_dict", ".", "keys", "(", ")", ")", ".", "union", "(", "set", "(", "self", ".", "valid_dict", ".", "keys", "(", ")", ")", ")", "\n", "all_ent", "=", "len", "(", "old_ent", ")", "+", "len", "(", "new_ent", ")", "\n", "removed_ent", "=", "self", ".", "num_ent", "(", ")", "-", "all_ent", "\n", "print", "(", "\"New entity ratio: \"", ",", "len", "(", "new_ent", ")", "/", "self", ".", "num_ent", "(", ")", ")", "\n", "print", "(", "\n", "\"Number of deleted entities: {}, ratio: {}\"", ".", "format", "(", "\n", "removed_ent", ",", "removed_ent", "/", "self", ".", "num_ent", "(", ")", "\n", ")", "\n", ")", "\n", "\n", "total_triples", "=", "len", "(", "self", ".", "old_triples", ")", "+", "len", "(", "self", ".", "test_triples", ")", "\n", "removed_triples", "=", "len", "(", "self", ".", "all_triples", ")", "-", "total_triples", "\n", "print", "(", "\n", "\"Number of deleted triples: {}, ratio: {}\"", ".", "format", "(", "\n", "removed_triples", ",", "removed_triples", "/", "len", "(", "self", ".", "all_triples", ")", "\n", ")", "\n", ")", "\n", "\n", "print", "(", "\n", "\"[Train] #entities: {}, #triples: {}\"", ".", "format", "(", "\n", "len", "(", "self", ".", "old_ent", ")", ",", "len", "(", "self", ".", "old_triples", ")", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "\"[Valid/Test] #entities: {}, #triples: {}\"", ".", "format", "(", "\n", "len", "(", "new_ent", ")", ",", "len", "(", "self", ".", "test_triples", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.separate_triples": [[122, 129], ["dataset_prep.DatasetPreprocess.get_ent_triples", "numpy.ones", "len"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples"], ["", "def", "separate_triples", "(", "self", ")", ":", "\n", "        ", "self", ".", "new_triples", ",", "new_ids", "=", "self", ".", "get_ent_triples", "(", "\n", "self", ".", "new_ent", ",", "self", ".", "all_triples", ",", "return_ids", "=", "True", "\n", ")", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "all_triples", ")", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "new_ids", "]", "=", "False", "\n", "self", ".", "old_triples", "=", "self", ".", "all_triples", "[", "mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.find_dangling_ent": [[130, 133], ["numpy.union1d", "list", "set", "set"], "methods", ["None"], ["", "def", "find_dangling_ent", "(", "self", ")", ":", "\n", "        ", "old_triples_ent", "=", "np", ".", "union1d", "(", "self", ".", "old_triples", "[", ":", ",", "0", "]", ",", "self", ".", "old_triples", "[", ":", ",", "2", "]", ")", "\n", "self", ".", "dang_ent", "=", "list", "(", "set", "(", "self", ".", "old_ent", ")", "-", "set", "(", "old_triples_ent", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.find_dangling_rel": [[134, 138], ["set", "list", "list", "dataset_prep.DatasetPreprocess.rel2id.values", "set"], "methods", ["None"], ["", "def", "find_dangling_rel", "(", "self", ")", ":", "\n", "        ", "old_triples_rel", "=", "set", "(", "self", ".", "old_triples", "[", ":", ",", "1", "]", ")", "\n", "rel_ids", "=", "list", "(", "self", ".", "rel2id", ".", "values", "(", ")", ")", "\n", "self", ".", "dang_rel", "=", "list", "(", "set", "(", "rel_ids", ")", "-", "old_triples_rel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.explore_split_dataset": [[139, 182], ["list", "random.sample", "list", "dataset_prep.DatasetPreprocess.get_ent_triples", "dataset_prep.DatasetPreprocess.get_ent_triples", "numpy.ones", "numpy.nonzero", "numpy.ones", "list", "dataset_prep.DatasetPreprocess.get_ent_triples", "numpy.ones", "numpy.where", "numpy.ones", "new_ent_dict.keys", "int", "len", "numpy.in1d", "len", "len", "len", "len", "dataset_prep.DatasetPreprocess.test_triples.extend", "set", "set", "set", "set", "dataset_prep.DatasetPreprocess.tolist", "len", "dataset_prep.DatasetPreprocess.get_ent_str", "dataset_prep.DatasetPreprocess.get_ent_str", "dataset_prep.DatasetPreprocess.get_rel_str", "dataset_prep.DatasetPreprocess.get_ent_str"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_rel_str", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str"], ["", "def", "explore_split_dataset", "(", "self", ")", ":", "\n", "        ", "new_ent_dict", "=", "{", "}", "\n", "for", "new_e", "in", "self", ".", "new_ent", ":", "\n", "            ", "ent_triples", "=", "self", ".", "get_ent_triples", "(", "[", "new_e", "]", ",", "self", ".", "new_triples", ")", "\n", "# remove those triples that contain dangle entity", "\n", "_", ",", "ids", "=", "self", ".", "get_ent_triples", "(", "self", ".", "dang_ent", ",", "ent_triples", ",", "return_ids", "=", "True", ")", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "ent_triples", ")", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "ids", "]", "=", "False", "\n", "ent_triples", "=", "ent_triples", "[", "mask", "]", "\n", "# remove those triples that contain dangle relations", "\n", "ids", "=", "np", ".", "nonzero", "(", "np", ".", "in1d", "(", "ent_triples", "[", ":", ",", "1", "]", ",", "self", ".", "dang_rel", ")", ")", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "ent_triples", ")", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "ids", "]", "=", "False", "\n", "ent_triples", "=", "ent_triples", "[", "mask", "]", "\n", "# remove those triples that contain other new_ent", "\n", "other_new_ent", "=", "list", "(", "set", "(", "self", ".", "new_ent", ")", "-", "set", "(", "[", "new_e", "]", ")", ")", "\n", "_", ",", "ids", "=", "self", ".", "get_ent_triples", "(", "other_new_ent", ",", "ent_triples", ",", "return_ids", "=", "True", ")", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "ent_triples", ")", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "ids", "]", "=", "False", "\n", "ent_triples", "=", "ent_triples", "[", "mask", "]", "\n", "\n", "# remove reflexive triples", "\n", "ref_ids", "=", "np", ".", "where", "(", "ent_triples", "[", ":", ",", "0", "]", "==", "ent_triples", "[", ":", ",", "2", "]", ")", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "ent_triples", ")", ",", "dtype", "=", "bool", ")", "\n", "mask", "[", "ref_ids", "]", "=", "False", "\n", "ent_triples", "=", "ent_triples", "[", "mask", "]", "\n", "\n", "if", "len", "(", "ent_triples", ")", ">=", "2", ":", "\n", "                ", "new_ent_dict", "[", "self", ".", "get_ent_str", "(", "new_e", ")", "]", "=", "[", "\n", "[", "\n", "self", ".", "get_ent_str", "(", "t", "[", "0", "]", ")", ",", "\n", "self", ".", "get_rel_str", "(", "t", "[", "1", "]", ")", ",", "\n", "self", ".", "get_ent_str", "(", "t", "[", "2", "]", ")", ",", "\n", "]", "\n", "for", "t", "in", "ent_triples", "\n", "]", "\n", "self", ".", "test_triples", ".", "extend", "(", "ent_triples", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "new_keys", "=", "list", "(", "new_ent_dict", ".", "keys", "(", ")", ")", "\n", "valid_ent", "=", "random", ".", "sample", "(", "new_keys", ",", "int", "(", "len", "(", "new_keys", ")", "*", "self", ".", "spl_ratio", ")", ")", "\n", "test_ent", "=", "list", "(", "set", "(", "new_keys", ")", "-", "set", "(", "valid_ent", ")", ")", "\n", "self", ".", "valid_dict", "=", "{", "k", ":", "new_ent_dict", "[", "k", "]", "for", "k", "in", "valid_ent", "}", "\n", "self", ".", "test_dict", "=", "{", "k", ":", "new_ent_dict", "[", "k", "]", "for", "k", "in", "test_ent", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_triples": [[183, 190], ["numpy.nonzero", "numpy.nonzero", "numpy.union1d", "numpy.in1d", "numpy.in1d"], "methods", ["None"], ["", "def", "get_ent_triples", "(", "self", ",", "e_ids", ",", "triples", ",", "return_ids", "=", "False", ")", ":", "\n", "        ", "h_ids", "=", "np", ".", "nonzero", "(", "np", ".", "in1d", "(", "triples", "[", ":", ",", "0", "]", ",", "e_ids", ")", ")", "\n", "t_ids", "=", "np", ".", "nonzero", "(", "np", ".", "in1d", "(", "triples", "[", ":", ",", "2", "]", ",", "e_ids", ")", ")", "\n", "triple_ids", "=", "np", ".", "union1d", "(", "h_ids", ",", "t_ids", ")", "\n", "if", "return_ids", ":", "\n", "            ", "return", "triples", "[", "triple_ids", "]", ",", "triple_ids", "\n", "", "return", "triples", "[", "triple_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.smpl_new_ent": [[191, 199], ["dataset_prep.DatasetPreprocess.ent2id.keys", "random.sample", "list", "list", "int", "set", "set", "dataset_prep.DatasetPreprocess.new_ent2id.values", "dataset_prep.DatasetPreprocess.old_ent2id.values", "dataset_prep.DatasetPreprocess.num_ent"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.pykeen105.negative_sampler.RelationalNegativeSampler.sample", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent"], ["", "def", "smpl_new_ent", "(", "self", ")", ":", "\n", "        ", "all_keys", "=", "self", ".", "ent2id", ".", "keys", "(", ")", "\n", "new_keys", "=", "random", ".", "sample", "(", "all_keys", ",", "int", "(", "self", ".", "num_ent", "(", ")", "*", "self", ".", "smpl_ratio", ")", ")", "\n", "old_keys", "=", "set", "(", "all_keys", ")", "-", "set", "(", "new_keys", ")", "\n", "self", ".", "new_ent2id", "=", "{", "k", ":", "self", ".", "ent2id", "[", "k", "]", "for", "k", "in", "new_keys", "}", "\n", "self", ".", "old_ent2id", "=", "{", "k", ":", "self", ".", "ent2id", "[", "k", "]", "for", "k", "in", "old_keys", "}", "\n", "self", ".", "new_ent", "=", "list", "(", "self", ".", "new_ent2id", ".", "values", "(", ")", ")", "\n", "self", ".", "old_ent", "=", "list", "(", "self", ".", "old_ent2id", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.num_ent": [[200, 202], ["len"], "methods", ["None"], ["", "def", "num_ent", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ent2id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.num_rel": [[203, 205], ["len"], "methods", ["None"], ["", "def", "num_rel", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "rel2id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.triple2ids": [[206, 211], ["dataset_prep.DatasetPreprocess.get_ent_id", "dataset_prep.DatasetPreprocess.get_rel_id", "dataset_prep.DatasetPreprocess.get_ent_id"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_rel_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id"], ["", "def", "triple2ids", "(", "self", ",", "triple", ")", ":", "\n", "        ", "return", "[", "\n", "self", ".", "get_ent_id", "(", "triple", "[", "0", "]", ")", ",", "\n", "self", ".", "get_rel_id", "(", "triple", "[", "1", "]", ")", ",", "\n", "self", ".", "get_ent_id", "(", "triple", "[", "2", "]", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.ids2triple": [[213, 216], ["dataset_prep.DatasetPreprocess.get_ent_str", "dataset_prep.DatasetPreprocess.get_rel_str", "dataset_prep.DatasetPreprocess.get_ent_str"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_rel_str", "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str"], ["", "def", "ids2triple", "(", "self", ",", "ids", ")", ":", "\n", "        ", "return", "\"{0}\\t{1}\\t{2}\\n\"", ".", "format", "(", "\n", "self", ".", "get_ent_str", "(", "ids", "[", "0", "]", ")", ",", "self", ".", "get_rel_str", "(", "ids", "[", "1", "]", ")", ",", "self", ".", "get_ent_str", "(", "ids", "[", "2", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_id": [[218, 222], ["len"], "methods", ["None"], ["", "def", "get_ent_id", "(", "self", ",", "ent", ")", ":", "\n", "        ", "if", "not", "ent", "in", "self", ".", "ent2id", ":", "\n", "            ", "self", ".", "ent2id", "[", "ent", "]", "=", "len", "(", "self", ".", "ent2id", ")", "\n", "", "return", "self", ".", "ent2id", "[", "ent", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_rel_id": [[223, 227], ["len"], "methods", ["None"], ["", "def", "get_rel_id", "(", "self", ",", "rel", ")", ":", "\n", "        ", "if", "not", "rel", "in", "self", ".", "rel2id", ":", "\n", "            ", "self", ".", "rel2id", "[", "rel", "]", "=", "len", "(", "self", ".", "rel2id", ")", "\n", "", "return", "self", ".", "rel2id", "[", "rel", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_ent_str": [[228, 232], ["dataset_prep.DatasetPreprocess.ent2id.items"], "methods", ["None"], ["", "def", "get_ent_str", "(", "self", ",", "e_id", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "self", ".", "ent2id", ".", "items", "(", ")", ":", "\n", "            ", "if", "value", "==", "e_id", ":", "\n", "                ", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.preprocess.dataset_prep.DatasetPreprocess.get_rel_str": [[233, 237], ["dataset_prep.DatasetPreprocess.rel2id.items"], "methods", ["None"], ["", "", "", "def", "get_rel_str", "(", "self", ",", "r_id", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "self", ".", "rel2id", ".", "items", "(", ")", ":", "\n", "            ", "if", "value", "==", "r_id", ":", "\n", "                ", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.__init__": [[10, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "hit1", "=", "0.0", "\n", "self", ".", "hit3", "=", "0.0", "\n", "self", ".", "hit10", "=", "0.0", "\n", "self", ".", "mrr", "=", "0.0", "\n", "self", ".", "mr", "=", "0.0", "\n", "self", ".", "num_facts", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.update": [[18, 28], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "rank", ")", ":", "\n", "        ", "if", "rank", "==", "1", ":", "\n", "            ", "self", ".", "hit1", "+=", "1.0", "\n", "", "if", "rank", "<=", "3", ":", "\n", "            ", "self", ".", "hit3", "+=", "1.0", "\n", "", "if", "rank", "<=", "10", ":", "\n", "            ", "self", ".", "hit10", "+=", "1.0", "\n", "", "self", ".", "mr", "+=", "rank", "\n", "self", ".", "mrr", "+=", "1.0", "/", "rank", "\n", "self", ".", "num_facts", "+=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.normalize": [[29, 38], ["None"], "methods", ["None"], ["", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "hit1", ">", "0.0", ":", "\n", "            ", "self", ".", "hit1", "/=", "self", ".", "num_facts", "\n", "", "if", "self", ".", "hit3", ">", "0.0", ":", "\n", "            ", "self", ".", "hit3", "/=", "self", ".", "num_facts", "\n", "", "if", "self", ".", "hit10", ">", "0.0", ":", "\n", "            ", "self", ".", "hit10", "/=", "self", ".", "num_facts", "\n", "", "self", ".", "mr", "/=", "self", ".", "num_facts", "\n", "self", ".", "mrr", "/=", "self", ".", "num_facts", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.measure.Measure.print_": [[39, 46], ["print", "print", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "print_", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"\\tHit@1 =\"", ",", "self", ".", "hit1", ")", "\n", "print", "(", "\"\\tHit@3 =\"", ",", "self", ".", "hit3", ")", "\n", "print", "(", "\"\\tHit@10 =\"", ",", "self", ".", "hit10", ")", "\n", "print", "(", "\"\\tMR =\"", ",", "self", ".", "mr", ")", "\n", "print", "(", "\"\\tMRR =\"", ",", "self", ".", "mrr", ")", "\n", "print", "(", "\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.__init__": [[21, 39], ["dataset.Dataset.read_text", "dataset.Dataset.num_ent", "dataset.Dataset.dataset_stat", "max", "dataset.Dataset.read_json", "dataset.Dataset.read_json", "map"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.read_text", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.dataset_stat", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.read_json", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.read_json"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "cons_masking", "=", "False", ",", "mask_prob", "=", "0.5", ",", "tokenize", "=", "False", ")", ":", "\n", "        ", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "data_path", "=", "\"../datasets/\"", "+", "dataset_name", "+", "\"/processed/\"", "\n", "self", ".", "ent2id", "=", "{", "}", "\n", "self", ".", "rel2id", "=", "{", "}", "\n", "self", ".", "train_data", "=", "self", ".", "read_text", "(", "self", ".", "data_path", "+", "\"train.txt\"", ")", "\n", "self", ".", "init_num_ent", "=", "self", ".", "num_ent", "(", ")", "\n", "\n", "if", "not", "tokenize", ":", "\n", "            ", "self", ".", "adj_list", ",", "self", ".", "ent_freq", ",", "self", ".", "rel_freq", "=", "self", ".", "dataset_stat", "(", "self", ".", "train_data", ")", "\n", "self", ".", "max_degree", "=", "max", "(", "map", "(", "len", ",", "self", ".", "adj_list", ")", ")", "\n", "", "self", ".", "val_test_data", "=", "{", "\n", "\"valid\"", ":", "self", ".", "read_json", "(", "self", ".", "data_path", "+", "\"valid.json\"", ")", ",", "\n", "\"test\"", ":", "self", ".", "read_json", "(", "self", ".", "data_path", "+", "\"test.json\"", ")", ",", "\n", "}", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "cons_masking", "=", "cons_masking", "\n", "self", ".", "mask_prob", "=", "mask_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.read_text": [[40, 48], ["numpy.zeros", "enumerate", "open", "f.readlines", "numpy.array", "len", "dataset.Dataset.triple2ids", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.triple2ids"], ["", "def", "read_text", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "triples", "=", "np", ".", "zeros", "(", "(", "len", "(", "lines", ")", ",", "3", ")", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "triples", "[", "i", "]", "=", "np", ".", "array", "(", "self", ".", "triple2ids", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", ")", ")", "\n", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.dataset_stat": [[49, 69], ["torch.zeros", "torch.zeros", "max", "dataset.Dataset.num_ent", "dataset.Dataset.num_rel", "t.astype.astype.astype", "adj_list[].append", "adj_list[].append", "map", "item.extend", "torch.tensor", "range", "dataset.Dataset.num_ent", "len", "dataset.Dataset.num_ent", "dataset.Dataset.num_rel"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_rel", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_rel"], ["", "def", "dataset_stat", "(", "self", ",", "triples", ")", ":", "\n", "        ", "adj_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_ent", "(", ")", ")", "]", "\n", "ent_freq", "=", "torch", ".", "zeros", "(", "self", ".", "num_ent", "(", ")", ")", "\n", "rel_freq", "=", "torch", ".", "zeros", "(", "self", ".", "num_rel", "(", ")", ")", "\n", "for", "t", "in", "triples", ":", "\n", "            ", "t", "=", "t", ".", "astype", "(", "int", ")", "\n", "adj_list", "[", "t", "[", "0", "]", "]", ".", "append", "(", "[", "t", "[", "2", "]", ",", "t", "[", "1", "]", ",", "0", "]", ")", "\n", "adj_list", "[", "t", "[", "2", "]", "]", ".", "append", "(", "[", "t", "[", "0", "]", ",", "t", "[", "1", "]", ",", "1", "]", ")", "\n", "ent_freq", "[", "t", "[", "0", "]", "]", "+=", "1", "\n", "ent_freq", "[", "t", "[", "2", "]", "]", "+=", "1", "\n", "rel_freq", "[", "t", "[", "1", "]", "]", "+=", "1", "\n", "", "max_degree", "=", "max", "(", "map", "(", "len", ",", "adj_list", ")", ")", "\n", "for", "item", "in", "adj_list", ":", "\n", "            ", "item", ".", "extend", "(", "\n", "[", "[", "self", ".", "num_ent", "(", ")", ",", "self", ".", "num_rel", "(", ")", ",", "0", "]", "]", "*", "(", "max_degree", "-", "len", "(", "item", ")", ")", "\n", ")", "\n", "", "return", "(", "\n", "torch", ".", "tensor", "(", "adj_list", ")", ",", "\n", "ent_freq", "/", "triples", ".", "shape", "[", "0", "]", ",", "\n", "rel_freq", "/", "triples", ".", "shape", "[", "0", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.read_json": [[71, 85], ["json.load.items", "open", "json.load", "triples.append", "dataset.Dataset.get_rel_id", "dataset.Dataset.get_ent_id", "dataset.Dataset.get_ent_id", "dataset.Dataset.get_rel_id"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_rel_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_rel_id"], ["", "def", "read_json", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ")", "as", "json_file", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "json_file", ")", "\n", "\n", "", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "triples", "=", "[", "]", "\n", "for", "t", "in", "v", ":", "\n", "                ", "if", "t", "[", "0", "]", "==", "k", ":", "\n", "                    ", "triples_ids", "=", "[", "t", "[", "0", "]", ",", "self", ".", "get_rel_id", "(", "t", "[", "1", "]", ")", ",", "self", ".", "get_ent_id", "(", "t", "[", "2", "]", ")", "]", "\n", "", "else", ":", "\n", "                    ", "triples_ids", "=", "[", "self", ".", "get_ent_id", "(", "t", "[", "0", "]", ")", ",", "self", ".", "get_rel_id", "(", "t", "[", "1", "]", ")", ",", "t", "[", "2", "]", "]", "\n", "", "triples", ".", "append", "(", "triples_ids", ")", "\n", "", "data", "[", "k", "]", "=", "triples", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.triple2ids": [[86, 91], ["dataset.Dataset.get_ent_id", "dataset.Dataset.get_rel_id", "dataset.Dataset.get_ent_id"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_rel_id", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id"], ["", "def", "triple2ids", "(", "self", ",", "triple", ")", ":", "\n", "        ", "return", "[", "\n", "self", ".", "get_ent_id", "(", "triple", "[", "0", "]", ")", ",", "\n", "self", ".", "get_rel_id", "(", "triple", "[", "1", "]", ")", ",", "\n", "self", ".", "get_ent_id", "(", "triple", "[", "2", "]", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_ent_id": [[93, 100], ["len"], "methods", ["None"], ["", "def", "get_ent_id", "(", "self", ",", "ent", ",", "add_ent", "=", "True", ")", ":", "\n", "        ", "if", "not", "ent", "in", "self", ".", "ent2id", ":", "\n", "            ", "if", "add_ent", ":", "\n", "                ", "self", ".", "ent2id", "[", "ent", "]", "=", "len", "(", "self", ".", "ent2id", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "init_num_ent", "\n", "", "", "return", "self", ".", "ent2id", "[", "ent", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.get_rel_id": [[101, 105], ["len"], "methods", ["None"], ["", "def", "get_rel_id", "(", "self", ",", "rel", ")", ":", "\n", "        ", "if", "not", "rel", "in", "self", ".", "rel2id", ":", "\n", "            ", "self", ".", "rel2id", "[", "rel", "]", "=", "len", "(", "self", ".", "rel2id", ")", "\n", "", "return", "self", ".", "rel2id", "[", "rel", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_ent": [[106, 108], ["len"], "methods", ["None"], ["", "def", "num_ent", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ent2id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_rel": [[109, 111], ["len"], "methods", ["None"], ["", "def", "num_rel", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "rel2id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.rand_ent_except": [[112, 117], ["random.randint", "random.randint"], "methods", ["None"], ["", "def", "rand_ent_except", "(", "self", ",", "ent", ")", ":", "\n", "        ", "rand_ent", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "init_num_ent", "-", "1", ")", "\n", "while", "rand_ent", "==", "ent", ":", "\n", "            ", "rand_ent", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "init_num_ent", "-", "1", ")", "\n", "", "return", "rand_ent", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.next_pos_batch": [[118, 127], ["numpy.append().astype", "len", "numpy.append", "numpy.ones", "len"], "methods", ["None"], ["", "def", "next_pos_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "batch_index", "+", "batch_size", "<", "len", "(", "self", ".", "train_data", ")", ":", "\n", "            ", "batch", "=", "self", ".", "train_data", "[", "self", ".", "batch_index", ":", "self", ".", "batch_index", "+", "batch_size", "]", "\n", "self", ".", "batch_index", "+=", "batch_size", "\n", "", "else", ":", "\n", "            ", "batch", "=", "self", ".", "train_data", "[", "self", ".", "batch_index", ":", "]", "\n", "self", ".", "batch_index", "=", "0", "\n", "", "return", "np", ".", "append", "(", "batch", ",", "np", ".", "ones", "(", "(", "len", "(", "batch", ")", ",", "1", ")", ")", ",", "axis", "=", "1", ")", ".", "astype", "(", "\n", "\"int\"", "\n", ")", "# appending the +1 label", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.generate_neg": [[129, 138], ["numpy.repeat", "range", "numpy.copy", "len", "random.random", "dataset.Dataset.rand_ent_except", "dataset.Dataset.rand_ent_except"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.rand_ent_except", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.rand_ent_except"], ["", "def", "generate_neg", "(", "self", ",", "pos_batch", ",", "neg_ratio", ")", ":", "\n", "        ", "neg_batch", "=", "np", ".", "repeat", "(", "np", ".", "copy", "(", "pos_batch", ")", ",", "neg_ratio", ",", "axis", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neg_batch", ")", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "neg_batch", "[", "i", "]", "[", "0", "]", "=", "self", ".", "rand_ent_except", "(", "neg_batch", "[", "i", "]", "[", "0", "]", ")", "# flipping head", "\n", "", "else", ":", "\n", "                ", "neg_batch", "[", "i", "]", "[", "2", "]", "=", "self", ".", "rand_ent_except", "(", "neg_batch", "[", "i", "]", "[", "2", "]", ")", "# flipping tail", "\n", "", "", "neg_batch", "[", ":", ",", "-", "1", "]", "=", "-", "1", "\n", "return", "neg_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.next_batch": [[139, 160], ["dataset.Dataset.next_pos_batch", "dataset.Dataset.generate_neg", "numpy.append", "torch.tensor", "utils.random_new_ent_mask", "numpy.repeat", "numpy.append", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "numpy.copy", "torch.tensor", "torch.tensor", "utils.random_new_ent_mask"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.next_pos_batch", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.generate_neg", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.random_new_ent_mask", "home.repos.pwc.inspect_result.migalkin_NodePiece.src.utils.random_new_ent_mask"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ",", "neg_ratio", ",", "device", ")", ":", "\n", "        ", "pos_batch", "=", "self", ".", "next_pos_batch", "(", "batch_size", ")", "\n", "neg_batch", "=", "self", ".", "generate_neg", "(", "pos_batch", ",", "neg_ratio", ")", "\n", "batch", "=", "np", ".", "append", "(", "pos_batch", ",", "neg_batch", ",", "axis", "=", "0", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "batch", "[", ":", ",", "3", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "triples", "=", "batch", "[", ":", ",", "0", ":", "3", "]", "\n", "\n", "if", "self", ".", "cons_masking", ":", "\n", "            ", "pos_new_ent_mask", "=", "random_new_ent_mask", "(", "pos_batch", "[", ":", ",", "0", ":", "3", "]", ",", "self", ".", "mask_prob", ")", "\n", "neg_new_ent_mask", "=", "np", ".", "repeat", "(", "np", ".", "copy", "(", "pos_new_ent_mask", ")", ",", "neg_ratio", ",", "axis", "=", "0", ")", "\n", "new_ent_mask", "=", "np", ".", "append", "(", "pos_new_ent_mask", ",", "neg_new_ent_mask", ",", "axis", "=", "0", ")", "\n", "new_ent_mask", "=", "torch", ".", "tensor", "(", "new_ent_mask", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "new_ent_mask", "=", "torch", ".", "tensor", "(", "\n", "random_new_ent_mask", "(", "triples", ",", "self", ".", "mask_prob", ")", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "return", "(", "\n", "torch", ".", "tensor", "(", "triples", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", ",", "\n", "labels", ",", "\n", "new_ent_mask", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.was_last_batch": [[162, 164], ["None"], "methods", ["None"], ["", "def", "was_last_batch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_index", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_batch": [[165, 167], ["int", "math.ceil", "float", "len"], "methods", ["None"], ["", "def", "num_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "self", ".", "train_data", ")", ")", "/", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.num_batch_simulated": [[168, 170], ["int", "math.ceil", "float", "len"], "methods", ["None"], ["", "def", "num_batch_simulated", "(", "self", ",", "simulate_batch_size", ")", ":", "\n", "        ", "return", "int", "(", "math", ".", "ceil", "(", "float", "(", "len", "(", "self", ".", "train_data", ")", ")", "/", "simulate_batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.generate_neg_obs": [[171, 181], ["numpy.repeat", "range", "numpy.copy", "len", "dataset.Dataset.rand_ent_except", "dataset.Dataset.rand_ent_except"], "methods", ["home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.rand_ent_except", "home.repos.pwc.inspect_result.migalkin_NodePiece.common.dataset.Dataset.rand_ent_except"], ["", "def", "generate_neg_obs", "(", "self", ",", "obs_triples", ",", "new_ent", ",", "neg_ratio", ")", ":", "\n", "        ", "neg_triples", "=", "np", ".", "repeat", "(", "np", ".", "copy", "(", "obs_triples", ")", ",", "neg_ratio", ",", "axis", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neg_triples", ")", ")", ":", "\n", "            ", "if", "neg_triples", "[", "i", ",", "0", "]", "==", "new_ent", ":", "\n", "# new entity is in head -> flip tail", "\n", "                ", "neg_triples", "[", "i", ",", "2", "]", "=", "self", ".", "rand_ent_except", "(", "neg_triples", "[", "i", ",", "2", "]", ")", "\n", "", "else", ":", "\n", "# new entity is in tail -> flip head", "\n", "                ", "neg_triples", "[", "i", ",", "0", "]", "=", "self", ".", "rand_ent_except", "(", "neg_triples", "[", "i", ",", "0", "]", ")", "\n", "", "", "return", "neg_triples", "\n", "", "", ""]]}