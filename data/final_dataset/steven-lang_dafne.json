{"home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.build_optimizer_custom": [[77, 129], ["set", "model.modules", "module.named_parameters", "torch.optim.SGD", "memo.add", "isinstance", "torch.optim.Adam", "RuntimeError"], "function", ["None"], ["def", "build_optimizer_custom", "(", "cfg", ":", "CfgNode", ",", "model", ":", "torch", ".", "nn", ".", "Module", ")", "->", "torch", ".", "optim", ".", "Optimizer", ":", "\n", "    ", "\"\"\"\n    Build an optimizer from config.\n    \"\"\"", "\n", "norm_module_types", "=", "(", "\n", "torch", ".", "nn", ".", "BatchNorm1d", ",", "\n", "torch", ".", "nn", ".", "BatchNorm2d", ",", "\n", "torch", ".", "nn", ".", "BatchNorm3d", ",", "\n", "torch", ".", "nn", ".", "SyncBatchNorm", ",", "\n", "# NaiveSyncBatchNorm inherits from BatchNorm2d", "\n", "torch", ".", "nn", ".", "GroupNorm", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm1d", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm2d", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm3d", ",", "\n", "torch", ".", "nn", ".", "LayerNorm", ",", "\n", "torch", ".", "nn", ".", "LocalResponseNorm", ",", "\n", ")", "\n", "params", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "[", "]", "\n", "memo", ":", "Set", "[", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "]", "=", "set", "(", ")", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "module", ".", "named_parameters", "(", "recurse", "=", "False", ")", ":", "\n", "            ", "if", "not", "value", ".", "requires_grad", ":", "\n", "                ", "continue", "\n", "# Avoid duplicating parameters", "\n", "", "if", "value", "in", "memo", ":", "\n", "                ", "continue", "\n", "", "memo", ".", "add", "(", "value", ")", "\n", "lr", "=", "cfg", ".", "SOLVER", ".", "BASE_LR", "\n", "weight_decay", "=", "cfg", ".", "SOLVER", ".", "WEIGHT_DECAY", "\n", "if", "isinstance", "(", "module", ",", "norm_module_types", ")", ":", "\n", "                ", "weight_decay", "=", "cfg", ".", "SOLVER", ".", "WEIGHT_DECAY_NORM", "\n", "", "elif", "key", "==", "\"bias\"", ":", "\n", "# NOTE: unlike Detectron v1, we now default BIAS_LR_FACTOR to 1.0", "\n", "# and WEIGHT_DECAY_BIAS to WEIGHT_DECAY so that bias optimizer", "\n", "# hyperparameters are by default exactly the same as for regular", "\n", "# weights.", "\n", "                ", "lr", "=", "cfg", ".", "SOLVER", ".", "BASE_LR", "*", "cfg", ".", "SOLVER", ".", "BIAS_LR_FACTOR", "\n", "weight_decay", "=", "cfg", ".", "SOLVER", ".", "WEIGHT_DECAY_BIAS", "\n", "", "params", "+=", "[", "{", "\"params\"", ":", "[", "value", "]", ",", "\"lr\"", ":", "lr", ",", "\"weight_decay\"", ":", "weight_decay", "}", "]", "\n", "\n", "", "", "if", "cfg", ".", "SOLVER", ".", "OPTIMIZER", "==", "\"sgd\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "params", ",", "\n", "cfg", ".", "SOLVER", ".", "BASE_LR", ",", "\n", "momentum", "=", "cfg", ".", "SOLVER", ".", "MOMENTUM", ",", "\n", "nesterov", "=", "cfg", ".", "SOLVER", ".", "NESTEROV", ",", "\n", ")", "\n", "", "elif", "cfg", ".", "SOLVER", ".", "OPTIMIZER", "==", "\"adam\"", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "cfg", ".", "SOLVER", ".", "BASE_LR", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Invalid optimizer selection ({cfg.SOLVER.OPTIMIZER})\"", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.detect_anomaly": [[131, 136], ["torch.isfinite().all", "breakpoint", "FloatingPointError", "torch.isfinite"], "function", ["None"], ["", "def", "detect_anomaly", "(", "losses", ",", "loss_dict", ",", "iter", ")", ":", "\n", "    ", "if", "not", "torch", ".", "isfinite", "(", "losses", ")", ".", "all", "(", ")", ":", "\n", "        ", "breakpoint", "(", ")", "\n", "raise", "FloatingPointError", "(", "\n", "\"Loss became infinite or NaN at iteration={}!\\nloss_dict = {}\"", ".", "format", "(", "iter", ",", "loss_dict", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.write_metrics": [[139, 169], ["detectron2.gather", "detectron2.is_main_process", "sum", "storage.put_scalar", "isinstance", "v.detach().cpu().item", "float", "metrics_dict.items", "numpy.max", "storage.put_scalar", "numpy.mean", "len", "storage.put_scalars", "all_metrics_dict[].keys", "v.detach().cpu", "x.pop", "metrics_dict.values", "v.detach"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop"], ["", "", "def", "write_metrics", "(", "storage", ",", "metrics_dict", ":", "dict", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        metrics_dict (dict): dict of scalar metrics\n    \"\"\"", "\n", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "metrics_dict", ".", "items", "(", ")", "\n", "}", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "if", "\"data_time\"", "in", "all_metrics_dict", "[", "0", "]", ":", "\n", "# data_time among workers can have high variance. The actual latency", "\n", "# caused by data_time is the maximum among workers.", "\n", "            ", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "# average the rest metrics", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "metrics_dict", ".", "values", "(", ")", ")", "\n", "\n", "storage", ".", "put_scalar", "(", "\"loss/total_loss\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "            ", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.get_evaluator": [[171, 217], ["evaluator_list.append", "detectron2.evaluation.DatasetEvaluators", "os.path.join", "dataset_name.lower", "dafne.evaluation.dota_evaluation.DotaEvaluator", "dataset_name.lower", "dafne.evaluation.hrsc_evaluation.HrscEvaluator", "dataset_name.lower", "dafne.evaluation.icdar15_evaluation.Icdar15Evaluator", "dataset_name.lower", "dafne.evaluation.ucas_aod_evaluation.UcasAodEvaluator", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "", "def", "get_evaluator", "(", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Create evaluator(s) for a given dataset.\n    This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n    For your own dataset, you can simply create an evaluator manually in your\n    script and do not have to worry about the hacky if-else logic here.\n    \"\"\"", "\n", "if", "output_folder", "is", "None", ":", "\n", "        ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "", "evaluator_list", "=", "[", "]", "\n", "\n", "# Construct the DOTA evaluator object", "\n", "if", "\"dota\"", "in", "dataset_name", ".", "lower", "(", ")", ":", "\n", "        ", "evaluator", "=", "DotaEvaluator", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", "", "elif", "\"hrsc\"", "in", "dataset_name", ".", "lower", "(", ")", ":", "\n", "        ", "evaluator", "=", "HrscEvaluator", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", "", "elif", "\"icdar\"", "in", "dataset_name", ".", "lower", "(", ")", ":", "\n", "        ", "evaluator", "=", "Icdar15Evaluator", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", "", "elif", "\"ucas\"", "in", "dataset_name", ".", "lower", "(", ")", ":", "\n", "        ", "evaluator", "=", "UcasAodEvaluator", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "evaluator_list", ".", "append", "(", "evaluator", ")", "\n", "return", "DatasetEvaluators", "(", "evaluator_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.build_train_loader": [[219, 278], ["dafne.data.datasets.dafne_dataset_mapper.DAFNeDatasetMapper", "detectron2.data.build_detection_train_loader", "detectron2.data.transforms.RandomFlip", "detectron2.data.transforms.RandomFlip", "augmentations.append", "len", "augmentations.append", "augmentations.extend", "detectron2.data.transforms.ResizeShortestEdge", "augmentations.append", "RuntimeError", "detectron2.data.transforms.RandomRotation", "detectron2.data.transforms.Resize", "detectron2.data.transforms.RandomLighting", "detectron2.data.transforms.RandomBrightness", "detectron2.data.transforms.RandomContrast", "detectron2.data.transforms.RandomSaturation"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "build_train_loader", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        iterable\n\n    It now calls :func:`detectron2.data.build_detection_train_loader`.\n    Overwrite it if you'd like a different data loader.\n    \"\"\"", "\n", "\n", "# Start list with default augmentations", "\n", "augmentations", "=", "[", "\n", "T", ".", "RandomFlip", "(", "prob", "=", "0.5", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", ",", "# HFLIP", "\n", "T", ".", "RandomFlip", "(", "prob", "=", "0.5", ",", "horizontal", "=", "False", ",", "vertical", "=", "True", ")", ",", "# VFLIP", "\n", "# T.RandomCrop(crop_type=\"relative_range\", crop_size=(0.66, 0.66))", "\n", "]", "\n", "\n", "# Choose between shortest-edge and rescale resizing", "\n", "if", "cfg", ".", "INPUT", ".", "RESIZE_TYPE", "==", "\"shortest-edge\"", ":", "\n", "# Build resize augmentation", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TRAIN", "\n", "sample_style", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN_SAMPLING", "\n", "augmentations", ".", "append", "(", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", ")", "\n", "", "elif", "cfg", ".", "INPUT", ".", "RESIZE_TYPE", "==", "\"both\"", ":", "\n", "        ", "h", "=", "cfg", ".", "INPUT", ".", "RESIZE_HEIGHT_TRAIN", "\n", "w", "=", "cfg", ".", "INPUT", ".", "RESIZE_WIDTH_TRAIN", "\n", "augmentations", ".", "append", "(", "T", ".", "Resize", "(", "shape", "=", "(", "h", ",", "w", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Invalid resize-type: {cfg.INPUT.RESIZE_TYPE}\"", ")", "\n", "\n", "# Use Rotations augmentation if aug_angles is given", "\n", "", "if", "len", "(", "cfg", ".", "INPUT", ".", "ROTATION_AUG_ANGLES", ")", ">", "0", ":", "\n", "        ", "augmentations", ".", "append", "(", "\n", "T", ".", "RandomRotation", "(", "\n", "sample_style", "=", "cfg", ".", "INPUT", ".", "ROTATION_AUG_SAMPLE_STYLE", ",", "\n", "angle", "=", "cfg", ".", "INPUT", ".", "ROTATION_AUG_ANGLES", ",", "\n", ")", "\n", ")", "\n", "\n", "# Add color augmentations ifenabled", "\n", "", "if", "cfg", ".", "INPUT", ".", "USE_COLOR_AUGMENTATIONS", ":", "\n", "        ", "augmentations", ".", "extend", "(", "\n", "[", "\n", "T", ".", "RandomLighting", "(", "scale", "=", "1.0", ")", ",", "\n", "T", ".", "RandomBrightness", "(", "intensity_min", "=", "0.5", ",", "intensity_max", "=", "1.5", ")", ",", "\n", "T", ".", "RandomContrast", "(", "intensity_min", "=", "0.5", ",", "intensity_max", "=", "1.5", ")", ",", "\n", "T", ".", "RandomSaturation", "(", "intensity_min", "=", "0.5", ",", "intensity_max", "=", "1.5", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "# Create datasetmapper", "\n", "", "mapper", "=", "DAFNeDatasetMapper", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "use_instance_mask", "=", "True", ",", "\n", "augmentations", "=", "augmentations", ",", "\n", ")", "\n", "\n", "return", "build_detection_train_loader", "(", "cfg", ",", "mapper", "=", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.build_test_loader": [[280, 314], ["dafne.data.datasets.dafne_dataset_mapper.DAFNeDatasetMapper", "detectron2.data.build_detection_test_loader", "augmentations.append", "detectron2.data.transforms.ResizeShortestEdge", "augmentations.append", "RuntimeError", "detectron2.data.transforms.Resize"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "build_test_loader", "(", "cfg", ",", "dataset_name", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        iterable\n\n    It now calls :func:`detectron2.data.build_detection_test_loader`.\n    Overwrite it if you'd like a different data loader.\n    \"\"\"", "\n", "\n", "# Collect augmentations", "\n", "augmentations", "=", "[", "]", "\n", "\n", "# Choose between shortest-edge and rescale resizing", "\n", "if", "cfg", ".", "INPUT", ".", "RESIZE_TYPE", "==", "\"shortest-edge\"", ":", "\n", "# Build resize augmentation", "\n", "        ", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", "sample_style", "=", "\"choice\"", "\n", "augmentations", ".", "append", "(", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", ")", "\n", "", "elif", "cfg", ".", "INPUT", ".", "RESIZE_TYPE", "==", "\"both\"", ":", "\n", "        ", "h", "=", "cfg", ".", "INPUT", ".", "RESIZE_HEIGHT_TRAIN", "\n", "w", "=", "cfg", ".", "INPUT", ".", "RESIZE_WIDTH_TRAIN", "\n", "augmentations", ".", "append", "(", "T", ".", "Resize", "(", "shape", "=", "(", "h", ",", "w", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Invalid resize-type: {cfg.INPUT.RESIZE_TYPE}\"", ")", "\n", "\n", "", "mapper", "=", "DAFNeDatasetMapper", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "# TODO: Shouldn't this be False?", "\n", "use_instance_mask", "=", "True", ",", "\n", "augmentations", "=", "augmentations", ",", "\n", ")", "\n", "\n", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ",", "mapper", "=", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test": [[316, 337], ["collections.OrderedDict", "setproctitle.setproctitle", "logger.info", "plain_train_net.build_test_loader", "detectron2.evaluation.inference_on_dataset", "logger.info", "logger.info", "plain_train_net.get_evaluator", "os.path.join", "pprint.pformat"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_test_loader", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.get_evaluator"], ["", "def", "do_test", "(", "cfg", ",", "model", ",", "evaluators", ":", "Dict", "=", "None", ")", ":", "\n", "    ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "dataset_name", "in", "cfg", ".", "DATASETS", ".", "TEST", ":", "\n", "        ", "exp_name", "=", "cfg", ".", "EXPERIMENT_NAME", "\n", "setproctitle", "(", "f\"@SL_{exp_name}|eval:{dataset_name}\"", ")", "\n", "logger", ".", "info", "(", "f'Starting testing on dataset \"{dataset_name}\"'", ")", "\n", "data_loader", "=", "build_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "if", "evaluators", "is", "None", ":", "\n", "            ", "evaluator", "=", "get_evaluator", "(", "\n", "cfg", ",", "\n", "dataset_name", ",", "\n", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "evaluator", "=", "evaluators", "[", "dataset_name", "]", "\n", "", "results_i", "=", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", "\n", "results", "[", "dataset_name", "]", "=", "results_i", "\n", "logger", ".", "info", "(", "f\"Evaluation results for dataset {dataset_name}\"", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "pformat", "(", "results_i", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test_with_TTA": [[339, 358], ["logging.getLogger", "logging.getLogger.info", "dafne.modeling.tta.OneStageRCNNWithTTA", "plain_train_net.do_test", "collections.OrderedDict", "plain_train_net.get_evaluator", "os.path.join", "collections.OrderedDict.items"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.get_evaluator"], ["", "def", "do_test_with_TTA", "(", "cfg", ",", "model", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "\"dafne.trainer\"", ")", "\n", "# In the end of training, run an evaluation with TTA", "\n", "# Only support some R-CNN models.", "\n", "logger", ".", "info", "(", "\"Running inference with test-time augmentation ...\"", ")", "\n", "model", "=", "OneStageRCNNWithTTA", "(", "cfg", ",", "model", ")", "\n", "\n", "evaluators", "=", "{", "\n", "name", ":", "get_evaluator", "(", "\n", "cfg", ",", "\n", "name", ",", "\n", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference_TTA\"", ",", "name", ")", ",", "\n", ")", "\n", "for", "name", "in", "cfg", ".", "DATASETS", ".", "TEST", "\n", "}", "\n", "res", "=", "do_test", "(", "cfg", ",", "model", ",", "evaluators", ")", "\n", "res", "=", "OrderedDict", "(", "{", "k", "+", "\"_TTA\"", ":", "v", "for", "k", ",", "v", "in", "res", ".", "items", "(", ")", "}", ")", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.save_test_results": [[360, 375], ["detectron2.is_main_process", "results.items", "os.path.join", "pathlib.Path().mkdir", "os.path.join", "open", "f.write", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["", "def", "save_test_results", "(", "results", ",", "cfg", ",", "iteration", ")", ":", "\n", "    ", "\"\"\"Evaluate the model at a specific iteration and save mAP results.\"\"\"", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "for", "dataset_name", ",", "dataset_result", "in", "results", ".", "items", "(", ")", ":", "\n", "\n", "            ", "if", "not", "\"task1\"", "in", "dataset_result", ":", "\n", "                ", "continue", "\n", "\n", "", "task_1_results", "=", "dataset_result", "[", "\"task1\"", "]", "\n", "d", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"map_evaluations\"", ")", "\n", "Path", "(", "d", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "d", ",", "dataset_name", "+", "\".csv\"", ")", "\n", "with", "open", "(", "fname", ",", "\"a\"", ")", "as", "f", ":", "\n", "                ", "map_value", "=", "task_1_results", "[", "\"map\"", "]", "\n", "f", ".", "write", "(", "f\"{iteration},{map_value}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.setup_rtpt": [[377, 388], ["dafne.utils.rtpt.RTPT", "dafne.utils.rtpt.RTPT.start"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.start"], ["", "", "", "", "def", "setup_rtpt", "(", "experiment_name", ",", "max_iter", ",", "start_iter", ")", ":", "\n", "    ", "rtpt", "=", "RTPT", "(", "\n", "name_initials", "=", "\"SL\"", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "max_iterations", "=", "max_iter", ",", "\n", "iteration_start", "=", "start_iter", ",", "\n", "update_interval", "=", "50", ",", "\n", "moving_avg_window_size", "=", "50", ",", "\n", ")", "\n", "rtpt", ".", "start", "(", ")", "\n", "return", "rtpt", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_train": [[390, 493], ["model.train", "plain_train_net.build_optimizer_custom", "detectron2.solver.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.PeriodicCheckpointer", "plain_train_net.setup_rtpt", "plain_train_net.build_train_loader", "logger.info", "detectron2.checkpoint.DetectionCheckpointer.resume_or_load().get", "detectron2.is_main_process", "detectron2.utils.events.EventStorage", "time.perf_counter", "zip", "detectron2.utils.events.CommonMetricPrinter", "detectron2.utils.events.JSONWriter", "detectron2.utils.events.TensorboardXWriter", "range", "storage.step", "model", "sum", "build_optimizer_custom.zero_grad", "sum.backward", "build_optimizer_custom.step", "storage.put_scalar", "detectron2.solver.build_lr_scheduler.step", "detectron2.checkpoint.PeriodicCheckpointer.step", "time.perf_counter", "setup_rtpt.step", "detectron2.checkpoint.DetectionCheckpointer.resume_or_load", "os.path.join", "time.perf_counter", "model.values", "plain_train_net.write_metrics", "plain_train_net.detect_anomaly", "plain_train_net.do_test", "plain_train_net.save_test_results", "torch.cuda.stream", "contextlib.nullcontext", "writer.write", "torch.cuda.Stream"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.build_optimizer_custom", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.setup_rtpt", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_train_loader", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step", "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.write_metrics", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.detect_anomaly", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.save_test_results"], ["", "def", "do_train", "(", "cfg", ",", "model", ",", "resume", "=", "False", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "build_optimizer_custom", "(", "cfg", ",", "model", ")", "\n", "scheduler", "=", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "checkpointer", "=", "DetectionCheckpointer", "(", "\n", "model", ",", "cfg", ".", "OUTPUT_DIR", ",", "optimizer", "=", "optimizer", ",", "scheduler", "=", "scheduler", "\n", ")", "\n", "\n", "resume_iter", "=", "(", "\n", "checkpointer", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "resume", ")", ".", "get", "(", "\"iteration\"", ",", "-", "1", ")", "+", "1", "\n", ")", "\n", "\n", "if", "resume", ":", "\n", "        ", "start_iter", "=", "resume_iter", "\n", "", "else", ":", "\n", "        ", "start_iter", "=", "0", "\n", "\n", "", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "\n", "periodic_checkpointer", "=", "PeriodicCheckpointer", "(", "\n", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", ",", "max_iter", "=", "max_iter", "\n", ")", "\n", "\n", "writers", "=", "(", "\n", "[", "\n", "CommonMetricPrinter", "(", "max_iter", ")", ",", "\n", "JSONWriter", "(", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"metrics.json\"", ")", ")", ",", "\n", "TensorboardXWriter", "(", "cfg", ".", "OUTPUT_DIR", ")", ",", "\n", "]", "\n", "if", "comm", ".", "is_main_process", "(", ")", "\n", "else", "[", "]", "\n", ")", "\n", "\n", "# Setup process name updater", "\n", "rtpt", "=", "setup_rtpt", "(", "\n", "experiment_name", "=", "cfg", ".", "EXPERIMENT_NAME", ",", "\n", "max_iter", "=", "max_iter", ",", "\n", "start_iter", "=", "start_iter", ",", "\n", ")", "\n", "\n", "# compared to \"train_net.py\", we do not support accurate timing and", "\n", "# precise BN here, because they are not trivial to implement in a small training loop", "\n", "data_loader_train", "=", "build_train_loader", "(", "cfg", ")", "\n", "\n", "# Create a config clone where the test dataset is the first original test set but as \"mini\" version", "\n", "# This set is used to evaluate the performance during the training", "\n", "# cfg_mini_test = cfg.clone()", "\n", "# cfg_mini_test.defrost()", "\n", "# cfg_mini_test.DATASETS.TEST = (cfg.DATASETS.TEST[0] + \"_mini\",)", "\n", "# cfg_mini_test.freeze()", "\n", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "storage", ":", "\n", "        ", "data_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "for", "data", ",", "iteration", "in", "zip", "(", "data_loader_train", ",", "range", "(", "start_iter", ",", "max_iter", ")", ")", ":", "\n", "            ", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "data_time", "\n", "iteration", "=", "iteration", "+", "1", "\n", "storage", ".", "step", "(", ")", "\n", "\n", "loss_dict", "=", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Backward pass", "\n", "losses", ".", "backward", "(", ")", "\n", "\n", "# use a new stream so the ops don't wait for DDP", "\n", "with", "torch", ".", "cuda", ".", "stream", "(", "\n", "torch", ".", "cuda", ".", "Stream", "(", ")", "\n", ")", "if", "losses", ".", "device", ".", "type", "==", "\"cuda\"", "else", "contextlib", ".", "nullcontext", "(", ")", ":", "\n", "                ", "metrics_dict", "=", "loss_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "write_metrics", "(", "storage", ",", "metrics_dict", ")", "\n", "detect_anomaly", "(", "losses", ",", "loss_dict", ",", "iteration", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "storage", ".", "put_scalar", "(", "\"lr\"", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "smoothing_hint", "=", "False", ")", "\n", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "if", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ">", "0", "\n", "and", "iteration", "%", "cfg", ".", "TEST", ".", "EVAL_PERIOD", "==", "0", "\n", "and", "iteration", "!=", "max_iter", "\n", ")", ":", "\n", "                ", "results", "=", "do_test", "(", "cfg", ",", "model", ")", "\n", "save_test_results", "(", "results", "=", "results", ",", "cfg", "=", "cfg", ",", "iteration", "=", "iteration", ")", "\n", "\n", "", "if", "iteration", "-", "start_iter", ">", "5", "and", "(", "iteration", "%", "20", "==", "0", "or", "iteration", "==", "max_iter", ")", ":", "\n", "                ", "for", "writer", "in", "writers", ":", "\n", "                    ", "writer", ".", "write", "(", ")", "\n", "", "", "periodic_checkpointer", ".", "step", "(", "iteration", ")", "\n", "\n", "# Reset data time", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "# Update process title", "\n", "progress", "=", "iteration", "/", "max_iter", "*", "100", "\n", "rtpt", ".", "step", "(", "subtitle", "=", "f\"[{progress:0>2.0f}%]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.is_debug_session": [[495, 505], ["cfg.OUTPUT_DIR.lower"], "function", ["None"], ["", "", "", "def", "is_debug_session", "(", "cfg", ")", "->", "bool", ":", "\n", "    ", "\"\"\"TODO: move to utils\"\"\"", "\n", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "        ", "return", "True", "\n", "", "if", "\"debug\"", "in", "cfg", ".", "OUTPUT_DIR", ".", "lower", "(", ")", ":", "\n", "        ", "return", "True", "\n", "", "if", "cfg", ".", "SOLVER", ".", "MAX_ITER", "<", "10000", ":", "\n", "        ", "return", "True", "\n", "# TODO: Add more cases where debugging is enabled", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.backup_config_file": [[507, 512], ["detectron2.is_main_process", "os.path.join", "os.path.join", "shutil.copy2"], "function", ["None"], ["", "def", "backup_config_file", "(", "cfg", ")", ":", "\n", "    ", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config.yaml\"", ")", "\n", "path_backup", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config_orig.yaml\"", ")", "\n", "shutil", ".", "copy2", "(", "path", ",", "path_backup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.restore_config_file": [[514, 519], ["detectron2.is_main_process", "os.path.join", "os.path.join", "shutil.move"], "function", ["None"], ["", "", "def", "restore_config_file", "(", "cfg", ")", ":", "\n", "    ", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config.yaml\"", ")", "\n", "path_backup", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config_orig.yaml\"", ")", "\n", "shutil", ".", "move", "(", "path_backup", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.setup": [[521, 545], ["dafne.config.get_cfg", "dafne.config.get_cfg.merge_from_file", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze", "detectron2.engine.default_setup", "detectron2.utils.logger.setup_logger", "plain_train_net.backup_config_file", "plain_train_net.restore_config_file", "detectron2.get_rank"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.backup_config_file", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.restore_config_file"], ["", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Create configs and perform basic setups.\n    \"\"\"", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "\n", "# Even in eval_only mode, `default_setup` will overwrite the original config.yaml in the output_dir.", "\n", "# Therefore, it is necessary to back it up such that an evaluation does not change the original", "\n", "# saved config file.", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "backup_config_file", "(", "cfg", ")", "\n", "\n", "", "default_setup", "(", "cfg", ",", "args", ")", "\n", "\n", "# Restore the original config file", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "restore_config_file", "(", "cfg", ")", "\n", "\n", "# Setup logger for \"dafne\" module", "\n", "", "setup_logger", "(", "output", "=", "cfg", ".", "OUTPUT_DIR", ",", "distributed_rank", "=", "comm", ".", "get_rank", "(", ")", ",", "name", "=", "\"dafne\"", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.custom_auto_scale_workers": [[547, 558], ["cfg.clone.clone", "cfg.clone.is_frozen", "cfg.clone.defrost", "cfg.clone.freeze"], "function", ["None"], ["", "def", "custom_auto_scale_workers", "(", "cfg", ",", "num_workers", ")", ":", "\n", "    ", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "frozen", "=", "cfg", ".", "is_frozen", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "old_world_size", "=", "cfg", ".", "SOLVER", ".", "REFERENCE_WORLD_SIZE", "\n", "scale", "=", "num_workers", "/", "old_world_size", "\n", "\n", "if", "frozen", ":", "\n", "        ", "cfg", ".", "freeze", "(", ")", "\n", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.main": [[560, 658], ["plain_train_net.setup", "detectron2.engine.DefaultTrainer.auto_scale_workers", "logging.getLogger", "dafne.data.datasets.dota.register_dota", "dafne.data.datasets.hrsc2016.register_hrsc", "dafne.data.datasets.ucas_aod.register_ucas_aod", "dafne.data.datasets.icdar15.register_icdar15", "detectron2.modeling.build_model", "logging.getLogger.info", "detectron2.get_world_size", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "plain_train_net.do_test", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "plain_train_net.do_train", "plain_train_net.do_test", "plain_train_net.save_test_results", "detectron2.utils.comm.synchronize", "plain_train_net.do_test_with_TTA", "do_test.update", "plain_train_net.do_test_with_TTA", "do_test.update", "plain_train_net.is_debug_session", "dafne.utils.mail.send_mail_success", "logging.getLogger.error", "detectron2.is_main_process", "detectron2.checkpoint.DetectionCheckpointer", "traceback.extract_tb().format", "detectron2.get_local_rank", "open", "f.write", "traceback.extract_tb", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup", "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.register_dota", "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.register_hrsc", "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.register_ucas_aod", "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.register_icdar15", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_train", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.save_test_results", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test_with_TTA", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.plain_train_net.do_test_with_TTA", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.is_debug_session", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.send_mail_success"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "# Scale config according to number of GPUs", "\n", "cfg", "=", "DefaultTrainer", ".", "auto_scale_workers", "(", "cfg", ",", "comm", ".", "get_world_size", "(", ")", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "# Register the datasets", "\n", "register_dota", "(", "cfg", ")", "\n", "register_hrsc", "(", "cfg", ")", "\n", "register_ucas_aod", "(", "cfg", ")", "\n", "register_icdar15", "(", "cfg", ")", "\n", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "\n", "results", "=", "do_test", "(", "cfg", ",", "model", ")", "\n", "# results = {}", "\n", "\n", "# Run testing with test-time-augmentation", "\n", "if", "cfg", ".", "TEST", ".", "AUG", ".", "ENABLED", ":", "\n", "            ", "results_tta", "=", "do_test_with_TTA", "(", "cfg", ",", "model", ")", "\n", "results", ".", "update", "(", "results_tta", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "distributed", "=", "comm", ".", "get_world_size", "(", ")", ">", "1", "\n", "if", "distributed", ":", "\n", "        ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ",", "\n", ")", "\n", "\n", "", "try", ":", "\n", "# Start training + testing", "\n", "        ", "do_train", "(", "cfg", ",", "model", ",", "resume", "=", "args", ".", "resume", ")", "\n", "\n", "results", "=", "do_test", "(", "cfg", ",", "model", ")", "\n", "save_test_results", "(", "results", ",", "cfg", ",", "iteration", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", ")", "\n", "\n", "if", "cfg", ".", "TEST", ".", "AUG", ".", "ENABLED", ":", "\n", "            ", "results_tta", "=", "do_test_with_TTA", "(", "cfg", ",", "model", ")", "\n", "results", ".", "update", "(", "results_tta", ")", "\n", "\n", "", "if", "not", "is_debug_session", "(", "cfg", ")", ":", "\n", "            ", "send_mail_success", "(", "cfg", ",", "results", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "except", "KeyboardInterrupt", ":", "# Catch keyboard interruptions", "\n", "        ", "pass", "\n", "\n", "# # Rename output dir", "\n", "# src = cfg.OUTPUT_DIR", "\n", "# dst = src + \"_interrupted\"", "\n", "\n", "# logger.error(f\"Keyboard interruption catched.\")", "\n", "# logger.error(f\"Moving output directory from\")", "\n", "# logger.error(src)", "\n", "# logger.error(\"to\")", "\n", "# logger.error(dst)", "\n", "\n", "# if comm.is_main_process():", "\n", "#     shutil.move(src, dst)", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# Log error message", "\n", "        ", "tbstr", "=", "\"\"", ".", "join", "(", "traceback", ".", "extract_tb", "(", "e", ".", "__traceback__", ")", ".", "format", "(", ")", ")", "\n", "errormsg", "=", "f\"Traceback:\\n{tbstr}\\nError: {e}\"", "\n", "\n", "logger", ".", "error", "(", "errormsg", ")", "\n", "\n", "# Rename output dir", "\n", "src", "=", "cfg", ".", "OUTPUT_DIR", "\n", "# dst = src + \"_error\"", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "# send_mail_error(cfg, args, errormsg)", "\n", "\n", "# Write error to separate file", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"error.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "errormsg", ")", "\n", "\n", "#     shutil.move(src, dst)", "\n", "\n", "# logger.error(\"Moving output directory from\")", "\n", "# logger.error(src)", "\n", "# logger.error(\"to\")", "\n", "# logger.error(dst)", "\n", "", "", "raise", "e", "\n", "", "finally", ":", "\n", "        ", "synchronize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.benchmark.setup": [[34, 42], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.utils.logger.setup_logger", "detectron2.utils.comm.get_rank"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "SOLVER", ".", "BASE_LR", "=", "0.001", "# Avoid NaNs. Not useful in this script anyway.", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "setup_logger", "(", "distributed_rank", "=", "comm", ".", "get_rank", "(", ")", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.benchmark.benchmark_data": [[44, 83], ["benchmark.setup", "fvcore.common.timer.Timer", "detectron2.data.build_detection_train_loader", "logger.info", "fvcore.common.timer.Timer.reset", "iter", "range", "fvcore.common.timer.Timer", "tqdm.trange", "logger.info", "logger.info", "psutil.virtual_memory", "logger.info", "range", "next", "next", "fvcore.common.timer.Timer", "tqdm.trange", "logger.info", "fvcore.common.timer.Timer.seconds", "fvcore.common.timer.Timer.seconds", "fvcore.common.timer.Timer.seconds", "next", "fvcore.common.timer.Timer.seconds"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.reset", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.next", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.next", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.next"], ["", "def", "benchmark_data", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "dataloader", "=", "build_detection_train_loader", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Initialize loader using {} seconds.\"", ".", "format", "(", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "timer", ".", "reset", "(", ")", "\n", "itr", "=", "iter", "(", "dataloader", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "# warmup", "\n", "        ", "next", "(", "itr", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "startup_time", "=", "timer", ".", "seconds", "(", ")", "\n", "", "", "timer", "=", "Timer", "(", ")", "\n", "max_iter", "=", "1000", "\n", "for", "_", "in", "tqdm", ".", "trange", "(", "max_iter", ")", ":", "\n", "        ", "next", "(", "itr", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"{} iters ({} images) in {} seconds.\"", ".", "format", "(", "\n", "max_iter", ",", "max_iter", "*", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "timer", ".", "seconds", "(", ")", "\n", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Startup time: {} seconds\"", ".", "format", "(", "startup_time", ")", ")", "\n", "vram", "=", "psutil", ".", "virtual_memory", "(", ")", "\n", "logger", ".", "info", "(", "\n", "\"RAM Usage: {:.2f}/{:.2f} GB\"", ".", "format", "(", "\n", "(", "vram", ".", "total", "-", "vram", ".", "available", ")", "/", "1024", "**", "3", ",", "vram", ".", "total", "/", "1024", "**", "3", "\n", ")", "\n", ")", "\n", "\n", "# test for a few more rounds", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "        ", "timer", "=", "Timer", "(", ")", "\n", "max_iter", "=", "1000", "\n", "for", "_", "in", "tqdm", ".", "trange", "(", "max_iter", ")", ":", "\n", "            ", "next", "(", "itr", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"{} iters ({} images) in {} seconds.\"", ".", "format", "(", "\n", "max_iter", ",", "max_iter", "*", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "timer", ".", "seconds", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.benchmark.benchmark_train": [[87, 115], ["benchmark.setup", "detectron2.modeling.build_model", "logger.info", "detectron2.solver.build_optimizer", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.load", "setup.defrost", "detectron2.data.build_detection_train_loader", "list", "detectron2.engine.SimpleTrainer", "detectron2.engine.SimpleTrainer.register_hooks", "detectron2.engine.SimpleTrainer.train", "detectron2.utils.comm.get_world_size", "torch.nn.parallel.DistributedDataParallel", "itertools.islice", "detectron2.data.DatasetFromList", "benchmark.benchmark_train.f"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup"], ["", "", "def", "benchmark_train", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "        ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "", "optimizer", "=", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "checkpointer", "=", "DetectionCheckpointer", "(", "model", ",", "optimizer", "=", "optimizer", ")", "\n", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "data_loader", "=", "build_detection_train_loader", "(", "cfg", ")", "\n", "dummy_data", "=", "list", "(", "itertools", ".", "islice", "(", "data_loader", ",", "100", ")", ")", "\n", "\n", "def", "f", "(", ")", ":", "\n", "        ", "data", "=", "DatasetFromList", "(", "dummy_data", ",", "copy", "=", "False", ")", "\n", "while", "True", ":", "\n", "            ", "yield", "from", "data", "\n", "\n", "", "", "max_iter", "=", "400", "\n", "trainer", "=", "SimpleTrainer", "(", "model", ",", "f", "(", ")", ",", "optimizer", ")", "\n", "trainer", ".", "register_hooks", "(", "\n", "[", "hooks", ".", "IterationTimer", "(", ")", ",", "hooks", ".", "PeriodicWriter", "(", "[", "CommonMetricPrinter", "(", "max_iter", ")", "]", ")", "]", "\n", ")", "\n", "trainer", ".", "train", "(", "1", ",", "max_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.benchmark.benchmark_eval": [[117, 146], ["torch.no_grad", "benchmark.setup", "detectron2.modeling.build_model", "detectron2.modeling.build_model.eval", "logger.info", "detectron2.checkpoint.DetectionCheckpointer().load", "setup.defrost", "detectron2.data.build_detection_test_loader", "list", "range", "fvcore.common.timer.Timer", "logger.info", "itertools.islice", "detectron2.modeling.build_model.", "tqdm.tqdm", "enumerate", "detectron2.checkpoint.DetectionCheckpointer", "benchmark.benchmark_train.f"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "benchmark_eval", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "model", ".", "eval", "(", ")", "\n", "logger", ".", "info", "(", "\"Model:\\n{}\"", ".", "format", "(", "model", ")", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "dummy_data", "=", "list", "(", "itertools", ".", "islice", "(", "data_loader", ",", "100", ")", ")", "\n", "\n", "def", "f", "(", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "from", "DatasetFromList", "(", "dummy_data", ",", "copy", "=", "False", ")", "\n", "\n", "", "", "for", "_", "in", "range", "(", "5", ")", ":", "# warmup", "\n", "        ", "model", "(", "dummy_data", "[", "0", "]", ")", "\n", "\n", "", "max_iter", "=", "400", "\n", "timer", "=", "Timer", "(", ")", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "max_iter", ")", "as", "pbar", ":", "\n", "        ", "for", "idx", ",", "d", "in", "enumerate", "(", "f", "(", ")", ")", ":", "\n", "            ", "if", "idx", "==", "max_iter", ":", "\n", "                ", "break", "\n", "", "model", "(", "d", ")", "\n", "pbar", ".", "update", "(", ")", "\n", "", "", "logger", ".", "info", "(", "\"{} iters in {} seconds.\"", ".", "format", "(", "max_iter", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.analyze_model.setup": [[26, 34], ["dafne.config.get_cfg", "dafne.config.get_cfg.merge_from_file", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze", "detectron2.utils.logger.setup_logger"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "setup_logger", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.analyze_model.do_flop": [[36, 52], ["detectron2.data.build_detection_test_loader", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "detectron2.modeling.build_model.eval", "collections.Counter", "zip", "logger.info", "logger.info", "tqdm.trange", "detectron2.utils.analysis.flop_count_operators", "total_flops.append", "detectron2.checkpoint.DetectionCheckpointer", "sum", "str", "numpy.mean", "numpy.std", "detectron2.utils.analysis.flop_count_operators.values", "collections.Counter.items"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "do_flop", "(", "cfg", ")", ":", "\n", "    ", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "counts", "=", "Counter", "(", ")", "\n", "total_flops", "=", "[", "]", "\n", "for", "idx", ",", "data", "in", "zip", "(", "tqdm", ".", "trange", "(", "args", ".", "num_inputs", ")", ",", "data_loader", ")", ":", "# noqa", "\n", "        ", "count", "=", "flop_count_operators", "(", "model", ",", "data", ")", "\n", "counts", "+=", "count", "\n", "total_flops", ".", "append", "(", "sum", "(", "count", ".", "values", "(", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"(G)Flops for Each Type of Operators:\\n\"", "+", "str", "(", "[", "(", "k", ",", "v", "/", "idx", ")", "for", "k", ",", "v", "in", "counts", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Total (G)Flops: {}\u00b1{}\"", ".", "format", "(", "np", ".", "mean", "(", "total_flops", ")", ",", "np", ".", "std", "(", "total_flops", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.analyze_model.do_activation": [[54, 73], ["detectron2.data.build_detection_test_loader", "detectron2.modeling.build_model", "detectron2.checkpoint.DetectionCheckpointer().load", "detectron2.modeling.build_model.eval", "collections.Counter", "zip", "logger.info", "logger.info", "tqdm.trange", "detectron2.utils.analysis.activation_count_operators", "total_activations.append", "detectron2.checkpoint.DetectionCheckpointer", "sum", "str", "numpy.mean", "numpy.std", "detectron2.utils.analysis.activation_count_operators.values", "collections.Counter.items"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "do_activation", "(", "cfg", ")", ":", "\n", "    ", "data_loader", "=", "build_detection_test_loader", "(", "cfg", ",", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ")", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "counts", "=", "Counter", "(", ")", "\n", "total_activations", "=", "[", "]", "\n", "for", "idx", ",", "data", "in", "zip", "(", "tqdm", ".", "trange", "(", "args", ".", "num_inputs", ")", ",", "data_loader", ")", ":", "# noqa", "\n", "        ", "count", "=", "activation_count_operators", "(", "model", ",", "data", ")", "\n", "counts", "+=", "count", "\n", "total_activations", ".", "append", "(", "sum", "(", "count", ".", "values", "(", ")", ")", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"(Million) Activations for Each Type of Operators:\\n\"", "\n", "+", "str", "(", "[", "(", "k", ",", "v", "/", "idx", ")", "for", "k", ",", "v", "in", "counts", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total (Million) Activations: {}\u00b1{}\"", ".", "format", "(", "\n", "np", ".", "mean", "(", "total_activations", ")", ",", "np", ".", "std", "(", "total_activations", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.analyze_model.do_parameter": [[77, 80], ["detectron2.modeling.build_model", "logger.info", "detectron2.utils.analysis.parameter_count_table"], "function", ["None"], ["", "def", "do_parameter", "(", "cfg", ")", ":", "\n", "    ", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Parameter Count:\\n\"", "+", "parameter_count_table", "(", "model", ",", "max_depth", "=", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.analyze_model.do_structure": [[82, 85], ["detectron2.modeling.build_model", "logger.info", "str"], "function", ["None"], ["", "def", "do_structure", "(", "cfg", ")", ":", "\n", "    ", "model", "=", "build_model", "(", "cfg", ")", "\n", "logger", ".", "info", "(", "\"Model Structure:\\n\"", "+", "str", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd": [[12, 24], ["print", "os.popen().read", "print", "os.system", "os.popen().read.split", "os.popen"], "function", ["None"], ["def", "cmd", "(", "command", ",", "split", "=", "False", ",", "interactive", "=", "False", ")", ":", "\n", "    ", "if", "interactive", ":", "\n", "        ", "print", "(", "command", ")", "\n", "os", ".", "system", "(", "command", ")", "\n", "return", "\n", "\n", "", "print", "(", "command", ")", "\n", "out", "=", "os", ".", "popen", "(", "command", ")", ".", "read", "(", ")", "\n", "if", "split", ":", "\n", "        ", "return", "out", ".", "split", "(", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.generate_run_base_dir": [[26, 60], ["datetime.datetime.fromtimestamp", "datetime.datetime.fromtimestamp.strftime", "os.path.join", "time.time"], "function", ["None"], ["", "", "def", "generate_run_base_dir", "(", "\n", "result_dir", ":", "str", ",", "timestamp", ":", "int", "=", "None", ",", "tag", ":", "str", "=", "None", ",", "sub_dirs", ":", "List", "[", "str", "]", "=", "None", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Generate a base directory for each experiment run.\n    Looks like this: result_dir/date_tag/sub_dir_1/.../sub_dir_n\n    Args:\n        result_dir (str): Experiment output directory.\n        timestamp (int): Timestamp which will be inlcuded in the form of '%y%m%d_%H%M'.\n        tag (str): Tag after timestamp.\n        sub_dirs (List[str]): List of subdirectories that should be created.\n\n    Returns:\n        str: Directory name.\n    \"\"\"", "\n", "if", "timestamp", "is", "None", ":", "\n", "        ", "timestamp", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "sub_dirs", "is", "None", ":", "\n", "        ", "sub_dirs", "=", "[", "]", "\n", "\n", "# Convert time", "\n", "", "date", "=", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "timestamp", ")", "\n", "date_str", "=", "date", ".", "strftime", "(", "\"%y-%m-%d_%H:%M\"", ")", "\n", "\n", "# Append tag if given", "\n", "if", "tag", "is", "None", ":", "\n", "        ", "base_dir", "=", "date_str", "\n", "", "else", ":", "\n", "        ", "base_dir", "=", "date_str", "+", "\"_\"", "+", "tag", "\n", "\n", "# Create directory", "\n", "", "base_dir", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "base_dir", ",", "*", "sub_dirs", ")", "\n", "return", "base_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir": [[62, 64], ["pathlib.Path().mkdir", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["", "def", "mkdir", "(", "directory", ")", ":", "\n", "    ", "Path", "(", "directory", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.parse_args": [[66, 152], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run.parse_gpu_arg", "os.path.join", "int", "time.time"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.parse_gpu_arg"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Run script wrapper to start DAFNe docker container.\"", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use-docker-root-user\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enter the docker container as a root user. This can be helpful if some files or directories have wrong permissions which need to be corrected. Only applicable if --no-run is set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-g\"", ",", "\"--gpus\"", ",", "help", "=", "\"Comma-separated list of GPU indices (e.g. 0,1,2,3).\"", ",", "required", "=", "True", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Additional configuration key-value pairs.\"", ",", "\n", "default", "=", "\"\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval-only\"", ",", "\n", "help", "=", "\"Don't train and only evaluate with the given model weights.\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume\"", ",", "help", "=", "\"Resume training\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "help", "=", "\"Config file to use.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--iter-scale\"", ",", "\n", "help", "=", "\"Scale factor to scale up/down the number of training iterations\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data-dir\"", ",", "\n", "help", "=", "\"Set the (host) data directory.\"", ",", "\n", "default", "=", "joinpath", "(", "os", ".", "environ", "[", "\"HOME\"", "]", ",", "\"data\"", ")", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output-dir\"", ",", "\n", "help", "=", "\"Set a fixed output directory. If None is given, a new one will be generated.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-t\"", ",", "\n", "\"--tag\"", ",", "\n", "help", "=", "\"Tag to identify the experiment in the output dir, as well as the docker container\"", ",", "\n", "default", "=", "f\"default-{int(time.time())}\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-d\"", ",", "\n", "\"--detach\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Run the docker container in detach mode.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Enable debug mode (fewew iterations, le).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shm-size\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Docker shared memory size.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-run\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Don't run the python script and only start the container in a shell. Or run the given argument in a shell in the container (e.g. '... --no-run nvidia-smi').\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "gpus", "=", "parse_gpu_arg", "(", "args", ".", "gpus", ")", "\n", "\n", "# Some assertions", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "assert", "args", ".", "output_dir", "is", "not", "None", "\n", "\n", "", "if", "args", ".", "resume", ":", "\n", "        ", "assert", "args", ".", "output_dir", "is", "not", "None", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.parse_gpu_arg": [[154, 169], ["arg.split", "str.split", "range", "str", "gpus.append", "int", "int", "gpus.append", "int", "str"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_gpu_arg", "(", "arg", ")", ":", "\n", "# Parse --gpus:", "\n", "# --gpus 1,2,3  --> [1,2,3]", "\n", "# --gpus 1,3-8,10  --> [1,3,4,5,6,7,8,10]", "\n", "    ", "gpus", "=", "[", "]", "\n", "for", "tag", "in", "arg", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "if", "\"-\"", "in", "tag", ":", "\n", "            ", "lower", ",", "upper", "=", "tag", ".", "split", "(", "\"-\"", ")", "\n", "lower", ",", "upper", "=", "int", "(", "lower", ")", ",", "int", "(", "upper", ")", "\n", "for", "x", "in", "range", "(", "lower", ",", "upper", "+", "1", ")", ":", "\n", "                ", "gpus", ".", "append", "(", "str", "(", "x", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "tag", "=", "str", "(", "int", "(", "tag", ")", ")", "# First convert to int to assert that its correct", "\n", "gpus", ".", "append", "(", "tag", ")", "\n", "", "", "return", "\",\"", ".", "join", "(", "gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_num_gpus": [[171, 174], ["len", "ARGS.gpus.split"], "function", ["None"], ["", "def", "get_num_gpus", "(", ")", ":", "\n", "    ", "\"\"\"Get the number of gpus.\"\"\"", "\n", "return", "len", "(", "ARGS", ".", "gpus", ".", "split", "(", "\",\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.is_docker_rootless": [[176, 180], ["cmd().strip", "run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "is_docker_rootless", "(", ")", ":", "\n", "    ", "\"\"\"Check if the docker daemon runs in rootless-mode\"\"\"", "\n", "out", "=", "cmd", "(", "\"docker info | grep 'rootless'\"", ")", ".", "strip", "(", ")", "\n", "return", "\"rootless\"", "in", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_gpu_flag": [[181, 191], ["cmd().strip", "run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "get_docker_gpu_flag", "(", ")", ":", "\n", "    ", "\"\"\"Get the proper GPU flag for the docker run command. Depending on whether\n    the docker nvidia runtime can be found or not, a different flag will be set.\"\"\"", "\n", "out", "=", "cmd", "(", "\"docker info | grep 'Runtimes.*nvidia'\"", ")", ".", "strip", "(", ")", "\n", "if", "out", "==", "\"\"", ":", "\n", "        ", "gpu_flag", "=", "f\"--gpus '\\\"device={ARGS.gpus}\\\"'\"", "\n", "", "else", ":", "\n", "        ", "gpu_flag", "=", "f\"--runtime=nvidia -e NVIDIA_VISIBLE_DEVICES={ARGS.gpus}\"", "\n", "\n", "", "return", "gpu_flag", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_main_model_cache_dir": [[192, 197], ["run.mkdir"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["", "def", "get_main_model_cache_dir", "(", ")", ":", "\n", "    ", "home_dir", "=", "os", ".", "environ", "[", "\"HOME\"", "]", "\n", "path", "=", "f\"{home_dir}/.torch/detectron2\"", "\n", "mkdir", "(", "path", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_volumes": [[198, 232], ["os.getcwd", "os.path.isdir", "os.path.join", "run.get_results_dir", "run.get_main_model_cache_dir", "mapping.items", "volumes.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_results_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_main_model_cache_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "get_docker_volumes", "(", ")", ":", "\n", "# Get current working directory", "\n", "    ", "pwd", "=", "os", ".", "getcwd", "(", ")", "\n", "\n", "home_dir", "=", "os", ".", "environ", "[", "\"HOME\"", "]", "\n", "data_dir", "=", "ARGS", ".", "data_dir", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "data_dir", ")", ",", "f\"Argument --data-dir ({ARGS.data_dir}) is not a valid directory.\"", "\n", "models_dir", "=", "joinpath", "(", "home_dir", ",", "\"models\"", ")", "\n", "results_dir", "=", "get_results_dir", "(", ")", "\n", "model_cache_dir", "=", "get_main_model_cache_dir", "(", ")", "\n", "\n", "# Define volumes", "\n", "# NOTE: Volume dirs must already exist on the host file or else the docker container root user", "\n", "# will create them with root owner and permissions", "\n", "# NOTE: \":z\" is necessary for read/write right in docker rootless mode", "\n", "mapping", "=", "{", "\n", "# Mount project code", "\n", "f\"{pwd}\"", ":", "\"/app/dafne:z\"", ",", "\n", "# Mount dataset, results and saved models", "\n", "f\"{data_dir}\"", ":", "\"/app/data/:z\"", ",", "\n", "f\"{models_dir}\"", ":", "\"/app/models/:z\"", ",", "\n", "f\"{results_dir}\"", ":", "\"/app/results/:z\"", ",", "\n", "f\"{model_cache_dir}\"", ":", "\"/app/.torch/detectron2:z\"", ",", "\n", "}", "\n", "\n", "\n", "# Collect", "\n", "volumes", "=", "[", "]", "\n", "for", "src", ",", "dst", "in", "mapping", ".", "items", "(", ")", ":", "\n", "        ", "volumes", ".", "append", "(", "f\"--volume {src}:{dst}\"", ")", "\n", "\n", "# Join into a single string", "\n", "", "volumes_arg", "=", "\" \"", ".", "join", "(", "volumes", ")", "\n", "return", "volumes_arg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_env_vars": [[234, 250], ["var_dict.items", "variables.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "get_docker_env_vars", "(", ")", ":", "\n", "    ", "var_dict", "=", "{", "\n", "\"DAFNE_DATA_DIR\"", ":", "\"/app/data\"", ",", "\n", "\"PYTHONPATH\"", ":", "\"./\"", ",", "\n", "# \"TORCH_HOME\": \"/app/.torch\",", "\n", "\"FVCORE_CACHE\"", ":", "\"/app/.torch\"", ",", "\n", "\"EMAIL_CREDENTIALS\"", ":", "\"/app/dafne/.mail\"", ",", "\n", "}", "\n", "\n", "variables", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "var_dict", ".", "items", "(", ")", ":", "\n", "        ", "variables", ".", "append", "(", "f\"-e {key}={value}\"", ")", "\n", "\n", "# Join into a single string", "\n", "", "variables_arg", "=", "\" \"", ".", "join", "(", "variables", ")", "\n", "return", "variables_arg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_options": [[252, 289], ["ARGS.tag.replace().replace", "run.get_docker_gpu_flag", "run.cmd", "run.cmd", "opts.append", "opts.append", "ARGS.tag.replace", "run.is_docker_rootless"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_gpu_flag", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.is_docker_rootless"], ["", "def", "get_docker_options", "(", ")", ":", "\n", "    ", "name", "=", "ARGS", ".", "tag", ".", "replace", "(", "\"=\"", ",", "\"_\"", ")", ".", "replace", "(", "\"+\"", ",", "\"_\"", ")", "\n", "gpu_cmd", "=", "get_docker_gpu_flag", "(", ")", "\n", "user_id", "=", "cmd", "(", "\"id -u\"", ",", "split", "=", "True", ")", "[", "0", "]", "\n", "user_group", "=", "cmd", "(", "\"id -g\"", ",", "split", "=", "True", ")", "[", "0", "]", "\n", "\n", "opts", "=", "[", "\n", "# Necessary for faster communication between processes", "\n", "# \"--ipc=host\",", "\n", "\"--shm-size=1024m\"", ",", "\n", "# Interactive", "\n", "\"--interactive\"", ",", "\n", "# Allocate pseudo tty", "\n", "\"-t\"", ",", "\n", "# Remove the container after it has finished running", "\n", "\"--rm\"", ",", "\n", "# Name the container (replace = with _ in tag)", "\n", "f\"--name dafne_{name}\"", ",", "\n", "# Set GPU options", "\n", "gpu_cmd", ",", "\n", "]", "\n", "\n", "if", "not", "(", "ARGS", ".", "use_docker_root_user", "or", "is_docker_rootless", "(", ")", ")", ":", "\n", "        ", "opts", ".", "append", "(", "\n", "# Set correct user", "\n", "f\"--user {user_id}:{user_group}\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "# Defaults to root user", "\n", "        ", "pass", "\n", "\n", "\n", "", "if", "ARGS", ".", "detach", ":", "\n", "        ", "opts", ".", "append", "(", "\"-d\"", ")", "\n", "\n", "", "opts_str", "=", "\" \"", ".", "join", "(", "opts", ")", "\n", "return", "opts_str", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_additional_opts": [[291, 329], ["opts.replace.replace", "opts.replace.replace", "opts.replace.replace", "opts.replace.replace", "abs", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "get_additional_opts", "(", ")", ":", "\n", "# Arguments passed via the command line", "\n", "    ", "opts", "=", "ARGS", ".", "opts", "\n", "\n", "if", "not", "(", "abs", "(", "ARGS", ".", "iter_scale", "-", "1.0", ")", "<", "1e-4", ")", ":", "\n", "        ", "s", "=", "ARGS", ".", "iter_scale", "\n", "if", "\"SOLVER.MAX_ITER\"", "not", "in", "opts", ":", "\n", "            ", "opts", "+=", "f\" SOLVER.MAX_ITER {int(90000 * s)} \"", "\n", "\n", "", "if", "\"SOLVER.STEPS\"", "not", "in", "opts", ":", "\n", "            ", "opts", "+=", "f\" SOLVER.STEPS ({int(60000 * s)},{int(80000 * s)}) \"", "\n", "\n", "", "if", "\"SOLVER.WARMUP_ITERS\"", "not", "in", "opts", ":", "\n", "            ", "opts", "+=", "f\" SOLVER.WARMUP_ITERS {int(500 * s)} \"", "\n", "\n", "", "if", "\"TEST.EVAL_PERIOD\"", "not", "in", "opts", ":", "\n", "            ", "opts", "+=", "f\" TEST.EVAL_PERIOD {int(9000 * s)} \"", "\n", "\n", "\n", "# If debug is enabled, set some specific arguments that", "\n", "# reduce the runtime", "\n", "", "", "if", "ARGS", ".", "debug", ":", "\n", "        ", "debug_args", "=", "[", "\n", "\"DEBUG.OVERFIT_NUM_IMAGES 8\"", ",", "\n", "\"SOLVER.MAX_ITER 20\"", ",", "\n", "\"DATALOADER.NUM_WORKERS 0\"", ",", "\n", "\"MODEL.WEIGHTS ''\"", ",", "\n", "]", "\n", "debug_args", "=", "\" \"", ".", "join", "(", "debug_args", ")", "\n", "opts", "+=", "\" \"", "+", "debug_args", "\n", "\n", "# Escape parenthesis and ticks", "\n", "", "opts", "=", "opts", ".", "replace", "(", "\"(\"", ",", "r\"\\(\"", ")", "\n", "opts", "=", "opts", ".", "replace", "(", "\")\"", ",", "r\"\\)\"", ")", "\n", "opts", "=", "opts", ".", "replace", "(", "'\"'", ",", "r\"\\\\\\\"\"", ")", "\n", "opts", "=", "opts", ".", "replace", "(", "\"'\"", ",", "r\"\\'\"", ")", "\n", "\n", "return", "opts", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_image_tag": [[331, 334], ["None"], "function", ["None"], ["", "def", "get_docker_image_tag", "(", ")", ":", "\n", "    ", "\"\"\"Tag of the image that should be run.\"\"\"", "\n", "return", "\"dafne\"", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_arguments": [[336, 345], ["run.get_docker_options", "run.get_docker_volumes", "run.get_docker_env_vars", "run.get_docker_image_tag"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_options", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_volumes", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_env_vars", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_docker_image_tag"], ["", "def", "get_docker_arguments", "(", ")", ":", "\n", "    ", "docker_args", "=", "[", "\n", "get_docker_options", "(", ")", ",", "\n", "get_docker_volumes", "(", ")", ",", "\n", "get_docker_env_vars", "(", ")", ",", "\n", "get_docker_image_tag", "(", ")", ",", "\n", "]", "\n", "docker_args_str", "=", "\" \"", ".", "join", "(", "docker_args", ")", "\n", "return", "docker_args_str", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.run_no_python": [[347, 350], ["run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "run_no_python", "(", ")", ":", "\n", "    ", "assert", "ARGS", ".", "no_run", "is", "not", "None", "\n", "cmd", "(", "f\"docker run {DOCKER_ARGS} {ARGS.no_run}\"", ",", "interactive", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_config_file": [[352, 365], ["run.get_relative_output_dir", "os.path.join", "run.get_relative_output_dir", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_relative_output_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_relative_output_dir"], ["", "def", "get_config_file", "(", ")", ":", "\n", "    ", "if", "ARGS", ".", "resume", ":", "\n", "        ", "output_dir", "=", "get_relative_output_dir", "(", ")", "\n", "return", "joinpath", "(", "output_dir", ",", "\"config.yaml\"", ")", "\n", "\n", "", "if", "ARGS", ".", "eval_only", ":", "\n", "        ", "if", "ARGS", ".", "output_dir", "is", "not", "None", ":", "\n", "            ", "rel", "=", "get_relative_output_dir", "(", ")", "\n", "return", "joinpath", "(", "rel", ",", "\"config.yaml\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "ARGS", ".", "config_file", "\n", "\n", "", "", "return", "ARGS", ".", "config_file", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.run_train_resume": [[367, 388], ["run.get_num_gpus", "run.get_additional_opts", "run.get_config_file", "run.get_relative_output_dir", "run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_num_gpus", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_additional_opts", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_config_file", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_relative_output_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "run_train_resume", "(", ")", ":", "\n", "    ", "num_gpus", "=", "get_num_gpus", "(", ")", "\n", "opts", "=", "get_additional_opts", "(", ")", "\n", "\n", "config_file", "=", "get_config_file", "(", ")", "\n", "\n", "output_dir", "=", "get_relative_output_dir", "(", ")", "\n", "\n", "lines", "=", "[", "\n", "f\"docker run {DOCKER_ARGS}\"", ",", "\n", "\"python ./tools/plain_train_net.py\"", ",", "\n", "f\"--config-file {config_file}\"", ",", "\n", "f\"--num-gpus {num_gpus}\"", ",", "\n", "\"--resume\"", ",", "\n", "# f\"--tag {ARGS.tag}\",", "\n", "f\"OUTPUT_DIR {output_dir}\"", ",", "\n", "opts", ",", "\n", "]", "\n", "\n", "run_command", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "cmd", "(", "run_command", ",", "interactive", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_results_dir": [[390, 395], ["os.path.join", "run.mkdir"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["", "def", "get_results_dir", "(", ")", ":", "\n", "    ", "home_dir", "=", "os", ".", "environ", "[", "\"HOME\"", "]", "\n", "results_dir", "=", "joinpath", "(", "home_dir", ",", "\"results\"", ")", "\n", "mkdir", "(", "results_dir", ")", "\n", "return", "results_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.run_train": [[397, 416], ["run.get_num_gpus", "run.get_additional_opts", "run.get_config_file", "run.generate_run_base_dir", "run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_num_gpus", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_additional_opts", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_config_file", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.generate_run_base_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "run_train", "(", ")", ":", "\n", "    ", "num_gpus", "=", "get_num_gpus", "(", ")", "\n", "opts", "=", "get_additional_opts", "(", ")", "\n", "config_file", "=", "get_config_file", "(", ")", "\n", "\n", "output_dir", "=", "generate_run_base_dir", "(", "result_dir", "=", "\"/app/results/dafne\"", ",", "tag", "=", "ARGS", ".", "tag", ")", "\n", "\n", "lines", "=", "[", "\n", "f\"docker run {DOCKER_ARGS}\"", ",", "\n", "\"python ./tools/plain_train_net.py\"", ",", "\n", "f\"--config-file {config_file}\"", ",", "\n", "f\"--num-gpus {num_gpus}\"", ",", "\n", "opts", ",", "\n", "f\"OUTPUT_DIR {output_dir}\"", ",", "\n", "f\"EXPERIMENT_NAME {ARGS.tag}\"", ",", "\n", "]", "\n", "\n", "run_command", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "cmd", "(", "run_command", ",", "interactive", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_relative_output_dir": [[418, 426], ["os.path.join", "output_dir.split"], "function", ["None"], ["", "def", "get_relative_output_dir", "(", ")", ":", "\n", "    ", "output_dir", "=", "ARGS", ".", "output_dir", "\n", "\n", "# Remove trailing slash", "\n", "if", "output_dir", "[", "-", "1", "]", "==", "\"/\"", ":", "\n", "        ", "output_dir", "=", "output_dir", "[", ":", "-", "1", "]", "\n", "", "output_dir_rel", "=", "output_dir", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "return", "joinpath", "(", "\"/app\"", ",", "\"results\"", ",", "\"dafne\"", ",", "output_dir_rel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.run_test": [[428, 448], ["run.get_num_gpus", "run.get_additional_opts", "run.get_config_file", "run.get_relative_output_dir", "run.cmd"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_num_gpus", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_additional_opts", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_config_file", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.get_relative_output_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.cmd"], ["", "def", "run_test", "(", ")", ":", "\n", "    ", "num_gpus", "=", "get_num_gpus", "(", ")", "\n", "opts", "=", "get_additional_opts", "(", ")", "\n", "config_file", "=", "get_config_file", "(", ")", "\n", "\n", "output_dir", "=", "get_relative_output_dir", "(", ")", "\n", "\n", "lines", "=", "[", "\n", "f\"docker run {DOCKER_ARGS}\"", ",", "\n", "\"python tools/plain_train_net.py\"", ",", "\n", "\"--eval-only\"", ",", "\n", "\"--resume\"", "if", "ARGS", ".", "resume", "else", "\"\"", ",", "\n", "f\"--config-file {config_file}\"", ",", "\n", "f\"--num-gpus {num_gpus}\"", ",", "\n", "opts", ",", "\n", "f\"OUTPUT_DIR {output_dir}\"", ",", "\n", "]", "\n", "\n", "run_command", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "cmd", "(", "run_command", ",", "interactive", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.visualize_data.setup": [[22, 29], ["dafne.config.get_cfg", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze", "dafne.config.get_cfg.merge_from_file"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "if", "args", ".", "config_file", ":", "\n", "        ", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.visualize_data.parse_args": [[31, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args"], ["", "def", "parse_args", "(", "in_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Visualize ground-truth data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--source\"", ",", "\n", "choices", "=", "[", "\"annotation\"", ",", "\"dataloader\"", "]", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"visualize the annotations or the data loader (with pre-processing)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--config-file\"", ",", "metavar", "=", "\"FILE\"", ",", "help", "=", "\"path to config file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output-dir\"", ",", "default", "=", "\"./\"", ",", "help", "=", "\"path to output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--show\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"show output in a window\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line\"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", "in_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.visualize_json_results.create_instances": [[19, 39], ["detectron2.structures.Instances", "numpy.asarray", "numpy.asarray().reshape", "detectron2.structures.BoxMode.convert", "numpy.asarray", "detectron2.structures.Boxes", "numpy.asarray", "dataset_id_map"], "function", ["None"], ["def", "create_instances", "(", "predictions", ",", "image_size", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "score", "=", "np", ".", "asarray", "(", "[", "x", "[", "\"score\"", "]", "for", "x", "in", "predictions", "]", ")", "\n", "chosen", "=", "(", "score", ">", "args", ".", "conf_threshold", ")", ".", "nonzero", "(", ")", "[", "0", "]", "\n", "score", "=", "score", "[", "chosen", "]", "\n", "bbox", "=", "np", ".", "asarray", "(", "[", "predictions", "[", "i", "]", "[", "\"bbox\"", "]", "for", "i", "in", "chosen", "]", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "bbox", "=", "BoxMode", ".", "convert", "(", "bbox", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "\n", "labels", "=", "np", ".", "asarray", "(", "[", "dataset_id_map", "(", "predictions", "[", "i", "]", "[", "\"category_id\"", "]", ")", "for", "i", "in", "chosen", "]", ")", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_boxes", "=", "Boxes", "(", "bbox", ")", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "\n", "try", ":", "\n", "        ", "ret", ".", "pred_masks", "=", "[", "predictions", "[", "i", "]", "[", "\"segmentation\"", "]", "for", "i", "in", "chosen", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "pass", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.__init__": [[64, 78], ["detectron2.engine.DefaultTrainer.__init__", "logging.getLogger", "logging.getLogger.info", "torch.cuda.amp.GradScaler", "logging.getLogger.info"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "\n", "# Init AMP if given", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using AMP\"", ")", "\n", "self", ".", "scaler", "=", "GradScaler", "(", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Not using AMP\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_train_loader": [[79, 110], ["dafne.data.datasets.dota.DotaDatasetMapper", "detectron2.data.build_detection_train_loader", "detectron2.data.transforms.ResizeShortestEdge", "detectron2.data.transforms.RandomFlip", "detectron2.data.transforms.RandomFlip", "detectron2.data.transforms.RandomRotation"], "methods", ["None"], ["", "", "def", "build_train_loader", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            iterable\n\n        It now calls :func:`detectron2.data.build_detection_train_loader`.\n        Overwrite it if you'd like a different data loader.\n        \"\"\"", "\n", "\n", "# Build resize augmentation", "\n", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TRAIN", "\n", "sample_style", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TRAIN_SAMPLING", "\n", "\n", "augmentations", "=", "[", "\n", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", ",", "\n", "# T.RandomLighting(scale=1.0),", "\n", "# T.RandomBrightness(intensity_min=0.5, intensity_max=1.5),", "\n", "# T.RandomContrast(intensity_min=0.5, intensity_max=1.5),", "\n", "# T.RandomSaturation(intensity_min=0.5, intensity_max=1.5),", "\n", "T", ".", "RandomFlip", "(", "prob", "=", "0.5", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", ",", "# HFLIP", "\n", "T", ".", "RandomFlip", "(", "prob", "=", "0.5", ",", "horizontal", "=", "False", ",", "vertical", "=", "True", ")", ",", "# VFLIP", "\n", "T", ".", "RandomRotation", "(", "sample_style", "=", "\"choice\"", ",", "angle", "=", "[", "0.0", ",", "90.0", ",", "180.0", ",", "270.0", "]", ")", ",", "\n", "]", "\n", "mapper", "=", "DotaDatasetMapper", "(", "\n", "cfg", ",", "\n", "is_train", "=", "True", ",", "\n", "use_instance_mask", "=", "True", ",", "\n", "augmentations", "=", "augmentations", ",", "\n", ")", "\n", "return", "build_detection_train_loader", "(", "cfg", ",", "mapper", "=", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_test_loader": [[111, 133], ["dafne.data.datasets.dota.DotaDatasetMapper", "detectron2.data.build_detection_test_loader", "detectron2.data.transforms.ResizeShortestEdge"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_test_loader", "(", "cls", ",", "cfg", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            iterable\n\n        It now calls :func:`detectron2.data.build_detection_test_loader`.\n        Overwrite it if you'd like a different data loader.\n        \"\"\"", "\n", "\n", "min_size", "=", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "\n", "max_size", "=", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", "sample_style", "=", "\"choice\"", "\n", "augmentations", "=", "[", "T", ".", "ResizeShortestEdge", "(", "min_size", ",", "max_size", ",", "sample_style", ")", "]", "\n", "mapper", "=", "DotaDatasetMapper", "(", "\n", "cfg", ",", "\n", "is_train", "=", "\"_train_\"", "in", "dataset_name", "or", "\"_val_\"", "in", "dataset_name", ",", "\n", "use_instance_mask", "=", "True", ",", "\n", "augmentations", "=", "augmentations", ",", "\n", ")", "\n", "\n", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ",", "mapper", "=", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_evaluator": [[134, 155], ["dafne.evaluation.dota_evaluation.DotaEvaluator", "evaluator_list.append", "detectron2.evaluation.DatasetEvaluators", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create evaluator(s) for a given dataset.\n        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n        For your own dataset, you can simply create an evaluator manually in your\n        script and do not have to worry about the hacky if-else logic here.\n        \"\"\"", "\n", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ",", "dataset_name", ")", "\n", "", "evaluator_list", "=", "[", "]", "\n", "\n", "# Construct the DOTA evaluator object", "\n", "dota_evaluator", "=", "DotaEvaluator", "(", "\n", "dataset_name", "=", "dataset_name", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "output_folder", ",", "\n", ")", "\n", "evaluator_list", ".", "append", "(", "dota_evaluator", ")", "\n", "return", "DatasetEvaluators", "(", "evaluator_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test": [[156, 175], ["super().test", "train_net.is_debug_session", "dafne.utils.mail.send_mail_success"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.is_debug_session", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.send_mail_success"], ["", "@", "classmethod", "\n", "def", "test", "(", "cls", ",", "cfg", ",", "model", ",", "evaluators", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Performs super().test() and sends results via email.\n\n        Args:\n            cfg (CfgNode):\n            model (nn.Module):\n            evaluators (list[DatasetEvaluator] or None): if None, will call\n                :meth:`build_evaluator`. Otherwise, must have the same length as\n                `cfg.DATASETS.TEST`.\n\n        Returns:\n            dict: a dict of result metrics\n        \"\"\"", "\n", "results", "=", "super", "(", ")", ".", "test", "(", "cfg", ",", "model", ",", "evaluators", ")", "\n", "if", "not", "is_debug_session", "(", "cfg", ")", ":", "\n", "            ", "send_mail_success", "(", "cfg", ",", "results", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test_with_TTA": [[176, 198], ["logging.getLogger", "logging.getLogger.info", "dafne.modeling.tta.OneStageRCNNWithTTA", "cls.test", "collections.OrderedDict", "cls.build_evaluator", "train_net.is_debug_session", "dafne.utils.mail.send_mail_success", "os.path.join", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.build_evaluator", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.is_debug_session", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.send_mail_success"], ["", "@", "classmethod", "\n", "def", "test_with_TTA", "(", "cls", ",", "cfg", ",", "model", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "\"dafne.trainer\"", ")", "\n", "# In the end of training, run an evaluation with TTA", "\n", "# Only support some R-CNN models.", "\n", "logger", ".", "info", "(", "\"Running inference with test-time augmentation ...\"", ")", "\n", "model", "=", "OneStageRCNNWithTTA", "(", "cfg", ",", "model", ")", "\n", "\n", "evaluators", "=", "[", "\n", "cls", ".", "build_evaluator", "(", "\n", "cfg", ",", "\n", "name", ",", "\n", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference_TTA\"", ",", "name", ")", ",", "\n", ")", "\n", "for", "name", "in", "cfg", ".", "DATASETS", ".", "TEST", "\n", "]", "\n", "res", "=", "cls", ".", "test", "(", "cfg", ",", "model", ",", "evaluators", ")", "\n", "res", "=", "OrderedDict", "(", "{", "k", "+", "\"_TTA\"", ":", "v", "for", "k", ",", "v", "in", "res", ".", "items", "(", ")", "}", ")", "\n", "\n", "if", "not", "is_debug_session", "(", "cfg", ")", ":", "\n", "            ", "send_mail_success", "(", "cfg", ",", "res", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.run_step": [[199, 207], ["train_net.Trainer.run_step_amp", "super().run_step"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.run_step_amp", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.run_step"], ["", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the standard training logic described above.\n        \"\"\"", "\n", "if", "self", ".", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", ":", "\n", "            ", "self", ".", "run_step_amp", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "run_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.run_step_amp": [[208, 253], ["time.perf_counter", "next", "train_net.Trainer.optimizer.zero_grad", "train_net.Trainer.scaler.scale().backward", "train_net.Trainer.scaler.step", "train_net.Trainer.scaler.update", "time.perf_counter", "torch.cuda.amp.autocast", "train_net.Trainer.model", "sum", "train_net.Trainer._write_metrics", "train_net.Trainer._detect_anomaly", "train_net.Trainer.scaler.unscale_", "train_net.Trainer.values", "train_net.Trainer.scaler.scale", "torch.cuda.stream", "contextlib.nullcontext", "torch.cuda.Stream"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.next", "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step"], ["", "", "def", "run_step_amp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Perform step() with automatic mixed precision.\"\"\"", "\n", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[SimpleTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\"\"\"\n        If you want to do something with the data, you can wrap the dataloader.\n        \"\"\"", "\n", "data", "=", "next", "(", "self", ".", "_data_loader_iter", ")", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "\"\"\"\n        If you want to do something with the losses, you can wrap the model.\n        \"\"\"", "\n", "with", "autocast", "(", ")", ":", "\n", "            ", "loss_dict", "=", "self", ".", "model", "(", "data", ")", "\n", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "\"\"\"\n        If you need to accumulate gradients or do something similar, you can\n        wrap the optimizer with your custom `zero_grad()` method.\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "scaler", ".", "scale", "(", "losses", ")", ".", "backward", "(", ")", "\n", "\n", "# use a new stream so the ops don't wait for DDP", "\n", "with", "torch", ".", "cuda", ".", "stream", "(", "\n", "torch", ".", "cuda", ".", "Stream", "(", ")", "\n", ")", "if", "losses", ".", "device", ".", "type", "==", "\"cuda\"", "else", "contextlib", ".", "nullcontext", "(", ")", ":", "\n", "            ", "metrics_dict", "=", "loss_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "self", ".", "_detect_anomaly", "(", "losses", ",", "loss_dict", ")", "\n", "\n", "", "\"\"\"\n        If you need gradient clipping/scaling or other processing, you can\n        wrap the optimizer with your custom `step()` method. But it is\n        suboptimal as explained in https://arxiv.org/abs/2006.15704 Sec 3.2.4\n        \"\"\"", "\n", "if", "self", ".", "cfg", ".", "SOLVER", ".", "CLIP_GRADIENTS", ".", "ENABLED", ":", "\n", "# Unscales the gradients of optimizer's assigned params in-place", "\n", "            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optimizer", ")", "\n", "\n", "", "self", ".", "scaler", ".", "step", "(", "self", ".", "optimizer", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.backup_config_file": [[255, 260], ["detectron2.is_main_process", "os.path.join", "os.path.join", "shutil.copy2"], "function", ["None"], ["", "", "def", "backup_config_file", "(", "cfg", ")", ":", "\n", "    ", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config.yaml\"", ")", "\n", "path_backup", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config_orig.yaml\"", ")", "\n", "shutil", ".", "copy2", "(", "path", ",", "path_backup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.restore_config_file": [[262, 267], ["detectron2.is_main_process", "os.path.join", "os.path.join", "shutil.move"], "function", ["None"], ["", "", "def", "restore_config_file", "(", "cfg", ")", ":", "\n", "    ", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config.yaml\"", ")", "\n", "path_backup", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"config_orig.yaml\"", ")", "\n", "shutil", ".", "move", "(", "path_backup", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup": [[269, 293], ["dafne.config.get_cfg", "dafne.config.get_cfg.merge_from_file", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze", "detectron2.engine.default_setup", "detectron2.utils.logger.setup_logger", "train_net.backup_config_file", "train_net.restore_config_file", "detectron2.get_rank"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.backup_config_file", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.restore_config_file"], ["", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Create configs and perform basic setups.\n    \"\"\"", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "\n", "# Even in eval_only mode, `default_setup` will overwrite the original config.yaml in the output_dir.", "\n", "# Therefore, it is necessary to back it up such that an evaluation does not change the original", "\n", "# saved config file.", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "backup_config_file", "(", "cfg", ")", "\n", "\n", "", "default_setup", "(", "cfg", ",", "args", ")", "\n", "\n", "# Restore the original config file", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "restore_config_file", "(", "cfg", ")", "\n", "\n", "# Setup logger for \"dafne\" module", "\n", "", "setup_logger", "(", "output", "=", "cfg", ".", "OUTPUT_DIR", ",", "distributed_rank", "=", "comm", ".", "get_rank", "(", ")", ",", "name", "=", "\"dafne\"", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup_hooks": [[295, 329], ["hook_list.append", "dafne.hooks.RTPTHook", "hook_list.append", "detectron2.engine.hooks.EvalHook", "trainer.test_with_TTA"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test_with_TTA"], ["", "def", "setup_hooks", "(", "cfg", ",", "trainer", ")", "->", "List", "[", "HookBase", "]", ":", "\n", "    ", "hook_list", "=", "[", "]", "\n", "\n", "# Update process title hook (only on main process)", "\n", "hook_list", ".", "append", "(", "RTPTHook", "(", ")", ")", "\n", "\n", "# Autograd profiler in iteration 10-20", "\n", "# hook_list.append(", "\n", "#     hooks.AutogradProfiler(", "\n", "#         lambda trainer: trainer.iter > 10 and trainer.iter < 20, cfg.OUTPUT_DIR", "\n", "#     )", "\n", "# )", "\n", "\n", "# TODO", "\n", "# evaluators = [", "\n", "#     trainer.build_evaluator(", "\n", "#         cfg,", "\n", "#         name,", "\n", "#         output_folder=os.path.join(cfg.OUTPUT_DIR, \"inference_mini\", name),", "\n", "#     )", "\n", "#     for name in cfg.DATASETS.TEST", "\n", "# ]", "\n", "\n", "# hook_list.append(", "\n", "#     hooks.EvalHook(cfg.SOLVER.MAX_ITER // 10, lambda: trainer.test(cfg, ))", "\n", "# )", "\n", "\n", "# Add EvalHook with TTA if test time augmentation is enabled", "\n", "if", "cfg", ".", "TEST", ".", "AUG", ".", "ENABLED", ":", "\n", "        ", "hook_list", ".", "append", "(", "\n", "hooks", ".", "EvalHook", "(", "0", ",", "lambda", ":", "trainer", ".", "test_with_TTA", "(", "cfg", ",", "trainer", ".", "model", ")", ")", "\n", ")", "\n", "\n", "", "return", "hook_list", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.is_debug_session": [[331, 340], ["cfg.OUTPUT_DIR.lower"], "function", ["None"], ["", "def", "is_debug_session", "(", "cfg", ")", "->", "bool", ":", "\n", "    ", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "        ", "return", "True", "\n", "", "if", "\"debug\"", "in", "cfg", ".", "OUTPUT_DIR", ".", "lower", "(", ")", ":", "\n", "        ", "return", "True", "\n", "", "if", "cfg", ".", "SOLVER", ".", "MAX_ITER", "<", "10000", ":", "\n", "        ", "return", "True", "\n", "# TODO: Add more cases where debugging is enabled", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.main": [[342, 396], ["train_net.setup", "logging.getLogger", "dafne.data.datasets.dota.register_dota", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "train_net.Trainer.test", "detectron2.is_main_process", "train_net.Trainer", "Trainer.register_hooks", "Trainer.resume_or_load", "Trainer.train", "Trainer.test.update", "detectron2.evaluation.verify_results", "train_net.setup_hooks", "logging.getLogger.error", "detectron2.is_main_process", "logging.getLogger.error", "shutil.move", "logging.getLogger.error", "logging.getLogger.error", "logging.getLogger.error", "logging.getLogger.error", "detectron2.checkpoint.DetectionCheckpointer", "train_net.Trainer.test_with_TTA", "shutil.rmtree", "traceback.extract_tb().format", "traceback.extract_tb"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup", "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.register_dota", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.setup_hooks", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.train_net.Trainer.test_with_TTA"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "# Register the DOTA dataset", "\n", "register_dota", "(", "cfg", ")", "\n", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "model", ")", "\n", "if", "cfg", ".", "TEST", ".", "AUG", ".", "ENABLED", ":", "\n", "            ", "res", ".", "update", "(", "Trainer", ".", "test_with_TTA", "(", "cfg", ",", "model", ")", ")", "\n", "", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "verify_results", "(", "cfg", ",", "res", ")", "\n", "", "return", "res", "\n", "\n", "", "\"\"\"\n    If you'd like to do anything fancier than the standard training logic,\n    consider writing your own training loop (see plain_train_net.py) or\n    subclassing the trainer.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "cfg", ")", "\n", "\n", "# Add hooks to trainer", "\n", "trainer", ".", "register_hooks", "(", "setup_hooks", "(", "cfg", ",", "trainer", ")", ")", "\n", "\n", "trainer", ".", "resume_or_load", "(", "resume", "=", "args", ".", "resume", ")", "\n", "return", "trainer", ".", "train", "(", ")", "\n", "\n", "", "except", "KeyboardInterrupt", ":", "# Catch keyboard interruptions", "\n", "        ", "logger", ".", "error", "(", "\"Keyboard interruption catched. Removing output directory\"", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "cfg", ".", "OUTPUT_DIR", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "# Log error message", "\n", "        ", "tbstr", "=", "\"\"", ".", "join", "(", "traceback", ".", "extract_tb", "(", "e", ".", "__traceback__", ")", ".", "format", "(", ")", ")", "\n", "errormsg", "=", "f\"Traceback:\\n{tbstr}\\nError: {e}\"", "\n", "logger", ".", "error", "(", "errormsg", ")", "\n", "\n", "# Rename output dir", "\n", "src", "=", "cfg", ".", "OUTPUT_DIR", "\n", "dst", "=", "src", "+", "\"_errror\"", "\n", "shutil", ".", "move", "(", "src", ",", "dst", ")", "\n", "\n", "logger", ".", "error", "(", "f\"Moving output directory from\"", ")", "\n", "logger", ".", "error", "(", "src", ")", "\n", "logger", ".", "error", "(", "\"to\"", ")", "\n", "logger", ".", "error", "(", "dst", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.demo.demo.TTADefaultPredictor.__init__": [[126, 130], ["detectron2.engine.defaults.DefaultPredictor.__init__", "dafne.modeling.tta.OneStageRCNNWithTTA"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "\n", "self", ".", "model", "=", "OneStageRCNNWithTTA", "(", "cfg", ",", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.demo.demo.VisualizationDemo.__init__": [[157, 173], ["detectron2.data.MetadataCatalog.get", "torch.device", "demo.TTADefaultPredictor", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ",", "parallel", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            instance_mode (ColorMode):\n            parallel (bool): whether to run the model in different processes from visualization.\n                Useful since the visualization logic can be slow.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\n", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", "if", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "else", "\"__unused\"", "\n", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "instance_mode", "=", "instance_mode", "\n", "\n", "self", ".", "parallel", "=", "parallel", "\n", "self", ".", "predictor", "=", "TTADefaultPredictor", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.demo.demo.VisualizationDemo.run_on_image": [[174, 208], ["demo.VisualizationDemo.predictor", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.colormap.colormap", "predictions[].to", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.structures.PolygonMasks"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "run_on_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n                This is the format used by OpenCV.\n\n        Returns:\n            predictions (dict): the output of the model.\n            vis_output (VisImage): the visualized image output.\n        \"\"\"", "\n", "vis_output", "=", "None", "\n", "predictions", "=", "self", ".", "predictor", "(", "image", ")", "\n", "# Convert image from OpenCV BGR format to Matplotlib RGB format.", "\n", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "visualizer", "=", "Visualizer", "(", "image", ",", "self", ".", "metadata", ",", "instance_mode", "=", "self", ".", "instance_mode", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "instances", "=", "predictions", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "labels", "=", "_create_text_labels", "(", "\n", "instances", ".", "pred_classes", ",", "instances", ".", "scores", ",", "classnames", "\n", ")", "\n", "\n", "vis_output", "=", "visualizer", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", "alpha", "=", "0.1", "\n", ")", "\n", "\n", "# vis_output = visualizer.draw_instance_predictions(predictions=instances)", "\n", "\n", "return", "predictions", ",", "vis_output", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.demo.demo.setup_cfg": [[49, 63], ["dafne.config.get_cfg", "dafne.config.get_cfg.merge_from_file", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup_cfg", "(", "args", ")", ":", "\n", "# load config from file and command-line arguments", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "# Set score_threshold for builtin models", "\n", "# cfg.MODEL.RETINANET.SCORE_THRESH_TEST = args.confidence_threshold", "\n", "# cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = args.confidence_threshold", "\n", "# cfg.MODEL.PANOPTIC_FPN.COMBINE.INSTANCES_CONFIDENCE_THRESH = (", "\n", "#     args.confidence_threshold", "\n", "# )", "\n", "cfg", ".", "MODEL", ".", "DAFNE", ".", "INFERENCE_TH_TEST", "=", "args", ".", "confidence_threshold", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.demo.demo.get_parser": [[65, 98], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Detectron2 demo for builtin configs\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"A list of space separated input images; \"", "\n", "\"or a single glob pattern such as 'directory/*.jpg'\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "help", "=", "\"A file or directory to save output visualizations. \"", "\n", "\"If not given, will show output in an OpenCV window.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--confidence-threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "\"Minimum score for instance predictions to be shown\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line 'KEY VALUE' pairs\"", ",", "\n", "default", "=", "[", "]", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.py_cpu_nms_poly": [[19, 54], ["range", "len", "polyiou.VectorDouble", "polys.append", "scores.argsort", "keep.append", "range", "numpy.array", "polyiou.iou_poly", "ovr.append", "numpy.sum", "print", "pdb.set_trace", "numpy.sum", "print", "pdb.set_trace", "numpy.where", "print", "print", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "py_cpu_nms_poly", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "polys", "=", "[", "]", "\n", "areas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "for", "j", "in", "range", "(", "order", ".", "size", "-", "1", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "order", "[", "j", "+", "1", "]", "]", ")", "\n", "ovr", ".", "append", "(", "iou", ")", "\n", "if", "(", "iou", "!=", "iou", ")", ":", "\n", "                ", "print", "(", "'poly i:'", ",", "polys", "[", "i", "]", ",", "'polys j + 1:'", ",", "polys", "[", "j", "+", "1", "]", ")", "\n", "print", "(", "'det i:'", ",", "dets", "[", "i", "]", ",", "'dets j + 1:'", ",", "dets", "[", "order", "[", "j", "+", "1", "]", "]", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "if", "(", "np", ".", "sum", "(", "ovr", "!=", "ovr", ")", ">", "0", ")", ":", "\n", "            ", "print", "(", "'before'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "", "ovr2", "=", "np", ".", "array", "(", "ovr", ")", "\n", "if", "(", "np", ".", "sum", "(", "ovr2", "!=", "ovr2", ")", ">", "0", ")", ":", "\n", "            ", "print", "(", "'after'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "inds", "=", "np", ".", "where", "(", "ovr2", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "", "return", "keep", "\n", "", "def", "test_nms", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.test_nms": [[54, 63], ["numpy.array", "ResultMerge.py_cpu_nms_poly", "print"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly"], ["", "def", "test_nms", "(", ")", ":", "\n", "    ", "dets", "=", "[", "[", "6.86000000e+02", ",", "2.97600000e+03", ",", "7.09000000e+02", ",", "2.97600000e+03", ",", "\n", "7.24000000e+02", ",", "2.97600000e+03", ",", "7.01000000e+02", ",", "2.97600000e+03", ",", "\n", "2.71368679e-03", "]", ",", "[", "6.86000000e+02", ",", "2.97600000e+03", ",", "7.09000000e+02", ",", "2.97600000e+03", ",", "\n", "7.24000000e+02", ",", "2.97600000e+03", ",", "7.01000000e+02", ",", "2.97600000e+03", ",", "\n", "2.70966860e-03", "]", "]", "\n", "dets", "=", "np", ".", "array", "(", "dets", ")", "\n", "keep", "=", "py_cpu_nms_poly", "(", "dets", ",", "nms_thresh", ")", "\n", "print", "(", "keep", ")", "\n", "", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.py_cpu_nms": [[63, 94], ["scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "#print('dets:', dets)", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.nmsbynamedict": [[95, 115], ["nms", "outdets.append", "numpy.array", "nms", "numpy.array"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "thresh", ")", ":", "\n", "    ", "nameboxnmsdict", "=", "{", "x", ":", "[", "]", "for", "x", "in", "nameboxdict", "}", "\n", "for", "imgname", "in", "nameboxdict", ":", "\n", "#print('imgname:', imgname)", "\n", "#keep = py_cpu_nms(np.array(nameboxdict[imgname]), thresh)", "\n", "#print('type nameboxdict:', type(nameboxnmsdict))", "\n", "#print('type imgname:', type(imgname))", "\n", "#print('type nms:', type(nms))", "\n", "        ", "try", ":", "\n", "            ", "keep", "=", "nms", "(", "np", ".", "array", "(", "nameboxdict", "[", "imgname", "]", ",", "dtype", "=", "np", ".", "float32", ")", ",", "thresh", ")", "## for gpu", "\n", "", "except", ":", "\n", "            ", "keep", "=", "nms", "(", "np", ".", "array", "(", "nameboxdict", "[", "imgname", "]", ")", ",", "thresh", ")", "## for cpu", "\n", "#print('keep:', keep)", "\n", "", "outdets", "=", "[", "]", "\n", "#print('nameboxdict[imgname]: ', nameboxnmsdict[imgname])", "\n", "for", "index", "in", "keep", ":", "\n", "# print('index:', index)", "\n", "            ", "outdets", ".", "append", "(", "nameboxdict", "[", "imgname", "]", "[", "index", "]", ")", "\n", "", "nameboxnmsdict", "[", "imgname", "]", "=", "outdets", "\n", "", "return", "nameboxnmsdict", "\n", "", "def", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.poly2origpoly": [[115, 123], ["range", "int", "origpoly.append", "origpoly.append", "float", "float", "float", "float", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", ":", "\n", "    ", "origpoly", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ":", "\n", "        ", "tmp_x", "=", "float", "(", "poly", "[", "i", "*", "2", "]", "+", "x", ")", "/", "float", "(", "rate", ")", "\n", "tmp_y", "=", "float", "(", "poly", "[", "i", "*", "2", "+", "1", "]", "+", "y", ")", "/", "float", "(", "rate", ")", "\n", "origpoly", ".", "append", "(", "tmp_x", ")", "\n", "origpoly", ".", "append", "(", "tmp_y", ")", "\n", "", "return", "origpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.mergebase": [[124, 169], ["os.path.exists", "dota_utils.GetFileFromThisRootDir", "os.path.exists", "dota_utils.custombasename", "os.path.join", "open", "f_in.readlines", "ResultMerge.nmsbynamedict", "x.strip().split", "subname.split", "re.compile", "re.findall", "re.findall", "re.compile", "list", "ResultMerge.poly2origpoly", "list.append", "list", "nameboxdict[].append", "open", "int", "int", "re.findall", "map", "map", "x.strip", "f_out.write", "map", "str", "ResultMerge.py_cpu_nms", "ResultMerge.py_cpu_nms_poly"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.nmsbynamedict", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.poly2origpoly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly"], ["", "def", "mergebase", "(", "srcpath", ",", "dstpath", ",", "nms", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "exists", "(", "srcpath", ")", ",", "\"The srcpath is not exists!\"", "\n", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "dstpath", ")", ",", "\"The dstpath is not exists!\"", "\n", "for", "fullname", "in", "filelist", ":", "\n", "        ", "name", "=", "util", ".", "custombasename", "(", "fullname", ")", "\n", "#print('name:', name)", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "'.txt'", ")", "\n", "with", "open", "(", "fullname", ",", "'r'", ")", "as", "f_in", ":", "\n", "            ", "nameboxdict", "=", "{", "}", "\n", "lines", "=", "f_in", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "lines", "]", "\n", "for", "splitline", "in", "splitlines", ":", "\n", "                ", "subname", "=", "splitline", "[", "0", "]", "\n", "splitname", "=", "subname", ".", "split", "(", "'__'", ")", "\n", "oriname", "=", "splitname", "[", "0", "]", "\n", "pattern1", "=", "re", ".", "compile", "(", "r'__\\d+___\\d+'", ")", "\n", "#print('subname:', subname)", "\n", "x_y", "=", "re", ".", "findall", "(", "pattern1", ",", "subname", ")", "\n", "x_y_2", "=", "re", ".", "findall", "(", "r'\\d+'", ",", "x_y", "[", "0", "]", ")", "\n", "x", ",", "y", "=", "int", "(", "x_y_2", "[", "0", "]", ")", ",", "int", "(", "x_y_2", "[", "1", "]", ")", "\n", "\n", "pattern2", "=", "re", ".", "compile", "(", "r'__([\\d+\\.]+)__\\d+___'", ")", "\n", "\n", "rate", "=", "re", ".", "findall", "(", "pattern2", ",", "subname", ")", "[", "0", "]", "\n", "\n", "confidence", "=", "splitline", "[", "1", "]", "\n", "poly", "=", "list", "(", "map", "(", "float", ",", "splitline", "[", "2", ":", "]", ")", ")", "\n", "origpoly", "=", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", "\n", "det", "=", "origpoly", "\n", "det", ".", "append", "(", "confidence", ")", "\n", "det", "=", "list", "(", "map", "(", "float", ",", "det", ")", ")", "\n", "if", "(", "oriname", "not", "in", "nameboxdict", ")", ":", "\n", "                    ", "nameboxdict", "[", "oriname", "]", "=", "[", "]", "\n", "", "nameboxdict", "[", "oriname", "]", ".", "append", "(", "det", ")", "\n", "", "nameboxnmsdict", "=", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "nms_thresh", ")", "\n", "with", "open", "(", "dstname", ",", "'w'", ")", "as", "f_out", ":", "\n", "                ", "for", "imgname", "in", "nameboxnmsdict", ":", "\n", "                    ", "for", "det", "in", "nameboxnmsdict", "[", "imgname", "]", ":", "\n", "#print('det:', det)", "\n", "                        ", "confidence", "=", "det", "[", "-", "1", "]", "\n", "bbox", "=", "det", "[", "0", ":", "-", "1", "]", "\n", "outline", "=", "imgname", "+", "' '", "+", "str", "(", "confidence", ")", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "bbox", ")", ")", "\n", "#print('outline:', outline)", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "", "", "", "def", "mergebyrec", "(", "srcpath", ",", "dstpath", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.mergebyrec": [[169, 180], ["ResultMerge.mergebase"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase"], ["", "", "", "", "", "", "def", "mergebyrec", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "\"\"\"\n    srcpath: result files before merge and nms\n    dstpath: result files after merge and nms\n    \"\"\"", "\n", "# srcpath = r'E:\\bod-dataset\\results\\bod-v3_rfcn_2000000'", "\n", "# dstpath = r'E:\\bod-dataset\\results\\bod-v3_rfcn_2000000_nms'", "\n", "\n", "mergebase", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms", ")", "\n", "", "def", "mergebypoly", "(", "srcpath", ",", "dstpath", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge.mergebypoly": [[180, 190], ["ResultMerge.mergebase"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase"], ["", "def", "mergebypoly", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "\"\"\"\n    srcpath: result files before merge and nms\n    dstpath: result files after merge and nms\n    \"\"\"", "\n", "# srcpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/comp4_test_results'", "\n", "# dstpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/testtime'", "\n", "mergebase", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms_poly", ")", "\n", "# mergebase(srcpath,", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.py_cpu_nms_poly_fast": [[10, 76], ["numpy.min", "numpy.min", "numpy.max", "numpy.max", "range", "len", "DOTA_devkit.VectorDouble", "polys.append", "scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "range", "print", "pdb.set_trace", "numpy.where", "DOTA_devkit.iou_poly", "math.isnan", "numpy.where", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly"], ["def", "py_cpu_nms_poly_fast", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "obbs", "=", "dets", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "print", "(", "'fail index'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "x1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "x2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "\n", "polys", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "# if order.size == 0:", "\n", "#     break", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "# w = np.maximum(0.0, xx2 - xx1 + 1)", "\n", "# h = np.maximum(0.0, yy2 - yy1 + 1)", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", ")", "\n", "hbb_inter", "=", "w", "*", "h", "\n", "hbb_ovr", "=", "hbb_inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "hbb_inter", ")", "\n", "# h_keep_inds = np.where(hbb_ovr == 0)[0]", "\n", "h_inds", "=", "np", ".", "where", "(", "hbb_ovr", ">", "0", ")", "[", "0", "]", "\n", "tmp_order", "=", "order", "[", "h_inds", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "tmp_order", ".", "size", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "tmp_order", "[", "j", "]", "]", ")", "\n", "hbb_ovr", "[", "h_inds", "[", "j", "]", "]", "=", "iou", "\n", "# ovr.append(iou)", "\n", "# ovr_index.append(tmp_order[j])", "\n", "\n", "# ovr = np.array(ovr)", "\n", "# ovr_index = np.array(ovr_index)", "\n", "# print('ovr: ', ovr)", "\n", "# print('thresh: ', thresh)", "\n", "", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "hbb_ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "\n", "# order_obb = ovr_index[inds]", "\n", "# print('inds: ', inds)", "\n", "# order_hbb = order[h_keep_inds + 1]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "# pdb.set_trace()", "\n", "# order = np.concatenate((order_obb, order_hbb), axis=0).astype(np.int)", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.py_cpu_nms": [[77, 109], ["scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "#print('dets:', dets)", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.bbox_poly2hbb": [[110, 129], ["numpy.zeros", "numpy.min", "numpy.min", "numpy.max", "numpy.max", "numpy.hstack", "numpy.reshape", "numpy.reshape"], "function", ["None"], ["", "def", "bbox_poly2hbb", "(", "boxes", ")", ":", "\n", "    ", "\"\"\"\n    with label\n    :param boxes: (x1, y1, ... x4, y4, score) [n, 9]\n    :return: hbb: (xmin, ymin, xmax, ymax, score) [n, 5]\n    \"\"\"", "\n", "# pdb.set_trace()", "\n", "n", "=", "boxes", ".", "shape", "[", "0", "]", "\n", "hbbs", "=", "np", ".", "zeros", "(", "(", "n", ",", "4", ")", ")", "\n", "\n", "xs", "=", "np", ".", "reshape", "(", "boxes", "[", ":", ",", ":", "-", "1", "]", ",", "(", "n", ",", "4", ",", "2", ")", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "ys", "=", "np", ".", "reshape", "(", "boxes", "[", ":", ",", ":", "-", "1", "]", ",", "(", "n", ",", "4", ",", "2", ")", ")", "[", ":", ",", ":", ",", "1", "]", "\n", "# pdb.set_trace()", "\n", "hbbs", "[", ":", ",", "0", "]", "=", "np", ".", "min", "(", "xs", ",", "axis", "=", "1", ")", "\n", "hbbs", "[", ":", ",", "1", "]", "=", "np", ".", "min", "(", "ys", ",", "axis", "=", "1", ")", "\n", "hbbs", "[", ":", ",", "2", "]", "=", "np", ".", "max", "(", "xs", ",", "axis", "=", "1", ")", "\n", "hbbs", "[", ":", ",", "3", "]", "=", "np", ".", "max", "(", "ys", ",", "axis", "=", "1", ")", "\n", "hbbs", "=", "np", ".", "hstack", "(", "(", "hbbs", ",", "boxes", "[", ":", ",", "-", "1", ",", "np", ".", "newaxis", "]", ")", ")", "\n", "return", "hbbs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.obb_HNMS": [[130, 141], ["nms.bbox_poly2hbb", "nms.py_cpu_nms"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.bbox_poly2hbb", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms"], ["", "def", "obb_HNMS", "(", "dets", ",", "thresh", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    do nms on obbs by corresponding hbbs\n    :param dets: shape (n, 9) (x1, y1, ..., score)\n    :param thresh:\n    :return:\n    \"\"\"", "\n", "h_dets", "=", "bbox_poly2hbb", "(", "dets", ")", "\n", "keep", "=", "py_cpu_nms", "(", "h_dets", ",", "thresh", ")", "\n", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.obb_hybrid_NMS": [[142, 161], ["nms.bbox_poly2hbb", "nms.py_cpu_nms", "numpy.array", "nms.py_cpu_nms_poly_fast"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.bbox_poly2hbb", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly_fast"], ["", "def", "obb_hybrid_NMS", "(", "thresh_obb", ",", "dets", ",", "thresh_hbb", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    do nms on obbs by 1. corresponding hbbs on relative high thresh 2. then nms by obbs on obbs\n    :param dets:\n    :param thresh:\n    :return:\n    \"\"\"", "\n", "# pdb.set_trace()", "\n", "h_dets", "=", "bbox_poly2hbb", "(", "dets", ")", "\n", "h_keep", "=", "py_cpu_nms", "(", "h_dets", ",", "thresh_hbb", ")", "\n", "\n", "h_keep", "=", "np", ".", "array", "(", "h_keep", ")", "\n", "\n", "keeped_o_dets", "=", "dets", "[", "h_keep", ",", ":", "]", "\n", "o_keep", "=", "py_cpu_nms_poly_fast", "(", "keeped_o_dets", ",", "thresh_obb", ")", "\n", "\n", "final_keep", "=", "h_keep", "[", "o_keep", "]", "\n", "\n", "return", "final_keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.results_obb2hbb.parse_args": [[9, 17], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a detector'", ")", "\n", "parser", ".", "add_argument", "(", "r'--path'", ",", "default", "=", "r'/home/dj/code/mmdetection_DOTA/work_dirs/faster_rcnn_r50_fpn_1x_dota_RoITrans_v2/save1_nms2000'", ")", "\n", "# parser.add_argument('--version', default='dota_v1',", "\n", "#                     help='dota version')", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.results_obb2hbb.OBB2HBB": [[18, 38], ["DOTA_devkit.GetFileFromThisRootDir", "os.path.exists", "os.makedirs", "open", "open", "f_in.readlines", "enumerate", "os.path.join", "x.strip().split", "list", "f_out.write", "map", "min", "max", "min", "max", "DOTA_devkit.mybasename", "x.strip", "map", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename"], ["", "def", "OBB2HBB", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "filenames", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dstpath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dstpath", ")", "\n", "", "for", "file", "in", "filenames", ":", "\n", "        ", "with", "open", "(", "file", ",", "'r'", ")", "as", "f_in", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "util", ".", "mybasename", "(", "file", ")", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "                ", "lines", "=", "f_in", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "x", "in", "lines", "]", "\n", "for", "index", ",", "splitline", "in", "enumerate", "(", "splitlines", ")", ":", "\n", "                    ", "imgname", "=", "splitline", "[", "0", "]", "\n", "score", "=", "splitline", "[", "1", "]", "\n", "poly", "=", "splitline", "[", "2", ":", "]", "\n", "poly", "=", "list", "(", "map", "(", "float", ",", "poly", ")", ")", "\n", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "min", "(", "poly", "[", "0", ":", ":", "2", "]", ")", ",", "max", "(", "poly", "[", "0", ":", ":", "2", "]", ")", ",", "min", "(", "poly", "[", "1", ":", ":", "2", "]", ")", ",", "max", "(", "poly", "[", "1", ":", ":", "2", "]", ")", "\n", "rec_poly", "=", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", "\n", "outline", "=", "imgname", "+", "' '", "+", "score", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "rec_poly", ")", ")", "\n", "if", "index", "!=", "(", "len", "(", "splitlines", ")", "-", "1", ")", ":", "\n", "                        ", "outline", "=", "outline", "+", "'\\n'", "\n", "", "f_out", ".", "write", "(", "outline", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.__init__": [[36, 82], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["    ", "def", "__init__", "(", "self", ",", "\n", "basepath", ",", "\n", "outpath", ",", "\n", "code", "=", "'utf-8'", ",", "\n", "gap", "=", "512", ",", "\n", "subsize", "=", "1024", ",", "\n", "thresh", "=", "0.7", ",", "\n", "choosebestpoint", "=", "True", ",", "\n", "ext", "=", "'.png'", ",", "\n", "padding", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param basepath: base path for dota data\n        :param outpath: output base path for dota data,\n        the basepath and outputpath have the similar subdirectory, 'images' and 'labelTxt'\n        :param code: encodeing format of txt file\n        :param gap: overlap between two patches\n        :param subsize: subsize of patch\n        :param thresh: the thresh determine whether to keep the instance if the instance is cut down in the process of split\n        :param choosebestpoint: used to choose the first point for the\n        :param ext: ext for the image format\n        :param padding: if to padding the images so that all the images have the same size\n        \"\"\"", "\n", "self", ".", "basepath", "=", "basepath", "\n", "self", ".", "outpath", "=", "outpath", "\n", "self", ".", "code", "=", "code", "\n", "self", ".", "gap", "=", "gap", "\n", "self", ".", "subsize", "=", "subsize", "\n", "self", ".", "slide", "=", "self", ".", "subsize", "-", "self", ".", "gap", "\n", "self", ".", "thresh", "=", "thresh", "\n", "self", ".", "imagepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'images'", ")", "\n", "self", ".", "labelpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'labelTxt'", ")", "\n", "self", ".", "outimagepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outpath", ",", "'images'", ")", "\n", "self", ".", "outlabelpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outpath", ",", "'labelTxt'", ")", "\n", "self", ".", "choosebestpoint", "=", "choosebestpoint", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "padding", "=", "padding", "\n", "\n", "# pdb.set_trace()", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outpath", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outpath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outimagepath", ")", ":", "\n", "# pdb.set_trace()", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outimagepath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outlabelpath", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outlabelpath", ")", "\n", "# pdb.set_trace()", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.polyorig2sub": [[87, 93], ["numpy.zeros", "range", "len", "int", "int", "int", "len"], "methods", ["None"], ["", "", "def", "polyorig2sub", "(", "self", ",", "left", ",", "up", ",", "poly", ")", ":", "\n", "        ", "polyInsub", "=", "np", ".", "zeros", "(", "len", "(", "poly", ")", ")", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ":", "\n", "            ", "polyInsub", "[", "i", "*", "2", "]", "=", "int", "(", "poly", "[", "i", "*", "2", "]", "-", "left", ")", "\n", "polyInsub", "[", "i", "*", "2", "+", "1", "]", "=", "int", "(", "poly", "[", "i", "*", "2", "+", "1", "]", "-", "up", ")", "\n", "", "return", "polyInsub", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.calchalf_iou": [[94, 103], ["poly1.intersection"], "methods", ["None"], ["", "def", "calchalf_iou", "(", "self", ",", "poly1", ",", "poly2", ")", ":", "\n", "        ", "\"\"\"\n            It is not the iou on usual, the iou is the value of intersection over poly1\n        \"\"\"", "\n", "inter_poly", "=", "poly1", ".", "intersection", "(", "poly2", ")", "\n", "inter_area", "=", "inter_poly", ".", "area", "\n", "poly1_area", "=", "poly1", ".", "area", "\n", "half_iou", "=", "inter_area", "/", "poly1_area", "\n", "return", "inter_poly", ",", "half_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.saveimagepatches": [[104, 114], ["copy.deepcopy", "os.path.join", "numpy.shape", "numpy.zeros", "cv2.imwrite", "cv2.imwrite"], "methods", ["None"], ["", "def", "saveimagepatches", "(", "self", ",", "img", ",", "subimgname", ",", "left", ",", "up", ")", ":", "\n", "        ", "subimg", "=", "copy", ".", "deepcopy", "(", "img", "[", "up", ":", "(", "up", "+", "self", ".", "subsize", ")", ",", "left", ":", "(", "left", "+", "self", ".", "subsize", ")", "]", ")", "\n", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outimagepath", ",", "subimgname", "+", "self", ".", "ext", ")", "\n", "h", ",", "w", ",", "c", "=", "np", ".", "shape", "(", "subimg", ")", "\n", "if", "(", "self", ".", "padding", ")", ":", "\n", "            ", "outimg", "=", "np", ".", "zeros", "(", "(", "self", ".", "subsize", ",", "self", ".", "subsize", ",", "3", ")", ")", "\n", "outimg", "[", "0", ":", "h", ",", "0", ":", "w", ",", ":", "]", "=", "subimg", "\n", "cv2", ".", "imwrite", "(", "outdir", ",", "outimg", ")", "\n", "", "else", ":", "\n", "            ", "cv2", ".", "imwrite", "(", "outdir", ",", "subimg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.GetPoly4FromPoly5": [[115, 136], ["distances.append", "ImgSplit.cal_line_length", "ImgSplit.cal_line_length", "numpy.array().argsort", "range", "outpoly.append", "outpoly.append", "int", "numpy.array", "outpoly.append", "outpoly.append", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "GetPoly4FromPoly5", "(", "self", ",", "poly", ")", ":", "\n", "        ", "distances", "=", "[", "cal_line_length", "(", "(", "poly", "[", "i", "*", "2", "]", ",", "poly", "[", "i", "*", "2", "+", "1", "]", ")", ",", "(", "poly", "[", "(", "i", "+", "1", ")", "*", "2", "]", ",", "poly", "[", "(", "i", "+", "1", ")", "*", "2", "+", "1", "]", ")", ")", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", "-", "1", ")", ")", "]", "\n", "distances", ".", "append", "(", "cal_line_length", "(", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "(", "poly", "[", "8", "]", ",", "poly", "[", "9", "]", ")", ")", ")", "\n", "pos", "=", "np", ".", "array", "(", "distances", ")", ".", "argsort", "(", ")", "[", "0", "]", "\n", "count", "=", "0", "\n", "outpoly", "=", "[", "]", "\n", "while", "count", "<", "5", ":", "\n", "#print('count:', count)", "\n", "            ", "if", "(", "count", "==", "pos", ")", ":", "\n", "                ", "outpoly", ".", "append", "(", "(", "poly", "[", "count", "*", "2", "]", "+", "poly", "[", "(", "count", "*", "2", "+", "2", ")", "%", "10", "]", ")", "/", "2", ")", "\n", "outpoly", ".", "append", "(", "(", "poly", "[", "(", "count", "*", "2", "+", "1", ")", "%", "10", "]", "+", "poly", "[", "(", "count", "*", "2", "+", "3", ")", "%", "10", "]", ")", "/", "2", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "elif", "(", "count", "==", "(", "pos", "+", "1", ")", "%", "5", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "continue", "\n", "\n", "", "else", ":", "\n", "                ", "outpoly", ".", "append", "(", "poly", "[", "count", "*", "2", "]", ")", "\n", "outpoly", ".", "append", "(", "poly", "[", "count", "*", "2", "+", "1", "]", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "return", "outpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.savepatches": [[137, 199], ["os.path.join", "shapely.Polygon", "ImgSplit.splitbase.saveimagepatches", "codecs.open", "shapely.Polygon", "ImgSplit.splitbase.calchalf_iou", "ImgSplit.splitbase.polyorig2sub", "f_out.write", "list", "str", "shapely.polygon.orient", "range", "ImgSplit.splitbase.polyorig2sub", "enumerate", "f_out.write", "map", "list", "len", "len", "choose_best_pointorder_fit_another.append", "choose_best_pointorder_fit_another.append", "len", "ImgSplit.splitbase.GetPoly4FromPoly5", "ImgSplit.choose_best_pointorder_fit_another", "list", "len", "map", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.saveimagepatches", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.calchalf_iou", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.polyorig2sub", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.polyorig2sub", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.GetPoly4FromPoly5", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.choose_best_pointorder_fit_another"], ["", "def", "savepatches", "(", "self", ",", "resizeimg", ",", "objects", ",", "subimgname", ",", "left", ",", "up", ",", "right", ",", "down", ")", ":", "\n", "        ", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outlabelpath", ",", "subimgname", "+", "'.txt'", ")", "\n", "mask_poly", "=", "[", "]", "\n", "imgpoly", "=", "shgeo", ".", "Polygon", "(", "[", "(", "left", ",", "up", ")", ",", "(", "right", ",", "up", ")", ",", "(", "right", ",", "down", ")", ",", "\n", "(", "left", ",", "down", ")", "]", ")", "\n", "with", "codecs", ".", "open", "(", "outdir", ",", "'w'", ",", "self", ".", "code", ")", "as", "f_out", ":", "\n", "            ", "for", "obj", "in", "objects", ":", "\n", "                ", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "[", "(", "obj", "[", "'poly'", "]", "[", "0", "]", ",", "obj", "[", "'poly'", "]", "[", "1", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "2", "]", ",", "obj", "[", "'poly'", "]", "[", "3", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "4", "]", ",", "obj", "[", "'poly'", "]", "[", "5", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "6", "]", ",", "obj", "[", "'poly'", "]", "[", "7", "]", ")", "]", ")", "\n", "if", "(", "gtpoly", ".", "area", "<=", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "inter_poly", ",", "half_iou", "=", "self", ".", "calchalf_iou", "(", "gtpoly", ",", "imgpoly", ")", "\n", "\n", "# print('writing...')", "\n", "if", "(", "half_iou", "==", "1", ")", ":", "\n", "                    ", "polyInsub", "=", "self", ".", "polyorig2sub", "(", "left", ",", "up", ",", "obj", "[", "'poly'", "]", ")", "\n", "outline", "=", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "polyInsub", ")", ")", ")", "\n", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "obj", "[", "'difficult'", "]", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "elif", "(", "half_iou", ">", "0", ")", ":", "\n", "#elif (half_iou > self.thresh):", "\n", "##  print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')", "\n", "                    ", "inter_poly", "=", "shgeo", ".", "polygon", ".", "orient", "(", "inter_poly", ",", "sign", "=", "1", ")", "\n", "out_poly", "=", "list", "(", "inter_poly", ".", "exterior", ".", "coords", ")", "[", "0", ":", "-", "1", "]", "\n", "if", "len", "(", "out_poly", ")", "<", "4", ":", "\n", "                        ", "continue", "\n", "\n", "", "out_poly2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "out_poly", ")", ")", ":", "\n", "                        ", "out_poly2", ".", "append", "(", "out_poly", "[", "i", "]", "[", "0", "]", ")", "\n", "out_poly2", ".", "append", "(", "out_poly", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "", "if", "(", "len", "(", "out_poly", ")", "==", "5", ")", ":", "\n", "#print('==========================')", "\n", "                        ", "out_poly2", "=", "self", ".", "GetPoly4FromPoly5", "(", "out_poly2", ")", "\n", "", "elif", "(", "len", "(", "out_poly", ")", ">", "5", ")", ":", "\n", "                        ", "\"\"\"\n                            if the cut instance is a polygon with points more than 5, we do not handle it currently\n                        \"\"\"", "\n", "continue", "\n", "", "if", "(", "self", ".", "choosebestpoint", ")", ":", "\n", "                        ", "out_poly2", "=", "choose_best_pointorder_fit_another", "(", "out_poly2", ",", "obj", "[", "'poly'", "]", ")", "\n", "\n", "", "polyInsub", "=", "self", ".", "polyorig2sub", "(", "left", ",", "up", ",", "out_poly2", ")", "\n", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "polyInsub", ")", ":", "\n", "                        ", "if", "(", "item", "<=", "1", ")", ":", "\n", "                            ", "polyInsub", "[", "index", "]", "=", "1", "\n", "", "elif", "(", "item", ">=", "self", ".", "subsize", ")", ":", "\n", "                            ", "polyInsub", "[", "index", "]", "=", "self", ".", "subsize", "\n", "", "", "outline", "=", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "polyInsub", ")", ")", ")", "\n", "if", "(", "half_iou", ">", "self", ".", "thresh", ")", ":", "\n", "                        ", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "obj", "[", "'difficult'", "]", ")", "\n", "", "else", ":", "\n", "## if the left part is too small, label as '2'", "\n", "                        ", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "'2'", "\n", "", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "#else:", "\n", "#   mask_poly.append(inter_poly)", "\n", "", "", "", "self", ".", "saveimagepatches", "(", "resizeimg", ",", "subimgname", ",", "left", ",", "up", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.SplitSingle": [[200, 246], ["cv2.imread", "os.path.join", "dota_utils.parse_dota_poly2", "os.path.join", "numpy.shape", "list", "cv2.resize", "numpy.shape", "numpy.shape", "map", "str", "max", "min", "min", "ImgSplit.splitbase.savepatches", "max", "str", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.resize", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.savepatches"], ["", "def", "SplitSingle", "(", "self", ",", "name", ",", "rate", ",", "extent", ")", ":", "\n", "        ", "\"\"\"\n            split a single image and ground truth\n        :param name: image name\n        :param rate: the resize scale for the image\n        :param extent: the image format\n        :return:\n        \"\"\"", "\n", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "imagepath", ",", "name", "+", "extent", ")", ")", "\n", "if", "np", ".", "shape", "(", "img", ")", "==", "(", ")", ":", "\n", "            ", "return", "\n", "", "fullname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "labelpath", ",", "name", "+", "'.txt'", ")", "\n", "objects", "=", "util", ".", "parse_dota_poly2", "(", "fullname", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "lambda", "x", ":", "rate", "*", "x", ",", "obj", "[", "'poly'", "]", ")", ")", "\n", "#obj['poly'] = list(map(lambda x: ([2 * y for y in x]), obj['poly']))", "\n", "\n", "", "if", "(", "rate", "!=", "1", ")", ":", "\n", "            ", "resizeimg", "=", "cv2", ".", "resize", "(", "img", ",", "None", ",", "fx", "=", "rate", ",", "fy", "=", "rate", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "", "else", ":", "\n", "            ", "resizeimg", "=", "img", "\n", "", "outbasename", "=", "name", "+", "'__'", "+", "str", "(", "rate", ")", "+", "'__'", "\n", "weight", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "1", "]", "\n", "height", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "0", "]", "\n", "\n", "left", ",", "up", "=", "0", ",", "0", "\n", "while", "(", "left", "<", "weight", ")", ":", "\n", "            ", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "left", "=", "max", "(", "weight", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "up", "=", "0", "\n", "while", "(", "up", "<", "height", ")", ":", "\n", "                ", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "up", "=", "max", "(", "height", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "right", "=", "min", "(", "left", "+", "self", ".", "subsize", ",", "weight", "-", "1", ")", "\n", "down", "=", "min", "(", "up", "+", "self", ".", "subsize", ",", "height", "-", "1", ")", "\n", "subimgname", "=", "outbasename", "+", "str", "(", "left", ")", "+", "'___'", "+", "str", "(", "up", ")", "\n", "# self.f_sub.write(name + ' ' + subimgname + ' ' + str(left) + ' ' + str(up) + '\\n')", "\n", "self", ".", "savepatches", "(", "resizeimg", ",", "objects", ",", "subimgname", ",", "left", ",", "up", ",", "right", ",", "down", ")", "\n", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "up", "=", "up", "+", "self", ".", "slide", "\n", "", "", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "left", "=", "left", "+", "self", ".", "slide", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.splitbase.splitdata": [[247, 256], ["dota_utils.GetFileFromThisRootDir", "dota_utils.custombasename", "ImgSplit.splitbase.SplitSingle", "dota_utils.custombasename"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.SplitSingle", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "", "", "def", "splitdata", "(", "self", ",", "rate", ")", ":", "\n", "        ", "\"\"\"\n        :param rate: resize rate before cut\n        \"\"\"", "\n", "\n", "imagelist", "=", "GetFileFromThisRootDir", "(", "self", ".", "imagepath", ")", "\n", "imagenames", "=", "[", "util", ".", "custombasename", "(", "x", ")", "for", "x", "in", "imagelist", "if", "(", "util", ".", "custombasename", "(", "x", ")", "!=", "'Thumbs'", ")", "]", "\n", "for", "name", "in", "imagenames", ":", "\n", "            ", "self", ".", "SplitSingle", "(", "name", ",", "rate", ",", "self", ".", "ext", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.choose_best_pointorder_fit_another": [[11, 29], ["numpy.array", "numpy.array", "np.array.argsort", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.sum"], "function", ["None"], ["def", "choose_best_pointorder_fit_another", "(", "poly1", ",", "poly2", ")", ":", "\n", "    ", "\"\"\"\n        To make the two polygons best fit with each point\n    \"\"\"", "\n", "x1", "=", "poly1", "[", "0", "]", "\n", "y1", "=", "poly1", "[", "1", "]", "\n", "x2", "=", "poly1", "[", "2", "]", "\n", "y2", "=", "poly1", "[", "3", "]", "\n", "x3", "=", "poly1", "[", "4", "]", "\n", "y3", "=", "poly1", "[", "5", "]", "\n", "x4", "=", "poly1", "[", "6", "]", "\n", "y4", "=", "poly1", "[", "7", "]", "\n", "combinate", "=", "[", "np", ".", "array", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "]", ")", ",", "np", ".", "array", "(", "[", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", ",", "x1", ",", "y1", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "x3", ",", "y3", ",", "x4", ",", "y4", ",", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ")", ",", "np", ".", "array", "(", "[", "x4", ",", "y4", ",", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", "]", ")", "]", "\n", "dst_coordinate", "=", "np", ".", "array", "(", "poly2", ")", "\n", "distances", "=", "np", ".", "array", "(", "[", "np", ".", "sum", "(", "(", "coord", "-", "dst_coordinate", ")", "**", "2", ")", "for", "coord", "in", "combinate", "]", ")", "\n", "sorted", "=", "distances", ".", "argsort", "(", ")", "\n", "return", "combinate", "[", "sorted", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit.cal_line_length": [[30, 32], ["math.sqrt", "math.pow", "math.pow"], "function", ["None"], ["", "def", "cal_line_length", "(", "point1", ",", "point2", ")", ":", "\n", "    ", "return", "math", ".", "sqrt", "(", "math", ".", "pow", "(", "point1", "[", "0", "]", "-", "point2", "[", "0", "]", ",", "2", ")", "+", "math", ".", "pow", "(", "point1", "[", "1", "]", "-", "point2", "[", "1", "]", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage.splitbase.__init__": [[8, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "srcpath", ",", "\n", "dstpath", ",", "\n", "gap", "=", "100", ",", "\n", "subsize", "=", "1024", ",", "\n", "ext", "=", "'.png'", ")", ":", "\n", "        ", "self", ".", "srcpath", "=", "srcpath", "\n", "self", ".", "outpath", "=", "dstpath", "\n", "self", ".", "gap", "=", "gap", "\n", "self", ".", "subsize", "=", "subsize", "\n", "self", ".", "slide", "=", "self", ".", "subsize", "-", "self", ".", "gap", "\n", "self", ".", "srcpath", "=", "srcpath", "\n", "self", ".", "dstpath", "=", "dstpath", "\n", "self", ".", "ext", "=", "ext", "\n", "", "def", "saveimagepatches", "(", "self", ",", "img", ",", "subimgname", ",", "left", ",", "up", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage.splitbase.saveimagepatches": [[22, 26], ["copy.deepcopy", "os.path.join", "cv2.imwrite"], "methods", ["None"], ["", "def", "saveimagepatches", "(", "self", ",", "img", ",", "subimgname", ",", "left", ",", "up", ")", ":", "\n", "        ", "subimg", "=", "copy", ".", "deepcopy", "(", "img", "[", "up", ":", "(", "up", "+", "self", ".", "subsize", ")", ",", "left", ":", "(", "left", "+", "self", ".", "subsize", ")", "]", ")", "\n", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dstpath", ",", "subimgname", "+", "self", ".", "ext", ")", "\n", "cv2", ".", "imwrite", "(", "outdir", ",", "subimg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage.splitbase.SplitSingle": [[27, 58], ["cv2.imread", "os.path.join", "numpy.shape", "cv2.resize", "numpy.shape", "numpy.shape", "str", "max", "SplitOnlyImage.splitbase.saveimagepatches", "max", "str", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.resize", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.saveimagepatches"], ["", "def", "SplitSingle", "(", "self", ",", "name", ",", "rate", ",", "extent", ")", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "srcpath", ",", "name", "+", "extent", ")", ",", "cv2", ".", "IMREAD_UNCHANGED", ")", "\n", "assert", "np", ".", "shape", "(", "img", ")", "!=", "(", ")", "\n", "\n", "if", "(", "rate", "!=", "1", ")", ":", "\n", "            ", "resizeimg", "=", "cv2", ".", "resize", "(", "img", ",", "None", ",", "fx", "=", "rate", ",", "fy", "=", "rate", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "", "else", ":", "\n", "            ", "resizeimg", "=", "img", "\n", "", "outbasename", "=", "name", "+", "'__'", "+", "str", "(", "rate", ")", "+", "'__'", "\n", "\n", "weight", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "1", "]", "\n", "height", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "0", "]", "\n", "\n", "left", ",", "up", "=", "0", ",", "0", "\n", "while", "(", "left", "<", "weight", ")", ":", "\n", "            ", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "left", "=", "max", "(", "weight", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "up", "=", "0", "\n", "while", "(", "up", "<", "height", ")", ":", "\n", "                ", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "up", "=", "max", "(", "height", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "subimgname", "=", "outbasename", "+", "str", "(", "left", ")", "+", "'___'", "+", "str", "(", "up", ")", "\n", "self", ".", "saveimagepatches", "(", "resizeimg", ",", "subimgname", ",", "left", ",", "up", ")", "\n", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "up", "=", "up", "+", "self", ".", "slide", "\n", "", "", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "left", "=", "left", "+", "self", ".", "slide", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage.splitbase.splitdata": [[59, 65], ["dota_utils.GetFileFromThisRootDir", "dota_utils.custombasename", "SplitOnlyImage.splitbase.SplitSingle", "dota_utils.custombasename"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.SplitSingle", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "", "", "def", "splitdata", "(", "self", ",", "rate", ")", ":", "\n", "\n", "        ", "imagelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "self", ".", "srcpath", ")", "\n", "imagenames", "=", "[", "util", ".", "custombasename", "(", "x", ")", "for", "x", "in", "imagelist", "if", "(", "util", ".", "custombasename", "(", "x", ")", "!=", "'Thumbs'", ")", "]", "\n", "for", "name", "in", "imagenames", ":", "\n", "            ", "self", ".", "SplitSingle", "(", "name", ",", "rate", ",", "self", ".", "ext", ")", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.__init__": [[43, 92], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "multiprocessing.Pool", "print", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["    ", "def", "__init__", "(", "self", ",", "\n", "basepath", ",", "\n", "outpath", ",", "\n", "code", "=", "'utf-8'", ",", "\n", "gap", "=", "512", ",", "\n", "subsize", "=", "1024", ",", "\n", "thresh", "=", "0.7", ",", "\n", "choosebestpoint", "=", "True", ",", "\n", "ext", "=", "'.png'", ",", "\n", "padding", "=", "True", ",", "\n", "num_process", "=", "8", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param basepath: base path for dota data\n        :param outpath: output base path for dota data,\n        the basepath and outputpath have the similar subdirectory, 'images' and 'labelTxt'\n        :param code: encodeing format of txt file\n        :param gap: overlap between two patches\n        :param subsize: subsize of patch\n        :param thresh: the thresh determine whether to keep the instance if the instance is cut down in the process of split\n        :param choosebestpoint: used to choose the first point for the\n        :param ext: ext for the image format\n        :param padding: if to padding the images so that all the images have the same size\n        \"\"\"", "\n", "self", ".", "basepath", "=", "basepath", "\n", "self", ".", "outpath", "=", "outpath", "\n", "self", ".", "code", "=", "code", "\n", "self", ".", "gap", "=", "gap", "\n", "self", ".", "subsize", "=", "subsize", "\n", "self", ".", "slide", "=", "self", ".", "subsize", "-", "self", ".", "gap", "\n", "self", ".", "thresh", "=", "thresh", "\n", "self", ".", "imagepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'images'", ")", "\n", "self", ".", "labelpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'labelTxt'", ")", "\n", "self", ".", "outimagepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outpath", ",", "'images'", ")", "\n", "self", ".", "outlabelpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outpath", ",", "'labelTxt'", ")", "\n", "self", ".", "choosebestpoint", "=", "choosebestpoint", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "pool", "=", "Pool", "(", "num_process", ")", "\n", "print", "(", "'padding:'", ",", "padding", ")", "\n", "\n", "# pdb.set_trace()", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outpath", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outpath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outimagepath", ")", ":", "\n", "# pdb.set_trace()", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outimagepath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outlabelpath", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outlabelpath", ")", "\n", "# pdb.set_trace()", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.polyorig2sub": [[97, 103], ["numpy.zeros", "range", "len", "int", "int", "int", "len"], "methods", ["None"], ["", "", "def", "polyorig2sub", "(", "self", ",", "left", ",", "up", ",", "poly", ")", ":", "\n", "        ", "polyInsub", "=", "np", ".", "zeros", "(", "len", "(", "poly", ")", ")", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ":", "\n", "            ", "polyInsub", "[", "i", "*", "2", "]", "=", "int", "(", "poly", "[", "i", "*", "2", "]", "-", "left", ")", "\n", "polyInsub", "[", "i", "*", "2", "+", "1", "]", "=", "int", "(", "poly", "[", "i", "*", "2", "+", "1", "]", "-", "up", ")", "\n", "", "return", "polyInsub", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.calchalf_iou": [[104, 113], ["poly1.intersection"], "methods", ["None"], ["", "def", "calchalf_iou", "(", "self", ",", "poly1", ",", "poly2", ")", ":", "\n", "        ", "\"\"\"\n            It is not the iou on usual, the iou is the value of intersection over poly1\n        \"\"\"", "\n", "inter_poly", "=", "poly1", ".", "intersection", "(", "poly2", ")", "\n", "inter_area", "=", "inter_poly", ".", "area", "\n", "poly1_area", "=", "poly1", ".", "area", "\n", "half_iou", "=", "inter_area", "/", "poly1_area", "\n", "return", "inter_poly", ",", "half_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.saveimagepatches": [[114, 124], ["copy.deepcopy", "os.path.join", "numpy.shape", "numpy.zeros", "cv2.imwrite", "cv2.imwrite"], "methods", ["None"], ["", "def", "saveimagepatches", "(", "self", ",", "img", ",", "subimgname", ",", "left", ",", "up", ")", ":", "\n", "        ", "subimg", "=", "copy", ".", "deepcopy", "(", "img", "[", "up", ":", "(", "up", "+", "self", ".", "subsize", ")", ",", "left", ":", "(", "left", "+", "self", ".", "subsize", ")", "]", ")", "\n", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outimagepath", ",", "subimgname", "+", "self", ".", "ext", ")", "\n", "h", ",", "w", ",", "c", "=", "np", ".", "shape", "(", "subimg", ")", "\n", "if", "(", "self", ".", "padding", ")", ":", "\n", "            ", "outimg", "=", "np", ".", "zeros", "(", "(", "self", ".", "subsize", ",", "self", ".", "subsize", ",", "3", ")", ")", "\n", "outimg", "[", "0", ":", "h", ",", "0", ":", "w", ",", ":", "]", "=", "subimg", "\n", "cv2", ".", "imwrite", "(", "outdir", ",", "outimg", ")", "\n", "", "else", ":", "\n", "            ", "cv2", ".", "imwrite", "(", "outdir", ",", "subimg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.GetPoly4FromPoly5": [[125, 146], ["distances.append", "ImgSplit_multi_process.cal_line_length", "ImgSplit_multi_process.cal_line_length", "numpy.array().argsort", "range", "outpoly.append", "outpoly.append", "int", "numpy.array", "outpoly.append", "outpoly.append", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "GetPoly4FromPoly5", "(", "self", ",", "poly", ")", ":", "\n", "        ", "distances", "=", "[", "cal_line_length", "(", "(", "poly", "[", "i", "*", "2", "]", ",", "poly", "[", "i", "*", "2", "+", "1", "]", ")", ",", "(", "poly", "[", "(", "i", "+", "1", ")", "*", "2", "]", ",", "poly", "[", "(", "i", "+", "1", ")", "*", "2", "+", "1", "]", ")", ")", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", "-", "1", ")", ")", "]", "\n", "distances", ".", "append", "(", "cal_line_length", "(", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "(", "poly", "[", "8", "]", ",", "poly", "[", "9", "]", ")", ")", ")", "\n", "pos", "=", "np", ".", "array", "(", "distances", ")", ".", "argsort", "(", ")", "[", "0", "]", "\n", "count", "=", "0", "\n", "outpoly", "=", "[", "]", "\n", "while", "count", "<", "5", ":", "\n", "#print('count:', count)", "\n", "            ", "if", "(", "count", "==", "pos", ")", ":", "\n", "                ", "outpoly", ".", "append", "(", "(", "poly", "[", "count", "*", "2", "]", "+", "poly", "[", "(", "count", "*", "2", "+", "2", ")", "%", "10", "]", ")", "/", "2", ")", "\n", "outpoly", ".", "append", "(", "(", "poly", "[", "(", "count", "*", "2", "+", "1", ")", "%", "10", "]", "+", "poly", "[", "(", "count", "*", "2", "+", "3", ")", "%", "10", "]", ")", "/", "2", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "elif", "(", "count", "==", "(", "pos", "+", "1", ")", "%", "5", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "continue", "\n", "\n", "", "else", ":", "\n", "                ", "outpoly", ".", "append", "(", "poly", "[", "count", "*", "2", "]", ")", "\n", "outpoly", ".", "append", "(", "poly", "[", "count", "*", "2", "+", "1", "]", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "return", "outpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.savepatches": [[147, 209], ["os.path.join", "shapely.Polygon", "ImgSplit_multi_process.splitbase.saveimagepatches", "codecs.open", "shapely.Polygon", "ImgSplit_multi_process.splitbase.calchalf_iou", "ImgSplit_multi_process.splitbase.polyorig2sub", "f_out.write", "list", "str", "shapely.polygon.orient", "range", "ImgSplit_multi_process.splitbase.polyorig2sub", "enumerate", "f_out.write", "map", "list", "len", "len", "choose_best_pointorder_fit_another.append", "choose_best_pointorder_fit_another.append", "len", "ImgSplit_multi_process.splitbase.GetPoly4FromPoly5", "ImgSplit_multi_process.choose_best_pointorder_fit_another", "list", "len", "map", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.saveimagepatches", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.calchalf_iou", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.polyorig2sub", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.polyorig2sub", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.GetPoly4FromPoly5", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.choose_best_pointorder_fit_another"], ["", "def", "savepatches", "(", "self", ",", "resizeimg", ",", "objects", ",", "subimgname", ",", "left", ",", "up", ",", "right", ",", "down", ")", ":", "\n", "        ", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "outlabelpath", ",", "subimgname", "+", "'.txt'", ")", "\n", "mask_poly", "=", "[", "]", "\n", "imgpoly", "=", "shgeo", ".", "Polygon", "(", "[", "(", "left", ",", "up", ")", ",", "(", "right", ",", "up", ")", ",", "(", "right", ",", "down", ")", ",", "\n", "(", "left", ",", "down", ")", "]", ")", "\n", "with", "codecs", ".", "open", "(", "outdir", ",", "'w'", ",", "self", ".", "code", ")", "as", "f_out", ":", "\n", "            ", "for", "obj", "in", "objects", ":", "\n", "                ", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "[", "(", "obj", "[", "'poly'", "]", "[", "0", "]", ",", "obj", "[", "'poly'", "]", "[", "1", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "2", "]", ",", "obj", "[", "'poly'", "]", "[", "3", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "4", "]", ",", "obj", "[", "'poly'", "]", "[", "5", "]", ")", ",", "\n", "(", "obj", "[", "'poly'", "]", "[", "6", "]", ",", "obj", "[", "'poly'", "]", "[", "7", "]", ")", "]", ")", "\n", "if", "(", "gtpoly", ".", "area", "<=", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "inter_poly", ",", "half_iou", "=", "self", ".", "calchalf_iou", "(", "gtpoly", ",", "imgpoly", ")", "\n", "\n", "# print('writing...')", "\n", "if", "(", "half_iou", "==", "1", ")", ":", "\n", "                    ", "polyInsub", "=", "self", ".", "polyorig2sub", "(", "left", ",", "up", ",", "obj", "[", "'poly'", "]", ")", "\n", "outline", "=", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "polyInsub", ")", ")", ")", "\n", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "obj", "[", "'difficult'", "]", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "elif", "(", "half_iou", ">", "0", ")", ":", "\n", "#elif (half_iou > self.thresh):", "\n", "##  print('<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<')", "\n", "                    ", "inter_poly", "=", "shgeo", ".", "polygon", ".", "orient", "(", "inter_poly", ",", "sign", "=", "1", ")", "\n", "out_poly", "=", "list", "(", "inter_poly", ".", "exterior", ".", "coords", ")", "[", "0", ":", "-", "1", "]", "\n", "if", "len", "(", "out_poly", ")", "<", "4", ":", "\n", "                        ", "continue", "\n", "\n", "", "out_poly2", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "out_poly", ")", ")", ":", "\n", "                        ", "out_poly2", ".", "append", "(", "out_poly", "[", "i", "]", "[", "0", "]", ")", "\n", "out_poly2", ".", "append", "(", "out_poly", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "", "if", "(", "len", "(", "out_poly", ")", "==", "5", ")", ":", "\n", "#print('==========================')", "\n", "                        ", "out_poly2", "=", "self", ".", "GetPoly4FromPoly5", "(", "out_poly2", ")", "\n", "", "elif", "(", "len", "(", "out_poly", ")", ">", "5", ")", ":", "\n", "                        ", "\"\"\"\n                            if the cut instance is a polygon with points more than 5, we do not handle it currently\n                        \"\"\"", "\n", "continue", "\n", "", "if", "(", "self", ".", "choosebestpoint", ")", ":", "\n", "                        ", "out_poly2", "=", "choose_best_pointorder_fit_another", "(", "out_poly2", ",", "obj", "[", "'poly'", "]", ")", "\n", "\n", "", "polyInsub", "=", "self", ".", "polyorig2sub", "(", "left", ",", "up", ",", "out_poly2", ")", "\n", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "polyInsub", ")", ":", "\n", "                        ", "if", "(", "item", "<=", "1", ")", ":", "\n", "                            ", "polyInsub", "[", "index", "]", "=", "1", "\n", "", "elif", "(", "item", ">=", "self", ".", "subsize", ")", ":", "\n", "                            ", "polyInsub", "[", "index", "]", "=", "self", ".", "subsize", "\n", "", "", "outline", "=", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "polyInsub", ")", ")", ")", "\n", "if", "(", "half_iou", ">", "self", ".", "thresh", ")", ":", "\n", "                        ", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "obj", "[", "'difficult'", "]", ")", "\n", "", "else", ":", "\n", "## if the left part is too small, label as '2'", "\n", "                        ", "outline", "=", "outline", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "'2'", "\n", "", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "#else:", "\n", "#   mask_poly.append(inter_poly)", "\n", "", "", "", "self", ".", "saveimagepatches", "(", "resizeimg", ",", "subimgname", ",", "left", ",", "up", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.SplitSingle": [[210, 263], ["os.path.join", "dota_utils.parse_dota_poly2", "cv2.imread", "print", "numpy.shape", "list", "cv2.resize", "numpy.shape", "numpy.shape", "os.path.join", "print", "map", "str", "max", "min", "min", "ImgSplit_multi_process.splitbase.savepatches", "max", "str", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.resize", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.savepatches"], ["", "def", "SplitSingle", "(", "self", ",", "name", ",", "rate", ",", "extent", ")", ":", "\n", "        ", "\"\"\"\n            split a single image and ground truth\n        :param name: image name\n        :param rate: the resize scale for the image\n        :param extent: the image format\n        :return:\n        \"\"\"", "\n", "try", ":", "\n", "            ", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "imagepath", ",", "name", "+", "extent", ")", ")", "\n", "print", "(", "'img name:'", ",", "name", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'img name:'", ",", "name", ")", "\n", "", "if", "np", ".", "shape", "(", "img", ")", "==", "(", ")", ":", "\n", "            ", "return", "\n", "", "fullname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "labelpath", ",", "name", "+", "'.txt'", ")", "\n", "objects", "=", "util", ".", "parse_dota_poly2", "(", "fullname", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "lambda", "x", ":", "rate", "*", "x", ",", "obj", "[", "'poly'", "]", ")", ")", "\n", "#obj['poly'] = list(map(lambda x: ([2 * y for y in x]), obj['poly']))", "\n", "\n", "", "if", "(", "rate", "!=", "1", ")", ":", "\n", "            ", "resizeimg", "=", "cv2", ".", "resize", "(", "img", ",", "None", ",", "fx", "=", "rate", ",", "fy", "=", "rate", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "", "else", ":", "\n", "            ", "resizeimg", "=", "img", "\n", "", "outbasename", "=", "name", "+", "'__'", "+", "str", "(", "rate", ")", "+", "'__'", "\n", "weight", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "1", "]", "\n", "height", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "0", "]", "\n", "\n", "# if (max(weight, height) < self.subsize):", "\n", "#     return", "\n", "\n", "left", ",", "up", "=", "0", ",", "0", "\n", "while", "(", "left", "<", "weight", ")", ":", "\n", "            ", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "left", "=", "max", "(", "weight", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "up", "=", "0", "\n", "while", "(", "up", "<", "height", ")", ":", "\n", "                ", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "up", "=", "max", "(", "height", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "right", "=", "min", "(", "left", "+", "self", ".", "subsize", ",", "weight", "-", "1", ")", "\n", "down", "=", "min", "(", "up", "+", "self", ".", "subsize", ",", "height", "-", "1", ")", "\n", "subimgname", "=", "outbasename", "+", "str", "(", "left", ")", "+", "'___'", "+", "str", "(", "up", ")", "\n", "# self.f_sub.write(name + ' ' + subimgname + ' ' + str(left) + ' ' + str(up) + '\\n')", "\n", "self", ".", "savepatches", "(", "resizeimg", ",", "objects", ",", "subimgname", ",", "left", ",", "up", ",", "right", ",", "down", ")", "\n", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "up", "=", "up", "+", "self", ".", "slide", "\n", "", "", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "left", "=", "left", "+", "self", ".", "slide", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.splitdata": [[264, 277], ["dota_utils.GetFileFromThisRootDir", "functools.partial", "ImgSplit_multi_process.splitbase.pool.map", "dota_utils.custombasename", "dota_utils.custombasename"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "", "", "def", "splitdata", "(", "self", ",", "rate", ")", ":", "\n", "        ", "\"\"\"\n        :param rate: resize rate before cut\n        \"\"\"", "\n", "\n", "imagelist", "=", "GetFileFromThisRootDir", "(", "self", ".", "imagepath", ")", "\n", "imagenames", "=", "[", "util", ".", "custombasename", "(", "x", ")", "for", "x", "in", "imagelist", "if", "(", "util", ".", "custombasename", "(", "x", ")", "!=", "'Thumbs'", ")", "]", "\n", "\n", "worker", "=", "partial", "(", "self", ".", "SplitSingle", ",", "rate", "=", "rate", ",", "extent", "=", "self", ".", "ext", ")", "\n", "#", "\n", "# for name in imagenames:", "\n", "#     self.SplitSingle(name, rate, self.ext)", "\n", "self", ".", "pool", ".", "map", "(", "worker", ",", "imagenames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.__getstate__": [[278, 282], ["ImgSplit_multi_process.splitbase.__dict__.copy"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "self_dict", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "del", "self_dict", "[", "'pool'", "]", "\n", "return", "self_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.splitbase.__setstate__": [[283, 285], ["ImgSplit_multi_process.splitbase.__dict__.update"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.choose_best_pointorder_fit_another": [[18, 36], ["numpy.array", "numpy.array", "np.array.argsort", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.sum"], "function", ["None"], ["def", "choose_best_pointorder_fit_another", "(", "poly1", ",", "poly2", ")", ":", "\n", "    ", "\"\"\"\n        To make the two polygons best fit with each point\n    \"\"\"", "\n", "x1", "=", "poly1", "[", "0", "]", "\n", "y1", "=", "poly1", "[", "1", "]", "\n", "x2", "=", "poly1", "[", "2", "]", "\n", "y2", "=", "poly1", "[", "3", "]", "\n", "x3", "=", "poly1", "[", "4", "]", "\n", "y3", "=", "poly1", "[", "5", "]", "\n", "x4", "=", "poly1", "[", "6", "]", "\n", "y4", "=", "poly1", "[", "7", "]", "\n", "combinate", "=", "[", "np", ".", "array", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "]", ")", ",", "np", ".", "array", "(", "[", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", ",", "x1", ",", "y1", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "x3", ",", "y3", ",", "x4", ",", "y4", ",", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ")", ",", "np", ".", "array", "(", "[", "x4", ",", "y4", ",", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", "]", ")", "]", "\n", "dst_coordinate", "=", "np", ".", "array", "(", "poly2", ")", "\n", "distances", "=", "np", ".", "array", "(", "[", "np", ".", "sum", "(", "(", "coord", "-", "dst_coordinate", ")", "**", "2", ")", "for", "coord", "in", "combinate", "]", ")", "\n", "sorted", "=", "distances", ".", "argsort", "(", ")", "\n", "return", "combinate", "[", "sorted", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ImgSplit_multi_process.cal_line_length": [[37, 39], ["math.sqrt", "math.pow", "math.pow"], "function", ["None"], ["", "def", "cal_line_length", "(", "point1", ",", "point2", ")", ":", "\n", "    ", "return", "math", ".", "sqrt", "(", "math", ".", "pow", "(", "point1", "[", "0", "]", "-", "point2", "[", "0", "]", ",", "2", ")", "+", "math", ".", "pow", "(", "point1", "[", "1", "]", "-", "point2", "[", "1", "]", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.__init__": [[10, 31], ["multiprocessing.Pool", "os.path.isdir", "os.mkdir"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["    ", "def", "__init__", "(", "self", ",", "\n", "srcpath", ",", "\n", "dstpath", ",", "\n", "gap", "=", "100", ",", "\n", "subsize", "=", "1024", ",", "\n", "ext", "=", "'.png'", ",", "\n", "padding", "=", "True", ",", "\n", "num_process", "=", "32", ")", ":", "\n", "        ", "self", ".", "srcpath", "=", "srcpath", "\n", "self", ".", "outpath", "=", "dstpath", "\n", "self", ".", "gap", "=", "gap", "\n", "self", ".", "subsize", "=", "subsize", "\n", "self", ".", "slide", "=", "self", ".", "subsize", "-", "self", ".", "gap", "\n", "self", ".", "srcpath", "=", "srcpath", "\n", "self", ".", "dstpath", "=", "dstpath", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "pool", "=", "Pool", "(", "num_process", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "outpath", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "outpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.saveimagepatches": [[32, 42], ["copy.deepcopy", "os.path.join", "numpy.shape", "numpy.zeros", "cv2.imwrite", "cv2.imwrite"], "methods", ["None"], ["", "", "def", "saveimagepatches", "(", "self", ",", "img", ",", "subimgname", ",", "left", ",", "up", ",", "ext", "=", "'.png'", ")", ":", "\n", "        ", "subimg", "=", "copy", ".", "deepcopy", "(", "img", "[", "up", ":", "(", "up", "+", "self", ".", "subsize", ")", ",", "left", ":", "(", "left", "+", "self", ".", "subsize", ")", "]", ")", "\n", "outdir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dstpath", ",", "subimgname", "+", "ext", ")", "\n", "h", ",", "w", ",", "c", "=", "np", ".", "shape", "(", "subimg", ")", "\n", "if", "(", "self", ".", "padding", ")", ":", "\n", "            ", "outimg", "=", "np", ".", "zeros", "(", "(", "self", ".", "subsize", ",", "self", ".", "subsize", ",", "3", ")", ")", "\n", "outimg", "[", "0", ":", "h", ",", "0", ":", "w", ",", ":", "]", "=", "subimg", "\n", "cv2", ".", "imwrite", "(", "outdir", ",", "outimg", ")", "\n", "", "else", ":", "\n", "            ", "cv2", ".", "imwrite", "(", "outdir", ",", "subimg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.SplitSingle": [[43, 77], ["cv2.imread", "os.path.join", "numpy.shape", "cv2.resize", "numpy.shape", "numpy.shape", "str", "max", "SplitOnlyImage_multi_process.splitbase.saveimagepatches", "max", "str", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.resize", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.saveimagepatches"], ["", "", "def", "SplitSingle", "(", "self", ",", "name", ",", "rate", ",", "extent", ")", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "srcpath", ",", "name", "+", "extent", ")", ")", "\n", "assert", "np", ".", "shape", "(", "img", ")", "!=", "(", ")", "\n", "\n", "if", "(", "rate", "!=", "1", ")", ":", "\n", "            ", "resizeimg", "=", "cv2", ".", "resize", "(", "img", ",", "None", ",", "fx", "=", "rate", ",", "fy", "=", "rate", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "", "else", ":", "\n", "            ", "resizeimg", "=", "img", "\n", "", "outbasename", "=", "name", "+", "'__'", "+", "str", "(", "rate", ")", "+", "'__'", "\n", "\n", "weight", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "1", "]", "\n", "height", "=", "np", ".", "shape", "(", "resizeimg", ")", "[", "0", "]", "\n", "\n", "# if (max(weight, height) < self.subsize/2):", "\n", "#     return", "\n", "\n", "left", ",", "up", "=", "0", ",", "0", "\n", "while", "(", "left", "<", "weight", ")", ":", "\n", "            ", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "left", "=", "max", "(", "weight", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "up", "=", "0", "\n", "while", "(", "up", "<", "height", ")", ":", "\n", "                ", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "up", "=", "max", "(", "height", "-", "self", ".", "subsize", ",", "0", ")", "\n", "", "subimgname", "=", "outbasename", "+", "str", "(", "left", ")", "+", "'___'", "+", "str", "(", "up", ")", "\n", "self", ".", "saveimagepatches", "(", "resizeimg", ",", "subimgname", ",", "left", ",", "up", ")", "\n", "if", "(", "up", "+", "self", ".", "subsize", ">=", "height", ")", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "up", "=", "up", "+", "self", ".", "slide", "\n", "", "", "if", "(", "left", "+", "self", ".", "subsize", ">=", "weight", ")", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "left", "=", "left", "+", "self", ".", "slide", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.splitdata": [[78, 86], ["dota_utils.GetFileFromThisRootDir", "functools.partial", "SplitOnlyImage_multi_process.splitbase.pool.map", "dota_utils.custombasename", "dota_utils.custombasename"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "", "", "def", "splitdata", "(", "self", ",", "rate", ")", ":", "\n", "\n", "        ", "imagelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "self", ".", "srcpath", ")", "\n", "imagenames", "=", "[", "util", ".", "custombasename", "(", "x", ")", "for", "x", "in", "imagelist", "if", "(", "util", ".", "custombasename", "(", "x", ")", "!=", "'Thumbs'", ")", "]", "\n", "\n", "worker", "=", "partial", "(", "self", ".", "SplitSingle", ",", "rate", "=", "rate", ",", "extent", "=", "self", ".", "ext", ")", "\n", "\n", "self", ".", "pool", ".", "map", "(", "worker", ",", "imagenames", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.__getstate__": [[89, 93], ["SplitOnlyImage_multi_process.splitbase.__dict__.copy"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "self_dict", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "del", "self_dict", "[", "'pool'", "]", "\n", "return", "self_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.__setstate__": [[94, 96], ["SplitOnlyImage_multi_process.splitbase.__dict__.update"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__init__": [[99, 101], ["AttributeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "AttributeError", "(", "\"No constructor defined - class is abstract\"", ")", "\n", "", "__repr__", "=", "_swig_repr", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.value": [[105, 107], ["_polyiou.SwigPyIterator_value"], "methods", ["None"], ["def", "value", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_value", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.incr": [[108, 110], ["_polyiou.SwigPyIterator_incr"], "methods", ["None"], ["", "def", "incr", "(", "self", ",", "n", "=", "1", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_incr", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.decr": [[111, 113], ["_polyiou.SwigPyIterator_decr"], "methods", ["None"], ["", "def", "decr", "(", "self", ",", "n", "=", "1", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_decr", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.distance": [[114, 116], ["_polyiou.SwigPyIterator_distance"], "methods", ["None"], ["", "def", "distance", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_distance", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.equal": [[117, 119], ["_polyiou.SwigPyIterator_equal"], "methods", ["None"], ["", "def", "equal", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_equal", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy": [[120, 122], ["_polyiou.SwigPyIterator_copy"], "methods", ["None"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_copy", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.next": [[123, 125], ["_polyiou.SwigPyIterator_next"], "methods", ["None"], ["", "def", "next", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_next", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__next__": [[126, 128], ["_polyiou.SwigPyIterator___next__"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___next__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.previous": [[129, 131], ["_polyiou.SwigPyIterator_previous"], "methods", ["None"], ["", "def", "previous", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_previous", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.advance": [[132, 134], ["_polyiou.SwigPyIterator_advance"], "methods", ["None"], ["", "def", "advance", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator_advance", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__eq__": [[135, 137], ["_polyiou.SwigPyIterator___eq__"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___eq__", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__ne__": [[138, 140], ["_polyiou.SwigPyIterator___ne__"], "methods", ["None"], ["", "def", "__ne__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___ne__", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__iadd__": [[141, 143], ["_polyiou.SwigPyIterator___iadd__"], "methods", ["None"], ["", "def", "__iadd__", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___iadd__", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__isub__": [[144, 146], ["_polyiou.SwigPyIterator___isub__"], "methods", ["None"], ["", "def", "__isub__", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___isub__", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__add__": [[147, 149], ["_polyiou.SwigPyIterator___add__"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___add__", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__sub__": [[150, 152], ["_polyiou.SwigPyIterator___sub__"], "methods", ["None"], ["", "def", "__sub__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "SwigPyIterator___sub__", "(", "self", ",", "*", "args", ")", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.__iter__": [[152, 154], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "", "", "SwigPyIterator_swigregister", "=", "_polyiou", ".", "SwigPyIterator_swigregister", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.iterator": [[164, 166], ["_polyiou.VectorDouble_iterator"], "methods", ["None"], ["def", "iterator", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_iterator", "(", "self", ")", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__iter__": [[166, 168], ["polyiou.VectorDouble.iterator"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "iterator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__nonzero__": [[169, 171], ["_polyiou.VectorDouble___nonzero__"], "methods", ["None"], ["", "def", "__nonzero__", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___nonzero__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__bool__": [[172, 174], ["_polyiou.VectorDouble___bool__"], "methods", ["None"], ["", "def", "__bool__", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___bool__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__len__": [[175, 177], ["_polyiou.VectorDouble___len__"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___len__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__getslice__": [[178, 180], ["_polyiou.VectorDouble___getslice__"], "methods", ["None"], ["", "def", "__getslice__", "(", "self", ",", "i", ",", "j", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___getslice__", "(", "self", ",", "i", ",", "j", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__setslice__": [[181, 183], ["_polyiou.VectorDouble___setslice__"], "methods", ["None"], ["", "def", "__setslice__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___setslice__", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__delslice__": [[184, 186], ["_polyiou.VectorDouble___delslice__"], "methods", ["None"], ["", "def", "__delslice__", "(", "self", ",", "i", ",", "j", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___delslice__", "(", "self", ",", "i", ",", "j", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__delitem__": [[187, 189], ["_polyiou.VectorDouble___delitem__"], "methods", ["None"], ["", "def", "__delitem__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___delitem__", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__getitem__": [[190, 192], ["_polyiou.VectorDouble___getitem__"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___getitem__", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__setitem__": [[193, 195], ["_polyiou.VectorDouble___setitem__"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble___setitem__", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop": [[196, 198], ["_polyiou.VectorDouble_pop"], "methods", ["None"], ["", "def", "pop", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_pop", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append": [[199, 201], ["_polyiou.VectorDouble_append"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_append", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty": [[202, 204], ["_polyiou.VectorDouble_empty"], "methods", ["None"], ["", "def", "empty", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_empty", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size": [[205, 207], ["_polyiou.VectorDouble_size"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_size", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.swap": [[208, 210], ["_polyiou.VectorDouble_swap"], "methods", ["None"], ["", "def", "swap", "(", "self", ",", "v", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_swap", "(", "self", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.begin": [[211, 213], ["_polyiou.VectorDouble_begin"], "methods", ["None"], ["", "def", "begin", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_begin", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.end": [[214, 216], ["_polyiou.VectorDouble_end"], "methods", ["None"], ["", "def", "end", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_end", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.rbegin": [[217, 219], ["_polyiou.VectorDouble_rbegin"], "methods", ["None"], ["", "def", "rbegin", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_rbegin", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.rend": [[220, 222], ["_polyiou.VectorDouble_rend"], "methods", ["None"], ["", "def", "rend", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_rend", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.clear": [[223, 225], ["_polyiou.VectorDouble_clear"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_clear", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.get_allocator": [[226, 228], ["_polyiou.VectorDouble_get_allocator"], "methods", ["None"], ["", "def", "get_allocator", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_get_allocator", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop_back": [[229, 231], ["_polyiou.VectorDouble_pop_back"], "methods", ["None"], ["", "def", "pop_back", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_pop_back", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.erase": [[232, 234], ["_polyiou.VectorDouble_erase"], "methods", ["None"], ["", "def", "erase", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_erase", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.__init__": [[235, 241], ["_polyiou.new_VectorDouble", "polyiou.VectorDouble.this.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "this", "=", "_polyiou", ".", "new_VectorDouble", "(", "*", "args", ")", "\n", "try", ":", "\n", "            ", "self", ".", "this", ".", "append", "(", "this", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "self", ".", "this", "=", "this", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.push_back": [[242, 244], ["_polyiou.VectorDouble_push_back"], "methods", ["None"], ["", "", "def", "push_back", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_push_back", "(", "self", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.front": [[245, 247], ["_polyiou.VectorDouble_front"], "methods", ["None"], ["", "def", "front", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_front", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.back": [[248, 250], ["_polyiou.VectorDouble_back"], "methods", ["None"], ["", "def", "back", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_back", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.assign": [[251, 253], ["_polyiou.VectorDouble_assign"], "methods", ["None"], ["", "def", "assign", "(", "self", ",", "n", ",", "x", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_assign", "(", "self", ",", "n", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.resize": [[254, 256], ["_polyiou.VectorDouble_resize"], "methods", ["None"], ["", "def", "resize", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_resize", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.insert": [[257, 259], ["_polyiou.VectorDouble_insert"], "methods", ["None"], ["", "def", "insert", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_insert", "(", "self", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.reserve": [[260, 262], ["_polyiou.VectorDouble_reserve"], "methods", ["None"], ["", "def", "reserve", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_reserve", "(", "self", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.capacity": [[263, 265], ["_polyiou.VectorDouble_capacity"], "methods", ["None"], ["", "def", "capacity", "(", "self", ")", ":", "\n", "        ", "return", "_polyiou", ".", "VectorDouble_capacity", "(", "self", ")", "\n", "", "__swig_destroy__", "=", "_polyiou", ".", "delete_VectorDouble", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_setattr_nondynamic": [[39, 56], ["class_type.__swig_setmethods__.get", "polyiou..this.own", "class_type.__swig_setmethods__.get.", "AttributeError", "object.__setattr__", "type"], "function", ["None"], ["", "def", "_swig_setattr_nondynamic", "(", "self", ",", "class_type", ",", "name", ",", "value", ",", "static", "=", "1", ")", ":", "\n", "    ", "if", "(", "name", "==", "\"thisown\"", ")", ":", "\n", "        ", "return", "self", ".", "this", ".", "own", "(", "value", ")", "\n", "", "if", "(", "name", "==", "\"this\"", ")", ":", "\n", "        ", "if", "type", "(", "value", ")", ".", "__name__", "==", "'SwigPyObject'", ":", "\n", "            ", "self", ".", "__dict__", "[", "name", "]", "=", "value", "\n", "return", "\n", "", "", "method", "=", "class_type", ".", "__swig_setmethods__", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "method", ":", "\n", "        ", "return", "method", "(", "self", ",", "value", ")", "\n", "", "if", "(", "not", "static", ")", ":", "\n", "        ", "if", "_newclass", ":", "\n", "            ", "object", ".", "__setattr__", "(", "self", ",", "name", ",", "value", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "__dict__", "[", "name", "]", "=", "value", "\n", "", "", "else", ":", "\n", "        ", "raise", "AttributeError", "(", "\"You cannot add attributes to %s\"", "%", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_setattr": [[58, 60], ["polyiou._swig_setattr_nondynamic"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_setattr_nondynamic"], ["", "", "def", "_swig_setattr", "(", "self", ",", "class_type", ",", "name", ",", "value", ")", ":", "\n", "    ", "return", "_swig_setattr_nondynamic", "(", "self", ",", "class_type", ",", "name", ",", "value", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_getattr_nondynamic": [[62, 72], ["class_type.__swig_getmethods__.get", "polyiou..this.own", "class_type.__swig_getmethods__.get.", "object.__getattr__", "AttributeError"], "function", ["None"], ["", "def", "_swig_getattr_nondynamic", "(", "self", ",", "class_type", ",", "name", ",", "static", "=", "1", ")", ":", "\n", "    ", "if", "(", "name", "==", "\"thisown\"", ")", ":", "\n", "        ", "return", "self", ".", "this", ".", "own", "(", ")", "\n", "", "method", "=", "class_type", ".", "__swig_getmethods__", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "method", ":", "\n", "        ", "return", "method", "(", "self", ")", "\n", "", "if", "(", "not", "static", ")", ":", "\n", "        ", "return", "object", ".", "__getattr__", "(", "self", ",", "name", ")", "\n", "", "else", ":", "\n", "        ", "raise", "AttributeError", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_getattr": [[73, 75], ["polyiou._swig_getattr_nondynamic"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_getattr_nondynamic"], ["", "", "def", "_swig_getattr", "(", "self", ",", "class_type", ",", "name", ")", ":", "\n", "    ", "return", "_swig_getattr_nondynamic", "(", "self", ",", "class_type", ",", "name", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou._swig_repr": [[77, 83], ["polyiou..this.__repr__"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SeparableConv2d.__repr__"], ["", "def", "_swig_repr", "(", "self", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "strthis", "=", "\"proxy of \"", "+", "self", ".", "this", ".", "__repr__", "(", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "strthis", "=", "\"\"", "\n", "", "return", "\"<%s.%s; %s >\"", "%", "(", "self", ".", "__class__", ".", "__module__", ",", "self", ".", "__class__", ".", "__name__", ",", "strthis", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly": [[271, 273], ["_polyiou.iou_poly"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly"], ["def", "iou_poly", "(", "p", ",", "q", ")", ":", "\n", "    ", "return", "_polyiou", ".", "iou_poly", "(", "p", ",", "q", ")", "\n", "", "iou_poly", "=", "_polyiou", ".", "iou_poly", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.__init__": [[19, 28], ["os.path.join", "os.path.join", "dota_utils.GetFileFromThisRootDir", "collections.defaultdict", "collections.defaultdict", "DOTA.DOTA.createIndex", "dota_utils.custombasename"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.createIndex", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["    ", "def", "__init__", "(", "self", ",", "basepath", ")", ":", "\n", "        ", "self", ".", "basepath", "=", "basepath", "\n", "self", ".", "labelpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'labelTxt'", ")", "\n", "self", ".", "imagepath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'images'", ")", "\n", "self", ".", "imgpaths", "=", "util", ".", "GetFileFromThisRootDir", "(", "self", ".", "labelpath", ")", "\n", "self", ".", "imglist", "=", "[", "util", ".", "custombasename", "(", "x", ")", "for", "x", "in", "self", ".", "imgpaths", "]", "\n", "self", ".", "catToImgs", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "ImgToAnns", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "createIndex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.createIndex": [[29, 37], ["dota_utils.parse_dota_poly", "dota_utils.custombasename", "DOTA.DOTA.catToImgs[].append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "createIndex", "(", "self", ")", ":", "\n", "        ", "for", "filename", "in", "self", ".", "imgpaths", ":", "\n", "            ", "objects", "=", "util", ".", "parse_dota_poly", "(", "filename", ")", "\n", "imgid", "=", "util", ".", "custombasename", "(", "filename", ")", "\n", "self", ".", "ImgToAnns", "[", "imgid", "]", "=", "objects", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "cat", "=", "obj", "[", "'name'", "]", "\n", "self", ".", "catToImgs", "[", "cat", "]", ".", "append", "(", "imgid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.getImgIds": [[38, 54], ["list", "DOTA._isArrayLike", "len", "enumerate", "set", "set"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA._isArrayLike"], ["", "", "", "def", "getImgIds", "(", "self", ",", "catNms", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        :param catNms: category names\n        :return: all the image ids contain the categories\n        \"\"\"", "\n", "catNms", "=", "catNms", "if", "_isArrayLike", "(", "catNms", ")", "else", "[", "catNms", "]", "\n", "if", "len", "(", "catNms", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "imglist", "\n", "", "else", ":", "\n", "            ", "imgids", "=", "[", "]", "\n", "for", "i", ",", "cat", "in", "enumerate", "(", "catNms", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "imgids", "=", "set", "(", "self", ".", "catToImgs", "[", "cat", "]", ")", "\n", "", "else", ":", "\n", "                    ", "imgids", "&=", "set", "(", "self", ".", "catToImgs", "[", "cat", "]", ")", "\n", "", "", "", "return", "list", "(", "imgids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.loadAnns": [[55, 67], ["DOTA._isArrayLike", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA._isArrayLike"], ["", "def", "loadAnns", "(", "self", ",", "catNms", "=", "[", "]", ",", "imgId", "=", "None", ",", "difficult", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param catNms: category names\n        :param imgId: the img to load anns\n        :return: objects\n        \"\"\"", "\n", "catNms", "=", "catNms", "if", "_isArrayLike", "(", "catNms", ")", "else", "[", "catNms", "]", "\n", "objects", "=", "self", ".", "ImgToAnns", "[", "imgId", "]", "\n", "if", "len", "(", "catNms", ")", "==", "0", ":", "\n", "            ", "return", "objects", "\n", "", "outobjects", "=", "[", "obj", "for", "obj", "in", "objects", "if", "(", "obj", "[", "'name'", "]", "in", "catNms", ")", "]", "\n", "return", "outobjects", "\n", "", "def", "showAnns", "(", "self", ",", "objects", ",", "imgId", ",", "range", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.showAnns": [[67, 99], ["matplotlib.imshow", "matplotlib.axis", "matplotlib.gca", "matplotlib.gca.set_autoscale_on", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "DOTA.DOTA.loadImgs", "polygons.append", "color.append", "matplotlib.patches.Circle", "circles.append", "matplotlib.patches.Polygon", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.loadImgs", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "showAnns", "(", "self", ",", "objects", ",", "imgId", ",", "range", ")", ":", "\n", "        ", "\"\"\"\n        :param catNms: category names\n        :param objects: objects to show\n        :param imgId: img to show\n        :param range: display range in the img\n        :return:\n        \"\"\"", "\n", "img", "=", "self", ".", "loadImgs", "(", "imgId", ")", "[", "0", "]", "\n", "plt", ".", "imshow", "(", "img", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "set_autoscale_on", "(", "False", ")", "\n", "polygons", "=", "[", "]", "\n", "color", "=", "[", "]", "\n", "circles", "=", "[", "]", "\n", "r", "=", "5", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "c", "=", "(", "np", ".", "random", ".", "random", "(", "(", "1", ",", "3", ")", ")", "*", "0.6", "+", "0.4", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "poly", "=", "obj", "[", "'poly'", "]", "\n", "polygons", ".", "append", "(", "Polygon", "(", "poly", ")", ")", "\n", "color", ".", "append", "(", "c", ")", "\n", "point", "=", "poly", "[", "0", "]", "\n", "circle", "=", "Circle", "(", "(", "point", "[", "0", "]", ",", "point", "[", "1", "]", ")", ",", "r", ")", "\n", "circles", ".", "append", "(", "circle", ")", "\n", "", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolors", "=", "color", ",", "linewidths", "=", "0", ",", "alpha", "=", "0.4", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolors", "=", "'none'", ",", "edgecolors", "=", "color", ",", "linewidths", "=", "2", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "p", "=", "PatchCollection", "(", "circles", ",", "facecolors", "=", "'red'", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "", "def", "loadImgs", "(", "self", ",", "imgids", "=", "[", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.loadImgs": [[99, 114], ["print", "print", "DOTA._isArrayLike", "DOTA._isArrayLike", "os.path.join", "print", "cv2.imread", "imgs.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA._isArrayLike", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA._isArrayLike", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "loadImgs", "(", "self", ",", "imgids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        :param imgids: integer ids specifying img\n        :return: loaded img objects\n        \"\"\"", "\n", "print", "(", "'isarralike:'", ",", "_isArrayLike", "(", "imgids", ")", ")", "\n", "imgids", "=", "imgids", "if", "_isArrayLike", "(", "imgids", ")", "else", "[", "imgids", "]", "\n", "print", "(", "'imgids:'", ",", "imgids", ")", "\n", "imgs", "=", "[", "]", "\n", "for", "imgid", "in", "imgids", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "imagepath", ",", "imgid", "+", "'.png'", ")", "\n", "print", "(", "'filename:'", ",", "filename", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "filename", ")", "\n", "imgs", ".", "append", "(", "img", ")", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA._isArrayLike": [[13, 17], ["type", "hasattr", "hasattr"], "function", ["None"], ["def", "_isArrayLike", "(", "obj", ")", ":", "\n", "    ", "if", "type", "(", "obj", ")", "==", "str", ":", "\n", "        ", "return", "False", "\n", "", "return", "hasattr", "(", "obj", ",", "'__iter__'", ")", "and", "hasattr", "(", "obj", ",", "'__len__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.custombasename": [[16, 18], ["os.path.basename", "os.path.splitext"], "function", ["None"], ["def", "custombasename", "(", "fullname", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "fullname", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.GetFileFromThisRootDir": [[19, 31], ["os.walk", "os.path.join", "allfiles.append", "os.path.splitext", "allfiles.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "GetFileFromThisRootDir", "(", "dir", ",", "ext", "=", "None", ")", ":", "\n", "  ", "allfiles", "=", "[", "]", "\n", "needExtFilter", "=", "(", "ext", "!=", "None", ")", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "dir", ")", ":", "\n", "    ", "for", "filespath", "in", "files", ":", "\n", "      ", "filepath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filespath", ")", "\n", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filepath", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "needExtFilter", "and", "extension", "in", "ext", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "elif", "not", "needExtFilter", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "", "", "return", "allfiles", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.TuplePoly2Poly": [[32, 39], ["None"], "function", ["None"], ["", "def", "TuplePoly2Poly", "(", "poly", ")", ":", "\n", "    ", "outpoly", "=", "[", "poly", "[", "0", "]", "[", "0", "]", ",", "poly", "[", "0", "]", "[", "1", "]", ",", "\n", "poly", "[", "1", "]", "[", "0", "]", ",", "poly", "[", "1", "]", "[", "1", "]", ",", "\n", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "2", "]", "[", "1", "]", ",", "\n", "poly", "[", "3", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "1", "]", "\n", "]", "\n", "return", "outpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.parse_dota_poly_refactor": [[40, 97], ["open", "f.readline", "codecs.open", "f.readline.strip().split", "shapely.Polygon", "objects.append", "len", "len", "len", "f.readline.strip", "len", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_dota_poly_refactor", "(", "filename", ",", "code", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n    \"\"\"", "\n", "objects", "=", "[", "]", "\n", "#print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "code", ")", "\n", "f", "=", "fd", "\n", "# count = 0", "\n", "", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "# count = count + 1", "\n", "# if count < 2:", "\n", "#     continue", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n", "### clear the wrong name after check all the data", "\n", "#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "# if (splitlines[9] == 'tr'):", "\n", "#     object_struct['difficult'] = '1'", "\n", "# else:", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n", "#     object_struct['difficult'] = 0", "\n", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "# poly = list(map(lambda x:np.array(x), object_struct['poly']))", "\n", "# object_struct['long-axis'] = max(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# object_struct['short-axis'] = min(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# if (object_struct['long-axis'] < 15):", "\n", "#     object_struct['difficult'] = '1'", "\n", "#     global small_count", "\n", "#     small_count = small_count + 1", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.parse_dota_poly": [[98, 155], ["open", "f.readline", "codecs.open", "f.readline.strip().split", "shapely.Polygon", "objects.append", "len", "len", "len", "f.readline.strip", "len", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_dota_poly", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n    \"\"\"", "\n", "objects", "=", "[", "]", "\n", "# print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "# count = 0", "\n", "", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "# count = count + 1", "\n", "# if count < 2:", "\n", "#     continue", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n", "### clear the wrong name after check all the data", "\n", "#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "# if (splitlines[9] == 'tr'):", "\n", "#     object_struct['difficult'] = '1'", "\n", "# else:", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n", "#     object_struct['difficult'] = 0", "\n", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "# poly = list(map(lambda x:np.array(x), object_struct['poly']))", "\n", "# object_struct['long-axis'] = max(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# object_struct['short-axis'] = min(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# if (object_struct['long-axis'] < 15):", "\n", "#     object_struct['difficult'] = '1'", "\n", "#     global small_count", "\n", "#     small_count = small_count + 1", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.parse_dota_poly2": [[156, 166], ["dota_utils.parse_dota_poly", "dota_utils.TuplePoly2Poly", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly"], ["", "def", "parse_dota_poly2", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [x1, y1, x2, y2, x3, y3, x4, y4]\n    \"\"\"", "\n", "objects", "=", "parse_dota_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "obj", "[", "'poly'", "]", "=", "TuplePoly2Poly", "(", "obj", "[", "'poly'", "]", ")", "\n", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "int", ",", "obj", "[", "'poly'", "]", ")", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.parse_dota_rec": [[167, 178], ["dota_utils.parse_dota_poly", "dota_utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "def", "parse_dota_rec", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the bounding box format:\n        \"xmin, ymin, xmax, ymax\"\n    \"\"\"", "\n", "objects", "=", "parse_dota_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "dots4ToRec4", "(", "poly", ")", "\n", "obj", "[", "'bndbox'", "]", "=", "bbox", "\n", "", "return", "objects", "\n", "## bounding box transfer for varies format", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.dots4ToRec4": [[180, 186], ["min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max"], "function", ["None"], ["", "def", "dots4ToRec4", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "min", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "min", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "", "def", "dots4ToRec8", "(", "poly", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.dots4ToRec8": [[186, 189], ["dota_utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "def", "dots4ToRec8", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "dots4ToRec4", "(", "poly", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "#return dots2ToRec8(dots4ToRec4(poly))", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.dots2ToRec8": [[190, 193], ["None"], "function", ["None"], ["", "def", "dots2ToRec8", "(", "rec", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "rec", "[", "0", "]", ",", "rec", "[", "1", "]", ",", "rec", "[", "2", "]", ",", "rec", "[", "3", "]", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.groundtruth2Task1": [[194, 222], ["dota_utils.GetFileFromThisRootDir", "open", "dota_utils.parse_dota_poly2", "dota_utils.custombasename", "re.compile", "re.findall", "filedict[].write", "os.path.join", "map", "map", "dota_utils.custombasename", "map", "dota_utils.custombasename", "dota_utils.custombasename"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "def", "groundtruth2Task1", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "# names = [custombasename(x.strip())for x in filelist]", "\n", "filedict", "=", "{", "}", "\n", "for", "cls", "in", "wordname_15", ":", "\n", "        ", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "'Task1_'", ")", "+", "cls", "+", "r'.txt'", ",", "'w'", ")", "\n", "filedict", "[", "cls", "]", "=", "fd", "\n", "", "for", "filepath", "in", "filelist", ":", "\n", "        ", "objects", "=", "parse_dota_poly2", "(", "filepath", ")", "\n", "\n", "subname", "=", "custombasename", "(", "filepath", ")", "\n", "pattern2", "=", "re", ".", "compile", "(", "r'__([\\d+\\.]+)__\\d+___'", ")", "\n", "rate", "=", "re", ".", "findall", "(", "pattern2", ",", "subname", ")", "[", "0", "]", "\n", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "category", "=", "obj", "[", "'name'", "]", "\n", "difficult", "=", "obj", "[", "'difficult'", "]", "\n", "poly", "=", "obj", "[", "'poly'", "]", "\n", "if", "difficult", "==", "'2'", ":", "\n", "                ", "continue", "\n", "", "if", "rate", "==", "'0.5'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'1'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "", "elif", "rate", "==", "'1'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'0.8'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "", "elif", "rate", "==", "'2'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'0.6'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "\n", "", "filedict", "[", "category", "]", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.Task2groundtruth_poly": [[223, 253], ["dota_utils.GetFileFromThisRootDir", "open", "open.readlines", "custombasename().split", "line.strip().split", "len", "float", "filedict[].write", "dota_utils.custombasename", "line.strip", "codecs.open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "", "", "def", "Task2groundtruth_poly", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "thresh", "=", "0.1", "\n", "filedict", "=", "{", "}", "\n", "Tasklist", "=", "GetFileFromThisRootDir", "(", "srcpath", ",", "'.txt'", ")", "\n", "\n", "for", "Taskfile", "in", "Tasklist", ":", "\n", "        ", "idname", "=", "custombasename", "(", "Taskfile", ")", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "# idname = datamap_inverse[idname]", "\n", "f", "=", "open", "(", "Taskfile", ",", "'r'", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "# print('line:', line)", "\n", "", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "filename", "=", "splitline", "[", "0", "]", "\n", "confidence", "=", "splitline", "[", "1", "]", "\n", "bbox", "=", "splitline", "[", "2", ":", "]", "\n", "if", "float", "(", "confidence", ")", ">", "thresh", ":", "\n", "                ", "if", "filename", "not", "in", "filedict", ":", "\n", "# filedict[filename] = codecs.open(os.path.join(dstpath, filename + '.txt'), 'w', 'utf_16')", "\n", "                    ", "filedict", "[", "filename", "]", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "filename", "+", "'.txt'", ")", ",", "'w'", ")", "\n", "# poly = util.dots2ToRec8(bbox)", "\n", "", "poly", "=", "bbox", "\n", "#               filedict[filename].write(' '.join(poly) + ' ' + idname + '_' + str(round(float(confidence), 2)) + '\\n')", "\n", "# print('idname:', idname)", "\n", "\n", "# filedict[filename].write(' '.join(poly) + ' ' + idname + '_' + str(round(float(confidence), 2)) + '\\n')", "\n", "\n", "filedict", "[", "filename", "]", ".", "write", "(", "' '", ".", "join", "(", "poly", ")", "+", "' '", "+", "idname", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.polygonToRotRectangle": [[255, 285], ["numpy.array", "numpy.reshape", "math.atan2", "range", "numpy.array", "numpy.matmul", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "numpy.array", "np.array.transpose", "float", "float", "math.cos", "math.sin", "math.cos", "math.sin"], "function", ["None"], ["", "", "", "", "def", "polygonToRotRectangle", "(", "bbox", ")", ":", "\n", "    ", "\"\"\"\n    :param bbox: The polygon stored in format [x1, y1, x2, y2, x3, y3, x4, y4]\n    :return: Rotated Rectangle in format [cx, cy, w, h, theta]\n    \"\"\"", "\n", "bbox", "=", "np", ".", "array", "(", "bbox", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "bbox", "=", "np", ".", "reshape", "(", "bbox", ",", "newshape", "=", "(", "2", ",", "4", ")", ",", "order", "=", "'F'", ")", "\n", "angle", "=", "math", ".", "atan2", "(", "-", "(", "bbox", "[", "0", ",", "1", "]", "-", "bbox", "[", "0", ",", "0", "]", ")", ",", "bbox", "[", "1", ",", "1", "]", "-", "bbox", "[", "1", ",", "0", "]", ")", "\n", "\n", "center", "=", "[", "[", "0", "]", ",", "[", "0", "]", "]", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "center", "[", "0", "]", "+=", "bbox", "[", "0", ",", "i", "]", "\n", "center", "[", "1", "]", "+=", "bbox", "[", "1", ",", "i", "]", "\n", "\n", "", "center", "=", "np", ".", "array", "(", "center", ",", "dtype", "=", "np", ".", "float32", ")", "/", "4.0", "\n", "\n", "R", "=", "np", ".", "array", "(", "[", "[", "math", ".", "cos", "(", "angle", ")", ",", "-", "math", ".", "sin", "(", "angle", ")", "]", ",", "[", "math", ".", "sin", "(", "angle", ")", ",", "math", ".", "cos", "(", "angle", ")", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "normalized", "=", "np", ".", "matmul", "(", "R", ".", "transpose", "(", ")", ",", "bbox", "-", "center", ")", "\n", "\n", "xmin", "=", "np", ".", "min", "(", "normalized", "[", "0", ",", ":", "]", ")", "\n", "xmax", "=", "np", ".", "max", "(", "normalized", "[", "0", ",", ":", "]", ")", "\n", "ymin", "=", "np", ".", "min", "(", "normalized", "[", "1", ",", ":", "]", ")", "\n", "ymax", "=", "np", ".", "max", "(", "normalized", "[", "1", ",", ":", "]", ")", "\n", "\n", "w", "=", "xmax", "-", "xmin", "+", "1", "\n", "h", "=", "ymax", "-", "ymin", "+", "1", "\n", "\n", "return", "[", "float", "(", "center", "[", "0", "]", ")", ",", "float", "(", "center", "[", "1", "]", ")", ",", "w", ",", "h", ",", "angle", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.cal_line_length": [[286, 288], ["math.sqrt", "math.pow", "math.pow"], "function", ["None"], ["", "def", "cal_line_length", "(", "point1", ",", "point2", ")", ":", "\n", "    ", "return", "math", ".", "sqrt", "(", "math", ".", "pow", "(", "point1", "[", "0", "]", "-", "point2", "[", "0", "]", ",", "2", ")", "+", "math", ".", "pow", "(", "point1", "[", "1", "]", "-", "point2", "[", "1", "]", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.dota_utils.get_best_begin_point": [[289, 318], ["min", "min", "max", "max", "range", "print", "dota_utils.cal_line_length", "dota_utils.cal_line_length", "dota_utils.cal_line_length", "dota_utils.cal_line_length"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length"], ["", "def", "get_best_begin_point", "(", "coordinate", ")", ":", "\n", "    ", "x1", "=", "coordinate", "[", "0", "]", "[", "0", "]", "\n", "y1", "=", "coordinate", "[", "0", "]", "[", "1", "]", "\n", "x2", "=", "coordinate", "[", "1", "]", "[", "0", "]", "\n", "y2", "=", "coordinate", "[", "1", "]", "[", "1", "]", "\n", "x3", "=", "coordinate", "[", "2", "]", "[", "0", "]", "\n", "y3", "=", "coordinate", "[", "2", "]", "[", "1", "]", "\n", "x4", "=", "coordinate", "[", "3", "]", "[", "0", "]", "\n", "y4", "=", "coordinate", "[", "3", "]", "[", "1", "]", "\n", "xmin", "=", "min", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymin", "=", "min", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "xmax", "=", "max", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymax", "=", "max", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "combinate", "=", "[", "[", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", "]", ",", "[", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", "]", ",", "\n", "[", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", "]", ",", "[", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", "]", "]", "\n", "dst_coordinate", "=", "[", "[", "xmin", ",", "ymin", "]", ",", "[", "xmax", ",", "ymin", "]", ",", "[", "xmax", ",", "ymax", "]", ",", "[", "xmin", ",", "ymax", "]", "]", "\n", "force", "=", "100000000.0", "\n", "force_flag", "=", "0", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "temp_force", "=", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "0", "]", ",", "dst_coordinate", "[", "0", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "1", "]", ",", "\n", "dst_coordinate", "[", "\n", "1", "]", ")", "+", "cal_line_length", "(", "\n", "combinate", "[", "i", "]", "[", "2", "]", ",", "dst_coordinate", "[", "2", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "3", "]", ",", "dst_coordinate", "[", "3", "]", ")", "\n", "if", "temp_force", "<", "force", ":", "\n", "            ", "force", "=", "temp_force", "\n", "force_flag", "=", "i", "\n", "", "", "if", "force_flag", "!=", "0", ":", "\n", "        ", "print", "(", "\"choose one direction!\"", ")", "\n", "", "return", "combinate", "[", "force_flag", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.parse_args": [[13, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Split the DOTA 1.0/1.5 raw data into image patches of the given size.\"", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--srcpath\"", ",", "help", "=", "\"DOTA 1.0/1.5 dataset raw data directory (source).\"", ",", "required", "=", "True", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dstpath\"", ",", "help", "=", "\"DOTA 1.0/1.5 dataset split data directory (destination).\"", ",", "required", "=", "True", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dota-version\"", ",", "\n", "required", "=", "True", ",", "\n", "choices", "=", "[", "\"1.0\"", ",", "\"1.5\"", "]", ",", "\n", "help", "=", "\"DOTA dataset version, can be one of [1.0, 1.5].\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--patchsize\"", ",", "type", "=", "int", ",", "help", "=", "\"Patchsize of each image patch.\"", ",", "default", "=", "1024", ")", "\n", "parser", ".", "add_argument", "(", "\"--overlap\"", ",", "type", "=", "int", ",", "help", "=", "\"Overlap between image patches.\"", ",", "default", "=", "200", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.single_copy": [[38, 40], ["shutil.copyfile"], "function", ["None"], ["", "def", "single_copy", "(", "src_dst_tuple", ")", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "*", "src_dst_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.filecopy": [[42, 54], ["multiprocessing.Pool", "utils.GetFileFromThisRootDir", "multiprocessing.Pool.map", "os.path.basename", "os.path.join", "name_pairs.append", "file.strip"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "filecopy", "(", "srcpath", ",", "dstpath", ",", "num_process", "=", "32", ")", ":", "\n", "    ", "pool", "=", "Pool", "(", "num_process", ")", "\n", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "\n", "name_pairs", "=", "[", "]", "\n", "for", "file", "in", "filelist", ":", "\n", "        ", "basename", "=", "os", ".", "path", ".", "basename", "(", "file", ".", "strip", "(", ")", ")", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", ")", "\n", "name_tuple", "=", "(", "file", ",", "dstname", ")", "\n", "name_pairs", ".", "append", "(", "name_tuple", ")", "\n", "\n", "", "pool", ".", "map", "(", "single_copy", ",", "name_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.singel_move": [[56, 58], ["shutil.move"], "function", ["None"], ["", "def", "singel_move", "(", "src_dst_tuple", ")", ":", "\n", "    ", "shutil", ".", "move", "(", "*", "src_dst_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.filemove": [[60, 72], ["multiprocessing.Pool", "utils.GetFileFromThisRootDir", "multiprocessing.Pool.map", "os.path.basename", "os.path.join", "name_pairs.append", "file.strip"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "filemove", "(", "srcpath", ",", "dstpath", ",", "num_process", "=", "32", ")", ":", "\n", "    ", "pool", "=", "Pool", "(", "num_process", ")", "\n", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "\n", "name_pairs", "=", "[", "]", "\n", "for", "file", "in", "filelist", ":", "\n", "        ", "basename", "=", "os", ".", "path", ".", "basename", "(", "file", ".", "strip", "(", ")", ")", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", ")", "\n", "name_tuple", "=", "(", "file", ",", "dstname", ")", "\n", "name_pairs", ".", "append", "(", "name_tuple", ")", "\n", "\n", "", "pool", ".", "map", "(", "filemove", ",", "name_pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.getnamelist": [[74, 80], ["utils.GetFileFromThisRootDir", "open", "utils.mybasename", "f_out.write"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename"], ["", "def", "getnamelist", "(", "srcpath", ",", "dstfile", ")", ":", "\n", "    ", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "with", "open", "(", "dstfile", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "        ", "for", "file", "in", "filelist", ":", "\n", "            ", "basename", "=", "util", ".", "mybasename", "(", "file", ")", "\n", "f_out", ".", "write", "(", "basename", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.prepare": [[82, 145], ["os.path.join", "os.path.isdir", "ImgSplit_multi_process.splitbase", "ImgSplit_multi_process.splitbase.splitdata", "os.path.join", "os.path.isdir", "ImgSplit_multi_process.splitbase", "ImgSplit_multi_process.splitbase.splitdata", "os.path.join", "os.path.isdir", "SplitOnlyImage_multi_process.splitbase", "SplitOnlyImage_multi_process.splitbase.splitdata", "DOTA2COCO.DOTA2COCOTrain", "DOTA2COCO.DOTA2COCOTrain", "DOTA2COCO.DOTA2COCOTest", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.splitdata", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.splitdata", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.SplitOnlyImage_multi_process.splitbase.splitdata", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA2COCO.DOTA2COCOTrain", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA2COCO.DOTA2COCOTrain", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA2COCO.DOTA2COCOTest", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir", "home.repos.pwc.inspect_result.steven-lang_dafne.tools.run.mkdir"], ["", "", "", "def", "prepare", "(", "srcpath", ",", "dstpath", ",", "patchsize", ",", "overlap", ")", ":", "\n", "    ", "\"\"\"\n    :param srcpath: train, val, test\n          train --> trainval1024, val --> trainval1024, test --> test1024\n    :return:\n    \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"test{patchsize}\"", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"test{patchsize}\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"train{patchsize}\"", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"train{patchsize}\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"val{patchsize}\"", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"val{patchsize}\"", ")", ")", "\n", "\n", "", "srcpath_train", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "\"train\"", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "srcpath_train", ")", ",", "f\"Directory '{srcpath_train}' does not exist. Please make sure, that the DOTA dataset is properly downloaded and extracted to '{srcpath}'.\"", "\n", "split_train", "=", "ImgSplit_multi_process", ".", "splitbase", "(", "\n", "srcpath_train", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"train{patchsize}\"", ")", ",", "\n", "gap", "=", "overlap", ",", "\n", "subsize", "=", "patchsize", ",", "\n", "num_process", "=", "32", ",", "\n", ")", "\n", "split_train", ".", "splitdata", "(", "1", ")", "\n", "\n", "srcpath_val", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "\"val\"", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "srcpath_val", ")", ",", "f\"Directory '{srcpath_val}' does not exist. Please make sure, that the DOTA dataset is properly downloaded and extracted to '{srcpath}'.\"", "\n", "split_val", "=", "ImgSplit_multi_process", ".", "splitbase", "(", "\n", "srcpath_val", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"val{patchsize}\"", ")", ",", "\n", "gap", "=", "overlap", ",", "\n", "subsize", "=", "patchsize", ",", "\n", "num_process", "=", "32", ",", "\n", ")", "\n", "split_val", ".", "splitdata", "(", "1", ")", "\n", "\n", "srcpath_test", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "\"test\"", ",", "\"images\"", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "srcpath_test", ")", ",", "f\"Directory '{srcpath_test}' does not exist. Please make sure, that the DOTA dataset is properly downloaded and extracted to '{srcpath}'.\"", "\n", "split_test", "=", "SplitOnlyImage_multi_process", ".", "splitbase", "(", "\n", "srcpath_test", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"test{patchsize}\"", ",", "\"images\"", ")", ",", "\n", "gap", "=", "overlap", ",", "\n", "subsize", "=", "patchsize", ",", "\n", "num_process", "=", "32", ",", "\n", ")", "\n", "split_test", ".", "splitdata", "(", "1", ")", "\n", "\n", "DOTA2COCOTrain", "(", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"train{patchsize}\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"train{patchsize}\"", ",", "f\"DOTA1_train{patchsize}.json\"", ")", ",", "\n", "classnames", ",", "\n", "difficult", "=", "\"-1\"", ",", "\n", ")", "\n", "DOTA2COCOTrain", "(", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"val{patchsize}\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"val{patchsize}\"", ",", "f\"DOTA1_val{patchsize}.json\"", ")", ",", "\n", "classnames", ",", "\n", "difficult", "=", "\"-1\"", ",", "\n", ")", "\n", "DOTA2COCOTest", "(", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"test{patchsize}\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "dstpath", ",", "f\"test{patchsize}\"", ",", "f\"DOTA1_test{patchsize}.json\"", ")", ",", "\n", "classnames", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.ensure_dir": [[148, 160], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "ensure_dir", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Ensure that a directory exists.\n\n    For 'foo/bar/baz.csv' the directories 'foo' and 'bar' will be created if not already present.\n\n    Args:\n        path (str): Directory path.\n    \"\"\"", "\n", "d", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.split_dota.get_class_names": [[162, 186], ["names.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "get_class_names", "(", "use_dota_1_5", ":", "bool", ")", ":", "\n", "    ", "names", "=", "[", "\n", "\"plane\"", ",", "\n", "\"baseball-diamond\"", ",", "\n", "\"bridge\"", ",", "\n", "\"ground-track-field\"", ",", "\n", "\"small-vehicle\"", ",", "\n", "\"large-vehicle\"", ",", "\n", "\"ship\"", ",", "\n", "\"tennis-court\"", ",", "\n", "\"basketball-court\"", ",", "\n", "\"storage-tank\"", ",", "\n", "\"soccer-ball-field\"", ",", "\n", "\"roundabout\"", ",", "\n", "\"harbor\"", ",", "\n", "\"swimming-pool\"", ",", "\n", "\"helicopter\"", ",", "\n", "]", "\n", "\n", "# Add container-craine if 1.5 is selected", "\n", "if", "use_dota_1_5", "==", "\"1.5\"", ":", "\n", "        ", "names", ".", "append", "(", "\"container-crane\"", ")", "\n", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.__init__": [[822, 832], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.basename", "os.path.basename", "utils.GetFileFromThisRootDir", "utils.GetFileFromThisRootDir", "os.path.splitext", "os.path.split"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir"], ["    ", "def", "__init__", "(", "self", ",", "\n", "basepath", ")", ":", "\n", "        ", "self", ".", "basepath", "=", "basepath", "\n", "self", ".", "labelpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'labelTxt'", ")", "\n", "self", ".", "imagepath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'images'", ")", "\n", "self", ".", "Polypath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "r'polylabelTxt'", ")", "\n", "self", ".", "wordlabelpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'wordlabel'", ")", "\n", "self", ".", "darkpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'labels'", ")", "\n", "self", ".", "namelist", "=", "[", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "0", "]", ")", "for", "x", "in", "GetFileFromThisRootDir", "(", "self", ".", "labelpath", ")", "]", "\n", "self", ".", "wordnamelist", "=", "[", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "split", "(", "x", ")", "[", "0", "]", ")", "for", "x", "in", "GetFileFromThisRootDir", "(", "self", ".", "wordlabelpath", ")", "]", "\n", "", "def", "testGenerateClassLabel", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.testGenerateClassLabel": [[832, 842], ["os.path.join", "utils.getorderLabel", "print", "f.write", "os.path.join", "open", "os.path.join", "str", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.getorderLabel"], ["", "def", "testGenerateClassLabel", "(", "self", ")", ":", "\n", "        ", "classlabel_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'classlabel'", ")", "\n", "for", "basename", "in", "self", ".", "namelist", ":", "\n", "            ", "orderlabel", "=", "getorderLabel", "(", "os", ".", "path", ".", "join", "(", "self", ".", "labelpath", ",", "basename", "+", "'.txt'", ")", ")", "\n", "print", "(", "'orderlabel:'", ",", "orderlabel", ")", "\n", "outline", "=", "''", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "classlabel_path", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "for", "cls", "in", "classname", ":", "\n", "                    ", "outline", "=", "outline", "+", "str", "(", "cls", ")", "+", "':'", "+", "str", "(", "orderlabel", "[", "cls", "]", ")", "+", "', '", "\n", "", "", "f", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "def", "bodpolyToRec", "(", "self", ",", "label", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.bodpolyToRec": [[842, 858], ["os.path.join", "utils.parse_bod_poly", "codecs.open", "os.path.join", "os.path.join", "utils.dots4ToRec8", "list", "codecs.open.write", "map", "str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec8"], ["", "", "def", "bodpolyToRec", "(", "self", ",", "label", ")", ":", "\n", "        ", "Recpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "r'ReclabelTxt'", ")", "\n", "for", "basename", "in", "self", ".", "namelist", ":", "\n", "#            objects = parse_bod_poly(os.path.join(self.labelpath, basename + '.txt'))", "\n", "            ", "objects", "=", "parse_bod_poly", "(", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "label", ",", "basename", "+", "'.txt'", ")", ")", "\n", "f_out", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "Recpath", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ",", "'utf_16'", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "bbox", "=", "dots4ToRec8", "(", "obj", "[", "'poly'", "]", ")", "\n", "name", "=", "obj", "[", "'name'", "]", "\n", "difficult", "=", "obj", "[", "'difficult'", "]", "\n", "bbox", "=", "list", "(", "map", "(", "str", ",", "bbox", ")", ")", "\n", "outline", "=", "' '", ".", "join", "(", "bbox", ")", "\n", "outline", "=", "outline", "+", "' '", "+", "name", "\n", "if", "difficult", ":", "\n", "                    ", "outline", "=", "outline", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "def", "labelme2txt", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.labelme2txt": [[858, 870], ["os.path.join", "utils.GetFileFromThisRootDir", "utils.parse_labelme_poly", "print", "utils.mybasename", "codecs.open", "os.path.join", "f_out.write", "int"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_labelme_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename"], ["", "", "", "def", "labelme2txt", "(", "self", ")", ":", "\n", "        ", "annotations_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'annotations'", ")", "\n", "xmllist", "=", "GetFileFromThisRootDir", "(", "annotations_path", ",", "'xml'", ")", "\n", "for", "xmlfile", "in", "xmllist", ":", "\n", "            ", "objects", "=", "parse_labelme_poly", "(", "xmlfile", ")", "\n", "print", "(", "'xmlfile:'", ",", "xmlfile", ")", "\n", "basename", "=", "mybasename", "(", "xmlfile", ")", "\n", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "labelpath", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ",", "'utf_16'", ")", "as", "f_out", ":", "\n", "                ", "for", "obj", "in", "objects", ":", "\n", "                    ", "if", "(", "not", "int", "(", "obj", "[", "'deleted'", "]", ")", ")", "and", "(", "obj", "[", "'name'", "]", "in", "datamap_getlabelme", ")", ":", "\n", "                        ", "outline", "=", "' '", ".", "join", "(", "obj", "[", "'polygon'", "]", ")", "+", "' '", "+", "datamap_getlabelme", "[", "obj", "[", "'name'", "]", "]", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "", "", "def", "bod2pascal", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.bod2pascal": [[870, 914], ["os.path.join", "print", "print", "utils.parse_bod_poly", "xml.Element", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement", "os.path.join", "str", "str", "xml.ElementTree", "xml.ElementTree.write", "os.path.join", "xml.SubElement", "xml.dump", "xml.SubElement", "xml.SubElement", "print", "str", "print", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement", "utils.dots4ToRec4", "str", "str", "str", "str", "os.path.join", "type"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "", "", "", "", "def", "bod2pascal", "(", "self", ")", ":", "\n", "        ", "pascalLabel_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "r'pascalLabel'", ")", "\n", "#pascalLabel_path = os.pardir.join(self.basepath, r'')", "\n", "print", "(", "'go in name list'", ")", "\n", "for", "basename", "in", "self", ".", "namelist", ":", "\n", "            ", "print", "(", "'basename:'", ",", "basename", ")", "\n", "#objects = parse_bod_poly(os.path.join(self.labelpath, basename + '.txt'))", "\n", "objects", "=", "parse_bod_poly", "(", "os", ".", "path", ".", "join", "(", "self", ".", "wordlabelpath", ",", "basename", "+", "'.txt'", ")", ")", "\n", "tree_root", "=", "ET", ".", "Element", "(", "'annotation'", ")", "\n", "folder", "=", "ET", ".", "SubElement", "(", "tree_root", ",", "'secondjpg'", ")", "\n", "filename", "=", "ET", ".", "SubElement", "(", "tree_root", ",", "basename", ")", "\n", "size", "=", "ET", ".", "SubElement", "(", "tree_root", ",", "'size'", ")", "\n", "width", "=", "ET", ".", "SubElement", "(", "size", ",", "'width'", ")", "\n", "height", "=", "ET", ".", "SubElement", "(", "size", ",", "'height'", ")", "\n", "## TODO: read imagesize from img or info", "\n", "imgname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'images'", ",", "basename", "+", "'.jpg'", ")", "\n", "# img = cv2.imread(imgname)", "\n", "\n", "## need change with different width, height", "\n", "width", ".", "text", "=", "str", "(", "608", ")", "\n", "height", ".", "text", "=", "str", "(", "608", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "object", "=", "ET", ".", "SubElement", "(", "tree_root", ",", "'object'", ")", "\n", "ET", ".", "dump", "(", "tree_root", ")", "\n", "name", "=", "ET", ".", "SubElement", "(", "object", ",", "'name'", ")", "\n", "#name.text = datamap[obj['name']]", "\n", "name", ".", "text", "=", "obj", "[", "'name'", "]", "\n", "difficult", "=", "ET", ".", "SubElement", "(", "object", ",", "'difficult'", ")", "\n", "print", "(", "'difficult:'", ",", "obj", "[", "'difficult'", "]", ")", "\n", "difficult", ".", "text", "=", "str", "(", "obj", "[", "'difficult'", "]", ")", "\n", "print", "(", "'type difficult.text:'", ",", "type", "(", "difficult", ".", "text", ")", ")", "\n", "bndbox", "=", "ET", ".", "SubElement", "(", "object", ",", "'bndbox'", ")", "\n", "xmin", "=", "ET", ".", "SubElement", "(", "bndbox", ",", "'xmin'", ")", "\n", "xmax", "=", "ET", ".", "SubElement", "(", "bndbox", ",", "'xmax'", ")", "\n", "ymin", "=", "ET", ".", "SubElement", "(", "bndbox", ",", "'ymin'", ")", "\n", "ymax", "=", "ET", ".", "SubElement", "(", "bndbox", ",", "'ymax'", ")", "\n", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "dots4ToRec4", "(", "poly", ")", "\n", "xmin", ".", "text", "=", "str", "(", "bbox", "[", "0", "]", ")", "\n", "ymin", ".", "text", "=", "str", "(", "bbox", "[", "1", "]", ")", "\n", "xmax", ".", "text", "=", "str", "(", "bbox", "[", "2", "]", ")", "\n", "ymax", ".", "text", "=", "str", "(", "bbox", "[", "3", "]", ")", "\n", "", "tree", "=", "ET", ".", "ElementTree", "(", "tree_root", ")", "\n", "tree", ".", "write", "(", "os", ".", "path", ".", "join", "(", "pascalLabel_path", ",", "basename", "+", "'.xml'", ")", ")", "\n", "", "", "def", "testtxt2pascal", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.testtxt2pascal": [[914, 916], ["utils.FormatTransBase.bod2pascal"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.bod2pascal"], ["", "", "def", "testtxt2pascal", "(", "self", ")", ":", "\n", "        ", "self", ".", "bod2pascal", "(", "self", ".", "basepath", ")", "\n", "", "def", "imageformatTrans", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.imageformatTrans": [[916, 925], ["os.path.join", "utils.GetFileFromThisRootDir", "cv2.imread", "utils.mybasename", "os.path.join", "cv2.imwrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename"], ["", "def", "imageformatTrans", "(", "self", ")", ":", "\n", "        ", "srcpath", "=", "self", ".", "imagepath", "\n", "dstpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "'jpgs'", ")", "\n", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "            ", "img", "=", "cv2", ".", "imread", "(", "fullname", ")", "\n", "basename", "=", "mybasename", "(", "fullname", ")", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", "+", "'.jpg'", ")", "\n", "cv2", ".", "imwrite", "(", "dstname", ",", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite": [[926, 963], ["utils.GetFileFromThisRootDir", "print", "utils.parse_bod_poly", "utils.mybasename", "os.path.join", "codecs.open", "utils.get_clockwiseorderwithfirstpoint", "print", "utils.TuplePoly2Poly", "print", "codecs.open.write", "utils.get_best_begin_point", "utils.TuplePoly2Poly", "print", "codecs.open.write", "str", "utils.get_best_begin_point", "str", "map", "map"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.get_clockwiseorderwithfirstpoint", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.get_best_begin_point", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.get_best_begin_point"], ["", "", "def", "ParseTxtAndWrite", "(", "self", ",", "srcpath", ",", "dstpath", ",", "transmap", "=", "None", ")", ":", "\n", "        ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "            ", "print", "(", "'fullname:'", ",", "fullname", ")", "\n", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "name", "=", "mybasename", "(", "fullname", ")", "\n", "outname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "dstpath", ",", "name", "+", "'.txt'", ")", "\n", "f_out", "=", "codecs", ".", "open", "(", "outname", ",", "'w'", ",", "'utf_16'", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "outpoly", "=", "obj", "[", "'poly'", "]", "\n", "outpoly", "=", "get_clockwiseorderwithfirstpoint", "(", "outpoly", ")", "\n", "if", "obj", "[", "'difficult'", "]", "==", "'0'", ":", "\n", "                    ", "difficult", "=", "'0'", "\n", "", "elif", "obj", "[", "'difficult'", "]", "==", "'2'", ":", "\n", "#outpoly = Get_clockOrderInPictureCoordinate(outpoly)", "\n", "                    ", "outpoly", "=", "get_best_begin_point", "(", "outpoly", ")", "\n", "difficult", "=", "'0'", "\n", "", "else", ":", "\n", "                    ", "difficult", "=", "'1'", "\n", "", "print", "(", "'obj:'", ",", "obj", ")", "\n", "if", "transmap", "!=", "None", ":", "\n", "                    ", "if", "obj", "[", "'name'", "]", "in", "transmap", ":", "\n", "                        ", "if", "transmap", "[", "obj", "[", "'name'", "]", "]", "in", "noorientationnames", ":", "\n", "#outpoly = Get_clockOrderInPictureCoordinate(outpoly)", "\n", "                            ", "outpoly", "=", "get_best_begin_point", "(", "outpoly", ")", "\n", "", "outpoly", "=", "TuplePoly2Poly", "(", "outpoly", ")", "\n", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "outpoly", ")", ")", "+", "' '", "+", "transmap", "[", "obj", "[", "'name'", "]", "]", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "\n", "#                        outline = ' '.join(map(str, obj['poly'])) + ' ' + transmap[obj['name']] + ' ' + str(obj['difficult'])", "\n", "print", "(", "'outline:'", ",", "outline", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "else", ":", "\n", "                    ", "outpoly", "=", "TuplePoly2Poly", "(", "outpoly", ")", "\n", "#                    outline = ' '.join(map(str, obj['poly'])) + ' ' + obj['name'] + ' ' + str(obj['difficult'])", "\n", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "outpoly", ")", ")", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "print", "(", "'outline:'", ",", "outline", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseAndWriteAllBestFirstPoint": [[964, 993], ["utils.GetFileFromThisRootDir", "utils.parse_bod_poly", "utils.mybasename", "os.path.join", "codecs.open", "utils.get_clockwiseorderwithfirstpoint", "utils.get_best_begin_point", "utils.TuplePoly2Poly", "print", "codecs.open.write", "print", "codecs.open.write", "str", "str", "map", "map"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.get_clockwiseorderwithfirstpoint", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.get_best_begin_point", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly"], ["", "", "", "", "def", "ParseAndWriteAllBestFirstPoint", "(", "self", ",", "srcpath", ",", "dstpath", ",", "transmap", "=", "None", ")", ":", "\n", "        ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "            ", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "name", "=", "mybasename", "(", "fullname", ")", "\n", "outname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "basepath", ",", "dstpath", ",", "name", "+", "'.txt'", ")", "\n", "f_out", "=", "codecs", ".", "open", "(", "outname", ",", "'w'", ",", "'utf_16'", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "outpoly", "=", "obj", "[", "'poly'", "]", "\n", "outpoly", "=", "get_clockwiseorderwithfirstpoint", "(", "outpoly", ")", "\n", "outpoly", "=", "get_best_begin_point", "(", "outpoly", ")", "\n", "if", "obj", "[", "'difficult'", "]", "==", "'0'", ":", "\n", "                    ", "difficult", "=", "'0'", "\n", "", "elif", "obj", "[", "'difficult'", "]", "==", "'2'", ":", "\n", "                    ", "difficult", "=", "'0'", "\n", "", "else", ":", "\n", "                    ", "difficult", "=", "'1'", "\n", "", "outpoly", "=", "TuplePoly2Poly", "(", "outpoly", ")", "\n", "if", "transmap", "!=", "None", ":", "\n", "                    ", "if", "obj", "[", "'name'", "]", "in", "transmap", ":", "\n", "                        ", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "outpoly", ")", ")", "+", "' '", "+", "transmap", "[", "obj", "[", "'name'", "]", "]", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "print", "(", "'outline:'", ",", "outline", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "else", ":", "\n", "\n", "#                    outline = ' '.join(map(str, obj['poly'])) + ' ' + obj['name'] + ' ' + str(obj['difficult'])", "\n", "                    ", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "outpoly", ")", ")", "+", "' '", "+", "obj", "[", "'name'", "]", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "print", "(", "'outline:'", ",", "outline", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "", "def", "TransTo15ID_gt", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.TransTo15ID_gt": [[993, 996], ["utils.FormatTransBase.ParseTxtAndWrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite"], ["", "", "", "", "def", "TransTo15ID_gt", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'label5Txt'", "\n", "self", ".", "ParseTxtAndWrite", "(", "self", ".", "labelpath", ",", "dstpath", ",", "identity_15", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.TransToDota15Word_gt": [[997, 1000], ["utils.FormatTransBase.ParseTxtAndWrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite"], ["", "def", "TransToDota15Word_gt", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'wordlabel'", "\n", "self", ".", "ParseTxtAndWrite", "(", "self", ".", "labelpath", ",", "dstpath", ",", "datamap_15_new", ")", "\n", "", "def", "TransTo15Word_gt", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.TransTo15Word_gt": [[1000, 1003], ["utils.FormatTransBase.ParseTxtAndWrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite"], ["", "def", "TransTo15Word_gt", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'wordlabel'", "\n", "self", ".", "ParseTxtAndWrite", "(", "self", ".", "labelpath", ",", "dstpath", ",", "datamap_15", ")", "\n", "# def TransTo15class(self, path):", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.JLLabel2bod": [[1021, 1026], ["utils.FormatTransBase.ParseTxtAndWrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite"], ["", "def", "JLLabel2bod", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'bodlabelTxt'", "\n", "srcpath", "=", "r'E:\\GFJL\\JL\\original-labelTxt'", "\n", "#testpath = r'E:\\GFJL\\JL\\testlabelTxt'", "\n", "self", ".", "ParseTxtAndWrite", "(", "srcpath", ",", "dstpath", ",", "JL2bod", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.GFLabel2bod": [[1027, 1031], ["utils.FormatTransBase.ParseTxtAndWrite"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseTxtAndWrite"], ["", "def", "GFLabel2bod", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'bodlabelTxt'", "\n", "srcpath", "=", "r'E:\\GFJL\\gaofen2\\labelTxt'", "\n", "self", ".", "ParseTxtAndWrite", "(", "srcpath", ",", "dstpath", ",", "GF2bod", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.TransTo15Word_gtAllBestPoint": [[1032, 1035], ["utils.FormatTransBase.ParseAndWriteAllBestFirstPoint"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.ParseAndWriteAllBestFirstPoint"], ["", "def", "TransTo15Word_gtAllBestPoint", "(", "self", ")", ":", "\n", "        ", "dstpath", "=", "r'wordlabelBestStart'", "\n", "self", ".", "ParseAndWriteAllBestFirstPoint", "(", "self", ".", "labelpath", ",", "dstpath", ",", "datamap_15", ")", "\n", "", "def", "wordlabel2dark", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.FormatTransBase.wordlabel2dark": [[1035, 1056], ["utils.GetFileFromThisRootDir", "utils.parse_bod_poly", "utils.mybasename", "open", "os.path.join", "f_out.write", "numpy.array", "str", "wordname_15.index", "utils.dots4ToRecC", "sum", "sum", "str", "list", "map"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRecC"], ["", "def", "wordlabel2dark", "(", "self", ")", ":", "\n", "        ", "filelist", "=", "GetFileFromThisRootDir", "(", "self", ".", "wordlabelpath", ")", "\n", "#print(filelist)", "\n", "for", "fullname", "in", "filelist", ":", "\n", "            ", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "name", "=", "mybasename", "(", "fullname", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "darkpath", ",", "name", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "                ", "for", "obj", "in", "objects", ":", "\n", "                    ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "np", ".", "array", "(", "dots4ToRecC", "(", "poly", ")", ")", "/", "1024", "\n", "## note: the box is x_center, y_center, w, h, that means the whole box can be out of border", "\n", "if", "(", "str", "(", "obj", "[", "'difficult'", "]", ")", "==", "'1'", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "(", "sum", "(", "bbox", "<=", "0", ")", "+", "sum", "(", "bbox", ">=", "1", ")", ")", ">=", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "(", "obj", "[", "'name'", "]", "in", "wordname_15", ")", ":", "\n", "                        ", "id", "=", "wordname_15", ".", "index", "(", "obj", "[", "'name'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "", "outline", "=", "str", "(", "id", ")", "+", "' '", "+", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "bbox", ")", ")", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "# def testmergepatchlabel():", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.latlon2decimals": [[127, 132], ["re.compile", "re.findall", "float", "float", "float"], "function", ["None"], ["def", "latlon2decimals", "(", "degreestr", ")", ":", "\n", "    ", "pattern", "=", "re", ".", "compile", "(", "r'-*[0-9]+'", ")", "\n", "src", "=", "re", ".", "findall", "(", "pattern", ",", "degreestr", ")", "\n", "dst", "=", "float", "(", "src", "[", "0", "]", ")", "+", "float", "(", "src", "[", "1", "]", ")", "/", "60", "+", "float", "(", "src", "[", "2", "]", ")", "/", "3600", "\n", "return", "dst", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.keyvalueReverse": [[133, 135], ["dict", "zip", "inputdic.values", "inputdic.keys"], "function", ["None"], ["", "def", "keyvalueReverse", "(", "inputdic", ")", ":", "\n", "    ", "return", "dict", "(", "zip", "(", "inputdic", ".", "values", "(", ")", ",", "inputdic", ".", "keys", "(", ")", ")", ")", "\n", "", "def", "GetFileFromThisRootDir", "(", "dir", ",", "ext", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.GetFileFromThisRootDir": [[135, 147], ["os.walk", "os.path.join", "allfiles.append", "os.path.splitext", "allfiles.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "GetFileFromThisRootDir", "(", "dir", ",", "ext", "=", "None", ")", ":", "\n", "  ", "allfiles", "=", "[", "]", "\n", "needExtFilter", "=", "(", "ext", "!=", "None", ")", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "dir", ")", ":", "\n", "    ", "for", "filespath", "in", "files", ":", "\n", "      ", "filepath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filespath", ")", "\n", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filepath", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "needExtFilter", "and", "extension", "in", "ext", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "elif", "not", "needExtFilter", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "", "", "return", "allfiles", "\n", "", "def", "filesetcalc", "(", "path1", ",", "path2", ",", "calc", "=", "''", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.filesetcalc": [[147, 167], ["utils.GetFileFromThisRootDir", "file_set1.intersection", "file_set1.difference", "file_set1.union", "print", "print", "os.path.splitext", "utils.GetFileFromThisRootDir", "os.path.splitext", "utils.GetFileFromThisRootDir", "print", "os.path.basename", "os.path.basename", "print"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir"], ["", "def", "filesetcalc", "(", "path1", ",", "path2", ",", "calc", "=", "''", ")", ":", "\n", "    ", "if", "calc", "==", "''", ":", "\n", "        ", "print", "(", "'please assigh a calc'", ")", "\n", "return", "\n", "", "file1_list", "=", "GetFileFromThisRootDir", "(", "path1", ")", "\n", "file_set1", "=", "{", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "x", ")", ")", "[", "0", "]", "for", "x", "in", "GetFileFromThisRootDir", "(", "path1", ")", "}", "\n", "file_set2", "=", "{", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "x", ")", ")", "[", "0", "]", "for", "x", "in", "GetFileFromThisRootDir", "(", "path2", ")", "}", "\n", "inter_set", "=", "file_set1", ".", "intersection", "(", "file_set2", ")", "\n", "diff_set", "=", "file_set1", ".", "difference", "(", "file_set2", ")", "\n", "union_set", "=", "file_set1", ".", "union", "(", "file_set2", ")", "\n", "#suffix1 = os.path.splitext(os.path.basename(file1_list[0]))[1]", "\n", "if", "calc", "==", "'u'", ":", "\n", "        ", "print", "(", "'union_set:'", ",", "union_set", ")", "\n", "return", "union_set", "\n", "", "elif", "calc", "==", "'d'", ":", "\n", "        ", "print", "(", "'diff_dict:'", ",", "diff_set", ")", "\n", "return", "diff_set", "\n", "", "elif", "calc", "==", "'i'", ":", "\n", "        ", "print", "(", "'inter_dict:'", ",", "inter_set", ")", "\n", "return", "inter_set", "\n", "", "", "def", "dots2ToRecC", "(", "rec", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots2ToRecC": [[167, 174], ["utils.dots2ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots2ToRec4"], ["", "", "def", "dots2ToRecC", "(", "rec", ")", ":", "\n", "    ", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "dots2ToRec4", "(", "rec", ")", "\n", "x", "=", "(", "xmin", "+", "xmax", ")", "/", "2", "\n", "y", "=", "(", "ymin", "+", "ymax", ")", "/", "2", "\n", "w", "=", "xmax", "-", "xmin", "\n", "h", "=", "ymax", "-", "ymin", "\n", "return", "x", ",", "y", ",", "w", ",", "h", "\n", "", "def", "dots2ToRec4", "(", "rec", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots2ToRec4": [[174, 182], ["range", "min", "max", "min", "max"], "function", ["None"], ["", "def", "dots2ToRec4", "(", "rec", ")", ":", "\n", "    ", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "rec", "[", "0", "]", ",", "rec", "[", "0", "]", ",", "rec", "[", "1", "]", ",", "rec", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "xmin", "=", "min", "(", "xmin", ",", "rec", "[", "i", "*", "2", "+", "1", "]", ")", "\n", "xmax", "=", "max", "(", "xmax", ",", "rec", "[", "i", "*", "2", "+", "1", "]", ")", "\n", "ymin", "=", "min", "(", "ymin", ",", "rec", "[", "i", "*", "2", "+", "2", "]", ")", "\n", "ymax", "=", "max", "(", "ymax", ",", "rec", "[", "i", "*", "2", "+", "2", "]", ")", "\n", "", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "", "def", "dots4ToRecC", "(", "poly", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRecC": [[182, 189], ["utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "def", "dots4ToRecC", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "dots4ToRec4", "(", "poly", ")", "\n", "x", "=", "(", "xmin", "+", "xmax", ")", "/", "2", "\n", "y", "=", "(", "ymin", "+", "ymax", ")", "/", "2", "\n", "w", "=", "xmax", "-", "xmin", "\n", "h", "=", "ymax", "-", "ymin", "\n", "return", "x", ",", "y", ",", "w", ",", "h", "\n", "", "def", "dots4ToRec4", "(", "poly", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRec4": [[189, 195], ["min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max"], "function", ["None"], ["", "def", "dots4ToRec4", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "min", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "min", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "", "def", "dots4ToRec8", "(", "poly", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRec8": [[195, 198], ["utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "def", "dots4ToRec8", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "dots4ToRec4", "(", "poly", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "#return dots2ToRec8(dots4ToRec4(poly))", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots2ToRec8": [[199, 202], ["None"], "function", ["None"], ["", "def", "dots2ToRec8", "(", "rec", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "rec", "[", "0", "]", ",", "rec", "[", "1", "]", ",", "rec", "[", "2", "]", ",", "rec", "[", "3", "]", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "", "def", "orderdict_byvalue", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.orderdict_byvalue": [[202, 204], ["None"], "function", ["None"], ["", "def", "orderdict_byvalue", "(", ")", ":", "\n", "    ", "pass", "\n", "", "def", "testparse_labelme_poly", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testparse_labelme_poly": [[204, 207], ["utils.parse_labelme_poly", "print"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_labelme_poly"], ["", "def", "testparse_labelme_poly", "(", ")", ":", "\n", "    ", "objects", "=", "parse_labelme_poly", "(", "r'E:\\GAOFEN2\\gaofen2Labelme\\annotations\\singapore-2016-4-27-1.xml'", ")", "\n", "print", "(", "objects", ")", "\n", "", "def", "filecopy", "(", "srcpath", ",", "dstpath", ",", "filenames", ",", "extent", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.filecopy": [[207, 215], ["os.path.join", "os.path.join", "print", "print", "os.path.exists", "shutil.copyfile"], "function", ["None"], ["", "def", "filecopy", "(", "srcpath", ",", "dstpath", ",", "filenames", ",", "extent", ")", ":", "\n", "    ", "for", "name", "in", "filenames", ":", "\n", "        ", "srcdir", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "name", "+", "extent", ")", "\n", "dstdir", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "extent", ")", "\n", "print", "(", "'srcdir:'", ",", "srcdir", ")", "\n", "print", "(", "'dstdir:'", ",", "dstdir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "srcdir", ")", ":", "\n", "            ", "shutil", ".", "copyfile", "(", "srcdir", ",", "dstdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.filemove": [[216, 226], ["os.path.join", "os.path.join", "print", "print", "os.path.exists", "shutil.move"], "function", ["None"], ["", "", "", "def", "filemove", "(", "srcpath", ",", "dstpath", ",", "filenames", ",", "extent", ")", ":", "\n", "    ", "for", "name", "in", "filenames", ":", "\n", "        ", "srcdir", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "name", "+", "extent", ")", "\n", "dstdir", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "extent", ")", "\n", "print", "(", "'srcdir:'", ",", "srcdir", ")", "\n", "print", "(", "'dstdir:'", ",", "dstdir", ")", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "if", "os", ".", "path", ".", "exists", "(", "srcdir", ")", ":", "\n", "            ", "shutil", ".", "move", "(", "srcdir", ",", "dstdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.TrainTestSplit": [[227, 251], ["utils.GetFileFromThisRootDir", "int", "int", "print", "print", "print", "random.shuffle", "print", "set", "set", "set", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.basename", "set.intersection", "len", "len", "os.path.splitext", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir"], ["", "", "", "def", "TrainTestSplit", "(", ")", ":", "\n", "    ", "basepath", "=", "r'E:\\bod-dataset'", "\n", "filelist", "=", "GetFileFromThisRootDir", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "'images'", ")", ")", "\n", "name", "=", "[", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "0", "]", ")", "for", "x", "in", "filelist", "if", "(", "x", "!=", "'Thumbs'", ")", "]", "\n", "train_len", "=", "int", "(", "len", "(", "name", ")", "*", "0.5", ")", "\n", "val_len", "=", "int", "(", "len", "(", "name", ")", "*", "1", "/", "6", ")", "\n", "test_len", "=", "len", "(", "name", ")", "-", "train_len", "-", "val_len", "\n", "print", "(", "'train_len:'", ",", "train_len", ")", "\n", "print", "(", "'val_len:'", ",", "val_len", ")", "\n", "print", "(", "'test_len:'", ",", "test_len", ")", "\n", "random", ".", "shuffle", "(", "name", ")", "\n", "print", "(", "'shuffle name:'", ",", "name", ")", "\n", "train_set", "=", "set", "(", "name", "[", "0", ":", "train_len", "]", ")", "\n", "val_set", "=", "set", "(", "name", "[", "train_len", ":", "(", "train_len", "+", "val_len", ")", "]", ")", "\n", "test_set", "=", "set", "(", "name", "[", "(", "train_len", "+", "val_len", ")", ":", "]", ")", "\n", "print", "(", "'intersection:'", ",", "train_set", ".", "intersection", "(", "test_set", ")", ")", "\n", "imgsrcpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'images'", ")", "\n", "txtsrcpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'wordlabel'", ")", "\n", "imgtestpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'testset'", ",", "'images'", ")", "\n", "txttestpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'testset'", ",", "'wordlabel'", ")", "\n", "imgtrainpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'trainset'", ",", "'images'", ")", "\n", "txttrainpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'trainset'", ",", "'wordlabel'", ")", "\n", "imgvalpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'valset'", ",", "'images'", ")", "\n", "txtvalpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'valset'", ",", "'wordlabel'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.py_cpu_nms_poly": [[281, 308], ["range", "len", "shapely.Polygon", "polys.append", "areas.append", "scores.argsort", "keep.append", "range", "numpy.array", "order.", "len", "polys[].intersection", "np.array.append", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "py_cpu_nms_poly", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "polys", "=", "[", "]", "\n", "areas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "shgeo", ".", "Polygon", "(", "[", "(", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ")", ",", "\n", "(", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ")", ",", "\n", "(", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ")", ",", "\n", "(", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", ")", "\n", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "areas", ".", "append", "(", "tm_polygon", ".", "area", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "order", ".", "size", "-", "1", ")", ")", ":", "\n", "            ", "inter_poly", "=", "polys", "[", "order", "[", "0", "]", "]", ".", "intersection", "(", "polys", "[", "order", "[", "order", "[", "j", "+", "1", "]", "]", "]", ")", "\n", "inter_area", "=", "inter_poly", ".", "area", "\n", "ovr", ".", "append", "(", "inter_area", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "j", "+", "1", "]", "]", "-", "inter_area", ")", ")", "\n", "", "ovr", "=", "np", ".", "array", "(", "ovr", ")", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "(", "[", "inds", "+", "1", "]", ")", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.py_cpu_nms": [[310, 340], ["scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "", "def", "test_py_cpu_nms", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.test_py_cpu_nms": [[340, 348], ["numpy.array", "utils.py_cpu_nms", "print"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms"], ["", "def", "test_py_cpu_nms", "(", ")", ":", "\n", "    ", "dets", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "4", ",", "4", ",", "0.7", "]", ",", "\n", "[", "2", ",", "2", ",", "7", ",", "6", ",", "0.8", "]", ",", "\n", "[", "3", ",", "2", ",", "8", ",", "5", ",", "0.6", "]", ",", "\n", "[", "0", ",", "0", ",", "7", ",", "7", ",", "0.75", "]", "\n", "]", ")", "\n", "keep", "=", "py_cpu_nms", "(", "dets", ",", "0.5", ")", "\n", "print", "(", "keep", ")", "\n", "", "def", "getorderLabel", "(", "filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.getorderLabel": [[348, 357], ["open", "open.readlines", "x.strip().split", "labellist.count", "len", "x.strip"], "function", ["None"], ["", "def", "getorderLabel", "(", "filename", ")", ":", "\n", "    ", "f", "=", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf_16'", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "lines", "]", "\n", "labellist", "=", "[", "x", "[", "8", "]", "for", "x", "in", "splitlines", "]", "\n", "orderlabel", "=", "{", "}", "\n", "for", "cls", "in", "clsdict", ":", "\n", "        ", "orderlabel", "[", "cls", "]", "=", "labellist", ".", "count", "(", "cls", ")", "/", "len", "(", "labellist", ")", "\n", "", "return", "orderlabel", "\n", "", "def", "parse_rec", "(", "filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_rec": [[357, 374], ["xml.parse", "ET.parse.findall", "int", "obj.find", "objects.append", "obj.find", "int", "int", "int", "int", "obj.find", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_rec", "(", "filename", ")", ":", "\n", "    ", "\"\"\" Parse a PASCAL VOC xml file \"\"\"", "\n", "tree", "=", "ET", ".", "parse", "(", "filename", ")", "\n", "objects", "=", "[", "]", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "'object'", ")", ":", "\n", "        ", "obj_struct", "=", "{", "}", "\n", "obj_struct", "[", "'name'", "]", "=", "obj", ".", "find", "(", "'name'", ")", ".", "text", "\n", "#obj_struct['pose'] = obj.find('pose').text", "\n", "#obj_struct['truncated'] = int(obj.find('truncated').text)", "\n", "obj_struct", "[", "'difficult'", "]", "=", "int", "(", "obj", ".", "find", "(", "'difficult'", ")", ".", "text", ")", "\n", "bbox", "=", "obj", ".", "find", "(", "'bndbox'", ")", "\n", "obj_struct", "[", "'bbox'", "]", "=", "[", "int", "(", "bbox", ".", "find", "(", "'xmin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "'ymin'", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "'xmax'", ")", ".", "text", ")", ",", "\n", "int", "(", "bbox", ".", "find", "(", "'ymax'", ")", ".", "text", ")", "]", "\n", "objects", ".", "append", "(", "obj_struct", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_pascal": [[375, 392], ["xml.parse", "ET.parse.findall", "int", "obj.find", "objects.append", "obj.find", "float", "float", "float", "float", "obj.find", "obj.find.find", "obj.find.find", "obj.find.find", "obj.find.find"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_pascal", "(", "filename", ")", ":", "\n", "    ", "\"\"\" Parse a PASCAL VOC xml file \"\"\"", "\n", "tree", "=", "ET", ".", "parse", "(", "filename", ")", "\n", "objects", "=", "[", "]", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "'object'", ")", ":", "\n", "        ", "obj_struct", "=", "{", "}", "\n", "obj_struct", "[", "'name'", "]", "=", "obj", ".", "find", "(", "'name'", ")", ".", "text", "\n", "#obj_struct['pose'] = obj.find('pose').text", "\n", "#obj_struct['truncated'] = int(obj.find('truncated').text)", "\n", "obj_struct", "[", "'difficult'", "]", "=", "int", "(", "obj", ".", "find", "(", "'difficult'", ")", ".", "text", ")", "\n", "bbox", "=", "obj", ".", "find", "(", "'bndbox'", ")", "\n", "obj_struct", "[", "'bbox'", "]", "=", "[", "float", "(", "bbox", ".", "find", "(", "'xmin'", ")", ".", "text", ")", ",", "\n", "float", "(", "bbox", ".", "find", "(", "'ymin'", ")", ".", "text", ")", ",", "\n", "float", "(", "bbox", ".", "find", "(", "'xmax'", ")", ".", "text", ")", ",", "\n", "float", "(", "bbox", ".", "find", "(", "'ymax'", ")", ".", "text", ")", "]", "\n", "objects", ".", "append", "(", "obj_struct", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.pascal2poly": [[393, 404], ["utils.GetFileFromThisRootDir", "utils.parse_pascal", "utils.mybasename", "codecs.open", "os.path.join", "utils.dots2ToRec8", "f_out.write", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_pascal", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots2ToRec8"], ["", "def", "pascal2poly", "(", ")", ":", "\n", "    ", "filenames", "=", "GetFileFromThisRootDir", "(", "r'E:\\bod-dataset\\cuttestpath2\\pascalLabel'", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "objects", "=", "parse_pascal", "(", "filename", ")", "\n", "basename", "=", "mybasename", "(", "filename", ")", "\n", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "r'E:\\bod-dataset\\cuttestpath2\\voc2dota'", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ",", "'utf_16'", ")", "as", "f_out", ":", "\n", "            ", "for", "obj", "in", "objects", ":", "\n", "                ", "rect", "=", "obj", "[", "'bbox'", "]", "\n", "poly", "=", "dots2ToRec8", "(", "rect", ")", "\n", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "+", "' '", "+", "obj", "[", "'name'", "]", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_labelme_poly": [[405, 423], ["xml.parse", "ET.parse.findall", "int", "obj.find().findall", "objects.append", "obj.find", "obj.find", "obj.find", "obj.find", "obj.find", "obj.find", "point.find", "point.find"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "", "", "def", "parse_labelme_poly", "(", "filename", ")", ":", "\n", "    ", "\"\"\" Parse a labelme xml file \"\"\"", "\n", "tree", "=", "ET", ".", "parse", "(", "filename", ")", "\n", "objects", "=", "[", "]", "\n", "for", "obj", "in", "tree", ".", "findall", "(", "'object'", ")", ":", "\n", "        ", "obj_struct", "=", "{", "}", "\n", "obj_struct", "[", "'name'", "]", "=", "obj", ".", "find", "(", "'name'", ")", ".", "text", "\n", "obj_struct", "[", "'deleted'", "]", "=", "obj", ".", "find", "(", "'deleted'", ")", ".", "text", "\n", "obj_struct", "[", "'verified'", "]", "=", "int", "(", "obj", ".", "find", "(", "'verified'", ")", ".", "text", ")", "\n", "obj_struct", "[", "'occluded'", "]", "=", "obj", ".", "find", "(", "'occluded'", ")", ".", "text", "\n", "obj_struct", "[", "'attributes'", "]", "=", "obj", ".", "find", "(", "'attributes'", ")", ".", "text", "\n", "poly", "=", "obj", ".", "find", "(", "'polygon'", ")", ".", "findall", "(", "'pt'", ")", "\n", "obj_struct", "[", "'polygon'", "]", "=", "[", "]", "\n", "for", "point", "in", "poly", ":", "\n", "            ", "pt", "=", "[", "point", ".", "find", "(", "'x'", ")", ".", "text", ",", "point", ".", "find", "(", "'y'", ")", ".", "text", "]", "\n", "obj_struct", "[", "'polygon'", "]", "=", "obj_struct", "[", "'polygon'", "]", "+", "pt", "\n", "", "objects", ".", "append", "(", "obj_struct", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance": [[424, 426], ["numpy.sqrt", "numpy.sum", "numpy.square"], "function", ["None"], ["", "def", "distance", "(", "point1", ",", "point2", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "point1", "-", "point2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_dota_poly": [[429, 482], ["open", "f.readline", "codecs.open", "f.readline.strip().split", "shapely.Polygon", "list", "max", "min", "objects.append", "len", "len", "len", "map", "utils.distance", "utils.distance", "utils.distance", "utils.distance", "f.readline.strip", "len", "float", "float", "float", "float", "float", "float", "float", "float", "numpy.array"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance"], ["def", "parse_dota_poly", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "[", "]", "\n", "#print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "", "count", "=", "0", "\n", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "count", "=", "count", "+", "1", "\n", "# if count < 2:", "\n", "#     continue", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n", "### clear the wrong name after check all the data", "\n", "#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "                ", "if", "(", "splitlines", "[", "9", "]", "==", "'tr'", ")", ":", "\n", "                    ", "object_struct", "[", "'difficult'", "]", "=", "'1'", "\n", "", "else", ":", "\n", "                    ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n", "#     object_struct['difficult'] = 0", "\n", "", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "poly", "=", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "array", "(", "x", ")", ",", "object_struct", "[", "'poly'", "]", ")", ")", "\n", "object_struct", "[", "'long-axis'", "]", "=", "max", "(", "distance", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "distance", "(", "poly", "[", "1", "]", ",", "poly", "[", "2", "]", ")", ")", "\n", "object_struct", "[", "'short-axis'", "]", "=", "min", "(", "distance", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "distance", "(", "poly", "[", "1", "]", ",", "poly", "[", "2", "]", ")", ")", "\n", "if", "(", "object_struct", "[", "'long-axis'", "]", "<", "15", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'1'", "\n", "global", "small_count", "\n", "small_count", "=", "small_count", "+", "1", "\n", "", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_dota_poly2": [[483, 489], ["utils.parse_dota_poly", "utils.TuplePoly2Poly", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly"], ["", "def", "parse_dota_poly2", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "parse_dota_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "obj", "[", "'poly'", "]", "=", "TuplePoly2Poly", "(", "obj", "[", "'poly'", "]", ")", "\n", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "int", ",", "obj", "[", "'poly'", "]", ")", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly": [[490, 539], ["open", "f.readline", "codecs.open", "f.readline.strip().split", "shapely.Polygon", "list", "max", "min", "objects.append", "len", "len", "len", "map", "utils.distance", "utils.distance", "utils.distance", "utils.distance", "f.readline.strip", "len", "float", "float", "float", "float", "float", "float", "float", "float", "numpy.array"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.distance"], ["", "def", "parse_bod_poly", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "[", "]", "\n", "#print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf_16'", ")", "\n", "f", "=", "fd", "\n", "", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "'utf-16'", ")", "\n", "f", "=", "fd", "\n", "", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n", "### clear the wrong name after check all the data", "\n", "#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "                ", "if", "(", "splitlines", "[", "9", "]", "==", "'tr'", ")", ":", "\n", "                    ", "object_struct", "[", "'difficult'", "]", "=", "'1'", "\n", "", "else", ":", "\n", "                    ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n", "#     object_struct['difficult'] = 0", "\n", "", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "poly", "=", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "array", "(", "x", ")", ",", "object_struct", "[", "'poly'", "]", ")", ")", "\n", "object_struct", "[", "'long-axis'", "]", "=", "max", "(", "distance", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "distance", "(", "poly", "[", "1", "]", ",", "poly", "[", "2", "]", ")", ")", "\n", "object_struct", "[", "'short-axis'", "]", "=", "min", "(", "distance", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "distance", "(", "poly", "[", "1", "]", ",", "poly", "[", "2", "]", ")", ")", "\n", "if", "(", "object_struct", "[", "'long-axis'", "]", "<", "15", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'1'", "\n", "global", "small_count", "\n", "small_count", "=", "small_count", "+", "1", "\n", "", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.TuplePoly2Poly": [[540, 547], ["None"], "function", ["None"], ["", "def", "TuplePoly2Poly", "(", "poly", ")", ":", "\n", "    ", "outpoly", "=", "[", "poly", "[", "0", "]", "[", "0", "]", ",", "poly", "[", "0", "]", "[", "1", "]", ",", "\n", "poly", "[", "1", "]", "[", "0", "]", ",", "poly", "[", "1", "]", "[", "1", "]", ",", "\n", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "2", "]", "[", "1", "]", ",", "\n", "poly", "[", "3", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "1", "]", "\n", "]", "\n", "return", "outpoly", "\n", "", "def", "Poly2TuplePoly", "(", "poly", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.Poly2TuplePoly": [[547, 554], ["None"], "function", ["None"], ["", "def", "Poly2TuplePoly", "(", "poly", ")", ":", "\n", "    ", "outpoly", "=", "[", "(", "poly", "[", "0", "]", ",", "poly", "[", "1", "]", ")", ",", "\n", "(", "poly", "[", "2", "]", ",", "poly", "[", "3", "]", ")", ",", "\n", "(", "poly", "[", "4", "]", ",", "poly", "[", "5", "]", ")", ",", "\n", "(", "poly", "[", "6", "]", ",", "poly", "[", "7", "]", ")", ",", "\n", "]", "\n", "return", "outpoly", "\n", "", "def", "parse_bod_poly2", "(", "filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly2": [[554, 560], ["utils.parse_bod_poly", "utils.TuplePoly2Poly", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly"], ["", "def", "parse_bod_poly2", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "parse_bod_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "obj", "[", "'poly'", "]", "=", "TuplePoly2Poly", "(", "obj", "[", "'poly'", "]", ")", "\n", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "int", ",", "obj", "[", "'poly'", "]", ")", ")", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_rec": [[561, 571], ["utils.parse_bod_poly", "utils.dots4ToRec4", "max", "min"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "def", "parse_bod_rec", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "parse_bod_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "dots4ToRec4", "(", "poly", ")", "\n", "obj", "[", "'bndbox'", "]", "=", "bbox", "\n", "obj", "[", "'long-axis'", "]", "=", "max", "(", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ")", "\n", "obj", "[", "'size'", "]", "=", "obj", "[", "'long-axis'", "]", "\n", "obj", "[", "'short-axis'", "]", "=", "min", "(", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", ")", "\n", "", "return", "objects", "\n", "", "def", "ImgFormT", "(", "srcpath", ",", "dstpath", ",", "srcform", ",", "dstform", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.ImgFormT": [[571, 577], ["utils.GetFileFromThisRootDir", "cv2.imread", "cv2.imwrite", "os.path.splitext", "os.path.join", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir"], ["", "def", "ImgFormT", "(", "srcpath", ",", "dstpath", ",", "srcform", ",", "dstform", ")", ":", "\n", "    ", "namelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ",", "srcform", ")", "\n", "for", "imgname", "in", "namelist", ":", "\n", "        ", "src", "=", "cv2", ".", "imread", "(", "imgname", ")", "\n", "basename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "imgname", ")", ")", "[", "0", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", "+", "dstform", ")", ",", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.saveimageWithMask": [[578, 595], ["copy.deepcopy", "cv2.imwrite", "range", "len", "int", "int", "range", "int", "int", "shapely.Point", "shgeo.Point.within", "int", "int"], "function", ["None"], ["", "", "def", "saveimageWithMask", "(", "img", ",", "outname", ",", "mask_poly", ")", ":", "\n", "\n", "    ", "dstimg", "=", "copy", ".", "deepcopy", "(", "img", ")", "\n", "for", "mask", "in", "mask_poly", ":", "\n", "        ", "bound", "=", "mask", ".", "bounds", "\n", "if", "(", "len", "(", "bound", ")", "<", "4", ")", ":", "\n", "            ", "continue", "\n", "", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "bound", "[", "0", "]", ",", "bound", "[", "1", "]", ",", "bound", "[", "2", "]", ",", "bound", "[", "3", "]", "\n", "for", "x", "in", "range", "(", "int", "(", "xmin", ")", ",", "int", "(", "xmax", ")", ")", ":", "\n", "            ", "for", "y", "in", "range", "(", "int", "(", "ymin", ")", ",", "int", "(", "ymax", ")", ")", ":", "\n", "                ", "point", "=", "shgeo", ".", "Point", "(", "x", ",", "y", ")", "\n", "if", "point", ".", "within", "(", "mask", ")", ":", "\n", "#print('withing')", "\n", "\n", "                    ", "dstimg", "[", "int", "(", "y", ")", "]", "[", "int", "(", "x", ")", "]", "=", "0", "\n", "\n", "", "", "", "", "cv2", ".", "imwrite", "(", "outname", ",", "dstimg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.reWriteImgWithMask": [[596, 616], ["utils.GetFileFromThisRootDir", "utils.parse_bod_poly", "utils.mybasename", "os.path.join", "cv2.imread", "os.path.join", "re.findall", "len", "utils.saveimageWithMask", "mask_polys.append", "shapely.Polygon", "mask_polys.append", "shapely.Polygon"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.saveimageWithMask", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "reWriteImgWithMask", "(", "srcpath", ",", "dstpath", ",", "gtpath", ",", "srcform", ",", "dstform", ")", ":", "\n", "    ", "namelist", "=", "GetFileFromThisRootDir", "(", "gtpath", ")", "\n", "for", "fullname", "in", "namelist", ":", "\n", "        ", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "mask_polys", "=", "[", "]", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "clsname", "=", "obj", "[", "'name'", "]", "\n", "matches", "=", "re", ".", "findall", "(", "'area|mask'", ",", "clsname", ")", "\n", "if", "'mask'", "in", "matches", ":", "\n", "#print('mask:')", "\n", "                ", "mask_polys", ".", "append", "(", "shgeo", ".", "Polygon", "(", "obj", "[", "'poly'", "]", ")", ")", "\n", "", "elif", "'area'", "in", "matches", ":", "\n", "#print('area:')", "\n", "                ", "mask_polys", ".", "append", "(", "shgeo", ".", "Polygon", "(", "obj", "[", "'poly'", "]", ")", ")", "\n", "", "", "basename", "=", "mybasename", "(", "fullname", ")", "\n", "imgname", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "basename", "+", "srcform", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "imgname", ")", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", "+", "dstform", ")", "\n", "if", "len", "(", "mask_polys", ")", ">", "0", ":", "\n", "            ", "saveimageWithMask", "(", "img", ",", "dstname", ",", "mask_polys", ")", "\n", "", "", "", "def", "testReWriteimgWithMask", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testReWriteimgWithMask": [[616, 625], ["utils.reWriteImgWithMask"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.reWriteImgWithMask"], ["", "", "", "def", "testReWriteimgWithMask", "(", ")", ":", "\n", "    ", "gtpath", "=", "r'E:\\bod-dataset\\labelTxt'", "\n", "srcpath", "=", "r'E:\\bod-dataset\\images'", "\n", "dstpath", "=", "r'E:\\bod-dataset\\jpgswithMask'", "\n", "reWriteImgWithMask", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "gtpath", ",", "\n", "'.png'", ",", "\n", "'.jpg'", ")", "\n", "", "def", "testImgTrans", "(", "basepath", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testImgTrans": [[625, 629], ["os.path.join", "os.path.join", "utils.ImgFormT"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.ImgFormT"], ["", "def", "testImgTrans", "(", "basepath", ")", ":", "\n", "    ", "dstpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'Secondjpg'", ")", "\n", "srcpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'secondQuality'", ")", "\n", "ImgFormT", "(", "srcpath", ",", "dstpath", ",", "'.jpg'", ")", "\n", "", "def", "getcategory", "(", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.getcategory": [[629, 659], ["utils.getcategory.initdic"], "function", ["None"], ["", "def", "getcategory", "(", "\n", "basepath", ",", "\n", "label", ",", "\n", ")", ":", "\n", "    ", "classedict", "=", "{", "}", "\n", "def", "initdic", "(", ")", ":", "\n", "        ", "for", "clsname", "in", "classname_15", ":", "\n", "            ", "wordname", "=", "datamap_15", "[", "clsname", "]", "\n", "classedict", "[", "wordname", "]", "=", "[", "]", "\n", "", "", "initdic", "(", ")", "\n", "picklepath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'pickle'", ")", "\n", "pickledir", "=", "os", ".", "path", ".", "join", "(", "picklepath", ",", "'category-file.pickle'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "pickledir", ")", ":", "\n", "        ", "labelpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "label", ")", "\n", "filelist", "=", "GetFileFromThisRootDir", "(", "labelpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "            ", "name", "=", "mybasename", "(", "fullname", ")", "\n", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "#wordname = datamap[obj['name']]", "\n", "                ", "wordname", "=", "obj", "[", "'name'", "]", "\n", "if", "name", "not", "in", "classedict", "[", "wordname", "]", ":", "\n", "                    ", "classedict", "[", "wordname", "]", ".", "append", "(", "name", ")", "\n", "\n", "", "", "", "with", "open", "(", "pickledir", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "classedict", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "pickledir", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "classedict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "return", "classedict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.bod2darknet": [[660, 677], ["utils.GetFileFromThisRootDir", "utils.parse_bod_poly", "os.path.splitext", "open", "os.path.basename", "os.path.join", "f_out.write", "numpy.array", "extractclassname.index", "utils.dots4ToRecC", "sum", "sum", "str", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRecC"], ["", "def", "bod2darknet", "(", "srcpath", ",", "dstpath", ",", "extractclassname", ")", ":", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "        ", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "fullname", ")", ")", "[", "0", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "obj", "in", "objects", ":", "\n", "                ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "np", ".", "array", "(", "dots4ToRecC", "(", "poly", ")", ")", "/", "1024", "\n", "if", "(", "sum", "(", "bbox", "<=", "0", ")", "+", "sum", "(", "bbox", ">=", "1", ")", ")", ">=", "1", ":", "\n", "                    ", "continue", "\n", "", "if", "(", "obj", "[", "'name'", "]", "in", "extractclassname", ")", ":", "\n", "                    ", "id", "=", "extractclassname", ".", "index", "(", "obj", "[", "'name'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "outline", "=", "str", "(", "id", ")", "+", "' '", "+", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "bbox", ")", ")", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.nwpubodcoord2darknet": [[678, 693], ["utils.GetFileFromThisRootDir", "utils.parse_bod_poly", "os.path.splitext", "open", "os.path.basename", "os.path.join", "f_out.write", "numpy.array", "int", "utils.dots4ToRecC", "sum", "sum", "str", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.dots4ToRecC"], ["", "", "", "", "def", "nwpubodcoord2darknet", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "        ", "objects", "=", "parse_bod_poly", "(", "fullname", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "fullname", ")", ")", "[", "0", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "obj", "in", "objects", ":", "\n", "                ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "np", ".", "array", "(", "dots4ToRecC", "(", "poly", ")", ")", "/", "1024", "\n", "if", "(", "sum", "(", "bbox", "<=", "0", ")", "+", "sum", "(", "bbox", ">=", "1", ")", ")", ">=", "1", ":", "\n", "                    ", "continue", "\n", "", "index", "=", "int", "(", "obj", "[", "'name'", "]", ")", "-", "1", "\n", "\n", "outline", "=", "str", "(", "index", ")", "+", "' '", "+", "' '", ".", "join", "(", "list", "(", "map", "(", "str", ",", "bbox", ")", ")", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "", "def", "testbod2darknet", "(", "basepath", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testbod2darknet": [[693, 696], ["utils.bod2darknet", "utils.bod2darknet", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.bod2darknet", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.bod2darknet"], ["", "", "", "", "def", "testbod2darknet", "(", "basepath", ")", ":", "\n", "    ", "bod2darknet", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "r'testsplit'", ")", ")", "\n", "bod2darknet", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "r'trainsplit-2'", ")", ")", "\n", "", "def", "generatefilelist", "(", "basepath", ",", "filepath", ",", "outname", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.generatefilelist": [[696, 703], ["utils.GetFileFromThisRootDir", "os.path.join", "open", "os.path.join", "os.path.basename", "os.path.join", "f_out.write", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir"], ["", "def", "generatefilelist", "(", "basepath", ",", "filepath", ",", "outname", ")", ":", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "os", ".", "path", ".", "join", "(", "filepath", ",", "'images'", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "outname", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "        ", "for", "fullname", "in", "filelist", ":", "\n", "            ", "name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "fullname", ")", "[", "0", "]", ")", "\n", "outline", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'JPEGImages'", ",", "name", "+", "'.jpg'", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "", "", "", "def", "testgeneratefilelist", "(", "basepath", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testgeneratefilelist": [[703, 708], ["os.path.join", "os.path.join", "utils.generatefilelist", "utils.generatefilelist"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.generatefilelist", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.generatefilelist"], ["", "", "", "def", "testgeneratefilelist", "(", "basepath", ")", ":", "\n", "    ", "testpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'testsplit'", ")", "\n", "trainpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'trainsplit-2'", ")", "\n", "generatefilelist", "(", "basepath", ",", "trainpath", ",", "'train.txt'", ")", "\n", "generatefilelist", "(", "basepath", ",", "testpath", ",", "'test.txt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.validate_clockwise_points": [[709, 735], ["len", "Exception", "int", "int", "int", "int", "int", "int", "int", "int", "str", "len"], "function", ["None"], ["", "def", "validate_clockwise_points", "(", "points", ")", ":", "\n", "    ", "\"\"\"\n    Validates that the points that the 4 points that dlimite a polygon are in clockwise order.\n    \"\"\"", "\n", "\n", "if", "len", "(", "points", ")", "!=", "4", ":", "\n", "        ", "raise", "Exception", "(", "\"Points list not valid.\"", "+", "str", "(", "len", "(", "points", ")", ")", ")", "\n", "\n", "", "point", "=", "[", "\n", "[", "int", "(", "points", "[", "0", "]", "[", "0", "]", ")", ",", "int", "(", "points", "[", "0", "]", "[", "1", "]", ")", "]", ",", "\n", "[", "int", "(", "points", "[", "1", "]", "[", "0", "]", ")", ",", "int", "(", "points", "[", "1", "]", "[", "1", "]", ")", "]", ",", "\n", "[", "int", "(", "points", "[", "2", "]", "[", "0", "]", ")", ",", "int", "(", "points", "[", "2", "]", "[", "1", "]", ")", "]", ",", "\n", "[", "int", "(", "points", "[", "3", "]", "[", "0", "]", ")", ",", "int", "(", "points", "[", "3", "]", "[", "1", "]", ")", "]", "\n", "]", "\n", "edge", "=", "[", "\n", "(", "point", "[", "1", "]", "[", "0", "]", "-", "point", "[", "0", "]", "[", "0", "]", ")", "*", "(", "point", "[", "1", "]", "[", "1", "]", "+", "point", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "(", "point", "[", "2", "]", "[", "0", "]", "-", "point", "[", "1", "]", "[", "0", "]", ")", "*", "(", "point", "[", "2", "]", "[", "1", "]", "+", "point", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "(", "point", "[", "3", "]", "[", "0", "]", "-", "point", "[", "2", "]", "[", "0", "]", ")", "*", "(", "point", "[", "3", "]", "[", "1", "]", "+", "point", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "(", "point", "[", "0", "]", "[", "0", "]", "-", "point", "[", "3", "]", "[", "0", "]", ")", "*", "(", "point", "[", "0", "]", "[", "1", "]", "+", "point", "[", "3", "]", "[", "1", "]", ")", "\n", "]", "\n", "\n", "summatory", "=", "edge", "[", "0", "]", "+", "edge", "[", "1", "]", "+", "edge", "[", "2", "]", "+", "edge", "[", "3", "]", ";", "\n", "if", "summatory", ">", "0", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "True", "\n", "", "", "def", "mybasename", "(", "fullname", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename": [[735, 737], ["os.path.basename", "os.path.splitext"], "function", ["None"], ["", "", "def", "mybasename", "(", "fullname", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "fullname", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.Get_clockOrderInPictureCoordinate": [[739, 744], ["shapely.Polygon", "shapely.polygon.orient", "list"], "function", ["None"], ["", "def", "Get_clockOrderInPictureCoordinate", "(", "poly", ")", ":", "\n", "    ", "tmpoly", "=", "shgeo", ".", "Polygon", "(", "poly", ")", "\n", "outpoly", "=", "shgeo", ".", "polygon", ".", "orient", "(", "tmpoly", ",", "sign", "=", "1", ")", "\n", "outpoly", "=", "list", "(", "outpoly", ".", "exterior", ".", "coords", ")", "[", "0", ":", "-", "1", "]", "\n", "return", "outpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.get_clockwiseorderwithfirstpoint": [[745, 756], ["utils.validate_clockwise_points"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.validate_clockwise_points"], ["", "def", "get_clockwiseorderwithfirstpoint", "(", "poly", ")", ":", "\n", "    ", "check", "=", "validate_clockwise_points", "(", "poly", ")", "\n", "if", "not", "check", ":", "\n", "        ", "outpoly", "=", "[", "[", "poly", "[", "0", "]", "[", "0", "]", ",", "poly", "[", "0", "]", "[", "1", "]", "]", ",", "\n", "[", "poly", "[", "3", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "1", "]", "]", ",", "\n", "[", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "2", "]", "[", "1", "]", "]", ",", "\n", "[", "poly", "[", "1", "]", "[", "0", "]", ",", "poly", "[", "1", "]", "[", "1", "]", "]", "\n", "]", "\n", "", "else", ":", "\n", "        ", "outpoly", "=", "poly", "\n", "", "return", "outpoly", "\n", "", "def", "get_best_begin_point", "(", "coordinate", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.get_best_begin_point": [[756, 785], ["min", "min", "max", "max", "range", "print", "utils.cal_line_length", "utils.cal_line_length", "utils.cal_line_length", "utils.cal_line_length"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length"], ["", "def", "get_best_begin_point", "(", "coordinate", ")", ":", "\n", "    ", "x1", "=", "coordinate", "[", "0", "]", "[", "0", "]", "\n", "y1", "=", "coordinate", "[", "0", "]", "[", "1", "]", "\n", "x2", "=", "coordinate", "[", "1", "]", "[", "0", "]", "\n", "y2", "=", "coordinate", "[", "1", "]", "[", "1", "]", "\n", "x3", "=", "coordinate", "[", "2", "]", "[", "0", "]", "\n", "y3", "=", "coordinate", "[", "2", "]", "[", "1", "]", "\n", "x4", "=", "coordinate", "[", "3", "]", "[", "0", "]", "\n", "y4", "=", "coordinate", "[", "3", "]", "[", "1", "]", "\n", "xmin", "=", "min", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymin", "=", "min", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "xmax", "=", "max", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymax", "=", "max", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "combinate", "=", "[", "[", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", "]", ",", "[", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", "]", ",", "\n", "[", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", "]", ",", "[", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", "]", "]", "\n", "dst_coordinate", "=", "[", "[", "xmin", ",", "ymin", "]", ",", "[", "xmax", ",", "ymin", "]", ",", "[", "xmax", ",", "ymax", "]", ",", "[", "xmin", ",", "ymax", "]", "]", "\n", "force", "=", "100000000.0", "\n", "force_flag", "=", "0", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "temp_force", "=", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "0", "]", ",", "dst_coordinate", "[", "0", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "1", "]", ",", "\n", "dst_coordinate", "[", "\n", "1", "]", ")", "+", "cal_line_length", "(", "\n", "combinate", "[", "i", "]", "[", "2", "]", ",", "dst_coordinate", "[", "2", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "3", "]", ",", "dst_coordinate", "[", "3", "]", ")", "\n", "if", "temp_force", "<", "force", ":", "\n", "            ", "force", "=", "temp_force", "\n", "force_flag", "=", "i", "\n", "", "", "if", "force_flag", "!=", "0", ":", "\n", "        ", "print", "(", "\"choose one direction!\"", ")", "\n", "", "return", "combinate", "[", "force_flag", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.choose_best_begin_point": [[786, 814], ["min", "min", "max", "max", "range", "final_result.append", "print", "utils.cal_line_length", "utils.cal_line_length", "utils.cal_line_length", "utils.cal_line_length"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length"], ["", "def", "choose_best_begin_point", "(", "pre_result", ")", ":", "\n", "    ", "final_result", "=", "[", "]", "\n", "for", "coordinate", "in", "pre_result", ":", "\n", "        ", "x1", "=", "coordinate", "[", "0", "]", "[", "0", "]", "\n", "y1", "=", "coordinate", "[", "0", "]", "[", "1", "]", "\n", "x2", "=", "coordinate", "[", "1", "]", "[", "0", "]", "\n", "y2", "=", "coordinate", "[", "1", "]", "[", "1", "]", "\n", "x3", "=", "coordinate", "[", "2", "]", "[", "0", "]", "\n", "y3", "=", "coordinate", "[", "2", "]", "[", "1", "]", "\n", "x4", "=", "coordinate", "[", "3", "]", "[", "0", "]", "\n", "y4", "=", "coordinate", "[", "3", "]", "[", "1", "]", "\n", "xmin", "=", "min", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymin", "=", "min", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "xmax", "=", "max", "(", "x1", ",", "x2", ",", "x3", ",", "x4", ")", "\n", "ymax", "=", "max", "(", "y1", ",", "y2", ",", "y3", ",", "y4", ")", "\n", "combinate", "=", "[", "[", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", "]", ",", "[", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", "]", ",", "[", "[", "x3", ",", "y3", "]", ",", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", "]", ",", "[", "[", "x4", ",", "y4", "]", ",", "[", "x1", ",", "y1", "]", ",", "[", "x2", ",", "y2", "]", ",", "[", "x3", ",", "y3", "]", "]", "]", "\n", "dst_coordinate", "=", "[", "[", "xmin", ",", "ymin", "]", ",", "[", "xmax", ",", "ymin", "]", ",", "[", "xmax", ",", "ymax", "]", ",", "[", "xmin", ",", "ymax", "]", "]", "\n", "force", "=", "100000000.0", "\n", "force_flag", "=", "0", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "temp_force", "=", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "0", "]", ",", "dst_coordinate", "[", "0", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "1", "]", ",", "dst_coordinate", "[", "1", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "2", "]", ",", "dst_coordinate", "[", "2", "]", ")", "+", "cal_line_length", "(", "combinate", "[", "i", "]", "[", "3", "]", ",", "dst_coordinate", "[", "3", "]", ")", "\n", "if", "temp_force", "<", "force", ":", "\n", "                ", "force", "=", "temp_force", "\n", "force_flag", "=", "i", "\n", "", "", "if", "force_flag", "!=", "0", ":", "\n", "            ", "print", "(", "\"choose one direction!\"", ")", "\n", "", "final_result", ".", "append", "(", "combinate", "[", "force_flag", "]", ")", "\n", "", "return", "final_result", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.cal_line_length": [[815, 817], ["math.sqrt", "math.pow", "math.pow"], "function", ["None"], ["", "def", "cal_line_length", "(", "point1", ",", "point2", ")", ":", "\n", "    ", "return", "math", ".", "sqrt", "(", "math", ".", "pow", "(", "point1", "[", "0", "]", "-", "point2", "[", "0", "]", ",", "2", ")", "+", "math", ".", "pow", "(", "point1", "[", "1", "]", "-", "point2", "[", "1", "]", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.npu2bod": [[1058, 1077], ["utils.GetFileFromThisRootDir", "os.path.join", "os.path.join", "open", "open.readlines", "utils.mybasename", "os.path.join", "codecs.open", "re.findall", "list", "utils.dots2ToRec8", "codecs.open.write", "len", "map", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots2ToRec8"], ["", "", "", "", "", "def", "npu2bod", "(", ")", ":", "\n", "    ", "basepath", "=", "r'E:\\downloaddataset\\NWPU VHR-10 dataset\\NWPU'", "\n", "filelist", "=", "GetFileFromThisRootDir", "(", "os", ".", "path", ".", "join", "(", "basepath", ",", "'ground truth'", ")", ")", "\n", "outpath", "=", "os", ".", "path", ".", "join", "(", "basepath", ",", "'bod_gt'", ")", "\n", "for", "fullname", "in", "filelist", ":", "\n", "        ", "f", "=", "open", "(", "fullname", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "basename", "=", "mybasename", "(", "fullname", ")", "\n", "outdir", "=", "os", ".", "path", ".", "join", "(", "outpath", ",", "basename", "+", "'.txt'", ")", "\n", "f_out", "=", "codecs", ".", "open", "(", "outdir", ",", "'w'", ",", "'utf_16'", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "obj", "=", "re", ".", "findall", "(", "r'\\d+'", ",", "line", ")", "\n", "if", "(", "len", "(", "obj", ")", "<", "5", ")", ":", "\n", "                ", "continue", "\n", "", "bbox", "=", "list", "(", "map", "(", "int", ",", "obj", "[", "0", ":", "4", "]", ")", ")", "\n", "#print('bbox:', bbox)", "\n", "bbox", "=", "dots2ToRec8", "(", "bbox", ")", "\n", "outline", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "bbox", ")", ")", "+", "' '", "+", "obj", "[", "-", "1", "]", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.extractInitailName": [[1084, 1087], ["name.split"], "function", ["None"], ["", "", "", "def", "extractInitailName", "(", "name", ")", ":", "\n", "    ", "initialname", "=", "name", ".", "split", "(", "'__'", ")", "[", "0", "]", "\n", "return", "initialname", "\n", "", "def", "GetListFromfile", "(", "fullname", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.GetListFromfile": [[1087, 1092], ["open", "f.readlines", "x.strip"], "function", ["None"], ["", "def", "GetListFromfile", "(", "fullname", ")", ":", "\n", "    ", "with", "open", "(", "fullname", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "names", "=", "{", "x", ".", "strip", "(", ")", "for", "x", "in", "lines", "}", "\n", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.testGetListFromfile": [[1093, 1097], ["utils.GetListFromfile", "print", "print", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.GetListFromfile"], ["", "def", "testGetListFromfile", "(", ")", ":", "\n", "    ", "names", "=", "GetListFromfile", "(", "r'E:\\bod-dataset\\trainset\\trainset.txt'", ")", "\n", "print", "(", "names", ")", "\n", "print", "(", "len", "(", "names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.bodpolyToRec": [[1098, 1116], ["utils.GetFileFromThisRootDir", "utils.mybasename", "utils.parse_bod_poly", "codecs.open", "x.strip", "os.path.join", "os.path.join", "utils.dots4ToRec8", "list", "codecs.open.write", "map", "str"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.parse_bod_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec8"], ["", "def", "bodpolyToRec", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "#dstpath = os.path.join(r'E:\\bod-dataset\\patches\\subcategorylabel\\results\\ReclabelTxt')", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "namelist", "=", "[", "mybasename", "(", "x", ".", "strip", "(", ")", ")", "for", "x", "in", "filelist", "]", "\n", "for", "basename", "in", "namelist", ":", "\n", "#            objects = parse_bod_poly(os.path.join(self.labelpath, basename + '.txt'))", "\n", "        ", "objects", "=", "parse_bod_poly", "(", "os", ".", "path", ".", "join", "(", "srcpath", ",", "basename", "+", "'.txt'", ")", ")", "\n", "f_out", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ",", "'utf_16'", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "bbox", "=", "dots4ToRec8", "(", "obj", "[", "'poly'", "]", ")", "\n", "name", "=", "obj", "[", "'name'", "]", "\n", "difficult", "=", "obj", "[", "'difficult'", "]", "\n", "bbox", "=", "list", "(", "map", "(", "str", ",", "bbox", ")", ")", "\n", "outline", "=", "' '", ".", "join", "(", "bbox", ")", "\n", "outline", "=", "outline", "+", "' '", "+", "name", "\n", "if", "difficult", ":", "\n", "                ", "outline", "=", "outline", "+", "' '", "+", "str", "(", "difficult", ")", "\n", "", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.comp4trans4to8": [[1117, 1134], ["utils.GetFileFromThisRootDir", "open", "f.readlines", "utils.mybasename", "x.strip().split", "open", "os.path.join", "utils.dots2ToRec8", "f_out.write", "x.strip", "len", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.utils.mybasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots2ToRec8"], ["", "", "", "def", "comp4trans4to8", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "filenames", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "x", "in", "lines", "]", "\n", "basename", "=", "mybasename", "(", "filename", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "basename", "+", "'.txt'", ")", ",", "'w'", ")", "as", "f_out", ":", "\n", "                ", "for", "splitline", "in", "splitlines", ":", "\n", "                    ", "if", "(", "len", "(", "splitline", ")", "<", "6", ")", ":", "\n", "                        ", "continue", "\n", "", "imgname", "=", "splitline", "[", "0", "]", "\n", "confidence", "=", "splitline", "[", "1", "]", "\n", "rect", "=", "splitline", "[", "2", ":", "]", "\n", "poly", "=", "dots2ToRec8", "(", "rect", ")", "\n", "outline", "=", "imgname", "+", "' '", "+", "confidence", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.py_cpu_nms_poly": [[27, 58], ["range", "len", "DOTA_devkit.VectorDouble", "polys.append", "scores.argsort", "keep.append", "range", "numpy.array", "DOTA_devkit.iou_poly", "np.array.append", "math.isnan", "numpy.where", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "py_cpu_nms_poly", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "polys", "=", "[", "]", "\n", "areas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "for", "j", "in", "range", "(", "order", ".", "size", "-", "1", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "order", "[", "j", "+", "1", "]", "]", ")", "\n", "ovr", ".", "append", "(", "iou", ")", "\n", "", "ovr", "=", "np", ".", "array", "(", "ovr", ")", "\n", "\n", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.py_cpu_nms_poly_fast": [[60, 109], ["numpy.min", "numpy.min", "numpy.max", "numpy.max", "range", "len", "DOTA_devkit.VectorDouble", "polys.append", "scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "range", "print", "pdb.set_trace", "numpy.where", "DOTA_devkit.iou_poly", "math.isnan", "numpy.where", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly"], ["", "def", "py_cpu_nms_poly_fast", "(", "dets", ",", "thresh", ")", ":", "\n", "# TODO: test it", "\n", "    ", "try", ":", "\n", "        ", "obbs", "=", "dets", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "print", "(", "'fail index'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "x1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "x2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "\n", "polys", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", ")", "\n", "hbb_inter", "=", "w", "*", "h", "\n", "hbb_ovr", "=", "hbb_inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "hbb_inter", ")", "\n", "h_inds", "=", "np", ".", "where", "(", "hbb_ovr", ">", "0", ")", "[", "0", "]", "\n", "tmp_order", "=", "order", "[", "h_inds", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "tmp_order", ".", "size", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "tmp_order", "[", "j", "]", "]", ")", "\n", "hbb_ovr", "[", "h_inds", "[", "j", "]", "]", "=", "iou", "\n", "", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "hbb_ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.py_cpu_nms": [[110, 141], ["scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "#print('dets:', dets)", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.nmsbynamedict": [[142, 151], ["nms", "numpy.array", "outdets.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "thresh", ")", ":", "\n", "    ", "nameboxnmsdict", "=", "{", "x", ":", "[", "]", "for", "x", "in", "nameboxdict", "}", "\n", "for", "imgname", "in", "nameboxdict", ":", "\n", "        ", "keep", "=", "nms", "(", "np", ".", "array", "(", "nameboxdict", "[", "imgname", "]", ")", ",", "thresh", ")", "\n", "outdets", "=", "[", "]", "\n", "for", "index", "in", "keep", ":", "\n", "            ", "outdets", ".", "append", "(", "nameboxdict", "[", "imgname", "]", "[", "index", "]", ")", "\n", "", "nameboxnmsdict", "[", "imgname", "]", "=", "outdets", "\n", "", "return", "nameboxnmsdict", "\n", "", "def", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.poly2origpoly": [[151, 159], ["range", "int", "origpoly.append", "origpoly.append", "float", "float", "float", "float", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", ":", "\n", "    ", "origpoly", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ":", "\n", "        ", "tmp_x", "=", "float", "(", "poly", "[", "i", "*", "2", "]", "+", "x", ")", "/", "float", "(", "rate", ")", "\n", "tmp_y", "=", "float", "(", "poly", "[", "i", "*", "2", "+", "1", "]", "+", "y", ")", "/", "float", "(", "rate", ")", "\n", "origpoly", ".", "append", "(", "tmp_x", ")", "\n", "origpoly", ".", "append", "(", "tmp_y", ")", "\n", "", "return", "origpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.mergesingle": [[160, 202], ["util.custombasename", "os.path.join", "open", "f_in.readlines", "ResultMerge_multi_process.nmsbynamedict", "x.strip().split", "subname.split", "re.compile", "re.findall", "re.findall", "re.compile", "list", "ResultMerge_multi_process.poly2origpoly", "list.append", "list", "nameboxdict[].append", "open", "int", "int", "re.findall", "map", "map", "x.strip", "f_out.write", "map", "str"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.nmsbynamedict", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.poly2origpoly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "mergesingle", "(", "dstpath", ",", "nms", ",", "nms_thresh", ",", "fullname", ")", ":", "\n", "    ", "name", "=", "util", ".", "custombasename", "(", "fullname", ")", "\n", "#print('name:', name)", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "'.txt'", ")", "\n", "with", "open", "(", "fullname", ",", "'r'", ")", "as", "f_in", ":", "\n", "# print('fullname: ', fullname)", "\n", "        ", "nameboxdict", "=", "{", "}", "\n", "lines", "=", "f_in", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "lines", "]", "\n", "for", "splitline", "in", "splitlines", ":", "\n", "            ", "subname", "=", "splitline", "[", "0", "]", "\n", "splitname", "=", "subname", ".", "split", "(", "'__'", ")", "\n", "oriname", "=", "splitname", "[", "0", "]", "\n", "pattern1", "=", "re", ".", "compile", "(", "r'__\\d+___\\d+'", ")", "\n", "#print('subname:', subname)", "\n", "x_y", "=", "re", ".", "findall", "(", "pattern1", ",", "subname", ")", "\n", "x_y_2", "=", "re", ".", "findall", "(", "r'\\d+'", ",", "x_y", "[", "0", "]", ")", "\n", "x", ",", "y", "=", "int", "(", "x_y_2", "[", "0", "]", ")", ",", "int", "(", "x_y_2", "[", "1", "]", ")", "\n", "\n", "pattern2", "=", "re", ".", "compile", "(", "r'__([\\d+\\.]+)__\\d+___'", ")", "\n", "\n", "rate", "=", "re", ".", "findall", "(", "pattern2", ",", "subname", ")", "[", "0", "]", "\n", "\n", "confidence", "=", "splitline", "[", "1", "]", "\n", "poly", "=", "list", "(", "map", "(", "float", ",", "splitline", "[", "2", ":", "]", ")", ")", "\n", "origpoly", "=", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", "\n", "det", "=", "origpoly", "\n", "det", ".", "append", "(", "confidence", ")", "\n", "det", "=", "list", "(", "map", "(", "float", ",", "det", ")", ")", "\n", "if", "(", "oriname", "not", "in", "nameboxdict", ")", ":", "\n", "                ", "nameboxdict", "[", "oriname", "]", "=", "[", "]", "\n", "", "nameboxdict", "[", "oriname", "]", ".", "append", "(", "det", ")", "\n", "", "nameboxnmsdict", "=", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "nms_thresh", ")", "\n", "with", "open", "(", "dstname", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "imgname", "in", "nameboxnmsdict", ":", "\n", "                ", "for", "det", "in", "nameboxnmsdict", "[", "imgname", "]", ":", "\n", "#print('det:', det)", "\n", "                    ", "confidence", "=", "det", "[", "-", "1", "]", "\n", "bbox", "=", "det", "[", "0", ":", "-", "1", "]", "\n", "outline", "=", "imgname", "+", "' '", "+", "str", "(", "confidence", ")", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "bbox", ")", ")", "\n", "#print('outline:', outline)", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.mergebase_parallel": [[203, 210], ["multiprocessing.Pool", "util.GetFileFromThisRootDir", "functools.partial", "multiprocessing.Pool.map", "ResultMerge_multi_process.py_cpu_nms", "ResultMerge_multi_process.py_cpu_nms_poly_fast", "DOTA_devkit.nms.obb_HNMS"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly_fast", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.nms.obb_HNMS"], ["", "", "", "", "", "def", "mergebase_parallel", "(", "srcpath", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", ":", "\n", "    ", "pool", "=", "Pool", "(", "16", ")", "\n", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "\n", "mergesingle_fn", "=", "partial", "(", "mergesingle", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", "\n", "# pdb.set_trace()", "\n", "pool", ".", "map", "(", "mergesingle_fn", ",", "filelist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.mergebase": [[211, 215], ["util.GetFileFromThisRootDir", "ResultMerge_multi_process.mergesingle"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergesingle"], ["", "def", "mergebase", "(", "srcpath", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", ":", "\n", "    ", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "filename", "in", "filelist", ":", "\n", "        ", "mergesingle", "(", "dstpath", ",", "nms", ",", "nms_thresh", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.mergebyrec": [[216, 220], ["ResultMerge_multi_process.mergebase_parallel"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel"], ["", "", "def", "mergebyrec", "(", "srcpath", ",", "dstpath", ",", "nms_thresh", "=", "0.3", ")", ":", "\n", "    ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms", ",", "nms_thresh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.ResultMerge_multi_process.mergebypoly_multiprocess": [[221, 241], ["ResultMerge_multi_process.mergebase_parallel", "ResultMerge_multi_process.mergebase_parallel", "functools.partial", "ResultMerge_multi_process.mergebase_parallel"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel"], ["", "def", "mergebypoly_multiprocess", "(", "srcpath", ",", "dstpath", ",", "nms_type", "=", "'py_cpu_nms_poly_fast'", ",", "o_thresh", "=", "0.1", ",", "h_thresh", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    srcpath: result files before merge and nms\n    dstpath: result files after merge and nms\n    \"\"\"", "\n", "# srcpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/comp4_test_results'", "\n", "# dstpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/testtime'", "\n", "if", "nms_type", "==", "'py_cpu_nms_poly_fast'", ":", "\n", "        ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms_poly_fast", ",", "o_thresh", ")", "\n", "", "elif", "nms_type", "==", "'obb_HNMS'", ":", "\n", "        ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "obb_HNMS", ",", "o_thresh", ")", "\n", "", "elif", "nms_type", "==", "'obb_hybrid_NMS'", ":", "\n", "        ", "obb_hybrid_NMS_partial", "=", "partial", "(", "obb_hybrid_NMS", ",", "o_thresh", ")", "\n", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "obb_hybrid_NMS_partial", ",", "h_thresh", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA2COCO.DOTA2COCOTrain": [[13, 69], ["os.path.join", "os.path.join", "enumerate", "data_dict[].append", "open", "dota_utils.GetFileFromThisRootDir", "json.dump", "dota_utils.custombasename", "os.path.join", "cv2.imread", "data_dict[].append", "dota_utils.parse_dota_poly2", "single_obj[].append", "data_dict[].append", "print", "cls_names.index", "min", "min", "max", "max"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "DOTA2COCOTrain", "(", "srcpath", ",", "destfile", ",", "cls_names", ",", "difficult", "=", "'2'", ")", ":", "\n", "# set difficult to filter '2', '1', or do not filter, set '-1'", "\n", "\n", "    ", "imageparent", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "'images'", ")", "\n", "labelparent", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "'labelTxt'", ")", "\n", "\n", "data_dict", "=", "{", "}", "\n", "data_dict", "[", "'images'", "]", "=", "[", "]", "\n", "data_dict", "[", "'categories'", "]", "=", "[", "]", "\n", "data_dict", "[", "'annotations'", "]", "=", "[", "]", "\n", "for", "idex", ",", "name", "in", "enumerate", "(", "cls_names", ")", ":", "\n", "        ", "single_cat", "=", "{", "'id'", ":", "idex", "+", "1", ",", "'name'", ":", "name", ",", "'supercategory'", ":", "name", "}", "\n", "data_dict", "[", "'categories'", "]", ".", "append", "(", "single_cat", ")", "\n", "\n", "", "inst_count", "=", "1", "\n", "image_id", "=", "1", "\n", "with", "open", "(", "destfile", ",", "'w'", ")", "as", "f_out", ":", "\n", "        ", "filenames", "=", "util", ".", "GetFileFromThisRootDir", "(", "labelparent", ")", "\n", "for", "file", "in", "filenames", ":", "\n", "            ", "basename", "=", "util", ".", "custombasename", "(", "file", ")", "\n", "# image_id = int(basename[1:])", "\n", "\n", "imagepath", "=", "os", ".", "path", ".", "join", "(", "imageparent", ",", "basename", "+", "'.png'", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "imagepath", ")", "\n", "height", ",", "width", ",", "c", "=", "img", ".", "shape", "\n", "\n", "single_image", "=", "{", "}", "\n", "single_image", "[", "'file_name'", "]", "=", "basename", "+", "'.png'", "\n", "single_image", "[", "'id'", "]", "=", "image_id", "\n", "single_image", "[", "'width'", "]", "=", "width", "\n", "single_image", "[", "'height'", "]", "=", "height", "\n", "data_dict", "[", "'images'", "]", ".", "append", "(", "single_image", ")", "\n", "\n", "# annotations", "\n", "objects", "=", "util", ".", "parse_dota_poly2", "(", "file", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "                ", "if", "obj", "[", "'difficult'", "]", "==", "difficult", ":", "\n", "                    ", "print", "(", "'difficult: '", ",", "difficult", ")", "\n", "continue", "\n", "", "single_obj", "=", "{", "}", "\n", "single_obj", "[", "'area'", "]", "=", "obj", "[", "'area'", "]", "\n", "single_obj", "[", "'category_id'", "]", "=", "cls_names", ".", "index", "(", "obj", "[", "'name'", "]", ")", "+", "1", "\n", "single_obj", "[", "'segmentation'", "]", "=", "[", "]", "\n", "single_obj", "[", "'segmentation'", "]", ".", "append", "(", "obj", "[", "'poly'", "]", ")", "\n", "single_obj", "[", "'iscrowd'", "]", "=", "0", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "min", "(", "obj", "[", "'poly'", "]", "[", "0", ":", ":", "2", "]", ")", ",", "min", "(", "obj", "[", "'poly'", "]", "[", "1", ":", ":", "2", "]", ")", ",", "max", "(", "obj", "[", "'poly'", "]", "[", "0", ":", ":", "2", "]", ")", ",", "max", "(", "obj", "[", "'poly'", "]", "[", "1", ":", ":", "2", "]", ")", "\n", "\n", "width", ",", "height", "=", "xmax", "-", "xmin", ",", "ymax", "-", "ymin", "\n", "single_obj", "[", "'bbox'", "]", "=", "xmin", ",", "ymin", ",", "width", ",", "height", "\n", "single_obj", "[", "'image_id'", "]", "=", "image_id", "\n", "data_dict", "[", "'annotations'", "]", ".", "append", "(", "single_obj", ")", "\n", "single_obj", "[", "'id'", "]", "=", "inst_count", "\n", "inst_count", "=", "inst_count", "+", "1", "\n", "", "image_id", "=", "image_id", "+", "1", "\n", "", "json", ".", "dump", "(", "data_dict", ",", "f_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA2COCO.DOTA2COCOTest": [[70, 99], ["os.path.join", "enumerate", "data_dict[].append", "open", "dota_utils.GetFileFromThisRootDir", "json.dump", "dota_utils.custombasename", "os.path.join", "PIL.Image.open", "data_dict[].append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "DOTA2COCOTest", "(", "srcpath", ",", "destfile", ",", "cls_names", ")", ":", "\n", "    ", "imageparent", "=", "os", ".", "path", ".", "join", "(", "srcpath", ",", "'images'", ")", "\n", "data_dict", "=", "{", "}", "\n", "\n", "data_dict", "[", "'images'", "]", "=", "[", "]", "\n", "data_dict", "[", "'categories'", "]", "=", "[", "]", "\n", "for", "idex", ",", "name", "in", "enumerate", "(", "cls_names", ")", ":", "\n", "        ", "single_cat", "=", "{", "'id'", ":", "idex", "+", "1", ",", "'name'", ":", "name", ",", "'supercategory'", ":", "name", "}", "\n", "data_dict", "[", "'categories'", "]", ".", "append", "(", "single_cat", ")", "\n", "\n", "", "image_id", "=", "1", "\n", "with", "open", "(", "destfile", ",", "'w'", ")", "as", "f_out", ":", "\n", "        ", "filenames", "=", "util", ".", "GetFileFromThisRootDir", "(", "imageparent", ")", "\n", "for", "file", "in", "filenames", ":", "\n", "            ", "basename", "=", "util", ".", "custombasename", "(", "file", ")", "\n", "imagepath", "=", "os", ".", "path", ".", "join", "(", "imageparent", ",", "basename", "+", "'.png'", ")", "\n", "img", "=", "Image", ".", "open", "(", "imagepath", ")", "\n", "height", "=", "img", ".", "height", "\n", "width", "=", "img", ".", "width", "\n", "\n", "single_image", "=", "{", "}", "\n", "single_image", "[", "'file_name'", "]", "=", "basename", "+", "'.png'", "\n", "single_image", "[", "'id'", "]", "=", "image_id", "\n", "single_image", "[", "'width'", "]", "=", "width", "\n", "single_image", "[", "'height'", "]", "=", "height", "\n", "data_dict", "[", "'images'", "]", ".", "append", "(", "single_image", ")", "\n", "\n", "image_id", "=", "image_id", "+", "1", "\n", "", "json", ".", "dump", "(", "data_dict", ",", "f_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.deploy.caffe2_converter.setup_cfg": [[17, 28], ["detectron2.config.get_cfg", "detectron2.export.add_export_config", "detectron2.export.add_export_config.merge_from_file", "detectron2.export.add_export_config.merge_from_list", "detectron2.export.add_export_config.freeze"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup_cfg", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "# cuda context is initialized before creating dataloader, so we don't fork anymore", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "cfg", "=", "add_export_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "if", "cfg", ".", "MODEL", ".", "DEVICE", "!=", "\"cpu\"", ":", "\n", "        ", "assert", "TORCH_VERSION", ">=", "(", "1", ",", "5", ")", ",", "\"PyTorch>=1.5 required for GPU conversion!\"", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.DefaultPredictor.__init__": [[154, 170], ["cfg.clone", "detectron2.modeling.build_model", "feature_maps.DefaultPredictor.model.eval", "len", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.load", "detectron2.ResizeShortestEdge", "detectron2.data.MetadataCatalog.get"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "# cfg can be modified by model", "\n", "self", ".", "model", "=", "build_model", "(", "self", ".", "cfg", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ":", "\n", "            ", "self", ".", "metadata", "=", "MetadataCatalog", ".", "get", "(", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ")", "\n", "\n", "", "checkpointer", "=", "DetectionCheckpointer", "(", "self", ".", "model", ")", "\n", "checkpointer", ".", "load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ")", "\n", "\n", "self", ".", "aug", "=", "T", ".", "ResizeShortestEdge", "(", "\n", "[", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", ",", "cfg", ".", "INPUT", ".", "MIN_SIZE_TEST", "]", ",", "cfg", ".", "INPUT", ".", "MAX_SIZE_TEST", "\n", ")", "\n", "\n", "self", ".", "input_format", "=", "cfg", ".", "INPUT", ".", "FORMAT", "\n", "assert", "self", ".", "input_format", "in", "[", "\"RGB\"", ",", "\"BGR\"", "]", ",", "self", ".", "input_format", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.DefaultPredictor.__call__": [[171, 194], ["torch.no_grad", "feature_maps.DefaultPredictor.aug.get_transform().apply_image", "torch.as_tensor", "torch.as_tensor.astype().transpose", "feature_maps.DefaultPredictor.model", "feature_maps.DefaultPredictor.aug.get_transform", "torch.as_tensor.astype"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_image", "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RandomRotation.get_transform"], ["", "def", "__call__", "(", "self", ",", "original_image", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            original_image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n\n        Returns:\n            predictions (dict):\n                the output of the model for one image only.\n                See :doc:`/tutorials/models` for details about the format.\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# https://github.com/sphinx-doc/sphinx/issues/4258", "\n", "# Apply pre-processing to image.", "\n", "            ", "if", "self", ".", "input_format", "==", "\"RGB\"", ":", "\n", "# whether the model expects BGR inputs or RGB", "\n", "                ", "original_image", "=", "original_image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "height", ",", "width", "=", "original_image", ".", "shape", "[", ":", "2", "]", "\n", "image", "=", "self", ".", "aug", ".", "get_transform", "(", "original_image", ")", ".", "apply_image", "(", "original_image", ")", "\n", "image", "=", "torch", ".", "as_tensor", "(", "image", ".", "astype", "(", "\"float32\"", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "inputs", "=", "{", "\"image\"", ":", "image", ",", "\"height\"", ":", "height", ",", "\"width\"", ":", "width", "}", "\n", "predictions", "=", "self", ".", "model", "(", "[", "inputs", "]", ")", "[", "0", "]", "\n", "features", "=", "self", ".", "model", ".", "proposal_generator", ".", "feature_cache", "\n", "return", "predictions", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.VisualizationDemo.__init__": [[197, 213], ["detectron2.data.MetadataCatalog.get", "torch.device", "feature_maps.DefaultPredictor", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ",", "parallel", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            instance_mode (ColorMode):\n            parallel (bool): whether to run the model in different processes from visualization.\n                Useful since the visualization logic can be slow.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\n", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", "if", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "else", "\"__unused\"", "\n", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "instance_mode", "=", "instance_mode", "\n", "\n", "self", ".", "parallel", "=", "parallel", "\n", "self", ".", "predictor", "=", "DefaultPredictor", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.VisualizationDemo.run_on_image": [[214, 302], ["detectron2.data.detection_utils.read_image", "feature_maps.VisualizationDemo.predictor", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.colormap.colormap", "predictions[].to", "feature_maps._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer.overlay_instances", "_t.unbind", "torch.stack", "detectron2.utils.visualizer.Visualizer.overlay_instances", "os.path.isdir", "os.path.join", "matplotlib.pyplot.imsave", "detectron2.utils.visualizer.Visualizer.overlay_instances.save", "detectron2.utils.visualizer.Visualizer.overlay_instances.save", "detectron2.utils.visualizer.Visualizer.overlay_instances.save", "os.path.basename", "os.path.join.replace", "os.path.join.replace", "os.path.join.replace", "detectron2.structures.PolygonMasks", "detectron2.structures.PolygonMasks", "detectron2.structures.PolygonMasks"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "run_on_image", "(", "self", ",", "image_path", ",", "output_dir", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n                This is the format used by OpenCV.\n\n        Returns:\n            predictions (dict): the output of the model.\n            vis_output (VisImage): the visualized image output.\n        \"\"\"", "\n", "\n", "image", "=", "read_image", "(", "image_path", ",", "format", "=", "\"BGR\"", ")", "\n", "vis_output", "=", "None", "\n", "predictions", ",", "features", "=", "self", ".", "predictor", "(", "image", ")", "\n", "\n", "\n", "# Convert image from OpenCV BGR format to Matplotlib RGB format.", "\n", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "visualizer_with_labels", "=", "Visualizer", "(", "image", ",", "self", ".", "metadata", ",", "instance_mode", "=", "self", ".", "instance_mode", ")", "\n", "visualizer_without_labels", "=", "Visualizer", "(", "image", ",", "self", ".", "metadata", ",", "instance_mode", "=", "self", ".", "instance_mode", ")", "\n", "visualizer_without_labels_hbox", "=", "Visualizer", "(", "image", ",", "self", ".", "metadata", ",", "instance_mode", "=", "self", ".", "instance_mode", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "instances", "=", "predictions", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "cpu_device", ")", "\n", "\n", "# if instances.pred_classes.shape[0] < 40:", "\n", "if", "(", "instances", ".", "pred_classes", "==", "0", ")", ".", "sum", "(", ")", "<", "10", ":", "\n", "            ", "return", "predictions", "\n", "\n", "", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "labels", "=", "_create_text_labels", "(", "\n", "instances", ".", "pred_classes", ",", "instances", ".", "scores", ",", "instances", ".", "fpn_levels", ",", "classnames", "\n", ")", "\n", "\n", "visualized_output_with_labels", "=", "visualizer_with_labels", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", "alpha", "=", "0.1", ",", "\n", ")", "\n", "visualized_output_without_labels", "=", "visualizer_without_labels", ".", "overlay_instances", "(", "\n", "# labels=labels,", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", "alpha", "=", "0.0", ",", "\n", ")", "\n", "\n", "_t", ":", "torch", ".", "Tensor", "=", "instances", ".", "pred_boxes", ".", "tensor", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "_t", ".", "unbind", "(", "-", "1", ")", "\n", "hbox_polymask", "=", "torch", ".", "stack", "(", "(", "xmin", ",", "ymin", ",", "xmin", ",", "ymax", ",", "xmax", ",", "ymax", ",", "xmax", ",", "ymin", ")", ",", "1", ")", "\n", "\n", "visualized_output_without_labels_hbox", "=", "visualizer_without_labels_hbox", ".", "overlay_instances", "(", "\n", "# labels=labels,", "\n", "# masks=PolygonMasks([[poly] for poly in instances.pred_corners]),", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "hbox_polymask", "]", ")", ",", "\n", "# boxes=instances.pred_boxes,", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", "alpha", "=", "0.00", ",", "\n", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "output", ")", ",", "args", ".", "output", "\n", "out_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "\n", "plt", ".", "imsave", "(", "out_filename", ",", "image", ")", "\n", "visualized_output_with_labels", ".", "save", "(", "out_filename", ".", "replace", "(", "\".png\"", ",", "\"_pred.png\"", ")", ")", "\n", "visualized_output_without_labels", ".", "save", "(", "out_filename", ".", "replace", "(", "\".png\"", ",", "\"_pred-no-label.png\"", ")", ")", "\n", "visualized_output_without_labels_hbox", ".", "save", "(", "out_filename", ".", "replace", "(", "\".png\"", ",", "\"_pred-no-label_hbox.png\"", ")", ")", "\n", "\n", "# # Add location dots", "\n", "# for cls, loc in zip(instances.pred_classes, instances.locations):", "\n", "#     visualizer.draw_circle((loc[0], loc[1]), color=colors[cls], radius=5)", "\n", "\n", "\n", "# fname_without_suffix = out_filename.split(\".\")[-2]", "\n", "# for level_name, feat_dict in features.items():", "\n", "#     for tower_name, features in feat_dict.items():", "\n", "#         base_dir = os.path.join(fname_without_suffix, tower_name)", "\n", "#         Path(base_dir).mkdir(parents=True, exist_ok=True)", "\n", "\n", "#         # For each channel", "\n", "#         features.squeeze_(0)", "\n", "\n", "#         features_np = features.cpu().numpy()", "\n", "#         np.save(os.path.join(base_dir, level_name + \".npy\"), features_np)", "\n", "\n", "\n", "# vis_output = visualizer.draw_instance_predictions(predictions=instances)", "\n", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.setup_cfg": [[57, 66], ["dafne.config.get_cfg", "detectron2_backbone.config.add_backbone_config", "dafne.config.get_cfg.merge_from_file", "dafne.config.get_cfg.merge_from_list", "dafne.config.get_cfg.freeze"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg"], ["def", "setup_cfg", "(", "args", ")", ":", "\n", "# load config from file and command-line arguments", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "add_backbone_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "MODEL", ".", "DAFNE", ".", "INFERENCE_TH_TEST", "=", "args", ".", "confidence_threshold", "\n", "cfg", ".", "freeze", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps.get_parser": [[68, 101], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Detectron2 demo for builtin configs\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config-file\"", ",", "\n", "default", "=", "\"configs/quick_schedules/mask_rcnn_R_50_FPN_inference_acc_test.yaml\"", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "\"path to config file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"A list of space separated input images; \"", "\n", "\"or a single glob pattern such as 'directory/*.jpg'\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "help", "=", "\"A file or directory to save output visualizations. \"", "\n", "\"If not given, will show output in an OpenCV window.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--confidence-threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "\"Minimum score for instance predictions to be shown\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Modify config options using the command-line 'KEY VALUE' pairs\"", ",", "\n", "default", "=", "[", "]", ",", "\n", "nargs", "=", "argparse", ".", "REMAINDER", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels": [[103, 126], ["len", "zip", "zip"], "function", ["None"], ["", "def", "_create_text_labels", "(", "classes", ",", "scores", ",", "fpn_levels", ",", "class_names", ",", "is_crowd", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        classes (list[int] or None):\n        scores (list[float] or None):\n        fpn_levels (list[int] or None):\n        class_names (list[str] or None):\n        is_crowd (list[bool] or None):\n\n    Returns:\n        list[str] or None\n    \"\"\"", "\n", "labels", "=", "None", "\n", "if", "classes", "is", "not", "None", "and", "class_names", "is", "not", "None", "and", "len", "(", "class_names", ")", ">", "0", ":", "\n", "        ", "labels", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "classes", "]", "\n", "", "if", "scores", "is", "not", "None", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "\"{:.0f}%\"", ".", "format", "(", "s", "*", "100", ")", "for", "s", "in", "scores", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "\"{} {:.0f}%, {}\"", ".", "format", "(", "l", ",", "s", "*", "100", ",", "lvl", "+", "3", ")", "for", "l", ",", "s", ",", "lvl", "in", "zip", "(", "labels", ",", "scores", ",", "fpn_levels", ")", "]", "\n", "", "", "if", "is_crowd", "is", "not", "None", ":", "\n", "        ", "labels", "=", "[", "l", "+", "(", "\"|crowd\"", "if", "crowd", "else", "\"\"", ")", "for", "l", ",", "crowd", "in", "zip", "(", "labels", ",", "is_crowd", ")", "]", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.hooks.RTPTHook.before_train": [[6, 21], ["dafne.utils.rtpt.RTPT", "hooks.RTPTHook.rtpt.start"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.start"], ["    ", "def", "before_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before the first iteration.\n        \"\"\"", "\n", "# High moving avg size due to large differences in number of objects per image", "\n", "window_size", "=", "500", "\n", "self", ".", "rtpt", "=", "RTPT", "(", "\n", "name_initials", "=", "\"SL\"", ",", "\n", "experiment_name", "=", "self", ".", "trainer", ".", "cfg", ".", "EXPERIMENT_NAME", ",", "\n", "max_iterations", "=", "self", ".", "trainer", ".", "max_iter", ",", "\n", "iteration_start", "=", "self", ".", "trainer", ".", "start_iter", ",", "\n", "update_interval", "=", "100", ",", "\n", "moving_avg_window_size", "=", "window_size", ",", "\n", ")", "\n", "self", ".", "rtpt", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.hooks.RTPTHook.after_train": [[22, 27], ["None"], "methods", ["None"], ["", "def", "after_train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after the last iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.hooks.RTPTHook.before_step": [[28, 33], ["None"], "methods", ["None"], ["", "def", "before_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called before each iteration.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.hooks.RTPTHook.after_step": [[34, 41], ["hooks.RTPTHook.rtpt.step"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step"], ["", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Called after each iteration.\n        \"\"\"", "\n", "progress", "=", "self", ".", "trainer", ".", "iter", "/", "self", ".", "trainer", ".", "max_iter", "*", "100", "\n", "self", ".", "rtpt", ".", "step", "(", "subtitle", "=", "f\"[{progress:0>2.0f}%]\"", ")", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.Mish.forward": [[33, 35], ["torch.tanh", "torch.nn.functional.softplus"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "tanh", "(", "F", ".", "softplus", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.Scale.__init__": [[48, 51], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_value", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "Scale", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "init_value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.Scale.forward": [[52, 54], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.ModuleListDial.__init__": [[57, 60], ["torch.nn.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "modules", "=", "None", ")", ":", "\n", "        ", "super", "(", "ModuleListDial", ",", "self", ")", ".", "__init__", "(", "modules", ")", "\n", "self", ".", "cur_position", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.ModuleListDial.forward": [[61, 67], ["len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "result", "=", "self", "[", "self", ".", "cur_position", "]", "(", "x", ")", "\n", "self", ".", "cur_position", "+=", "1", "\n", "if", "self", ".", "cur_position", ">=", "len", "(", "self", ")", ":", "\n", "            ", "self", ".", "cur_position", "=", "0", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNe.__init__": [[71, 83], ["torch.nn.Module.__init__", "dafne.DAFNeHead", "dafne_outputs.DAFNeOutputs"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ":", "Dict", "[", "str", ",", "ShapeSpec", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "IN_FEATURES", "\n", "self", ".", "fpn_strides", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "FPN_STRIDES", "\n", "self", ".", "yield_proposal", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "YIELD_PROPOSAL", "\n", "\n", "# Construct head", "\n", "shape_list", "=", "[", "input_shape", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "self", ".", "dafne_head", "=", "DAFNeHead", "(", "cfg", ",", "shape_list", ")", "\n", "\n", "self", ".", "in_channels_to_top_module", "=", "self", ".", "dafne_head", ".", "in_channels_to_top_module", "\n", "self", ".", "dafne_outputs", "=", "DAFNeOutputs", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNe.forward_head": [[84, 87], ["dafne.DAFNe.dafne_head"], "methods", ["None"], ["", "def", "forward_head", "(", "self", ",", "features", ",", "top_module", "=", "None", ")", ":", "\n", "        ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "return", "self", ".", "dafne_head", "(", "features", ",", "top_module", ",", "self", ".", "yield_proposal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNe.forward": [[88, 157], ["dafne.DAFNe.compute_locations", "dafne.DAFNe.dafne_head", "enumerate", "dafne.DAFNe.dafne_outputs.losses", "dafne.DAFNe.dafne_outputs.predict_proposals", "towers.items", "torch.no_grad", "dafne.DAFNe.dafne_outputs.predict_proposals", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.compute_locations", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.losses", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.predict_proposals", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.predict_proposals"], ["", "def", "forward", "(", "self", ",", "images", ",", "features", ",", "gt_instances", "=", "None", ",", "top_module", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            images (list[Tensor] or ImageList): images to be processed\n            targets (list[BoxList]): ground-truth boxes present in the image (optional)\n\n        Returns:\n            result (list[BoxList] or dict[Tensor]): the output from the model.\n                During training, it returns a dict[Tensor] which contains the losses.\n                During testing, it returns list[BoxList] contains additional fields\n                like `scores`, `labels` and `mask` (for Mask R-CNN models).\n\n        \"\"\"", "\n", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "locations", "=", "self", ".", "compute_locations", "(", "features", ")", "\n", "(", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "center_reg_pred", ",", "\n", "ltrb_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "top_feats", ",", "\n", "towers", ",", "\n", ")", "=", "self", ".", "dafne_head", "(", "images", ",", "features", ",", "top_module", ",", "self", ".", "yield_proposal", ")", "\n", "\n", "results", "=", "{", "}", "\n", "if", "self", ".", "yield_proposal", ":", "\n", "            ", "results", "[", "\"features\"", "]", "=", "{", "}", "\n", "for", "i", ",", "level_name", "in", "enumerate", "(", "self", ".", "in_features", ")", ":", "\n", "                ", "results", "[", "\"features\"", "]", "[", "level_name", "]", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "towers", ".", "items", "(", ")", ":", "\n", "                    ", "if", "len", "(", "v", ")", ">", "0", ":", "\n", "                        ", "results", "[", "\"features\"", "]", "[", "level_name", "]", "[", "k", "]", "=", "v", "[", "i", "]", "\n", "", "", "", "self", ".", "feature_cache", "=", "results", "[", "\"features\"", "]", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "results", ",", "losses", "=", "self", ".", "dafne_outputs", ".", "losses", "(", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "center_reg_pred", ",", "\n", "ltrb_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "locations", ",", "\n", "gt_instances", ",", "\n", "top_feats", ",", "\n", ")", "\n", "\n", "if", "self", ".", "yield_proposal", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "[", "\"proposals\"", "]", "=", "self", ".", "dafne_outputs", ".", "predict_proposals", "(", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "locations", ",", "\n", "images", ".", "image_sizes", ",", "\n", "top_feats", ",", "\n", ")", "\n", "", "", "return", "results", ",", "losses", "\n", "", "else", ":", "\n", "            ", "results", "=", "self", ".", "dafne_outputs", ".", "predict_proposals", "(", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "locations", ",", "\n", "images", ".", "image_sizes", ",", "\n", "top_feats", ",", "\n", ")", "\n", "\n", "return", "results", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNe.compute_locations": [[158, 165], ["enumerate", "dafne.DAFNe.compute_locations"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.compute_locations"], ["", "", "def", "compute_locations", "(", "self", ",", "features", ")", ":", "\n", "        ", "locations", "=", "[", "]", "\n", "for", "level", ",", "feature", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "h", ",", "w", "=", "feature", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "locations_per_level", "=", "compute_locations", "(", "h", ",", "w", ",", "self", ".", "fpn_strides", "[", "level", "]", ",", "feature", ".", "device", ")", "\n", "locations", ".", "append", "(", "locations_per_level", ")", "\n", "", "return", "locations", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNeHead.__init__": [[168, 286], ["torch.nn.Module.__init__", "len", "dafne.DAFNeHead.make_towers", "torch.nn.Conv2d", "modules_init_list.extend", "torch.nn.init.constant_", "len", "torch.nn.Conv2d", "modules_init_list.append", "torch.nn.Conv2d", "modules_init_list.append", "torch.nn.Conv2d", "modules_init_list.append", "torch.nn.Conv2d", "modules_init_list.append", "torch.nn.Parameter", "dafne.DAFNeHead.__init__._conv"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNeHead.make_towers", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ":", "List", "[", "ShapeSpec", "]", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            in_channels (int): number of channels of the input feature\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "num_classes", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_CLASSES", "\n", "self", ".", "fpn_strides", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "FPN_STRIDES", "\n", "norm", "=", "None", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NORM", "==", "\"none\"", "else", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NORM", "\n", "self", ".", "num_levels", "=", "len", "(", "input_shape", ")", "\n", "centerness_mode", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "\n", "assert", "centerness_mode", "in", "[", "\"none\"", ",", "\"plain\"", ",", "\"oriented\"", "]", "\n", "self", ".", "use_centerness", "=", "centerness_mode", "!=", "\"none\"", "\n", "self", ".", "merge_corner_center_pred", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "MERGE_CORNER_CENTER_PRED", "\n", "\n", "self", ".", "corner_prediction_strategy", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CORNER_PREDICTION", "\n", "self", ".", "corner_tower_on_center_tower", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CORNER_TOWER_ON_CENTER_TOWER", "\n", "assert", "self", ".", "corner_prediction_strategy", "in", "[", "\n", "\"direct\"", ",", "\n", "\"iterative\"", ",", "\n", "\"center-to-corner\"", ",", "\n", "\"offset\"", ",", "\n", "\"angle\"", ",", "\n", "]", "\n", "\n", "# Get in_channels", "\n", "in_channels", "=", "[", "s", ".", "channels", "for", "s", "in", "input_shape", "]", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "\"Each level must have the same channel!\"", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "self", ".", "in_channels_to_top_module", "=", "in_channels", "\n", "\n", "in_channels_cls", "=", "in_channels", "\n", "\n", "modules_init_list", "=", "[", "]", "\n", "\n", "# Construct the towers for each objective", "\n", "self", ".", "make_towers", "(", "in_channels", ",", "in_channels_cls", ",", "norm", ",", "modules_init_list", ")", "\n", "\n", "# Make prediction modules for class, centerness, corners and centers", "\n", "self", ".", "cls_logits", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels_cls", ",", "self", ".", "num_classes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", "\n", ")", "\n", "\n", "if", "self", ".", "use_centerness", ":", "\n", "            ", "self", ".", "ctrness", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "1", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "modules_init_list", ".", "append", "(", "self", ".", "ctrness", ")", "\n", "\n", "# Construct \"corners\" prediction from in-channels->8", "\n", "", "if", "self", ".", "corner_prediction_strategy", "in", "[", "\"direct\"", ",", "\"center-to-corner\"", ",", "\"offset\"", "]", ":", "\n", "            ", "self", ".", "corners_pred", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "8", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "modules_init_list", ".", "append", "(", "self", ".", "corners_pred", ")", "\n", "\n", "# Construct xywha prediction", "\n", "", "if", "self", ".", "corner_prediction_strategy", "==", "\"angle\"", ":", "\n", "            ", "self", ".", "xywha_pred", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "5", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "modules_init_list", ".", "append", "(", "self", ".", "xywha_pred", ")", "\n", "\n", "# Construct \"center\" prediction from in-channels->2", "\n", "", "if", "self", ".", "corner_prediction_strategy", "==", "\"center-to-corner\"", ":", "\n", "            ", "self", ".", "center_pred", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "modules_init_list", ".", "append", "(", "self", ".", "center_pred", ")", "\n", "\n", "", "if", "self", ".", "corner_prediction_strategy", "==", "\"offset\"", ":", "\n", "# Construct base corners", "\n", "            ", "self", ".", "base_corners", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "tensor", "(", "[", "-", "2.0", ",", "2.0", ",", "2.0", ",", "2.0", ",", "2.0", ",", "-", "2.0", ",", "-", "2.0", ",", "-", "2.0", "]", ")", ".", "view", "(", "1", ",", "8", ",", "1", ",", "1", ")", ",", "\n", "requires_grad", "=", "False", ",", "\n", ")", "\n", "\n", "", "if", "self", ".", "corner_prediction_strategy", "==", "\"iterative\"", ":", "\n", "\n", "            ", "def", "_conv", "(", "_in_channels", ")", ":", "\n", "                ", "return", "nn", ".", "Conv2d", "(", "_in_channels", ",", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "\n", "", "self", ".", "c0_pred", "=", "_conv", "(", "in_channels", ")", "\n", "self", ".", "c1_pred", "=", "_conv", "(", "in_channels", "+", "2", ")", "\n", "self", ".", "c2_pred", "=", "_conv", "(", "in_channels", "+", "4", ")", "\n", "self", ".", "c3_pred", "=", "_conv", "(", "in_channels", "+", "6", ")", "\n", "modules_init_list", ".", "extend", "(", "\n", "[", "\n", "self", ".", "c0_pred", ",", "\n", "self", ".", "c1_pred", ",", "\n", "self", ".", "c2_pred", ",", "\n", "self", ".", "c3_pred", ",", "\n", "]", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "            ", "self", ".", "scales", "=", "nn", ".", "ModuleList", "(", "[", "Scale", "(", "init_value", "=", "1.0", ")", "for", "_", "in", "range", "(", "self", ".", "num_levels", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "scales", "=", "None", "\n", "\n", "# Add predictions modules to the module list", "\n", "", "modules_init_list", ".", "extend", "(", "\n", "[", "\n", "self", ".", "cls_logits", ",", "\n", "]", "\n", ")", "\n", "\n", "# Initialize modules", "\n", "for", "modules", "in", "modules_init_list", ":", "\n", "            ", "for", "l", "in", "modules", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "l", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "l", ",", "DeformConv", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "\n", "# Bias might be disabled if conv is followeb by batchnorm", "\n", "if", "l", ".", "bias", "is", "not", "None", ":", "\n", "                        ", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "\n", "", "", "if", "isinstance", "(", "l", ",", "DFConv2dNoOffset", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "conv", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "\n", "# initialize the bias for focal loss", "\n", "", "", "", "prior_prob", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "PRIOR_PROB", "\n", "bias_value", "=", "-", "math", ".", "log", "(", "(", "1", "-", "prior_prob", ")", "/", "prior_prob", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "cls_logits", ".", "bias", ",", "bias_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNeHead.make_towers": [[287, 349], ["range", "dafne.DAFNeHead.add_module", "modules_init_list.append", "tower.append", "tower.append", "torch.nn.Sequential", "getattr", "conv_func", "tower.append", "torch.nn.ReLU", "torch.nn.GroupNorm", "tower.append", "dafne.ModuleListDial", "tower.append", "dafne.ModuleListDial", "torch.nn.BatchNorm2d", "range", "detectron2.layers.NaiveSyncBatchNorm", "range"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "make_towers", "(", "self", ",", "in_channels", ",", "in_channels_cls", ",", "norm", ",", "modules_init_list", ")", ":", "\n", "        ", "head_configs", "=", "{", "\n", "\"cls\"", ":", "(", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_CLS_CONVS", ",", "\n", "in_channels_cls", ",", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_DEFORMABLE", ",", "\n", ")", ",", "\n", "\"corners\"", ":", "(", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_BOX_CONVS", ",", "\n", "in_channels", ",", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_DEFORMABLE", ",", "\n", ")", ",", "\n", "\"share\"", ":", "(", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_SHARE_CONVS", ",", "in_channels", ",", "False", ")", ",", "\n", "}", "\n", "\n", "if", "self", ".", "corner_prediction_strategy", "==", "\"center-to-corner\"", ":", "\n", "            ", "if", "not", "self", ".", "merge_corner_center_pred", ":", "\n", "                ", "head_configs", "[", "\"center\"", "]", "=", "(", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_BOX_CONVS", ",", "\n", "in_channels", ",", "\n", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_DEFORMABLE", ",", "\n", ")", "\n", "\n", "", "", "for", "head", "in", "head_configs", ":", "\n", "            ", "tower", "=", "[", "]", "\n", "num_convs", ",", "head_in_channels", ",", "use_deformable", "=", "head_configs", "[", "head", "]", "\n", "for", "i", "in", "range", "(", "num_convs", ")", ":", "\n", "                ", "if", "use_deformable", "and", "i", "==", "num_convs", "-", "1", ":", "\n", "                    ", "conv_func", "=", "DFConv2d", "\n", "bias", "=", "False", "\n", "", "else", ":", "\n", "                    ", "conv_func", "=", "nn", ".", "Conv2d", "\n", "bias", "=", "True", "\n", "", "tower", ".", "append", "(", "\n", "conv_func", "(", "\n", "head_in_channels", ",", "\n", "head_in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", ")", "\n", "if", "norm", "==", "\"GN\"", ":", "\n", "                    ", "tower", ".", "append", "(", "nn", ".", "GroupNorm", "(", "head_in_channels", "//", "8", ",", "head_in_channels", ")", ")", "\n", "", "elif", "norm", "==", "\"BN\"", ":", "\n", "                    ", "tower", ".", "append", "(", "\n", "ModuleListDial", "(", "\n", "[", "nn", ".", "BatchNorm2d", "(", "head_in_channels", ")", "for", "_", "in", "range", "(", "self", ".", "num_levels", ")", "]", "\n", ")", "\n", ")", "\n", "", "elif", "norm", "==", "\"SyncBN\"", ":", "\n", "                    ", "tower", ".", "append", "(", "\n", "ModuleListDial", "(", "\n", "[", "NaiveSyncBatchNorm", "(", "head_in_channels", ")", "for", "_", "in", "range", "(", "self", ".", "num_levels", ")", "]", "\n", ")", "\n", ")", "\n", "", "tower", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "module_name", "=", "f\"{head}_tower\"", "\n", "self", ".", "add_module", "(", "module_name", ",", "nn", ".", "Sequential", "(", "*", "tower", ")", ")", "\n", "modules_init_list", ".", "append", "(", "getattr", "(", "self", ",", "module_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.DAFNeHead.forward": [[350, 493], ["enumerate", "dafne.DAFNeHead.share_tower", "dafne.DAFNeHead.cls_tower", "cls_towers.append", "corners_reg.append", "corners_towers.append", "dafne.DAFNeHead.cls_logits", "logits.append", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.corners_pred", "ctrness.append", "torch.ones", "ctrness.append", "top_feats.append", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.c0_pred", "dafne.DAFNeHead.c1_pred", "dafne.DAFNeHead.c2_pred", "dafne.DAFNeHead.c3_pred", "torch.cat", "dafne.DAFNeHead.ctrness", "dafne.DAFNeHead.ctrness", "top_module", "torch.cat", "torch.cat", "torch.cat", "center_reg.append", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.corners_pred", "dafne.DAFNeHead.center_pred", "dafne.DAFNeHead.center_tower", "dafne.DAFNeHead.center_pred", "dafne.DAFNeHead.corners_pred", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.corners_pred", "dafne.DAFNeHead.repeat", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.repeat", "dafne.DAFNeHead.corners_tower", "dafne.DAFNeHead.xywha_pred", "dafne.DAFNeHead.unbind", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sin", "torch.cos", "torch.stack", "torch.stack.mean", "reg_corners.permute.permute.view", "reg_corners.permute.permute.permute", "RuntimeError", "torch.sigmoid", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "forward", "(", "self", ",", "images", ",", "x", ",", "top_module", "=", "None", ",", "yield_corners_towers", "=", "False", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "corners_reg", "=", "[", "]", "\n", "ltrb_reg", "=", "[", "]", "\n", "center_reg", "=", "[", "]", "\n", "ctrness", "=", "[", "]", "\n", "top_feats", "=", "[", "]", "\n", "corners_towers", "=", "[", "]", "\n", "center_towers", "=", "[", "]", "\n", "cls_towers", "=", "[", "]", "\n", "\n", "# For each feature level", "\n", "for", "level", ",", "feature", "in", "enumerate", "(", "x", ")", ":", "\n", "\n", "# Apply sharing tower if set, else no-op", "\n", "            ", "feature", "=", "self", ".", "share_tower", "(", "feature", ")", "\n", "\n", "# Apply cls tower on FPN features", "\n", "cls_tower", "=", "self", ".", "cls_tower", "(", "feature", ")", "\n", "cls_towers", ".", "append", "(", "cls_tower", ")", "\n", "\n", "# Direct corner prediction", "\n", "if", "self", ".", "corner_prediction_strategy", "==", "\"direct\"", ":", "\n", "                ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "reg_corners", "=", "self", ".", "corners_pred", "(", "corners_tower", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "                    ", "reg_corners", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_corners", ")", "\n", "", "", "elif", "self", ".", "corner_prediction_strategy", "==", "\"iterative\"", ":", "\n", "                ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "c0", "=", "self", ".", "c0_pred", "(", "corners_tower", ")", "\n", "c1", "=", "self", ".", "c1_pred", "(", "torch", ".", "cat", "(", "(", "corners_tower", ",", "c0", ")", ",", "dim", "=", "1", ")", ")", "\n", "c2", "=", "self", ".", "c2_pred", "(", "torch", ".", "cat", "(", "(", "corners_tower", ",", "c0", ",", "c1", ")", ",", "dim", "=", "1", ")", ")", "\n", "c3", "=", "self", ".", "c3_pred", "(", "torch", ".", "cat", "(", "(", "corners_tower", ",", "c0", ",", "c1", ",", "c2", ")", ",", "dim", "=", "1", ")", ")", "\n", "reg_corners", "=", "torch", ".", "cat", "(", "(", "c0", ",", "c1", ",", "c2", ",", "c3", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "                    ", "reg_corners", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_corners", ")", "\n", "", "", "elif", "self", ".", "corner_prediction_strategy", "==", "\"center-to-corner\"", ":", "\n", "\n", "                ", "if", "self", ".", "merge_corner_center_pred", ":", "\n", "                    ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "\n", "# center-to-corner vectors", "\n", "reg_corners_delta", "=", "self", ".", "corners_pred", "(", "corners_tower", ")", "\n", "reg_center", "=", "self", ".", "center_pred", "(", "corners_tower", ")", "\n", "reg_corners", "=", "reg_center", ".", "repeat", "(", "1", ",", "4", ",", "1", ",", "1", ")", "+", "reg_corners_delta", "\n", "", "else", ":", "\n", "                    ", "center_tower", "=", "self", ".", "center_tower", "(", "feature", ")", "\n", "\n", "if", "self", ".", "corner_tower_on_center_tower", ":", "\n", "                        ", "corners_tower", "=", "self", ".", "corners_tower", "(", "center_tower", ")", "\n", "", "else", ":", "\n", "                        ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "\n", "", "reg_center", "=", "self", ".", "center_pred", "(", "center_tower", ")", "\n", "reg_corners_delta", "=", "self", ".", "corners_pred", "(", "corners_tower", ")", "\n", "reg_corners", "=", "reg_center", ".", "repeat", "(", "1", ",", "4", ",", "1", ",", "1", ")", "+", "reg_corners_delta", "\n", "\n", "", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "                    ", "reg_corners", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_corners", ")", "\n", "reg_center", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_center", ")", "\n", "\n", "# Collect center regression", "\n", "", "center_reg", ".", "append", "(", "reg_center", ")", "\n", "", "elif", "self", ".", "corner_prediction_strategy", "==", "\"offset\"", ":", "\n", "                ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "reg_corners_delta", "=", "self", ".", "corners_pred", "(", "corners_tower", ")", "\n", "\n", "# Use regression as offset to obtain the actual prediction", "\n", "reg_corners", "=", "self", ".", "base_corners", "+", "reg_corners_delta", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "                    ", "reg_corners", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_corners", ")", "\n", "", "", "elif", "self", ".", "corner_prediction_strategy", "==", "\"angle\"", ":", "\n", "                ", "corners_tower", "=", "self", ".", "corners_tower", "(", "feature", ")", "\n", "reg_xywha", "=", "self", ".", "xywha_pred", "(", "corners_tower", ")", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", ",", "alpha", "=", "reg_xywha", ".", "unbind", "(", "1", ")", "\n", "\n", "# Note: x,y are the top-left corner", "\n", "c0", "=", "torch", ".", "stack", "(", "(", "x", ",", "y", ")", ",", "dim", "=", "-", "1", ")", "\n", "c1", "=", "torch", ".", "stack", "(", "(", "x", ",", "y", "+", "h", ")", ",", "dim", "=", "-", "1", ")", "\n", "c2", "=", "torch", ".", "stack", "(", "(", "x", "+", "w", ",", "y", "+", "h", ")", ",", "dim", "=", "-", "1", ")", "\n", "c3", "=", "torch", ".", "stack", "(", "(", "x", "+", "w", ",", "y", ")", ",", "dim", "=", "-", "1", ")", "\n", "corners", "=", "torch", ".", "stack", "(", "(", "c0", ",", "c1", ",", "c2", ",", "c3", ")", ",", "dim", "=", "-", "2", ")", "\n", "\n", "# Fix alpha to range", "\n", "alpha", "=", "torch", ".", "sigmoid", "(", "alpha", ")", "*", "np", ".", "pi", "-", "np", ".", "pi", "/", "2", "\n", "\n", "# Construct rotation matrix", "\n", "sin", "=", "torch", ".", "sin", "(", "alpha", ")", "\n", "cos", "=", "torch", ".", "cos", "(", "alpha", ")", "\n", "R", "=", "torch", ".", "stack", "(", "[", "torch", ".", "stack", "(", "[", "cos", ",", "-", "sin", "]", ",", "-", "1", ")", ",", "torch", ".", "stack", "(", "[", "sin", ",", "cos", "]", ",", "-", "1", ")", "]", ",", "-", "1", ")", "\n", "\n", "# Perform rotate the proposed box by alph", "\n", "reg_corners_mean", "=", "corners", ".", "mean", "(", "-", "2", ",", "keepdim", "=", "True", ")", "\n", "reg_corners", "=", "corners", "-", "reg_corners_mean", "\n", "reg_corners", "=", "reg_corners", "@", "R", "\n", "reg_corners", "=", "reg_corners", "+", "reg_corners_mean", "\n", "shape", "=", "reg_corners", ".", "shape", "\n", "reg_corners", "=", "reg_corners", ".", "view", "(", "*", "shape", "[", "0", ":", "-", "2", "]", ",", "-", "1", ")", "\n", "reg_corners", "=", "reg_corners", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "USE_SCALE", ":", "\n", "                    ", "reg_corners", "=", "self", ".", "scales", "[", "level", "]", "(", "reg_corners", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Invalid corner prediction strategy.\"", ")", "\n", "\n", "", "corners_reg", ".", "append", "(", "reg_corners", ")", "\n", "corners_towers", ".", "append", "(", "corners_tower", ")", "\n", "\n", "reg_cls_logits", "=", "self", ".", "cls_logits", "(", "cls_tower", ")", "\n", "logits", ".", "append", "(", "reg_cls_logits", ")", "\n", "\n", "# Predict centerness if enabled", "\n", "if", "self", ".", "use_centerness", ":", "\n", "                ", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CTR_ON_REG", ":", "\n", "                    ", "reg_ctrness", "=", "self", ".", "ctrness", "(", "corners_tower", ")", "\n", "", "else", ":", "\n", "                    ", "reg_ctrness", "=", "self", ".", "ctrness", "(", "cls_tower", ")", "\n", "", "ctrness", ".", "append", "(", "reg_ctrness", ")", "\n", "", "else", ":", "\n", "                ", "reg_ctrness", "=", "torch", ".", "ones", "(", "\n", "(", "feature", ".", "shape", "[", "0", "]", ",", "1", ",", "*", "feature", ".", "shape", "[", "2", ":", "]", ")", ",", "\n", "device", "=", "feature", ".", "device", ",", "\n", "dtype", "=", "feature", ".", "dtype", ",", "\n", ")", "\n", "ctrness", ".", "append", "(", "reg_ctrness", ")", "\n", "\n", "", "if", "top_module", "is", "not", "None", ":", "\n", "                ", "top_feats", ".", "append", "(", "top_module", "(", "corners_tower", ")", ")", "\n", "", "", "return", "(", "\n", "logits", ",", "\n", "corners_reg", ",", "\n", "center_reg", ",", "\n", "ltrb_reg", ",", "\n", "ctrness", ",", "\n", "top_feats", ",", "\n", "{", "\n", "\"corners_towers\"", ":", "corners_towers", ",", "\n", "\"center_towers\"", ":", "center_towers", ",", "\n", "\"cls_towers\"", ":", "cls_towers", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne.compute_locations": [[37, 45], ["torch.arange", "torch.arange", "torch.meshgrid", "shift_x.reshape.reshape", "shift_y.reshape.reshape", "torch.stack"], "function", ["None"], ["", "", "def", "compute_locations", "(", "h", ",", "w", ",", "stride", ",", "device", ")", ":", "\n", "    ", "shifts_x", "=", "torch", ".", "arange", "(", "0", ",", "w", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "0", ",", "h", "*", "stride", ",", "step", "=", "stride", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "stride", "//", "2", "\n", "return", "locations", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.__init__": [[123, 191], ["torch.nn.Module.__init__", "dafne.modeling.losses.smooth_l1.SmoothL1Loss", "soi.append", "dafne.modeling.losses.smooth_l1.ModulatedEightPointLoss", "dafne.modeling.losses.smooth_l1.SmoothL1Loss", "dafne_outputs.DAFNeOutputs.normalize_lambdas", "soi.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.normalize_lambdas", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "DAFNeOutputs", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "focal_loss_alpha", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_ALPHA", "\n", "self", ".", "focal_loss_gamma", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_GAMMA", "\n", "self", ".", "center_sample", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTER_SAMPLE", "\n", "self", ".", "radius", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "POS_RADIUS", "\n", "self", ".", "pre_nms_thresh_train", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "INFERENCE_TH_TRAIN", "\n", "self", ".", "pre_nms_topk_train", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "PRE_NMS_TOPK_TRAIN", "\n", "self", ".", "post_nms_topk_train", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "POST_NMS_TOPK_TRAIN", "\n", "self", ".", "sort_corners", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "SORT_CORNERS", "\n", "\n", "logspace", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_LOSS_LOG", "\n", "beta", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_SMOOTH_L1_BETA", "\n", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_LOSS_MODULATION", ":", "\n", "            ", "self", ".", "corners_loss_func", "=", "ModulatedEightPointLoss", "(", "\n", "beta", "=", "beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "logspace", "=", "logspace", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "corners_loss_func", "=", "SmoothL1Loss", "(", "\n", "beta", "=", "beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "logspace", "=", "logspace", ",", "\n", ")", "\n", "\n", "", "self", ".", "center_loss_func", "=", "SmoothL1Loss", "(", "\n", "beta", "=", "beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", "logspace", "=", "logspace", ",", "\n", ")", "\n", "\n", "self", ".", "pre_nms_thresh_test", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "INFERENCE_TH_TEST", "\n", "self", ".", "pre_nms_topk_test", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "PRE_NMS_TOPK_TEST", "\n", "self", ".", "post_nms_topk_test", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "POST_NMS_TOPK_TEST", "\n", "self", ".", "nms_thresh", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NMS_TH", "\n", "self", ".", "thresh_with_ctr", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "THRESH_WITH_CTR", "\n", "self", ".", "centerness_mode", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "\n", "self", ".", "centerness_alpha", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_ALPHA", "\n", "self", ".", "has_centerness", "=", "self", ".", "centerness_mode", "!=", "\"none\"", "\n", "assert", "self", ".", "centerness_mode", "in", "[", "\"none\"", ",", "\"plain\"", ",", "\"oriented\"", "]", "\n", "self", ".", "corner_prediction_strategy", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CORNER_PREDICTION", "\n", "self", ".", "has_center_reg", "=", "self", ".", "corner_prediction_strategy", "==", "\"center-to-corner\"", "\n", "self", ".", "num_classes", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "NUM_CLASSES", "\n", "self", ".", "strides", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "FPN_STRIDES", "\n", "\n", "# Lambdas", "\n", "self", ".", "lambda_cls", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CLS", "\n", "self", ".", "lambda_ctr", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CTR", "\n", "self", ".", "lambda_corners", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CORNERS", "\n", "self", ".", "lambda_center", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CENTER", "\n", "self", ".", "lambda_ltrb", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "LTRB", "\n", "lambda_normalize", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA_NORM", "\n", "\n", "if", "lambda_normalize", ":", "\n", "            ", "self", ".", "normalize_lambdas", "(", ")", "\n", "\n", "# generate sizes of interest", "\n", "", "soi", "=", "[", "]", "\n", "prev_size", "=", "-", "1", "\n", "for", "s", "in", "cfg", ".", "MODEL", ".", "DAFNE", ".", "SIZES_OF_INTEREST", ":", "\n", "            ", "soi", ".", "append", "(", "[", "prev_size", ",", "s", "]", ")", "\n", "prev_size", "=", "s", "\n", "", "soi", ".", "append", "(", "[", "prev_size", ",", "INF", "]", ")", "\n", "self", ".", "sizes_of_interest", "=", "soi", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.normalize_lambdas": [[192, 207], ["None"], "methods", ["None"], ["", "def", "normalize_lambdas", "(", "self", ")", ":", "\n", "# Make them sum up to one", "\n", "        ", "lambda_sum", "=", "self", ".", "lambda_cls", "+", "self", ".", "lambda_corners", "\n", "if", "self", ".", "has_centerness", ":", "\n", "            ", "lambda_sum", "+=", "self", ".", "lambda_ctr", "\n", "\n", "", "if", "self", ".", "has_center_reg", ":", "\n", "            ", "lambda_sum", "+=", "self", ".", "lambda_center", "\n", "\n", "\n", "", "self", ".", "lambda_cls", "=", "self", ".", "lambda_cls", "/", "lambda_sum", "\n", "self", ".", "lambda_ctr", "=", "self", ".", "lambda_ctr", "/", "lambda_sum", "\n", "self", ".", "lambda_corners", "=", "self", ".", "lambda_corners", "/", "lambda_sum", "\n", "self", ".", "lambda_center", "=", "self", ".", "lambda_center", "/", "lambda_sum", "\n", "self", ".", "lambda_ltrb", "=", "self", ".", "lambda_ltrb", "/", "lambda_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.update_lambdas": [[208, 238], ["dafne_outputs.DAFNeOutputs.normalize_lambdas"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.normalize_lambdas"], ["", "def", "update_lambdas", "(", "\n", "self", ",", "\n", "lambda_cls", "=", "None", ",", "\n", "lambda_ctr", "=", "None", ",", "\n", "lambda_corners", "=", "None", ",", "\n", "lambda_center", "=", "None", ",", "\n", "normalize", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "lambda_cls", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_cls", "=", "lambda_cls", "\n", "", "else", ":", "\n", "            ", "self", ".", "lambda_cls", "=", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CLS", "\n", "\n", "", "if", "lambda_ctr", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_ctr", "=", "lambda_ctr", "\n", "", "else", ":", "\n", "            ", "self", ".", "lambda_ctr", "=", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CTR", "\n", "\n", "", "if", "lambda_corners", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_corners", "=", "lambda_corners", "\n", "", "else", ":", "\n", "            ", "self", ".", "lambda_corners", "=", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CORNERS", "\n", "\n", "", "if", "lambda_center", "is", "not", "None", ":", "\n", "            ", "self", ".", "lambda_center", "=", "lambda_center", "\n", "", "else", ":", "\n", "            ", "self", ".", "lambda_center", "=", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "LOSS_LAMBDA", ".", "CENTER", "\n", "\n", "", "if", "normalize", ":", "\n", "            ", "self", ".", "normalize_lambdas", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs._transpose": [[239, 251], ["range", "zip", "len", "torch.split", "torch.split", "torch.split", "torch.split", "targets_level_first.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "_transpose", "(", "self", ",", "training_targets", ",", "num_loc_list", ")", ":", "\n", "        ", "\"\"\"\n        This function is used to transpose image first training targets to level first ones\n        :return: level first training targets\n        \"\"\"", "\n", "for", "im_i", "in", "range", "(", "len", "(", "training_targets", ")", ")", ":", "\n", "            ", "training_targets", "[", "im_i", "]", "=", "torch", ".", "split", "(", "training_targets", "[", "im_i", "]", ",", "num_loc_list", ",", "dim", "=", "0", ")", "\n", "\n", "", "targets_level_first", "=", "[", "]", "\n", "for", "targets_per_level", "in", "zip", "(", "*", "training_targets", ")", ":", "\n", "            ", "targets_level_first", ".", "append", "(", "torch", ".", "cat", "(", "targets_per_level", ",", "dim", "=", "0", ")", ")", "\n", "", "return", "targets_level_first", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs._get_ground_truth": [[252, 296], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dafne_outputs.DAFNeOutputs.compute_targets_for_locations", "len", "loc_per_level.new_tensor", "torch.cat.append", "torch.cat.append", "torch.cat.clone", "torch.cat.clone", "dafne_outputs.DAFNeOutputs._transpose", "range", "loc_to_size_range_per_level[].expand", "range", "torch.cat.new_ones", "torch.cat.new_ones", "range", "dafne_outputs.DAFNeOutputs.items", "loc.new_ones", "enumerate", "len", "len", "torch.cat.size", "torch.cat.size", "len", "len", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.compute_targets_for_locations", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs._transpose", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "_get_ground_truth", "(", "self", ",", "locations", ",", "gt_instances", ")", ":", "\n", "        ", "num_loc_list", "=", "[", "len", "(", "loc", ")", "for", "loc", "in", "locations", "]", "\n", "\n", "# compute locations to size ranges", "\n", "loc_to_size_range", "=", "[", "]", "\n", "for", "l", ",", "loc_per_level", "in", "enumerate", "(", "locations", ")", ":", "\n", "            ", "loc_to_size_range_per_level", "=", "loc_per_level", ".", "new_tensor", "(", "self", ".", "sizes_of_interest", "[", "l", "]", ")", "\n", "loc_to_size_range", ".", "append", "(", "loc_to_size_range_per_level", "[", "None", "]", ".", "expand", "(", "num_loc_list", "[", "l", "]", ",", "-", "1", ")", ")", "\n", "\n", "", "loc_to_size_range", "=", "torch", ".", "cat", "(", "loc_to_size_range", ",", "dim", "=", "0", ")", "\n", "locations", "=", "torch", ".", "cat", "(", "locations", ",", "dim", "=", "0", ")", "\n", "\n", "training_targets", "=", "self", ".", "compute_targets_for_locations", "(", "\n", "locations", ",", "gt_instances", ",", "loc_to_size_range", ",", "num_loc_list", "\n", ")", "\n", "\n", "training_targets", "[", "\"locations\"", "]", "=", "[", "locations", ".", "clone", "(", ")", "for", "_", "in", "range", "(", "len", "(", "gt_instances", ")", ")", "]", "\n", "training_targets", "[", "\"im_inds\"", "]", "=", "[", "\n", "locations", ".", "new_ones", "(", "locations", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", "*", "i", "\n", "for", "i", "in", "range", "(", "len", "(", "gt_instances", ")", ")", "\n", "]", "\n", "\n", "# transpose im first training_targets to level first ones", "\n", "training_targets", "=", "{", "\n", "k", ":", "self", ".", "_transpose", "(", "v", ",", "num_loc_list", ")", "for", "k", ",", "v", "in", "training_targets", ".", "items", "(", ")", "\n", "}", "\n", "\n", "training_targets", "[", "\"fpn_levels\"", "]", "=", "[", "\n", "loc", ".", "new_ones", "(", "len", "(", "loc", ")", ",", "dtype", "=", "torch", ".", "long", ")", "*", "level", "\n", "for", "level", ",", "loc", "in", "enumerate", "(", "training_targets", "[", "\"locations\"", "]", ")", "\n", "]", "\n", "\n", "# we normalize reg_targets by FPN's strides here", "\n", "reg_targets_corners", "=", "training_targets", "[", "\"reg_targets_corners\"", "]", "\n", "reg_targets_ltrb", "=", "training_targets", "[", "\"reg_targets_ltrb\"", "]", "\n", "reg_targets_abcd", "=", "training_targets", "[", "\"reg_targets_abcd\"", "]", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_FPN_STRIDE_NORM", ":", "\n", "            ", "for", "l", "in", "range", "(", "len", "(", "reg_targets_corners", ")", ")", ":", "\n", "                ", "reg_targets_corners", "[", "l", "]", "=", "reg_targets_corners", "[", "l", "]", "/", "float", "(", "self", ".", "strides", "[", "l", "]", ")", "\n", "reg_targets_ltrb", "[", "l", "]", "=", "reg_targets_ltrb", "[", "l", "]", "/", "float", "(", "self", ".", "strides", "[", "l", "]", ")", "\n", "reg_targets_abcd", "[", "l", "]", "=", "reg_targets_abcd", "[", "l", "]", "/", "float", "(", "self", ".", "strides", "[", "l", "]", ")", "\n", "\n", "", "", "return", "training_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.get_sample_region": [[297, 353], ["len", "boxes[].expand", "center_x[].expand", "center_y[].expand", "boxes[].expand.new_zeros", "enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bitmasks.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "bitmasks.sum().sum().clamp", "loc_xs.new_zeros", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "boxes[].sum", "boxes[].sum", "center_x[].expand.numel", "center_x[].sum", "torch.stack.min", "torch.stack.min", "bitmasks.sum().sum", "bitmasks.sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "get_sample_region", "(", "\n", "self", ",", "boxes", ",", "strides", ",", "num_loc_list", ",", "loc_xs", ",", "loc_ys", ",", "bitmasks", "=", "None", ",", "radius", "=", "1", "\n", ")", ":", "\n", "        ", "if", "bitmasks", "is", "not", "None", ":", "\n", "            ", "_", ",", "h", ",", "w", "=", "bitmasks", ".", "size", "(", ")", "\n", "\n", "ys", "=", "torch", ".", "arange", "(", "0", ",", "h", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bitmasks", ".", "device", ")", "\n", "xs", "=", "torch", ".", "arange", "(", "0", ",", "w", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bitmasks", ".", "device", ")", "\n", "\n", "m00", "=", "bitmasks", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "clamp", "(", "min", "=", "1e-6", ")", "\n", "m10", "=", "(", "bitmasks", "*", "xs", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "m01", "=", "(", "bitmasks", "*", "ys", "[", ":", ",", "None", "]", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "center_x", "=", "m10", "/", "m00", "\n", "center_y", "=", "m01", "/", "m00", "\n", "", "else", ":", "\n", "            ", "center_x", "=", "boxes", "[", "...", ",", "[", "0", ",", "2", "]", "]", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "0.5", "\n", "center_y", "=", "boxes", "[", "...", ",", "[", "1", ",", "3", "]", "]", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "0.5", "\n", "\n", "", "num_gts", "=", "boxes", ".", "shape", "[", "0", "]", "\n", "K", "=", "len", "(", "loc_xs", ")", "\n", "boxes", "=", "boxes", "[", "None", "]", ".", "expand", "(", "K", ",", "num_gts", ",", "4", ")", "\n", "center_x", "=", "center_x", "[", "None", "]", ".", "expand", "(", "K", ",", "num_gts", ")", "\n", "center_y", "=", "center_y", "[", "None", "]", ".", "expand", "(", "K", ",", "num_gts", ")", "\n", "center_gt", "=", "boxes", ".", "new_zeros", "(", "boxes", ".", "shape", ")", "\n", "# no gt", "\n", "if", "center_x", ".", "numel", "(", ")", "==", "0", "or", "center_x", "[", "...", ",", "0", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "            ", "return", "loc_xs", ".", "new_zeros", "(", "loc_xs", ".", "shape", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "", "beg", "=", "0", "\n", "for", "level", ",", "num_loc", "in", "enumerate", "(", "num_loc_list", ")", ":", "\n", "            ", "end", "=", "beg", "+", "num_loc", "\n", "stride", "=", "strides", "[", "level", "]", "*", "radius", "\n", "xmin", "=", "center_x", "[", "beg", ":", "end", "]", "-", "stride", "\n", "ymin", "=", "center_y", "[", "beg", ":", "end", "]", "-", "stride", "\n", "xmax", "=", "center_x", "[", "beg", ":", "end", "]", "+", "stride", "\n", "ymax", "=", "center_y", "[", "beg", ":", "end", "]", "+", "stride", "\n", "# limit sample region in gt", "\n", "center_gt", "[", "beg", ":", "end", ",", ":", ",", "0", "]", "=", "torch", ".", "where", "(", "\n", "xmin", ">", "boxes", "[", "beg", ":", "end", ",", ":", ",", "0", "]", ",", "xmin", ",", "boxes", "[", "beg", ":", "end", ",", ":", ",", "0", "]", "\n", ")", "\n", "center_gt", "[", "beg", ":", "end", ",", ":", ",", "1", "]", "=", "torch", ".", "where", "(", "\n", "ymin", ">", "boxes", "[", "beg", ":", "end", ",", ":", ",", "1", "]", ",", "ymin", ",", "boxes", "[", "beg", ":", "end", ",", ":", ",", "1", "]", "\n", ")", "\n", "center_gt", "[", "beg", ":", "end", ",", ":", ",", "2", "]", "=", "torch", ".", "where", "(", "\n", "xmax", ">", "boxes", "[", "beg", ":", "end", ",", ":", ",", "2", "]", ",", "boxes", "[", "beg", ":", "end", ",", ":", ",", "2", "]", ",", "xmax", "\n", ")", "\n", "center_gt", "[", "beg", ":", "end", ",", ":", ",", "3", "]", "=", "torch", ".", "where", "(", "\n", "ymax", ">", "boxes", "[", "beg", ":", "end", ",", ":", ",", "3", "]", ",", "boxes", "[", "beg", ":", "end", ",", ":", ",", "3", "]", ",", "ymax", "\n", ")", "\n", "beg", "=", "end", "\n", "", "left", "=", "loc_xs", "[", ":", ",", "None", "]", "-", "center_gt", "[", "...", ",", "0", "]", "\n", "right", "=", "center_gt", "[", "...", ",", "2", "]", "-", "loc_xs", "[", ":", ",", "None", "]", "\n", "top", "=", "loc_ys", "[", ":", ",", "None", "]", "-", "center_gt", "[", "...", ",", "1", "]", "\n", "bottom", "=", "center_gt", "[", "...", ",", "3", "]", "-", "loc_ys", "[", ":", ",", "None", "]", "\n", "center_bbox", "=", "torch", ".", "stack", "(", "(", "left", ",", "top", ",", "right", ",", "bottom", ")", ",", "-", "1", ")", "\n", "inside_gt_bbox_mask", "=", "center_bbox", ".", "min", "(", "-", "1", ")", "[", "0", "]", ">", "0", "\n", "return", "inside_gt_bbox_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.compute_targets_for_locations": [[354, 503], ["len", "range", "len", "area[].repeat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "dafne_outputs.compute_abcd", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "area[].repeat.min", "len", "labels.append", "reg_targets_ltrb.append", "reg_targets_abcd.append", "reg_targets_corners.append", "target_inds.append", "bboxes.numel", "labels.append", "reg_targets_ltrb.append", "reg_targets_abcd.append", "reg_targets_corners.append", "target_inds.append", "targets_per_im.has", "dafne_outputs.DAFNeOutputs.get_sample_region", "corners[].repeat", "dafne_outputs.is_in_quadrilateral", "torch.stack.max", "torch.stack.max", "locations.new_zeros", "locations.new_zeros", "locations.new_zeros", "labels_per_im.new_zeros", "labels_per_im.new_zeros", "torch.stack.min", "torch.stack.min", "range", "range", "range", "locations.size", "locations.size", "locations.size", "locations.size", "locations.size", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_abcd", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.get_sample_region", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.is_in_quadrilateral", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "compute_targets_for_locations", "(", "self", ",", "locations", ",", "targets", ",", "size_ranges", ",", "num_loc_list", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "reg_targets_corners", "=", "[", "]", "\n", "reg_targets_ltrb", "=", "[", "]", "\n", "reg_targets_abcd", "=", "[", "]", "\n", "target_inds", "=", "[", "]", "\n", "xs", ",", "ys", "=", "locations", "[", ":", ",", "0", "]", ",", "locations", "[", ":", ",", "1", "]", "\n", "\n", "\n", "K", "=", "len", "(", "xs", ")", "\n", "num_targets", "=", "0", "\n", "for", "im_i", "in", "range", "(", "len", "(", "targets", ")", ")", ":", "\n", "            ", "targets_per_im", "=", "targets", "[", "im_i", "]", "\n", "bboxes", "=", "targets_per_im", ".", "gt_boxes", ".", "tensor", "\n", "num_gts", "=", "bboxes", ".", "shape", "[", "0", "]", "\n", "corners", "=", "targets_per_im", ".", "gt_corners", "\n", "area", "=", "targets_per_im", ".", "gt_corners_area", "\n", "labels_per_im", "=", "targets_per_im", ".", "gt_classes", "\n", "locations_to_gt_area", "=", "area", "[", "None", "]", ".", "repeat", "(", "K", ",", "1", ")", "\n", "\n", "# no gt", "\n", "if", "bboxes", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "labels", ".", "append", "(", "labels_per_im", ".", "new_zeros", "(", "locations", ".", "size", "(", "0", ")", ")", "+", "self", ".", "num_classes", ")", "\n", "reg_targets_ltrb", ".", "append", "(", "locations", ".", "new_zeros", "(", "(", "locations", ".", "size", "(", "0", ")", ",", "4", ")", ")", ")", "\n", "reg_targets_abcd", ".", "append", "(", "locations", ".", "new_zeros", "(", "(", "locations", ".", "size", "(", "0", ")", ",", "4", ")", ")", ")", "\n", "reg_targets_corners", ".", "append", "(", "locations", ".", "new_zeros", "(", "(", "locations", ".", "size", "(", "0", ")", ",", "8", ")", ")", ")", "\n", "target_inds", ".", "append", "(", "labels_per_im", ".", "new_zeros", "(", "locations", ".", "size", "(", "0", ")", ")", "-", "1", ")", "\n", "continue", "\n", "\n", "", "xs_ext", "=", "xs", "[", ":", ",", "None", "]", "\n", "ys_ext", "=", "ys", "[", ":", ",", "None", "]", "\n", "\n", "# Generate ltrb values", "\n", "l", "=", "xs_ext", "-", "bboxes", "[", ":", ",", "0", "]", "[", "None", "]", "\n", "t", "=", "ys_ext", "-", "bboxes", "[", ":", ",", "1", "]", "[", "None", "]", "\n", "r", "=", "bboxes", "[", ":", ",", "2", "]", "[", "None", "]", "-", "xs_ext", "\n", "b", "=", "bboxes", "[", ":", ",", "3", "]", "[", "None", "]", "-", "ys_ext", "\n", "reg_targets_ltrb_per_im", "=", "torch", ".", "stack", "(", "[", "l", ",", "t", ",", "r", ",", "b", "]", ",", "dim", "=", "2", ")", "\n", "\n", "reg_targets_abcd_per_im", "=", "compute_abcd", "(", "corners", ",", "xs_ext", ",", "ys_ext", ")", "\n", "\n", "# Compute corner w.r.t. locations (expand for each location)", "\n", "x0_centered", "=", "corners", "[", ":", ",", "0", "]", "[", "None", "]", "-", "xs_ext", "\n", "y0_centered", "=", "corners", "[", ":", ",", "1", "]", "[", "None", "]", "-", "ys_ext", "\n", "x1_centered", "=", "corners", "[", ":", ",", "2", "]", "[", "None", "]", "-", "xs_ext", "\n", "y1_centered", "=", "corners", "[", ":", ",", "3", "]", "[", "None", "]", "-", "ys_ext", "\n", "x2_centered", "=", "corners", "[", ":", ",", "4", "]", "[", "None", "]", "-", "xs_ext", "\n", "y2_centered", "=", "corners", "[", ":", ",", "5", "]", "[", "None", "]", "-", "ys_ext", "\n", "x3_centered", "=", "corners", "[", ":", ",", "6", "]", "[", "None", "]", "-", "xs_ext", "\n", "y3_centered", "=", "corners", "[", ":", ",", "7", "]", "[", "None", "]", "-", "ys_ext", "\n", "\n", "reg_targets_corners_per_im", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "x0_centered", ",", "\n", "y0_centered", ",", "\n", "x1_centered", ",", "\n", "y1_centered", ",", "\n", "x2_centered", ",", "\n", "y2_centered", ",", "\n", "x3_centered", ",", "\n", "y3_centered", ",", "\n", "]", ",", "\n", "dim", "=", "2", ",", "\n", ")", "\n", "\n", "if", "self", ".", "center_sample", ":", "\n", "                ", "if", "targets_per_im", ".", "has", "(", "\"gt_bitmasks_full\"", ")", ":", "\n", "                    ", "bitmasks", "=", "targets_per_im", ".", "gt_bitmasks_full", "\n", "", "else", ":", "\n", "                    ", "bitmasks", "=", "None", "\n", "", "is_in_boxes_center_sampling", "=", "self", ".", "get_sample_region", "(", "\n", "bboxes", ",", "\n", "self", ".", "strides", ",", "\n", "num_loc_list", ",", "\n", "xs", ",", "\n", "ys", ",", "\n", "bitmasks", "=", "bitmasks", ",", "\n", "radius", "=", "self", ".", "radius", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "is_in_boxes_center_sampling", "=", "reg_targets_ltrb_per_im", ".", "min", "(", "dim", "=", "2", ")", "[", "0", "]", ">", "0", "\n", "\n", "# is_in_boxes = is_in_boxes_ltrb", "\n", "\n", "", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTER_SAMPLE_ONLY", ":", "\n", "# Only use center sampling", "\n", "                ", "is_in_boxes", "=", "is_in_boxes_center_sampling", "\n", "", "else", ":", "\n", "# IS_IN_BOXES for quadrilateral", "\n", "                ", "corners_rep", "=", "corners", "[", "None", "]", ".", "repeat", "(", "K", ",", "1", ",", "1", ")", "\n", "is_in_boxes_quad", "=", "is_in_quadrilateral", "(", "\n", "corners_rep", "[", "...", ",", "0", ":", "2", "]", ",", "\n", "corners_rep", "[", "...", ",", "2", ":", "4", "]", ",", "\n", "corners_rep", "[", "...", ",", "4", ":", "6", "]", ",", "\n", "corners_rep", "[", "...", ",", "6", ":", "8", "]", ",", "\n", "locations_to_gt_area", ",", "\n", "locations", "[", ":", ",", "None", "]", ",", "\n", ")", "\n", "\n", "# Combine center_sampling + is_in_quadrilateral with logical and", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "COMBINE_CENTER_SAMPLE", ":", "\n", "                    ", "is_in_boxes", "=", "is_in_boxes_center_sampling", "&", "is_in_boxes_quad", "\n", "", "else", ":", "\n", "# Only use box-check sampling", "\n", "                    ", "is_in_boxes", "=", "is_in_boxes_quad", "\n", "\n", "", "", "max_reg_targets_per_im", "=", "reg_targets_ltrb_per_im", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", "\n", "# limit the regression range for each location", "\n", "is_cared_in_the_level", "=", "(", "max_reg_targets_per_im", ">=", "size_ranges", "[", ":", ",", "[", "0", "]", "]", ")", "&", "(", "\n", "max_reg_targets_per_im", "<=", "size_ranges", "[", ":", ",", "[", "1", "]", "]", "\n", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_IN_BOX_CHECK", ":", "\n", "                ", "locations_to_gt_area", "[", "is_in_boxes", "==", "0", "]", "=", "INF", "\n", "\n", "", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_LEVEL_SIZE_FILTERING", ":", "\n", "                ", "locations_to_gt_area", "[", "is_cared_in_the_level", "==", "0", "]", "=", "INF", "\n", "\n", "# if there are still more than one objects for a location,", "\n", "# we choose the one with minimal area", "\n", "", "locations_to_min_area", ",", "locations_to_gt_inds", "=", "locations_to_gt_area", ".", "min", "(", "dim", "=", "1", ")", "\n", "\n", "reg_targets_ltrb_per_im", "=", "reg_targets_ltrb_per_im", "[", "\n", "range", "(", "len", "(", "locations", ")", ")", ",", "locations_to_gt_inds", "\n", "]", "\n", "reg_targets_abcd_per_im", "=", "reg_targets_abcd_per_im", "[", "\n", "range", "(", "len", "(", "locations", ")", ")", ",", "locations_to_gt_inds", "\n", "]", "\n", "reg_targets_corners_per_im", "=", "reg_targets_corners_per_im", "[", "\n", "range", "(", "len", "(", "locations", ")", ")", ",", "locations_to_gt_inds", "\n", "]", "\n", "target_inds_per_im", "=", "locations_to_gt_inds", "+", "num_targets", "\n", "num_targets", "+=", "len", "(", "targets_per_im", ")", "\n", "\n", "labels_per_im", "=", "labels_per_im", "[", "locations_to_gt_inds", "]", "\n", "labels_per_im", "[", "locations_to_min_area", "==", "INF", "]", "=", "self", ".", "num_classes", "\n", "\n", "labels", ".", "append", "(", "labels_per_im", ")", "\n", "reg_targets_ltrb", ".", "append", "(", "reg_targets_ltrb_per_im", ")", "\n", "reg_targets_abcd", ".", "append", "(", "reg_targets_abcd_per_im", ")", "\n", "reg_targets_corners", ".", "append", "(", "reg_targets_corners_per_im", ")", "\n", "target_inds", ".", "append", "(", "target_inds_per_im", ")", "\n", "\n", "", "return", "{", "\n", "\"labels\"", ":", "labels", ",", "\n", "\"reg_targets_ltrb\"", ":", "reg_targets_ltrb", ",", "\n", "\"reg_targets_abcd\"", ":", "reg_targets_abcd", ",", "\n", "\"reg_targets_corners\"", ":", "reg_targets_corners", ",", "\n", "\"target_inds\"", ":", "target_inds", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.losses": [[505, 619], ["dafne_outputs.DAFNeOutputs._get_ground_truth", "detectron2.structures.Instances", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "detectron2.layers.cat", "dafne_outputs.DAFNeOutputs.dafne_losses", "detectron2.layers.cat", "detectron2.layers.cat", "len", "detectron2.layers.cat", "x.reshape", "x.reshape", "x.reshape", "x.reshape", "x.reshape", "x.reshape", "x.reshape", "x.reshape", "x.permute().reshape", "x.permute().reshape", "x.permute().reshape", "x.permute().reshape", "x.permute().reshape", "x.permute", "x.permute", "x.size", "x.permute", "x.permute", "x.permute"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs._get_ground_truth", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.dafne_losses", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "losses", "(", "\n", "self", ",", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "center_reg_pred", ",", "\n", "ltrb_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "locations", ",", "\n", "gt_instances", ",", "\n", "top_feats", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Return the losses from a set of DAFNE predictions and their associated ground-truth.\n\n        Returns:\n            dict[loss name -> loss value]: A dict mapping from loss name to loss value.\n        \"\"\"", "\n", "\n", "training_targets", "=", "self", ".", "_get_ground_truth", "(", "locations", ",", "gt_instances", ")", "\n", "\n", "# Collect all logits and regression predictions over feature maps", "\n", "# and images to arrive at the same shape as the labels and targets", "\n", "# The final ordering is L, N, H, W from slowest to fastest axis.", "\n", "\n", "instances", "=", "Instances", "(", "(", "0", ",", "0", ")", ")", "\n", "instances", ".", "labels", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, 1, Hi, Wi) -> (N*Hi*Wi,)", "\n", "x", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "training_targets", "[", "\"labels\"", "]", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "instances", ".", "gt_inds", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, 1, Hi, Wi) -> (N*Hi*Wi,)", "\n", "x", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "training_targets", "[", "\"target_inds\"", "]", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "instances", ".", "im_inds", "=", "cat", "(", "[", "x", ".", "reshape", "(", "-", "1", ")", "for", "x", "in", "training_targets", "[", "\"im_inds\"", "]", "]", ",", "dim", "=", "0", ")", "\n", "instances", ".", "reg_targets_corners", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, Hi, Wi, 8) -> (N*Hi*Wi, 8)", "\n", "x", ".", "reshape", "(", "-", "1", ",", "8", ")", "\n", "for", "x", "in", "training_targets", "[", "\"reg_targets_corners\"", "]", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "instances", ".", "reg_targets_ltrb", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, Hi, Wi, 4) -> (N*Hi*Wi, 4)", "\n", "x", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "for", "x", "in", "training_targets", "[", "\"reg_targets_ltrb\"", "]", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "instances", ".", "reg_targets_abcd", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, Hi, Wi, 4) -> (N*Hi*Wi, 4)", "\n", "x", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "for", "x", "in", "training_targets", "[", "\"reg_targets_abcd\"", "]", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "instances", ".", "locations", "=", "cat", "(", "[", "x", ".", "reshape", "(", "-", "1", ",", "2", ")", "for", "x", "in", "training_targets", "[", "\"locations\"", "]", "]", ",", "dim", "=", "0", ")", "\n", "instances", ".", "fpn_levels", "=", "cat", "(", "[", "x", ".", "reshape", "(", "-", "1", ")", "for", "x", "in", "training_targets", "[", "\"fpn_levels\"", "]", "]", ",", "dim", "=", "0", ")", "\n", "\n", "instances", ".", "logits_pred", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, C, Hi, Wi) -> (N, Hi, Wi, C) -> (N*Hi*Wi, C)", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "self", ".", "num_classes", ")", "\n", "for", "x", "in", "logits_pred", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "instances", ".", "corners_reg_pred", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, B, Hi, Wi) -> (N, Hi, Wi, B) -> (N*Hi*Wi, B)", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "8", ")", "\n", "for", "x", "in", "corners_reg_pred", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "if", "self", ".", "has_center_reg", ":", "\n", "            ", "instances", ".", "center_reg_pred", "=", "cat", "(", "\n", "[", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "for", "x", "in", "center_reg_pred", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "\n", "", "if", "self", ".", "has_centerness", ":", "\n", "            ", "instances", ".", "ctrness_pred", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, 1, Hi, Wi) -> (N*Hi*Wi,)", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", "\n", "for", "x", "in", "ctrness_pred", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "", "if", "len", "(", "top_feats", ")", ">", "0", ":", "\n", "            ", "instances", ".", "top_feats", "=", "cat", "(", "\n", "[", "\n", "# Reshape: (N, -1, Hi, Wi) -> (N*Hi*Wi, -1)", "\n", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "x", ".", "size", "(", "1", ")", ")", "\n", "for", "x", "in", "top_feats", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "", "return", "self", ".", "dafne_losses", "(", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.dafne_losses": [[620, 732], ["instances.logits_pred.size", "instances.labels.flatten", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze.numel", "torch.nonzero().squeeze.numel", "detectron2.utils.comm.get_world_size", "reduce_sum().item", "max", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "compute_ctrness_targets.sum", "max", "fvcore.nn.sigmoid_focal_loss_jit", "dafne_outputs.compute_ctrness_targets", "torch.nonzero().squeeze.numel", "torch.nonzero().squeeze.numel", "instances.reg_targets_corners.view().mean", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "dafne_outputs.reduce_sum", "dafne_outputs.compute_ctrness_targets", "dafne_outputs.compute_ctrness_targets", "reduce_sum().item", "dafne.utils.sort_corners.sort_quadrilateral", "dafne_outputs.DAFNeOutputs.corners_loss_func", "instances.corners_reg_pred.sum", "torch.nonzero().squeeze.new_tensor", "torch.nonzero().squeeze.new_tensor", "instances.reg_targets_corners.view", "dafne_outputs.DAFNeOutputs.center_loss_func", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "instances.center_reg_pred.sum", "instances.ctrness_pred.sum", "dafne_outputs.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_ctrness_targets", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.reduce_sum", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_ctrness_targets", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_ctrness_targets", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort_quadrilateral", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.reduce_sum"], ["", "def", "dafne_losses", "(", "self", ",", "instances", ")", ":", "\n", "        ", "num_classes", "=", "instances", ".", "logits_pred", ".", "size", "(", "1", ")", "\n", "assert", "num_classes", "==", "self", ".", "num_classes", "\n", "\n", "labels", "=", "instances", ".", "labels", ".", "flatten", "(", ")", "\n", "\n", "pos_inds", "=", "torch", ".", "nonzero", "(", "labels", "!=", "num_classes", ")", ".", "squeeze", "(", "1", ")", "\n", "num_pos_local", "=", "pos_inds", ".", "numel", "(", ")", "\n", "num_gpus", "=", "get_world_size", "(", ")", "\n", "total_num_pos", "=", "reduce_sum", "(", "pos_inds", ".", "new_tensor", "(", "[", "num_pos_local", "]", ")", ")", ".", "item", "(", ")", "\n", "num_pos_avg", "=", "max", "(", "total_num_pos", "/", "num_gpus", ",", "1.0", ")", "\n", "\n", "# prepare one_hot", "\n", "class_target", "=", "torch", ".", "zeros_like", "(", "instances", ".", "logits_pred", ")", "\n", "class_target", "[", "pos_inds", ",", "labels", "[", "pos_inds", "]", "]", "=", "1", "\n", "\n", "class_loss", "=", "(", "\n", "sigmoid_focal_loss_jit", "(", "\n", "instances", ".", "logits_pred", ",", "\n", "class_target", ",", "\n", "alpha", "=", "self", ".", "focal_loss_alpha", ",", "\n", "gamma", "=", "self", ".", "focal_loss_gamma", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "/", "num_pos_avg", "\n", ")", "\n", "\n", "instances", "=", "instances", "[", "pos_inds", "]", "\n", "instances", ".", "pos_inds", "=", "pos_inds", "\n", "\n", "if", "self", ".", "centerness_mode", "==", "\"oriented\"", ":", "\n", "            ", "ctrness_targets", "=", "compute_ctrness_targets", "(", "\n", "instances", ".", "reg_targets_abcd", ",", "self", ".", "centerness_alpha", "\n", ")", "\n", "", "elif", "self", ".", "centerness_mode", "==", "\"plain\"", ":", "\n", "            ", "ctrness_targets", "=", "compute_ctrness_targets", "(", "\n", "instances", ".", "reg_targets_ltrb", ",", "self", ".", "centerness_alpha", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ctrness_targets", "=", "compute_ctrness_targets", "(", "\n", "instances", ".", "reg_targets_abcd", ",", "self", ".", "centerness_alpha", "\n", ")", "\n", "ctrness_targets", "[", ":", "]", "=", "1.0", "\n", "\n", "", "ctrness_targets_sum", "=", "ctrness_targets", ".", "sum", "(", ")", "\n", "loss_denorm", "=", "max", "(", "reduce_sum", "(", "ctrness_targets_sum", ")", ".", "item", "(", ")", "/", "num_gpus", ",", "1e-6", ")", "\n", "instances", ".", "gt_ctrs", "=", "ctrness_targets", "\n", "\n", "if", "pos_inds", ".", "numel", "(", ")", ">", "0", ":", "\n", "\n", "# Sort corners if flag is set", "\n", "# NOTE: targets are sorted in the datasetmapper", "\n", "            ", "if", "self", ".", "sort_corners", ":", "\n", "                ", "instances", ".", "corners_reg_pred", "=", "sort_quadrilateral", "(", "instances", ".", "corners_reg_pred", ")", "\n", "\n", "", "corners_reg_loss", "=", "(", "\n", "self", ".", "corners_loss_func", "(", "\n", "instances", ".", "corners_reg_pred", ",", "\n", "instances", ".", "reg_targets_corners", ",", "\n", "ctrness_targets", ",", "\n", ")", "\n", "/", "loss_denorm", "\n", ")", "\n", "\n", "reg_targets_center", "=", "instances", ".", "reg_targets_corners", ".", "view", "(", "-", "1", ",", "4", ",", "2", ")", ".", "mean", "(", "1", ")", "\n", "if", "self", ".", "has_center_reg", ":", "\n", "                ", "center_reg_loss", "=", "(", "\n", "self", ".", "center_loss_func", "(", "\n", "instances", ".", "center_reg_pred", ",", "\n", "reg_targets_center", ",", "\n", "ctrness_targets", ",", "\n", ")", "\n", "/", "loss_denorm", "\n", ")", "\n", "\n", "\n", "", "if", "self", ".", "has_centerness", ":", "\n", "                ", "ctrness_loss", "=", "(", "\n", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "instances", ".", "ctrness_pred", ",", "ctrness_targets", ",", "reduction", "=", "\"sum\"", "\n", ")", "\n", "/", "num_pos_avg", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "corners_reg_loss", "=", "instances", ".", "corners_reg_pred", ".", "sum", "(", ")", "*", "0", "\n", "if", "self", ".", "has_center_reg", ":", "\n", "                ", "center_reg_loss", "=", "instances", ".", "center_reg_pred", ".", "sum", "(", ")", "*", "0", "\n", "\n", "", "if", "self", ".", "has_centerness", ":", "\n", "                ", "ctrness_loss", "=", "instances", ".", "ctrness_pred", ".", "sum", "(", ")", "*", "0", "\n", "\n", "\n", "# Apply lambdas", "\n", "", "", "class_loss", "=", "class_loss", "*", "self", ".", "lambda_cls", "\n", "corners_reg_loss", "=", "corners_reg_loss", "*", "self", ".", "lambda_corners", "\n", "\n", "losses", "=", "{", "\n", "\"loss/cls\"", ":", "class_loss", ",", "\n", "\"loss/corners\"", ":", "corners_reg_loss", ",", "\n", "}", "\n", "\n", "# Add center reg", "\n", "if", "self", ".", "has_center_reg", ":", "\n", "            ", "losses", "[", "\"loss/center\"", "]", "=", "center_reg_loss", "*", "self", ".", "lambda_center", "\n", "\n", "# Add centerness if not none", "\n", "", "if", "self", ".", "has_centerness", ":", "\n", "            ", "losses", "[", "\"loss/ctr\"", "]", "=", "ctrness_loss", "*", "self", ".", "lambda_ctr", "\n", "\n", "\n", "", "extras", "=", "{", "\"instances\"", ":", "instances", ",", "\"loss_denorm\"", ":", "loss_denorm", "}", "\n", "return", "extras", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.predict_proposals": [[733, 791], ["enumerate", "list", "dafne_outputs.DAFNeOutputs.select_over_all_levels", "len", "zip", "dict", "sampled_boxes.append", "zip", "detectron2.structures.Instances.cat", "zip", "dafne_outputs.DAFNeOutputs.forward_for_single_feature_map", "bundle.values", "bundle.keys", "l.new_ones", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.select_over_all_levels", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.forward_for_single_feature_map"], ["", "def", "predict_proposals", "(", "\n", "self", ",", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "locations", ",", "\n", "image_sizes", ",", "\n", "top_feats", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "pre_nms_thresh", "=", "self", ".", "pre_nms_thresh_train", "\n", "self", ".", "pre_nms_topk", "=", "self", ".", "pre_nms_topk_train", "\n", "self", ".", "post_nms_topk", "=", "self", ".", "post_nms_topk_train", "\n", "", "else", ":", "\n", "            ", "self", ".", "pre_nms_thresh", "=", "self", ".", "pre_nms_thresh_test", "\n", "self", ".", "pre_nms_topk", "=", "self", ".", "pre_nms_topk_test", "\n", "self", ".", "post_nms_topk", "=", "self", ".", "post_nms_topk_test", "\n", "\n", "", "sampled_boxes", "=", "[", "]", "\n", "\n", "bundle", "=", "{", "\n", "\"l\"", ":", "locations", ",", "\n", "\"o\"", ":", "logits_pred", ",", "\n", "\"rc\"", ":", "corners_reg_pred", ",", "\n", "\"c\"", ":", "ctrness_pred", ",", "\n", "\"s\"", ":", "self", ".", "strides", ",", "\n", "}", "\n", "\n", "if", "len", "(", "top_feats", ")", ">", "0", ":", "\n", "            ", "bundle", "[", "\"t\"", "]", "=", "top_feats", "\n", "\n", "", "for", "i", ",", "per_bundle", "in", "enumerate", "(", "zip", "(", "*", "bundle", ".", "values", "(", ")", ")", ")", ":", "\n", "# get per-level bundle", "\n", "            ", "per_bundle", "=", "dict", "(", "zip", "(", "bundle", ".", "keys", "(", ")", ",", "per_bundle", ")", ")", "\n", "# recall that during training, we normalize regression targets with FPN's stride.", "\n", "# we denormalize them here.", "\n", "l", "=", "per_bundle", "[", "\"l\"", "]", "\n", "o", "=", "per_bundle", "[", "\"o\"", "]", "\n", "if", "self", ".", "cfg", ".", "MODEL", ".", "DAFNE", ".", "ENABLE_FPN_STRIDE_NORM", ":", "\n", "                ", "rc", "=", "per_bundle", "[", "\"rc\"", "]", "*", "per_bundle", "[", "\"s\"", "]", "\n", "", "else", ":", "\n", "                ", "rc", "=", "per_bundle", "[", "\"rc\"", "]", "\n", "", "c", "=", "per_bundle", "[", "\"c\"", "]", "\n", "t", "=", "per_bundle", "[", "\"t\"", "]", "if", "\"t\"", "in", "bundle", "else", "None", "\n", "\n", "sampled_boxes", ".", "append", "(", "self", ".", "forward_for_single_feature_map", "(", "l", ",", "o", ",", "rc", ",", "c", ",", "image_sizes", ",", "t", ")", ")", "\n", "\n", "for", "per_im_sampled_boxes", "in", "sampled_boxes", "[", "-", "1", "]", ":", "\n", "                ", "per_im_sampled_boxes", ".", "fpn_levels", "=", "(", "\n", "l", ".", "new_ones", "(", "len", "(", "per_im_sampled_boxes", ")", ",", "dtype", "=", "torch", ".", "long", ")", "*", "i", "\n", ")", "\n", "\n", "", "", "boxlists", "=", "list", "(", "zip", "(", "*", "sampled_boxes", ")", ")", "\n", "\n", "boxlists", "=", "[", "Instances", ".", "cat", "(", "boxlist", ")", "for", "boxlist", "in", "boxlists", "]", "\n", "boxlists", "=", "self", ".", "select_over_all_levels", "(", "boxlists", ")", "\n", "\n", "return", "boxlists", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.forward_for_single_feature_map": [[792, 906], ["logits_pred.view().permute.view().permute.view().permute", "logits_pred.view().permute.view().permute.reshape().sigmoid", "corners_reg_pred.view().permute", "box_regression_corners.reshape.reshape.reshape", "ctrness_pred.sigmoid.sigmoid.view().permute", "ctrness_pred.sigmoid.sigmoid.reshape", "candidate_inds.reshape().sum", "pre_nms_top_n.clamp.clamp.clamp", "range", "ctrness_pred.sigmoid.sigmoid.sigmoid", "top_feat.reshape.reshape.view().permute", "top_feat.reshape.reshape.reshape", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "per_candidate_inds.nonzero", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "detectron2.structures.Instances", "detectron2.structures.boxes.Boxes", "results.append", "logits_pred.view().permute.view().permute.view", "logits_pred.view().permute.view().permute.reshape", "corners_reg_pred.view", "ctrness_pred.sigmoid.sigmoid.view", "candidate_inds.reshape", "per_candidate_inds.sum().item", "per_pre_nms_top_n.item", "per_box_cls.topk", "dafne.utils.sort_corners.sort_quadrilateral", "type", "tuple", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "dafne.utils.sort_corners.sort_quadrilateral.new_empty", "top_feat.reshape.reshape.view", "image_sizes[].tolist", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "per_candidate_inds.sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort_quadrilateral"], ["", "def", "forward_for_single_feature_map", "(", "\n", "self", ",", "\n", "locations", ",", "\n", "logits_pred", ",", "\n", "corners_reg_pred", ",", "\n", "ctrness_pred", ",", "\n", "image_sizes", ",", "\n", "top_feat", "=", "None", ",", "\n", ")", ":", "\n", "        ", "N", ",", "C", ",", "H", ",", "W", "=", "logits_pred", ".", "shape", "\n", "\n", "# put in the same format as locations", "\n", "logits_pred", "=", "logits_pred", ".", "view", "(", "N", ",", "C", ",", "H", ",", "W", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "cls_pred", "=", "logits_pred", ".", "reshape", "(", "N", ",", "-", "1", ",", "C", ")", ".", "sigmoid", "(", ")", "\n", "box_regression_corners", "=", "corners_reg_pred", ".", "view", "(", "N", ",", "8", ",", "H", ",", "W", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "box_regression_corners", "=", "box_regression_corners", ".", "reshape", "(", "N", ",", "-", "1", ",", "8", ")", "\n", "ctrness_pred", "=", "ctrness_pred", ".", "view", "(", "N", ",", "1", ",", "H", ",", "W", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "ctrness_pred", "=", "ctrness_pred", ".", "reshape", "(", "N", ",", "-", "1", ")", "\n", "\n", "# Only apply sigmoid if centerness is enabled, else keep dummy \"1.0\" values", "\n", "if", "self", ".", "has_centerness", ":", "\n", "            ", "ctrness_pred", "=", "ctrness_pred", ".", "sigmoid", "(", ")", "\n", "\n", "", "if", "top_feat", "is", "not", "None", ":", "\n", "            ", "top_feat", "=", "top_feat", ".", "view", "(", "N", ",", "-", "1", ",", "H", ",", "W", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "top_feat", "=", "top_feat", ".", "reshape", "(", "N", ",", "H", "*", "W", ",", "-", "1", ")", "\n", "\n", "# if self.thresh_with_ctr is True, we multiply the classification", "\n", "# scores with centerness scores before applying the threshold.", "\n", "", "if", "self", ".", "has_centerness", "and", "self", ".", "thresh_with_ctr", ":", "\n", "            ", "cls_pred", "=", "torch", ".", "sqrt", "(", "cls_pred", "*", "ctrness_pred", "[", ":", ",", ":", ",", "None", "]", ")", "\n", "\n", "", "candidate_inds", "=", "cls_pred", ">", "self", ".", "pre_nms_thresh", "\n", "pre_nms_top_n", "=", "candidate_inds", ".", "reshape", "(", "N", ",", "-", "1", ")", ".", "sum", "(", "1", ")", "\n", "pre_nms_top_n", "=", "pre_nms_top_n", ".", "clamp", "(", "max", "=", "self", ".", "pre_nms_topk", ")", "\n", "\n", "if", "self", ".", "has_centerness", "and", "not", "self", ".", "thresh_with_ctr", ":", "\n", "            ", "cls_pred", "=", "torch", ".", "sqrt", "(", "cls_pred", "*", "ctrness_pred", "[", ":", ",", ":", ",", "None", "]", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "per_box_cls", "=", "cls_pred", "[", "i", "]", "\n", "per_candidate_inds", "=", "candidate_inds", "[", "i", "]", "\n", "per_box_cls", "=", "per_box_cls", "[", "per_candidate_inds", "]", "\n", "\n", "per_candidate_nonzeros", "=", "per_candidate_inds", ".", "nonzero", "(", ")", "\n", "per_box_loc", "=", "per_candidate_nonzeros", "[", ":", ",", "0", "]", "\n", "per_class", "=", "per_candidate_nonzeros", "[", ":", ",", "1", "]", "\n", "\n", "per_box_regression_corners", "=", "box_regression_corners", "[", "i", "]", "\n", "per_box_regression_corners", "=", "per_box_regression_corners", "[", "per_box_loc", "]", "\n", "per_locations", "=", "locations", "[", "per_box_loc", "]", "\n", "per_box_centerness", "=", "ctrness_pred", "[", "i", ",", "per_box_loc", "]", "\n", "if", "top_feat", "is", "not", "None", ":", "\n", "                ", "per_top_feat", "=", "top_feat", "[", "i", "]", "\n", "per_top_feat", "=", "per_top_feat", "[", "per_box_loc", "]", "\n", "\n", "", "per_pre_nms_top_n", "=", "pre_nms_top_n", "[", "i", "]", "\n", "\n", "if", "per_candidate_inds", ".", "sum", "(", ")", ".", "item", "(", ")", ">", "per_pre_nms_top_n", ".", "item", "(", ")", ":", "\n", "                ", "per_box_cls", ",", "top_k_indices", "=", "per_box_cls", ".", "topk", "(", "per_pre_nms_top_n", ",", "sorted", "=", "False", ")", "\n", "per_class", "=", "per_class", "[", "top_k_indices", "]", "\n", "per_box_regression_corners", "=", "per_box_regression_corners", "[", "top_k_indices", "]", "\n", "per_locations", "=", "per_locations", "[", "top_k_indices", "]", "\n", "per_box_centerness", "=", "per_box_centerness", "[", "top_k_indices", "]", "\n", "if", "top_feat", "is", "not", "None", ":", "\n", "                    ", "per_top_feat", "=", "per_top_feat", "[", "top_k_indices", "]", "\n", "\n", "", "", "detections_poly", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "per_locations", "[", ":", ",", "0", "]", "+", "per_box_regression_corners", "[", ":", ",", "0", "]", ",", "\n", "per_locations", "[", ":", ",", "1", "]", "+", "per_box_regression_corners", "[", ":", ",", "1", "]", ",", "\n", "per_locations", "[", ":", ",", "0", "]", "+", "per_box_regression_corners", "[", ":", ",", "2", "]", ",", "\n", "per_locations", "[", ":", ",", "1", "]", "+", "per_box_regression_corners", "[", ":", ",", "3", "]", ",", "\n", "per_locations", "[", ":", ",", "0", "]", "+", "per_box_regression_corners", "[", ":", ",", "4", "]", ",", "\n", "per_locations", "[", ":", ",", "1", "]", "+", "per_box_regression_corners", "[", ":", ",", "5", "]", ",", "\n", "per_locations", "[", ":", ",", "0", "]", "+", "per_box_regression_corners", "[", ":", ",", "6", "]", ",", "\n", "per_locations", "[", ":", ",", "1", "]", "+", "per_box_regression_corners", "[", ":", ",", "7", "]", ",", "\n", "]", ",", "\n", "dim", "=", "1", ",", "\n", ")", "\n", "\n", "# Sort quadrilateral to have a canonical representation", "\n", "if", "self", ".", "sort_corners", ":", "\n", "                ", "detections_poly", "=", "sort_quadrilateral", "(", "detections_poly", ")", "\n", "\n", "", "if", "type", "(", "image_sizes", "[", "i", "]", ")", "==", "torch", ".", "Tensor", ":", "\n", "                ", "image_size", "=", "tuple", "(", "image_sizes", "[", "i", "]", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "image_size", "=", "image_sizes", "[", "i", "]", "\n", "", "boxlist", "=", "Instances", "(", "image_size", ")", "\n", "\n", "# Generate surrounding hboxes from corners", "\n", "if", "detections_poly", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                ", "xmin", "=", "torch", ".", "min", "(", "detections_poly", "[", ":", ",", "0", ":", ":", "2", "]", ",", "dim", "=", "1", ")", ".", "values", "\n", "xmax", "=", "torch", ".", "max", "(", "detections_poly", "[", ":", ",", "0", ":", ":", "2", "]", ",", "dim", "=", "1", ")", ".", "values", "\n", "ymin", "=", "torch", ".", "min", "(", "detections_poly", "[", ":", ",", "1", ":", ":", "2", "]", ",", "dim", "=", "1", ")", ".", "values", "\n", "ymax", "=", "torch", ".", "max", "(", "detections_poly", "[", ":", ",", "1", ":", ":", "2", "]", ",", "dim", "=", "1", ")", ".", "values", "\n", "hbboxes", "=", "torch", ".", "stack", "(", "(", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "hbboxes", "=", "detections_poly", ".", "new_empty", "(", "0", ",", "4", ")", "\n", "\n", "", "boxlist", ".", "pred_boxes", "=", "Boxes", "(", "hbboxes", ")", "\n", "boxlist", ".", "pred_corners", "=", "detections_poly", "\n", "boxlist", ".", "scores", "=", "per_box_cls", "\n", "boxlist", ".", "centerness", "=", "per_box_centerness", "\n", "# boxlist.scores = torch.sqrt(per_box_cls)", "\n", "boxlist", ".", "pred_classes", "=", "per_class", "\n", "boxlist", ".", "locations", "=", "per_locations", "\n", "if", "top_feat", "is", "not", "None", ":", "\n", "                ", "boxlist", ".", "top_feat", "=", "per_top_feat", "\n", "", "results", ".", "append", "(", "boxlist", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.select_over_all_levels": [[907, 926], ["len", "range", "dafne.modeling.nms.nms.ml_nms", "len", "results.append", "torch.kthvalue", "torch.kthvalue", "torch.kthvalue", "torch.kthvalue", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "cls_scores.cpu", "image_thresh.item", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.nms.nms.ml_nms", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "select_over_all_levels", "(", "self", ",", "boxlists", ")", ":", "\n", "        ", "num_images", "=", "len", "(", "boxlists", ")", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "# multiclass nms", "\n", "            ", "result", "=", "ml_nms", "(", "boxlists", "[", "i", "]", ",", "self", ".", "nms_thresh", ")", "\n", "number_of_detections", "=", "len", "(", "result", ")", "\n", "\n", "# Limit to max_per_image detections **over all classes**", "\n", "if", "number_of_detections", ">", "self", ".", "post_nms_topk", ">", "0", ":", "\n", "                ", "cls_scores", "=", "result", ".", "scores", "\n", "image_thresh", ",", "_", "=", "torch", ".", "kthvalue", "(", "\n", "cls_scores", ".", "cpu", "(", ")", ",", "number_of_detections", "-", "self", ".", "post_nms_topk", "+", "1", "\n", ")", "\n", "keep", "=", "cls_scores", ">=", "image_thresh", ".", "item", "(", ")", "\n", "keep", "=", "torch", ".", "nonzero", "(", "keep", ")", ".", "squeeze", "(", "1", ")", "\n", "result", "=", "result", "[", "keep", "]", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.reduce_sum": [[44, 51], ["detectron2.utils.comm.get_world_size", "tensor.clone.clone", "torch.distributed.all_reduce"], "function", ["None"], ["def", "reduce_sum", "(", "tensor", ")", ":", "\n", "    ", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "tensor", "\n", "", "tensor", "=", "tensor", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "tensor", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.dist_point_to_line": [[53, 65], ["p1.unbind", "p2.unbind", "torch.abs", "torch.abs", "torch.sqrt", "torch.sqrt"], "function", ["None"], ["", "def", "dist_point_to_line", "(", "p1", ",", "p2", ",", "x0", ",", "y0", ")", ":", "\n", "    ", "\"\"\"\n    https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line\n    Line defined by P1=(x1,y1), P2=(x2,y2)\n    Point defined by P0=(x0, y0)\n    \"\"\"", "\n", "x1", ",", "y1", "=", "p1", ".", "unbind", "(", "2", ")", "\n", "x2", ",", "y2", "=", "p2", ".", "unbind", "(", "2", ")", "\n", "nom", "=", "torch", ".", "abs", "(", "(", "y2", "-", "y1", ")", "*", "x0", "-", "(", "x2", "-", "x1", ")", "*", "y0", "+", "x2", "*", "y1", "-", "y2", "*", "x1", ")", "\n", "denom", "=", "torch", ".", "sqrt", "(", "(", "y2", "-", "y1", ")", "**", "2", "+", "(", "x2", "-", "x1", ")", "**", "2", ")", "\n", "\n", "return", "nom", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_abcd": [[67, 77], ["len", "corners[].repeat", "corners[].repeat.view().unbind", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "dafne_outputs.dist_point_to_line", "corners[].repeat.view"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.dist_point_to_line"], ["", "def", "compute_abcd", "(", "corners", ",", "xs_ext", ",", "ys_ext", ")", ":", "\n", "    ", "num_locs", "=", "len", "(", "xs_ext", ")", "\n", "num_targets", "=", "corners", ".", "shape", "[", "0", "]", "\n", "corners_rep", "=", "corners", "[", "None", "]", ".", "repeat", "(", "num_locs", ",", "1", ",", "1", ")", "\n", "c0", ",", "c1", ",", "c2", ",", "c3", "=", "corners_rep", ".", "view", "(", "num_locs", ",", "num_targets", ",", "4", ",", "2", ")", ".", "unbind", "(", "2", ")", "\n", "\n", "left", "=", "torch", ".", "stack", "(", "(", "c0", ",", "c1", ",", "c2", ",", "c3", ")", ",", "dim", "=", "-", "1", ")", "\n", "right", "=", "torch", ".", "stack", "(", "(", "c1", ",", "c2", ",", "c3", ",", "c0", ")", ",", "dim", "=", "-", "1", ")", "\n", "abcd", "=", "dist_point_to_line", "(", "left", ",", "right", ",", "xs_ext", "[", "...", ",", "None", "]", ",", "ys_ext", "[", "...", ",", "None", "]", ")", "\n", "return", "abcd", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.compute_ctrness_targets": [[79, 94], ["len", "reg_targets.new_zeros", "len", "torch.isnan", "torch.isnan", "left_right.min", "left_right.max", "top_bottom.min", "top_bottom.max"], "function", ["None"], ["", "def", "compute_ctrness_targets", "(", "reg_targets", ",", "alpha", ")", ":", "\n", "    ", "if", "len", "(", "reg_targets", ")", "==", "0", ":", "\n", "        ", "return", "reg_targets", ".", "new_zeros", "(", "len", "(", "reg_targets", ")", ")", "\n", "", "left_right", "=", "reg_targets", "[", ":", ",", "[", "0", ",", "2", "]", "]", "\n", "top_bottom", "=", "reg_targets", "[", ":", ",", "[", "1", ",", "3", "]", "]", "\n", "ctrness", "=", "(", "left_right", ".", "min", "(", "dim", "=", "-", "1", ")", "[", "0", "]", "/", "left_right", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ")", "*", "(", "\n", "top_bottom", ".", "min", "(", "dim", "=", "-", "1", ")", "[", "0", "]", "/", "top_bottom", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", "\n", ")", "\n", "\n", "ctrness", "=", "ctrness", "**", "(", "1", "/", "alpha", ")", "\n", "\n", "# Set critical cases where the ctrness computation was not possible to zero", "\n", "ctrness", "[", "torch", ".", "isnan", "(", "ctrness", ")", "]", "=", "0.0", "\n", "\n", "return", "ctrness", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs._cross2d": [[96, 99], ["None"], "function", ["None"], ["", "def", "_cross2d", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"Cross product in 2D.\"\"\"", "\n", "return", "x", "[", ":", ",", ":", ",", "0", "]", "*", "y", "[", ":", ",", ":", ",", "1", "]", "-", "x", "[", ":", ",", ":", ",", "1", "]", "*", "y", "[", ":", ",", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.area_triangle": [[101, 107], ["torch.abs", "torch.abs", "dafne_outputs._cross2d"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._cross2d"], ["", "def", "area_triangle", "(", "a", ",", "b", ",", "c", ")", ":", "\n", "    ", "\"\"\"Area of a triangle\"\"\"", "\n", "x", "=", "a", "-", "c", "\n", "y", "=", "b", "-", "c", "\n", "crs", "=", "1", "/", "2", "*", "torch", ".", "abs", "(", "_cross2d", "(", "x", ",", "y", ")", ")", "\n", "return", "crs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.is_in_quadrilateral": [[109, 120], ["dafne_outputs.area_triangle", "dafne_outputs.area_triangle", "dafne_outputs.area_triangle", "dafne_outputs.area_triangle"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.area_triangle", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.area_triangle", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.area_triangle", "home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.area_triangle"], ["", "def", "is_in_quadrilateral", "(", "c0", ",", "c1", ",", "c2", ",", "c3", ",", "poly_area", ",", "loc", ")", ":", "\n", "    ", "\"\"\"Check if loc is in the given quadrilateral.\n    Assumes, that the quadrilateral is sorted.\"\"\"", "\n", "# Compute area between edges and loc", "\n", "a", "=", "area_triangle", "(", "c0", ",", "c1", ",", "loc", ")", "\n", "b", "=", "area_triangle", "(", "c1", ",", "c2", ",", "loc", ")", "\n", "c", "=", "area_triangle", "(", "c2", ",", "c3", ",", "loc", ")", "\n", "d", "=", "area_triangle", "(", "c3", ",", "c0", ",", "loc", ")", "\n", "sum_area_to_loc", "=", "a", "+", "b", "+", "c", "+", "d", "\n", "\n", "return", "~", "(", "sum_area_to_loc", ">", "(", "poly_area", "+", "1e-3", ")", ")", "# 1e-3 is some epsilon to avoid equality", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.__init__": [[13, 60], ["experiment_name.replace", "collections.deque", "rtpt.RTPT._update_title"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._update_title"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "name_initials", ":", "str", ",", "\n", "experiment_name", ":", "str", ",", "\n", "max_iterations", ":", "int", ",", "\n", "iteration_start", "=", "0", ",", "\n", "moving_avg_window_size", "=", "20", ",", "\n", "update_interval", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the Remaining-Time-To-Process (RTPT) object.\n\n        Args:\n            name_initials (str): Name initials (e.g. \"QD\" for \"Quentin Delfosse\").\n            experiment_name (str): A unique name to identify the running experiment.\n                Spaces will be replaced with underscores.\n            max_iterations (int): The maximum number of iterations.\n            iteration_start (int): The iteration at which to start (optional, default: 0).\n            moving_avg_window_size (int): The window size for the moving average for the ETA approximation (optional, default: 20).\n            update_interval (int): After how many iterations the title should be updated (optional, default: 1).\n        \"\"\"", "\n", "# Some assertions upfront", "\n", "assert", "(", "\n", "max_iterations", ">", "0", "\n", ")", ",", "f\"Maximum number of iterations has to be greater than 0 but was {max_iterations}\"", "\n", "assert", "(", "\n", "iteration_start", ">=", "0", "\n", ")", ",", "f\"Starting iteration count must be equal or greater than 0 but was {iteration_start}\"", "\n", "\n", "# Store args", "\n", "self", ".", "name_initials", "=", "name_initials", "\n", "self", ".", "experiment_name", "=", "experiment_name", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "self", ".", "_current_iteration", "=", "iteration_start", "\n", "self", ".", "max_iterations", "=", "max_iterations", "\n", "self", ".", "update_interval", "=", "update_interval", "\n", "\n", "# Store time for each iterations in a deque", "\n", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "moving_avg_window_size", ")", "\n", "\n", "# Track end of iterations", "\n", "self", ".", "_last_iteration_time_end", "=", "None", "\n", "\n", "# Variable title part", "\n", "self", ".", "_variable_part", "=", "None", "\n", "\n", "# Perform an initial title update", "\n", "self", ".", "_update_title", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.start": [[62, 65], ["time.time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Start the internal iteration timer.\"\"\"", "\n", "self", ".", "_last_iteration_time_start", "=", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT.step": [[66, 88], ["time.time.time", "rtpt.RTPT.deque.append", "rtpt.RTPT._update_title"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._update_title"], ["", "def", "step", "(", "self", ",", "subtitle", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Perform an update step:\n        - Measure new time for the last epoch\n        - Update deque\n        - Compute new ETA from deque\n        - Set new process title with the latest ETA\n\n        Args:\n            subtitle (str): Variable part of the title that can be updated in each step (optional, default: None). If None, it doesn't appear at all.\n        \"\"\"", "\n", "# Update subtitle", "\n", "self", ".", "_variable_part", "=", "subtitle", "\n", "\n", "# Add the time delta of the current iteration to the deque", "\n", "time_end", "=", "time", "(", ")", "\n", "time_delta", "=", "time_end", "-", "self", ".", "_last_iteration_time_start", "\n", "self", ".", "deque", ".", "append", "(", "time_delta", ")", "\n", "\n", "self", ".", "_update_title", "(", ")", "\n", "self", ".", "_current_iteration", "+=", "1", "\n", "self", ".", "_last_iteration_time_start", "=", "time_end", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._moving_average_seconds_per_iteration": [[89, 95], ["len", "sum", "len", "list"], "methods", ["None"], ["", "def", "_moving_average_seconds_per_iteration", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compute moving average of seconds per iteration.\"\"\"", "\n", "if", "len", "(", "self", ".", "deque", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "else", ":", "\n", "            ", "return", "sum", "(", "list", "(", "self", ".", "deque", ")", ")", "/", "len", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._get_eta_str": [[96, 119], ["rtpt.RTPT._moving_average_seconds_per_iteration", "round", "round", "round", "round"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._moving_average_seconds_per_iteration"], ["", "", "def", "_get_eta_str", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the eta string in the format 'Dd:H:M:S'.\"\"\"", "\n", "# TODO: This is currently expected and hardcoded in IRON for the first iteration", "\n", "if", "self", ".", "_current_iteration", "==", "0", ":", "\n", "            ", "return", "\"first_epoch\"", "\n", "\n", "# Get mean seconds per iteration", "\n", "", "avg", "=", "self", ".", "_moving_average_seconds_per_iteration", "(", ")", "\n", "\n", "# Compute the ETA based on the remaining number of iterations", "\n", "remaining_iterations", "=", "self", ".", "max_iterations", "-", "self", ".", "_current_iteration", "\n", "c", "=", "remaining_iterations", "*", "avg", "\n", "\n", "# Compute days/hours/minutes/seconds", "\n", "days", "=", "round", "(", "c", "//", "86400", ")", "\n", "hours", "=", "round", "(", "c", "//", "3600", "%", "24", ")", "\n", "minutes", "=", "round", "(", "c", "//", "60", "%", "60", ")", "\n", "seconds", "=", "round", "(", "c", "%", "60", ")", "\n", "\n", "# Format", "\n", "eta_str", "=", "f\"{days}d:{hours:>02d}h:{minutes:>02d}m:{seconds:>02d}s\"", "\n", "\n", "return", "eta_str", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._get_title": [[120, 133], ["rtpt.RTPT._get_eta_str"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._get_eta_str"], ["", "def", "_get_title", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the full process title. Includes name initials, base name and ETA.\"\"\"", "\n", "# Obtain the ETA", "\n", "eta_str", "=", "self", ".", "_get_eta_str", "(", ")", "\n", "\n", "# Construct the title", "\n", "if", "self", ".", "_variable_part", "is", "None", ":", "\n", "            ", "title", "=", "f\"@{self.name_initials}_{self.experiment_name}#{eta_str}\"", "\n", "", "else", ":", "\n", "            ", "title", "=", "f\"@{self.name_initials}_{self.experiment_name}_{self._variable_part}#{eta_str}\"", "\n", "\n", "\n", "", "return", "title", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._update_title": [[134, 140], ["rtpt.RTPT._get_title", "setproctitle.setproctitle.setproctitle"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.rtpt.RTPT._get_title"], ["", "def", "_update_title", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update the process title.\"\"\"", "\n", "title", "=", "self", ".", "_get_title", "(", ")", "\n", "\n", "if", "self", ".", "_current_iteration", "%", "self", ".", "update_interval", "==", "0", ":", "\n", "            ", "setproctitle", "(", "title", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.dafne_breakpoint": [[24, 27], ["dafne_core.utils.comm.is_main_process", "pdb.set_trace"], "function", ["None"], ["def", "dafne_breakpoint", "(", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "pdb", ".", "set_trace", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.time_delta_now": [[29, 48], ["time.time", "round", "round", "round", "round", "round"], "function", ["None"], ["", "", "def", "time_delta_now", "(", "t_start", ":", "float", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Convert the difference of the given timestamp and now into a human readable timestring.\n    Args:\n        t_start (float): Start timestamp.\n\n    Returns:\n        Human readable timestring of time passed between `t_start` and now.\n    \"\"\"", "\n", "a", "=", "t_start", "\n", "b", "=", "time", ".", "time", "(", ")", "# current epoch time", "\n", "c", "=", "b", "-", "a", "# seconds", "\n", "days", "=", "round", "(", "c", "//", "86400", ")", "\n", "hours", "=", "round", "(", "c", "//", "3600", "%", "24", ")", "\n", "minutes", "=", "round", "(", "c", "//", "60", "%", "60", ")", "\n", "seconds", "=", "round", "(", "c", "%", "60", ")", "\n", "millisecs", "=", "round", "(", "c", "%", "1", "*", "1000", ")", "\n", "return", "\"{} days, {} hours, {} minutes, {} seconds, {} milliseconds\"", ".", "format", "(", "\n", "days", ",", "hours", ",", "minutes", ",", "seconds", ",", "millisecs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.ensure_dir": [[51, 63], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "ensure_dir", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Ensure that a directory exists.\n\n    For 'foo/bar/baz.csv' the directories 'foo' and 'bar' will be created if not already present.\n\n    Args:\n        path (str): Directory path.\n    \"\"\"", "\n", "d", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.count_params": [[65, 76], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "", "def", "count_params", "(", "model", ":", "torch", ".", "nn", ".", "Module", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Count the number of parameters in a model.\n\n    Args:\n        model (torch.nn.Module): PyTorch model.\n\n    Returns:\n        int: Number of learnable parameters.\n    \"\"\"", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.generate_run_base_dir": [[78, 113], ["datetime.datetime.fromtimestamp", "datetime.datetime.fromtimestamp.strftime", "experiment.ensure_dir", "time.time", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.ensure_dir"], ["", "def", "generate_run_base_dir", "(", "\n", "result_dir", ":", "str", ",", "timestamp", ":", "int", "=", "None", ",", "tag", ":", "str", "=", "None", ",", "sub_dirs", ":", "List", "[", "str", "]", "=", "None", "\n", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Generate a base directory for each experiment run.\n    Looks like this: result_dir/date_tag/sub_dir_1/.../sub_dir_n\n    Args:\n        result_dir (str): Experiment output directory.\n        timestamp (int): Timestamp which will be inlcuded in the form of '%y%m%d_%H%M'.\n        tag (str): Tag after timestamp.\n        sub_dirs (List[str]): List of subdirectories that should be created.\n\n    Returns:\n        str: Directory name.\n    \"\"\"", "\n", "if", "timestamp", "is", "None", ":", "\n", "        ", "timestamp", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "sub_dirs", "is", "None", ":", "\n", "        ", "sub_dirs", "=", "[", "]", "\n", "\n", "# Convert time", "\n", "", "date", "=", "datetime", ".", "datetime", ".", "fromtimestamp", "(", "timestamp", ")", "\n", "date_str", "=", "date", ".", "strftime", "(", "\"%y-%m-%d_%H:%M\"", ")", "\n", "\n", "# Append tag if given", "\n", "if", "tag", "is", "None", ":", "\n", "        ", "base_dir", "=", "date_str", "\n", "", "else", ":", "\n", "        ", "base_dir", "=", "date_str", "+", "\"_\"", "+", "tag", "\n", "\n", "# Create directory", "\n", "", "base_dir", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "base_dir", ",", "*", "sub_dirs", ")", "+", "\"/\"", "\n", "ensure_dir", "(", "base_dir", ")", "\n", "return", "base_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.setup_logging": [[115, 136], ["experiment.ensure_dir", "os.path.exists", "logging.basicConfig", "os.path.dirname", "os.remove", "logging.getLevelName", "level.upper", "logging.StreamHandler", "logging.FileHandler"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.ensure_dir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.remove"], ["", "def", "setup_logging", "(", "log_file_path", ":", "str", "=", "\"log.txt\"", ",", "level", ":", "str", "=", "\"INFO\"", ")", ":", "\n", "    ", "\"\"\"\n    Setup global loggers. Logs to stdout and the given log file.\n\n    Args:\n        log_file_path (str): Log file destination.\n        level (str): Log level.\n    \"\"\"", "\n", "# Make sure the directory actually exists", "\n", "ensure_dir", "(", "os", ".", "path", ".", "dirname", "(", "log_file_path", ")", ")", "\n", "\n", "# Check if previous log exists since logging.FileHandler only appends", "\n", "if", "os", ".", "path", ".", "exists", "(", "log_file_path", ")", ":", "\n", "        ", "os", ".", "remove", "(", "log_file_path", ")", "\n", "\n", "", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "getLevelName", "(", "level", ".", "upper", "(", ")", ")", ",", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(message)s\"", ",", "\n", "handlers", "=", "[", "\n", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", ",", "\n", "logging", ".", "FileHandler", "(", "filename", "=", "log_file_path", ")", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.set_seed": [[140, 150], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Set the seed globally for python, numpy and torch.\n\n    Args:\n        seed (int): Seed.\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.set_cuda_device": [[152, 176], ["logger.warning", "str"], "function", ["None"], ["", "def", "set_cuda_device", "(", "cuda_device_id", ":", "List", "[", "int", "]", ")", ":", "\n", "    ", "\"\"\"\n    Set the `CUDA_VISIBLE_DEVICES` environment variable to the list of device ids.\n\n    Reminder: torch's cuda device index will index the given list. That is,\n    if `cuda_device_id` == [3, 4, 5], then torch.device('cuda:0') will point to\n    the physical GPU #3.\n\n    Warning is logged if `CUDA_VISIBLE_DEVICES` has already been set in the environment.\n\n    Args:\n        cuda_device_id (List[int]): List of physical cuda device ids.\n\n    \"\"\"", "\n", "key", "=", "\"CUDA_VISIBLE_DEVICES\"", "\n", "new_val", "=", "\",\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "cuda_device_id", "]", ")", "\n", "if", "key", "in", "os", ".", "environ", ":", "\n", "        ", "val", "=", "os", ".", "environ", "[", "key", "]", "\n", "logger", ".", "warning", "(", "\n", "'Environment variable \"{}\" exists with value \"{}\". Overwriting with \"{}\".'", ".", "format", "(", "\n", "key", ",", "val", ",", "new_val", "\n", ")", "\n", ")", "\n", "", "os", ".", "environ", "[", "key", "]", "=", "new_val", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.make_multi_gpu": [[178, 214], ["logger.info", "logger.info", "torch.cuda.device_count", "len", "list", "list", "logger.info", "torch.nn.DataParallel", "logger.info", "range", "range", "len"], "function", ["None"], ["", "def", "make_multi_gpu", "(", "model", ":", "torch", ".", "nn", ".", "Module", ",", "cuda_device_id", ":", "List", ")", ":", "\n", "    ", "\"\"\"\n    Distribute a given model across the cuda device list.\n\n    If cuda_device_id == [-1], all available cuda devices will be selected.\n\n    Args:\n        model (torch.nn.Module): Model which is to be distributed across the cuda devices.\n        cuda_device_id (List): List of physical cuda device ids.\n    \"\"\"", "\n", "multi_gpu", "=", "len", "(", "cuda_device_id", ")", ">", "1", "or", "cuda_device_id", "[", "0", "]", "==", "-", "1", "\n", "\n", "# Check if multiple cuda devices are selected", "\n", "if", "multi_gpu", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using multiple gpus\"", ")", "\n", "logger", ".", "info", "(", "\"cuda_device_id=%s\"", "%", "cuda_device_id", ")", "\n", "num_cuda_devices", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "if", "cuda_device_id", "[", "0", "]", "==", "-", "1", ":", "\n", "# Select all devices", "\n", "            ", "cuda_device_id_vis", "=", "list", "(", "range", "(", "num_cuda_devices", ")", ")", "\n", "", "else", ":", "\n", "# Select all visible devices", "\n", "            ", "cuda_device_id_vis", "=", "list", "(", "range", "(", "len", "(", "cuda_device_id", ")", ")", ")", "\n", "\n", "# Check if multiple cuda devices are available", "\n", "", "if", "num_cuda_devices", ">", "1", ":", "\n", "            ", "logger", ".", "info", "(", "\"Running experiment on the following GPUs: %s\"", "%", "cuda_device_id", ")", "\n", "\n", "# Transform model into data parallel model on all selected cuda deviecs", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "cuda_device_id_vis", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Attempted to run the experiment on multiple GPUs while only a single GPU was available\"", "\n", ")", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.load_args": [[216, 233], ["argparse.ArgumentParser", "argparse.ArgumentParser.parse_args", "open", "json.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args"], ["", "def", "load_args", "(", "base_dir", ":", "str", ",", "filename", "=", "\"args.txt\"", ")", "->", "argparse", ".", "Namespace", ":", "\n", "    ", "\"\"\"\n    Load the commandline arguments.\n\n    Args:\n        base_dir (str): Directory in which the arguments are stored.\n        filename (str): Filename of the stored arguments. Defaults to \"args.txt\".\n\n    Returns:\n        argparse.Namespace: Argparse namespace object that is constructed from the loaded arguments.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "filename", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "args", ".", "__dict__", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.save_args": [[235, 246], ["open", "json.dump", "os.path.join"], "function", ["None"], ["", "def", "save_args", "(", "args", ":", "argparse", ".", "Namespace", ",", "base_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Save the commandline arguments.\n\n    Args:\n        args (argparse.Namespace): Commandline arguments.\n        base_dir (str): Directory to store the arguments into.\n\n    \"\"\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "\"args.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "args", ".", "__dict__", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.clone_args": [[248, 262], ["argparse.ArgumentParser", "argparse.ArgumentParser.parse_args", "args.__dict__.copy"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy"], ["", "", "def", "clone_args", "(", "args", ":", "argparse", ".", "Namespace", ")", "->", "argparse", ".", "Namespace", ":", "\n", "    ", "\"\"\"\n    Clone the given namespace object.\n\n    Args:\n        args (argparse.Namespace): Namespace object which is to be cloned.\n\n    Returns:\n        argparse.Namespace: Cloned input namespace object.\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "tmp_args", "=", "parser", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "tmp_args", ".", "__dict__", "=", "args", ".", "__dict__", ".", "copy", "(", ")", "\n", "return", "tmp_args", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.experiment.plot_samples": [[264, 285], ["torchvision.utils.make_grid", "plt.figure", "plt.imshow", "plt.title", "plt.show", "torchvision.utils.make_grid.permute", "x.min", "x.max", "x.min", "y.squeeze().numpy", "y.squeeze"], "function", ["None"], ["", "def", "plot_samples", "(", "x", ":", "torch", ".", "Tensor", ",", "y", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Plot a single sample witht the target and prediction in the title.\n\n    Args:\n        x (torch.Tensor): Batch of input images. Has to be shape: [N, C, H, W].\n        y (torch.Tensor): Target.\n        y_pred: Target prediction.\n        loss: Loss value.\n    \"\"\"", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "# Normalize in valid range", "\n", "x", "=", "(", "x", "-", "x", ".", "min", "(", ")", ")", "/", "(", "x", ".", "max", "(", ")", "-", "x", ".", "min", "(", ")", ")", "\n", "tensors", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "x", ",", "nrow", "=", "8", ",", "padding", "=", "1", ")", "\n", "\n", "# Permute channels and h/w for matplotlib", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "tensors", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "plt", ".", "title", "(", "\"y={}\"", ".", "format", "(", "y", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._cross2d": [[5, 8], ["None"], "function", ["None"], ["def", "_cross2d", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Cross product in 2D.\"\"\"", "\n", "return", "a", "[", ":", ",", "0", "]", "*", "b", "[", ":", ",", "1", "]", "-", "a", "[", ":", ",", "1", "]", "*", "b", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._remove": [[10, 24], ["torch.ones", "T.view", "range"], "function", ["None"], ["", "def", "_remove", "(", "T", ",", "idx_remove", ")", ":", "\n", "    ", "\"\"\"Remove an element from the list of points for each batch element.\"\"\"", "\n", "num_boxes", "=", "T", ".", "shape", "[", "0", "]", "\n", "num_points_left", "=", "T", ".", "shape", "[", "1", "]", "\n", "\n", "# Define which elements to keep", "\n", "keep", "=", "torch", ".", "ones", "(", "num_boxes", ",", "num_points_left", ",", "dtype", "=", "bool", ",", "device", "=", "T", ".", "device", ")", "\n", "keep", "[", "range", "(", "num_boxes", ")", ",", "idx_remove", "]", "=", "False", "\n", "\n", "# Apply mask", "\n", "T", "=", "T", "[", "keep", "]", "\n", "\n", "# Put back in correct shape", "\n", "return", "T", ".", "view", "(", "num_boxes", ",", "num_points_left", "-", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort_quadrilateral": [[26, 93], ["bboxes.view", "bboxes.new_zeros", "bboxes.new_zeros", "bboxes.new_zeros", "sort_corners._remove", "bboxes.new_zeros", "bboxes.new_zeros", "range", "bboxes.new_zeros", "range", "torch.stack().view", "bboxes.dim", "S[].min", "sort_corners._remove", "sort_corners._cross2d", "sort_corners._cross2d", "torch.stack", "torch.all", "sort_corners._remove", "sort_corners._cross2d", "torch.stack", "range"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._remove", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._remove", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._cross2d", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._cross2d", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._remove", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners._cross2d"], ["", "def", "sort_quadrilateral", "(", "bboxes", ")", ":", "\n", "    ", "\"\"\"Algorithm according to Alg. 1 in 'Learning Modulated Loss for Rotated Object Detection'.\n\n    Sequence ordering of quadrilateral corners\n    \"\"\"", "\n", "assert", "bboxes", ".", "dim", "(", ")", "==", "2", "\n", "num_boxes", "=", "bboxes", ".", "shape", "[", "0", "]", "\n", "\n", "# If no boxes are present, return", "\n", "if", "num_boxes", "==", "0", ":", "\n", "        ", "return", "bboxes", "\n", "\n", "", "device", "=", "bboxes", ".", "device", "\n", "S", "=", "bboxes", ".", "view", "(", "num_boxes", ",", "4", ",", "2", ")", "\n", "\n", "p2_", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "2", ")", "\n", "p3_", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "2", ")", "\n", "p4_", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "2", ")", "\n", "\n", "# Find leftmost vertext", "\n", "leftmost_idx", "=", "S", "[", ":", ",", ":", ",", "0", "]", ".", "min", "(", "dim", "=", "1", ")", ".", "indices", "# TODO what if two have the same xmin", "\n", "p1_", "=", "S", "[", "range", "(", "num_boxes", ")", ",", "leftmost_idx", "]", "\n", "\n", "# Remove leftmost from set", "\n", "S", "=", "_remove", "(", "S", ",", "leftmost_idx", ")", "\n", "# S: [3, 2]", "\n", "\n", "# Track which batch elements have already been set", "\n", "done", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "dtype", "=", "bool", ")", "\n", "S_new", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "2", ",", "2", ")", "\n", "for", "i", "in", "range", "(", "S", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "s1", "=", "S", "[", ":", ",", "i", "]", "\n", "S_", "=", "_remove", "(", "S", ",", "i", ")", "\n", "# S_: [2, 2]", "\n", "s2", ",", "s3", "=", "S_", "[", ":", ",", "0", "]", ",", "S_", "[", ":", ",", "1", "]", "\n", "\n", "l", "=", "_cross2d", "(", "s1", "-", "p1_", ",", "s2", "-", "p1_", ")", "\n", "r", "=", "_cross2d", "(", "s1", "-", "p1_", ",", "s3", "-", "p1_", ")", "\n", "\n", "cond", "=", "(", "l", "*", "r", ")", "<", "0.0", "\n", "cond", "=", "cond", "&", "~", "done", "\n", "p3_", "[", "cond", "]", "=", "s1", "[", "cond", "]", "\n", "S_new", "[", "cond", "]", "=", "torch", ".", "stack", "(", "(", "s2", "[", "cond", "]", ",", "s3", "[", "cond", "]", ")", ",", "dim", "=", "1", ")", "\n", "done", "=", "done", "|", "cond", "\n", "\n", "# Stop early if all are already done", "\n", "if", "torch", ".", "all", "(", "done", ")", ":", "\n", "            ", "break", "\n", "\n", "", "", "S", "=", "S_new", "\n", "\n", "done", "=", "bboxes", ".", "new_zeros", "(", "num_boxes", ",", "dtype", "=", "bool", ")", "\n", "for", "i", "in", "range", "(", "S", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "s1", "=", "S", "[", ":", ",", "i", "]", "\n", "S_", "=", "_remove", "(", "S", ",", "i", ")", "\n", "s2", "=", "S_", "[", ":", ",", "0", "]", "\n", "\n", "cond", "=", "_cross2d", "(", "p3_", "-", "p1_", ",", "s1", "-", "p1_", ")", ">", "0.0", "\n", "cond", "=", "cond", "&", "~", "done", "\n", "p2_", "[", "cond", "]", "=", "s1", "[", "cond", "]", "\n", "p4_", "[", "cond", "]", "=", "s2", "[", "cond", "]", "\n", "p2_", "[", "~", "cond", "]", "=", "s2", "[", "~", "cond", "]", "\n", "p4_", "[", "~", "cond", "]", "=", "s1", "[", "~", "cond", "]", "\n", "done", "=", "done", "|", "cond", "\n", "\n", "", "bbox_sorted", "=", "torch", ".", "stack", "(", "(", "p1_", ",", "p2_", ",", "p3_", ",", "p4_", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "num_boxes", ",", "-", "1", ")", "\n", "return", "bbox_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.cross2d": [[95, 97], ["None"], "function", ["None"], ["", "def", "cross2d", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "a", "[", "0", "]", "*", "b", "[", "1", "]", "-", "a", "[", "1", "]", "*", "b", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.remove": [[99, 103], ["None"], "function", ["None"], ["", "def", "remove", "(", "T", ",", "i", ")", ":", "\n", "    ", "mask", "=", "[", "True", "]", "*", "T", ".", "shape", "[", "0", "]", "\n", "mask", "[", "i", "]", "=", "False", "\n", "return", "T", "[", "mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort": [[105, 154], ["range", "torch.stack", "bboxes[].view", "torch.zeros", "sort_corners.remove", "enumerate", "enumerate", "torch.stack().view", "torch.stack.append", "S[].min", "sort_corners.remove", "sort_corners.cross2d", "sort_corners.cross2d", "sort_corners.remove", "torch.stack", "sort_corners.cross2d", "torch.stack"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.remove", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.remove", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.cross2d", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.cross2d", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.remove", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.cross2d"], ["", "def", "sort", "(", "bboxes", ")", ":", "\n", "    ", "\"\"\"Algorithm according to Alg. 1 in 'Learning Modulated Loss for Rotated Object Detection'.\n\n    Sequence ordering of quadrilateral corners\n    \"\"\"", "\n", "num_boxes", "=", "bboxes", ".", "shape", "[", "0", "]", "\n", "bboxes_sorted", "=", "[", "]", "\n", "device", "=", "bboxes", ".", "device", "\n", "for", "box_idx", "in", "range", "(", "num_boxes", ")", ":", "\n", "        ", "S", "=", "bboxes", "[", "box_idx", "]", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "\n", "p2_", "=", "p3_", "=", "p4_", "=", "torch", ".", "zeros", "(", "2", ",", "device", "=", "device", ")", "\n", "\n", "# Find leftmost vertext", "\n", "leftmost_idx", "=", "S", "[", ":", ",", "0", "]", ".", "min", "(", "dim", "=", "0", ")", ".", "indices", "# TODO what if two have the same xmin", "\n", "p1_", "=", "S", "[", "leftmost_idx", "]", "\n", "\n", "# Remove leftmost from set", "\n", "S", "=", "remove", "(", "S", ",", "leftmost_idx", ")", "\n", "# S: [3, 2]", "\n", "\n", "for", "j", ",", "s1", "in", "enumerate", "(", "S", ")", ":", "\n", "            ", "S_", "=", "remove", "(", "S", ",", "j", ")", "\n", "# S_: [2, 2]", "\n", "s2", ",", "s3", "=", "S_", "[", "0", "]", ",", "S_", "[", "1", "]", "\n", "\n", "l", "=", "cross2d", "(", "s1", "-", "p1_", ",", "s2", "-", "p1_", ")", "\n", "r", "=", "cross2d", "(", "s1", "-", "p1_", ",", "s3", "-", "p1_", ")", "\n", "if", "l", "*", "r", "<", "0.0", ":", "\n", "                ", "p3_", "=", "s1", "\n", "S", "=", "torch", ".", "stack", "(", "(", "s2", ",", "s3", ")", ",", "dim", "=", "0", ")", "\n", "break", "\n", "\n", "", "", "for", "j", ",", "s1", "in", "enumerate", "(", "S", ")", ":", "\n", "            ", "S_", "=", "remove", "(", "S", ",", "j", ")", "\n", "s2", "=", "S_", "[", "0", "]", "\n", "\n", "if", "cross2d", "(", "p3_", "-", "p1_", ",", "s1", "-", "p1_", ")", ">", "0.0", ":", "\n", "                ", "p2_", "=", "s1", "\n", "p4_", "=", "s2", "\n", "", "else", ":", "\n", "                ", "p2_", "=", "s2", "\n", "p4_", "=", "s1", "\n", "\n", "", "", "bbox_sorted", "=", "torch", ".", "stack", "(", "(", "p1_", ",", "p2_", ",", "p3_", ",", "p4_", ")", ",", "dim", "=", "0", ")", ".", "view", "(", "-", "1", ")", "\n", "bboxes_sorted", ".", "append", "(", "bbox_sorted", ")", "\n", "\n", "", "bboxes_sorted", "=", "torch", ".", "stack", "(", "(", "bboxes_sorted", ")", ",", "dim", "=", "0", ")", "\n", "return", "bboxes_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.notify_mail": [[14, 56], ["email.mime.multipart.MIMEMultipart", "email.mime.multipart.MIMEMultipart.attach", "smtplib.SMTP", "smtplib.SMTP.starttls", "smtplib.SMTP.login", "email.mime.multipart.MIMEMultipart.as_string", "smtplib.SMTP.sendmail", "smtplib.SMTP.quit", "open", "f.readlines", "email.mime.text.MIMEText", "open", "email.mime.base.MIMEBase", "email.mime.base.MIMEBase.set_payload", "email.encoders.encode_base64", "email.mime.base.MIMEBase.add_header", "email.mime.multipart.MIMEMultipart.attach", "open.read", "lines[].split", "lines[].split", "lines[].split"], "function", ["None"], ["def", "notify_mail", "(", "credentials_path", ",", "subject", ",", "message", ",", "filename", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Sends an E-Mail to the a specified address with a chosen message and subject\n     Args:\n        cred_path (string): path to the credentials\n        subject (string): subject of the e-mail\n        message (string): message of the e-mail\n        filename (string): path to the file that is going to be send via mail\n    Returns:\n        None\n    \"\"\"", "\n", "with", "open", "(", "credentials_path", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "email", "=", "lines", "[", "0", "]", ".", "split", "(", "\"=\"", ")", "[", "1", "]", "[", ":", "-", "1", "]", "\n", "password", "=", "lines", "[", "1", "]", ".", "split", "(", "\"=\"", ")", "[", "1", "]", "[", ":", "-", "1", "]", "\n", "receiver", "=", "lines", "[", "2", "]", ".", "split", "(", "\"=\"", ")", "[", "1", "]", "[", ":", "-", "1", "]", "\n", "\n", "", "msg", "=", "MIMEMultipart", "(", ")", "\n", "\n", "msg", "[", "\"From\"", "]", "=", "email", "\n", "msg", "[", "\"To\"", "]", "=", "receiver", "\n", "msg", "[", "\"Subject\"", "]", "=", "subject", "\n", "\n", "body", "=", "f\"<body>{message}</body>\"", "\n", "msg", ".", "attach", "(", "MIMEText", "(", "body", ",", "\"html\"", ")", ")", "\n", "\n", "if", "filename", "is", "not", "None", ":", "\n", "        ", "attachment", "=", "open", "(", "filename", ",", "\"rb\"", ")", "\n", "\n", "part", "=", "MIMEBase", "(", "\"application\"", ",", "\"octet-stream\"", ")", "\n", "part", ".", "set_payload", "(", "(", "attachment", ")", ".", "read", "(", ")", ")", "\n", "encoders", ".", "encode_base64", "(", "part", ")", "\n", "part", ".", "add_header", "(", "\"Content-Disposition\"", ",", "\"attachment; filename= %s\"", "%", "filename", ")", "\n", "\n", "msg", ".", "attach", "(", "part", ")", "\n", "\n", "", "server", "=", "smtplib", ".", "SMTP", "(", "\"smtp.gmail.com\"", ",", "587", ")", "\n", "server", ".", "starttls", "(", ")", "\n", "server", ".", "login", "(", "email", ",", "password", ")", "\n", "text", "=", "msg", ".", "as_string", "(", ")", "\n", "server", ".", "sendmail", "(", "email", ",", "receiver", ",", "text", ")", "\n", "server", ".", "quit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.send_mail_error": [[58, 71], ["mail.notify_mail", "detectron2.utils.comm.is_main_process", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.notify_mail"], ["", "def", "send_mail_error", "(", "cfg", ",", "args", ",", "errormsg", ")", ":", "\n", "    ", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "return", "\n", "", "subject", "=", "f\"[DAFNE -- {cfg.OUTPUT_DIR}] Experiment Error!\"", "\n", "message", "=", "(", "\n", "f\"The experiment in {cfg.OUTPUT_DIR} has failed. An error occurred \"", "\n", "f\"during training:\\n\\n{errormsg}\"", "\n", ")", "\n", "notify_mail", "(", "\n", "credentials_path", "=", "cfg", ".", "EMAIL", ".", "CREDENTIALS_PATH", ",", "\n", "subject", "=", "subject", ",", "\n", "message", "=", "message", ",", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"log.txt\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.send_mail_success": [[74, 113], ["results.copy.copy", "results.copy.items", "mail.notify_mail", "detectron2.utils.comm.is_main_process", "dataset_result.copy.copy", "dataset_result[].pop", "table.append", "list", "tabulate.tabulate", "dataset_result[].items", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.mail.notify_mail", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "send_mail_success", "(", "cfg", ",", "results", ")", ":", "\n", "    ", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "return", "\n", "", "exp_name", "=", "cfg", ".", "EXPERIMENT_NAME", "\n", "subject", "=", "f\"[{exp_name}] Experiment Finished!\"", "\n", "message", "=", "f\"Experiment: {exp_name}<br>\"", "\n", "message", "+=", "\"Test Results:<br>\"", "\n", "message", "+=", "\"<br>\"", "\n", "\n", "# Copy to prevent modification of the original", "\n", "results", "=", "results", ".", "copy", "(", ")", "\n", "\n", "for", "dataset_name", ",", "dataset_result", "in", "results", ".", "items", "(", ")", ":", "\n", "# Copy to prevent modification of the original", "\n", "        ", "dataset_result", "=", "dataset_result", ".", "copy", "(", ")", "\n", "message", "+=", "f\"{dataset_name}<br>\"", "\n", "message", "+=", "\"-\"", "*", "(", "26", ")", "+", "\"<br>\"", "\n", "\n", "\n", "# Add mAP to the top", "\n", "table", "=", "[", "]", "\n", "\n", "if", "\"task1\"", "not", "in", "dataset_result", ":", "\n", "            ", "continue", "\n", "\n", "", "mAP", "=", "dataset_result", "[", "\"task1\"", "]", ".", "pop", "(", "\"map\"", ")", "\n", "table", ".", "append", "(", "(", "\"map\"", ",", "mAP", ")", ")", "\n", "table", "+=", "list", "(", "dataset_result", "[", "\"task1\"", "]", ".", "items", "(", ")", ")", "\n", "message", "+=", "tabulate", "(", "\n", "table", ",", "headers", "=", "[", "\"class\"", ",", "\"ap\"", "]", ",", "tablefmt", "=", "\"html\"", ",", "floatfmt", "=", "(", "\"\"", ",", "\"1.3f\"", ")", "\n", ")", "\n", "\n", "message", "+=", "\"<br><br>\"", "\n", "\n", "", "notify_mail", "(", "\n", "subject", "=", "subject", ",", "\n", "message", "=", "message", ",", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"log.txt\"", ")", ",", "\n", "credentials_path", "=", "os", ".", "environ", "[", "\"EMAIL_CREDENTIALS\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename": [[16, 18], ["os.path.basename", "os.path.splitext"], "function", ["None"], ["def", "custombasename", "(", "fullname", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "splitext", "(", "fullname", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir": [[19, 31], ["os.walk", "os.path.join", "allfiles.append", "os.path.splitext", "allfiles.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "GetFileFromThisRootDir", "(", "dir", ",", "ext", "=", "None", ")", ":", "\n", "  ", "allfiles", "=", "[", "]", "\n", "needExtFilter", "=", "(", "ext", "!=", "None", ")", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "dir", ")", ":", "\n", "    ", "for", "filespath", "in", "files", ":", "\n", "      ", "filepath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filespath", ")", "\n", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filepath", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "needExtFilter", "and", "extension", "in", "ext", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "elif", "not", "needExtFilter", ":", "\n", "        ", "allfiles", ".", "append", "(", "filepath", ")", "\n", "", "", "", "return", "allfiles", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly": [[32, 39], ["None"], "function", ["None"], ["", "def", "TuplePoly2Poly", "(", "poly", ")", ":", "\n", "    ", "outpoly", "=", "[", "poly", "[", "0", "]", "[", "0", "]", ",", "poly", "[", "0", "]", "[", "1", "]", ",", "\n", "poly", "[", "1", "]", "[", "0", "]", ",", "poly", "[", "1", "]", "[", "1", "]", ",", "\n", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "2", "]", "[", "1", "]", ",", "\n", "poly", "[", "3", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "1", "]", "\n", "]", "\n", "return", "outpoly", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly": [[40, 97], ["open", "f.readline", "codecs.open", "f.readline.strip().split", "shapely.Polygon", "objects.append", "len", "len", "len", "f.readline.strip", "len", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_dota_poly_refactor", "(", "filename", ",", "code", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n    \"\"\"", "\n", "objects", "=", "[", "]", "\n", "#print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ",", "code", ")", "\n", "f", "=", "fd", "\n", "# count = 0", "\n", "", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "# count = count + 1", "\n", "# if count < 2:", "\n", "#     continue", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n", "### clear the wrong name after check all the data", "\n", "#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "# if (splitlines[9] == 'tr'):", "\n", "#     object_struct['difficult'] = '1'", "\n", "# else:", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n", "#     object_struct['difficult'] = 0", "\n", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "# poly = list(map(lambda x:np.array(x), object_struct['poly']))", "\n", "# object_struct['long-axis'] = max(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# object_struct['short-axis'] = min(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# if (object_struct['long-axis'] < 15):", "\n", "#     object_struct['difficult'] = '1'", "\n", "#     global small_count", "\n", "#     small_count = small_count + 1", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2": [[98, 108], ["dota_utils.parse_dota_poly", "dota_utils.TuplePoly2Poly", "list", "map"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.TuplePoly2Poly"], ["", "def", "parse_dota_poly", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [(x1, y1), (x2, y2), (x3, y3), (x4, y4)]\n    \"\"\"", "\n", "objects", "=", "[", "]", "\n", "# print('filename:', filename)", "\n", "f", "=", "[", "]", "\n", "if", "(", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ")", ":", "\n", "        ", "fd", "=", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_rec": [[109, 120], ["dota_utils.parse_dota_poly", "dota_utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["", "elif", "(", "sys", ".", "version_info", ">=", "2.7", ")", ":", "\n", "        ", "fd", "=", "codecs", ".", "open", "(", "filename", ",", "'r'", ")", "\n", "f", "=", "fd", "\n", "# count = 0", "\n", "", "while", "True", ":", "\n", "        ", "line", "=", "f", ".", "readline", "(", ")", "\n", "# count = count + 1", "\n", "# if count < 2:", "\n", "#     continue", "\n", "if", "line", ":", "\n", "            ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "object_struct", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4": [[122, 128], ["min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max"], "function", ["None"], ["#if (len(splitlines) >= 9) and (splitlines[8] in classname):", "\n", "if", "(", "len", "(", "splitlines", ")", "<", "9", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "len", "(", "splitlines", ")", ">=", "9", ")", ":", "\n", "                    ", "object_struct", "[", "'name'", "]", "=", "splitlines", "[", "8", "]", "\n", "", "if", "(", "len", "(", "splitlines", ")", "==", "9", ")", ":", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec8": [[128, 131], ["dota_utils.dots4ToRec4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots4ToRec4"], ["                ", "object_struct", "[", "'difficult'", "]", "=", "'0'", "\n", "", "elif", "(", "len", "(", "splitlines", ")", ">=", "10", ")", ":", "\n", "# if splitlines[9] == '1':", "\n", "# if (splitlines[9] == 'tr'):", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.dots2ToRec8": [[132, 135], ["None"], "function", ["None"], ["#     object_struct['difficult'] = '1'", "\n", "# else:", "\n", "                ", "object_struct", "[", "'difficult'", "]", "=", "splitlines", "[", "9", "]", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.groundtruth2Task1": [[136, 164], ["dota_utils.GetFileFromThisRootDir", "open", "dota_utils.parse_dota_poly2", "dota_utils.custombasename", "re.compile", "re.findall", "filedict[].write", "os.path.join", "map", "map", "dota_utils.custombasename", "map", "dota_utils.custombasename", "dota_utils.custombasename"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.parse_dota_poly2", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["#     object_struct['difficult'] = 0", "\n", "", "object_struct", "[", "'poly'", "]", "=", "[", "(", "float", "(", "splitlines", "[", "0", "]", ")", ",", "float", "(", "splitlines", "[", "1", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "2", "]", ")", ",", "float", "(", "splitlines", "[", "3", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "4", "]", ")", ",", "float", "(", "splitlines", "[", "5", "]", ")", ")", ",", "\n", "(", "float", "(", "splitlines", "[", "6", "]", ")", ",", "float", "(", "splitlines", "[", "7", "]", ")", ")", "\n", "]", "\n", "gtpoly", "=", "shgeo", ".", "Polygon", "(", "object_struct", "[", "'poly'", "]", ")", "\n", "object_struct", "[", "'area'", "]", "=", "gtpoly", ".", "area", "\n", "# poly = list(map(lambda x:np.array(x), object_struct['poly']))", "\n", "# object_struct['long-axis'] = max(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# object_struct['short-axis'] = min(distance(poly[0], poly[1]), distance(poly[1], poly[2]))", "\n", "# if (object_struct['long-axis'] < 15):", "\n", "#     object_struct['difficult'] = '1'", "\n", "#     global small_count", "\n", "#     small_count = small_count + 1", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "return", "objects", "\n", "\n", "", "def", "parse_dota_poly2", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the format:\n        [x1, y1, x2, y2, x3, y3, x4, y4]\n    \"\"\"", "\n", "objects", "=", "parse_dota_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "obj", "[", "'poly'", "]", "=", "TuplePoly2Poly", "(", "obj", "[", "'poly'", "]", ")", "\n", "obj", "[", "'poly'", "]", "=", "list", "(", "map", "(", "int", ",", "obj", "[", "'poly'", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.Task2groundtruth_poly": [[165, 195], ["dota_utils.GetFileFromThisRootDir", "open", "open.readlines", "custombasename().split", "line.strip().split", "len", "float", "filedict[].write", "dota_utils.custombasename", "line.strip", "codecs.open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename"], ["", "return", "objects", "\n", "\n", "", "def", "parse_dota_rec", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n        parse the dota ground truth in the bounding box format:\n        \"xmin, ymin, xmax, ymax\"\n    \"\"\"", "\n", "objects", "=", "parse_dota_poly", "(", "filename", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "        ", "poly", "=", "obj", "[", "'poly'", "]", "\n", "bbox", "=", "dots4ToRec4", "(", "poly", ")", "\n", "obj", "[", "'bndbox'", "]", "=", "bbox", "\n", "", "return", "objects", "\n", "## bounding box transfer for varies format", "\n", "\n", "", "def", "dots4ToRec4", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "min", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "0", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "0", "]", ",", "poly", "[", "3", "]", "[", "0", "]", ")", ")", ")", ",", "min", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "min", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", ",", "max", "(", "poly", "[", "0", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "1", "]", "[", "1", "]", ",", "max", "(", "poly", "[", "2", "]", "[", "1", "]", ",", "poly", "[", "3", "]", "[", "1", "]", ")", ")", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "\n", "", "def", "dots4ToRec8", "(", "poly", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "dots4ToRec4", "(", "poly", ")", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "#return dots2ToRec8(dots4ToRec4(poly))", "\n", "", "def", "dots2ToRec8", "(", "rec", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "rec", "[", "0", "]", ",", "rec", "[", "1", "]", ",", "rec", "[", "2", "]", ",", "rec", "[", "3", "]", "\n", "return", "xmin", ",", "ymin", ",", "xmax", ",", "ymin", ",", "xmax", ",", "ymax", ",", "xmin", ",", "ymax", "\n", "\n", "", "def", "groundtruth2Task1", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "filelist", "=", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.polygonToRotRectangle": [[197, 227], ["numpy.array", "numpy.reshape", "math.atan2", "range", "numpy.array", "numpy.matmul", "numpy.min", "numpy.max", "numpy.min", "numpy.max", "numpy.array", "np.array.transpose", "float", "float", "math.cos", "math.sin", "math.cos", "math.sin"], "function", ["None"], ["filedict", "=", "{", "}", "\n", "for", "cls", "in", "wordname_15", ":", "\n", "        ", "fd", "=", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "'Task1_'", ")", "+", "cls", "+", "r'.txt'", ",", "'w'", ")", "\n", "filedict", "[", "cls", "]", "=", "fd", "\n", "", "for", "filepath", "in", "filelist", ":", "\n", "        ", "objects", "=", "parse_dota_poly2", "(", "filepath", ")", "\n", "\n", "subname", "=", "custombasename", "(", "filepath", ")", "\n", "pattern2", "=", "re", ".", "compile", "(", "r'__([\\d+\\.]+)__\\d+___'", ")", "\n", "rate", "=", "re", ".", "findall", "(", "pattern2", ",", "subname", ")", "[", "0", "]", "\n", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "category", "=", "obj", "[", "'name'", "]", "\n", "difficult", "=", "obj", "[", "'difficult'", "]", "\n", "poly", "=", "obj", "[", "'poly'", "]", "\n", "if", "difficult", "==", "'2'", ":", "\n", "                ", "continue", "\n", "", "if", "rate", "==", "'0.5'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'1'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "", "elif", "rate", "==", "'1'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'0.8'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "", "elif", "rate", "==", "'2'", ":", "\n", "                ", "outline", "=", "custombasename", "(", "filepath", ")", "+", "' '", "+", "'0.6'", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "poly", ")", ")", "\n", "\n", "", "filedict", "[", "category", "]", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n", "", "", "", "def", "Task2groundtruth_poly", "(", "srcpath", ",", "dstpath", ")", ":", "\n", "    ", "thresh", "=", "0.1", "\n", "filedict", "=", "{", "}", "\n", "Tasklist", "=", "GetFileFromThisRootDir", "(", "srcpath", ",", "'.txt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length": [[228, 230], ["math.sqrt", "math.pow", "math.pow"], "function", ["None"], ["for", "Taskfile", "in", "Tasklist", ":", "\n", "        ", "idname", "=", "custombasename", "(", "Taskfile", ")", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "# idname = datamap_inverse[idname]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.get_best_begin_point": [[231, 260], ["min", "min", "max", "max", "range", "print", "dota_utils.cal_line_length", "dota_utils.cal_line_length", "dota_utils.cal_line_length", "dota_utils.cal_line_length"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.cal_line_length"], ["f", "=", "open", "(", "Taskfile", ",", "'r'", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "# print('line:', line)", "\n", "", "splitline", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "filename", "=", "splitline", "[", "0", "]", "\n", "confidence", "=", "splitline", "[", "1", "]", "\n", "bbox", "=", "splitline", "[", "2", ":", "]", "\n", "if", "float", "(", "confidence", ")", ">", "thresh", ":", "\n", "                ", "if", "filename", "not", "in", "filedict", ":", "\n", "# filedict[filename] = codecs.open(os.path.join(dstpath, filename + '.txt'), 'w', 'utf_16')", "\n", "                    ", "filedict", "[", "filename", "]", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "dstpath", ",", "filename", "+", "'.txt'", ")", ",", "'w'", ")", "\n", "# poly = util.dots2ToRec8(bbox)", "\n", "", "poly", "=", "bbox", "\n", "#               filedict[filename].write(' '.join(poly) + ' ' + idname + '_' + str(round(float(confidence), 2)) + '\\n')", "\n", "# print('idname:', idname)", "\n", "\n", "# filedict[filename].write(' '.join(poly) + ' ' + idname + '_' + str(round(float(confidence), 2)) + '\\n')", "\n", "\n", "filedict", "[", "filename", "]", ".", "write", "(", "' '", ".", "join", "(", "poly", ")", "+", "' '", "+", "idname", "+", "'\\n'", ")", "\n", "\n", "\n", "", "", "", "", "def", "polygonToRotRectangle", "(", "bbox", ")", ":", "\n", "    ", "\"\"\"\n    :param bbox: The polygon stored in format [x1, y1, x2, y2, x3, y3, x4, y4]\n    :return: Rotated Rectangle in format [cx, cy, w, h, theta]\n    \"\"\"", "\n", "bbox", "=", "np", ".", "array", "(", "bbox", ",", "dtype", "=", "np", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly": [[24, 59], ["range", "len", "polyiou.VectorDouble", "polys.append", "scores.argsort", "keep.append", "range", "numpy.array", "polyiou.iou_poly", "np.array.append", "math.isnan", "numpy.where", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["from", "DOTA_devkit", ".", "nms", "import", "obb_hybrid_NMS", ",", "obb_HNMS", "\n", "\n", "#TODO: there is a bug at 5 decimal places of mAP when using the program", "\n", "def", "py_cpu_nms_poly", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "polys", "=", "[", "]", "\n", "areas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "for", "j", "in", "range", "(", "order", ".", "size", "-", "1", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "order", "[", "j", "+", "1", "]", "]", ")", "\n", "ovr", ".", "append", "(", "iou", ")", "\n", "", "ovr", "=", "np", ".", "array", "(", "ovr", ")", "\n", "\n", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly_fast": [[61, 123], ["numpy.min", "numpy.min", "numpy.max", "numpy.max", "range", "len", "polyiou.VectorDouble", "polys.append", "scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "range", "numpy.where", "polyiou.iou_poly", "math.isnan", "numpy.where", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.iou_poly"], ["# TODO: test it", "\n", "    ", "try", ":", "\n", "        ", "obbs", "=", "dets", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "print", "(", "'fail index'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "x1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "x2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "\n", "polys", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", ")", "\n", "hbb_inter", "=", "w", "*", "h", "\n", "hbb_ovr", "=", "hbb_inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "hbb_inter", ")", "\n", "h_inds", "=", "np", ".", "where", "(", "hbb_ovr", ">", "0", ")", "[", "0", "]", "\n", "tmp_order", "=", "order", "[", "h_inds", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "tmp_order", ".", "size", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "tmp_order", "[", "j", "]", "]", ")", "\n", "hbb_ovr", "[", "h_inds", "[", "j", "]", "]", "=", "iou", "\n", "", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "hbb_ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "", "return", "keep", "\n", "\n", "", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "#print('dets:', dets)", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms": [[124, 156], ["scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "keep", "\n", "\n", "", "def", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "thresh", ")", ":", "\n", "    ", "nameboxnmsdict", "=", "{", "x", ":", "[", "]", "for", "x", "in", "nameboxdict", "}", "\n", "for", "imgname", "in", "nameboxdict", ":", "\n", "        ", "keep", "=", "nms", "(", "np", ".", "array", "(", "nameboxdict", "[", "imgname", "]", ")", ",", "thresh", ")", "\n", "outdets", "=", "[", "]", "\n", "for", "index", "in", "keep", ":", "\n", "            ", "outdets", ".", "append", "(", "nameboxdict", "[", "imgname", "]", "[", "index", "]", ")", "\n", "", "nameboxnmsdict", "[", "imgname", "]", "=", "outdets", "\n", "", "return", "nameboxnmsdict", "\n", "", "def", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", ":", "\n", "    ", "origpoly", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "poly", ")", "/", "2", ")", ")", ":", "\n", "        ", "tmp_x", "=", "float", "(", "poly", "[", "i", "*", "2", "]", "+", "x", ")", "/", "float", "(", "rate", ")", "\n", "tmp_y", "=", "float", "(", "poly", "[", "i", "*", "2", "+", "1", "]", "+", "y", ")", "/", "float", "(", "rate", ")", "\n", "origpoly", ".", "append", "(", "tmp_x", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.nmsbynamedict": [[157, 174], ["nms", "numpy.array", "outdets.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["origpoly", ".", "append", "(", "tmp_y", ")", "\n", "", "return", "origpoly", "\n", "\n", "", "def", "mergesingle", "(", "dstpath", ",", "nms", ",", "nms_thresh", ",", "fullname", ")", ":", "\n", "    ", "name", "=", "util", ".", "custombasename", "(", "fullname", ")", "\n", "#print('name:', name)", "\n", "dstname", "=", "os", ".", "path", ".", "join", "(", "dstpath", ",", "name", "+", "'.txt'", ")", "\n", "with", "open", "(", "fullname", ",", "'r'", ")", "as", "f_in", ":", "\n", "# print('fullname: ', fullname)", "\n", "        ", "nameboxdict", "=", "{", "}", "\n", "lines", "=", "f_in", ".", "readlines", "(", ")", "\n", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "lines", "]", "\n", "for", "splitline", "in", "splitlines", ":", "\n", "            ", "subname", "=", "splitline", "[", "0", "]", "\n", "splitname", "=", "subname", ".", "split", "(", "'__'", ")", "\n", "oriname", "=", "splitname", "[", "0", "]", "\n", "pattern1", "=", "re", ".", "compile", "(", "r'__\\d+___\\d+'", ")", "\n", "#print('subname:', subname)", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.poly2origpoly": [[174, 182], ["range", "int", "origpoly.append", "origpoly.append", "float", "float", "float", "float", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["#print('subname:', subname)", "\n", "x_y", "=", "re", ".", "findall", "(", "pattern1", ",", "subname", ")", "\n", "x_y_2", "=", "re", ".", "findall", "(", "r'\\d+'", ",", "x_y", "[", "0", "]", ")", "\n", "x", ",", "y", "=", "int", "(", "x_y_2", "[", "0", "]", ")", ",", "int", "(", "x_y_2", "[", "1", "]", ")", "\n", "\n", "pattern2", "=", "re", ".", "compile", "(", "r'__([\\d+\\.]+)__\\d+___'", ")", "\n", "\n", "rate", "=", "re", ".", "findall", "(", "pattern2", ",", "subname", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergesingle": [[183, 224], ["dota_utils.custombasename", "os.path.join", "open", "f_in.readlines", "ResultMerge_multi_process.nmsbynamedict", "x.strip().split", "subname.split", "re.compile", "re.findall", "re.findall", "re.compile", "list", "ResultMerge_multi_process.poly2origpoly", "list.append", "list", "nameboxdict[].append", "open", "int", "int", "re.findall", "map", "map", "x.strip", "f_out.write", "map", "str"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.custombasename", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.nmsbynamedict", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.poly2origpoly", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["confidence", "=", "splitline", "[", "1", "]", "\n", "poly", "=", "list", "(", "map", "(", "float", ",", "splitline", "[", "2", ":", "]", ")", ")", "\n", "origpoly", "=", "poly2origpoly", "(", "poly", ",", "x", ",", "y", ",", "rate", ")", "\n", "det", "=", "origpoly", "\n", "det", ".", "append", "(", "confidence", ")", "\n", "det", "=", "list", "(", "map", "(", "float", ",", "det", ")", ")", "\n", "if", "(", "oriname", "not", "in", "nameboxdict", ")", ":", "\n", "                ", "nameboxdict", "[", "oriname", "]", "=", "[", "]", "\n", "", "nameboxdict", "[", "oriname", "]", ".", "append", "(", "det", ")", "\n", "", "nameboxnmsdict", "=", "nmsbynamedict", "(", "nameboxdict", ",", "nms", ",", "nms_thresh", ")", "\n", "with", "open", "(", "dstname", ",", "'w'", ")", "as", "f_out", ":", "\n", "            ", "for", "imgname", "in", "nameboxnmsdict", ":", "\n", "                ", "for", "det", "in", "nameboxnmsdict", "[", "imgname", "]", ":", "\n", "#print('det:', det)", "\n", "                    ", "confidence", "=", "det", "[", "-", "1", "]", "\n", "bbox", "=", "det", "[", "0", ":", "-", "1", "]", "\n", "outline", "=", "imgname", "+", "' '", "+", "str", "(", "confidence", ")", "+", "' '", "+", "' '", ".", "join", "(", "map", "(", "str", ",", "bbox", ")", ")", "\n", "#print('outline:', outline)", "\n", "f_out", ".", "write", "(", "outline", "+", "'\\n'", ")", "\n", "\n", "", "", "", "", "", "def", "mergebase_parallel", "(", "srcpath", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", ":", "\n", "    ", "pool", "=", "Pool", "(", "16", ")", "\n", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "\n", "mergesingle_fn", "=", "partial", "(", "mergesingle", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", "\n", "# pdb.set_trace()", "\n", "pool", ".", "map", "(", "mergesingle_fn", ",", "filelist", ")", "\n", "\n", "", "def", "mergebase", "(", "srcpath", ",", "dstpath", ",", "nms", ",", "nms_thresh", ")", ":", "\n", "    ", "filelist", "=", "util", ".", "GetFileFromThisRootDir", "(", "srcpath", ")", "\n", "for", "filename", "in", "filelist", ":", "\n", "        ", "mergesingle", "(", "dstpath", ",", "nms", ",", "nms_thresh", ",", "filename", ")", "\n", "\n", "", "", "def", "mergebyrec", "(", "srcpath", ",", "dstpath", ",", "nms_thresh", "=", "0.3", ")", ":", "\n", "    ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms", ",", "nms_thresh", ")", "\n", "\n", "", "def", "mergebypoly_multiprocess", "(", "srcpath", ",", "dstpath", ",", "nms_type", "=", "'py_cpu_nms_poly_fast'", ",", "o_thresh", "=", "0.1", ",", "h_thresh", "=", "0.5", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel": [[225, 232], ["multiprocessing.Pool", "dota_utils.GetFileFromThisRootDir", "functools.partial", "multiprocessing.Pool.map", "ResultMerge_multi_process.py_cpu_nms_poly_fast"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms_poly_fast"], ["\n", "# srcpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/comp4_test_results'", "\n", "# dstpath = r'/home/dingjian/evaluation_task1/result/faster-rcnn-59/testtime'", "\n", "if", "nms_type", "==", "'py_cpu_nms_poly_fast'", ":", "\n", "        ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "py_cpu_nms_poly_fast", ",", "o_thresh", ")", "\n", "", "elif", "nms_type", "==", "'obb_HNMS'", ":", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase": [[233, 237], ["dota_utils.GetFileFromThisRootDir", "ResultMerge_multi_process.mergesingle", "ResultMerge_multi_process.py_cpu_nms"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.dota_utils.GetFileFromThisRootDir", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergesingle", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.py_cpu_nms"], ["        ", "mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "obb_HNMS", ",", "o_thresh", ")", "\n", "", "elif", "nms_type", "==", "'obb_hybrid_NMS'", ":", "\n", "        ", "obb_hybrid_NMS_partial", "=", "partial", "(", "obb_hybrid_NMS", ",", "o_thresh", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebyrec": [[238, 249], ["ResultMerge_multi_process.mergebase"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase"], ["mergebase_parallel", "(", "srcpath", ",", "\n", "dstpath", ",", "\n", "obb_hybrid_NMS_partial", ",", "h_thresh", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "# mergebypoly(r'/home/dingjian/code/DOTA_devkit/Test_nms2/Task1_results', r'/home/dingjian/code/DOTA_devkit/Test_nms2/Task1_results_0.1_nms_fast')", "\n", "    ", "mergebyrec", "(", "r'/home/dingjian/Documents/Research/experiments/mmdetection_DOTA/scratch_faster_rcnn_r50_fpn_gn_2x_dota2/Task2_results'", ",", "\n", "r'/home/dingjian/Documents/Research/experiments/mmdetection_DOTA/scratch_faster_rcnn_r50_fpn_gn_2x_dota2/Task2_results_nms'", ")", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebypoly": [[249, 263], ["ResultMerge_multi_process.mergebase_parallel"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebase_parallel"], []], "home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args": [[264, 269], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.parse_args"], []], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.__init__": [[41, 44], ["detectron2.modeling.ProposalNetwork.__init__", "one_stage_detector.build_top_module"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.build_top_module"], ["def", "__init__", "(", "self", ",", "cfg", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "top_module", "=", "build_top_module", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.forward": [[45, 56], ["super().forward", "super().forward", "one_stage_detector.OneStageDetector._postprocess"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.forward", "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.forward", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN._postprocess"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ",", "do_postprocess", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "super", "(", ")", ".", "forward", "(", "batched_inputs", ")", "\n", "", "processed_results", "=", "super", "(", ")", ".", "forward", "(", "batched_inputs", ")", "\n", "\n", "if", "do_postprocess", ":", "\n", "            ", "processed_results", "=", "self", ".", "_postprocess", "(", "processed_results", ",", "batched_inputs", ")", "\n", "\n", "", "processed_results", "=", "[", "{", "\"instances\"", ":", "r", "[", "\"proposals\"", "]", "}", "for", "r", "in", "processed_results", "]", "\n", "\n", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.inference": [[57, 77], ["one_stage_detector.OneStageDetector.forward"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.forward"], ["", "def", "inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ",", "do_postprocess", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            same as in :meth:`forward`.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "\n", "return", "self", ".", "forward", "(", "batched_inputs", ",", "do_postprocess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector._postprocess": [[78, 99], ["zip", "detectron2.structures.Instances", "res[].get_fields"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_postprocess", "(", "processed_results", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Rescale the output instances (corners) to the target size.\n        \"\"\"", "\n", "for", "res", ",", "inp", "in", "zip", "(", "processed_results", ",", "batched_inputs", ")", ":", "\n", "            ", "output_height", ",", "output_width", "=", "inp", "[", "\"height\"", "]", ",", "inp", "[", "\"width\"", "]", "\n", "height_orig", ",", "width_orig", "=", "inp", "[", "\"image\"", "]", ".", "shape", "[", "1", ":", "3", "]", "\n", "\n", "scale_x", ",", "scale_y", "=", "(", "\n", "output_width", "/", "width_orig", ",", "\n", "output_height", "/", "height_orig", ",", "\n", ")", "\n", "\n", "result", "=", "Instances", "(", "(", "output_height", ",", "output_width", ")", ",", "**", "res", "[", "\"proposals\"", "]", ".", "get_fields", "(", ")", ")", "\n", "result", ".", "pred_corners", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "result", ".", "pred_corners", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "result", ".", "locations", "[", ":", ",", "0", "]", "*=", "scale_x", "\n", "result", ".", "locations", "[", ":", ",", "1", "]", "*=", "scale_y", "\n", "\n", "", "return", "processed_results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.preprocess_image": [[100, 108], ["detectron2.structures.ImageList.from_tensors", "x[].to"], "methods", ["None"], ["", "def", "preprocess_image", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Normalize, pad and batch the input images.\n        \"\"\"", "\n", "images", "=", "[", "x", "[", "\"image\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "images", "=", "[", "(", "x", "-", "self", ".", "pixel_mean", ")", "/", "self", ".", "pixel_std", "for", "x", "in", "images", "]", "\n", "images", "=", "ImageList", ".", "from_tensors", "(", "images", ",", "self", ".", "backbone", ".", "size_divisibility", ")", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN.__init__": [[128, 132], ["detectron2.modeling.GeneralizedRCNN.__init__", "one_stage_detector.build_top_module", "one_stage_detector.OneStageRCNN.to"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.build_top_module"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "top_module", "=", "build_top_module", "(", "cfg", ")", "\n", "self", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN.forward": [[133, 193], ["one_stage_detector.OneStageRCNN.preprocess_image", "one_stage_detector.OneStageRCNN.backbone", "one_stage_detector.OneStageRCNN.roi_heads", "losses.update", "losses.update", "one_stage_detector.OneStageRCNN.inference", "one_stage_detector.OneStageRCNN.proposal_generator", "detectron2.utils.events.get_event_storage", "x[].to", "detectron2.utils.logger.log_first_n", "x[].to", "one_stage_detector.OneStageRCNN.visualize_training", "x[].to"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.preprocess_image", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN.inference"], ["", "def", "forward", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\n                Each item in the list contains the inputs for one image.\n                For now, each item in the list is a dict that contains:\n\n                * image: Tensor, image in (C, H, W) format.\n                * instances (optional): groundtruth :class:`Instances`\n                * proposals (optional): :class:`Instances`, precomputed proposals.\n\n                Other information that's included in the original dicts, such as:\n\n                * \"height\", \"width\" (int): the output resolution of the model, used in inference.\n                  See :meth:`postprocess` for details.\n\n        Returns:\n            list[dict]:\n                Each dict is the output for one input image.\n                The dict contains one key \"instances\" whose value is a :class:`Instances`.\n                The :class:`Instances` object has the following keys:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\n        \"\"\"", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "elif", "\"targets\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "log_first_n", "(", "\n", "logging", ".", "WARN", ",", "\n", "\"'targets' in the model inputs is now renamed to 'instances'!\"", ",", "\n", "n", "=", "10", ",", "\n", ")", "\n", "gt_instances", "=", "[", "x", "[", "\"targets\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "self", ".", "proposal_generator", ":", "\n", "            ", "proposals", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", ",", "self", ".", "top_module", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "proposal_losses", "=", "{", "}", "\n", "\n", "", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "gt_instances", ")", "\n", "if", "self", ".", "vis_period", ">", "0", ":", "\n", "            ", "storage", "=", "get_event_storage", "(", ")", "\n", "if", "storage", ".", "iter", "%", "self", ".", "vis_period", "==", "0", ":", "\n", "                ", "self", ".", "visualize_training", "(", "batched_inputs", ",", "proposals", ")", "\n", "\n", "", "", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN.inference": [[194, 238], ["one_stage_detector.OneStageRCNN.preprocess_image", "one_stage_detector.OneStageRCNN.backbone", "one_stage_detector.OneStageRCNN.roi_heads", "one_stage_detector.OneStageRCNN.roi_heads.forward_with_given_boxes", "one_stage_detector.OneStageRCNN._postprocess", "one_stage_detector.OneStageRCNN.proposal_generator", "x.to", "x[].to"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageDetector.preprocess_image", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN._postprocess"], ["", "def", "inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ",", "do_postprocess", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            same as in :meth:`forward`.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "if", "self", ".", "proposal_generator", ":", "\n", "                ", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "None", ",", "self", ".", "top_module", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "results", ",", "_", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "detected_instances", "=", "[", "x", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "detected_instances", "]", "\n", "results", "=", "self", ".", "roi_heads", ".", "forward_with_given_boxes", "(", "\n", "features", ",", "detected_instances", "\n", ")", "\n", "\n", "", "if", "do_postprocess", ":", "\n", "            ", "return", "OneStageRCNN", ".", "_postprocess", "(", "\n", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN._postprocess": [[239, 254], ["zip", "input_per_image.get", "input_per_image.get", "detectron2.modeling.postprocessing.detector_postprocess", "processed_results.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.detector_postprocess", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "@", "staticmethod", "\n", "def", "_postprocess", "(", "instances", ",", "batched_inputs", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Rescale the output instances to the target size.\n        \"\"\"", "\n", "# note: private function; subject to changes", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "instances", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "", "return", "processed_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.detector_postprocess": [[12, 32], ["detectron2.modeling.postprocessing.detector_postprocess", "detectron2.modeling.postprocessing.detector_postprocess.has", "detectron2.modeling.postprocessing.detector_postprocess.has"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.detector_postprocess"], ["def", "detector_postprocess", "(", "results", ",", "output_height", ",", "output_width", ",", "mask_threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    In addition to the post processing of detectron2, we add scalign for\n    bezier control points.\n    \"\"\"", "\n", "scale_x", ",", "scale_y", "=", "(", "\n", "output_width", "/", "results", ".", "image_size", "[", "1", "]", ",", "\n", "output_height", "/", "results", ".", "image_size", "[", "0", "]", ",", "\n", ")", "\n", "results", "=", "d2_postprocesss", "(", "results", ",", "output_height", ",", "output_width", ",", "mask_threshold", ")", "\n", "\n", "if", "results", ".", "has", "(", "\"pred_corners\"", ")", ":", "\n", "        ", "results", ".", "pred_corners", "[", ":", ",", "0", ":", ":", "2", "]", "*=", "scale_x", "\n", "results", ".", "pred_corners", "[", ":", ",", "1", ":", ":", "2", "]", "*=", "scale_y", "\n", "\n", "", "if", "results", ".", "has", "(", "\"locations\"", ")", ":", "\n", "        ", "results", ".", "locations", "[", ":", ",", "0", "]", "*=", "scale_x", "\n", "results", ".", "locations", "[", ":", ",", "1", "]", "*=", "scale_y", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.build_top_module": [[110, 119], ["torch.nn.Conv2d"], "function", ["None"], ["", "", "def", "build_top_module", "(", "cfg", ")", ":", "\n", "    ", "top_type", "=", "cfg", ".", "MODEL", ".", "TOP_MODULE", ".", "NAME", "\n", "if", "top_type", "==", "\"conv\"", ":", "\n", "        ", "inp", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "oup", "=", "cfg", ".", "MODEL", ".", "TOP_MODULE", ".", "DIM", "\n", "top_module", "=", "nn", ".", "Conv2d", "(", "inp", ",", "oup", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "top_module", "=", "None", "\n", "", "return", "top_module", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.DotaDatasetMapperTTA.__init__": [[38, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "min_sizes", "=", "cfg", ".", "TEST", ".", "AUG", ".", "MIN_SIZES", "\n", "self", ".", "max_size", "=", "cfg", ".", "TEST", ".", "AUG", ".", "MAX_SIZE", "\n", "self", ".", "resize_type", "=", "cfg", ".", "INPUT", ".", "RESIZE_TYPE", "\n", "self", ".", "vflip", "=", "cfg", ".", "TEST", ".", "AUG", ".", "VFLIP", "\n", "self", ".", "hflip", "=", "cfg", ".", "TEST", ".", "AUG", ".", "HFLIP", "\n", "self", ".", "rotation_angles", "=", "cfg", ".", "TEST", ".", "AUG", ".", "ROTATION_ANGLES", "\n", "self", ".", "image_format", "=", "cfg", ".", "INPUT", ".", "FORMAT", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.DotaDatasetMapperTTA.__call__": [[48, 136], ["dataset_dict[].permute().numpy", "detectron2.data.transforms.ResizeTransform", "fvcore.transforms.NoOpTransform", "aug_candidates.append", "detectron2.data.transforms.apply_augmentations", "torch.from_numpy", "copy.deepcopy", "ret.append", "dataset_dict[].permute", "detectron2.data.transforms.ResizeShortestEdge", "len", "numpy.copy", "numpy.ascontiguousarray", "int", "detectron2.data.transforms.Resize", "RuntimeError", "detectron2.data.transforms.RandomFlip", "aug_candidates.append", "detectron2.data.transforms.RandomFlip", "aug_candidates.append", "detectron2.data.transforms.augmentation_impl.RandomRotation", "new_image.transpose", "detectron2.data.transforms.RandomFlip", "aug_candidates.append", "aug_candidates.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dict: a dict in standard model input format. See tutorials for details.\n\n        Returns:\n            list[dict]:\n                a list of dicts, which contain augmented version of the input image.\n                The total number of dicts is ``len(min_sizes) * (2 if flip else 1)``.\n                Each dict has field \"transforms\" which is a TransformList,\n                containing the transforms that are used to generate this image.\n        \"\"\"", "\n", "numpy_image", "=", "dataset_dict", "[", "\"image\"", "]", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "shape", "=", "numpy_image", ".", "shape", "\n", "orig_shape", "=", "(", "dataset_dict", "[", "\"height\"", "]", ",", "dataset_dict", "[", "\"width\"", "]", ")", "\n", "if", "shape", "[", ":", "2", "]", "!=", "orig_shape", ":", "\n", "# It transforms the \"original\" image in the dataset to the input image", "\n", "            ", "pre_tfm", "=", "ResizeTransform", "(", "orig_shape", "[", "0", "]", ",", "orig_shape", "[", "1", "]", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "pre_tfm", "=", "NoOpTransform", "(", ")", "\n", "\n", "# Create all combinations of augmentations to use", "\n", "", "aug_candidates", "=", "[", "]", "# each element is a list[Augmentation]", "\n", "for", "min_size", "in", "self", ".", "min_sizes", ":", "\n", "            ", "if", "self", ".", "resize_type", "==", "\"shortest-edge\"", ":", "\n", "                ", "resize", "=", "ResizeShortestEdge", "(", "\n", "min_size", ",", "self", ".", "max_size", "\n", ")", "\n", "", "elif", "self", ".", "resize_type", "==", "\"both\"", ":", "\n", "# Get original resize height/width for testing", "\n", "                ", "h_test", "=", "self", ".", "cfg", ".", "INPUT", ".", "RESIZE_HEIGHT_TEST", "\n", "w_test", "=", "self", ".", "cfg", ".", "INPUT", ".", "RESIZE_WIDTH_TEST", "\n", "\n", "# Find scale of current min_size w.r.t. to test width", "\n", "scale", "=", "min_size", "/", "w_test", "\n", "\n", "# Scale height accordingly", "\n", "h", "=", "int", "(", "h_test", "*", "scale", ")", "\n", "w", "=", "min_size", "\n", "resize", "=", "Resize", "(", "shape", "=", "(", "h", ",", "w", ")", ")", "\n", "# resize = ResizeTransform(shape[0], shape[1], h, w)", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"Invalid resize-type: {self.cfg.INPUT.RESIZE_TYPE}\"", ")", "\n", "\n", "", "aug_candidates", ".", "append", "(", "[", "resize", "]", ")", "# resize only", "\n", "\n", "if", "len", "(", "self", ".", "rotation_angles", ")", "==", "0", ":", "\n", "# Horizontal Flip", "\n", "                ", "if", "self", ".", "hflip", ":", "\n", "                    ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "flip", "]", ")", "# resize + hflip", "\n", "\n", "# Horizontal Flip", "\n", "", "if", "self", ".", "vflip", ":", "\n", "                    ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ",", "horizontal", "=", "False", ",", "vertical", "=", "True", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "flip", "]", ")", "# resize + vflip", "\n", "\n", "", "", "else", ":", "\n", "                ", "for", "angle", "in", "self", ".", "rotation_angles", ":", "\n", "# Choose specific rotation augmentation (choice from a single element)", "\n", "                    ", "rot", "=", "RandomRotation", "(", "angle", "=", "[", "angle", "]", ",", "sample_style", "=", "\"choice\"", ")", "\n", "\n", "# Horizontal Flip", "\n", "if", "self", ".", "hflip", ":", "\n", "                        ", "flip", "=", "RandomFlip", "(", "prob", "=", "1.0", ",", "horizontal", "=", "True", ",", "vertical", "=", "False", ")", "\n", "aug_candidates", ".", "append", "(", "[", "resize", ",", "rot", ",", "flip", "]", ")", "# resize + rot + hflip", "\n", "\n", "# Vertical Flip", "\n", "# NOTE: VLIP is unnecessary since HFLIP + ROT(180) = VFLIP", "\n", "# if self.vflip:", "\n", "#     flip = RandomFlip(prob=1.0, horizontal=False, vertical=True)", "\n", "#     aug_candidates.append([resize, rot, flip])  # resize + rot + vflip", "\n", "\n", "# If no flip flag was active, just add resize + rot", "\n", "", "if", "not", "self", ".", "hflip", ":", "\n", "                        ", "aug_candidates", ".", "append", "(", "[", "resize", ",", "rot", "]", ")", "\n", "\n", "# Apply all the augmentations", "\n", "", "", "", "", "ret", "=", "[", "]", "\n", "for", "aug", "in", "aug_candidates", ":", "\n", "            ", "new_image", ",", "tfms", "=", "apply_augmentations", "(", "aug", ",", "np", ".", "copy", "(", "numpy_image", ")", ")", "\n", "torch_image", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "new_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "\n", "dic", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "\n", "dic", "[", "\"transforms\"", "]", "=", "pre_tfm", "+", "tfms", "\n", "dic", "[", "\"image\"", "]", "=", "torch_image", "\n", "ret", ".", "append", "(", "dic", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA.__init__": [[144, 172], ["torch.nn.Module.__init__", "isinstance", "isinstance", "cfg.clone", "type", "tta.DotaDatasetMapperTTA"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "model", ",", "tta_mapper", "=", "None", ",", "batch_size", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            model (GeneralizedRCNN): a GeneralizedRCNN to apply TTA on.\n            tta_mapper (callable): takes a dataset dict and returns a list of\n                augmented versions of the dataset dict. Defaults to\n                `DatasetMapperTTA(cfg)`.\n            batch_size (int): batch the augmented images into this batch size for inference.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "model", ",", "DistributedDataParallel", ")", ":", "\n", "            ", "model", "=", "model", ".", "module", "\n", "", "assert", "isinstance", "(", "\n", "model", ",", "OneStageDetector", "\n", ")", ",", "\"TTA is only supported on OneStageDetector. Got a model of type {}\"", ".", "format", "(", "type", "(", "model", ")", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "\n", "assert", "not", "self", ".", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", ",", "\"TTA for keypoint is not supported yet\"", "\n", "assert", "(", "\n", "not", "self", ".", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", ")", ",", "\"TTA for pre-computed proposals is not supported yet\"", "\n", "\n", "self", ".", "model", "=", "model", "\n", "\n", "if", "tta_mapper", "is", "None", ":", "\n", "            ", "tta_mapper", "=", "DotaDatasetMapperTTA", "(", "cfg", ")", "\n", "", "self", ".", "tta_mapper", "=", "tta_mapper", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._batch_inference": [[173, 198], ["zip", "itertools.count", "inputs.append", "instances.append", "len", "outputs.extend", "len", "tta.OneStageRCNNWithTTA.model.inference", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.one_stage_detector.OneStageRCNN.inference"], ["", "def", "_batch_inference", "(", "self", ",", "batched_inputs", ",", "detected_instances", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Execute inference on a list of inputs,\n        using batch size = self.batch_size, instead of the length of the list.\n\n        Inputs & outputs have the same format as :meth:`GeneralizedRCNN.inference`\n        \"\"\"", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "detected_instances", "=", "[", "None", "]", "*", "len", "(", "batched_inputs", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "input", ",", "instance", "in", "zip", "(", "count", "(", ")", ",", "batched_inputs", ",", "detected_instances", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "input", ")", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "if", "len", "(", "inputs", ")", "==", "self", ".", "batch_size", "or", "idx", "==", "len", "(", "batched_inputs", ")", "-", "1", ":", "\n", "                ", "outputs", ".", "extend", "(", "\n", "self", ".", "model", ".", "inference", "(", "\n", "inputs", ",", "\n", "instances", "if", "instances", "[", "0", "]", "is", "not", "None", "else", "None", ",", "\n", "do_postprocess", "=", "False", ",", "\n", ")", "\n", ")", "\n", "inputs", ",", "instances", "=", "[", "]", ",", "[", "]", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA.__call__": [[199, 216], ["copy.copy", "tta.OneStageRCNNWithTTA._inference_one_image", "detectron2.data.detection_utils.read_image", "torch.from_numpy().permute", "tta.OneStageRCNNWithTTA.__call__._maybe_read_image"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.SwigPyIterator.copy", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._inference_one_image"], ["", "def", "__call__", "(", "self", ",", "batched_inputs", ")", ":", "\n", "        ", "\"\"\"\n        Same input/output format as :meth:`GeneralizedRCNN.forward`\n        \"\"\"", "\n", "\n", "def", "_maybe_read_image", "(", "dataset_dict", ")", ":", "\n", "            ", "ret", "=", "copy", ".", "copy", "(", "dataset_dict", ")", "\n", "if", "\"image\"", "not", "in", "ret", ":", "\n", "                ", "image", "=", "read_image", "(", "ret", ".", "pop", "(", "\"file_name\"", ")", ",", "self", ".", "tta_mapper", ".", "image_format", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "image", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# CHW", "\n", "ret", "[", "\"image\"", "]", "=", "image", "\n", "", "if", "\"height\"", "not", "in", "ret", "and", "\"width\"", "not", "in", "ret", ":", "\n", "                ", "ret", "[", "\"height\"", "]", "=", "image", ".", "shape", "[", "1", "]", "\n", "ret", "[", "\"width\"", "]", "=", "image", ".", "shape", "[", "2", "]", "\n", "", "return", "ret", "\n", "\n", "", "return", "[", "self", ".", "_inference_one_image", "(", "_maybe_read_image", "(", "x", ")", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._inference_one_image": [[217, 230], ["tta.OneStageRCNNWithTTA._get_augmented_inputs", "tta.OneStageRCNNWithTTA._get_augmented_corners", "tta.OneStageRCNNWithTTA._merge_detections"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._get_augmented_inputs", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._get_augmented_corners", "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._merge_detections"], ["", "def", "_inference_one_image", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input (dict): one dataset dict with \"image\" field being a CHW tensor\n\n        Returns:\n            dict: one output dict\n        \"\"\"", "\n", "orig_shape", "=", "(", "input", "[", "\"height\"", "]", ",", "input", "[", "\"width\"", "]", ")", "\n", "augmented_inputs", ",", "tfms", "=", "self", ".", "_get_augmented_inputs", "(", "input", ")", "\n", "instances", "=", "self", ".", "_get_augmented_corners", "(", "augmented_inputs", ",", "tfms", ")", "\n", "merged_instances", "=", "self", ".", "_merge_detections", "(", "instances", ")", "\n", "return", "{", "\"instances\"", ":", "merged_instances", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._get_augmented_inputs": [[231, 235], ["tta.OneStageRCNNWithTTA.tta_mapper", "x.pop"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop"], ["", "def", "_get_augmented_inputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "augmented_inputs", "=", "self", ".", "tta_mapper", "(", "input", ")", "\n", "tfms", "=", "[", "x", ".", "pop", "(", "\"transforms\"", ")", "for", "x", "in", "augmented_inputs", "]", "\n", "return", "augmented_inputs", ",", "tfms", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._get_augmented_corners": [[236, 263], ["tta.OneStageRCNNWithTTA._batch_inference", "zip", "detectron2.structures.Instances.cat", "pred_corners.view.view.view", "pred_corners.view.view.cpu().numpy", "tfm.inverse().apply_coords", "original_pred_corners.reshape.reshape.reshape", "detectron2.structures.Instances", "torch.from_numpy().to", "instances_list.append", "pred_corners.view.view.cpu", "tfm.inverse", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._batch_inference", "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_coords", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.inverse"], ["", "def", "_get_augmented_corners", "(", "self", ",", "augmented_inputs", ",", "tfms", ")", ":", "\n", "# 1: forward with all augmented images", "\n", "        ", "outputs", "=", "self", ".", "_batch_inference", "(", "augmented_inputs", ")", "\n", "# 2: union the results", "\n", "# all_corners = []", "\n", "# all_scores = []", "\n", "# all_classes = []", "\n", "instances_list", "=", "[", "]", "\n", "for", "output", ",", "tfm", "in", "zip", "(", "outputs", ",", "tfms", ")", ":", "\n", "# Need to inverse the transforms on boxes, to obtain results on original image", "\n", "            ", "instances", "=", "output", "[", "\"instances\"", "]", "\n", "pred_corners", "=", "instances", ".", "pred_corners", "\n", "N", ",", "C", "=", "pred_corners", ".", "shape", "\n", "assert", "C", "==", "8", "\n", "pred_corners", "=", "pred_corners", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "pred_corners_np", "=", "pred_corners", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "original_pred_corners", "=", "tfm", ".", "inverse", "(", ")", ".", "apply_coords", "(", "pred_corners_np", ")", "\n", "original_pred_corners", "=", "original_pred_corners", ".", "reshape", "(", "N", ",", "C", ")", "\n", "inst", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "inst", ".", "scores", "=", "instances", ".", "scores", "\n", "inst", ".", "centerness", "=", "instances", ".", "centerness", "\n", "inst", ".", "pred_corners", "=", "torch", ".", "from_numpy", "(", "original_pred_corners", ")", ".", "to", "(", "\n", "pred_corners", ".", "device", ",", "dtype", "=", "pred_corners", ".", "dtype", "\n", ")", "\n", "inst", ".", "pred_classes", "=", "instances", ".", "pred_classes", "\n", "instances_list", ".", "append", "(", "inst", ")", "\n", "", "return", "Instances", ".", "cat", "(", "instances_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.modeling.tta.OneStageRCNNWithTTA._merge_detections": [[264, 269], ["tta.OneStageRCNNWithTTA.model.proposal_generator.dafne_outputs.select_over_all_levels"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.dafne.dafne_outputs.DAFNeOutputs.select_over_all_levels"], ["", "def", "_merge_detections", "(", "self", ",", "instances", ")", ":", "\n", "        ", "merged_instances", "=", "self", ".", "model", ".", "proposal_generator", ".", "dafne_outputs", ".", "select_over_all_levels", "(", "\n", "[", "instances", "]", "\n", ")", "[", "0", "]", "\n", "return", "merged_instances", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.nms.nms.ml_nms": [[10, 34], ["nms.batched_nms_poly"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.nms.nms.batched_nms_poly"], ["def", "py_cpu_nms_poly_fast", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "obbs", "=", "dets", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "print", "(", "'fail index'", ")", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "x1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y1", "=", "np", ".", "min", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "x2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "y2", "=", "np", ".", "max", "(", "obbs", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "dets", "[", ":", ",", "8", "]", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "\n", "polys", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dets", ")", ")", ":", "\n", "        ", "tm_polygon", "=", "polyiou", ".", "VectorDouble", "(", "[", "dets", "[", "i", "]", "[", "0", "]", ",", "dets", "[", "i", "]", "[", "1", "]", ",", "\n", "dets", "[", "i", "]", "[", "2", "]", ",", "dets", "[", "i", "]", "[", "3", "]", ",", "\n", "dets", "[", "i", "]", "[", "4", "]", ",", "dets", "[", "i", "]", "[", "5", "]", ",", "\n", "dets", "[", "i", "]", "[", "6", "]", ",", "dets", "[", "i", "]", "[", "7", "]", "]", ")", "\n", "polys", ".", "append", "(", "tm_polygon", ")", "\n", "", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "ovr", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.nms.nms.batched_nms_poly": [[37, 93], ["boxes.max", "boxes.min", "idxs.clone.clone", "boxes.clone", "boxes.clone.data.cpu().numpy", "scores.data.cpu().numpy", "numpy.hstack", "poly_nms.poly_gpu_nms", "boxes.numel", "torch.empty", "idxs.clone.to", "detectron2.get_local_rank", "boxes.clone.data.cpu", "scores.data.cpu", "scores.data.cpu().numpy.reshape"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["# if order.size == 0:", "\n", "#     break", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "# w = np.maximum(0.0, xx2 - xx1 + 1)", "\n", "# h = np.maximum(0.0, yy2 - yy1 + 1)", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", ")", "\n", "hbb_inter", "=", "w", "*", "h", "\n", "hbb_ovr", "=", "hbb_inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "hbb_inter", ")", "\n", "# h_keep_inds = np.where(hbb_ovr == 0)[0]", "\n", "h_inds", "=", "np", ".", "where", "(", "hbb_ovr", ">", "0", ")", "[", "0", "]", "\n", "tmp_order", "=", "order", "[", "h_inds", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "tmp_order", ".", "size", ")", ":", "\n", "            ", "iou", "=", "polyiou", ".", "iou_poly", "(", "polys", "[", "i", "]", ",", "polys", "[", "tmp_order", "[", "j", "]", "]", ")", "\n", "hbb_ovr", "[", "h_inds", "[", "j", "]", "]", "=", "iou", "\n", "# ovr.append(iou)", "\n", "# ovr_index.append(tmp_order[j])", "\n", "\n", "# ovr = np.array(ovr)", "\n", "# ovr_index = np.array(ovr_index)", "\n", "# print('ovr: ', ovr)", "\n", "# print('thresh: ', thresh)", "\n", "", "try", ":", "\n", "            ", "if", "math", ".", "isnan", "(", "ovr", "[", "0", "]", ")", ":", "\n", "                ", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "inds", "=", "np", ".", "where", "(", "hbb_ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "\n", "# order_obb = ovr_index[inds]", "\n", "# print('inds: ', inds)", "\n", "# order_hbb = order[h_keep_inds + 1]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "# pdb.set_trace()", "\n", "# order = np.concatenate((order_obb, order_hbb), axis=0).astype(np.int)", "\n", "", "return", "keep", "\n", "\n", "", "def", "py_cpu_nms", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Pure Python NMS baseline.\"\"\"", "\n", "#print('dets:', dets)", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "## index for dets", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.InvertedResidual.__init__": [[30, 61], ["torch.nn.Module.__init__", "int", "round", "torch.nn.Sequential", "torch.nn.Sequential", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inp", ",", "oup", ",", "stride", ",", "expand_ratio", ")", ":", "\n", "        ", "super", "(", "InvertedResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "\n", "hidden_dim", "=", "int", "(", "round", "(", "inp", "*", "expand_ratio", ")", ")", "\n", "self", ".", "use_res_connect", "=", "self", ".", "stride", "==", "1", "and", "inp", "==", "oup", "\n", "\n", "if", "expand_ratio", "==", "1", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "# dw", "\n", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "3", ",", "stride", ",", "1", ",", "groups", "=", "hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# pw-linear", "\n", "Conv2d", "(", "hidden_dim", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "# pw", "\n", "Conv2d", "(", "inp", ",", "hidden_dim", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# dw", "\n", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "3", ",", "stride", ",", "1", ",", "groups", "=", "hidden_dim", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", ",", "\n", "# pw-linear", "\n", "Conv2d", "(", "hidden_dim", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.InvertedResidual.forward": [[63, 68], ["mobilenet.InvertedResidual.conv", "mobilenet.InvertedResidual.conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "use_res_connect", ":", "\n", "            ", "return", "x", "+", "self", ".", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.MobileNetV2.__init__": [[74, 109], ["detectron2.modeling.backbone.Backbone.__init__", "int", "torch.nn.ModuleList", "mobilenet.MobileNetV2._initialize_weights", "mobilenet.MobileNetV2._freeze_backbone", "int", "range", "mobilenet.conv_bn", "mobilenet.MobileNetV2.features.append", "mobilenet.MobileNetV2.features.append", "mobilenet.MobileNetV2.return_features_num_channels.append", "block", "block", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet._initialize_weights", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_backbone", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.conv_bn", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "__init__", "(", "self", ",", "cfg", ",", "n_class", "=", "1000", ",", "input_size", "=", "224", ",", "width_mult", "=", "1.", ")", ":", "\n", "        ", "super", "(", "MobileNetV2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "block", "=", "InvertedResidual", "\n", "input_channel", "=", "32", "\n", "interverted_residual_setting", "=", "[", "\n", "# t, c, n, s", "\n", "[", "1", ",", "16", ",", "1", ",", "1", "]", ",", "\n", "[", "6", ",", "24", ",", "2", ",", "2", "]", ",", "\n", "[", "6", ",", "32", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "64", ",", "4", ",", "2", "]", ",", "\n", "[", "6", ",", "96", ",", "3", ",", "1", "]", ",", "\n", "[", "6", ",", "160", ",", "3", ",", "2", "]", ",", "\n", "[", "6", ",", "320", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "\n", "# building first layer", "\n", "assert", "input_size", "%", "32", "==", "0", "\n", "input_channel", "=", "int", "(", "input_channel", "*", "width_mult", ")", "\n", "self", ".", "return_features_indices", "=", "[", "3", ",", "6", ",", "13", ",", "17", "]", "\n", "self", ".", "return_features_num_channels", "=", "[", "]", "\n", "self", ".", "features", "=", "nn", ".", "ModuleList", "(", "[", "conv_bn", "(", "3", ",", "input_channel", ",", "2", ")", "]", ")", "\n", "# building inverted residual blocks", "\n", "for", "t", ",", "c", ",", "n", ",", "s", "in", "interverted_residual_setting", ":", "\n", "            ", "output_channel", "=", "int", "(", "c", "*", "width_mult", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "self", ".", "features", ".", "append", "(", "block", "(", "input_channel", ",", "output_channel", ",", "s", ",", "expand_ratio", "=", "t", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "features", ".", "append", "(", "block", "(", "input_channel", ",", "output_channel", ",", "1", ",", "expand_ratio", "=", "t", ")", ")", "\n", "", "input_channel", "=", "output_channel", "\n", "if", "len", "(", "self", ".", "features", ")", "-", "1", "in", "self", ".", "return_features_indices", ":", "\n", "                    ", "self", ".", "return_features_num_channels", ".", "append", "(", "output_channel", ")", "\n", "\n", "", "", "", "self", ".", "_initialize_weights", "(", ")", "\n", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.MobileNetV2._freeze_backbone": [[110, 114], ["range", "mobilenet.MobileNetV2.features[].parameters"], "methods", ["None"], ["", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "for", "layer_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "for", "p", "in", "self", ".", "features", "[", "layer_index", "]", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.MobileNetV2.forward": [[115, 122], ["enumerate", "m", "res.append", "enumerate"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "features", ")", ":", "\n", "            ", "x", "=", "m", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "return_features_indices", ":", "\n", "                ", "res", ".", "append", "(", "x", ")", "\n", "", "", "return", "{", "'res{}'", ".", "format", "(", "i", "+", "2", ")", ":", "r", "for", "i", ",", "r", "in", "enumerate", "(", "res", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.MobileNetV2._initialize_weights": [[123, 137], ["mobilenet.MobileNetV2.modules", "isinstance", "m.weight.data.normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.size", "m.weight.data.normal_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "_initialize_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "(", "2.", "/", "n", ")", "**", "0.5", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "n", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.conv_bn": [[13, 18], ["torch.nn.Sequential", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6"], "function", ["None"], ["def", "conv_bn", "(", "inp", ",", "oup", ",", "stride", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "inp", ",", "oup", ",", "3", ",", "stride", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.mobilenet.conv_1x1_bn": [[21, 26], ["torch.nn.Sequential", "detectron2.layers.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU6"], "function", ["None"], ["", "def", "conv_1x1_bn", "(", "inp", ",", "oup", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "Conv2d", "(", "inp", ",", "oup", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm2d", "(", "oup", ")", ",", "\n", "nn", ".", "ReLU6", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.fpn.LastLevelP6P7.__init__": [[22, 33], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "fvcore.c2_xavier_fill"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "in_features", "=", "\"res5\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_levels", "=", "2", "\n", "self", ".", "in_feature", "=", "in_features", "\n", "self", ".", "p6", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "p7", "=", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "for", "module", "in", "[", "self", ".", "p6", ",", "self", ".", "p7", "]", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "module", ")", "\n", "\n", "\n", "", "self", ".", "act", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.fpn.LastLevelP6P7.forward": [[34, 38], ["fpn.LastLevelP6P7.p6", "fpn.LastLevelP6P7.p7", "fpn.LastLevelP6P7.act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "p6", "=", "self", ".", "p6", "(", "x", ")", "\n", "p7", "=", "self", ".", "p7", "(", "self", ".", "act", "(", "p6", ")", ")", "\n", "return", "[", "p6", ",", "p7", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.fpn.LastLevelP6.__init__": [[45, 52], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "fvcore.c2_xavier_fill"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "in_features", "=", "\"res5\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_levels", "=", "1", "\n", "self", ".", "in_feature", "=", "in_features", "\n", "self", ".", "p6", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "3", ",", "2", ",", "1", ")", "\n", "for", "module", "in", "[", "self", ".", "p6", "]", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.fpn.LastLevelP6.forward": [[53, 56], ["fpn.LastLevelP6.p6"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "p6", "=", "self", ".", "p6", "(", "x", ")", "\n", "return", "[", "p6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.fpn.build_dafne_resnet_fpn_backbone": [[58, 92], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "detectron2.modeling.backbone.FPN", "resnet_lpf.build_resnet_lpf_backbone", "fpn.LastLevelP6P7", "fpn.LastLevelP6", "resnet_interval.build_resnet_interval_backbone", "detectron2.modeling.backbone.build_resnet_backbone"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.build_resnet_lpf_backbone", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_interval.build_resnet_interval_backbone"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_dafne_resnet_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "if", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "ANTI_ALIAS", ":", "\n", "        ", "bottom_up", "=", "build_resnet_lpf_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "", "elif", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_INTERVAL", ">", "1", ":", "\n", "        ", "bottom_up", "=", "build_resnet_interval_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "", "else", ":", "\n", "        ", "bottom_up", "=", "build_resnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "top_levels", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "TOP_LEVELS", "\n", "in_channels_top", "=", "out_channels", "\n", "if", "top_levels", "==", "2", ":", "\n", "        ", "top_block", "=", "LastLevelP6P7", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "if", "top_levels", "==", "1", ":", "\n", "        ", "top_block", "=", "LastLevelP6", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "elif", "top_levels", "==", "0", ":", "\n", "        ", "top_block", "=", "None", "\n", "", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "top_block", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_interval.make_stage_intervals": [[12, 37], ["kwargs.get", "range", "blocks.append", "blocks.append", "block_class", "detectron2.modeling.backbone.resnet.BottleneckBlock"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "make_stage_intervals", "(", "block_class", ",", "num_blocks", ",", "first_stride", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Create a resnet stage by creating many blocks.\n    Args:\n        block_class (class): a subclass of ResNetBlockBase\n        num_blocks (int):\n        first_stride (int): the stride of the first block. The other blocks will have stride=1.\n            A `stride` argument will be passed to the block constructor.\n        kwargs: other arguments passed to the block constructor.\n\n    Returns:\n        list[nn.Module]: a list of block module.\n    \"\"\"", "\n", "blocks", "=", "[", "]", "\n", "conv_kwargs", "=", "{", "key", ":", "kwargs", "[", "key", "]", "for", "key", "in", "kwargs", "if", "\"deform\"", "not", "in", "key", "}", "\n", "deform_kwargs", "=", "{", "key", ":", "kwargs", "[", "key", "]", "for", "key", "in", "kwargs", "if", "key", "!=", "\"deform_interval\"", "}", "\n", "deform_interval", "=", "kwargs", ".", "get", "(", "\"deform_interval\"", ",", "None", ")", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "        ", "if", "deform_interval", "and", "i", "%", "deform_interval", "==", "0", ":", "\n", "            ", "blocks", ".", "append", "(", "block_class", "(", "stride", "=", "first_stride", "if", "i", "==", "0", "else", "1", ",", "**", "deform_kwargs", ")", ")", "\n", "", "else", ":", "\n", "            ", "blocks", ".", "append", "(", "BottleneckBlock", "(", "stride", "=", "first_stride", "if", "i", "==", "0", "else", "1", ",", "**", "conv_kwargs", ")", ")", "\n", "", "conv_kwargs", "[", "\"in_channels\"", "]", "=", "conv_kwargs", "[", "\"out_channels\"", "]", "\n", "deform_kwargs", "[", "\"in_channels\"", "]", "=", "deform_kwargs", "[", "\"out_channels\"", "]", "\n", "", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_interval.build_resnet_interval_backbone": [[39, 117], ["detectron2.modeling.backbone.BACKBONE_REGISTRY.register", "detectron2.modeling.backbone.resnet.BasicStem", "max", "enumerate", "detectron2.modeling.backbone.resnet.ResNet", "FrozenBatchNorm2d.convert_frozen_batchnorm.parameters", "detectron2.layers.FrozenBatchNorm2d.convert_frozen_batchnorm", "range", "resnet_interval.make_stage_intervals", "stages.append", "block.freeze"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_interval.make_stage_intervals", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_resnet_interval_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a ResNet instance from config.\n\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    \"\"\"", "\n", "# need registration of new blocks/stems?", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "stem", "=", "BasicStem", "(", "\n", "in_channels", "=", "input_shape", ".", "channels", ",", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", ",", "\n", "norm", "=", "norm", ",", "\n", ")", "\n", "freeze_at", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "\n", "\n", "if", "freeze_at", ">=", "1", ":", "\n", "        ", "for", "p", "in", "stem", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "stem", "=", "FrozenBatchNorm2d", ".", "convert_frozen_batchnorm", "(", "stem", ")", "\n", "\n", "# fmt: off", "\n", "", "out_features", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "OUT_FEATURES", "\n", "depth", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEPTH", "\n", "num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NUM_GROUPS", "\n", "width_per_group", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "WIDTH_PER_GROUP", "\n", "bottleneck_channels", "=", "num_groups", "*", "width_per_group", "\n", "in_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STEM_OUT_CHANNELS", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES2_OUT_CHANNELS", "\n", "stride_in_1x1", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "STRIDE_IN_1X1", "\n", "res5_dilation", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "RES5_DILATION", "\n", "deform_on_per_stage", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_ON_PER_STAGE", "\n", "deform_modulated", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_MODULATED", "\n", "deform_num_groups", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_NUM_GROUPS", "\n", "deform_interval", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEFORM_INTERVAL", "\n", "# fmt: on", "\n", "assert", "res5_dilation", "in", "{", "1", ",", "2", "}", ",", "\"res5_dilation cannot be {}.\"", ".", "format", "(", "res5_dilation", ")", "\n", "\n", "num_blocks_per_stage", "=", "{", "50", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "101", ":", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "152", ":", "[", "3", ",", "8", ",", "36", ",", "3", "]", "}", "[", "depth", "]", "\n", "\n", "stages", "=", "[", "]", "\n", "\n", "# Avoid creating variables without gradients", "\n", "# It consumes extra memory and may cause allreduce to fail", "\n", "out_stage_idx", "=", "[", "{", "\"res2\"", ":", "2", ",", "\"res3\"", ":", "3", ",", "\"res4\"", ":", "4", ",", "\"res5\"", ":", "5", "}", "[", "f", "]", "for", "f", "in", "out_features", "]", "\n", "max_stage_idx", "=", "max", "(", "out_stage_idx", ")", "\n", "for", "idx", ",", "stage_idx", "in", "enumerate", "(", "range", "(", "2", ",", "max_stage_idx", "+", "1", ")", ")", ":", "\n", "        ", "dilation", "=", "res5_dilation", "if", "stage_idx", "==", "5", "else", "1", "\n", "first_stride", "=", "1", "if", "idx", "==", "0", "or", "(", "stage_idx", "==", "5", "and", "dilation", "==", "2", ")", "else", "2", "\n", "stage_kargs", "=", "{", "\n", "\"num_blocks\"", ":", "num_blocks_per_stage", "[", "idx", "]", ",", "\n", "\"first_stride\"", ":", "first_stride", ",", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"bottleneck_channels\"", ":", "bottleneck_channels", ",", "\n", "\"out_channels\"", ":", "out_channels", ",", "\n", "\"num_groups\"", ":", "num_groups", ",", "\n", "\"norm\"", ":", "norm", ",", "\n", "\"stride_in_1x1\"", ":", "stride_in_1x1", ",", "\n", "\"dilation\"", ":", "dilation", ",", "\n", "}", "\n", "if", "deform_on_per_stage", "[", "idx", "]", ":", "\n", "            ", "stage_kargs", "[", "\"block_class\"", "]", "=", "DeformBottleneckBlock", "\n", "stage_kargs", "[", "\"deform_modulated\"", "]", "=", "deform_modulated", "\n", "stage_kargs", "[", "\"deform_num_groups\"", "]", "=", "deform_num_groups", "\n", "stage_kargs", "[", "\"deform_interval\"", "]", "=", "deform_interval", "\n", "", "else", ":", "\n", "            ", "stage_kargs", "[", "\"block_class\"", "]", "=", "BottleneckBlock", "\n", "", "blocks", "=", "make_stage_intervals", "(", "**", "stage_kargs", ")", "\n", "in_channels", "=", "out_channels", "\n", "out_channels", "*=", "2", "\n", "bottleneck_channels", "*=", "2", "\n", "\n", "if", "freeze_at", ">=", "stage_idx", ":", "\n", "            ", "for", "block", "in", "blocks", ":", "\n", "                ", "block", ".", "freeze", "(", ")", "\n", "", "", "stages", ".", "append", "(", "blocks", ")", "\n", "", "return", "ResNet", "(", "stem", ",", "stages", ",", "out_features", "=", "out_features", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._NewEmptyTensorOp.forward": [[30, 34], ["x.new_empty"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._NewEmptyTensorOp.backward": [[35, 39], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._Conv2d.__init__": [[42, 70], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.Conv2d.__init__", "max", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "image_size", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "padding_mode", "=", "padding_mode", "\n", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "\n", "# pading format:", "\n", "#     tuple(pad_l, pad_r, pad_t, pad_b) or default", "\n", "if", "padding_mode", "==", "\"static_same\"", ":", "\n", "            ", "p", "=", "max", "(", "kernel_size", "[", "0", "]", "-", "stride", "[", "0", "]", ",", "0", ")", "\n", "padding", "=", "(", "p", "//", "2", ",", "p", "-", "p", "//", "2", ",", "p", "//", "2", ",", "p", "-", "p", "//", "2", ")", "\n", "", "elif", "padding_mode", "==", "\"dynamic_same\"", ":", "\n", "            ", "padding", "=", "_pair", "(", "0", ")", "\n", "", "super", "(", "_Conv2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ",", "bias", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._Conv2d.conv2d_forward": [[72, 100], ["torch.nn.functional.conv2d", "torch.nn.functional.pad", "torch.nn.modules.utils._pair", "max", "max", "x.size", "layers._Conv2d.weight.size", "math.ceil", "math.ceil", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "conv2d_forward", "(", "self", ",", "input", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "padding_mode", "==", "\"circular\"", ":", "\n", "            ", "expanded_padding", "=", "(", "\n", "(", "self", ".", "padding", "[", "1", "]", "+", "1", ")", "//", "2", ",", "\n", "self", ".", "padding", "[", "1", "]", "//", "2", ",", "\n", "(", "self", ".", "padding", "[", "0", "]", "+", "1", ")", "//", "2", ",", "\n", "self", ".", "padding", "[", "0", "]", "//", "2", ",", "\n", ")", "\n", "input", "=", "F", ".", "pad", "(", "input", ",", "expanded_padding", ",", "mode", "=", "\"circular\"", ")", "\n", "\n", "", "elif", "self", ".", "padding_mode", "==", "\"dynamic_same\"", ":", "\n", "            ", "ih", ",", "iw", "=", "x", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "kh", ",", "kw", "=", "self", ".", "weight", ".", "size", "(", ")", "[", "-", "2", ":", "]", "\n", "sh", ",", "sw", "=", "self", ".", "stride", "\n", "oh", ",", "ow", "=", "math", ".", "ceil", "(", "ih", "/", "sh", ")", ",", "math", ".", "ceil", "(", "iw", "/", "sw", ")", "\n", "pad_h", "=", "max", "(", "(", "oh", "-", "1", ")", "*", "self", ".", "stride", "[", "0", "]", "+", "(", "kh", "-", "1", ")", "*", "self", ".", "dilation", "[", "0", "]", "+", "1", "-", "ih", ",", "0", ")", "\n", "pad_w", "=", "max", "(", "(", "ow", "-", "1", ")", "*", "self", ".", "stride", "[", "1", "]", "+", "(", "kw", "-", "1", ")", "*", "self", ".", "dilation", "[", "1", "]", "+", "1", "-", "iw", ",", "0", ")", "\n", "if", "pad_h", ">", "0", "or", "pad_w", ">", "0", ":", "\n", "                ", "input", "=", "F", ".", "pad", "(", "\n", "input", ",", "[", "pad_w", "//", "2", ",", "pad_w", "-", "pad_w", "//", "2", ",", "pad_h", "//", "2", ",", "pad_h", "-", "pad_h", "//", "2", "]", "\n", ")", "\n", "\n", "", "", "elif", "self", ".", "padding_mode", "==", "\"static_same\"", ":", "\n", "            ", "input", "=", "F", ".", "pad", "(", "input", ",", "self", ".", "padding", ")", "\n", "", "else", ":", "# default padding", "\n", "            ", "input", "=", "F", ".", "pad", "(", "input", ",", "self", ".", "padding", ")", "\n", "\n", "", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "_pair", "(", "0", ")", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._Conv2d.forward": [[101, 103], ["layers._Conv2d.conv2d_forward"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._Conv2d.conv2d_forward"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "conv2d_forward", "(", "input", ",", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers._Conv2d.__repr__": [[104, 119], ["len", "len", "len", "s.format"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"{in_channels}, {out_channels}, kernel_size={kernel_size}\"", "\", stride={stride}\"", "\n", "if", "self", ".", "padding", "!=", "(", "0", ",", ")", "*", "len", "(", "self", ".", "padding", ")", ":", "\n", "            ", "s", "+=", "\", padding={padding}\"", "\n", "", "if", "self", ".", "dilation", "!=", "(", "1", ",", ")", "*", "len", "(", "self", ".", "dilation", ")", ":", "\n", "            ", "s", "+=", "\", dilation={dilation}\"", "\n", "", "if", "self", ".", "output_padding", "!=", "(", "0", ",", ")", "*", "len", "(", "self", ".", "output_padding", ")", ":", "\n", "            ", "s", "+=", "\", output_padding={output_padding}\"", "\n", "", "if", "self", ".", "groups", "!=", "1", ":", "\n", "            ", "s", "+=", "\", groups={groups}\"", "\n", "", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "\", bias=False\"", "\n", "", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "s", "+=", "\", padding_mode={padding_mode}\"", "\n", "", "return", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "+", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.Conv2d.__init__": [[126, 142], ["kwargs.pop", "kwargs.pop", "layers._Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.pop", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Extra keyword arguments supported in addition to those in `torch.nn.Conv2d`:\n\n        Args:\n            norm (nn.Module, optional): a normalization layer\n            activation (callable(Tensor) -> Tensor): a callable activation function\n\n        It assumes that norm layer is used before activation.\n        \"\"\"", "\n", "norm", "=", "kwargs", ".", "pop", "(", "\"norm\"", ",", "None", ")", "\n", "activation", "=", "kwargs", ".", "pop", "(", "\"activation\"", ",", "None", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.Conv2d.forward": [[143, 180], ["layers._Conv2d.forward", "_NewEmptyTensorOp.apply", "layers.Conv2d.norm", "layers.Conv2d.activation", "layers.Conv2d.numel", "isinstance", "layers.Conv2d.numel", "isinstance", "zip", "sum", "layers.Conv2d.view", "layers.Conv2d.parameters"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", "==", "0", "and", "self", ".", "training", ":", "\n", "# https://github.com/pytorch/pytorch/issues/12013", "\n", "            ", "assert", "not", "isinstance", "(", "\n", "self", ".", "norm", ",", "torch", ".", "nn", ".", "SyncBatchNorm", "\n", ")", ",", "\"SyncBatchNorm does not support empty inputs!\"", "\n", "\n", "", "if", "x", ".", "numel", "(", ")", "==", "0", "and", "TORCH_VERSION", "<=", "(", "1", ",", "4", ")", ":", "\n", "            ", "assert", "not", "isinstance", "(", "\n", "self", ".", "norm", ",", "torch", ".", "nn", ".", "GroupNorm", "\n", ")", ",", "\"GroupNorm does not support empty inputs in PyTorch <=1.4!\"", "\n", "# When input is empty, we want to return a empty tensor with \"correct\" shape,", "\n", "# So that the following operations will not panic", "\n", "# if they check for the shape of the tensor.", "\n", "# This computes the height and width of the output tensor", "\n", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "s", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "s", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "empty", "=", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "if", "self", ".", "training", ":", "\n", "# This is to make DDP happy.", "\n", "# DDP expects all workers to have gradient w.r.t the same set of parameters.", "\n", "                ", "_dummy", "=", "sum", "(", "x", ".", "view", "(", "-", "1", ")", "[", "0", "]", "for", "x", "in", "self", ".", "parameters", "(", ")", ")", "*", "0.0", "\n", "return", "empty", "+", "_dummy", "\n", "", "else", ":", "\n", "                ", "return", "empty", "\n", "\n", "", "", "x", "=", "super", "(", ")", ".", "forward", "(", "x", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SeparableConv2d.__init__": [[183, 232], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "layers.Conv2d", "layers.Conv2d", "detectron2.layers.batch_norm.get_norm"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "padding_mode", "=", "\"zeros\"", ",", "\n", "norm", "=", "None", ",", "\n", "eps", "=", "1e-05", ",", "\n", "momentum", "=", "0.1", ",", "\n", "activation", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "SeparableConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "\n", "self", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "self", ".", "groups", "=", "in_channels", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n", "self", ".", "depthwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "in_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "groups", "=", "in_channels", ",", "\n", "bias", "=", "False", ",", "\n", "padding_mode", "=", "padding_mode", ",", "\n", ")", "\n", "self", ".", "pointwise", "=", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "1", ",", "1", ",", "0", ",", "1", ",", "1", ",", "bias", "=", "bias", ",", "padding_mode", "=", "padding_mode", "\n", ")", "\n", "\n", "self", ".", "padding", "=", "self", ".", "depthwise", ".", "padding", "\n", "self", ".", "norm", "=", "None", "if", "norm", "==", "\"\"", "else", "norm", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", "\n", "assert", "self", ".", "norm", "!=", "None", "\n", "self", ".", "norm", ".", "eps", "=", "eps", "\n", "self", ".", "norm", ".", "momentum", "=", "momentum", "\n", "", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SeparableConv2d.forward": [[233, 241], ["layers.SeparableConv2d.depthwise", "layers.SeparableConv2d.pointwise", "layers.SeparableConv2d.norm", "layers.SeparableConv2d.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "depthwise", "(", "x", ")", "\n", "x", "=", "self", ".", "pointwise", "(", "x", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SeparableConv2d.__repr__": [[242, 260], ["len", "len", "layers.SeparableConv2d.norm.__repr__", "s.format", "s.format"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SeparableConv2d.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "\n", "        ", "s", "=", "\"{in_channels}, {out_channels}, kernel_size={kernel_size}\"", "\", stride={stride}\"", "\n", "if", "self", ".", "padding", "!=", "(", "0", ",", ")", "*", "len", "(", "self", ".", "padding", ")", ":", "\n", "            ", "s", "+=", "\", padding={padding}\"", "\n", "", "if", "self", ".", "dilation", "!=", "(", "1", ",", ")", "*", "len", "(", "self", ".", "dilation", ")", ":", "\n", "            ", "s", "+=", "\", dilation={dilation}\"", "\n", "", "if", "self", ".", "groups", "!=", "1", ":", "\n", "            ", "s", "+=", "\", groups={groups}\"", "\n", "", "if", "self", ".", "pointwise", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "\", bias=False\"", "\n", "", "if", "self", ".", "padding_mode", "!=", "\"zeros\"", ":", "\n", "            ", "s", "+=", "\", padding_mode={padding_mode}\"", "\n", "", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "s", "=", "\"  \"", "+", "s", "+", "\"\\n    norm=\"", "+", "self", ".", "norm", ".", "__repr__", "(", ")", "\n", "return", "self", ".", "__class__", ".", "__name__", "+", "\"(\\n  \"", "+", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "+", "\"\\n)\"", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "+", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.MaxPool2d.__init__": [[263, 290], ["torch.nn.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "max", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "None", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "return_indices", "=", "False", ",", "\n", "ceil_mode", "=", "False", ",", "\n", "padding_mode", "=", "\"static_same\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "MaxPool2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "self", ".", "stride", "=", "_pair", "(", "stride", ")", "or", "self", ".", "kernel_size", "\n", "self", ".", "padding", "=", "_pair", "(", "padding", ")", "\n", "self", ".", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "self", ".", "return_indices", "=", "return_indices", "\n", "self", ".", "ceil_mode", "=", "ceil_mode", "\n", "self", ".", "padding_mode", "=", "padding_mode", "\n", "\n", "if", "padding_mode", "==", "\"static_same\"", ":", "\n", "            ", "p", "=", "max", "(", "self", ".", "kernel_size", "[", "0", "]", "-", "self", ".", "stride", "[", "0", "]", ",", "0", ")", "\n", "# tuple(pad_l, pad_r, pad_t, pad_b)", "\n", "padding", "=", "(", "p", "//", "2", ",", "p", "-", "p", "//", "2", ",", "p", "//", "2", ",", "p", "-", "p", "//", "2", ")", "\n", "self", ".", "padding", "=", "padding", "\n", "", "elif", "padding_mode", "==", "\"dynamic_same\"", ":", "\n", "            ", "padding", "=", "_pair", "(", "0", ")", "\n", "self", ".", "padding", "=", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.MaxPool2d.forward": [[291, 301], ["torch.nn.functional.pad", "torch.nn.functional.max_pool2d", "torch.nn.modules.utils._pair"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "input", "=", "F", ".", "pad", "(", "input", ",", "self", ".", "padding", ")", "\n", "return", "F", ".", "max_pool2d", "(", "\n", "input", ",", "\n", "self", ".", "kernel_size", ",", "\n", "self", ".", "stride", ",", "\n", "_pair", "(", "0", ")", ",", "\n", "self", ".", "dilation", ",", "\n", "self", ".", "ceil_mode", ",", "\n", "self", ".", "return_indices", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.MaxPool2d.extra_repr": [[303, 308], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "\"kernel_size={kernel_size}, stride={stride}, padding={padding}\"", "\n", "\", dilation={dilation}, ceil_mode={ceil_mode}, padding_mode={padding_mode}\"", ".", "format", "(", "\n", "**", "self", ".", "__dict__", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SwishImplementation.forward": [[313, 318], ["ctx.save_for_backward", "torch.sigmoid"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "i", ")", ":", "\n", "        ", "result", "=", "i", "*", "torch", ".", "sigmoid", "(", "i", ")", "\n", "ctx", ".", "save_for_backward", "(", "i", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.SwishImplementation.backward": [[319, 324], ["torch.sigmoid"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "i", "=", "ctx", ".", "saved_variables", "[", "0", "]", "\n", "sigmoid_i", "=", "torch", ".", "sigmoid", "(", "i", ")", "\n", "return", "grad_output", "*", "(", "sigmoid_i", "*", "(", "1", "+", "i", "*", "(", "1", "-", "sigmoid_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.MemoryEfficientSwish.forward": [[327, 329], ["SwishImplementation.apply"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "SwishImplementation", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.layers.Swish.forward": [[332, 334], ["torch.sigmoid"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.BasicBlock.__init__": [[39, 51], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn1", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn2", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.BasicBlock.forward": [[52, 67], ["dla.BasicBlock.conv1", "dla.BasicBlock.bn1", "dla.BasicBlock.relu", "dla.BasicBlock.conv2", "dla.BasicBlock.bn2", "dla.BasicBlock.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "residual", "=", "None", ")", ":", "\n", "        ", "if", "residual", "is", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Bottleneck.__init__": [[72, 88], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "expansion", "=", "Bottleneck", ".", "expansion", "\n", "bottle_planes", "=", "planes", "//", "expansion", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "bottle_planes", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "bottle_planes", ",", "bottle_planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn2", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "bottle_planes", ",", "planes", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Bottleneck.forward": [[89, 108], ["dla.Bottleneck.conv1", "dla.Bottleneck.bn1", "dla.Bottleneck.relu", "dla.Bottleneck.conv2", "dla.Bottleneck.bn2", "dla.Bottleneck.relu", "dla.Bottleneck.conv3", "dla.Bottleneck.bn3", "dla.Bottleneck.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "residual", "=", "None", ")", ":", "\n", "        ", "if", "residual", "is", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.BottleneckX.__init__": [[114, 132], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "BottleneckX", ",", "self", ")", ".", "__init__", "(", ")", "\n", "cardinality", "=", "BottleneckX", ".", "cardinality", "\n", "# dim = int(math.floor(planes * (BottleneckV5.expansion / 64.0)))", "\n", "# bottle_planes = dim * cardinality", "\n", "bottle_planes", "=", "planes", "*", "cardinality", "//", "32", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "bottle_planes", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "bottle_planes", ",", "bottle_planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ",", "groups", "=", "cardinality", ")", "\n", "self", ".", "bn2", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "bottle_planes", ",", "planes", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.BottleneckX.forward": [[133, 152], ["dla.BottleneckX.conv1", "dla.BottleneckX.bn1", "dla.BottleneckX.relu", "dla.BottleneckX.conv2", "dla.BottleneckX.bn2", "dla.BottleneckX.relu", "dla.BottleneckX.conv3", "dla.BottleneckX.bn3", "dla.BottleneckX.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "residual", "=", "None", ")", ":", "\n", "        ", "if", "residual", "is", "None", ":", "\n", "            ", "residual", "=", "x", "\n", "\n", "", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Root.__init__": [[155, 163], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "residual", ")", ":", "\n", "        ", "super", "(", "Root", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "stride", "=", "1", ",", "bias", "=", "False", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ")", "\n", "self", ".", "bn", "=", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "out_channels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "residual", "=", "residual", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Root.forward": [[164, 173], ["dla.Root.conv", "dla.Root.bn", "dla.Root.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "x", ")", ":", "\n", "        ", "children", "=", "x", "\n", "x", "=", "self", ".", "conv", "(", "torch", ".", "cat", "(", "x", ",", "1", ")", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "if", "self", ".", "residual", ":", "\n", "            ", "x", "+=", "children", "[", "0", "]", "\n", "", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Tree.__init__": [[176, 213], ["torch.nn.Module.__init__", "block", "block", "dla.Tree", "dla.Tree", "dla.Root", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "levels", ",", "block", ",", "in_channels", ",", "out_channels", ",", "stride", "=", "1", ",", "\n", "level_root", "=", "False", ",", "root_dim", "=", "0", ",", "root_kernel_size", "=", "1", ",", "\n", "dilation", "=", "1", ",", "root_residual", "=", "False", ")", ":", "\n", "        ", "super", "(", "Tree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "root_dim", "==", "0", ":", "\n", "            ", "root_dim", "=", "2", "*", "out_channels", "\n", "", "if", "level_root", ":", "\n", "            ", "root_dim", "+=", "in_channels", "\n", "", "if", "levels", "==", "1", ":", "\n", "            ", "self", ".", "tree1", "=", "block", "(", "cfg", ",", "in_channels", ",", "out_channels", ",", "stride", ",", "\n", "dilation", "=", "dilation", ")", "\n", "self", ".", "tree2", "=", "block", "(", "cfg", ",", "out_channels", ",", "out_channels", ",", "1", ",", "\n", "dilation", "=", "dilation", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tree1", "=", "Tree", "(", "cfg", ",", "levels", "-", "1", ",", "block", ",", "in_channels", ",", "out_channels", ",", "\n", "stride", ",", "root_dim", "=", "0", ",", "\n", "root_kernel_size", "=", "root_kernel_size", ",", "\n", "dilation", "=", "dilation", ",", "root_residual", "=", "root_residual", ")", "\n", "self", ".", "tree2", "=", "Tree", "(", "cfg", ",", "levels", "-", "1", ",", "block", ",", "out_channels", ",", "out_channels", ",", "\n", "root_dim", "=", "root_dim", "+", "out_channels", ",", "\n", "root_kernel_size", "=", "root_kernel_size", ",", "\n", "dilation", "=", "dilation", ",", "root_residual", "=", "root_residual", ")", "\n", "", "if", "levels", "==", "1", ":", "\n", "            ", "self", ".", "root", "=", "Root", "(", "cfg", ",", "root_dim", ",", "out_channels", ",", "root_kernel_size", ",", "\n", "root_residual", ")", "\n", "", "self", ".", "level_root", "=", "level_root", "\n", "self", ".", "root_dim", "=", "root_dim", "\n", "self", ".", "downsample", "=", "None", "\n", "self", ".", "project", "=", "None", "\n", "self", ".", "levels", "=", "levels", "\n", "if", "stride", ">", "1", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "MaxPool2d", "(", "stride", ",", "stride", "=", "stride", ")", "\n", "", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "project", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "out_channels", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.Tree.forward": [[215, 231], ["dla.Tree.tree1", "dla.Tree.downsample", "dla.Tree.project", "children.append", "dla.Tree.tree2", "dla.Tree.root", "children.append", "dla.Tree.tree2", "residual.sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "residual", "=", "None", ",", "children", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "training", "and", "residual", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "+", "residual", ".", "sum", "(", ")", "*", "0.0", "\n", "", "children", "=", "[", "]", "if", "children", "is", "None", "else", "children", "\n", "bottom", "=", "self", ".", "downsample", "(", "x", ")", "if", "self", ".", "downsample", "else", "x", "\n", "residual", "=", "self", ".", "project", "(", "bottom", ")", "if", "self", ".", "project", "else", "bottom", "\n", "if", "self", ".", "level_root", ":", "\n", "            ", "children", ".", "append", "(", "bottom", ")", "\n", "", "x1", "=", "self", ".", "tree1", "(", "x", ",", "residual", ")", "\n", "if", "self", ".", "levels", "==", "1", ":", "\n", "            ", "x2", "=", "self", ".", "tree2", "(", "x1", ")", "\n", "x", "=", "self", ".", "root", "(", "x2", ",", "x1", ",", "*", "children", ")", "\n", "", "else", ":", "\n", "            ", "children", ".", "append", "(", "x1", ")", "\n", "x", "=", "self", ".", "tree2", "(", "x1", ",", "children", "=", "children", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA.__init__": [[234, 270], ["detectron2.modeling.backbone.Backbone.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "dla.DLA._make_conv_level", "dla.DLA._make_conv_level", "dla.Tree", "dla.Tree", "dla.Tree", "dla.Tree", "dla.DLA.modules", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "isinstance", "range", "enumerate", "enumerate", "m.weight.data.normal_", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA._make_conv_level", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA._make_conv_level"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "levels", ",", "channels", ",", "block", "=", "BasicBlock", ",", "residual_root", "=", "False", ")", ":", "\n", "        ", "super", "(", "DLA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "channels", "=", "channels", "\n", "\n", "self", ".", "_out_features", "=", "[", "\"level{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "6", ")", "]", "\n", "self", ".", "_out_feature_channels", "=", "{", "k", ":", "channels", "[", "i", "]", "for", "i", ",", "k", "in", "enumerate", "(", "self", ".", "_out_features", ")", "}", "\n", "self", ".", "_out_feature_strides", "=", "{", "k", ":", "2", "**", "i", "for", "i", ",", "k", "in", "enumerate", "(", "self", ".", "_out_features", ")", "}", "\n", "\n", "self", ".", "base_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "channels", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "\n", "padding", "=", "3", ",", "bias", "=", "False", ")", ",", "\n", "get_norm", "(", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "channels", "[", "0", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "level0", "=", "self", ".", "_make_conv_level", "(", "\n", "channels", "[", "0", "]", ",", "channels", "[", "0", "]", ",", "levels", "[", "0", "]", ")", "\n", "self", ".", "level1", "=", "self", ".", "_make_conv_level", "(", "\n", "channels", "[", "0", "]", ",", "channels", "[", "1", "]", ",", "levels", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "level2", "=", "Tree", "(", "cfg", ",", "levels", "[", "2", "]", ",", "block", ",", "channels", "[", "1", "]", ",", "channels", "[", "2", "]", ",", "2", ",", "\n", "level_root", "=", "False", ",", "\n", "root_residual", "=", "residual_root", ")", "\n", "self", ".", "level3", "=", "Tree", "(", "cfg", ",", "levels", "[", "3", "]", ",", "block", ",", "channels", "[", "2", "]", ",", "channels", "[", "3", "]", ",", "2", ",", "\n", "level_root", "=", "True", ",", "root_residual", "=", "residual_root", ")", "\n", "self", ".", "level4", "=", "Tree", "(", "cfg", ",", "levels", "[", "4", "]", ",", "block", ",", "channels", "[", "3", "]", ",", "channels", "[", "4", "]", ",", "2", ",", "\n", "level_root", "=", "True", ",", "root_residual", "=", "residual_root", ")", "\n", "self", ".", "level5", "=", "Tree", "(", "cfg", ",", "levels", "[", "5", "]", ",", "block", ",", "channels", "[", "4", "]", ",", "channels", "[", "5", "]", ",", "2", ",", "\n", "level_root", "=", "True", ",", "root_residual", "=", "residual_root", ")", "\n", "\n", "# self.avgpool = nn.AvgPool2d(pool_size)", "\n", "# self.fc = nn.Conv2d(channels[-1], num_classes, kernel_size=1,", "\n", "#                     stride=1, padding=0, bias=True)", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA._make_level": [[271, 287], ["layers.append", "range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "block", "layers.append", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "block"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "", "", "def", "_make_level", "(", "self", ",", "block", ",", "inplanes", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool2d", "(", "stride", ",", "stride", "=", "stride", ")", ",", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "get_norm", "(", "self", ".", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "inplanes", ",", "planes", ",", "stride", ",", "downsample", "=", "downsample", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA._make_conv_level": [[288, 299], ["range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "modules.extend", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "detectron2.layers.batch_norm.get_norm", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["None"], ["", "def", "_make_conv_level", "(", "self", ",", "inplanes", ",", "planes", ",", "convs", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "modules", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "convs", ")", ":", "\n", "            ", "modules", ".", "extend", "(", "[", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", "if", "i", "==", "0", "else", "1", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", ",", "\n", "get_norm", "(", "self", ".", "cfg", ".", "MODEL", ".", "DLA", ".", "NORM", ",", "planes", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", ")", "\n", "inplanes", "=", "planes", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.DLA.forward": [[300, 308], ["dla.DLA.base_layer", "range", "getattr"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "{", "}", "\n", "x", "=", "self", ".", "base_layer", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "            ", "name", "=", "'level{}'", ".", "format", "(", "i", ")", "\n", "x", "=", "getattr", "(", "self", ",", "name", ")", "(", "x", ")", "\n", "y", "[", "name", "]", "=", "x", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.get_model_url": [[27, 30], ["os.path.join"], "function", ["None"], ["def", "get_model_url", "(", "data", ",", "name", ")", ":", "\n", "    ", "return", "join", "(", "WEB_ROOT", ",", "data", ".", "name", ",", "\n", "'{}-{}.pth'", ".", "format", "(", "name", ",", "data", ".", "model_hash", "[", "name", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.conv3x3": [[32, 36], ["torch.nn.Conv2d"], "function", ["None"], ["", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla34": [[310, 317], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "", "def", "dla34", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-34", "\n", "    ", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "block", "=", "BasicBlock", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla34'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla46_c": [[319, 327], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla46_c", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-46-C", "\n", "    ", "Bottleneck", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "Bottleneck", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla46_c'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla46x_c": [[329, 337], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla46x_c", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-X-46-C", "\n", "    ", "BottleneckX", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "BottleneckX", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla46x_c'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla60x_c": [[339, 347], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla60x_c", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-X-60-C", "\n", "    ", "BottleneckX", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "64", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "block", "=", "BottleneckX", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla60x_c'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla60": [[349, 357], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla60", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-60", "\n", "    ", "Bottleneck", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "Bottleneck", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla60'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla60x": [[359, 367], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla60x", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-X-60", "\n", "    ", "BottleneckX", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", ",", "1", "]", ",", "\n", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "BottleneckX", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla60x'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla102": [[369, 376], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla102", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-102", "\n", "    ", "Bottleneck", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "Bottleneck", ",", "residual_root", "=", "True", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla102'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla102x": [[378, 385], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla102x", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-X-102", "\n", "    ", "BottleneckX", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "BottleneckX", ",", "residual_root", "=", "True", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla102x'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla102x2": [[387, 394], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla102x2", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-X-102 64", "\n", "    ", "BottleneckX", ".", "cardinality", "=", "64", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "1", ",", "3", ",", "4", ",", "1", "]", ",", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "BottleneckX", ",", "residual_root", "=", "True", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla102x2'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.dla169": [[396, 403], ["dla.DLA", "DLA.load_pretrained_model"], "function", ["None"], ["", "def", "dla169", "(", "cfg", ",", "pretrained", "=", "None", ",", "**", "kwargs", ")", ":", "# DLA-169", "\n", "    ", "Bottleneck", ".", "expansion", "=", "2", "\n", "model", "=", "DLA", "(", "cfg", ",", "[", "1", ",", "1", ",", "2", ",", "3", ",", "5", ",", "1", "]", ",", "[", "16", ",", "32", ",", "128", ",", "256", ",", "512", ",", "1024", "]", ",", "\n", "block", "=", "Bottleneck", ",", "residual_root", "=", "True", ",", "**", "kwargs", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_pretrained_model", "(", "pretrained", ",", "'dla169'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.dla.build_dafne_dla_fpn_backbone": [[405, 442], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "detectron2.modeling.backbone.FPN", "fpn.LastLevelP6P7", "fpn.LastLevelP6", "NotImplementedError"], "function", ["None"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_dafne_dla_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "assert", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "==", "-", "1", ",", "\"Freezing layers does not be supported for DLA\"", "\n", "\n", "depth_to_creator", "=", "{", "\"DLA34\"", ":", "dla34", "}", "\n", "bottom_up", "=", "depth_to_creator", "[", "cfg", ".", "MODEL", ".", "DLA", ".", "CONV_BODY", "]", "(", "cfg", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "top_levels", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "TOP_LEVELS", "\n", "in_channels_top", "=", "out_channels", "\n", "\n", "if", "top_levels", "==", "2", ":", "\n", "        ", "top_block", "=", "LastLevelP6P7", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "elif", "top_levels", "==", "1", ":", "\n", "        ", "top_block", "=", "LastLevelP6", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "elif", "top_levels", "==", "0", ":", "\n", "        ", "top_block", "=", "None", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "top_block", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "\n", "return", "backbone", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.Downsample.__init__": [[9, 40], ["torch.Module.__init__", "int", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "lpf.Downsample.register_buffer", "int", "int", "int", "int", "numpy.array", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "filt[].repeat", "lpf.get_pad_layer", "numpy.ceil", "numpy.ceil", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.get_pad_layer"], ["    ", "def", "__init__", "(", "self", ",", "pad_type", "=", "'reflect'", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ",", "channels", "=", "None", ",", "pad_off", "=", "0", ")", ":", "\n", "        ", "super", "(", "Downsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filt_size", "=", "filt_size", "\n", "self", ".", "pad_off", "=", "pad_off", "\n", "self", ".", "pad_sizes", "=", "[", "int", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ",", "int", "(", "np", ".", "ceil", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ")", ",", "int", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ",", "int", "(", "np", ".", "ceil", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ")", "]", "\n", "self", ".", "pad_sizes", "=", "[", "pad_size", "+", "pad_off", "for", "pad_size", "in", "self", ".", "pad_sizes", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "off", "=", "int", "(", "(", "self", ".", "stride", "-", "1", ")", "/", "2.", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "\n", "# print('Filter size [%i]'%filt_size)", "\n", "if", "(", "self", ".", "filt_size", "==", "1", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "2", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "3", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "2.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "4", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "3.", ",", "3.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "5", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "4.", ",", "6.", ",", "4.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "6", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "5.", ",", "10.", ",", "10.", ",", "5.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "7", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "6.", ",", "15.", ",", "20.", ",", "15.", ",", "6.", ",", "1.", "]", ")", "\n", "\n", "", "filt", "=", "torch", ".", "Tensor", "(", "a", "[", ":", ",", "None", "]", "*", "a", "[", "None", ",", ":", "]", ")", "\n", "filt", "=", "filt", "/", "torch", ".", "sum", "(", "filt", ")", "\n", "self", ".", "register_buffer", "(", "'filt'", ",", "filt", "[", "None", ",", "None", ",", ":", ",", ":", "]", ".", "repeat", "(", "(", "self", ".", "channels", ",", "1", ",", "1", ",", "1", ")", ")", ")", "\n", "\n", "self", ".", "pad", "=", "get_pad_layer", "(", "pad_type", ")", "(", "self", ".", "pad_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.Downsample.forward": [[41, 49], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "lpf.Downsample.pad", "lpf.Downsample.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "(", "self", ".", "filt_size", "==", "1", ")", ":", "\n", "            ", "if", "(", "self", ".", "pad_off", "==", "0", ")", ":", "\n", "                ", "return", "inp", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "pad", "(", "inp", ")", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "F", ".", "conv2d", "(", "self", ".", "pad", "(", "inp", ")", ",", "self", ".", "filt", ",", "stride", "=", "self", ".", "stride", ",", "groups", "=", "inp", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.Downsample1D.__init__": [[63, 94], ["torch.Module.__init__", "int", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "lpf.Downsample1D.register_buffer", "int", "int", "numpy.array", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "filt[].repeat", "lpf.get_pad_layer_1d", "numpy.ceil", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.get_pad_layer_1d"], ["    ", "def", "__init__", "(", "self", ",", "pad_type", "=", "'reflect'", ",", "filt_size", "=", "3", ",", "stride", "=", "2", ",", "channels", "=", "None", ",", "pad_off", "=", "0", ")", ":", "\n", "        ", "super", "(", "Downsample1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filt_size", "=", "filt_size", "\n", "self", ".", "pad_off", "=", "pad_off", "\n", "self", ".", "pad_sizes", "=", "[", "int", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ",", "int", "(", "np", ".", "ceil", "(", "1.", "*", "(", "filt_size", "-", "1", ")", "/", "2", ")", ")", "]", "\n", "self", ".", "pad_sizes", "=", "[", "pad_size", "+", "pad_off", "for", "pad_size", "in", "self", ".", "pad_sizes", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "off", "=", "int", "(", "(", "self", ".", "stride", "-", "1", ")", "/", "2.", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "\n", "# print('Filter size [%i]' % filt_size)", "\n", "if", "(", "self", ".", "filt_size", "==", "1", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "2", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "3", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "2.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "4", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "3.", ",", "3.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "5", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "4.", ",", "6.", ",", "4.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "6", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "5.", ",", "10.", ",", "10.", ",", "5.", ",", "1.", "]", ")", "\n", "", "elif", "(", "self", ".", "filt_size", "==", "7", ")", ":", "\n", "            ", "a", "=", "np", ".", "array", "(", "[", "1.", ",", "6.", ",", "15.", ",", "20.", ",", "15.", ",", "6.", ",", "1.", "]", ")", "\n", "\n", "", "filt", "=", "torch", ".", "Tensor", "(", "a", ")", "\n", "filt", "=", "filt", "/", "torch", ".", "sum", "(", "filt", ")", "\n", "self", ".", "register_buffer", "(", "'filt'", ",", "filt", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "(", "self", ".", "channels", ",", "1", ",", "1", ")", ")", ")", "\n", "\n", "self", ".", "pad", "=", "get_pad_layer_1d", "(", "pad_type", ")", "(", "self", ".", "pad_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.Downsample1D.forward": [[95, 103], ["torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d", "lpf.Downsample1D.pad", "lpf.Downsample1D.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "(", "self", ".", "filt_size", "==", "1", ")", ":", "\n", "            ", "if", "(", "self", ".", "pad_off", "==", "0", ")", ":", "\n", "                ", "return", "inp", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "pad", "(", "inp", ")", "[", ":", ",", ":", ",", ":", ":", "self", ".", "stride", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "F", ".", "conv1d", "(", "self", ".", "pad", "(", "inp", ")", ",", "self", ".", "filt", ",", "stride", "=", "self", ".", "stride", ",", "groups", "=", "inp", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.get_pad_layer": [[50, 60], ["print"], "function", ["None"], ["", "", "", "def", "get_pad_layer", "(", "pad_type", ")", ":", "\n", "    ", "if", "(", "pad_type", "in", "[", "'refl'", ",", "'reflect'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReflectionPad2d", "\n", "", "elif", "(", "pad_type", "in", "[", "'repl'", ",", "'replicate'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReplicationPad2d", "\n", "", "elif", "(", "pad_type", "==", "'zero'", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ZeroPad2d", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Pad type [%s] not recognized'", "%", "pad_type", ")", "\n", "", "return", "PadLayer", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.lpf.get_pad_layer_1d": [[105, 115], ["print"], "function", ["None"], ["", "", "", "def", "get_pad_layer_1d", "(", "pad_type", ")", ":", "\n", "    ", "if", "(", "pad_type", "in", "[", "'refl'", ",", "'reflect'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReflectionPad1d", "\n", "", "elif", "(", "pad_type", "in", "[", "'repl'", ",", "'replicate'", "]", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ReplicationPad1d", "\n", "", "elif", "(", "pad_type", "==", "'zero'", ")", ":", "\n", "        ", "PadLayer", "=", "nn", ".", "ZeroPad1d", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Pad type [%s] not recognized'", "%", "pad_type", ")", "\n", "", "return", "PadLayer", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.Hsigmoid.__init__": [[101, 104], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ")", ":", "\n", "        ", "super", "(", "Hsigmoid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.Hsigmoid.forward": [[105, 107], ["torch.relu6", "torch.relu6", "torch.relu6"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "relu6", "(", "x", "+", "3.", ",", "inplace", "=", "self", ".", "inplace", ")", "/", "6.", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.eSEModule.__init__": [[110, 116], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "vovnet.Hsigmoid"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "4", ")", ":", "\n", "        ", "super", "(", "eSEModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "kernel_size", "=", "1", ",", "\n", "padding", "=", "0", ")", "\n", "self", ".", "hsigmoid", "=", "Hsigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.eSEModule.forward": [[117, 123], ["vovnet.eSEModule.avg_pool", "vovnet.eSEModule.fc", "vovnet.eSEModule.hsigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "input", "=", "x", "\n", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "self", ".", "hsigmoid", "(", "x", ")", "\n", "return", "input", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet._OSA_module.__init__": [[127, 150], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vovnet.eSEModule", "vovnet._OSA_module.layers.append", "collections.OrderedDict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vovnet.conv1x1", "collections.OrderedDict", "vovnet.conv3x3"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_ch", ",", "\n", "stage_ch", ",", "\n", "concat_ch", ",", "\n", "layer_per_block", ",", "\n", "module_name", ",", "\n", "SE", "=", "False", ",", "\n", "identity", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "_OSA_module", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "identity", "=", "identity", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "in_channel", "=", "in_ch", "\n", "for", "i", "in", "range", "(", "layer_per_block", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Sequential", "(", "OrderedDict", "(", "conv3x3", "(", "in_channel", ",", "stage_ch", ",", "module_name", ",", "i", ")", ")", ")", ")", "\n", "in_channel", "=", "stage_ch", "\n", "\n", "# feature aggregation", "\n", "", "in_channel", "=", "in_ch", "+", "layer_per_block", "*", "stage_ch", "\n", "self", ".", "concat", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "conv1x1", "(", "in_channel", ",", "concat_ch", ",", "module_name", ",", "'concat'", ")", ")", ")", "\n", "\n", "self", ".", "ese", "=", "eSEModule", "(", "concat_ch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet._OSA_module.forward": [[151, 170], ["output.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vovnet._OSA_module.concat", "vovnet._OSA_module.ese", "layer", "output.append"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "identity_feat", "=", "x", "\n", "\n", "output", "=", "[", "]", "\n", "output", ".", "append", "(", "x", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "output", ".", "append", "(", "x", ")", "\n", "\n", "", "x", "=", "torch", ".", "cat", "(", "output", ",", "dim", "=", "1", ")", "\n", "xt", "=", "self", ".", "concat", "(", "x", ")", "\n", "\n", "xt", "=", "self", ".", "ese", "(", "xt", ")", "\n", "\n", "if", "self", ".", "identity", ":", "\n", "            ", "xt", "=", "xt", "+", "identity_feat", "\n", "\n", "", "return", "xt", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet._OSA_stage.__init__": [[174, 208], ["torch.Sequential.__init__", "vovnet._OSA_stage.add_module", "range", "vovnet._OSA_stage.add_module", "vovnet._OSA_module", "vovnet._OSA_stage.add_module", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "vovnet._OSA_module"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "in_ch", ",", "\n", "stage_ch", ",", "\n", "concat_ch", ",", "\n", "block_per_stage", ",", "\n", "layer_per_block", ",", "\n", "stage_num", ",", "\n", "SE", "=", "False", ")", ":", "\n", "        ", "super", "(", "_OSA_stage", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "not", "stage_num", "==", "2", ":", "\n", "            ", "self", ".", "add_module", "(", "'Pooling'", ",", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "ceil_mode", "=", "True", ")", ")", "\n", "\n", "", "if", "block_per_stage", "!=", "1", ":", "\n", "            ", "SE", "=", "False", "\n", "", "module_name", "=", "f'OSA{stage_num}_1'", "\n", "self", ".", "add_module", "(", "module_name", ",", "_OSA_module", "(", "in_ch", ",", "\n", "stage_ch", ",", "\n", "concat_ch", ",", "\n", "layer_per_block", ",", "\n", "module_name", ",", "\n", "SE", ")", ")", "\n", "for", "i", "in", "range", "(", "block_per_stage", "-", "1", ")", ":", "\n", "            ", "if", "i", "!=", "block_per_stage", "-", "2", ":", "#last block", "\n", "                ", "SE", "=", "False", "\n", "", "module_name", "=", "f'OSA{stage_num}_{i + 2}'", "\n", "self", ".", "add_module", "(", "module_name", ",", "\n", "_OSA_module", "(", "concat_ch", ",", "\n", "stage_ch", ",", "\n", "concat_ch", ",", "\n", "layer_per_block", ",", "\n", "module_name", ",", "\n", "SE", ",", "\n", "identity", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet.__init__": [[213, 269], ["detectron2.modeling.backbone.Backbone.__init__", "vovnet.conv3x3", "vovnet.conv3x3", "vovnet.conv3x3", "vovnet.VoVNet.add_module", "range", "vovnet.VoVNet._initialize_weights", "vovnet.VoVNet._freeze_backbone", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vovnet.VoVNet.stage_names.append", "vovnet.VoVNet.add_module", "collections.OrderedDict", "vovnet._OSA_stage", "int"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet._initialize_weights", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_backbone", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_ch", ",", "out_features", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_ch(int) : the number of input channel\n            out_features (list[str]): name of the layers whose outputs should\n                be returned in forward. Can be anything in \"stem\", \"stage2\" ...\n        \"\"\"", "\n", "super", "(", "VoVNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "global", "_NORM", "\n", "_NORM", "=", "cfg", ".", "MODEL", ".", "VOVNET", ".", "NORM", "\n", "\n", "stage_specs", "=", "_STAGE_SPECS", "[", "cfg", ".", "MODEL", ".", "VOVNET", ".", "CONV_BODY", "]", "\n", "\n", "config_stage_ch", "=", "stage_specs", "[", "'stage_conv_ch'", "]", "\n", "config_concat_ch", "=", "stage_specs", "[", "'stage_out_ch'", "]", "\n", "block_per_stage", "=", "stage_specs", "[", "'block_per_stage'", "]", "\n", "layer_per_block", "=", "stage_specs", "[", "'layer_per_block'", "]", "\n", "SE", "=", "stage_specs", "[", "'eSE'", "]", "\n", "\n", "self", ".", "_out_features", "=", "out_features", "\n", "\n", "\n", "# Stem module", "\n", "stem", "=", "conv3x3", "(", "input_ch", ",", "64", ",", "'stem'", ",", "'1'", ",", "2", ")", "\n", "stem", "+=", "conv3x3", "(", "64", ",", "64", ",", "'stem'", ",", "'2'", ",", "1", ")", "\n", "stem", "+=", "conv3x3", "(", "64", ",", "128", ",", "'stem'", ",", "'3'", ",", "2", ")", "\n", "self", ".", "add_module", "(", "'stem'", ",", "nn", ".", "Sequential", "(", "(", "OrderedDict", "(", "stem", ")", ")", ")", ")", "\n", "current_stirde", "=", "4", "\n", "self", ".", "_out_feature_strides", "=", "{", "\"stem\"", ":", "current_stirde", ",", "\"stage2\"", ":", "current_stirde", "}", "\n", "self", ".", "_out_feature_channels", "=", "{", "\"stem\"", ":", "128", "}", "\n", "\n", "stem_out_ch", "=", "[", "128", "]", "\n", "in_ch_list", "=", "stem_out_ch", "+", "config_concat_ch", "[", ":", "-", "1", "]", "\n", "# OSA stages", "\n", "self", ".", "stage_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "# num_stages", "\n", "            ", "name", "=", "'stage%d'", "%", "(", "i", "+", "2", ")", "# stage 2 ... stage 5", "\n", "self", ".", "stage_names", ".", "append", "(", "name", ")", "\n", "self", ".", "add_module", "(", "name", ",", "_OSA_stage", "(", "in_ch_list", "[", "i", "]", ",", "\n", "config_stage_ch", "[", "i", "]", ",", "\n", "config_concat_ch", "[", "i", "]", ",", "\n", "block_per_stage", "[", "i", "]", ",", "\n", "layer_per_block", ",", "\n", "i", "+", "2", ",", "\n", "SE", ")", ")", "\n", "\n", "self", ".", "_out_feature_channels", "[", "name", "]", "=", "config_concat_ch", "[", "i", "]", "\n", "if", "not", "i", "==", "0", ":", "\n", "                ", "self", ".", "_out_feature_strides", "[", "name", "]", "=", "current_stirde", "=", "int", "(", "\n", "current_stirde", "*", "2", ")", "\n", "\n", "# initialize weights", "\n", "", "", "self", ".", "_initialize_weights", "(", ")", "\n", "# Optionally freeze (requires_grad=False) parts of the backbone", "\n", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet._initialize_weights": [[271, 275], ["vovnet.VoVNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet._freeze_backbone": [[276, 291], ["vovnet.VoVNet.modules", "range", "isinstance", "getattr.parameters", "freeze_bn_params", "getattr", "detectron2.layers.FrozenBatchNorm2d.convert_frozen_batchnorm", "str"], "methods", ["None"], ["", "", "", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "if", "freeze_at", "<", "0", ":", "\n", "            ", "return", "\n", "# freeze BN layers", "\n", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "freeze_bn_params", "(", "m", ")", "\n", "", "", "for", "stage_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "if", "stage_index", "==", "0", ":", "\n", "                ", "m", "=", "self", ".", "stem", "# stage 0 is the stem", "\n", "", "else", ":", "\n", "                ", "m", "=", "getattr", "(", "self", ",", "\"stage\"", "+", "str", "(", "stage_index", "+", "1", ")", ")", "\n", "", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "FrozenBatchNorm2d", ".", "convert_frozen_batchnorm", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet.forward": [[292, 303], ["vovnet.VoVNet.stem", "getattr"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "{", "}", "\n", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "if", "\"stem\"", "in", "self", ".", "_out_features", ":", "\n", "            ", "outputs", "[", "\"stem\"", "]", "=", "x", "\n", "", "for", "name", "in", "self", ".", "stage_names", ":", "\n", "            ", "x", "=", "getattr", "(", "self", ",", "name", ")", "(", "x", ")", "\n", "if", "name", "in", "self", ".", "_out_features", ":", "\n", "                ", "outputs", "[", "name", "]", "=", "x", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.VoVNet.output_shape": [[304, 310], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "_out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.conv3x3": [[67, 81], ["torch.Conv2d", "detectron2.layers.get_norm", "torch.ReLU"], "function", ["None"], ["def", "conv3x3", "(", "in_channels", ",", "out_channels", ",", "module_name", ",", "postfix", ",", "\n", "stride", "=", "1", ",", "groups", "=", "1", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "[", "\n", "(", "f'{module_name}_{postfix}/conv'", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "groups", "=", "groups", ",", "\n", "bias", "=", "False", ")", ")", ",", "\n", "(", "f'{module_name}_{postfix}/norm'", ",", "get_norm", "(", "_NORM", ",", "out_channels", ")", ")", ",", "\n", "(", "f'{module_name}_{postfix}/relu'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.conv1x1": [[84, 98], ["torch.Conv2d", "detectron2.layers.get_norm", "torch.ReLU"], "function", ["None"], ["", "def", "conv1x1", "(", "in_channels", ",", "out_channels", ",", "module_name", ",", "postfix", ",", "\n", "stride", "=", "1", ",", "groups", "=", "1", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", ":", "\n", "    ", "\"\"\"1x1 convolution with padding\"\"\"", "\n", "return", "[", "\n", "(", "f'{module_name}_{postfix}/conv'", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "groups", "=", "groups", ",", "\n", "bias", "=", "False", ")", ")", ",", "\n", "(", "f'{module_name}_{postfix}/norm'", ",", "get_norm", "(", "_NORM", ",", "out_channels", ")", ")", ",", "\n", "(", "f'{module_name}_{postfix}/relu'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.build_vovnet_backbone": [[313, 323], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "vovnet.VoVNet"], "function", ["None"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_vovnet_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a VoVNet instance from config.\n\n    Returns:\n        VoVNet: a :class:`VoVNet` instance.\n    \"\"\"", "\n", "out_features", "=", "cfg", ".", "MODEL", ".", "VOVNET", ".", "OUT_FEATURES", "\n", "return", "VoVNet", "(", "cfg", ",", "input_shape", ".", "channels", ",", "out_features", "=", "out_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.build_vovnet_fpn_backbone": [[325, 346], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "vovnet.build_vovnet_backbone", "detectron2.modeling.backbone.fpn.FPN", "LastLevelMaxPool"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.build_vovnet_backbone"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_vovnet_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_vovnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "LastLevelMaxPool", "(", ")", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.build_dafne_vovnet_fpn_backbone": [[348, 377], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "vovnet.build_vovnet_backbone", "detectron2.modeling.backbone.fpn.FPN", "fpn.LastLevelP6P7", "fpn.LastLevelP6"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.backbone.vovnet.build_vovnet_backbone"], ["", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_dafne_vovnet_fpn_backbone", "(", "cfg", ",", "input_shape", ":", "ShapeSpec", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        cfg: a detectron2 CfgNode\n\n    Returns:\n        backbone (Backbone): backbone module, must be a subclass of :class:`Backbone`.\n    \"\"\"", "\n", "bottom_up", "=", "build_vovnet_backbone", "(", "cfg", ",", "input_shape", ")", "\n", "in_features", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "IN_FEATURES", "\n", "out_channels", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "OUT_CHANNELS", "\n", "top_levels", "=", "cfg", ".", "MODEL", ".", "DAFNE", ".", "TOP_LEVELS", "\n", "in_channels_top", "=", "out_channels", "\n", "if", "top_levels", "==", "2", ":", "\n", "        ", "top_block", "=", "LastLevelP6P7", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "if", "top_levels", "==", "1", ":", "\n", "        ", "top_block", "=", "LastLevelP6", "(", "in_channels_top", ",", "out_channels", ",", "\"p5\"", ")", "\n", "", "elif", "top_levels", "==", "0", ":", "\n", "        ", "top_block", "=", "None", "\n", "", "backbone", "=", "FPN", "(", "\n", "bottom_up", "=", "bottom_up", ",", "\n", "in_features", "=", "in_features", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "NORM", ",", "\n", "top_block", "=", "top_block", ",", "\n", "fuse_type", "=", "cfg", ".", "MODEL", ".", "FPN", ".", "FUSE_TYPE", ",", "\n", ")", "\n", "return", "backbone", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.BasicBlock.__init__": [[66, 84], ["torch.Module.__init__", "resnet_lpf.conv3x3", "norm_layer", "torch.ReLU", "norm_layer", "ValueError", "resnet_lpf.conv3x3", "torch.Sequential", "lpf.Downsample", "resnet_lpf.conv3x3"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "norm_layer", "=", "None", ",", "filter_size", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1'", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "if", "(", "stride", "==", "1", ")", ":", "\n", "            ", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "stride", ",", "channels", "=", "planes", ")", ",", "\n", "conv3x3", "(", "planes", ",", "planes", ")", ",", ")", "\n", "", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.BasicBlock.forward": [[85, 102], ["resnet_lpf.BasicBlock.conv1", "resnet_lpf.BasicBlock.bn1", "resnet_lpf.BasicBlock.relu", "resnet_lpf.BasicBlock.conv2", "resnet_lpf.BasicBlock.bn2", "resnet_lpf.BasicBlock.relu", "resnet_lpf.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.Bottleneck.__init__": [[107, 125], ["torch.Module.__init__", "resnet_lpf.conv1x1", "norm_layer", "resnet_lpf.conv3x3", "norm_layer", "norm_layer", "torch.ReLU", "resnet_lpf.conv1x1", "torch.Sequential", "lpf.Downsample", "resnet_lpf.conv1x1"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "norm_layer", "=", "None", ",", "filter_size", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "groups", ")", "# stride moved", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "if", "(", "stride", "==", "1", ")", ":", "\n", "            ", "self", ".", "conv3", "=", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "stride", ",", "channels", "=", "planes", ")", ",", "\n", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.Bottleneck.forward": [[126, 147], ["resnet_lpf.Bottleneck.conv1", "resnet_lpf.Bottleneck.bn1", "resnet_lpf.Bottleneck.relu", "resnet_lpf.Bottleneck.conv2", "resnet_lpf.Bottleneck.bn2", "resnet_lpf.Bottleneck.relu", "resnet_lpf.Bottleneck.conv3", "resnet_lpf.Bottleneck.bn3", "resnet_lpf.Bottleneck.relu", "resnet_lpf.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF.__init__": [[151, 208], ["detectron2.modeling.backbone.Backbone.__init__", "norm_layer", "torch.ReLU", "resnet_lpf.ResNetLPF._make_layer", "resnet_lpf.ResNetLPF._make_layer", "resnet_lpf.ResNetLPF._make_layer", "resnet_lpf.ResNetLPF._make_layer", "resnet_lpf.ResNetLPF.modules", "resnet_lpf.ResNetLPF._freeze_backbone", "int", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "isinstance", "resnet_lpf.ResNetLPF.modules", "resnet_lpf.ResNetLPF._freeze_bn", "range", "isinstance", "isinstance", "torch.init.kaiming_normal_", "print", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.MaxPool2d", "lpf.Downsample", "lpf.Downsample", "torch.MaxPool2d", "lpf.Downsample", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._make_layer", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._make_layer", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._make_layer", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._make_layer", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_backbone", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_bn"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "norm_layer", "=", "None", ",", "filter_size", "=", "1", ",", "\n", "pool_only", "=", "True", ",", "return_idx", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "return_idx", "=", "return_idx", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "planes", "=", "[", "int", "(", "width_per_group", "*", "groups", "*", "2", "**", "i", ")", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "self", ".", "inplanes", "=", "planes", "[", "0", "]", "\n", "\n", "if", "(", "pool_only", ")", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "planes", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "planes", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "norm_layer", "(", "planes", "[", "0", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "if", "(", "pool_only", ")", ":", "\n", "            ", "self", ".", "maxpool", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "2", ",", "channels", "=", "planes", "[", "0", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "maxpool", "=", "nn", ".", "Sequential", "(", "*", "[", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "2", ",", "channels", "=", "planes", "[", "0", "]", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "2", ",", "channels", "=", "planes", "[", "0", "]", ")", "]", ")", "\n", "\n", "", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "planes", "[", "0", "]", ",", "layers", "[", "0", "]", ",", "groups", "=", "groups", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "planes", "[", "1", "]", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "groups", "=", "groups", ",", "norm_layer", "=", "norm_layer", ",", "filter_size", "=", "filter_size", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "planes", "[", "2", "]", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "groups", "=", "groups", ",", "norm_layer", "=", "norm_layer", ",", "filter_size", "=", "filter_size", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "planes", "[", "3", "]", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "groups", "=", "groups", ",", "norm_layer", "=", "norm_layer", ",", "filter_size", "=", "filter_size", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "if", "(", "m", ".", "in_channels", "!=", "m", ".", "out_channels", "or", "m", ".", "out_channels", "!=", "m", ".", "groups", "or", "m", ".", "bias", "is", "not", "None", ")", ":", "\n", "# don't want to reinitialize downsample layers, code assuming normal conv layers will not have these characteristics", "\n", "                    ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Not initializing'", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "", "", "", "self", ".", "_freeze_backbone", "(", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", ")", "\n", "if", "False", ":", "\n", "            ", "self", ".", "_freeze_bn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_backbone": [[209, 223], ["range", "resnet_lpf.ResNetLPF.conv1.parameters", "resnet_lpf.ResNetLPF.bn1.parameters", "getattr", "getattr.parameters", "str"], "methods", ["None"], ["", "", "def", "_freeze_backbone", "(", "self", ",", "freeze_at", ")", ":", "\n", "        ", "if", "freeze_at", "<", "0", ":", "\n", "            ", "return", "\n", "", "for", "stage_index", "in", "range", "(", "freeze_at", ")", ":", "\n", "            ", "if", "stage_index", "==", "0", ":", "\n", "# stage 0 is the stem", "\n", "                ", "for", "p", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "for", "p", "in", "self", ".", "bn1", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "m", "=", "getattr", "(", "self", ",", "\"layer\"", "+", "str", "(", "stage_index", ")", ")", "\n", "for", "p", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._freeze_bn": [[224, 228], ["resnet_lpf.ResNetLPF.modules", "isinstance", "m.eval"], "methods", ["None"], ["", "", "", "", "def", "_freeze_bn", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF._make_layer": [[229, 255], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet_lpf.conv1x1", "norm_layer", "block", "lpf.Downsample"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "norm_layer", "=", "None", ",", "filter_size", "=", "1", ")", ":", "\n", "        ", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "# downsample = nn.Sequential(", "\n", "#     conv1x1(self.inplanes, planes * block.expansion, stride, filter_size=filter_size),", "\n", "#     norm_layer(planes * block.expansion),", "\n", "# )", "\n", "\n", "            ", "downsample", "=", "[", "Downsample", "(", "filt_size", "=", "filter_size", ",", "stride", "=", "stride", ",", "\n", "channels", "=", "self", ".", "inplanes", ")", ",", "]", "if", "(", "stride", "!=", "1", ")", "else", "[", "]", "\n", "downsample", "+=", "[", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "1", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", "]", "\n", "# print(downsample)", "\n", "downsample", "=", "nn", ".", "Sequential", "(", "*", "downsample", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "\n", "groups", ",", "norm_layer", ",", "filter_size", "=", "filter_size", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "groups", ",", "\n", "norm_layer", "=", "norm_layer", ",", "filter_size", "=", "filter_size", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.ResNetLPF.forward": [[256, 268], ["resnet_lpf.ResNetLPF.conv1", "resnet_lpf.ResNetLPF.bn1", "resnet_lpf.ResNetLPF.relu", "resnet_lpf.ResNetLPF.maxpool", "outs.append", "outs.append", "outs.append", "outs.append", "resnet_lpf.ResNetLPF.layer1", "resnet_lpf.ResNetLPF.layer2", "resnet_lpf.ResNetLPF.layer3", "resnet_lpf.ResNetLPF.layer4"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "outs", ".", "append", "(", "self", ".", "layer1", "(", "x", ")", ")", "# 1/4", "\n", "outs", ".", "append", "(", "self", ".", "layer2", "(", "outs", "[", "-", "1", "]", ")", ")", "# 1/8", "\n", "outs", ".", "append", "(", "self", ".", "layer3", "(", "outs", "[", "-", "1", "]", ")", ")", "# 1/16", "\n", "outs", ".", "append", "(", "self", ".", "layer4", "(", "outs", "[", "-", "1", "]", ")", ")", "# 1/32", "\n", "return", "{", "\"res{}\"", ".", "format", "(", "idx", "+", "2", ")", ":", "outs", "[", "idx", "]", "for", "idx", "in", "self", ".", "return_idx", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv3x3": [[52, 56], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "groups", "=", "groups", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.conv1x1": [[58, 61], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.backbone.resnet_lpf.build_resnet_lpf_backbone": [[270, 292], ["detectron2.modeling.backbone.build.BACKBONE_REGISTRY.register", "resnet_lpf.ResNetLPF"], "function", ["None"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_resnet_lpf_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a ResNet instance from config.\n\n    Returns:\n        ResNet: a :class:`ResNet` instance.\n    \"\"\"", "\n", "depth", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "DEPTH", "\n", "out_features", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "OUT_FEATURES", "\n", "\n", "num_blocks_per_stage", "=", "{", "50", ":", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "101", ":", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "152", ":", "[", "3", ",", "8", ",", "36", ",", "3", "]", "}", "[", "depth", "]", "\n", "out_stage_idx", "=", "[", "{", "\"res2\"", ":", "0", ",", "\"res3\"", ":", "1", ",", "\"res4\"", ":", "2", ",", "\"res5\"", ":", "3", "}", "[", "f", "]", "for", "f", "in", "out_features", "]", "\n", "out_feature_channels", "=", "{", "\"res2\"", ":", "256", ",", "\"res3\"", ":", "512", ",", "\n", "\"res4\"", ":", "1024", ",", "\"res5\"", ":", "2048", "}", "\n", "out_feature_strides", "=", "{", "\"res2\"", ":", "4", ",", "\"res3\"", ":", "8", ",", "\"res4\"", ":", "16", ",", "\"res5\"", ":", "32", "}", "\n", "model", "=", "ResNetLPF", "(", "cfg", ",", "Bottleneck", ",", "num_blocks_per_stage", ",", "norm_layer", "=", "NaiveSyncBatchNorm", ",", "\n", "filter_size", "=", "3", ",", "pool_only", "=", "True", ",", "return_idx", "=", "out_stage_idx", ")", "\n", "model", ".", "_out_features", "=", "out_features", "\n", "model", ".", "_out_feature_channels", "=", "out_feature_channels", "\n", "model", ".", "_out_feature_strides", "=", "out_feature_strides", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.SmoothL1Loss.__init__": [[17, 22], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "beta", "=", "1.0", "/", "9", ",", "reduction", "=", "\"sum\"", ",", "logspace", "=", "True", ")", ":", "\n", "        ", "super", "(", "SmoothL1Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "logspace", "=", "logspace", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.SmoothL1Loss.forward": [[23, 40], ["fvcore.nn.smooth_l1_loss", "loss.sum.sum.log1p", "loss.sum.sum.mean", "weight.sum", "loss.sum.sum.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "# Get original smooth_l1_loss without reduction", "\n", "        ", "loss", "=", "smooth_l1_loss", "(", "input", ",", "target", ",", "self", ".", "beta", ",", "reduction", "=", "\"None\"", ")", "\n", "\n", "if", "self", ".", "logspace", ":", "\n", "            ", "loss", "=", "loss", ".", "log1p", "(", ")", "\n", "\n", "# Scale by weights if given", "\n", "", "if", "weight", "is", "not", "None", "and", "weight", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "loss", "*=", "weight", "[", ":", ",", "None", "]", "\n", "\n", "# Perform reduction", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedEightPointLoss.__init__": [[43, 48], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", "/", "9", ",", "reduction", "=", "\"sum\"", ",", "logspace", "=", "True", ")", ":", "\n", "        ", "super", "(", "ModulatedEightPointLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "logspace", "=", "logspace", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedEightPointLoss._smooth_l1_loss": [[49, 68], ["torch.abs", "torch.abs", "torch.where"], "methods", ["None"], ["", "def", "_smooth_l1_loss", "(", "\n", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "target", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"none\"", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"See https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/smooth_l1_loss.py\"\"\"", "\n", "if", "self", ".", "beta", "<", "1e-5", ":", "\n", "# if self.beta == 0, then torch.where will result in nan gradients when", "\n", "# the chain rule is applied due to pytorch implementation details", "\n", "# (the False branch \"0.5 * n ** 2 / 0\" has an incoming gradient of", "\n", "# zeros, rather than \"no gradient\"). To avoid this issue, we define", "\n", "# small values of self.beta to be exactly l1 loss.", "\n", "            ", "loss", "=", "torch", ".", "abs", "(", "input", "-", "target", ")", "\n", "# loss = l1_abs", "\n", "", "else", ":", "\n", "            ", "n", "=", "torch", ".", "abs", "(", "input", "-", "target", ")", "\n", "# n = l1_abs", "\n", "cond", "=", "n", "<", "self", ".", "beta", "\n", "loss", "=", "torch", ".", "where", "(", "cond", ",", "0.5", "*", "n", "**", "2", "/", "self", ".", "beta", ",", "n", "-", "0.5", "*", "self", ".", "beta", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedEightPointLoss.forward": [[69, 113], ["smooth_l1.ModulatedEightPointLoss._smooth_l1_loss", "input.view.view.view", "input[].view", "smooth_l1.ModulatedEightPointLoss._smooth_l1_loss", "input[].view", "smooth_l1.ModulatedEightPointLoss._smooth_l1_loss", "loss_0.sum.sum.log1p", "loss_1.sum.sum.log1p", "loss_2.sum.sum.log1p", "loss_0.sum.sum.mean", "loss_1.sum.sum.mean", "loss_2.sum.sum.mean", "torch.min", "losses.mean", "loss_0.sum.sum.sum", "loss_1.sum.sum.sum", "loss_2.sum.sum.sum", "torch.stack", "weight.sum", "losses.sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "\n", "# Convert xywha to corner representation and sort them canonically", "\n", "\n", "        ", "num_pos", "=", "input", ".", "shape", "[", "0", "]", "\n", "\n", "# Loss without shift", "\n", "loss_0", "=", "self", ".", "_smooth_l1_loss", "(", "input", ",", "target", ")", "\n", "\n", "input", "=", "input", ".", "view", "(", "num_pos", ",", "4", ",", "2", ")", "\n", "\n", "# Clockwise shift", "\n", "input_tmp", "=", "input", "[", ":", ",", "[", "1", ",", "2", ",", "3", ",", "0", "]", "]", ".", "view", "(", "num_pos", ",", "-", "1", ")", "\n", "loss_1", "=", "self", ".", "_smooth_l1_loss", "(", "input_tmp", ",", "target", ")", "\n", "\n", "# Clockwise shift", "\n", "input_tmp", "=", "input", "[", ":", ",", "[", "3", ",", "0", ",", "1", ",", "2", "]", "]", ".", "view", "(", "num_pos", ",", "-", "1", ")", "\n", "loss_2", "=", "self", ".", "_smooth_l1_loss", "(", "input_tmp", ",", "target", ")", "\n", "\n", "if", "self", ".", "logspace", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "log1p", "(", ")", "\n", "loss_1", "=", "loss_1", ".", "log1p", "(", ")", "\n", "loss_2", "=", "loss_2", ".", "log1p", "(", ")", "\n", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "mean", "(", "1", ")", "\n", "loss_1", "=", "loss_1", ".", "mean", "(", "1", ")", "\n", "loss_2", "=", "loss_2", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "sum", "(", "1", ")", "\n", "loss_1", "=", "loss_1", ".", "sum", "(", "1", ")", "\n", "loss_2", "=", "loss_2", ".", "sum", "(", "1", ")", "\n", "\n", "", "losses", "=", "torch", ".", "min", "(", "torch", ".", "stack", "(", "(", "loss_0", ",", "loss_1", ",", "loss_2", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "\n", "# Scale by weights if given", "\n", "if", "weight", "is", "not", "None", "and", "weight", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "losses", "*=", "weight", "\n", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "return", "losses", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "return", "losses", ".", "sum", "(", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss.__init__": [[116, 121], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "beta", "=", "1.0", "/", "9", ",", "reduction", "=", "\"sum\"", ",", "logspace", "=", "True", ")", ":", "\n", "        ", "super", "(", "ModulatedSmoothL1Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "logspace", "=", "logspace", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss": [[122, 140], ["torch.log1p", "torch.log1p", "torch.where"], "methods", ["None"], ["", "def", "_smooth_l1_loss", "(", "\n", "self", ",", "l1_abs", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"none\"", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"See https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/smooth_l1_loss.py\"\"\"", "\n", "if", "self", ".", "beta", "<", "1e-5", ":", "\n", "# if self.beta == 0, then torch.where will result in nan gradients when", "\n", "# the chain rule is applied due to pytorch implementation details", "\n", "# (the False branch \"0.5 * n ** 2 / 0\" has an incoming gradient of", "\n", "# zeros, rather than \"no gradient\"). To avoid this issue, we define", "\n", "# small values of self.beta to be exactly l1 loss.", "\n", "            ", "loss", "=", "torch", ".", "log1p", "(", "l1_abs", ")", "\n", "# loss = l1_abs", "\n", "", "else", ":", "\n", "            ", "n", "=", "torch", ".", "log1p", "(", "l1_abs", ")", "\n", "# n = l1_abs", "\n", "cond", "=", "n", "<", "self", ".", "beta", "\n", "loss", "=", "torch", ".", "where", "(", "cond", ",", "0.5", "*", "n", "**", "2", "/", "self", ".", "beta", ",", "n", "-", "0.5", "*", "self", ".", "beta", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss.forward": [[141, 182], ["torch.abs", "smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss", "torch.abs", "torch.abs", "smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss", "loss_0.sum.sum.log1p", "loss_1.sum.sum.log1p", "loss_2.log1p.log1p.log1p", "loss_0.sum.sum.mean", "loss_1.sum.sum.mean", "torch.min", "losses.mean", "loss_0.sum.sum.sum", "loss_1.sum.sum.sum", "torch.stack", "weight.sum", "losses.sum"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.ModulatedSmoothL1Loss._smooth_l1_loss"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "# Convert degrees to radians", "\n", "        ", "input", "[", ":", ",", "4", "]", "=", "input", "[", ":", ",", "4", "]", "/", "180.0", "*", "math", ".", "pi", "\n", "target", "[", ":", ",", "4", "]", "=", "target", "[", ":", ",", "4", "]", "/", "180.0", "*", "math", ".", "pi", "\n", "\n", "# Loss without changes", "\n", "# |x1 - x2| + |y1 - y2| + |w1 - w2| + |h1 - h2| + |theta1 - theta2|", "\n", "l1_abs", "=", "torch", ".", "abs", "(", "input", "-", "target", ")", "\n", "loss_0", "=", "self", ".", "_smooth_l1_loss", "(", "l1_abs", ")", "\n", "\n", "# Loss with h/w swap and 90 - angle", "\n", "# |x1 - x2| + |y1 - y2| + |w1 - h2| + |h1 - w2| + |pi/2 - |theta1 - theta2||", "\n", "input_tmp", "=", "input", "[", ":", ",", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", "]", "\n", "l1_abs", "=", "torch", ".", "abs", "(", "input_tmp", "-", "target", ")", "\n", "l1_abs", "[", ":", ",", "4", "]", "=", "torch", ".", "abs", "(", "math", ".", "pi", "/", "2.0", "-", "l1_abs", "[", ":", ",", "4", "]", ")", "\n", "loss_1", "=", "self", ".", "_smooth_l1_loss", "(", "l1_abs", ")", "\n", "\n", "if", "self", ".", "logspace", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "log1p", "(", ")", "\n", "loss_1", "=", "loss_1", ".", "log1p", "(", ")", "\n", "loss_2", "=", "loss_2", ".", "log1p", "(", ")", "\n", "\n", "# Reduce over all elements (x, y, w, h, theta) in a single box", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "mean", "(", "1", ")", "\n", "loss_1", "=", "loss_1", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "loss_0", "=", "loss_0", ".", "sum", "(", "1", ")", "\n", "loss_1", "=", "loss_1", ".", "sum", "(", "1", ")", "\n", "\n", "", "losses", "=", "torch", ".", "min", "(", "torch", ".", "stack", "(", "(", "loss_0", ",", "loss_1", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ".", "values", "\n", "\n", "# Scale by weights if given", "\n", "if", "weight", "is", "not", "None", "and", "weight", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "losses", "*=", "weight", "\n", "\n", "", "if", "self", ".", "reduction", "==", "\"mean\"", ":", "\n", "            ", "return", "losses", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "\"sum\"", ":", "\n", "            ", "return", "losses", ".", "sum", "(", ")", "\n", "", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.smooth_l1.smooth_l1": [[10, 13], ["fvcore.nn.smooth_l1_loss"], "function", ["None"], ["@", "weighted_loss", "\n", "def", "smooth_l1", "(", "pred", ",", "target", ",", "beta", ")", ":", "\n", "    ", "return", "smooth_l1_loss", "(", "pred", ",", "target", ",", "beta", ",", "\"none\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.get_intersection_points": [[15, 59], ["torch.cat", "torch.cat", "torch.cat.unsqueeze().repeat", "torch.cat.unsqueeze().repeat", "torch.stack", "mask.float().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "mask.float"], "function", ["None"], ["def", "get_intersection_points", "(", "polys1", ":", "torch", ".", "Tensor", ",", "polys2", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Find intersection points of rectangles\n    Convention: if two edges are collinear, there is no intersection point\n\n    Args:\n        polys1 (torch.Tensor): n, 4, 2\n        polys2 (torch.Tensor): n, 4, 2\n\n    Returns:\n        intersectons (torch.Tensor): n, 4, 4, 2\n        mask (torch.Tensor) : n, 4, 4; bool\n    \"\"\"", "\n", "# build edges from corners", "\n", "line1", "=", "torch", ".", "cat", "(", "[", "polys1", ",", "polys1", "[", "...", ",", "[", "1", ",", "2", ",", "3", ",", "0", "]", ",", ":", "]", "]", ",", "\n", "dim", "=", "2", ")", "# n, 4, 4: Box, edge, point", "\n", "line2", "=", "torch", ".", "cat", "(", "[", "polys2", ",", "polys2", "[", "...", ",", "[", "1", ",", "2", ",", "3", ",", "0", "]", ",", ":", "]", "]", ",", "dim", "=", "2", ")", "\n", "# duplicate data to pair each edges from the boxes", "\n", "# (n, 4, 4) -> (n, 4, 4, 4) : Box, edge1, edge2, point", "\n", "line1_ext", "=", "line1", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "[", "1", ",", "1", ",", "4", ",", "1", "]", ")", "\n", "line2_ext", "=", "line2", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "[", "1", ",", "4", ",", "1", ",", "1", "]", ")", "\n", "x1", "=", "line1_ext", "[", "...", ",", "0", "]", "\n", "y1", "=", "line1_ext", "[", "...", ",", "1", "]", "\n", "x2", "=", "line1_ext", "[", "...", ",", "2", "]", "\n", "y2", "=", "line1_ext", "[", "...", ",", "3", "]", "\n", "x3", "=", "line2_ext", "[", "...", ",", "0", "]", "\n", "y3", "=", "line2_ext", "[", "...", ",", "1", "]", "\n", "x4", "=", "line2_ext", "[", "...", ",", "2", "]", "\n", "y4", "=", "line2_ext", "[", "...", ",", "3", "]", "\n", "# math: https://en.wikipedia.org/wiki/Line%E2%80%93line_intersection", "\n", "num", "=", "(", "x1", "-", "x2", ")", "*", "(", "y3", "-", "y4", ")", "-", "(", "y1", "-", "y2", ")", "*", "(", "x3", "-", "x4", ")", "\n", "den_t", "=", "(", "x1", "-", "x3", ")", "*", "(", "y3", "-", "y4", ")", "-", "(", "y1", "-", "y3", ")", "*", "(", "x3", "-", "x4", ")", "\n", "t", "=", "den_t", "/", "num", "\n", "t", "[", "num", "==", ".0", "]", "=", "-", "1.", "\n", "mask_t", "=", "(", "t", ">", "0", ")", "*", "(", "t", "<", "1", ")", "# intersection on line segment 1", "\n", "den_u", "=", "(", "x1", "-", "x2", ")", "*", "(", "y1", "-", "y3", ")", "-", "(", "y1", "-", "y2", ")", "*", "(", "x1", "-", "x3", ")", "\n", "u", "=", "-", "den_u", "/", "num", "\n", "u", "[", "num", "==", ".0", "]", "=", "-", "1.", "\n", "mask_u", "=", "(", "u", ">", "0", ")", "*", "(", "u", "<", "1", ")", "# intersection on line segment 2", "\n", "mask", "=", "mask_t", "*", "mask_u", "\n", "# overwrite with EPSILON. otherwise numerically unstable", "\n", "t", "=", "den_t", "/", "(", "num", "+", "EPSILON", ")", "\n", "intersections", "=", "torch", ".", "stack", "(", "[", "x1", "+", "t", "*", "(", "x2", "-", "x1", ")", ",", "y1", "+", "t", "*", "(", "y2", "-", "y1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "intersections", "=", "intersections", "*", "mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "intersections", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.get_in_box_points": [[61, 89], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "get_in_box_points", "(", "polys1", ":", "torch", ".", "Tensor", ",", "polys2", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"check if corners of poly1 lie in poly2\n    Convention: if a corner is exactly on the edge of the other box, it's also a valid point\n\n    Args:\n        polys1 (torch.Tensor): (n, 4, 2)\n        polys2 (torch.Tensor): (n, 4, 2)\n\n    Returns:\n        c1_in_2: (n, 4) Bool\n    \"\"\"", "\n", "a", "=", "polys2", "[", "...", ",", "0", ":", "1", ",", ":", "]", "# (n, 1, 2)", "\n", "b", "=", "polys2", "[", "...", ",", "1", ":", "2", ",", ":", "]", "# (n, 1, 2)", "\n", "d", "=", "polys2", "[", "...", ",", "3", ":", "4", ",", ":", "]", "# (n, 1, 2)", "\n", "ab", "=", "b", "-", "a", "# (n, 1, 2)", "\n", "am", "=", "polys1", "-", "a", "# (n, 4, 2)", "\n", "ad", "=", "d", "-", "a", "# (n, 1, 2)", "\n", "p_ab", "=", "torch", ".", "sum", "(", "ab", "*", "am", ",", "dim", "=", "-", "1", ")", "# (n, 4)", "\n", "norm_ab", "=", "torch", ".", "sum", "(", "ab", "*", "ab", ",", "dim", "=", "-", "1", ")", "# (n, 1)", "\n", "p_ad", "=", "torch", ".", "sum", "(", "ad", "*", "am", ",", "dim", "=", "-", "1", ")", "# (n, 4)", "\n", "norm_ad", "=", "torch", ".", "sum", "(", "ad", "*", "ad", ",", "dim", "=", "-", "1", ")", "# (n, 1)", "\n", "# NOTE: the expression looks ugly but is stable if the two boxes are exactly the same", "\n", "# also stable with different scale of bboxes", "\n", "cond1", "=", "(", "p_ab", "/", "norm_ab", ">", "-", "1e-6", ")", "*", "(", "p_ab", "/", "norm_ab", "<", "1", "+", "1e-6", ")", "# (n, 4)", "\n", "cond2", "=", "(", "p_ad", "/", "norm_ad", ">", "-", "1e-6", ")", "*", "(", "p_ad", "/", "norm_ad", "<", "1", "+", "1e-6", ")", "# (n, 4)", "\n", "return", "cond1", "*", "cond2", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.build_vertices": [[91, 117], ["polys1.size", "torch.cat", "torch.cat", "inters.view", "mask_inter.view"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.size"], ["", "def", "build_vertices", "(", "polys1", ":", "torch", ".", "Tensor", ",", "polys2", ":", "torch", ".", "Tensor", ",", "\n", "c1_in_2", ":", "torch", ".", "Tensor", ",", "c2_in_1", ":", "torch", ".", "Tensor", ",", "\n", "inters", ":", "torch", ".", "Tensor", ",", "mask_inter", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"find vertices of intersection area\n\n    Args:\n        polys1 (torch.Tensor): (n, 4, 2)\n        polys2 (torch.Tensor): (n, 4, 2)\n        c1_in_2 (torch.Tensor): Bool, (n, 4)\n        c2_in_1 (torch.Tensor): Bool, (n, 4)\n        inters (torch.Tensor): (n, 4, 4, 2)\n        mask_inter (torch.Tensor): (n, 4, 4)\n\n    Returns:\n        vertices (torch.Tensor): (n, 24, 2) vertices of intersection area. only some elements are valid\n        mask (torch.Tensor): (n, 24) indicates valid elements in vertices\n    \"\"\"", "\n", "# NOTE: inter has elements equals zero and has zeros gradient (masked by multiplying with 0).", "\n", "# can be used as trick", "\n", "n", "=", "polys1", ".", "size", "(", "0", ")", "\n", "# (n, 4+4+16, 2)", "\n", "vertices", "=", "torch", ".", "cat", "(", "[", "polys1", ",", "polys2", ",", "inters", ".", "view", "(", "\n", "[", "n", ",", "-", "1", ",", "2", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "# Bool (n, 4+4+16)", "\n", "mask", "=", "torch", ".", "cat", "(", "[", "c1_in_2", ",", "c2_in_1", ",", "mask_inter", ".", "view", "(", "[", "n", ",", "-", "1", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "return", "vertices", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.sort_indices": [[119, 146], ["vertices.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze", "torch.sum().int", "sort_vertices_cuda.sort_vertices_forward().squeeze().long", "torch.sum", "torch.sum().int.unsqueeze().unsqueeze", "torch.sum", "sort_vertices_cuda.sort_vertices_forward().squeeze", "mask.unsqueeze.int", "mask.unsqueeze.float().unsqueeze", "torch.sum().int.unsqueeze", "sort_vertices_cuda.sort_vertices_forward", "mask.unsqueeze.float"], "function", ["None"], ["", "def", "sort_indices", "(", "vertices", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"[summary]\n\n    Args:\n        vertices (torch.Tensor): float (n, 24, 2)\n        mask (torch.Tensor): bool (n, 24)\n\n    Returns:\n        sorted_index: bool (n, 9)\n\n    Note:\n        why 9? the polygon has maximal 8 vertices. +1 to duplicate the first element.\n        the index should have following structure:\n            (A, B, C, ... , A, X, X, X) \n        and X indicates the index of arbitary elements in the last 16 (intersections not corners) with \n        value 0 and mask False. (cause they have zero value and zero gradient)\n    \"\"\"", "\n", "# here we pad dim 0 to be consistent with the `sort_vertices_forward` function", "\n", "vertices", "=", "vertices", ".", "unsqueeze", "(", "0", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "num_valid", "=", "torch", ".", "sum", "(", "mask", ".", "int", "(", ")", ",", "dim", "=", "2", ")", ".", "int", "(", ")", "# (B, N)", "\n", "mean", "=", "torch", ".", "sum", "(", "vertices", "*", "mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "dim", "=", "2", ",", "\n", "keepdim", "=", "True", ")", "/", "num_valid", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# normalization makes sorting easier", "\n", "vertices_normalized", "=", "vertices", "-", "mean", "\n", "return", "sort_vertices_forward", "(", "vertices_normalized", ",", "mask", ",", "num_valid", ")", ".", "squeeze", "(", "0", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.calculate_area": [[148, 166], ["idx_sorted.unsqueeze().repeat", "torch.gather", "torch.sum", "torch.abs", "idx_sorted.unsqueeze"], "function", ["None"], ["", "def", "calculate_area", "(", "idx_sorted", ":", "torch", ".", "Tensor", ",", "vertices", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"calculate area of intersection\n\n    Args:\n        idx_sorted (torch.Tensor): (n, 9)\n        vertices (torch.Tensor): (n, 24, 2)\n\n    return:\n        area: (n), area of intersection\n        selected: (n, 9, 2), vertices of polygon with zero padding \n    \"\"\"", "\n", "idx_ext", "=", "idx_sorted", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "[", "1", ",", "1", ",", "2", "]", ")", "\n", "selected", "=", "torch", ".", "gather", "(", "vertices", ",", "1", ",", "idx_ext", ")", "\n", "total", "=", "selected", "[", "...", ",", "0", ":", "-", "1", ",", "0", "]", "*", "selected", "[", "...", ",", "1", ":", ",", "1", "]", "-", "selected", "[", "...", ",", "0", ":", "-", "1", ",", "1", "]", "*", "selected", "[", "...", ",", "1", ":", ",", "0", "]", "\n", "total", "=", "torch", ".", "sum", "(", "total", ",", "dim", "=", "1", ")", "\n", "area", "=", "torch", ".", "abs", "(", "total", ")", "/", "2", "\n", "return", "area", ",", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.oriented_box_intersection_2d": [[168, 191], ["box_intersection_2d.get_intersection_points", "box_intersection_2d.get_in_box_points", "box_intersection_2d.get_in_box_points", "box_intersection_2d.build_vertices", "box_intersection_2d.sort_indices", "box_intersection_2d.calculate_area"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.get_intersection_points", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.get_in_box_points", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.get_in_box_points", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.build_vertices", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.sort_indices", "home.repos.pwc.inspect_result.steven-lang_dafne.losses.box_intersection_2d.calculate_area"], ["", "def", "oriented_box_intersection_2d", "(", "polys1", ":", "torch", ".", "Tensor", ",", "polys2", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"calculate intersection area of 2d rectangles \n\n    Args:\n        polys1 (torch.Tensor): (n, 4, 2)\n        polys2 (torch.Tensor): (n, 4, 2)\n\n    Returns:\n        area: (n,), area of intersection\n        selected: (n, 9, 2), vertices of polygon with zero padding \n    \"\"\"", "\n", "# find intersection points", "\n", "inters", ",", "mask_inter", "=", "get_intersection_points", "(", "polys1", ",", "polys2", ")", "\n", "# find inter points", "\n", "c12", "=", "get_in_box_points", "(", "polys1", ",", "polys2", ")", "\n", "c21", "=", "get_in_box_points", "(", "polys2", ",", "polys1", ")", "\n", "# build vertices", "\n", "vertices", ",", "mask", "=", "build_vertices", "(", "\n", "polys1", ",", "polys2", ",", "c12", ",", "c21", ",", "inters", ",", "mask_inter", ")", "\n", "# getting sorted indices", "\n", "sorted_indices", "=", "sort_indices", "(", "vertices", ",", "mask", ")", "\n", "# calculate areas using torch.gather", "\n", "return", "calculate_area", "(", "sorted_indices", ",", "vertices", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.utils.reduce_loss": [[10, 26], ["torch._Reduction.get_enum", "loss.mean", "loss.sum"], "function", ["None"], ["import", "xml", ".", "etree", ".", "ElementTree", "as", "ET", "\n", "import", "codecs", "\n", "import", "cv2", "\n", "import", "sys", "\n", "import", "numpy", "as", "np", "\n", "import", "random", "\n", "import", "shutil", "\n", "import", "shapely", ".", "geometry", "as", "shgeo", "\n", "import", "re", "\n", "import", "pickle", "\n", "import", "math", "\n", "import", "copy", "\n", "\n", "\n", "## initail annotation", "\n", "datamap", "=", "{", "'0A'", ":", "'passenger plane'", ",", "'0B'", ":", "'fighter aeroplane'", ",", "'0C'", ":", "'radar warning aircraft'", ",", "\n", "'1'", ":", "'baseball diamond'", ",", "'2'", ":", "'bridge'", ",", "'3'", ":", "'ground track'", ",", "'4A'", ":", "'car'", ",", "'4B'", ":", "'truck'", ",", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.utils.weight_reduce_loss": [[28, 53], ["utils.reduce_loss", "reduce_loss.sum", "ValueError"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.losses.utils.reduce_loss"], ["'7B'", ":", "'half basketball'", ",", "'8'", ":", "'storage tank'", ",", "'9'", ":", "'soccer ball field'", ",", "'10'", ":", "'Turntable'", ",", "\n", "'11'", ":", "'harbor'", ",", "'12'", ":", "'electric pole'", ",", "'13'", ":", "'parking lot'", ",", "'14'", ":", "'swimming pool'", ",", "'15'", ":", "'lake'", ",", "\n", "'16'", ":", "'helicopter'", ",", "'17'", ":", "'airport'", ",", "'18A'", ":", "'viaduct'", ",", "'18B'", ":", "'18B'", ",", "'18C'", ":", "'18C'", ",", "'18D'", ":", "'18D'", ",", "\n", "'18E'", ":", "'18E'", ",", "'18F'", ":", "'18F'", ",", "'18G'", ":", "'18G'", ",", "'18H'", ":", "'18H'", ",", "'18I'", ":", "'18I'", ",", "'18J'", ":", "'18J'", ",", "'18K'", ":", "'18K'", ",", "\n", "'18L'", ":", "'18L'", ",", "'18M'", ":", "'18M'", ",", "'18N'", ":", "'18N'", ",", "'4A_area'", ":", "'4A_area'", ",", "'4B_area'", ":", "'4B_area'", ",", "\n", "'5A_area'", ":", "'5A_area'", ",", "'8_area'", ":", "'8_area'", ",", "'13_area'", ":", "'13_area'", ",", "'bridge'", ":", "'bridge'", ",", "'plane'", ":", "'plane'", ",", "\n", "'ship'", ":", "'ship'", ",", "'storage'", ":", "'storage'", ",", "'harbor'", ":", "'harbor'", "}", "\n", "classname", "=", "[", "'0A'", ",", "'0B'", ",", "'0C'", ",", "'1'", ",", "'2'", ",", "'3'", ",", "'4A'", ",", "'4B'", ",", "'4C'", ",", "'5A'", ",", "'5B'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'10'", "\n", ",", "'11'", ",", "'12'", ",", "'13'", ",", "'14'", ",", "'15'", ",", "'16'", ",", "'17'", ",", "'18A'", ",", "'18B'", ",", "'18C'", ",", "'18D'", ",", "'18E'", "\n", ",", "'18F'", ",", "'18G'", ",", "'18H'", ",", "'18I'", ",", "'18J'", ",", "'18K'", ",", "'18L'", ",", "'18M'", ",", "'18N'", ",", "'5'", ",", "'plane'", ",", "'ship'", ",", "'storage'", ",", "'bridge'", ",", "\n", "'harbor'", "]", "\n", "clsdict", "=", "{", "'0A'", ":", "0", ",", "'0B'", ":", "0", ",", "'0C'", ":", "0", ",", "'1'", ":", "0", ",", "'2'", ":", "0", ",", "'3'", ":", "0", ",", "'4A'", ":", "0", ",", "'4B'", ":", "0", ",", "'4C'", ":", "0", ",", "'5A'", ":", "0", ",", "'5B'", ":", "0", ",", "'6'", ":", "0", ",", "\n", "'7'", ":", "0", ",", "'8'", ":", "0", ",", "'9'", ":", "0", ",", "'10'", ":", "0", "\n", ",", "'11'", ":", "0", ",", "'12'", ":", "0", ",", "'13'", ":", "0", ",", "'14'", ":", "0", ",", "'15'", ":", "0", ",", "'16'", ":", "0", ",", "'17'", ":", "0", ",", "'18A'", ":", "0", ",", "'18B'", ":", "0", ",", "'18C'", ":", "0", ",", "'18D'", ":", "0", ",", "\n", "'18E'", ":", "0", "\n", ",", "'18F'", ":", "0", ",", "'18G'", ":", "0", ",", "'18H'", ":", "0", ",", "'18I'", ":", "0", ",", "'18J'", ":", "0", ",", "'18K'", ":", "0", ",", "'18L'", ":", "0", ",", "'18M'", ":", "0", ",", "'18N'", ":", "0", ",", "'5'", ":", "0", "\n", ",", "'plane'", ":", "0", ",", "'ship'", ":", "0", ",", "'storage'", ":", "0", ",", "'bridge'", ":", "0", ",", "'harbor'", ":", "0", "}", "\n", "### tmp experiments", "\n", "datamap2", "=", "{", "'0A'", ":", "'passenger plane'", ",", "'0B'", ":", "'fighter aeroplane'", ",", "'0C'", ":", "'radar'", ",", "\n", "'1'", ":", "'baseball diamond'", ",", "'2'", ":", "'bridge'", ",", "'3'", ":", "'ground track'", ",", "'4A'", ":", "'car'", ",", "'4B'", ":", "'trunck'", ",", "\n", "'4C'", ":", "'bus'", ",", "'5A'", ":", "'ship'", ",", "'5B'", ":", "'big ship'", ",", "'6'", ":", "'tennis court'", ",", "'7'", ":", "'baseketball court'", ",", "\n", "'8'", ":", "'storage tank'", ",", "'9'", ":", "'soccer ball field'", ",", "'10'", ":", "'turntable'", ",", "\n", "'11'", ":", "'harbor'", ",", "'12'", ":", "'electric pole'", ",", "'13'", ":", "'parking lot'", ",", "'14'", ":", "'swimming pool'", ",", "'15'", ":", "'lake'", ",", "\n", "'16'", ":", "'helicopter'", ",", "'17'", ":", "'airport'", ",", "'18A'", ":", "'viaduct'", "}", "\n", "classname_part", "=", "[", "'0A'", ",", "'0B'", ",", "'0C'", ",", "'1'", ",", "'2'", ",", "'3'", ",", "'4A'", ",", "'4B'", ",", "'4C'", ",", "'5A'", ",", "'5B'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'10'", "\n", ",", "'11'", ",", "'12'", ",", "'13'", ",", "'14'", ",", "'15'", ",", "'16'", ",", "'17'", ",", "'18A'", "]", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.losses.utils.weighted_loss": [[55, 94], ["functools.wraps", "loss_func", "utils.weight_reduce_loss"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.losses.utils.weight_reduce_loss"], ["\n", "## prepare for release v1", "\n", "datamap_15_new", "=", "{", "'0A'", ":", "'plane'", ",", "'0B'", ":", "'plane'", ",", "'0C'", ":", "'plane'", ",", "'1'", ":", "'baseball-diamond'", ",", "'2'", ":", "'bridge'", ",", "'3'", ":", "'ground-track-field'", ",", "'4A'", ":", "'small-vehicle'", ",", "'4B'", ":", "'large-vehicle'", ",", "\n", "'4C'", ":", "'large-vehicle'", ",", "'5A'", ":", "'ship'", ",", "'5B'", ":", "'ship'", ",", "'6'", ":", "'tennis-court'", ",", "'7'", ":", "'basketball-court'", ",", "\n", "'8'", ":", "'storage-tank'", ",", "'9'", ":", "'soccer-ball-field'", ",", "'10'", ":", "'roundabout'", ",", "\n", "'11'", ":", "'harbor'", ",", "'14'", ":", "'swimming-pool'", ",", "\n", "'16'", ":", "'helicopter'", "}", "\n", "\n", "wordname_15_new", "=", "[", "'plane'", ",", "'baseball-diamond'", ",", "'bridge'", ",", "'ground-track-field'", ",", "'small-vehicle'", ",", "'large-vehicle'", ",", "'ship'", ",", "'tennis-court'", ",", "\n", "'basketball-court'", ",", "'storage-tank'", ",", "'soccer-ball-field'", ",", "'roundabout'", ",", "'harbor'", ",", "'swimming-pool'", ",", "'helicopter'", "]", "\n", "\n", "## before release 1.0 version", "\n", "datamap_15", "=", "{", "'0A'", ":", "'plane'", ",", "'0B'", ":", "'plane'", ",", "'0C'", ":", "'plane'", ",", "'1'", ":", "'baseball-diamond'", ",", "'2'", ":", "'bridge'", ",", "'3'", ":", "'ground-track-field'", ",", "'4A'", ":", "'small-vehicle'", ",", "'4B'", ":", "'large-vehicle'", ",", "\n", "'4C'", ":", "'large-vehicle'", ",", "'5A'", ":", "'ship'", ",", "'5B'", ":", "'ship'", ",", "'6'", ":", "'tennis-court'", ",", "'7'", ":", "'basketball-court'", ",", "\n", "'8'", ":", "'storage-tank'", ",", "'9'", ":", "'soccer-ball-field'", ",", "'10'", ":", "'turntable'", ",", "\n", "'11'", ":", "'harbor'", ",", "'14'", ":", "'swimming-pool'", ",", "\n", "'16'", ":", "'helicopter'", "}", "\n", "identity_15", "=", "{", "x", ":", "x", "for", "x", "in", "datamap_15", "}", "\n", "\n", "noorientationnames", "=", "[", "'bridge'", ",", "'ground-track-field'", ",", "'tennis-court'", ",", "'basketball-court'", ",", "\n", "'soccer-ball-field'", ",", "\n", "'swimming-pool'", ",", "\n", "]", "\n", "\n", "classname_15", "=", "[", "'0A'", ",", "'0B'", ",", "'0C'", ",", "'1'", ",", "'2'", ",", "'3'", ",", "'4A'", ",", "'4B'", ",", "'4C'", ",", "'5A'", ",", "'5B'", ",", "'6'", ",", "'7'", ",", "'8'", ",", "'9'", ",", "'10'", ",", "'11'", ",", "'14'", ",", "'16'", "]", "\n", "\n", "clsdict_15", "=", "{", "'0A'", ":", "0", ",", "'0B'", ":", "0", ",", "'0C'", ":", "0", ",", "'1'", ":", "0", ",", "'2'", ":", "0", ",", "'3'", ":", "0", ",", "'4A'", ":", "0", ",", "'4B'", ":", "0", ",", "'4C'", ":", "0", ",", "'5A'", ":", "0", ",", "'5B'", ":", "0", ",", "'6'", ":", "0", ",", "\n", "'7'", ":", "0", ",", "'8'", ":", "0", ",", "'9'", ":", "0", ",", "'10'", ":", "0", "\n", ",", "'11'", ":", "0", ",", "'14'", ":", "0", ",", "'16'", ":", "0", "}", "\n", "\n", "wordname_15", "=", "[", "'plane'", ",", "'baseball-diamond'", ",", "'bridge'", ",", "'ground-track-field'", ",", "'small-vehicle'", ",", "'large-vehicle'", ",", "'ship'", ",", "'tennis-court'", ",", "\n", "'basketball-court'", ",", "'storage-tank'", ",", "'soccer-ball-field'", ",", "'turntable'", ",", "'harbor'", ",", "'swimming-pool'", ",", "'helicopter'", "]", "\n", "classnums_15", "=", "{", "'ground-track-field'", ":", "0", ",", "'small-vehicle'", ":", "0", ",", "'large-vehicle'", ":", "0", ",", "'harbor'", ":", "0", ",", "'plane'", ":", "0", ",", "'ship'", ":", "0", ",", "'basketball-court'", ":", "0", ",", "\n", "'swimming-pool'", ":", "0", ",", "'helicopter'", ":", "0", ",", "'bridge'", ":", "0", ",", "'tennis-court'", ":", "0", ",", "\n", "'baseball-diamond'", ":", "0", ",", "'storage-tank'", ":", "0", ",", "'soccer-ball-field'", ":", "0", ",", "'turntable'", ":", "0", "}", "\n", "\n", "subcategory", "=", "[", "'helicopter'", ",", "'bridge'", ",", "'baseball-diamond'", ",", "\n", "'ground-track-field'", ",", "'basketball-court'", ",", "\n", "'soccer-ball-field'", ",", "'harbor'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.config.config.get_cfg": [[4, 14], ["_C.clone"], "function", ["None"], ["def", "get_cfg", "(", ")", "->", "CfgNode", ":", "\n", "    ", "\"\"\"\n    Get a copy of the default config.\n\n    Returns:\n        a detectron2 CfgNode instance.\n    \"\"\"", "\n", "from", ".", "defaults", "import", "_C", "\n", "\n", "return", "_C", ".", "clone", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv._NewEmptyTensorOp.forward": [[13, 17], ["x.new_empty"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv._NewEmptyTensorOp.backward": [[18, 22], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2dNoOffset.__init__": [[210, 260], ["torch.nn.Module.__init__", "isinstance", "conv_block", "isinstance", "isinstance", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "with_modulated_dcn", "=", "False", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "padding", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DFConv2dNoOffset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "kernel_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "isinstance", "(", "stride", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "dilation", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "kernel_size", ")", "==", "2", "\n", "assert", "len", "(", "stride", ")", "==", "2", "\n", "assert", "len", "(", "dilation", ")", "==", "2", "\n", "padding", "=", "(", "\n", "dilation", "[", "0", "]", "*", "(", "kernel_size", "[", "0", "]", "-", "1", ")", "//", "2", ",", "\n", "dilation", "[", "1", "]", "*", "(", "kernel_size", "[", "1", "]", "-", "1", ")", "//", "2", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "padding", "=", "dilation", "*", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "", "if", "with_modulated_dcn", ":", "\n", "            ", "from", "detectron2", ".", "layers", ".", "deform_conv", "import", "ModulatedDeformConv", "\n", "\n", "conv_block", "=", "ModulatedDeformConv", "\n", "", "else", ":", "\n", "            ", "from", "detectron2", ".", "layers", ".", "deform_conv", "import", "DeformConv", "\n", "\n", "conv_block", "=", "DeformConv", "\n", "", "self", ".", "conv", "=", "conv_block", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "\n", "deformable_groups", "=", "deformable_groups", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "with_modulated_dcn", "=", "with_modulated_dcn", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2dNoOffset.forward": [[261, 280], ["_NewEmptyTensorOp.apply", "deform_conv.DFConv2dNoOffset.numel", "deform_conv.DFConv2dNoOffset.conv", "deform_conv.DFConv2dNoOffset.offset", "offset_mask[].sigmoid", "deform_conv.DFConv2dNoOffset.conv", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "offset", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "if", "not", "self", ".", "with_modulated_dcn", ":", "\n", "                ", "x", "=", "self", ".", "conv", "(", "x", ",", "offset", ")", "\n", "", "else", ":", "\n", "                ", "offset_mask", "=", "self", ".", "offset", "(", "x", ")", "\n", "offset", "=", "offset_mask", "[", ":", ",", ":", "self", ".", "offset_split", ",", ":", ",", ":", "]", "\n", "mask", "=", "offset_mask", "[", ":", ",", "self", ".", "offset_split", ":", ",", ":", ",", ":", "]", ".", "sigmoid", "(", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ",", "offset", ",", "mask", ")", "\n", "", "return", "x", "\n", "# get output shape", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "d", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "conv", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.__init__": [[290, 359], ["torch.nn.Module.__init__", "isinstance", "detectron2.layers.Conv2d", "conv_block", "isinstance", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "with_modulated_dcn", "=", "True", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "deformable_groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "padding", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DFConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "kernel_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "isinstance", "(", "stride", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "dilation", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "kernel_size", ")", "==", "2", "\n", "assert", "len", "(", "stride", ")", "==", "2", "\n", "assert", "len", "(", "dilation", ")", "==", "2", "\n", "padding", "=", "(", "\n", "dilation", "[", "0", "]", "*", "(", "kernel_size", "[", "0", "]", "-", "1", ")", "//", "2", ",", "\n", "dilation", "[", "1", "]", "*", "(", "kernel_size", "[", "1", "]", "-", "1", ")", "//", "2", ",", "\n", ")", "\n", "offset_base_channels", "=", "kernel_size", "[", "0", "]", "*", "kernel_size", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "padding", "=", "dilation", "*", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "offset_base_channels", "=", "kernel_size", "*", "kernel_size", "\n", "", "if", "with_modulated_dcn", ":", "\n", "            ", "from", "detectron2", ".", "layers", ".", "deform_conv", "import", "ModulatedDeformConv", "\n", "\n", "offset_channels", "=", "offset_base_channels", "*", "3", "# default: 27", "\n", "conv_block", "=", "ModulatedDeformConv", "\n", "", "else", ":", "\n", "            ", "from", "detectron2", ".", "layers", ".", "deform_conv", "import", "DeformConv", "\n", "\n", "offset_channels", "=", "offset_base_channels", "*", "2", "# default: 18", "\n", "conv_block", "=", "DeformConv", "\n", "", "self", ".", "offset", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "deformable_groups", "*", "offset_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "groups", "=", "1", ",", "\n", "dilation", "=", "dilation", ",", "\n", ")", "\n", "for", "l", "in", "[", "\n", "self", ".", "offset", ",", "\n", "]", ":", "\n", "            ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "l", ".", "weight", ",", "a", "=", "1", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0.0", ")", "\n", "", "self", ".", "conv", "=", "conv_block", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "\n", "deformable_groups", "=", "deformable_groups", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "with_modulated_dcn", "=", "with_modulated_dcn", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "offset_split", "=", "offset_base_channels", "*", "deformable_groups", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.DFConv2d.forward": [[360, 382], ["_NewEmptyTensorOp.apply", "deform_conv.DFConv2d.numel", "deform_conv.DFConv2d.offset", "deform_conv.DFConv2d.conv", "deform_conv.DFConv2d.offset", "offset_mask[].sigmoid", "deform_conv.DFConv2d.conv", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "return_offset", "=", "False", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "if", "not", "self", ".", "with_modulated_dcn", ":", "\n", "                ", "offset_mask", "=", "self", ".", "offset", "(", "x", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ",", "offset_mask", ")", "\n", "", "else", ":", "\n", "                ", "offset_mask", "=", "self", ".", "offset", "(", "x", ")", "\n", "offset", "=", "offset_mask", "[", ":", ",", ":", "self", ".", "offset_split", ",", ":", ",", ":", "]", "\n", "mask", "=", "offset_mask", "[", ":", ",", "self", ".", "offset_split", ":", ",", ":", ",", ":", "]", ".", "sigmoid", "(", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ",", "offset", ",", "mask", ")", "\n", "", "if", "return_offset", ":", "\n", "                ", "return", "x", ",", "offset_mask", "\n", "", "return", "x", "\n", "# get output shape", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "d", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "conv", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "x", ",", "output_shape", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.ltrb_to_offset_mask": [[23, 77], ["ltrb.unbind", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat"], "function", ["None"], ["", "", "def", "ltrb_to_offset_mask", "(", "ltrb", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert the corner regression to an offset mask.\n\n    Generate a 3x3 offset mask:\n\n    off_0 = tl | off_1 | off_2 = tr\n    -----------|-------|-----------\n    off_3      | off_4 | off_5\n    -----------|-------|-----------\n    off_6 = bl | off_7 | off_8 = br\n\n    tl = top-left, tr = top-right, bl = bottom-left, br = bottom-right.\n\n    Where the corners off_0, off_2, off_6 and off_8 are equal to the original corners,\n    off_4 is the mean of all corners (center), and off_1, off_3, off_5, off_7 are\n    middle-points on the edge between the corners accordingly.\n\n    Args:\n        corners: Tensor of shape [N, 4, H, W]\n    Returns:\n        torch.Tensor: Offset tensor of shape [N, 18, H, W].\n    \"\"\"", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "ltrb", ".", "shape", "\n", "\n", "l", ",", "t", ",", "r", ",", "b", "=", "ltrb", ".", "unbind", "(", "1", ")", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "-", "l", ",", "-", "t", ",", "r", ",", "b", "\n", "\n", "# Compute corners from hbox xmin,ymin,xmax,ymax", "\n", "tl", "=", "torch", ".", "stack", "(", "(", "ymin", ",", "xmin", ")", ",", "dim", "=", "1", ")", "\n", "bl", "=", "torch", ".", "stack", "(", "(", "ymax", ",", "xmin", ")", ",", "dim", "=", "1", ")", "\n", "br", "=", "torch", ".", "stack", "(", "(", "ymax", ",", "xmax", ")", ",", "dim", "=", "1", ")", "\n", "tr", "=", "torch", ".", "stack", "(", "(", "ymin", ",", "xmax", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Corners", "\n", "off_0", "=", "tl", "\n", "off_2", "=", "tr", "\n", "off_8", "=", "br", "\n", "off_6", "=", "bl", "\n", "\n", "# Center", "\n", "off_4", "=", "(", "tl", "+", "tr", "+", "br", "+", "bl", ")", "/", "4", "\n", "\n", "# Middle-points on edges", "\n", "off_1", "=", "(", "tl", "+", "tr", ")", "/", "2", "\n", "off_5", "=", "(", "tr", "+", "br", ")", "/", "2", "\n", "off_7", "=", "(", "bl", "+", "br", ")", "/", "2", "\n", "off_3", "=", "(", "tl", "+", "bl", ")", "/", "2", "\n", "\n", "# Cat in column-major order", "\n", "offset", "=", "torch", ".", "cat", "(", "\n", "(", "off_0", ",", "off_1", ",", "off_2", ",", "off_3", ",", "off_4", ",", "off_5", ",", "off_6", ",", "off_7", ",", "off_8", ")", ",", "dim", "=", "1", "\n", ")", "\n", "return", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.hbox_to_offset_mask": [[78, 131], ["hbox.unbind", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat"], "function", ["None"], ["", "def", "hbox_to_offset_mask", "(", "hbox", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert the corner regression to an offset mask.\n\n    Generate a 3x3 offset mask:\n\n    off_0 = tl | off_1 | off_2 = tr\n    -----------|-------|-----------\n    off_3      | off_4 | off_5\n    -----------|-------|-----------\n    off_6 = bl | off_7 | off_8 = br\n\n    tl = top-left, tr = top-right, bl = bottom-left, br = bottom-right.\n\n    Where the corners off_0, off_2, off_6 and off_8 are equal to the original corners,\n    off_4 is the mean of all corners (center), and off_1, off_3, off_5, off_7 are\n    middle-points on the edge between the corners accordingly.\n\n    Args:\n        corners: Tensor of shape [N, 4, H, W]\n    Returns:\n        torch.Tensor: Offset tensor of shape [N, 18, H, W].\n    \"\"\"", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "hbox", ".", "shape", "\n", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "hbox", ".", "unbind", "(", "1", ")", "\n", "\n", "# Compute corners from hbox xmin,ymin,xmax,ymax", "\n", "tl", "=", "torch", ".", "stack", "(", "(", "ymin", ",", "xmin", ")", ",", "dim", "=", "1", ")", "\n", "bl", "=", "torch", ".", "stack", "(", "(", "ymax", ",", "xmin", ")", ",", "dim", "=", "1", ")", "\n", "br", "=", "torch", ".", "stack", "(", "(", "ymax", ",", "xmax", ")", ",", "dim", "=", "1", ")", "\n", "tr", "=", "torch", ".", "stack", "(", "(", "ymin", ",", "xmax", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Corners", "\n", "off_0", "=", "tl", "\n", "off_2", "=", "tr", "\n", "off_8", "=", "br", "\n", "off_6", "=", "bl", "\n", "\n", "# Center", "\n", "off_4", "=", "(", "tl", "+", "tr", "+", "br", "+", "bl", ")", "/", "4", "\n", "\n", "# Middle-points on edges", "\n", "off_1", "=", "(", "tl", "+", "tr", ")", "/", "2", "\n", "off_5", "=", "(", "tr", "+", "br", ")", "/", "2", "\n", "off_7", "=", "(", "bl", "+", "br", ")", "/", "2", "\n", "off_3", "=", "(", "tl", "+", "bl", ")", "/", "2", "\n", "\n", "# Cat in column-major order", "\n", "offset", "=", "torch", ".", "cat", "(", "\n", "(", "off_0", ",", "off_1", ",", "off_2", ",", "off_3", ",", "off_4", ",", "off_5", ",", "off_6", ",", "off_7", ",", "off_8", ")", ",", "dim", "=", "1", "\n", ")", "\n", "return", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.center_to_offset_mask": [[133, 148], ["center.repeat"], "function", ["None"], ["", "def", "center_to_offset_mask", "(", "center", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert the corner regression to an offset mask.\n\n    Generate a 3x3 offset mask that shifts the convolution sampling\n    by the given center value.\n\n\n    Args:\n        corners: Tensor of shape [N, 8, H, W]\n    Returns:\n        torch.Tensor: Offset tensor of shape [N, 18, H, W].\n    \"\"\"", "\n", "offset", "=", "center", ".", "repeat", "(", "1", ",", "3", "*", "3", ",", "1", ",", "1", ")", "\n", "return", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.layers.deform_conv.corners_to_offset_mask": [[150, 196], ["corners.view().unbind", "torch.cat", "corners.view"], "function", ["None"], ["", "def", "corners_to_offset_mask", "(", "corners", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Convert the corner regression to an offset mask.\n\n    Generate a 3x3 offset mask:\n\n    off_0 = c0 | off_1 | off_2 = c3\n    -----------|-------|-----------\n    off_3      | off_4 | off_5\n    -----------|-------|-----------\n    off_6 = c1 | off_7 | off_8 = c2\n\n    Where the corners off_0, off_2, off_6 and off_8 are equal to the original corners,\n    off_4 is the mean of all corners (center), and off_1, off_3, off_5, off_7 are\n    middle-points on the edge between the corners accordingly.\n\n    Args:\n        corners: Tensor of shape [N, 8, H, W]\n    Returns:\n        torch.Tensor: Offset tensor of shape [N, 18, H, W].\n    \"\"\"", "\n", "N", ",", "C", ",", "H", ",", "W", "=", "corners", ".", "shape", "\n", "# Swap (x, y) coordinates since the offset arrays expects (y, x) format", "\n", "corners", "=", "corners", "[", ":", ",", "[", "1", ",", "0", ",", "3", ",", "2", ",", "5", ",", "4", ",", "7", ",", "6", "]", ",", ":", ",", ":", "]", "\n", "c0", ",", "c1", ",", "c2", ",", "c3", "=", "corners", ".", "view", "(", "N", ",", "4", ",", "2", ",", "H", ",", "W", ")", ".", "unbind", "(", "1", ")", "\n", "\n", "# Corners", "\n", "off_0", "=", "c0", "\n", "off_2", "=", "c3", "\n", "off_8", "=", "c2", "\n", "off_6", "=", "c1", "\n", "\n", "# Center", "\n", "off_4", "=", "(", "c0", "+", "c1", "+", "c2", "+", "c3", ")", "/", "4", "\n", "\n", "# Middle-points on edges", "\n", "off_1", "=", "(", "off_0", "+", "off_2", ")", "/", "2", "\n", "off_5", "=", "(", "off_2", "+", "off_8", ")", "/", "2", "\n", "off_7", "=", "(", "off_6", "+", "off_8", ")", "/", "2", "\n", "off_3", "=", "(", "off_0", "+", "off_6", ")", "/", "2", "\n", "\n", "# Cat in column-major order", "\n", "offset", "=", "torch", ".", "cat", "(", "\n", "(", "off_0", ",", "off_1", ",", "off_2", ",", "off_3", ",", "off_4", ",", "off_5", ",", "off_6", ",", "off_7", ",", "off_8", ")", ",", "dim", "=", "1", "\n", ")", "\n", "return", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.load_annotation": [[39, 55], ["os.path.join", "os.path.join", "open", "f.read", "f.read.split", "numpy.array", "numpy.array", "len", "boxes.append", "gt_classes.append", "obj.split", "obj.split", "eval"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "load_annotation", "(", "root_dir", ",", "img_id", ")", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"Annotations\"", ",", "img_id", "+", "\".txt\"", ")", "\n", "\n", "boxes", ",", "gt_classes", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "read", "(", ")", "\n", "objects", "=", "content", ".", "split", "(", "\"\\n\"", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "if", "len", "(", "obj", ")", "!=", "0", ":", "\n", "                ", "class_name", "=", "obj", ".", "split", "(", ")", "[", "0", "]", "\n", "box", "=", "obj", ".", "split", "(", ")", "[", "1", ":", "9", "]", "\n", "label", "=", "name2label", "[", "class_name", "]", "\n", "box", "=", "[", "eval", "(", "x", ")", "for", "x", "in", "box", "]", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "gt_classes", ".", "append", "(", "label", ")", "\n", "", "", "", "return", "{", "\"boxes\"", ":", "np", ".", "array", "(", "boxes", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\"gt_classes\"", ":", "np", ".", "array", "(", "gt_classes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.xywha2xy4": [[57, 63], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["", "def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.norm_angle": [[65, 67], ["None"], "function", ["None"], ["", "def", "norm_angle", "(", "angle", ",", "range", "=", "[", "-", "np", ".", "pi", "/", "4", ",", "np", ".", "pi", "]", ")", ":", "\n", "    ", "return", "(", "angle", "-", "range", "[", "0", "]", ")", "%", "range", "[", "1", "]", "+", "range", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.parse_annotation": [[75, 129], ["ucas_aod.load_annotation", "os.path.join", "os.path.join", "cv2.imread", "range", "numpy.array().reshape", "numpy.abs", "numpy.abs", "numpy.maximum", "numpy.array", "obbox.reshape().tolist", "objs.append", "bbox[].min", "bbox[].max", "bbox[].min", "bbox[].max", "numpy.array", "obbox.reshape"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.load_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "parse_annotation", "(", "img_id", ":", "str", ",", "root", ":", "str", ")", ":", "\n", "    ", "anno", "=", "load_annotation", "(", "root_dir", "=", "root", ",", "img_id", "=", "img_id", ")", "\n", "\n", "# Construct image and annotation path", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"AllImages\"", ",", "f\"{img_id}.png\"", ")", "\n", "# anno_path = os.path.join(root, \"Annotations\", f\"{img_id}.txt\")", "\n", "\n", "# Create new data record for each image", "\n", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "img_path", "\n", "record", "[", "\"image_id\"", "]", "=", "img_id", "[", "1", ":", "]", "# Strip starting letter \"P\"", "\n", "\n", "img", "=", "cv2", ".", "imread", "(", "img_path", ")", "\n", "record", "[", "\"width\"", "]", "=", "img", ".", "shape", "[", "1", "]", "\n", "record", "[", "\"height\"", "]", "=", "img", ".", "shape", "[", "0", "]", "\n", "\n", "# Collect annotations", "\n", "objs", "=", "[", "]", "\n", "num_objects", "=", "anno", "[", "\"boxes\"", "]", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "num_objects", ")", ":", "\n", "        ", "obj", "=", "{", "}", "\n", "obbox", "=", "anno", "[", "\"boxes\"", "]", "[", "i", "]", "\n", "label", "=", "anno", "[", "\"gt_classes\"", "]", "[", "i", "]", "-", "1", "\n", "\n", "if", "label", "==", "-", "1", ":", "\n", "# Skip background", "\n", "            ", "continue", "\n", "\n", "", "bbox", "=", "np", ".", "array", "(", "obbox", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "xmin", ",", "xmax", "=", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "ymin", ",", "ymax", "=", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "w", "=", "np", ".", "abs", "(", "xmax", "-", "xmin", ")", "\n", "h", "=", "np", ".", "abs", "(", "ymax", "-", "ymin", ")", "\n", "\n", "ar", "=", "np", ".", "maximum", "(", "w", "/", "(", "h", "+", "1e-16", ")", ",", "h", "/", "(", "w", "+", "1e-16", ")", ")", "\n", "is_valid_box", "=", "(", "w", ">", "2", ")", "&", "(", "h", ">", "2", ")", "&", "(", "ar", "<", "30", ")", "\n", "if", "not", "is_valid_box", ":", "\n", "            ", "continue", "\n", "\n", "", "obj", "[", "\"bbox\"", "]", "=", "[", "xmin", ",", "ymin", ",", "w", ",", "h", "]", "\n", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYWH_ABS", "\n", "obj", "[", "\"area\"", "]", "=", "w", "*", "h", "\n", "area", "=", "w", "*", "h", "\n", "bbox", "=", "np", ".", "array", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "\n", "obj", "[", "\"segmentation\"", "]", "=", "obbox", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "obj", "[", "\"category_id\"", "]", "=", "label", "\n", "obj", "[", "\"bbox\"", "]", "=", "bbox", "\n", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "obj", "[", "\"difficult\"", "]", "=", "0", "\n", "obj", "[", "\"area\"", "]", "=", "area", "\n", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "return", "record", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.load_ucas_aod": [[131, 148], ["isinstance", "open", "f.read().splitlines", "ucas_aod.parse_annotation", "dataset_dicts.append", "os.path.join", "os.path.join", "f.read"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.parse_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "load_ucas_aod", "(", "root", ",", "image_set", ",", "cfg", ")", ":", "\n", "    ", "image_sets", "=", "[", "image_set", "]", "if", "isinstance", "(", "image_set", ",", "str", ")", "else", "image_set", "\n", "dataset_dicts", "=", "[", "]", "\n", "for", "image_set", "in", "image_sets", ":", "\n", "# Read lines in image set file", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"ImageSets\"", ",", "f\"{image_set}.txt\"", ")", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "# Select the first N images", "\n", "            ", "lines", "=", "lines", "[", ":", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", "]", "\n", "\n", "", "for", "img_id", "in", "lines", ":", "\n", "            ", "record", "=", "parse_annotation", "(", "img_id", ",", "root", ")", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.register_ucas_aod_instances": [[150, 181], ["isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "ucas_aod.load_ucas_aod", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.load_ucas_aod"], ["", "def", "register_ucas_aod_instances", "(", "name", ",", "split", ",", "metadata", ",", "image_root", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "\n", "lambda", ":", "load_ucas_aod", "(", "\n", "root", "=", "metadata", "[", "\"root_dir\"", "]", ",", "\n", "image_set", "=", "split", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"ucas_aod\"", ",", "**", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod._make_datasets_dict": [[183, 197], ["None"], "function", ["None"], ["", "def", "_make_datasets_dict", "(", ")", ":", "\n", "    ", "datasets_dict", "=", "{", "}", "\n", "# Construct datasets dict from currently available datasets", "\n", "for", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "name", "=", "f\"ucas_aod_{split}\"", "\n", "datasets_dict", "[", "name", "]", "=", "{", "\n", "\"root_dir\"", ":", "\"UCAS-AOD\"", ",", "\n", "\"img_dir\"", ":", "\"images\"", ",", "\n", "\"ann_file\"", ":", "f\"ImageSets/{split}.txt\"", ",", "\n", "\"split\"", ":", "split", ",", "\n", "\"is_test\"", ":", "\"test\"", "in", "name", ",", "\n", "}", "\n", "\n", "", "return", "datasets_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.ucas_aod.register_ucas_aod": [[199, 223], ["ucas_aod._make_datasets_dict", "detectron2.utils.colormap.colormap", "_make_datasets_dict.items", "ucas_aod.register_ucas_aod.reg"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota._make_datasets_dict"], ["", "def", "register_ucas_aod", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Setup method to register the ucas_aod dataset.\"\"\"", "\n", "datasets_dict", "=", "_make_datasets_dict", "(", ")", "\n", "\n", "# Get the data directory", "\n", "data_dir", "=", "os", ".", "environ", "[", "\"DAFNE_DATA_DIR\"", "]", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "255", ")", "\n", "for", "dataset_name", ",", "d", "in", "datasets_dict", ".", "items", "(", ")", ":", "\n", "\n", "        ", "def", "reg", "(", "name", ")", ":", "\n", "            ", "register_ucas_aod_instances", "(", "\n", "name", "=", "name", ",", "\n", "metadata", "=", "{", "\n", "\"is_test\"", ":", "d", "[", "\"is_test\"", "]", ",", "\n", "\"root_dir\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ")", ",", "\n", "\"thing_colors\"", ":", "colors", ",", "\n", "}", ",", "\n", "image_root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ",", "d", "[", "\"img_dir\"", "]", ")", ",", "\n", "split", "=", "d", "[", "\"split\"", "]", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", "\n", "\n", "# Register normal version", "\n", "", "reg", "(", "dataset_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.load_annotation": [[39, 56], ["os.path.join", "os.path.join", "open", "f.read", "f.read.split", "numpy.array", "numpy.array", "len", "boxes.append", "gt_classes.append", "obj.split", "eval"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "load_annotation", "(", "root_dir", ",", "img_id", ",", "imageset", ")", ":", "\n", "    ", "if", "imageset", "==", "\"val\"", ":", "\n", "        ", "imageset", "=", "\"train\"", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"Annotations\"", ",", "imageset", ",", "\"gt_img_\"", "+", "img_id", "+", "\".txt\"", ")", "\n", "\n", "boxes", ",", "gt_classes", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "read", "(", ")", "\n", "objects", "=", "content", ".", "split", "(", "\"\\n\"", ")", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "if", "len", "(", "obj", ")", "!=", "0", ":", "\n", "                ", "box", "=", "obj", ".", "split", "(", "\",\"", ")", "[", "0", ":", "8", "]", "\n", "label", "=", "0", "\n", "box", "=", "[", "eval", "(", "x", ")", "for", "x", "in", "box", "]", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "gt_classes", ".", "append", "(", "label", ")", "\n", "", "", "", "return", "{", "\"boxes\"", ":", "np", ".", "array", "(", "boxes", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\"gt_classes\"", ":", "np", ".", "array", "(", "gt_classes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.xywha2xy4": [[58, 64], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["", "def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.norm_angle": [[66, 68], ["None"], "function", ["None"], ["", "def", "norm_angle", "(", "angle", ",", "range", "=", "[", "-", "np", ".", "pi", "/", "4", ",", "np", ".", "pi", "]", ")", ":", "\n", "    ", "return", "(", "angle", "-", "range", "[", "0", "]", ")", "%", "range", "[", "1", "]", "+", "range", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.parse_annotation": [[76, 124], ["icdar15.load_annotation", "os.path.join", "os.path.join", "cv2.imread", "range", "numpy.array().reshape", "numpy.abs", "numpy.abs", "numpy.maximum", "numpy.array", "obbox.reshape().tolist", "objs.append", "bbox[].min", "bbox[].max", "bbox[].min", "bbox[].max", "numpy.array", "obbox.reshape"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.load_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "parse_annotation", "(", "img_id", ":", "str", ",", "root", ":", "str", ",", "image_set", ":", "str", ")", ":", "\n", "    ", "anno", "=", "load_annotation", "(", "root_dir", "=", "root", ",", "img_id", "=", "img_id", ",", "imageset", "=", "image_set", ")", "\n", "\n", "# Construct image and annotation path", "\n", "if", "image_set", "==", "\"val\"", ":", "\n", "        ", "image_set", "=", "\"train\"", "# val images are in the train folder", "\n", "", "img_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"images\"", ",", "image_set", ",", "f\"img_{img_id}.jpg\"", ")", "\n", "\n", "# Create new data record for each image", "\n", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "img_path", "\n", "record", "[", "\"image_id\"", "]", "=", "img_id", "# Strip starting letter \"P\"", "\n", "\n", "img", "=", "cv2", ".", "imread", "(", "img_path", ")", "\n", "record", "[", "\"width\"", "]", "=", "img", ".", "shape", "[", "1", "]", "\n", "record", "[", "\"height\"", "]", "=", "img", ".", "shape", "[", "0", "]", "\n", "\n", "# Collect annotations", "\n", "objs", "=", "[", "]", "\n", "num_objects", "=", "anno", "[", "\"boxes\"", "]", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "num_objects", ")", ":", "\n", "        ", "obj", "=", "{", "}", "\n", "obbox", "=", "anno", "[", "\"boxes\"", "]", "[", "i", "]", "\n", "label", "=", "0", "\n", "\n", "bbox", "=", "np", ".", "array", "(", "obbox", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "xmin", ",", "xmax", "=", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "ymin", ",", "ymax", "=", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "w", "=", "np", ".", "abs", "(", "xmax", "-", "xmin", ")", "\n", "h", "=", "np", ".", "abs", "(", "ymax", "-", "ymin", ")", "\n", "\n", "ar", "=", "np", ".", "maximum", "(", "w", "/", "(", "h", "+", "1e-16", ")", ",", "h", "/", "(", "w", "+", "1e-16", ")", ")", "\n", "is_valid_box", "=", "(", "w", ">", "2", ")", "&", "(", "h", ">", "2", ")", "&", "(", "ar", "<", "30", ")", "\n", "if", "not", "is_valid_box", ":", "\n", "            ", "continue", "\n", "\n", "", "area", "=", "w", "*", "h", "\n", "bbox", "=", "np", ".", "array", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "\n", "obj", "[", "\"segmentation\"", "]", "=", "obbox", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "obj", "[", "\"category_id\"", "]", "=", "label", "\n", "obj", "[", "\"bbox\"", "]", "=", "bbox", "\n", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYXY_ABS", "\n", "obj", "[", "\"difficult\"", "]", "=", "0", "\n", "obj", "[", "\"area\"", "]", "=", "area", "\n", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "return", "record", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.load_icdar15": [[126, 144], ["isinstance", "open", "f.read().splitlines", "img_id.replace.replace", "icdar15.parse_annotation", "dataset_dicts.append", "os.path.join", "os.path.join", "f.read"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.parse_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "load_icdar15", "(", "root", ",", "image_set", ",", "cfg", ")", ":", "\n", "    ", "image_sets", "=", "[", "image_set", "]", "if", "isinstance", "(", "image_set", ",", "str", ")", "else", "image_set", "\n", "dataset_dicts", "=", "[", "]", "\n", "for", "image_set", "in", "image_sets", ":", "\n", "# Read lines in image set file", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"ImageSets\"", ",", "f\"{image_set}.txt\"", ")", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "# Select the first N images", "\n", "            ", "lines", "=", "lines", "[", ":", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", "]", "\n", "\n", "", "for", "img_id", "in", "lines", ":", "\n", "            ", "img_id", "=", "img_id", ".", "replace", "(", "\"gt_img_\"", ",", "\"\"", ")", "\n", "record", "=", "parse_annotation", "(", "img_id", ",", "root", ",", "image_set", ")", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.register_icdar15_instances": [[146, 177], ["isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "icdar15.load_icdar15", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.load_icdar15"], ["", "def", "register_icdar15_instances", "(", "name", ",", "split", ",", "metadata", ",", "image_root", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "\n", "lambda", ":", "load_icdar15", "(", "\n", "root", "=", "metadata", "[", "\"root_dir\"", "]", ",", "\n", "image_set", "=", "split", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"icdar15\"", ",", "**", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15._make_datasets_dict": [[179, 194], ["None"], "function", ["None"], ["", "def", "_make_datasets_dict", "(", ")", ":", "\n", "    ", "datasets_dict", "=", "{", "}", "\n", "# Construct datasets dict from currently available datasets", "\n", "for", "split", "in", "[", "\"train\"", ",", "\"test\"", ",", "\"val\"", "]", ":", "\n", "        ", "name", "=", "f\"icdar15_{split}\"", "\n", "img_dir", "=", "\"images/train\"", "if", "split", "in", "[", "\"train\"", ",", "\"val\"", "]", "else", "\"images/test\"", "\n", "datasets_dict", "[", "name", "]", "=", "{", "\n", "\"root_dir\"", ":", "\"icdar-2015\"", ",", "\n", "\"img_dir\"", ":", "img_dir", ",", "\n", "\"ann_file\"", ":", "f\"ImageSets/{split}.txt\"", ",", "\n", "\"split\"", ":", "split", ",", "\n", "\"is_test\"", ":", "\"test\"", "in", "name", ",", "\n", "}", "\n", "\n", "", "return", "datasets_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.register_icdar15": [[196, 220], ["icdar15._make_datasets_dict", "detectron2.utils.colormap.colormap", "_make_datasets_dict.items", "icdar15.register_icdar15.reg"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota._make_datasets_dict"], ["", "def", "register_icdar15", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Setup method to register the icdar15 dataset.\"\"\"", "\n", "datasets_dict", "=", "_make_datasets_dict", "(", ")", "\n", "\n", "# Get the data directory", "\n", "data_dir", "=", "os", ".", "environ", "[", "\"DAFNE_DATA_DIR\"", "]", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "255", ")", "\n", "for", "dataset_name", ",", "d", "in", "datasets_dict", ".", "items", "(", ")", ":", "\n", "\n", "        ", "def", "reg", "(", "name", ")", ":", "\n", "            ", "register_icdar15_instances", "(", "\n", "name", "=", "name", ",", "\n", "metadata", "=", "{", "\n", "\"is_test\"", ":", "d", "[", "\"is_test\"", "]", ",", "\n", "\"root_dir\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ")", ",", "\n", "\"thing_colors\"", ":", "colors", ",", "\n", "}", ",", "\n", "image_root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ",", "d", "[", "\"img_dir\"", "]", ")", ",", "\n", "split", "=", "d", "[", "\"split\"", "]", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", "\n", "\n", "# Register normal version", "\n", "", "reg", "(", "dataset_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.HrscDatasetMapper.__call__": [[165, 184], ["super().__call__", "instances.has", "numpy.stack().squeeze", "torch.tensor", "dafne.utils.sort_corners.sort_quadrilateral", "instances.gt_masks.area().float", "torch.empty", "torch.empty", "len", "numpy.stack", "instances.gt_masks.area"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dafne_dataset_mapper.DAFNeDatasetMapper.__call__", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort_quadrilateral", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["    ", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "result", "=", "super", "(", ")", ".", "__call__", "(", "dataset_dict", ")", "\n", "if", "\"instances\"", "in", "result", ":", "\n", "            ", "instances", "=", "result", "[", "\"instances\"", "]", "\n", "if", "instances", ".", "has", "(", "\"gt_masks\"", ")", "and", "len", "(", "instances", ".", "gt_masks", ")", ">", "0", ":", "\n", "                ", "gt_masks", "=", "np", ".", "stack", "(", "instances", ".", "gt_masks", ")", ".", "squeeze", "(", "1", ")", "\n", "gt_corners", "=", "torch", ".", "tensor", "(", "gt_masks", ",", "dtype", "=", "instances", ".", "gt_boxes", ".", "tensor", ".", "dtype", ")", "\n", "\n", "# Sort corners", "\n", "gt_corners", "=", "sort_quadrilateral", "(", "gt_corners", ")", "\n", "\n", "instances", ".", "gt_corners", "=", "gt_corners", "\n", "instances", ".", "gt_corners_area", "=", "instances", ".", "gt_masks", ".", "area", "(", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "instances", ".", "gt_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "instances", ".", "gt_corners_area", "=", "torch", ".", "empty", "(", "0", ")", "\n", "", "result", "[", "\"instances\"", "]", "=", "instances", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.xywha2xy4": [[37, 43], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.norm_angle": [[45, 47], ["None"], "function", ["None"], ["", "def", "norm_angle", "(", "angle", ",", "range", "=", "[", "-", "np", ".", "pi", "/", "4", ",", "np", ".", "pi", "]", ")", ":", "\n", "    ", "return", "(", "angle", "-", "range", "[", "0", "]", ")", "%", "range", "[", "1", "]", "+", "range", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.load_hrsc": [[55, 129], ["isinstance", "open", "f.read().splitlines", "int", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "xml.parse", "ET.parse.getroot", "int", "int", "[].findall", "dataset_dicts.append", "os.path.join", "os.path.join", "int", "list", "xywha2xy4().reshape().tolist", "numpy.array", "numpy.abs", "numpy.abs", "objs.append", "f.read", "anno_tree.getroot.find", "anno_tree.getroot.find", "np.array.append", "map", "bbox[].min", "bbox[].max", "bbox[].min", "bbox[].max", "anno_tree.getroot.findall", "obj.find", "xywha2xy4().reshape", "obj.find", "hrsc2016.xywha2xy4"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.xywha2xy4"], ["def", "load_hrsc", "(", "root", ",", "image_set", ",", "cfg", ")", ":", "\n", "    ", "image_sets", "=", "[", "image_set", "]", "if", "isinstance", "(", "image_set", ",", "str", ")", "else", "image_set", "\n", "dataset_dicts", "=", "[", "]", "\n", "for", "image_set", "in", "image_sets", ":", "\n", "# Read lines in image set file", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"ImageSets\"", ",", "f\"{image_set}.txt\"", ")", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "# Select the first N images", "\n", "            ", "lines", "=", "lines", "[", ":", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", "]", "\n", "\n", "", "for", "img_id", "in", "lines", ":", "\n", "            ", "img_id", "=", "int", "(", "img_id", ")", "\n", "# Construct image and annotation path", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"images\"", ",", "f\"{img_id}.bmp\"", ")", "\n", "anno_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"labelXml\"", ",", "f\"{img_id}.xml\"", ")", "\n", "\n", "# Create new data record for each image", "\n", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "img_path", "\n", "record", "[", "\"image_id\"", "]", "=", "img_id", "\n", "\n", "# Parse annotation", "\n", "anno_tree", "=", "ET", ".", "parse", "(", "anno_path", ")", "\n", "anno_root", "=", "anno_tree", ".", "getroot", "(", ")", "\n", "\n", "record", "[", "\"width\"", "]", "=", "int", "(", "anno_root", ".", "find", "(", "\"Img_SizeWidth\"", ")", ".", "text", ")", "\n", "record", "[", "\"height\"", "]", "=", "int", "(", "anno_root", ".", "find", "(", "\"Img_SizeHeight\"", ")", ".", "text", ")", "\n", "\n", "# # Skip invalid paths", "\n", "# if not anno_path:", "\n", "#     continue", "\n", "\n", "# Collect annotations", "\n", "objs", "=", "[", "]", "\n", "for", "obj", "in", "anno_root", ".", "findall", "(", "\"HRSC_Objects\"", ")", "[", "0", "]", ".", "findall", "(", "\"HRSC_Object\"", ")", ":", "\n", "                ", "label", "=", "name2label", "[", "\"ship\"", "]", "\n", "difficult", "=", "int", "(", "obj", ".", "find", "(", "\"difficult\"", ")", ".", "text", ")", "\n", "bbox", "=", "[", "]", "\n", "for", "key", "in", "[", "\"mbox_cx\"", ",", "\"mbox_cy\"", ",", "\"mbox_w\"", ",", "\"mbox_h\"", ",", "\"mbox_ang\"", "]", ":", "\n", "                    ", "bbox", ".", "append", "(", "obj", ".", "find", "(", "key", ")", ".", "text", ")", "\n", "# TODO: check whether it is necessary to use int", "\n", "# Coordinates may be float type", "\n", "", "cx", ",", "cy", ",", "w", ",", "h", ",", "a", "=", "list", "(", "map", "(", "float", ",", "bbox", ")", ")", "\n", "# set w the long side and h the short side", "\n", "# new_w, new_h = max(w, h), min(w, h)", "\n", "# # adjust angle", "\n", "# a = a if w > h else a + np.pi / 2", "\n", "# normalize angle to [-np.pi/4, pi/4*3]", "\n", "# a = norm_angle(a)", "\n", "bbox", "=", "[", "cx", ",", "cy", ",", "w", ",", "h", ",", "a", "]", "\n", "\n", "obj", "=", "{", "}", "\n", "obbox", "=", "xywha2xy4", "(", "bbox", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "obj", "[", "\"segmentation\"", "]", "=", "obbox", "\n", "obj", "[", "\"category_id\"", "]", "=", "label", "\n", "obj", "[", "\"difficult\"", "]", "=", "difficult", "\n", "\n", "bbox", "=", "np", ".", "array", "(", "obbox", ")", "\n", "xmin", ",", "xmax", "=", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "0", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "ymin", ",", "ymax", "=", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "min", "(", ")", ",", "bbox", "[", ":", ",", "1", ":", ":", "2", "]", ".", "max", "(", ")", "\n", "w", "=", "np", ".", "abs", "(", "xmax", "-", "xmin", ")", "\n", "h", "=", "np", ".", "abs", "(", "ymax", "-", "ymin", ")", "\n", "obj", "[", "\"bbox\"", "]", "=", "[", "xmin", ",", "ymin", ",", "w", ",", "h", "]", "\n", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYWH_ABS", "\n", "obj", "[", "\"area\"", "]", "=", "w", "*", "h", "\n", "\n", "objs", ".", "append", "(", "obj", ")", "\n", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.register_hrsc_instances": [[131, 162], ["isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "hrsc2016.load_hrsc", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.load_hrsc"], ["", "def", "register_hrsc_instances", "(", "name", ",", "split", ",", "metadata", ",", "image_root", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "\n", "lambda", ":", "load_hrsc", "(", "\n", "root", "=", "metadata", "[", "\"root_dir\"", "]", ",", "\n", "image_set", "=", "split", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"hrsc\"", ",", "**", "metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016._make_datasets_dict": [[186, 200], ["None"], "function", ["None"], ["", "", "def", "_make_datasets_dict", "(", ")", ":", "\n", "    ", "datasets_dict", "=", "{", "}", "\n", "# Construct datasets dict from currently available datasets", "\n", "for", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "name", "=", "f\"hrsc_{split}\"", "\n", "datasets_dict", "[", "name", "]", "=", "{", "\n", "\"root_dir\"", ":", "\"hrsc\"", ",", "\n", "\"img_dir\"", ":", "\"images\"", ",", "\n", "\"ann_file\"", ":", "f\"ImageSets/{split}.txt\"", ",", "\n", "\"split\"", ":", "split", ",", "\n", "\"is_test\"", ":", "\"test\"", "in", "name", ",", "\n", "}", "\n", "\n", "", "return", "datasets_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.hrsc2016.register_hrsc": [[202, 226], ["hrsc2016._make_datasets_dict", "detectron2.utils.colormap.colormap", "_make_datasets_dict.items", "hrsc2016.register_hrsc.reg"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota._make_datasets_dict"], ["", "def", "register_hrsc", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Setup method to register the hrsc dataset.\"\"\"", "\n", "datasets_dict", "=", "_make_datasets_dict", "(", ")", "\n", "\n", "# Get the data directory", "\n", "data_dir", "=", "os", ".", "environ", "[", "\"DAFNE_DATA_DIR\"", "]", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "255", ")", "\n", "for", "dataset_name", ",", "d", "in", "datasets_dict", ".", "items", "(", ")", ":", "\n", "\n", "        ", "def", "reg", "(", "name", ")", ":", "\n", "            ", "register_hrsc_instances", "(", "\n", "name", "=", "name", ",", "\n", "metadata", "=", "{", "\n", "\"is_test\"", ":", "d", "[", "\"is_test\"", "]", ",", "\n", "\"root_dir\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ")", ",", "\n", "\"thing_colors\"", ":", "colors", ",", "\n", "}", ",", "\n", "image_root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ",", "d", "[", "\"img_dir\"", "]", ")", ",", "\n", "split", "=", "d", "[", "\"split\"", "]", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", "\n", "\n", "# Register normal version", "\n", "", "reg", "(", "dataset_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dafne_dataset_mapper.DAFNeDatasetMapper.__init__": [[14, 17], ["detectron2.data.DatasetMapper.__init__"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "**", "kwargs", ")", "\n", "self", ".", "_cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dafne_dataset_mapper.DAFNeDatasetMapper.__call__": [[18, 48], ["super().__call__", "detectron2.data.detection_utils.filter_empty_instances", "detectron2.data.detection_utils.filter_empty_instances.has", "enumerate", "detectron2.data.detection_utils.filter_empty_instances.has", "numpy.stack().squeeze", "torch.tensor", "detectron2.data.detection_utils.filter_empty_instances.gt_masks.area().float", "torch.empty", "torch.empty", "len", "len", "dafne.utils.sort_corners.sort_quadrilateral", "numpy.stack", "detectron2.data.detection_utils.filter_empty_instances.gt_masks.area"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dafne_dataset_mapper.DAFNeDatasetMapper.__call__", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.utils.sort_corners.sort_quadrilateral"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "result", "=", "super", "(", ")", ".", "__call__", "(", "dataset_dict", ")", "\n", "if", "\"instances\"", "in", "result", ":", "\n", "            ", "instances", "=", "result", "[", "\"instances\"", "]", "\n", "\n", "\n", "# Iterate over polygons and check that they are still valid", "\n", "if", "instances", ".", "has", "(", "\"gt_masks\"", ")", "and", "len", "(", "instances", ".", "gt_masks", ".", "polygons", ")", ">", "0", ":", "\n", "                ", "for", "i", ",", "ps", "in", "enumerate", "(", "instances", ".", "gt_masks", ")", ":", "\n", "                    ", "instances", ".", "gt_masks", ".", "polygons", "[", "i", "]", "=", "[", "p", "for", "p", "in", "ps", "if", "p", ".", "shape", "[", "0", "]", "==", "8", "]", "\n", "\n", "\n", "", "", "instances", "=", "filter_empty_instances", "(", "instances", ",", "by_mask", "=", "True", ")", "\n", "\n", "if", "instances", ".", "has", "(", "\"gt_masks\"", ")", "and", "len", "(", "instances", ".", "gt_masks", ")", ">", "0", ":", "\n", "                ", "gt_masks", "=", "np", ".", "stack", "(", "instances", ".", "gt_masks", ")", ".", "squeeze", "(", "1", ")", "\n", "gt_corners", "=", "torch", ".", "tensor", "(", "gt_masks", ",", "dtype", "=", "instances", ".", "gt_boxes", ".", "tensor", ".", "dtype", ")", "\n", "\n", "# Sort corners", "\n", "if", "self", ".", "_cfg", ".", "MODEL", ".", "DAFNE", ".", "SORT_CORNERS_DATALOADER", ":", "\n", "                    ", "gt_corners", "=", "sort_quadrilateral", "(", "gt_corners", ")", "\n", "\n", "", "instances", ".", "gt_corners", "=", "gt_corners", "\n", "instances", ".", "gt_corners_area", "=", "instances", ".", "gt_masks", ".", "area", "(", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "instances", ".", "gt_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "instances", ".", "gt_corners_area", "=", "torch", ".", "empty", "(", "0", ")", "\n", "", "result", "[", "\"instances\"", "]", "=", "instances", "\n", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.plot_hist": [[37, 42], ["matplotlib.figure", "matplotlib.title", "seaborn.kdeplot", "matplotlib.savefig", "os.path.join", "os.path.join"], "function", ["None"], ["def", "plot_hist", "(", "data", ",", "output_dir", ",", "dataset_name", ",", "var_name", ")", ":", "\n", "    ", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "title", "(", "f\"{dataset_name}: {var_name}\"", ")", "\n", "sns", ".", "kdeplot", "(", "data", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{dataset_name}_{var_name}\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.load_dota_json": [[47, 321], ["dataset_name.endswith", "fvcore.common.timer.Timer", "fvcore.common.file_io.PathManager.get_local_path", "sorted", "COCO.loadImgs", "sum", "len", "list", "logger.info", "scipy.stats.mstats.mquantiles", "scipy.stats.mstats.mquantiles", "logger.info", "logger.info", "numpy.histogram", "numpy.histogram", "numpy.histogram", "logger.info", "logger.info", "logger.info", "logger.warn", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logger.info", "detectron2.data.MetadataCatalog.get", "sorted", "COCO.loadCats", "COCO.imgs.keys", "logger.warning", "zip", "os.path.join", "os.path.join", "np.random.choice().tolist.append", "logger.warning", "len", "int", "max", "numpy.random.choice().tolist", "io.StringIO", "COCO.getCatIds", "len", "len", "len", "len", "areas.append", "ws.append", "hs.append", "anno.get", "anno.get", "objs.append", "fvcore.common.timer.Timer.seconds", "sorted", "logger.warning", "enumerate", "set", "anno.get", "isinstance", "numpy.array().reshape", "range", "enumerate", "numpy.random.choice", "len", "min", "max", "len", "max", "isinstance", "range", "pycocotools.frPyObjects", "len", "numpy.array", "numpy.sum", "numpy.abs", "len", "len"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.DOTA.DOTA.loadImgs", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "load_dota_json", "(", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ",", "extra_annotation_keys", "=", "None", ",", "cfg", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    ---\n    Code used from detectron2.data.datasets.coco.load_coco_json to adopt for DOTA.\n    ---\n\n    Load a json file with COCO's instances annotation format.\n    Currently supports instance detection, instance segmentation,\n    and person keypoints annotations.\n\n    Args:\n        json_file (str): full path to the json file in COCO instances annotation format.\n        image_root (str or path-like): the directory where the images in this json file exists.\n        dataset_name (str): the name of the dataset (e.g., coco_2017_train).\n            If provided, this function will also put \"thing_classes\" into\n            the metadata associated with this dataset.\n        extra_annotation_keys (list[str]): list of per-annotation keys that should also be\n            loaded into the dataset dict (besides \"iscrowd\", \"bbox\", \"keypoints\",\n            \"category_id\", \"segmentation\"). The values for these keys will be returned as-is.\n            For example, the densepose annotations are loaded in this way.\n        cfg (ConfigNode): Configuration node object.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard dataset dicts format. (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ )\n\n    Notes:\n        1. This function does not read the image files.\n           The results do not have the \"image\" field.\n    \"\"\"", "\n", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "\n", "# Check if this should be the mini version", "\n", "if", "dataset_name", ".", "endswith", "(", "\"_mini\"", ")", ":", "\n", "        ", "dataset_name", "=", "dataset_name", "[", ":", "-", "len", "(", "\"_mini\"", ")", "]", "\n", "is_mini_set", "=", "True", "\n", "", "else", ":", "\n", "        ", "is_mini_set", "=", "False", "\n", "\n", "", "timer", "=", "Timer", "(", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "        ", "coco_api", "=", "COCO", "(", "json_file", ")", "\n", "", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "", "id_map", "=", "None", "\n", "if", "dataset_name", "is", "not", "None", ":", "\n", "        ", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "cat_ids", "=", "sorted", "(", "coco_api", ".", "getCatIds", "(", ")", ")", "\n", "cats", "=", "coco_api", ".", "loadCats", "(", "cat_ids", ")", "\n", "# The categories in a custom json file may not be sorted.", "\n", "thing_classes", "=", "[", "c", "[", "\"name\"", "]", "for", "c", "in", "sorted", "(", "cats", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "]", "\n", "\n", "# # Remove container-crane to make DOTA 1.5 compatible wiith DOTA 1.0", "\n", "# if \"container-crane\" in thing_classes:", "\n", "#     thing_classes.remove(\"container-crane\")", "\n", "\n", "meta", ".", "thing_classes", "=", "thing_classes", "\n", "\n", "# In COCO, certain category ids are artificially removed,", "\n", "# and by convention they are always ignored.", "\n", "# We deal with COCO's id issue and translate", "\n", "# the category ids to contiguous ids in [0, 80).", "\n", "\n", "# It works by looking at the \"categories\" field in the json, therefore", "\n", "# if users' own json also have incontiguous ids, we'll", "\n", "# apply this mapping as well but print a warning.", "\n", "if", "not", "(", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "cat_ids", ")", ")", ":", "\n", "            ", "if", "\"coco\"", "not", "in", "dataset_name", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"\"\"\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\"\"\"", "\n", ")", "\n", "", "", "id_map", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "cat_ids", ")", "}", "\n", "meta", ".", "thing_dataset_id_to_contiguous_id", "=", "id_map", "\n", "\n", "# sort indices for reproducible results", "\n", "", "img_ids", "=", "sorted", "(", "coco_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "\n", "if", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", ">", "0", ":", "\n", "# Select the first N images", "\n", "        ", "img_ids", "=", "img_ids", "[", ":", "cfg", ".", "DEBUG", ".", "OVERFIT_NUM_IMAGES", "]", "\n", "\n", "# imgs is a list of dicts, each looks something like:", "\n", "# {'license': 4,", "\n", "#  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',", "\n", "#  'file_name': 'COCO_val2014_000000001268.jpg',", "\n", "#  'height': 427,", "\n", "#  'width': 640,", "\n", "#  'date_captured': '2013-11-17 05:57:24',", "\n", "#  'id': 1268}", "\n", "", "imgs", "=", "coco_api", ".", "loadImgs", "(", "img_ids", ")", "\n", "# anns is a list[list[dict]], where each dict is an annotation", "\n", "# record for an object. The inner list enumerates the objects in an image", "\n", "# and the outer list enumerates over images. Example of anns[0]:", "\n", "# [{'segmentation': [[192.81,", "\n", "#     247.09,", "\n", "#     ...", "\n", "#     219.03,", "\n", "#     249.06]],", "\n", "#   'area': 1035.749,", "\n", "#   'iscrowd': 0,", "\n", "#   'image_id': 1268,", "\n", "#   'bbox': [192.81, 224.8, 74.73, 33.43],", "\n", "#   'category_id': 16,", "\n", "#   'id': 42986},", "\n", "#  ...]", "\n", "anns", "=", "[", "coco_api", ".", "imgToAnns", "[", "img_id", "]", "for", "img_id", "in", "img_ids", "]", "\n", "total_num_valid_anns", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "anns", "]", ")", "\n", "total_num_anns", "=", "len", "(", "coco_api", ".", "anns", ")", "\n", "if", "total_num_valid_anns", "<", "total_num_anns", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"{json_file} contains {total_num_anns} annotations, but only \"", "\n", "f\"{total_num_valid_anns} of them match to images in the file.\"", "\n", ")", "\n", "\n", "", "if", "\"minival\"", "not", "in", "json_file", ":", "\n", "# The popular valminusminival & minival annotations for COCO2014 contain this bug.", "\n", "# However the ratio of buggy annotations there is tiny and does not affect accuracy.", "\n", "# Therefore we explicitly white-list them.", "\n", "        ", "ann_ids", "=", "[", "ann", "[", "\"id\"", "]", "for", "anns_per_image", "in", "anns", "for", "ann", "in", "anns_per_image", "]", "\n", "assert", "len", "(", "set", "(", "ann_ids", ")", ")", "==", "len", "(", "ann_ids", ")", ",", "\"Annotation ids in '{}' are not unique!\"", ".", "format", "(", "\n", "json_file", "\n", ")", "\n", "\n", "", "imgs_anns", "=", "list", "(", "zip", "(", "imgs", ",", "anns", ")", ")", "\n", "logger", ".", "info", "(", "\"Loaded {} images in COCO format from {}\"", ".", "format", "(", "len", "(", "imgs_anns", ")", ",", "json_file", ")", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "\n", "ann_keys", "=", "[", "\"bbox\"", ",", "\"category_id\"", "]", "+", "(", "extra_annotation_keys", "or", "[", "]", ")", "\n", "\n", "num_instances_without_valid_segmentation", "=", "0", "\n", "count_skipped_boxes", "=", "0", "\n", "area_skipped", "=", "[", "]", "\n", "w_skipped", "=", "[", "]", "\n", "h_skipped", "=", "[", "]", "\n", "\n", "areas", "=", "[", "]", "\n", "ws", "=", "[", "]", "\n", "hs", "=", "[", "]", "\n", "\n", "count_skipped_container_crane", "=", "0", "\n", "\n", "for", "(", "img_dict", ",", "anno_dict_list", ")", "in", "imgs_anns", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "os", ".", "path", ".", "join", "(", "image_root", ",", "img_dict", "[", "\"file_name\"", "]", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "anno_dict_list", ":", "\n", "# Check that the image_id in this annotation is the same as", "\n", "# the image_id we're looking at.", "\n", "# This fails only when the data parsing logic or the annotation file is buggy.", "\n", "\n", "# The original COCO valminusminival2014 & minival2014 annotation files", "\n", "# actually contains bugs that, together with certain ways of using COCO API,", "\n", "# can trigger this assertion.", "\n", "            ", "assert", "anno", "[", "\"image_id\"", "]", "==", "image_id", "\n", "\n", "assert", "anno", ".", "get", "(", "\"ignore\"", ",", "0", ")", "==", "0", ",", "'\"ignore\" in COCO json file is not supported.'", "\n", "\n", "obj", "=", "{", "key", ":", "anno", "[", "key", "]", "for", "key", "in", "ann_keys", "if", "key", "in", "anno", "}", "\n", "\n", "# # Skip container-crane in dota_1_5 to make 1.5 compatible with 1.0", "\n", "# if obj[\"category_id\"] == 16:", "\n", "#     count_skipped_container_crane += 1", "\n", "#     continue", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "obj", "[", "\"bbox\"", "]", "\n", "area", "=", "obj", "[", "\"area\"", "]", "\n", "areas", ".", "append", "(", "area", ")", "\n", "ws", ".", "append", "(", "w", ")", "\n", "hs", ".", "append", "(", "h", ")", "\n", "# TODO: make threshold configurable", "\n", "if", "obj", "[", "\"area\"", "]", "<=", "cfg", ".", "INPUT", ".", "MIN_AREA", "or", "max", "(", "w", ",", "h", ")", "<", "cfg", ".", "INPUT", ".", "MIN_SIDE", ":", "\n", "                ", "count_skipped_boxes", "+=", "1", "\n", "area_skipped", "+=", "[", "obj", "[", "\"area\"", "]", "]", "\n", "w_skipped", "+=", "[", "w", "]", "\n", "h_skipped", "+=", "[", "h", "]", "\n", "# Skip way too small object", "\n", "continue", "\n", "\n", "", "segm", "=", "anno", ".", "get", "(", "\"segmentation\"", ",", "None", ")", "\n", "if", "segm", ":", "# either list[list[float]] or dict(RLE)", "\n", "                ", "if", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "                    ", "if", "isinstance", "(", "segm", "[", "\"counts\"", "]", ",", "list", ")", ":", "\n", "# convert to compressed RLE", "\n", "                        ", "segm", "=", "mask_util", ".", "frPyObjects", "(", "segm", ",", "*", "segm", "[", "\"size\"", "]", ")", "\n", "", "", "else", ":", "\n", "# filter out invalid polygons (< 3 points)", "\n", "                    ", "segm", "=", "[", "poly", "for", "poly", "in", "segm", "if", "len", "(", "poly", ")", "%", "2", "==", "0", "and", "len", "(", "poly", ")", ">=", "6", "]", "\n", "if", "len", "(", "segm", ")", "==", "0", ":", "\n", "                        ", "num_instances_without_valid_segmentation", "+=", "1", "\n", "continue", "# ignore this instance", "\n", "\n", "# Filter out segmentations where two corners overlap", "\n", "", "", "seg", "=", "np", ".", "array", "(", "segm", "[", "0", "]", ")", ".", "reshape", "(", "4", ",", "2", ")", "\n", "has_overlapping_corners", "=", "False", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "                    ", "if", "has_overlapping_corners", ":", "\n", "                        ", "break", "\n", "", "for", "j", "in", "range", "(", "i", ",", "4", ")", ":", "\n", "                        ", "if", "i", "==", "j", ":", "\n", "                            ", "continue", "\n", "", "seg_i", "=", "seg", "[", "i", "]", "\n", "seg_j", "=", "seg", "[", "j", "]", "\n", "if", "np", ".", "sum", "(", "np", ".", "abs", "(", "seg_i", "-", "seg_j", ")", ")", "<", "1e-2", ":", "\n", "                            ", "has_overlapping_corners", "=", "True", "\n", "break", "\n", "\n", "# Skip this object if there are overlapping corners", "\n", "", "", "", "if", "has_overlapping_corners", ":", "\n", "                    ", "continue", "\n", "\n", "", "obj", "[", "\"segmentation\"", "]", "=", "segm", "\n", "\n", "", "keypts", "=", "anno", ".", "get", "(", "\"keypoints\"", ",", "None", ")", "\n", "if", "keypts", ":", "# list[int]", "\n", "                ", "for", "idx", ",", "v", "in", "enumerate", "(", "keypts", ")", ":", "\n", "                    ", "if", "idx", "%", "3", "!=", "2", ":", "\n", "# COCO's segmentation coordinates are floating points in [0, H or W],", "\n", "# but keypoint coordinates are integers in [0, H-1 or W-1]", "\n", "# Therefore we assume the coordinates are \"pixel indices\" and", "\n", "# add 0.5 to convert to floating point coordinates.", "\n", "                        ", "keypts", "[", "idx", "]", "=", "v", "+", "0.5", "\n", "", "", "obj", "[", "\"keypoints\"", "]", "=", "keypts", "\n", "\n", "", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYWH_ABS", "\n", "if", "id_map", ":", "\n", "                ", "obj", "[", "\"category_id\"", "]", "=", "id_map", "[", "obj", "[", "\"category_id\"", "]", "]", "\n", "", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "if", "num_instances_without_valid_segmentation", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Filtered out {} instances without valid segmentation. \"", ".", "format", "(", "\n", "num_instances_without_valid_segmentation", "\n", ")", "\n", "+", "\"There might be issues in your dataset generation process. \"", "\n", "\"A valid polygon should be a list[float] with even length >= 6.\"", "\n", ")", "\n", "\n", "", "wqs", "=", "stats", ".", "mstats", ".", "mquantiles", "(", "ws", ",", "prob", "=", "[", "1", "/", "5", ",", "2", "/", "5", ",", "3", "/", "5", ",", "4", "/", "5", "]", ")", "\n", "hqs", "=", "stats", ".", "mstats", ".", "mquantiles", "(", "hs", ",", "prob", "=", "[", "1", "/", "5", ",", "2", "/", "5", ",", "3", "/", "5", ",", "4", "/", "5", "]", ")", "\n", "logger", ".", "info", "(", "f\"Width quantiles: {wqs}\"", ")", "\n", "logger", ".", "info", "(", "f\"Height quantiles: {hqs}\"", ")", "\n", "area_hist", ",", "_", "=", "np", ".", "histogram", "(", "areas", ",", "bins", "=", "[", "0", "]", "+", "cfg", ".", "MODEL", ".", "DAFNE", ".", "SIZES_OF_INTEREST", "+", "[", "np", ".", "inf", "]", ")", "\n", "width_hist", ",", "_", "=", "np", ".", "histogram", "(", "ws", ",", "bins", "=", "[", "0", "]", "+", "cfg", ".", "MODEL", ".", "DAFNE", ".", "SIZES_OF_INTEREST", "+", "[", "np", ".", "inf", "]", ")", "\n", "height_hist", ",", "_", "=", "np", ".", "histogram", "(", "hs", ",", "bins", "=", "[", "0", "]", "+", "cfg", ".", "MODEL", ".", "DAFNE", ".", "SIZES_OF_INTEREST", "+", "[", "np", ".", "inf", "]", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Area hist: {area_hist}\"", ")", "\n", "logger", ".", "info", "(", "f\"Width hist: {width_hist}\"", ")", "\n", "logger", ".", "info", "(", "f\"Height hist: {height_hist}\"", ")", "\n", "\n", "# logger.info(", "\n", "#     f\"Skipped {count_skipped_container_crane} annotations with the label 'container-crane'. This is to make Dota 1.5 usable in conjunction with Dota 1.0.\"", "\n", "# )", "\n", "logger", ".", "warn", "(", "f\"Skipped {count_skipped_boxes} annotations with too small area or width/height.\"", ")", "\n", "\n", "# If this is the mini set, only sample a random 5% subset", "\n", "if", "is_mini_set", ":", "\n", "        ", "n", "=", "len", "(", "dataset_dicts", ")", "\n", "p", "=", "0.05", "\n", "n_mini", "=", "int", "(", "n", "*", "p", ")", "\n", "n_mini", "=", "max", "(", "10", ",", "n_mini", ")", "\n", "dataset_dicts", "=", "np", ".", "random", ".", "choice", "(", "dataset_dicts", ",", "n_mini", ")", ".", "tolist", "(", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.register_dota_instances": [[323, 359], ["isinstance", "isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "dota.load_dota_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.load_dota_json"], ["", "def", "register_dota_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "json_file", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "json_file", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "\n", "lambda", ":", "load_dota_json", "(", "\n", "json_file", ",", "\n", "image_root", ",", "\n", "name", ",", "\n", "extra_annotation_keys", "=", "[", "\"segmentation\"", ",", "\"area\"", "]", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"dota\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota._make_datasets_dict": [[362, 384], ["ds_name_template.format", "root_dir_template.format", "ann_file_template.format"], "function", ["None"], ["", "def", "_make_datasets_dict", "(", ")", ":", "\n", "    ", "ds_name_template", "=", "\"dota_{version}_{split}_{size}\"", "\n", "root_dir_template", "=", "\"dota_{version}_split/{split}{size}\"", "\n", "ann_file_template", "=", "\"DOTA{version}_{split}{size}.json\"", "\n", "\n", "datasets_dict", "=", "{", "}", "\n", "# Construct datasets dict from currently available datasets", "\n", "for", "version", "in", "[", "\"1\"", ",", "\"1_5\"", "]", ":", "\n", "        ", "for", "split", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", ":", "\n", "            ", "for", "size", "in", "[", "\"600\"", ",", "\"800\"", ",", "\"1024\"", ",", "\"1300\"", ",", "\"1600\"", ",", "\"2048\"", "]", ":", "\n", "                ", "name", "=", "ds_name_template", ".", "format", "(", "version", "=", "version", ",", "split", "=", "split", ",", "size", "=", "size", ")", "\n", "root_dir", "=", "root_dir_template", ".", "format", "(", "version", "=", "version", ",", "split", "=", "split", ",", "size", "=", "size", ")", "\n", "ann_file", "=", "ann_file_template", ".", "format", "(", "version", "=", "version", ",", "split", "=", "split", ",", "size", "=", "size", ")", "\n", "\n", "datasets_dict", "[", "name", "]", "=", "{", "\n", "\"root_dir\"", ":", "root_dir", ",", "\n", "\"img_dir\"", ":", "\"images\"", ",", "\n", "\"ann_file\"", ":", "ann_file", ",", "\n", "\"is_test\"", ":", "\"test\"", "in", "name", ",", "\n", "}", "\n", "\n", "", "", "", "return", "datasets_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota.register_dota": [[386, 413], ["dota._make_datasets_dict", "detectron2.utils.colormap.colormap", "_make_datasets_dict.items", "dota.register_dota.reg"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.dota._make_datasets_dict"], ["", "def", "register_dota", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Setup method to register the dota dataset.\"\"\"", "\n", "datasets_dict", "=", "_make_datasets_dict", "(", ")", "\n", "\n", "# Get the data directory", "\n", "data_dir", "=", "os", ".", "environ", "[", "\"DAFNE_DATA_DIR\"", "]", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "255", ")", "\n", "for", "dataset_name", ",", "d", "in", "datasets_dict", ".", "items", "(", ")", ":", "\n", "\n", "        ", "def", "reg", "(", "name", ")", ":", "\n", "            ", "register_dota_instances", "(", "\n", "name", "=", "name", ",", "\n", "metadata", "=", "{", "\n", "\"is_test\"", ":", "d", "[", "\"is_test\"", "]", ",", "\n", "\"root_dir\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ")", ",", "\n", "\"thing_colors\"", ":", "colors", ",", "\n", "}", ",", "\n", "json_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ",", "d", "[", "\"ann_file\"", "]", ")", ",", "\n", "image_root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "d", "[", "\"root_dir\"", "]", ",", "d", "[", "\"img_dir\"", "]", ")", ",", "\n", "cfg", "=", "cfg", ",", "\n", ")", "\n", "\n", "# Register normal version", "\n", "", "reg", "(", "dataset_name", ")", "\n", "\n", "# Register mini version", "\n", "reg", "(", "dataset_name", "+", "\"_mini\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.__init__": [[23, 49], ["fvcore.transforms.transform.Transform.__init__", "numpy.array", "transform.RotationTransform._set_attributes", "transform.RotationTransform.create_rotation_matrix", "transform.RotationTransform.create_rotation_matrix", "abs", "abs", "locals", "numpy.cos", "numpy.sin", "numpy.deg2rad", "numpy.deg2rad"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__", "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.create_rotation_matrix", "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.create_rotation_matrix"], ["def", "__init__", "(", "self", ",", "h", ",", "w", ",", "angle", ",", "center", "=", "None", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            h, w (int): original image size\n            angle (float): degrees for rotation\n            center (tuple (width, height)): coordinates of the rotation center\n                if left to None, the center will be fit to the center of each image\n                center has no effect if expand=True because it only affects shifting\n            interp: cv2 interpolation method, default cv2.INTER_LINEAR\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "image_center", "=", "np", ".", "array", "(", "(", "w", "/", "2", ",", "h", "/", "2", ")", ")", "\n", "if", "center", "is", "None", ":", "\n", "            ", "center", "=", "image_center", "\n", "", "if", "interp", "is", "None", ":", "\n", "            ", "interp", "=", "cv2", ".", "INTER_LINEAR", "\n", "", "abs_cos", ",", "abs_sin", "=", "(", "\n", "abs", "(", "np", ".", "cos", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ",", "\n", "abs", "(", "np", ".", "sin", "(", "np", ".", "deg2rad", "(", "angle", ")", ")", ")", ",", "\n", ")", "\n", "bound_w", ",", "bound_h", "=", "w", ",", "h", "\n", "\n", "self", ".", "_set_attributes", "(", "locals", "(", ")", ")", "\n", "self", ".", "rm_coords", "=", "self", ".", "create_rotation_matrix", "(", ")", "\n", "# Needed because of this problem https://github.com/opencv/opencv/issues/11784", "\n", "self", ".", "rm_image", "=", "self", ".", "create_rotation_matrix", "(", "offset", "=", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_image": [[50, 60], ["cv2.warpAffine", "len"], "methods", ["None"], ["", "def", "apply_image", "(", "self", ",", "img", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        img should be a numpy array, formatted as Height * Width * Nchannels\n        \"\"\"", "\n", "if", "len", "(", "img", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "img", "\n", "", "assert", "img", ".", "shape", "[", ":", "2", "]", "==", "(", "self", ".", "h", ",", "self", ".", "w", ")", "\n", "interp", "=", "interp", "if", "interp", "is", "not", "None", "else", "self", ".", "interp", "\n", "return", "cv2", ".", "warpAffine", "(", "\n", "img", ",", "self", ".", "rm_image", ",", "(", "self", ".", "bound_w", ",", "self", ".", "bound_h", ")", ",", "flags", "=", "interp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_coords": [[62, 70], ["numpy.asarray", "cv2.transform", "len"], "methods", ["None"], ["", "def", "apply_coords", "(", "self", ",", "coords", ")", ":", "\n", "        ", "\"\"\"\n        coords should be a N * 2 array-like, containing N couples of (x, y) points\n        \"\"\"", "\n", "coords", "=", "np", ".", "asarray", "(", "coords", ",", "dtype", "=", "float", ")", "\n", "if", "len", "(", "coords", ")", "==", "0", "or", "self", ".", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "coords", "\n", "", "return", "cv2", ".", "transform", "(", "coords", "[", ":", ",", "np", ".", "newaxis", ",", ":", "]", ",", "self", ".", "rm_coords", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_segmentation": [[71, 74], ["transform.RotationTransform.apply_image"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.apply_image"], ["", "def", "apply_segmentation", "(", "self", ",", "segmentation", ")", ":", "\n", "        ", "segmentation", "=", "self", ".", "apply_image", "(", "segmentation", ",", "interp", "=", "cv2", ".", "INTER_NEAREST", ")", "\n", "return", "segmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.create_rotation_matrix": [[75, 79], ["cv2.getRotationMatrix2D", "tuple"], "methods", ["None"], ["", "def", "create_rotation_matrix", "(", "self", ",", "offset", "=", "0", ")", ":", "\n", "        ", "center", "=", "(", "self", ".", "center", "[", "0", "]", "+", "offset", ",", "self", ".", "center", "[", "1", "]", "+", "offset", ")", "\n", "rm", "=", "cv2", ".", "getRotationMatrix2D", "(", "tuple", "(", "center", ")", ",", "self", ".", "angle", ",", "1", ")", "\n", "return", "rm", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RotationTransform.inverse": [[80, 88], ["transform.RotationTransform", "fvcore.transforms.transform.TransformList"], "methods", ["None"], ["", "def", "inverse", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The inverse is to rotate it back with expand, and crop to get the original shape.\n        \"\"\"", "\n", "rotation", "=", "RotationTransform", "(", "\n", "self", ".", "bound_h", ",", "self", ".", "bound_w", ",", "-", "self", ".", "angle", ",", "None", ",", "self", ".", "interp", "\n", ")", "\n", "return", "TransformList", "(", "[", "rotation", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RandomRotation.__init__": [[96, 117], ["detectron2.data.transforms.augmentation.Augmentation.__init__", "isinstance", "transform.RandomRotation._init", "isinstance", "locals"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__"], ["def", "__init__", "(", "self", ",", "angle", ",", "center", "=", "None", ",", "sample_style", "=", "\"range\"", ",", "interp", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            angle (list[float]): If ``sample_style==\"range\"``,\n                a [min, max] interval from which to sample the angle (in degrees).\n                If ``sample_style==\"choice\"``, a list of angles to sample from\n            center (list[[float, float]]):  If ``sample_style==\"range\"``,\n                a [[minx, miny], [maxx, maxy]] relative interval from which to sample the center,\n                [0, 0] being the top left of the image and [1, 1] the bottom right.\n                If ``sample_style==\"choice\"``, a list of centers to sample from\n                Default: None, which means that the center of rotation is the center of the image\n                center has no effect if expand=True because it only affects shifting\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "sample_style", "in", "[", "\"range\"", ",", "\"choice\"", "]", ",", "sample_style", "\n", "self", ".", "is_range", "=", "sample_style", "==", "\"range\"", "\n", "if", "isinstance", "(", "angle", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "angle", "=", "(", "angle", ",", "angle", ")", "\n", "", "if", "center", "is", "not", "None", "and", "isinstance", "(", "center", "[", "0", "]", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "center", "=", "(", "center", ",", "center", ")", "\n", "", "self", ".", "_init", "(", "locals", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.transforms.transform.RandomRotation.get_transform": [[118, 141], ["transform.RotationTransform", "numpy.random.uniform", "numpy.random.choice", "fvcore.transforms.transform.NoOpTransform", "numpy.random.choice", "numpy.random.uniform", "numpy.random.uniform"], "methods", ["None"], ["", "def", "get_transform", "(", "self", ",", "image", ")", ":", "\n", "        ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "center", "=", "None", "\n", "if", "self", ".", "is_range", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "uniform", "(", "self", ".", "angle", "[", "0", "]", ",", "self", ".", "angle", "[", "1", "]", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "(", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "0", "]", ",", "self", ".", "center", "[", "1", "]", "[", "0", "]", ")", ",", "\n", "np", ".", "random", ".", "uniform", "(", "self", ".", "center", "[", "0", "]", "[", "1", "]", ",", "self", ".", "center", "[", "1", "]", "[", "1", "]", ")", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "angle", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "angle", ")", "\n", "if", "self", ".", "center", "is", "not", "None", ":", "\n", "                ", "center", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "center", ")", "\n", "\n", "", "", "if", "center", "is", "not", "None", ":", "\n", "            ", "center", "=", "(", "w", "*", "center", "[", "0", "]", ",", "h", "*", "center", "[", "1", "]", ")", "# Convert to absolute coordinates", "\n", "\n", "", "if", "angle", "%", "360", "==", "0", ":", "\n", "            ", "return", "NoOpTransform", "(", ")", "\n", "\n", "", "return", "RotationTransform", "(", "\n", "h", ",", "w", ",", "angle", ",", "center", "=", "center", ",", "interp", "=", "self", ".", "interp", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_ap": [[7, 39], ["numpy.arange", "numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where", "numpy.sum", "numpy.max"], "function", ["None"], ["def", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", "=", "False", ")", ":", "\n", "    ", "\"\"\"ap = voc_ap(rec, prec, [use_07_metric])\n    Compute VOC AP given precision and recall.\n    If use_07_metric is true, uses the\n    VOC 07 11 point method (default:False).\n    \"\"\"", "\n", "if", "use_07_metric", ":", "\n", "# 11 point metric", "\n", "        ", "ap", "=", "0.0", "\n", "for", "t", "in", "np", ".", "arange", "(", "0.0", ",", "1.1", ",", "0.1", ")", ":", "\n", "            ", "if", "np", ".", "sum", "(", "rec", ">=", "t", ")", "==", "0", ":", "\n", "                ", "p", "=", "0", "\n", "", "else", ":", "\n", "                ", "p", "=", "np", ".", "max", "(", "prec", "[", "rec", ">=", "t", "]", ")", "\n", "", "ap", "=", "ap", "+", "p", "/", "11.0", "\n", "", "", "else", ":", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "        ", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "rec", ",", "[", "1.0", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "prec", ",", "[", "0.0", "]", ")", ")", "\n", "\n", "# compute the precision envelope", "\n", "for", "i", "in", "range", "(", "mpre", ".", "size", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "mpre", "[", "i", "-", "1", "]", "=", "np", ".", "maximum", "(", "mpre", "[", "i", "-", "1", "]", ",", "mpre", "[", "i", "]", ")", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_eval": [[41, 225], ["enumerate", "detpath.format", "numpy.array", "numpy.array", "numpy.argsort", "len", "numpy.zeros", "numpy.zeros", "range", "numpy.cumsum", "numpy.cumsum", "voc_eval.voc_ap", "open", "f.readlines", "x.strip", "parse_gt", "numpy.array", "numpy.array().astype", "open", "f.readlines", "x.strip().split", "BB[].astype", "R[].astype", "float", "numpy.maximum", "annopath.format", "len", "sum", "float", "numpy.min", "numpy.min", "numpy.max", "numpy.max", "numpy.min", "numpy.min", "numpy.max", "numpy.max", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.array", "x.strip", "float", "numpy.where", "enumerate", "len", "voc_eval.voc_eval.calcoverlaps"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_ap", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.parse_gt"], ["", "def", "voc_eval", "(", "\n", "detpath", ",", "\n", "annopath", ",", "\n", "imagesetfile", ",", "\n", "classname", ",", "\n", "# cachedir,", "\n", "ovthresh", "=", "0.5", ",", "\n", "use_07_metric", "=", "False", ",", "\n", "parse_gt", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"rec, prec, ap = voc_eval(detpath,\n                                annopath,\n                                imagesetfile,\n                                classname,\n                                [ovthresh],\n                                [use_07_metric])\n    Top level function that does the PASCAL VOC evaluation.\n    detpath: Path to detections\n        detpath.format(classname) should produce the detection results file.\n    annopath: Path to annotations\n        annopath.format(imagename) should be the xml annotations file.\n    imagesetfile: Text file containing the list of images, one image per line.\n    classname: Category name (duh)\n    cachedir: Directory for caching the annotations\n    [ovthresh]: Overlap threshold (default = 0.5)\n    [use_07_metric]: Whether to use VOC07's 11 point AP computation\n        (default False)\n    \"\"\"", "\n", "# assumes detections are in detpath.format(classname)", "\n", "# assumes annotations are in annopath.format(imagename)", "\n", "# assumes imagesetfile is a text file with each line an image name", "\n", "# cachedir caches the annotations in a pickle file", "\n", "\n", "# first load gt", "\n", "# if not os.path.isdir(cachedir):", "\n", "#   os.mkdir(cachedir)", "\n", "# cachefile = os.path.join(cachedir, 'annots.pkl')", "\n", "# read list of images", "\n", "with", "open", "(", "imagesetfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "imagenames", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "lines", "]", "\n", "# logger.info('imagenames: ', imagenames)", "\n", "# if not os.path.isfile(cachefile):", "\n", "# load annots", "\n", "recs", "=", "{", "}", "\n", "for", "i", ",", "imagename", "in", "enumerate", "(", "imagenames", ")", ":", "\n", "# logger.info('parse_files name: ', annopath.format(imagename))", "\n", "        ", "recs", "[", "imagename", "]", "=", "parse_gt", "(", "annopath", ".", "format", "(", "imagename", ")", ")", "\n", "\n", "# extract gt objects for this class", "\n", "", "class_recs", "=", "{", "}", "\n", "npos", "=", "0", "\n", "for", "imagename", "in", "imagenames", ":", "\n", "        ", "R", "=", "[", "obj", "for", "obj", "in", "recs", "[", "imagename", "]", "if", "obj", "[", "\"name\"", "]", "==", "classname", "]", "\n", "bbox", "=", "np", ".", "array", "(", "[", "x", "[", "\"bbox\"", "]", "for", "x", "in", "R", "]", ")", "\n", "difficult", "=", "np", ".", "array", "(", "[", "x", "[", "\"difficult\"", "]", "for", "x", "in", "R", "]", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "det", "=", "[", "False", "]", "*", "len", "(", "R", ")", "\n", "npos", "=", "npos", "+", "sum", "(", "~", "difficult", ")", "\n", "class_recs", "[", "imagename", "]", "=", "{", "\"bbox\"", ":", "bbox", ",", "\"difficult\"", ":", "difficult", ",", "\"det\"", ":", "det", "}", "\n", "\n", "# read dets from Task1* files", "\n", "", "detfile", "=", "detpath", ".", "format", "(", "classname", ")", "\n", "with", "open", "(", "detfile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "splitlines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "for", "x", "in", "lines", "]", "\n", "image_ids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "splitlines", "]", "\n", "confidence", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "1", "]", ")", "for", "x", "in", "splitlines", "]", ")", "\n", "\n", "# logger.info('check confidence: ', confidence)", "\n", "\n", "BB", "=", "np", ".", "array", "(", "[", "[", "float", "(", "z", ")", "for", "z", "in", "x", "[", "2", ":", "]", "]", "for", "x", "in", "splitlines", "]", ")", "\n", "\n", "# sort by confidence", "\n", "sorted_ind", "=", "np", ".", "argsort", "(", "-", "confidence", ")", "\n", "sorted_scores", "=", "confidence", "[", "sorted_ind", "]", "\n", "\n", "# logger.info('check sorted_scores: ', sorted_scores)", "\n", "# logger.info('check sorted_ind: ', sorted_ind)", "\n", "\n", "## note the usage only in numpy not for list", "\n", "if", "BB", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "        ", "BB", "=", "BB", "[", "sorted_ind", ",", ":", "]", "\n", "", "image_ids", "=", "[", "image_ids", "[", "x", "]", "for", "x", "in", "sorted_ind", "]", "\n", "# logger.info('check imge_ids: ', image_ids)", "\n", "# logger.info('imge_ids len:', len(image_ids))", "\n", "# go down dets and mark TPs and FPs", "\n", "nd", "=", "len", "(", "image_ids", ")", "\n", "tp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "nd", ")", "\n", "\n", "data_scores_overlap", "=", "[", "]", "\n", "\n", "for", "d", "in", "range", "(", "nd", ")", ":", "\n", "        ", "R", "=", "class_recs", "[", "image_ids", "[", "d", "]", "]", "\n", "bb", "=", "BB", "[", "d", ",", ":", "]", ".", "astype", "(", "float", ")", "\n", "conf", "=", "confidence", "[", "d", "]", "\n", "ovmax", "=", "-", "np", ".", "inf", "\n", "BBGT", "=", "R", "[", "\"bbox\"", "]", ".", "astype", "(", "float", ")", "\n", "\n", "## compute det bb with each BBGT", "\n", "\n", "if", "BBGT", ".", "size", ">", "0", ":", "\n", "# compute overlaps", "\n", "# intersection", "\n", "\n", "# 1. calculate the overlaps between hbbs, if the iou between hbbs are 0, the iou between obbs are 0, too.", "\n", "# pdb.set_trace()", "\n", "            ", "BBGT_xmin", "=", "np", ".", "min", "(", "BBGT", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "BBGT_ymin", "=", "np", ".", "min", "(", "BBGT", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "BBGT_xmax", "=", "np", ".", "max", "(", "BBGT", "[", ":", ",", "0", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "BBGT_ymax", "=", "np", ".", "max", "(", "BBGT", "[", ":", ",", "1", ":", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "bb_xmin", "=", "np", ".", "min", "(", "bb", "[", "0", ":", ":", "2", "]", ")", "\n", "bb_ymin", "=", "np", ".", "min", "(", "bb", "[", "1", ":", ":", "2", "]", ")", "\n", "bb_xmax", "=", "np", ".", "max", "(", "bb", "[", "0", ":", ":", "2", "]", ")", "\n", "bb_ymax", "=", "np", ".", "max", "(", "bb", "[", "1", ":", ":", "2", "]", ")", "\n", "\n", "ixmin", "=", "np", ".", "maximum", "(", "BBGT_xmin", ",", "bb_xmin", ")", "\n", "iymin", "=", "np", ".", "maximum", "(", "BBGT_ymin", ",", "bb_ymin", ")", "\n", "ixmax", "=", "np", ".", "minimum", "(", "BBGT_xmax", ",", "bb_xmax", ")", "\n", "iymax", "=", "np", ".", "minimum", "(", "BBGT_ymax", ",", "bb_ymax", ")", "\n", "iw", "=", "np", ".", "maximum", "(", "ixmax", "-", "ixmin", "+", "1.0", ",", "0.0", ")", "\n", "ih", "=", "np", ".", "maximum", "(", "iymax", "-", "iymin", "+", "1.0", ",", "0.0", ")", "\n", "inters", "=", "iw", "*", "ih", "\n", "\n", "# union", "\n", "uni", "=", "(", "\n", "(", "bb_xmax", "-", "bb_xmin", "+", "1.0", ")", "*", "(", "bb_ymax", "-", "bb_ymin", "+", "1.0", ")", "\n", "+", "(", "BBGT_xmax", "-", "BBGT_xmin", "+", "1.0", ")", "*", "(", "BBGT_ymax", "-", "BBGT_ymin", "+", "1.0", ")", "\n", "-", "inters", "\n", ")", "\n", "\n", "overlaps", "=", "inters", "/", "uni", "\n", "\n", "BBGT_keep_mask", "=", "overlaps", ">", "0", "\n", "BBGT_keep", "=", "BBGT", "[", "BBGT_keep_mask", ",", ":", "]", "\n", "BBGT_keep_index", "=", "np", ".", "where", "(", "overlaps", ">", "0", ")", "[", "0", "]", "\n", "# pdb.set_trace()", "\n", "def", "calcoverlaps", "(", "BBGT_keep", ",", "bb", ")", ":", "\n", "                ", "overlaps", "=", "[", "]", "\n", "for", "index", ",", "GT", "in", "enumerate", "(", "BBGT_keep", ")", ":", "\n", "# Sort first", "\n", "# GT_sorted = sort_quadrilateral(torch.tensor(GT).view(1, 8)).view(8).numpy()", "\n", "                    ", "overlap", "=", "polyiou", ".", "iou_poly", "(", "\n", "polyiou", ".", "VectorDouble", "(", "GT", ")", ",", "polyiou", ".", "VectorDouble", "(", "bb", ")", "\n", ")", "\n", "overlaps", ".", "append", "(", "overlap", ")", "\n", "", "return", "overlaps", "\n", "\n", "", "if", "len", "(", "BBGT_keep", ")", ">", "0", ":", "\n", "                ", "overlaps", "=", "calcoverlaps", "(", "BBGT_keep", ",", "bb", ")", "\n", "\n", "ovmax", "=", "np", ".", "max", "(", "overlaps", ")", "\n", "jmax", "=", "np", ".", "argmax", "(", "overlaps", ")", "\n", "# pdb.set_trace()", "\n", "jmax", "=", "BBGT_keep_index", "[", "jmax", "]", "\n", "", "", "if", "ovmax", ">", "ovthresh", ":", "\n", "            ", "if", "not", "R", "[", "\"difficult\"", "]", "[", "jmax", "]", ":", "\n", "                ", "if", "not", "R", "[", "\"det\"", "]", "[", "jmax", "]", ":", "\n", "                    ", "tp", "[", "d", "]", "=", "1.0", "\n", "R", "[", "\"det\"", "]", "[", "jmax", "]", "=", "1", "\n", "\n", "# Collect detection as tuple of confidence and overlap (1 indicates true positive)", "\n", "data_scores_overlap", ".", "append", "(", "[", "conf", ",", "ovmax", ",", "1", ",", "classname", "]", ")", "\n", "", "else", ":", "\n", "                    ", "fp", "[", "d", "]", "=", "1.0", "\n", "\n", "# Collect detection as tuple of confidence and overlap (0 indicates false positive)", "\n", "data_scores_overlap", ".", "append", "(", "[", "conf", ",", "ovmax", ",", "0", ",", "classname", "]", ")", "\n", "", "", "", "else", ":", "\n", "            ", "fp", "[", "d", "]", "=", "1.0", "\n", "\n", "\n", "# compute precision recall", "\n", "", "", "fp", "=", "np", ".", "cumsum", "(", "fp", ")", "\n", "tp", "=", "np", ".", "cumsum", "(", "tp", ")", "\n", "\n", "rec", "=", "tp", "/", "float", "(", "npos", ")", "\n", "# avoid divide by zero in case the first detection matches a difficult", "\n", "# ground truth", "\n", "prec", "=", "tp", "/", "np", ".", "maximum", "(", "tp", "+", "fp", ",", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", ")", "\n", "ap", "=", "voc_ap", "(", "rec", ",", "prec", ",", "use_07_metric", ")", "\n", "\n", "return", "rec", ",", "prec", ",", "ap", ",", "data_scores_overlap", "\n", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.HrscEvaluator._eval_predictions": [[30, 39], ["hrsc_evaluation.do_hrsc_evaluation"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.do_hrsc_evaluation"], ["    ", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "do_hrsc_evaluation", "(", "\n", "dataset_name", "=", "self", ".", "_dataset_name", ",", "\n", "metadata", "=", "self", ".", "_metadata", ",", "\n", "predictions", "=", "predictions", ",", "\n", "output_folder", "=", "self", ".", "_output_dir", ",", "\n", "logger", "=", "self", ".", "_logger", ",", "\n", "results", "=", "self", ".", "_results", ",", "\n", "cfg", "=", "self", ".", "_cfg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.xywha2xy4": [[77, 83], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.parse_gt": [[85, 104], ["xml.parse", "ET.parse.getroot", "[].findall", "int", "list", "xywha2xy4().reshape", "xywha2xy4().reshape.tolist", "objects.append", "bbox.append", "map", "tree.getroot.findall", "obj.find", "hrsc_evaluation.xywha2xy4", "obj.find"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.xywha2xy4"], ["", "def", "parse_gt", "(", "filename", ")", ":", "\n", "    ", "objects", "=", "[", "]", "\n", "tree", "=", "ET", ".", "parse", "(", "filename", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "for", "obj", "in", "root", ".", "findall", "(", "\"HRSC_Objects\"", ")", "[", "0", "]", ".", "findall", "(", "\"HRSC_Object\"", ")", ":", "\n", "        ", "object_struct", "=", "{", "}", "\n", "object_struct", "[", "\"name\"", "]", "=", "\"ship\"", "\n", "object_struct", "[", "\"difficult\"", "]", "=", "int", "(", "obj", ".", "find", "(", "\"difficult\"", ")", ".", "text", ")", "\n", "bbox", "=", "[", "]", "\n", "for", "key", "in", "[", "\"mbox_cx\"", ",", "\"mbox_cy\"", ",", "\"mbox_w\"", ",", "\"mbox_h\"", ",", "\"mbox_ang\"", "]", ":", "\n", "            ", "bbox", ".", "append", "(", "obj", ".", "find", "(", "key", ")", ".", "text", ")", "\n", "# Coordinates may be float type", "\n", "", "cx", ",", "cy", ",", "w", ",", "h", ",", "a", "=", "list", "(", "map", "(", "float", ",", "bbox", ")", ")", "\n", "bbox", "=", "[", "cx", ",", "cy", ",", "w", ",", "h", ",", "a", "]", "\n", "poly", "=", "xywha2xy4", "(", "bbox", ")", ".", "reshape", "(", "-", "1", ")", "\n", "object_struct", "[", "\"bbox\"", "]", "=", "poly", ".", "tolist", "(", ")", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "\n", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation._generate_task_1_files": [[106, 155], ["open", "set", "logger.info", "fp_classes.items", "os.path.join", "os.path.join", "set.add", "range", "fp.close", "open", "f.write", "prediction.unbind", "labels[].item", "fp_classes[].write", "os.path.join", "os.path.join", "list", "fname.split"], "function", ["None"], ["", "def", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"Construct files according to Task1: https://captain-whu.github.io/DOAI2019/tasks.html\"\"\"", "\n", "\n", "fp_classes", "=", "{", "}", "\n", "cls_name", "=", "classnames", "[", "0", "]", "\n", "fp_classes", "[", "0", "]", "=", "open", "(", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "f\"Task1_{cls_name}.txt\"", ")", ",", "\"w\"", ")", "\n", "\n", "fname_set", "=", "set", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Collecting predictions into Task1_<class-name>.txt files\"", ")", "\n", "\n", "# Iterate over images", "\n", "for", "prediction", "in", "predictions", ":", "\n", "        ", "fname", "=", "prediction", "[", "\"file_name\"", "]", "\n", "fname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "fname_set", ".", "add", "(", "fname", ")", "\n", "corners", "=", "prediction", "[", "\"corners\"", "]", "\n", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", "\n", "\n", "# Remove centerness from score to get back original class confidences", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "!=", "\"none\"", "and", "not", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_USE_IN_SCORE", ":", "\n", "            ", "centerness", "=", "prediction", "[", "\"centerness\"", "]", "\n", "scores", "=", "scores", "**", "2", "\n", "scores", "=", "scores", "/", "centerness", "\n", "\n", "# Iterate over boxes", "\n", "", "num_boxes", "=", "corners", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "            ", "prediction", "=", "corners", "[", "i", "]", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "=", "prediction", ".", "unbind", "(", ")", "\n", "label", "=", "labels", "[", "i", "]", ".", "item", "(", ")", "\n", "score", "=", "scores", "[", "i", "]", "\n", "\n", "# Add line to the correct class file", "\n", "line", "=", "f\"{fname} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f}\\n\"", "\n", "fp_classes", "[", "label", "]", ".", "write", "(", "line", ")", "\n", "\n", "# Close files", "\n", "", "", "for", "_", ",", "fp", "in", "fp_classes", ".", "items", "(", ")", ":", "\n", "        ", "fp", ".", "close", "(", ")", "\n", "\n", "# Create the imageset file", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "\"\\n\"", ".", "join", "(", "list", "(", "fname_set", ")", ")", "\n", "f", ".", "write", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.plot_pr_curve": [[157, 168], ["matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.plot", "matplotlib.tight_layout", "matplotlib.savefig", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", ":", "\n", "# Plot PR Curve", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "6", ")", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1", ")", "\n", "plt", ".", "title", "(", "f\"PR-Curve {classname} (AP={ap * 100:2.2f})\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Recall\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Precision\"", ")", "\n", "plt", ".", "plot", "(", "rec", ",", "prec", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "pr_dir", ",", "f\"pr-curve_{classname}.png\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.run_merge": [[170, 174], ["logger.info", "dafne.utils.ResultMerge_multi_process.mergebypoly", "logger.info"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebypoly"], ["", "def", "run_merge", "(", "src", ",", "dst", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Starting task1 result merge ...\"", ")", "\n", "mergebypoly", "(", "src", ",", "dst", ")", "\n", "logger", ".", "info", "(", "\"task1 result merge done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.create_zip": [[176, 188], ["logger.info", "zipfile.ZipFile", "glob.glob", "zipfile.ZipFile.close", "logger.info", "zipfile.ZipFile.write", "os.path.join", "os.path.join", "fname.split"], "function", ["None"], ["", "def", "create_zip", "(", "output_dir", ",", "task1_merged_dir", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Creating zip file ...\"", ")", "\n", "zfile", "=", "zipfile", ".", "ZipFile", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"task1_merged.zip\"", ")", ",", "\n", "mode", "=", "\"w\"", ",", "\n", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ",", "\n", ")", "\n", "for", "fname", "in", "glob", ".", "glob", "(", "task1_merged_dir", "+", "\"/Task1_*.txt\"", ")", ":", "\n", "        ", "arcname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# Avoid directory structure in zip file", "\n", "zfile", ".", "write", "(", "fname", ",", "arcname", "=", "arcname", ")", "\n", "", "zfile", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Zip file done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.create_instances": [[190, 214], ["detectron2.structures.Instances", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["", "def", "create_instances", "(", "predictions", ",", "image_size", ",", "conf_threshold", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "        ", "ret", ".", "scores", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "# ret.pred_boxes = torch.empty(0, 5)", "\n", "ret", ".", "pred_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "ret", ".", "pred_classes", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "\n", "", "score", "=", "torch", ".", "cat", "(", "[", "x", "[", "\"scores\"", "]", "for", "x", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "chosen_mask", "=", "score", ">", "conf_threshold", "\n", "score", "=", "score", "[", "chosen_mask", "]", "\n", "\n", "corners", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"corners\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "corners", "=", "corners", "[", "chosen_mask", "]", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"labels\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "labels", "=", "labels", "[", "chosen_mask", "]", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "ret", ".", "pred_corners", "=", "corners", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.make_sample_plots": [[216, 278], ["collections.defaultdict", "collections.defaultdict.keys", "list", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "detectron2.utils.colormap.colormap", "pred_by_image[].append", "detectron2.data.DatasetCatalog.get", "os.path.basename", "os.path.basename", "hrsc_evaluation.create_instances", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "numpy.concatenate", "cv2.imwrite", "cv2.imread", "len", "os.path.join", "os.path.join", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.structures.masks.PolygonMasks"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_instances", "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_dir", ",", "conf_threshold", ")", ":", "\n", "\n", "    ", "pred_by_image", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "predictions", ":", "\n", "        ", "pred_by_image", "[", "p", "[", "\"image_id\"", "]", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "valid_image_ids", "=", "pred_by_image", ".", "keys", "(", ")", "\n", "dicts", "=", "list", "(", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", ")", "\n", "dicts", "=", "[", "d", "for", "d", "in", "dicts", "if", "d", "[", "\"image_id\"", "]", "in", "valid_image_ids", "]", "\n", "\n", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"samples\"", ",", "f\"{conf_threshold:0.1f}\"", ")", "\n", "os", ".", "makedirs", "(", "samples_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "count", "=", "0", "\n", "for", "dic", "in", "dicts", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "dic", "[", "\"file_name\"", "]", ",", "cv2", ".", "IMREAD_COLOR", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "dic", "[", "\"file_name\"", "]", ")", "\n", "\n", "instances", "=", "create_instances", "(", "\n", "pred_by_image", "[", "dic", "[", "\"image_id\"", "]", "]", ",", "\n", "img", ".", "shape", "[", ":", "2", "]", ",", "\n", "conf_threshold", "=", "conf_threshold", ",", "\n", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "labels", "=", "_create_text_labels", "(", "instances", ".", "pred_classes", ",", "instances", ".", "scores", ",", "classnames", ")", "\n", "\n", "vis_pred", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "\n", "annos", "=", "dic", "[", "\"annotations\"", "]", "\n", "\n", "# Skip images without annotations", "\n", "if", "len", "(", "annos", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "\n", "labels", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "names", "=", "classnames", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "if", "names", ":", "\n", "            ", "labels", "=", "[", "names", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "", "vis_gt", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "masks", "=", "masks", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "concat", "=", "np", ".", "concatenate", "(", "(", "vis_pred", ",", "vis_gt", ")", ",", "axis", "=", "1", ")", "\n", "assert", "basename", "[", "-", "4", ":", "]", "==", "\".bmp\"", "\n", "basename_png", "=", "basename", "[", ":", "-", "4", "]", "+", "\".png\"", "# Remove \".bmp\"", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "samples_dir", ",", "basename_png", ")", ",", "concat", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "count", "+=", "1", "\n", "if", "count", ">", "19", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.hrsc_evaluation.do_hrsc_evaluation": [[280, 348], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "hrsc_evaluation._generate_task_1_files", "hrsc_evaluation.make_sample_plots", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fvcore.common.file_io.PathManager.mkdirs", "collections.OrderedDict", "numpy.savetxt", "logger.info", "detectron2.utils.comm.is_main_process", "voc_eval.voc_eval", "hrsc_evaluation.plot_pr_curve", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "pprint.pformat", "os.path.join", "os.path.join", "open", "results[].items", "os.path.join", "os.path.join", "f.write"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation._generate_task_1_files", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.make_sample_plots", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_eval", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.plot_pr_curve"], ["", "", "", "def", "do_hrsc_evaluation", "(", "\n", "dataset_name", ",", "\n", "metadata", ",", "\n", "predictions", ":", "dict", ",", "\n", "output_folder", ":", "str", ",", "\n", "logger", ",", "\n", "results", ":", "dict", ",", "\n", "cfg", ",", "\n", ")", ":", "\n", "\n", "    ", "task1_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"Task1\"", ")", "\n", "os", ".", "makedirs", "(", "task1_dir", ",", "exist_ok", "=", "True", ")", "\n", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", "\n", "\n", "# Create sample plots", "\n", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_folder", ",", "conf_threshold", "=", "0.4", ")", "\n", "\n", "dataset_base_path", "=", "metadata", ".", "root_dir", "\n", "\n", "detpath", "=", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "r\"Task1_{:s}.txt\"", ")", "\n", "annopath", "=", "os", ".", "path", ".", "join", "(", "dataset_base_path", ",", "\"labelXml\"", ",", "r\"{:s}.xml\"", ")", "\n", "imagesetfile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", "\n", "\n", "mean_ap", "=", "0.0", "\n", "pr_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"pr-curves/\"", ")", "\n", "PathManager", ".", "mkdirs", "(", "pr_dir", ")", "\n", "task_results", "=", "OrderedDict", "(", ")", "\n", "\n", "data_scores_overlap", "=", "[", "]", "\n", "for", "classname", "in", "classnames", ":", "\n", "# Skip container crane", "\n", "# if classname == \"container-crane\":", "\n", "#     continue", "\n", "# Compute class AP", "\n", "        ", "rec", ",", "prec", ",", "ap", ",", "data_scores_overlap_per_cls", "=", "voc_eval", "(", "\n", "detpath", ",", "\n", "annopath", ",", "\n", "imagesetfile", ",", "\n", "classname", ",", "\n", "ovthresh", "=", "cfg", ".", "TEST", ".", "IOU_TH", ",", "\n", "use_07_metric", "=", "True", ",", "\n", "parse_gt", "=", "parse_gt", ",", "\n", ")", "\n", "mean_ap", "=", "mean_ap", "+", "ap", "\n", "task_results", "[", "classname", "]", "=", "ap", "\n", "\n", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", "\n", "data_scores_overlap", "+=", "data_scores_overlap_per_cls", "\n", "\n", "# Save score to overlap tuples", "\n", "", "np", ".", "savetxt", "(", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"scores_overlap.csv\"", ")", ",", "\n", "X", "=", "data_scores_overlap", ",", "\n", "delimiter", "=", "\",\"", ",", "\n", "fmt", "=", "\"%s\"", "\n", ")", "\n", "\n", "mean_ap", "=", "mean_ap", "/", "len", "(", "classnames", ")", "\n", "task_results", "[", "\"map\"", "]", "=", "mean_ap", "\n", "\n", "results", "[", "\"task1\"", "]", "=", "task_results", "\n", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "pformat", "(", "results", ")", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "results", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.pth\"", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "value", "in", "results", "[", "\"task1\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"{key: <18}: {value:2.4f}\\n\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.UcasAodEvaluator._eval_predictions": [[30, 39], ["ucas_aod_evaluation.do_ucas_aod_evaluation"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.do_ucas_aod_evaluation"], ["    ", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "do_ucas_aod_evaluation", "(", "\n", "dataset_name", "=", "self", ".", "_dataset_name", ",", "\n", "metadata", "=", "self", ".", "_metadata", ",", "\n", "predictions", "=", "predictions", ",", "\n", "output_folder", "=", "self", ".", "_output_dir", ",", "\n", "logger", "=", "self", ".", "_logger", ",", "\n", "results", "=", "self", ".", "_results", ",", "\n", "cfg", "=", "self", ".", "_cfg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.xywha2xy4": [[83, 89], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.parse_gt": [[91, 104], ["os.path.split", "os.path.split", "os.path.split", "os.path.split", "dafne.data.datasets.ucas_aod.parse_annotation", "objs.append"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.parse_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_gt", "(", "annopath", ")", ":", "\n", "    ", "anno_dir", ",", "img_path", "=", "os", ".", "path", ".", "split", "(", "annopath", ")", "\n", "root_dir", ",", "_", "=", "os", ".", "path", ".", "split", "(", "anno_dir", ")", "\n", "objects", "=", "parse_annotation", "(", "root", "=", "root_dir", ",", "img_id", "=", "img_path", "[", ":", "-", "4", "]", ")", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "objects", "[", "\"annotations\"", "]", ":", "\n", "        ", "object_struct", "=", "{", "}", "\n", "object_struct", "[", "\"name\"", "]", "=", "label2name", "[", "anno", "[", "\"category_id\"", "]", "]", "\n", "object_struct", "[", "\"difficult\"", "]", "=", "0", "\n", "object_struct", "[", "\"bbox\"", "]", "=", "anno", "[", "\"segmentation\"", "]", "[", "0", "]", "\n", "objs", ".", "append", "(", "object_struct", ")", "\n", "\n", "", "return", "objs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation._generate_task_1_files": [[106, 156], ["range", "set", "logger.info", "fp_classes.items", "len", "open", "set.add", "range", "fp.close", "open", "f.write", "os.path.join", "os.path.join", "prediction.unbind", "labels[].item", "fp_classes[].write", "os.path.join", "os.path.join", "list", "fname.split"], "function", ["None"], ["", "def", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"Construct files according to Task1: https://captain-whu.github.io/DOAI2019/tasks.html\"\"\"", "\n", "\n", "fp_classes", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "classnames", ")", ")", ":", "\n", "        ", "cls_name", "=", "classnames", "[", "i", "]", "\n", "fp_classes", "[", "i", "]", "=", "open", "(", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "f\"Task1_{cls_name}.txt\"", ")", ",", "\"w\"", ")", "\n", "\n", "", "fname_set", "=", "set", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Collecting predictions into Task1_<class-name>.txt files\"", ")", "\n", "\n", "# Iterate over images", "\n", "for", "prediction", "in", "predictions", ":", "\n", "        ", "fname", "=", "prediction", "[", "\"file_name\"", "]", "\n", "fname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "fname_set", ".", "add", "(", "fname", ")", "\n", "corners", "=", "prediction", "[", "\"corners\"", "]", "\n", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", "\n", "\n", "# Remove centerness from score to get back original class confidences", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "!=", "\"none\"", "and", "not", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_USE_IN_SCORE", ":", "\n", "            ", "centerness", "=", "prediction", "[", "\"centerness\"", "]", "\n", "scores", "=", "scores", "**", "2", "\n", "scores", "=", "scores", "/", "centerness", "\n", "\n", "# Iterate over boxes", "\n", "", "num_boxes", "=", "corners", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "            ", "prediction", "=", "corners", "[", "i", "]", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "=", "prediction", ".", "unbind", "(", ")", "\n", "label", "=", "labels", "[", "i", "]", ".", "item", "(", ")", "\n", "score", "=", "scores", "[", "i", "]", "\n", "\n", "# Add line to the correct class file", "\n", "line", "=", "f\"{fname} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f}\\n\"", "\n", "fp_classes", "[", "label", "]", ".", "write", "(", "line", ")", "\n", "\n", "# Close files", "\n", "", "", "for", "_", ",", "fp", "in", "fp_classes", ".", "items", "(", ")", ":", "\n", "        ", "fp", ".", "close", "(", ")", "\n", "\n", "# Create the imageset file", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "\"\\n\"", ".", "join", "(", "list", "(", "fname_set", ")", ")", "\n", "f", ".", "write", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.plot_pr_curve": [[158, 169], ["matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.plot", "matplotlib.tight_layout", "matplotlib.savefig", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", ":", "\n", "# Plot PR Curve", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "6", ")", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1", ")", "\n", "plt", ".", "title", "(", "f\"PR-Curve {classname} (AP={ap * 100:2.2f})\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Recall\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Precision\"", ")", "\n", "plt", ".", "plot", "(", "rec", ",", "prec", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "pr_dir", ",", "f\"pr-curve_{classname}.png\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.run_merge": [[171, 175], ["logger.info", "dafne.utils.ResultMerge_multi_process.mergebypoly", "logger.info"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebypoly"], ["", "def", "run_merge", "(", "src", ",", "dst", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Starting task1 result merge ...\"", ")", "\n", "mergebypoly", "(", "src", ",", "dst", ")", "\n", "logger", ".", "info", "(", "\"task1 result merge done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.create_zip": [[177, 189], ["logger.info", "zipfile.ZipFile", "glob.glob", "zipfile.ZipFile.close", "logger.info", "zipfile.ZipFile.write", "os.path.join", "os.path.join", "fname.split"], "function", ["None"], ["", "def", "create_zip", "(", "output_dir", ",", "task1_merged_dir", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Creating zip file ...\"", ")", "\n", "zfile", "=", "zipfile", ".", "ZipFile", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"task1_merged.zip\"", ")", ",", "\n", "mode", "=", "\"w\"", ",", "\n", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ",", "\n", ")", "\n", "for", "fname", "in", "glob", ".", "glob", "(", "task1_merged_dir", "+", "\"/Task1_*.txt\"", ")", ":", "\n", "        ", "arcname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# Avoid directory structure in zip file", "\n", "zfile", ".", "write", "(", "fname", ",", "arcname", "=", "arcname", ")", "\n", "", "zfile", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Zip file done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.create_instances": [[191, 215], ["detectron2.structures.Instances", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["", "def", "create_instances", "(", "predictions", ",", "image_size", ",", "conf_threshold", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "        ", "ret", ".", "scores", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "# ret.pred_boxes = torch.empty(0, 5)", "\n", "ret", ".", "pred_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "ret", ".", "pred_classes", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "\n", "", "score", "=", "torch", ".", "cat", "(", "[", "x", "[", "\"scores\"", "]", "for", "x", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "chosen_mask", "=", "score", ">", "conf_threshold", "\n", "score", "=", "score", "[", "chosen_mask", "]", "\n", "\n", "corners", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"corners\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "corners", "=", "corners", "[", "chosen_mask", "]", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"labels\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "labels", "=", "labels", "[", "chosen_mask", "]", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "ret", ".", "pred_corners", "=", "corners", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.make_sample_plots": [[217, 278], ["collections.defaultdict", "collections.defaultdict.keys", "list", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "detectron2.utils.colormap.colormap", "pred_by_image[].append", "detectron2.data.DatasetCatalog.get", "os.path.basename", "os.path.basename", "ucas_aod_evaluation.create_instances", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "numpy.concatenate", "cv2.imwrite", "cv2.imread", "len", "os.path.join", "os.path.join", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.structures.masks.PolygonMasks"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_instances", "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_dir", ",", "conf_threshold", ")", ":", "\n", "\n", "    ", "pred_by_image", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "predictions", ":", "\n", "        ", "pred_by_image", "[", "p", "[", "\"image_id\"", "]", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "valid_image_ids", "=", "pred_by_image", ".", "keys", "(", ")", "\n", "dicts", "=", "list", "(", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", ")", "\n", "dicts", "=", "[", "d", "for", "d", "in", "dicts", "if", "d", "[", "\"image_id\"", "]", "in", "valid_image_ids", "]", "\n", "\n", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"samples\"", ",", "f\"{conf_threshold:0.1f}\"", ")", "\n", "os", ".", "makedirs", "(", "samples_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "count", "=", "0", "\n", "for", "dic", "in", "dicts", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "dic", "[", "\"file_name\"", "]", ",", "cv2", ".", "IMREAD_COLOR", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "dic", "[", "\"file_name\"", "]", ")", "\n", "\n", "instances", "=", "create_instances", "(", "\n", "pred_by_image", "[", "dic", "[", "\"image_id\"", "]", "]", ",", "\n", "img", ".", "shape", "[", ":", "2", "]", ",", "\n", "conf_threshold", "=", "conf_threshold", ",", "\n", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "labels", "=", "_create_text_labels", "(", "instances", ".", "pred_classes", ",", "instances", ".", "scores", ",", "classnames", ")", "\n", "\n", "vis_pred", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "\n", "annos", "=", "dic", "[", "\"annotations\"", "]", "\n", "\n", "# Skip images without annotations", "\n", "if", "len", "(", "annos", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "\n", "labels", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "names", "=", "classnames", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "if", "names", ":", "\n", "            ", "labels", "=", "[", "names", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "", "vis_gt", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "masks", "=", "masks", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "concat", "=", "np", ".", "concatenate", "(", "(", "vis_pred", ",", "vis_gt", ")", ",", "axis", "=", "1", ")", "\n", "assert", "basename", "[", "-", "4", ":", "]", "==", "\".png\"", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "samples_dir", ",", "basename", ")", ",", "concat", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "count", "+=", "1", "\n", "if", "count", ">", "19", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.ucas_aod_evaluation.do_ucas_aod_evaluation": [[280, 348], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "ucas_aod_evaluation._generate_task_1_files", "ucas_aod_evaluation.make_sample_plots", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fvcore.common.file_io.PathManager.mkdirs", "collections.OrderedDict", "numpy.savetxt", "logger.info", "detectron2.utils.comm.is_main_process", "voc_eval.voc_eval", "ucas_aod_evaluation.plot_pr_curve", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "pprint.pformat", "os.path.join", "os.path.join", "open", "results[].items", "os.path.join", "os.path.join", "f.write"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation._generate_task_1_files", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.make_sample_plots", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_eval", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.plot_pr_curve"], ["", "", "", "def", "do_ucas_aod_evaluation", "(", "\n", "dataset_name", ",", "\n", "metadata", ",", "\n", "predictions", ":", "dict", ",", "\n", "output_folder", ":", "str", ",", "\n", "logger", ",", "\n", "results", ":", "dict", ",", "\n", "cfg", ",", "\n", ")", ":", "\n", "\n", "    ", "task1_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"Task1\"", ")", "\n", "os", ".", "makedirs", "(", "task1_dir", ",", "exist_ok", "=", "True", ")", "\n", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", "\n", "\n", "# Create sample plots", "\n", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_folder", ",", "conf_threshold", "=", "0.4", ")", "\n", "\n", "dataset_base_path", "=", "metadata", ".", "root_dir", "\n", "\n", "detpath", "=", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "r\"Task1_{:s}.txt\"", ")", "\n", "annopath", "=", "os", ".", "path", ".", "join", "(", "dataset_base_path", ",", "\"Annotations\"", ",", "r\"{:s}.txt\"", ")", "\n", "imagesetfile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", "\n", "\n", "mean_ap", "=", "0.0", "\n", "pr_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"pr-curves/\"", ")", "\n", "PathManager", ".", "mkdirs", "(", "pr_dir", ")", "\n", "task_results", "=", "OrderedDict", "(", ")", "\n", "\n", "data_scores_overlap", "=", "[", "]", "\n", "for", "classname", "in", "classnames", ":", "\n", "# Skip container crane", "\n", "# if classname == \"container-crane\":", "\n", "#     continue", "\n", "# Compute class AP", "\n", "        ", "rec", ",", "prec", ",", "ap", ",", "data_scores_overlap_per_cls", "=", "voc_eval", "(", "\n", "detpath", ",", "\n", "annopath", ",", "\n", "imagesetfile", ",", "\n", "classname", ",", "\n", "ovthresh", "=", "cfg", ".", "TEST", ".", "IOU_TH", ",", "\n", "use_07_metric", "=", "True", ",", "\n", "parse_gt", "=", "parse_gt", ",", "\n", ")", "\n", "mean_ap", "=", "mean_ap", "+", "ap", "\n", "task_results", "[", "classname", "]", "=", "ap", "\n", "\n", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", "\n", "data_scores_overlap", "+=", "data_scores_overlap_per_cls", "\n", "\n", "# Save score to overlap tuples", "\n", "", "np", ".", "savetxt", "(", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"scores_overlap.csv\"", ")", ",", "\n", "X", "=", "data_scores_overlap", ",", "\n", "delimiter", "=", "\",\"", ",", "\n", "fmt", "=", "\"%s\"", ",", "\n", ")", "\n", "\n", "mean_ap", "=", "mean_ap", "/", "len", "(", "classnames", ")", "\n", "task_results", "[", "\"map\"", "]", "=", "mean_ap", "\n", "\n", "results", "[", "\"task1\"", "]", "=", "task_results", "\n", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "pformat", "(", "results", ")", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "results", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.pth\"", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "value", "in", "results", "[", "\"task1\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"{key: <18}: {value:2.4f}\\n\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.DotaEvaluator._eval_predictions": [[27, 36], ["dota_evaluation.do_dota_evaluation"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.do_dota_evaluation"], ["    ", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "do_dota_evaluation", "(", "\n", "dataset_name", "=", "self", ".", "_dataset_name", ",", "\n", "metadata", "=", "self", ".", "_metadata", ",", "\n", "predictions", "=", "predictions", ",", "\n", "output_folder", "=", "self", ".", "_output_dir", ",", "\n", "logger", "=", "self", ".", "_logger", ",", "\n", "results", "=", "self", ".", "_results", ",", "\n", "cfg", "=", "self", ".", "_cfg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.parse_gt": [[73, 108], ["open", "f.readline", "f.readline.strip().split", "objects.append", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "f.readline.strip", "len", "int"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["def", "parse_gt", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n\n    :param filename: ground truth file to parse\n    :return: all instances in a picture\n    \"\"\"", "\n", "objects", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "line", "=", "f", ".", "readline", "(", ")", "\n", "if", "line", ":", "\n", "                ", "splitlines", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "object_struct", "=", "{", "}", "\n", "if", "len", "(", "splitlines", ")", "<", "9", ":", "\n", "                    ", "continue", "\n", "", "object_struct", "[", "\"name\"", "]", "=", "splitlines", "[", "8", "]", "\n", "\n", "if", "len", "(", "splitlines", ")", "==", "9", ":", "\n", "                    ", "object_struct", "[", "\"difficult\"", "]", "=", "0", "\n", "", "elif", "len", "(", "splitlines", ")", "==", "10", ":", "\n", "                    ", "object_struct", "[", "\"difficult\"", "]", "=", "int", "(", "splitlines", "[", "9", "]", ")", "\n", "", "object_struct", "[", "\"bbox\"", "]", "=", "[", "\n", "float", "(", "splitlines", "[", "0", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "1", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "2", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "3", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "4", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "5", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "6", "]", ")", ",", "\n", "float", "(", "splitlines", "[", "7", "]", ")", ",", "\n", "]", "\n", "objects", ".", "append", "(", "object_struct", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "", "return", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation._generate_task_1_files": [[110, 165], ["range", "set", "logger.info", "fp_classes.items", "len", "open", "set.add", "range", "fp.close", "open", "f.write", "os.path.join", "os.path.join", "prediction.unbind", "labels[].item", "fp_classes[].write", "os.path.join", "os.path.join", "list", "fname.split"], "function", ["None"], ["", "def", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "classnames", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"Construct files according to Task1: https://captain-whu.github.io/DOAI2019/tasks.html\"\"\"", "\n", "\n", "fp_classes", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "classnames", ")", ")", ":", "\n", "        ", "cls_name", "=", "classnames", "[", "i", "]", "\n", "fp_classes", "[", "i", "]", "=", "open", "(", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "f\"Task1_{cls_name}.txt\"", ")", ",", "\"w\"", ")", "\n", "\n", "", "fname_set", "=", "set", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Collecting predictions into Task1_<class-name>.txt files\"", ")", "\n", "\n", "# Iterate over images", "\n", "for", "prediction", "in", "predictions", ":", "\n", "        ", "fname", "=", "prediction", "[", "\"file_name\"", "]", "\n", "fname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "fname_set", ".", "add", "(", "fname", ")", "\n", "corners", "=", "prediction", "[", "\"corners\"", "]", "\n", "assert", "prediction", "[", "\"height\"", "]", "==", "prediction", "[", "\"width\"", "]", "\n", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", "\n", "\n", "# Remove centerness from score to get back original class confidences", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "!=", "\"none\"", "and", "not", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_USE_IN_SCORE", ":", "\n", "            ", "centerness", "=", "prediction", "[", "\"centerness\"", "]", "\n", "scores", "=", "scores", "**", "2", "\n", "scores", "=", "scores", "/", "centerness", "\n", "\n", "# Iterate over boxes", "\n", "", "num_boxes", "=", "corners", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "            ", "prediction", "=", "corners", "[", "i", "]", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "=", "prediction", ".", "unbind", "(", ")", "\n", "label", "=", "labels", "[", "i", "]", ".", "item", "(", ")", "\n", "score", "=", "scores", "[", "i", "]", "\n", "\n", "if", "label", "==", "15", "and", "cfg", ".", "DATASETS", ".", "DOTA_REMOVE_CONTAINER_CRANE", ":", "\n", "# Skip 'container-crane' label", "\n", "                ", "continue", "\n", "\n", "# Add line to the correct class file", "\n", "", "line", "=", "f\"{fname} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f}\\n\"", "\n", "fp_classes", "[", "label", "]", ".", "write", "(", "line", ")", "\n", "\n", "# Close files", "\n", "", "", "for", "_", ",", "fp", "in", "fp_classes", ".", "items", "(", ")", ":", "\n", "        ", "fp", ".", "close", "(", ")", "\n", "\n", "# Create the imageset file", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "\"\\n\"", ".", "join", "(", "list", "(", "fname_set", ")", ")", "\n", "f", ".", "write", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.plot_pr_curve": [[167, 179], ["matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.plot", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", ":", "\n", "# Plot PR Curve", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "6", ")", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1", ")", "\n", "plt", ".", "title", "(", "f\"PR-Curve {classname} (AP={ap * 100:2.2f})\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Recall\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Precision\"", ")", "\n", "plt", ".", "plot", "(", "rec", ",", "prec", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "pr_dir", ",", "f\"pr-curve_{classname}.png\"", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.run_merge": [[181, 185], ["logger.info", "dafne.utils.ResultMerge_multi_process.mergebypoly", "logger.info"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebypoly"], ["", "def", "run_merge", "(", "src", ",", "dst", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Starting task1 result merge ...\"", ")", "\n", "mergebypoly", "(", "src", ",", "dst", ")", "\n", "logger", ".", "info", "(", "\"task1 result merge done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.create_zip": [[187, 199], ["logger.info", "zipfile.ZipFile", "glob.glob", "zipfile.ZipFile.close", "logger.info", "zipfile.ZipFile.write", "os.path.join", "os.path.join", "fname.split"], "function", ["None"], ["", "def", "create_zip", "(", "output_dir", ",", "task1_merged_dir", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Creating zip file ...\"", ")", "\n", "zfile", "=", "zipfile", ".", "ZipFile", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"task1_merged.zip\"", ")", ",", "\n", "mode", "=", "\"w\"", ",", "\n", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ",", "\n", ")", "\n", "for", "fname", "in", "glob", ".", "glob", "(", "task1_merged_dir", "+", "\"/Task1_*.txt\"", ")", ":", "\n", "        ", "arcname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# Avoid directory structure in zip file", "\n", "zfile", ".", "write", "(", "fname", ",", "arcname", "=", "arcname", ")", "\n", "", "zfile", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Zip file done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.create_instances": [[201, 229], ["detectron2.structures.Instances", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["", "def", "create_instances", "(", "predictions", ",", "image_size", ",", "conf_threshold", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "        ", "ret", ".", "scores", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "# ret.pred_boxes = torch.empty(0, 5)", "\n", "ret", ".", "pred_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "ret", ".", "pred_classes", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "\n", "", "score", "=", "torch", ".", "cat", "(", "[", "x", "[", "\"scores\"", "]", "for", "x", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "chosen_mask", "=", "score", ">", "conf_threshold", "\n", "score", "=", "score", "[", "chosen_mask", "]", "\n", "\n", "corners", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"corners\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "corners", "=", "corners", "[", "chosen_mask", "]", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"labels\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "labels", "=", "labels", "[", "chosen_mask", "]", "\n", "\n", "centerness", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"centerness\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "centerness", "=", "centerness", "[", "chosen_mask", "]", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "ret", ".", "pred_corners", "=", "corners", "\n", "ret", ".", "centerness", "=", "centerness", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.make_sample_plots": [[231, 306], ["collections.defaultdict", "collections.defaultdict.keys", "list", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "detectron2.utils.colormap.colormap", "pred_by_image[].append", "detectron2.data.DatasetCatalog.get", "os.path.basename", "os.path.basename", "dota_evaluation.create_instances", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "numpy.concatenate", "cv2.imwrite", "cv2.imread", "len", "os.path.join", "os.path.join", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.structures.masks.PolygonMasks"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_instances", "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_dir", ",", "conf_threshold", ",", "classnames", ",", "cfg", ")", ":", "\n", "\n", "    ", "pred_by_image", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "predictions", ":", "\n", "        ", "pred_by_image", "[", "p", "[", "\"image_id\"", "]", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "valid_image_ids", "=", "pred_by_image", ".", "keys", "(", ")", "\n", "dicts", "=", "list", "(", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", ")", "\n", "dicts", "=", "[", "d", "for", "d", "in", "dicts", "if", "d", "[", "\"image_id\"", "]", "in", "valid_image_ids", "]", "\n", "\n", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"samples\"", ",", "f\"{conf_threshold:0.1f}\"", ")", "\n", "os", ".", "makedirs", "(", "samples_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "count", "=", "0", "\n", "for", "dic", "in", "dicts", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "dic", "[", "\"file_name\"", "]", ",", "cv2", ".", "IMREAD_COLOR", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "dic", "[", "\"file_name\"", "]", ")", "\n", "\n", "instances", "=", "create_instances", "(", "\n", "pred_by_image", "[", "dic", "[", "\"image_id\"", "]", "]", ",", "\n", "img", ".", "shape", "[", ":", "2", "]", ",", "\n", "conf_threshold", "=", "conf_threshold", ",", "\n", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "scores", "=", "instances", ".", "scores", "\n", "\n", "# Remove centerness from score to get back original class confidences", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "!=", "\"none\"", "and", "not", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_USE_IN_SCORE", ":", "\n", "            ", "centerness", "=", "instances", ".", "centerness", "\n", "scores", "=", "scores", "**", "2", "\n", "scores", "=", "scores", "/", "centerness", "\n", "\n", "", "labels", "=", "_create_text_labels", "(", "instances", ".", "pred_classes", ",", "scores", ",", "classnames", ")", "\n", "\n", "vis_pred", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "\n", "annos", "=", "dic", "[", "\"annotations\"", "]", "\n", "\n", "# Skip images without annotations", "\n", "if", "len", "(", "annos", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "\n", "labels", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "names", "=", "classnames", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "if", "names", ":", "\n", "            ", "labels", "=", "[", "names", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "", "vis_gt", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "masks", "=", "masks", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "concat", "=", "np", ".", "concatenate", "(", "(", "vis_pred", ",", "vis_gt", ")", ",", "axis", "=", "1", ")", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "samples_dir", ",", "basename", ")", ",", "concat", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "# plt.figure()", "\n", "# plt.imshow(concat[:, :, ::-1])", "\n", "# plt.axis(\"off\")", "\n", "# plt.savefig(os.path.join(samples_dir, basename))", "\n", "# plt.savefig(os.path.join(samples_dir, basename).replace(\".png\", \".pdf\"))", "\n", "# plt.close()", "\n", "\n", "count", "+=", "1", "\n", "if", "count", ">", "cfg", ".", "TEST", ".", "NUM_PRED_VIS", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dota_evaluation.do_dota_evaluation": [[308, 415], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "dota_evaluation._generate_task_1_files", "dota_evaluation.make_sample_plots", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fvcore.common.file_io.PathManager.mkdirs", "collections.OrderedDict", "numpy.savetxt", "detectron2.utils.comm.is_main_process", "classnames.append", "logger.info", "logger.info", "os.path.join", "os.path.join", "fvcore.common.file_io.PathManager.mkdirs", "dota_evaluation.run_merge", "dota_evaluation.create_zip", "voc_eval.voc_eval", "dota_evaluation.plot_pr_curve", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "results[].items", "os.path.join", "os.path.join", "f.write"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation._generate_task_1_files", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.make_sample_plots", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.run_merge", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_zip", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_eval", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.plot_pr_curve"], ["", "", "", "def", "do_dota_evaluation", "(", "\n", "dataset_name", ",", "\n", "metadata", ",", "\n", "predictions", ":", "dict", ",", "\n", "output_folder", ":", "str", ",", "\n", "logger", ",", "\n", "results", ":", "dict", ",", "\n", "cfg", ",", "\n", ")", ":", "\n", "\n", "# For DOTA-v1.0", "\n", "    ", "classnames", "=", "[", "\n", "\"plane\"", ",", "\n", "\"baseball-diamond\"", ",", "\n", "\"bridge\"", ",", "\n", "\"ground-track-field\"", ",", "\n", "\"small-vehicle\"", ",", "\n", "\"large-vehicle\"", ",", "\n", "\"ship\"", ",", "\n", "\"tennis-court\"", ",", "\n", "\"basketball-court\"", ",", "\n", "\"storage-tank\"", ",", "\n", "\"soccer-ball-field\"", ",", "\n", "\"roundabout\"", ",", "\n", "\"harbor\"", ",", "\n", "\"swimming-pool\"", ",", "\n", "\"helicopter\"", ",", "\n", "]", "\n", "\n", "# For DOTA-v1.5", "\n", "if", "\"1_5\"", "in", "dataset_name", "and", "not", "cfg", ".", "DATASETS", ".", "DOTA_REMOVE_CONTAINER_CRANE", ":", "\n", "        ", "classnames", ".", "append", "(", "\"container-crane\"", ")", "\n", "\n", "", "task1_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"Task1\"", ")", "\n", "os", ".", "makedirs", "(", "task1_dir", ",", "exist_ok", "=", "True", ")", "\n", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "classnames", ",", "cfg", ")", "\n", "if", "metadata", ".", "is_test", ":", "\n", "        ", "logger", ".", "info", "(", "\"Test mode active, skipping evaluation.\"", ")", "\n", "logger", ".", "info", "(", "\"Merging results and creating Task1.zip.\"", ")", "\n", "task1_merged_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"Task1_merged\"", ")", "\n", "PathManager", ".", "mkdirs", "(", "task1_merged_dir", ")", "\n", "run_merge", "(", "src", "=", "task1_dir", ",", "dst", "=", "task1_merged_dir", ")", "\n", "create_zip", "(", "output_folder", ",", "task1_merged_dir", ")", "\n", "return", "\n", "\n", "# Create sample plots", "\n", "", "make_sample_plots", "(", "\n", "metadata", ",", "\n", "dataset_name", ",", "\n", "predictions", ",", "\n", "output_folder", ",", "\n", "conf_threshold", "=", "0.4", ",", "\n", "classnames", "=", "classnames", ",", "\n", "cfg", "=", "cfg", "\n", ")", "\n", "\n", "dataset_base_path", "=", "metadata", ".", "root_dir", "\n", "\n", "detpath", "=", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "r\"Task1_{:s}.txt\"", ")", "\n", "annopath", "=", "os", ".", "path", ".", "join", "(", "dataset_base_path", ",", "\"labelTxt\"", ",", "r\"{:s}.txt\"", ")", "\n", "imagesetfile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", "\n", "\n", "mean_ap", "=", "0.0", "\n", "pr_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"pr-curves/\"", ")", "\n", "PathManager", ".", "mkdirs", "(", "pr_dir", ")", "\n", "task_results", "=", "OrderedDict", "(", ")", "\n", "\n", "data_scores_overlap", "=", "[", "]", "\n", "for", "classname", "in", "classnames", ":", "\n", "# Skip container crane", "\n", "# if classname == \"container-crane\":", "\n", "#     continue", "\n", "# Compute class AP", "\n", "        ", "rec", ",", "prec", ",", "ap", ",", "data_scores_overlap_per_cls", "=", "voc_eval", "(", "\n", "detpath", ",", "\n", "annopath", ",", "\n", "imagesetfile", ",", "\n", "classname", ",", "\n", "ovthresh", "=", "cfg", ".", "TEST", ".", "IOU_TH", ",", "\n", "use_07_metric", "=", "True", ",", "\n", "parse_gt", "=", "parse_gt", ",", "\n", ")", "\n", "mean_ap", "=", "mean_ap", "+", "ap", "\n", "task_results", "[", "classname", "]", "=", "ap", "\n", "\n", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", "\n", "\n", "# Save score to overlap tuples", "\n", "data_scores_overlap", "+=", "data_scores_overlap_per_cls", "\n", "\n", "", "np", ".", "savetxt", "(", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"scores_overlap.csv\"", ")", ",", "\n", "X", "=", "data_scores_overlap", ",", "\n", "delimiter", "=", "\",\"", ",", "\n", "fmt", "=", "\"%s\"", ",", "\n", ")", "\n", "\n", "mean_ap", "=", "mean_ap", "/", "len", "(", "classnames", ")", "\n", "task_results", "[", "\"map\"", "]", "=", "mean_ap", "\n", "\n", "results", "[", "\"task1\"", "]", "=", "task_results", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "results", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.pth\"", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "value", "in", "results", "[", "\"task1\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"{key: <18}: {value:2.4f}\\n\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.Icdar15Evaluator._eval_predictions": [[30, 39], ["icdar15_evaluation.do_icdar_evaluation"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.do_icdar_evaluation"], ["    ", "def", "_eval_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "do_icdar_evaluation", "(", "\n", "dataset_name", "=", "self", ".", "_dataset_name", ",", "\n", "metadata", "=", "self", ".", "_metadata", ",", "\n", "predictions", "=", "predictions", ",", "\n", "output_folder", "=", "self", ".", "_output_dir", ",", "\n", "logger", "=", "self", ".", "_logger", ",", "\n", "results", "=", "self", ".", "_results", ",", "\n", "cfg", "=", "self", ".", "_cfg", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.xywha2xy4": [[83, 89], ["numpy.array", "numpy.array", "np.array.dot", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["def", "xywha2xy4", "(", "xywha", ")", ":", "# a represents the angle(degree), clockwise, a=0 along the X axis", "\n", "    ", "x", ",", "y", ",", "w", ",", "h", ",", "a", "=", "xywha", "\n", "corner", "=", "np", ".", "array", "(", "[", "[", "-", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "-", "h", "/", "2", "]", ",", "[", "w", "/", "2", ",", "h", "/", "2", "]", ",", "[", "-", "w", "/", "2", ",", "h", "/", "2", "]", "]", ")", "\n", "# a = np.deg2rad(a)", "\n", "transform", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", ",", "-", "np", ".", "sin", "(", "a", ")", "]", ",", "[", "np", ".", "sin", "(", "a", ")", ",", "np", ".", "cos", "(", "a", ")", "]", "]", ")", "\n", "return", "transform", ".", "dot", "(", "corner", ".", "T", ")", ".", "T", "+", "[", "x", ",", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.parse_gt": [[91, 106], ["os.path.split", "os.path.split", "os.path.split", "os.path.split", "os.path.split", "os.path.split", "img_path.replace().replace().replace", "dafne.data.datasets.icdar15.parse_annotation", "objs.append", "img_path.replace().replace", "img_path.replace"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.datasets.icdar15.parse_annotation", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "parse_gt", "(", "annopath", ")", ":", "\n", "    ", "anno_dir", ",", "img_path", "=", "os", ".", "path", ".", "split", "(", "annopath", ")", "\n", "anno_dir", ",", "imageset", "=", "os", ".", "path", ".", "split", "(", "anno_dir", ")", "\n", "root_dir", ",", "_", "=", "os", ".", "path", ".", "split", "(", "anno_dir", ")", "\n", "img_id", "=", "img_path", ".", "replace", "(", "\"img_\"", ",", "\"\"", ")", ".", "replace", "(", "\"gt_\"", ",", "\"\"", ")", ".", "replace", "(", "\".txt\"", ",", "\"\"", ")", "\n", "objects", "=", "parse_annotation", "(", "root", "=", "root_dir", ",", "img_id", "=", "img_id", ",", "image_set", "=", "imageset", ")", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "objects", "[", "\"annotations\"", "]", ":", "\n", "        ", "object_struct", "=", "{", "}", "\n", "object_struct", "[", "\"name\"", "]", "=", "label2name", "[", "anno", "[", "\"category_id\"", "]", "]", "\n", "object_struct", "[", "\"difficult\"", "]", "=", "0", "\n", "object_struct", "[", "\"bbox\"", "]", "=", "anno", "[", "\"segmentation\"", "]", "[", "0", "]", "\n", "objs", ".", "append", "(", "object_struct", ")", "\n", "\n", "", "return", "objs", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation._generate_task_1_files": [[108, 158], ["range", "set", "logger.info", "fp_classes.items", "len", "open", "set.add", "range", "fp.close", "open", "f.write", "os.path.join", "os.path.join", "prediction.unbind", "labels[].item", "fp_classes[].write", "os.path.join", "os.path.join", "list", "fname.split"], "function", ["None"], ["", "def", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"Construct files according to Task1: https://captain-whu.github.io/DOAI2019/tasks.html\"\"\"", "\n", "\n", "fp_classes", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "classnames", ")", ")", ":", "\n", "        ", "cls_name", "=", "classnames", "[", "i", "]", "\n", "fp_classes", "[", "i", "]", "=", "open", "(", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "f\"Task1_{cls_name}.txt\"", ")", ",", "\"w\"", ")", "\n", "\n", "", "fname_set", "=", "set", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Collecting predictions into Task1_<class-name>.txt files\"", ")", "\n", "\n", "# Iterate over images", "\n", "for", "prediction", "in", "predictions", ":", "\n", "        ", "fname", "=", "prediction", "[", "\"file_name\"", "]", "\n", "fname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "fname_set", ".", "add", "(", "fname", ")", "\n", "corners", "=", "prediction", "[", "\"corners\"", "]", "\n", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", "\n", "\n", "# Remove centerness from score to get back original class confidences", "\n", "if", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS", "!=", "\"none\"", "and", "not", "cfg", ".", "MODEL", ".", "DAFNE", ".", "CENTERNESS_USE_IN_SCORE", ":", "\n", "            ", "centerness", "=", "prediction", "[", "\"centerness\"", "]", "\n", "scores", "=", "scores", "**", "2", "\n", "scores", "=", "scores", "/", "centerness", "\n", "\n", "# Iterate over boxes", "\n", "", "num_boxes", "=", "corners", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "            ", "prediction", "=", "corners", "[", "i", "]", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "x3", ",", "y3", ",", "x4", ",", "y4", "=", "prediction", ".", "unbind", "(", ")", "\n", "label", "=", "labels", "[", "i", "]", ".", "item", "(", ")", "\n", "score", "=", "scores", "[", "i", "]", "\n", "\n", "# Add line to the correct class file", "\n", "line", "=", "f\"{fname} {score:.4f} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {x3:.2f} {y3:.2f} {x4:.2f} {y4:.2f}\\n\"", "\n", "fp_classes", "[", "label", "]", ".", "write", "(", "line", ")", "\n", "\n", "# Close files", "\n", "", "", "for", "_", ",", "fp", "in", "fp_classes", ".", "items", "(", ")", ":", "\n", "        ", "fp", ".", "close", "(", ")", "\n", "\n", "# Create the imageset file", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "\"\\n\"", ".", "join", "(", "list", "(", "fname_set", ")", ")", "\n", "f", ".", "write", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.plot_pr_curve": [[160, 171], ["matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.plot", "matplotlib.tight_layout", "matplotlib.savefig", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", ":", "\n", "# Plot PR Curve", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "6", ")", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "1", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "1", ")", "\n", "plt", ".", "title", "(", "f\"PR-Curve {classname} (AP={ap * 100:2.2f})\"", ")", "\n", "plt", ".", "xlabel", "(", "\"Recall\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Precision\"", ")", "\n", "plt", ".", "plot", "(", "rec", ",", "prec", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "pr_dir", ",", "f\"pr-curve_{classname}.png\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.run_merge": [[173, 177], ["logger.info", "dafne.utils.ResultMerge_multi_process.mergebypoly", "logger.info"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.utils.ResultMerge_multi_process.mergebypoly"], ["", "def", "run_merge", "(", "src", ",", "dst", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Starting task1 result merge ...\"", ")", "\n", "mergebypoly", "(", "src", ",", "dst", ")", "\n", "logger", ".", "info", "(", "\"task1 result merge done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_zip": [[179, 191], ["logger.info", "zipfile.ZipFile", "glob.glob", "zipfile.ZipFile.close", "logger.info", "zipfile.ZipFile.write", "os.path.join", "os.path.join", "fname.split"], "function", ["None"], ["", "def", "create_zip", "(", "output_dir", ",", "task1_merged_dir", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"Creating zip file ...\"", ")", "\n", "zfile", "=", "zipfile", ".", "ZipFile", "(", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"task1_merged.zip\"", ")", ",", "\n", "mode", "=", "\"w\"", ",", "\n", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ",", "\n", ")", "\n", "for", "fname", "in", "glob", ".", "glob", "(", "task1_merged_dir", "+", "\"/Task1_*.txt\"", ")", ":", "\n", "        ", "arcname", "=", "fname", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "# Avoid directory structure in zip file", "\n", "zfile", ".", "write", "(", "fname", ",", "arcname", "=", "arcname", ")", "\n", "", "zfile", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "\"Zip file done ...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_instances": [[193, 217], ["detectron2.structures.Instances", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty", "home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.empty"], ["", "def", "create_instances", "(", "predictions", ",", "image_size", ",", "conf_threshold", ")", ":", "\n", "    ", "ret", "=", "Instances", "(", "image_size", ")", "\n", "\n", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "        ", "ret", ".", "scores", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "# ret.pred_boxes = torch.empty(0, 5)", "\n", "ret", ".", "pred_corners", "=", "torch", ".", "empty", "(", "0", ",", "8", ")", "\n", "ret", ".", "pred_classes", "=", "torch", ".", "empty", "(", "0", ",", "1", ")", "\n", "\n", "", "score", "=", "torch", ".", "cat", "(", "[", "x", "[", "\"scores\"", "]", "for", "x", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "chosen_mask", "=", "score", ">", "conf_threshold", "\n", "score", "=", "score", "[", "chosen_mask", "]", "\n", "\n", "corners", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"corners\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "corners", "=", "corners", "[", "chosen_mask", "]", "\n", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "p", "[", "\"labels\"", "]", "for", "p", "in", "predictions", "]", ",", "dim", "=", "0", ")", "\n", "labels", "=", "labels", "[", "chosen_mask", "]", "\n", "\n", "ret", ".", "scores", "=", "score", "\n", "ret", ".", "pred_classes", "=", "labels", "\n", "ret", ".", "pred_corners", "=", "corners", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.make_sample_plots": [[219, 280], ["collections.defaultdict", "collections.defaultdict.keys", "list", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "detectron2.utils.colormap.colormap", "pred_by_image[].append", "detectron2.data.DatasetCatalog.get", "os.path.basename", "os.path.basename", "icdar15_evaluation.create_instances", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.overlay_instances().get_image", "numpy.concatenate", "cv2.imwrite", "cv2.imread", "len", "os.path.join", "os.path.join", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.structures.masks.PolygonMasks"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.create_instances", "home.repos.pwc.inspect_result.steven-lang_dafne.vis.feature_maps._create_text_labels"], ["", "def", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_dir", ",", "conf_threshold", ")", ":", "\n", "\n", "    ", "pred_by_image", "=", "defaultdict", "(", "list", ")", "\n", "for", "p", "in", "predictions", ":", "\n", "        ", "pred_by_image", "[", "p", "[", "\"image_id\"", "]", "]", ".", "append", "(", "p", ")", "\n", "\n", "", "valid_image_ids", "=", "pred_by_image", ".", "keys", "(", ")", "\n", "dicts", "=", "list", "(", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", ")", "\n", "dicts", "=", "[", "d", "for", "d", "in", "dicts", "if", "d", "[", "\"image_id\"", "]", "in", "valid_image_ids", "]", "\n", "\n", "samples_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"samples\"", ",", "f\"{conf_threshold:0.1f}\"", ")", "\n", "os", ".", "makedirs", "(", "samples_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "colors", "=", "colormap", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "count", "=", "0", "\n", "for", "dic", "in", "dicts", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "dic", "[", "\"file_name\"", "]", ",", "cv2", ".", "IMREAD_COLOR", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "dic", "[", "\"file_name\"", "]", ")", "\n", "\n", "instances", "=", "create_instances", "(", "\n", "pred_by_image", "[", "dic", "[", "\"image_id\"", "]", "]", ",", "\n", "img", ".", "shape", "[", ":", "2", "]", ",", "\n", "conf_threshold", "=", "conf_threshold", ",", "\n", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "instances", ".", "pred_classes", "]", "\n", "labels", "=", "_create_text_labels", "(", "instances", ".", "pred_classes", ",", "instances", ".", "scores", ",", "classnames", ")", "\n", "\n", "vis_pred", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "\n", "masks", "=", "PolygonMasks", "(", "[", "[", "poly", "]", "for", "poly", "in", "instances", ".", "pred_corners", "]", ")", ",", "\n", "assigned_colors", "=", "assigned_colors", ",", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "vis", "=", "Visualizer", "(", "img", ",", "metadata", ")", "\n", "\n", "annos", "=", "dic", "[", "\"annotations\"", "]", "\n", "\n", "# Skip images without annotations", "\n", "if", "len", "(", "annos", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "\n", "labels", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "names", "=", "classnames", "\n", "assigned_colors", "=", "[", "colors", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "if", "names", ":", "\n", "            ", "labels", "=", "[", "names", "[", "i", "]", "for", "i", "in", "labels", "]", "\n", "", "vis_gt", "=", "vis", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "masks", "=", "masks", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", ".", "get_image", "(", ")", "\n", "\n", "concat", "=", "np", ".", "concatenate", "(", "(", "vis_pred", ",", "vis_gt", ")", ",", "axis", "=", "1", ")", "\n", "assert", "basename", "[", "-", "4", ":", "]", "==", "\".jpg\"", ",", "\"Basename should end with jpg but was: \"", "+", "basename", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "samples_dir", ",", "basename", ")", ",", "concat", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "count", "+=", "1", "\n", "if", "count", ">", "19", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.do_icdar_evaluation": [[282, 352], ["os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "icdar15_evaluation._generate_task_1_files", "icdar15_evaluation.make_sample_plots", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fvcore.common.file_io.PathManager.mkdirs", "collections.OrderedDict", "numpy.savetxt", "logger.info", "detectron2.utils.comm.is_main_process", "dataset_name.endswith", "dataset_name.endswith", "voc_eval.voc_eval", "icdar15_evaluation.plot_pr_curve", "len", "torch.save", "torch.save", "os.path.join", "os.path.join", "pprint.pformat", "os.path.join", "os.path.join", "open", "results[].items", "os.path.join", "os.path.join", "f.write"], "function", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation._generate_task_1_files", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.make_sample_plots", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.voc_eval.voc_eval", "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.plot_pr_curve"], ["", "", "", "def", "do_icdar_evaluation", "(", "\n", "dataset_name", ",", "\n", "metadata", ",", "\n", "predictions", ":", "dict", ",", "\n", "output_folder", ":", "str", ",", "\n", "logger", ",", "\n", "results", ":", "dict", ",", "\n", "cfg", ",", "\n", ")", ":", "\n", "\n", "    ", "task1_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"Task1\"", ")", "\n", "os", ".", "makedirs", "(", "task1_dir", ",", "exist_ok", "=", "True", ")", "\n", "_generate_task_1_files", "(", "metadata", ",", "predictions", ",", "output_folder", ",", "task1_dir", ",", "cfg", ")", "\n", "\n", "# Create sample plots", "\n", "make_sample_plots", "(", "metadata", ",", "dataset_name", ",", "predictions", ",", "output_folder", ",", "conf_threshold", "=", "0.4", ")", "\n", "\n", "dataset_base_path", "=", "metadata", ".", "root_dir", "\n", "\n", "detpath", "=", "os", ".", "path", ".", "join", "(", "task1_dir", ",", "r\"Task1_{:s}.txt\"", ")", "\n", "\n", "# Validation images are part of the train set directory", "\n", "if", "dataset_name", ".", "endswith", "(", "\"val\"", ")", "or", "dataset_name", ".", "endswith", "(", "\"train\"", ")", ":", "\n", "        ", "imageset", "=", "\"train\"", "\n", "", "else", ":", "\n", "        ", "imageset", "=", "\"test\"", "\n", "", "annopath", "=", "os", ".", "path", ".", "join", "(", "dataset_base_path", ",", "\"Annotations\"", ",", "imageset", ",", "r\"gt_img_{:s}.txt\"", ")", "\n", "imagesetfile", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"imageset.txt\"", ")", "\n", "\n", "mean_ap", "=", "0.0", "\n", "pr_dir", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"pr-curves/\"", ")", "\n", "PathManager", ".", "mkdirs", "(", "pr_dir", ")", "\n", "task_results", "=", "OrderedDict", "(", ")", "\n", "\n", "data_scores_overlap", "=", "[", "]", "\n", "for", "classname", "in", "classnames", ":", "\n", "        ", "rec", ",", "prec", ",", "ap", ",", "data_scores_overlap_per_cls", "=", "voc_eval", "(", "\n", "detpath", ",", "\n", "annopath", ",", "\n", "imagesetfile", ",", "\n", "classname", ",", "\n", "ovthresh", "=", "cfg", ".", "TEST", ".", "IOU_TH", ",", "\n", "use_07_metric", "=", "True", ",", "\n", "parse_gt", "=", "parse_gt", ",", "\n", ")", "\n", "mean_ap", "=", "mean_ap", "+", "ap", "\n", "task_results", "[", "classname", "]", "=", "ap", "\n", "\n", "plot_pr_curve", "(", "rec", ",", "prec", ",", "ap", ",", "classname", ",", "pr_dir", ")", "\n", "data_scores_overlap", "+=", "data_scores_overlap_per_cls", "\n", "\n", "# Save score to overlap tuples", "\n", "", "np", ".", "savetxt", "(", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"scores_overlap.csv\"", ")", ",", "\n", "X", "=", "data_scores_overlap", ",", "\n", "delimiter", "=", "\",\"", ",", "\n", "fmt", "=", "\"%s\"", ",", "\n", ")", "\n", "\n", "mean_ap", "=", "mean_ap", "/", "len", "(", "classnames", ")", "\n", "task_results", "[", "\"map\"", "]", "=", "mean_ap", "\n", "\n", "results", "[", "\"task1\"", "]", "=", "task_results", "\n", "\n", "logger", ".", "info", "(", "\"\\n\"", "+", "pformat", "(", "results", ")", ")", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "results", ",", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.pth\"", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"results.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "value", "in", "results", "[", "\"task1\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"{key: <18}: {value:2.4f}\\n\"", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.__init__": [[19, 39], ["torch.device", "logging.getLogger", "detectron2.data.MetadataCatalog.get"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "cfg", ",", "\n", "distributed", ",", "\n", "output_dir", ":", "str", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "_cfg", "=", "cfg", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "\n", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "\n", "# Collect predictions during proces(...) in this array", "\n", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.reset": [[40, 43], ["super().reset"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "return", "super", "(", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.process": [[44, 59], ["zip", "dafne_evaluator.DafneEvaluator._predictions.append", "output[].to"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.prepare_dota.polyiou.VectorDouble.append"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\n", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", ",", "\n", "\"file_name\"", ":", "input", "[", "\"file_name\"", "]", ",", "\n", "\"height\"", ":", "input", "[", "\"height\"", "]", ",", "\n", "\"width\"", ":", "input", "[", "\"width\"", "]", ",", "\n", "}", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"labels\"", "]", "=", "instances", ".", "pred_classes", "\n", "prediction", "[", "\"scores\"", "]", "=", "instances", ".", "scores", "\n", "prediction", "[", "\"corners\"", "]", "=", "instances", ".", "pred_corners", "\n", "prediction", "[", "\"centerness\"", "]", "=", "instances", ".", "centerness", "\n", "", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.dafne_evaluator.DafneEvaluator.evaluate": [[60, 85], ["collections.OrderedDict", "dafne_evaluator.DafneEvaluator._eval_predictions", "copy.deepcopy", "detectron2.utils.comm.synchronize", "detectron2.utils.comm.gather", "list", "len", "dafne_evaluator.DafneEvaluator._logger.warning", "fvcore.common.file_io.PathManager.mkdirs", "os.path.join", "itertools.chain", "detectron2.utils.comm.is_main_process", "fvcore.common.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.steven-lang_dafne.evaluation.icdar15_evaluation.Icdar15Evaluator._eval_predictions"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "{", "}", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[DafneEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "self", ".", "_eval_predictions", "(", "predictions", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "", "", ""]]}