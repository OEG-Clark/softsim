{"home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnv.__init__": [[48, 53], ["gym.Env.__init__"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "dataset_url", "=", "None", ",", "ref_max_score", "=", "None", ",", "ref_min_score", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OfflineEnv", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dataset_url", "=", "self", ".", "_dataset_url", "=", "dataset_url", "\n", "self", ".", "ref_max_score", "=", "ref_max_score", "\n", "self", ".", "ref_min_score", "=", "ref_min_score", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnv.get_normalized_score": [[54, 58], ["ValueError"], "methods", ["None"], ["", "def", "get_normalized_score", "(", "self", ",", "score", ")", ":", "\n", "        ", "if", "(", "self", ".", "ref_max_score", "is", "None", ")", "or", "(", "self", ".", "ref_min_score", "is", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Reference score not provided for env\"", ")", "\n", "", "return", "(", "score", "-", "self", ".", "ref_min_score", ")", "/", "(", "self", ".", "ref_max_score", "-", "self", ".", "ref_min_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnv.dataset_filepath": [[59, 62], ["offline_env.filepath_from_url"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.filepath_from_url"], ["", "@", "property", "\n", "def", "dataset_filepath", "(", "self", ")", ":", "\n", "        ", "return", "filepath_from_url", "(", "self", ".", "dataset_url", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnv.get_dataset": [[63, 89], ["h5py.File", "h5py.File.close", "offline_env.download_dataset_from_url", "str", "str", "ValueError", "offline_env.get_keys", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.download_dataset_from_url", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.get_offline_data.get_keys"], ["", "def", "get_dataset", "(", "self", ",", "h5path", "=", "None", ")", ":", "\n", "        ", "if", "h5path", "is", "None", ":", "\n", "            ", "if", "self", ".", "_dataset_url", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Offline env not configured with a dataset URL.\"", ")", "\n", "", "h5path", "=", "download_dataset_from_url", "(", "self", ".", "dataset_url", ")", "\n", "\n", "", "dataset_file", "=", "h5py", ".", "File", "(", "h5path", ",", "'r'", ")", "\n", "data_dict", "=", "{", "k", ":", "dataset_file", "[", "k", "]", "[", ":", "]", "for", "k", "in", "get_keys", "(", "dataset_file", ")", "}", "\n", "dataset_file", ".", "close", "(", ")", "\n", "\n", "# Run a few quick sanity checks", "\n", "for", "key", "in", "[", "'observations'", ",", "'actions'", ",", "'rewards'", ",", "'terminals'", "]", ":", "\n", "            ", "assert", "key", "in", "data_dict", ",", "'Dataset is missing key %s'", "%", "key", "\n", "", "N_samples", "=", "data_dict", "[", "'observations'", "]", ".", "shape", "[", "0", "]", "\n", "if", "self", ".", "observation_space", ".", "shape", "is", "not", "None", ":", "\n", "            ", "assert", "data_dict", "[", "'observations'", "]", ".", "shape", "[", "1", ":", "]", "==", "self", ".", "observation_space", ".", "shape", ",", "'Observation shape does not match env: %s vs %s'", "%", "(", "str", "(", "data_dict", "[", "'observations'", "]", ".", "shape", "[", "1", ":", "]", ")", ",", "str", "(", "self", ".", "observation_space", ".", "shape", ")", ")", "\n", "", "assert", "data_dict", "[", "'actions'", "]", ".", "shape", "[", "1", ":", "]", "==", "self", ".", "action_space", ".", "shape", ",", "'Action shape does not match env: %s vs %s'", "%", "(", "str", "(", "data_dict", "[", "'actions'", "]", ".", "shape", "[", "1", ":", "]", ")", ",", "str", "(", "self", ".", "action_space", ".", "shape", ")", ")", "\n", "if", "data_dict", "[", "'rewards'", "]", ".", "shape", "==", "(", "N_samples", ",", "1", ")", ":", "\n", "            ", "data_dict", "[", "'rewards'", "]", "=", "data_dict", "[", "'rewards'", "]", "[", ":", ",", "0", "]", "\n", "", "assert", "data_dict", "[", "'rewards'", "]", ".", "shape", "==", "(", "N_samples", ",", ")", ",", "'Reward has wrong shape: %s'", "%", "(", "str", "(", "data_dict", "[", "'rewards'", "]", ".", "shape", ")", ")", "\n", "if", "data_dict", "[", "'terminals'", "]", ".", "shape", "==", "(", "N_samples", ",", "1", ")", ":", "\n", "            ", "data_dict", "[", "'terminals'", "]", "=", "data_dict", "[", "'terminals'", "]", "[", ":", ",", "0", "]", "\n", "", "assert", "data_dict", "[", "'terminals'", "]", ".", "shape", "==", "(", "N_samples", ",", ")", ",", "'Terminals has wrong shape: %s'", "%", "(", "str", "(", "data_dict", "[", "'rewards'", "]", ".", "shape", ")", ")", "\n", "return", "data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnv.get_dataset_chunk": [[91, 118], ["h5py.File", "h5py.File.close", "offline_env.download_dataset_from_url", "h5py.File.keys", "ValueError", "int", "ValueError", "ValueError", "list", "dataset_file[].keys", "str"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.download_dataset_from_url"], ["", "def", "get_dataset_chunk", "(", "self", ",", "chunk_id", ",", "h5path", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns a slice of the full dataset.\n\n        Args:\n            chunk_id (int): An integer representing which slice of the dataset to return.\n\n        Returns:\n            A dictionary containing observtions, actions, rewards, and terminals.\n        \"\"\"", "\n", "if", "h5path", "is", "None", ":", "\n", "            ", "if", "self", ".", "_dataset_url", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Offline env not configured with a dataset URL.\"", ")", "\n", "", "h5path", "=", "download_dataset_from_url", "(", "self", ".", "dataset_url", ")", "\n", "\n", "", "dataset_file", "=", "h5py", ".", "File", "(", "h5path", ",", "'r'", ")", "\n", "\n", "if", "'virtual'", "not", "in", "dataset_file", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Dataset is not a chunked dataset'", ")", "\n", "", "available_chunks", "=", "[", "int", "(", "_chunk", ")", "for", "_chunk", "in", "list", "(", "dataset_file", "[", "'virtual'", "]", ".", "keys", "(", ")", ")", "]", "\n", "if", "chunk_id", "not", "in", "available_chunks", ":", "\n", "            ", "raise", "ValueError", "(", "'Chunk id not found: %d. Available chunks: %s'", "%", "(", "chunk_id", ",", "str", "(", "available_chunks", ")", ")", ")", "\n", "\n", "", "load_keys", "=", "[", "'observations'", ",", "'actions'", ",", "'rewards'", ",", "'terminals'", "]", "\n", "data_dict", "=", "{", "k", ":", "dataset_file", "[", "'virtual/%d/%s'", "%", "(", "chunk_id", ",", "k", ")", "]", "[", ":", "]", "for", "k", "in", "load_keys", "}", "\n", "dataset_file", ".", "close", "(", ")", "\n", "return", "data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnvWrapper.__init__": [[124, 127], ["gym.Wrapper.__init__", "offline_env.OfflineEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "**", "kwargs", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "OfflineEnv", ".", "__init__", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnvWrapper.reset": [[128, 130], ["offline_env.OfflineEnvWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnvWrapper.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.set_dataset_path": [[6, 10], ["os.makedirs"], "function", ["None"], ["def", "set_dataset_path", "(", "path", ")", ":", "\n", "    ", "global", "DATASET_PATH", "\n", "DATASET_PATH", "=", "path", "\n", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.get_keys": [[13, 20], ["h5file.visititems", "isinstance", "keys.append"], "function", ["None"], ["def", "get_keys", "(", "h5file", ")", ":", "\n", "    ", "keys", "=", "[", "]", "\n", "def", "visitor", "(", "name", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "h5py", ".", "Dataset", ")", ":", "\n", "            ", "keys", ".", "append", "(", "name", ")", "\n", "", "", "h5file", ".", "visititems", "(", "visitor", ")", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.filepath_from_url": [[22, 26], ["os.path.split", "os.path.join"], "function", ["None"], ["", "def", "filepath_from_url", "(", "dataset_url", ")", ":", "\n", "    ", "_", ",", "dataset_name", "=", "os", ".", "path", ".", "split", "(", "dataset_url", ")", "\n", "dataset_filepath", "=", "os", ".", "path", ".", "join", "(", "DATASET_PATH", ",", "dataset_name", ")", "\n", "return", "dataset_filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.download_dataset_from_url": [[28, 36], ["offline_env.filepath_from_url", "os.path.exists", "print", "urllib.request.urlretrieve", "os.path.exists", "IOError"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.filepath_from_url"], ["", "def", "download_dataset_from_url", "(", "dataset_url", ")", ":", "\n", "    ", "dataset_filepath", "=", "filepath_from_url", "(", "dataset_url", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_filepath", ")", ":", "\n", "        ", "print", "(", "'Downloading dataset:'", ",", "dataset_url", ",", "'to'", ",", "dataset_filepath", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "dataset_url", ",", "dataset_filepath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_filepath", ")", ":", "\n", "        ", "raise", "IOError", "(", "\"Failed to download dataset from %s\"", "%", "dataset_url", ")", "\n", "", "return", "dataset_filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.get_offline_data.get_keys": [[18, 27], ["h5file.visititems", "isinstance", "keys.append"], "function", ["None"], ["def", "get_keys", "(", "h5file", ")", ":", "\n", "  ", "keys", "=", "[", "]", "\n", "\n", "def", "visitor", "(", "name", ",", "item", ")", ":", "\n", "    ", "if", "isinstance", "(", "item", ",", "h5py", ".", "Dataset", ")", ":", "\n", "      ", "keys", ".", "append", "(", "name", ")", "\n", "\n", "", "", "h5file", ".", "visititems", "(", "visitor", ")", "\n", "return", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.get_offline_data.get_data_env_d4rl": [[29, 135], ["h5py.File", "get_offline_data.get_keys", "h5py.File.close", "len", "numpy.squeeze", "numpy.squeeze", "numpy.where", "absl.logging.info", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "scripts.dataset.Transition_model_free", "dataset.Dataset.add_transitions", "numpy.random.RandomState", "scripts.utils.shuffle_indices_with_steps", "dataset.Dataset.create_view", "print", "numpy.logical_and", "numpy.max", "numpy.min", "scripts.dataset.PrioritizedReplayBuffer", "scripts.dataset.Dataset", "numpy.logical_not", "numpy.mean", "len", "numpy.arange", "len", "numpy.std"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.get_offline_data.get_keys", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.add_transitions", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.shuffle_indices_with_steps", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.create_view"], ["", "def", "get_data_env_d4rl", "(", "gym_env", ",", "file_name", ",", "identifier", "=", "'model_free'", ",", "num_transitions", "=", "-", "1", ",", "\n", "normalize_states", "=", "False", ",", "scale_rewards", "=", "False", ",", "per", "=", "False", ")", ":", "\n", "  ", "\"\"\"get transitions\"\"\"", "\n", "s_dim", ",", "a_dim", "=", "gym_env", "\n", "\n", "dataset_file", "=", "h5py", ".", "File", "(", "file_name", ",", "'r'", ")", "\n", "# offline_dataset = {k: dataset_file[k][:] for k in get_keys(dataset_file)}", "\n", "data_dict", "=", "{", "}", "\n", "for", "k", "in", "get_keys", "(", "dataset_file", ")", ":", "\n", "    ", "try", ":", "\n", "# first try loading as an array", "\n", "      ", "data_dict", "[", "k", "]", "=", "dataset_file", "[", "k", "]", "[", ":", "]", "\n", "", "except", "ValueError", "as", "e", ":", "# try loading as a scalar", "\n", "      ", "data_dict", "[", "k", "]", "=", "dataset_file", "[", "k", "]", "[", "(", ")", "]", "\n", "", "", "dataset_file", ".", "close", "(", ")", "\n", "offline_dataset", "=", "data_dict", "\n", "\n", "dataset_size", "=", "len", "(", "offline_dataset", "[", "'observations'", "]", ")", "\n", "observation_dtype", "=", "tf", ".", "float32", "# gym_env.observation_space.dtype", "\n", "action_dtype", "=", "tf", ".", "float32", "# gym_env.action_space.dtype", "\n", "\n", "offline_dataset", "[", "'terminals'", "]", "=", "np", ".", "squeeze", "(", "offline_dataset", "[", "'terminals'", "]", ")", "\n", "offline_dataset", "[", "'rewards'", "]", "=", "np", ".", "squeeze", "(", "offline_dataset", "[", "'rewards'", "]", ")", "\n", "\n", "nonterminal_steps", ",", "=", "np", ".", "where", "(", "\n", "np", ".", "logical_and", "(", "\n", "np", ".", "logical_not", "(", "offline_dataset", "[", "'terminals'", "]", ")", ",", "\n", "np", ".", "arange", "(", "dataset_size", ")", "<", "dataset_size", "-", "1", ")", ")", "\n", "logging", ".", "info", "(", "'Found %d non-terminal steps out of a total of %d steps.'", "%", "(", "\n", "len", "(", "nonterminal_steps", ")", ",", "dataset_size", ")", ")", "\n", "\n", "demo_s1", "=", "offline_dataset", "[", "'observations'", "]", "[", "nonterminal_steps", "]", "\n", "demo_s2", "=", "offline_dataset", "[", "'observations'", "]", "[", "nonterminal_steps", "+", "1", "]", "\n", "demo_a1", "=", "offline_dataset", "[", "'actions'", "]", "[", "nonterminal_steps", "]", "\n", "demo_a2", "=", "offline_dataset", "[", "'actions'", "]", "[", "nonterminal_steps", "+", "1", "]", "\n", "demo_r", "=", "offline_dataset", "[", "'rewards'", "]", "[", "nonterminal_steps", "]", "\n", "demo_d", "=", "offline_dataset", "[", "'terminals'", "]", "[", "nonterminal_steps", "+", "1", "]", "\n", "\n", "if", "num_transitions", "!=", "-", "1", ":", "\n", "    ", "demo_s1", "=", "demo_s1", "[", ":", "num_transitions", "]", "\n", "demo_s2", "=", "demo_s2", "[", ":", "num_transitions", "]", "\n", "demo_a1", "=", "demo_a1", "[", ":", "num_transitions", "]", "\n", "demo_a2", "=", "demo_a2", "[", ":", "num_transitions", "]", "\n", "demo_r", "=", "demo_r", "[", ":", "num_transitions", "]", "\n", "demo_d", "=", "demo_d", "[", ":", "num_transitions", "]", "\n", "\n", "# (demo_s1, demo_a1, demo_s2, demo_a2, demo_r, demo_d,", "\n", "#  traj_sum_rewards) = utils.subsample_trajectories(demo_s1,", "\n", "#                                                   demo_a1,", "\n", "#                                                   demo_s2,", "\n", "#                                                   demo_a2,", "\n", "#                                                   demo_r,", "\n", "#                                                   demo_d,", "\n", "#                                                   num_trajectories=None,", "\n", "#                                                   rank_identifier='origin')", "\n", "\n", "", "dataset_size", "=", "demo_s1", ".", "shape", "[", "0", "]", "\n", "# traj_mean_rewards = np.mean(traj_sum_rewards)", "\n", "# print('{} demonstraions, mean reward is {}'.format(dataset_size, traj_mean_rewards))", "\n", "\n", "if", "normalize_states", ":", "\n", "    ", "shift", "=", "-", "np", ".", "mean", "(", "demo_s1", ",", "0", ")", "\n", "scale", "=", "1.0", "/", "(", "np", ".", "std", "(", "demo_s1", ",", "0", ")", "+", "1e-3", ")", "\n", "demo_s1", "=", "(", "demo_s1", "+", "shift", ")", "*", "scale", "\n", "demo_s2", "=", "(", "demo_s2", "+", "shift", ")", "*", "scale", "\n", "", "else", ":", "\n", "    ", "shift", "=", "None", "\n", "scale", "=", "None", "\n", "\n", "", "if", "scale_rewards", ":", "\n", "    ", "r_max", "=", "np", ".", "max", "(", "demo_r", ")", "\n", "r_min", "=", "np", ".", "min", "(", "demo_r", ")", "\n", "demo_r", "=", "(", "demo_r", "-", "r_min", ")", "/", "(", "r_max", "-", "r_min", ")", "\n", "\n", "", "if", "per", ":", "\n", "    ", "demo_dataset", "=", "dataset", ".", "PrioritizedReplayBuffer", "(", "\n", "s_dim", ",", "\n", "a_dim", ",", "\n", "identifier", "=", "identifier", ",", "\n", "size", "=", "dataset_size", ")", "\n", "", "else", ":", "\n", "    ", "demo_dataset", "=", "dataset", ".", "Dataset", "(", "\n", "s_dim", ",", "\n", "a_dim", ",", "\n", "identifier", "=", "identifier", ",", "\n", "size", "=", "dataset_size", ")", "\n", "\n", "", "demo_s1", "=", "tf", ".", "convert_to_tensor", "(", "demo_s1", ",", "dtype", "=", "observation_dtype", ")", "\n", "demo_s2", "=", "tf", ".", "convert_to_tensor", "(", "demo_s2", ",", "dtype", "=", "observation_dtype", ")", "\n", "demo_a1", "=", "tf", ".", "convert_to_tensor", "(", "demo_a1", ",", "dtype", "=", "action_dtype", ")", "\n", "demo_a2", "=", "tf", ".", "convert_to_tensor", "(", "demo_a2", ",", "dtype", "=", "action_dtype", ")", "\n", "demo_r", "=", "tf", ".", "convert_to_tensor", "(", "demo_r", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "demo_d", "=", "tf", ".", "convert_to_tensor", "(", "1.", "-", "demo_d", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "transitions", "=", "dataset", ".", "Transition_model_free", "(", "demo_s1", ",", "demo_s2", ",", "demo_a1", ",", "demo_a2", ",", "demo_d", ",", "demo_r", ")", "\n", "\n", "demo_dataset", ".", "add_transitions", "(", "transitions", ")", "\n", "\n", "# Split data.", "\n", "rand", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "indices", "=", "utils", ".", "shuffle_indices_with_steps", "(", "\n", "n", "=", "demo_dataset", ".", "size", ",", "steps", "=", "0", ",", "rand", "=", "rand", ")", "\n", "train_data", "=", "demo_dataset", ".", "create_view", "(", "indices", ")", "\n", "print", "(", "'n_train is %d'", "%", "(", "len", "(", "indices", ")", ")", ")", "\n", "\n", "return", "train_data", ",", "shift", ",", "scale", "\n", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.__init__": [[34, 67], ["agent.Agent._build_agent"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_agent"], ["def", "__init__", "(", "\n", "self", ",", "\n", "observation_spec", "=", "None", ",", "\n", "action_spec", "=", "None", ",", "\n", "time_step_spec", "=", "None", ",", "\n", "modules", "=", "None", ",", "\n", "optimizers", "=", "(", "(", "'adam'", ",", "0.001", ")", ",", ")", ",", "\n", "batch_size", "=", "64", ",", "\n", "weight_decays", "=", "(", "0.0", ",", ")", ",", "\n", "update_freq", "=", "1", ",", "\n", "update_rate", "=", "0.005", ",", "\n", "discount", "=", "0.99", ",", "\n", "train_data", "=", "None", ",", "\n", "# model-based", "\n", "fic_dataset", "=", "None", ",", "\n", "static_fns", "=", "None", ",", "\n", ")", ":", "\n", "    ", "self", ".", "_observation_spec", "=", "observation_spec", "\n", "self", ".", "_action_spec", "=", "action_spec", "\n", "self", ".", "_a_max", "=", "action_spec", ".", "maximum", "\n", "self", ".", "_a_dim", "=", "action_spec", ".", "shape", "[", "0", "]", "\n", "self", ".", "_time_step_spec", "=", "time_step_spec", "\n", "self", ".", "_modules", "=", "modules", "\n", "self", ".", "_optimizers", "=", "optimizers", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_weight_decays", "=", "weight_decays", "\n", "self", ".", "_train_data", "=", "train_data", "\n", "self", ".", "_update_freq", "=", "update_freq", "\n", "self", ".", "_update_rate", "=", "update_rate", "\n", "self", ".", "_discount", "=", "discount", "\n", "self", ".", "_fic_dataset", "=", "fic_dataset", "\n", "self", ".", "_static_fns", "=", "static_fns", "\n", "self", ".", "_build_agent", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_agent": [[68, 80], ["agent.Agent._build_fns", "agent.Agent._build_optimizers", "tensorflow.Variable", "collections.OrderedDict", "agent.Agent._build_checkpointer", "collections.OrderedDict", "agent.Agent._build_test_policies", "agent.Agent._build_online_policy", "agent.Agent._get_train_batch", "agent.Agent._init_vars"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_fns", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_optimizers", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_checkpointer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_test_policies", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_online_policy", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_vars"], ["", "def", "_build_agent", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds agent components.\"\"\"", "\n", "self", ".", "_build_fns", "(", ")", "\n", "self", ".", "_build_optimizers", "(", ")", "\n", "self", ".", "_global_step", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "self", ".", "_train_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_checkpointer", "=", "self", ".", "_build_checkpointer", "(", ")", "\n", "self", ".", "_test_policies", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_build_test_policies", "(", ")", "\n", "self", ".", "_online_policy", "=", "self", ".", "_build_online_policy", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "self", ".", "_init_vars", "(", "train_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_fns": [[81, 83], ["agent.AgentModule"], "methods", ["None"], ["", "def", "_build_fns", "(", "self", ")", ":", "\n", "    ", "self", ".", "_agent_module", "=", "AgentModule", "(", "modules", "=", "self", ".", "_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_vars": [[84, 86], ["None"], "methods", ["None"], ["", "def", "_get_vars", "(", "self", ")", ":", "\n", "    ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_optimizers": [[87, 91], ["scripts.utils.get_optimizer", "scripts.utils.get_optimizer."], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer"], ["", "def", "_build_optimizers", "(", "self", ")", ":", "\n", "    ", "opt", "=", "self", ".", "_optimizers", "[", "0", "]", "\n", "opt_fn", "=", "utils", ".", "get_optimizer", "(", "opt", "[", "0", "]", ")", "\n", "self", ".", "_optimizer", "=", "opt_fn", "(", "lr", "=", "opt", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_loss": [[92, 94], ["None"], "methods", ["None"], ["", "def", "_build_loss", "(", "self", ",", "batch", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_checkpointer": [[95, 99], ["tensorflow.train.Checkpoint"], "methods", ["None"], ["", "def", "_build_checkpointer", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "self", ".", "_agent_module", ",", "\n", "global_step", "=", "self", ".", "_global_step", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_test_policies": [[101, 103], ["None"], "methods", ["None"], ["", "def", "_build_test_policies", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "# raise NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_online_policy": [[105, 107], ["None"], "methods", ["None"], ["", "def", "_build_online_policy", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.test_policies": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_policies", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_test_policies", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.online_policy": [[112, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "online_policy", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_online_policy", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch": [[116, 130], ["numpy.random.choice", "agent.Agent._train_data.get_batch", "dict"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch"], ["", "def", "_get_train_batch", "(", "self", ",", ")", ":", "\n", "    ", "\"\"\"Samples and constructs batch of transitions.\"\"\"", "\n", "batch_indices", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "_train_data", ".", "size", ",", "self", ".", "_batch_size", ")", "\n", "batch_", "=", "self", ".", "_train_data", ".", "get_batch", "(", "batch_indices", ")", "\n", "transition_batch", "=", "batch_", "\n", "batch", "=", "dict", "(", "\n", "s1", "=", "transition_batch", ".", "s1", ",", "\n", "s2", "=", "transition_batch", ".", "s2", ",", "\n", "r", "=", "transition_batch", ".", "reward", ",", "\n", "dsc", "=", "transition_batch", ".", "discount", ",", "\n", "a1", "=", "transition_batch", ".", "a1", ",", "\n", "a2", "=", "transition_batch", ".", "a2", ",", "\n", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch": [[131, 143], ["agent.Agent._train_data.get_batch", "dict"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch"], ["", "def", "_get_batch", "(", "self", ",", "batch_indices", ")", ":", "\n", "    ", "batch_", "=", "self", ".", "_train_data", ".", "get_batch", "(", "batch_indices", ")", "\n", "transition_batch", "=", "batch_", "\n", "batch", "=", "dict", "(", "\n", "s1", "=", "transition_batch", ".", "s1", ",", "\n", "s2", "=", "transition_batch", ".", "s2", ",", "\n", "r", "=", "transition_batch", ".", "reward", ",", "\n", "dsc", "=", "transition_batch", ".", "discount", ",", "\n", "a1", "=", "transition_batch", ".", "a1", ",", "\n", "a2", "=", "transition_batch", ".", "a2", ",", "\n", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._optimize_step": [[144, 152], ["agent.Agent._get_vars", "tape.gradient", "tuple", "agent.Agent._optimizer.apply_gradients", "tensorflow.GradientTape", "agent.Agent._build_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._build_loss"], ["", "def", "_optimize_step", "(", "self", ",", "batch", ")", ":", "\n", "    ", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "      ", "loss", ",", "info", "=", "self", ".", "_build_loss", "(", "batch", ")", "\n", "", "trainable_vars", "=", "self", ".", "_get_vars", "(", ")", "\n", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "trainable_vars", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "trainable_vars", ")", ")", "\n", "self", ".", "_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.train_step": [[153, 159], ["agent.Agent._get_train_batch", "agent.Agent._optimize_step", "agent.Agent.items", "agent.Agent._global_step.assign_add", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_step"], ["", "def", "train_step", "(", "self", ")", ":", "\n", "    ", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_step", "(", "train_batch", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "_train_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "self", ".", "_global_step", ".", "assign_add", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._init_vars": [[160, 162], ["None"], "methods", ["None"], ["", "def", "_init_vars", "(", "self", ",", "batch", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_source_target_vars": [[163, 165], ["None"], "methods", ["None"], ["", "def", "_get_source_target_vars", "(", "self", ")", ":", "\n", "    ", "return", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._update_target_fns": [[166, 171], ["scripts.utils.soft_variables_update"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.soft_variables_update"], ["", "def", "_update_target_fns", "(", "self", ",", "source_vars", ",", "target_vars", ")", ":", "\n", "    ", "utils", ".", "soft_variables_update", "(", "\n", "source_vars", ",", "\n", "target_vars", ",", "\n", "tau", "=", "self", ".", "_update_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.print_train_info": [[172, 177], ["agent.Agent._global_step.numpy", "scripts.utils.get_summary_str", "absl.logging.info"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str"], ["", "def", "print_train_info", "(", "self", ")", ":", "\n", "    ", "info", "=", "self", ".", "_train_info", "\n", "step", "=", "self", ".", "_global_step", ".", "numpy", "(", ")", "\n", "summary_str", "=", "utils", ".", "get_summary_str", "(", "step", ",", "info", ")", "\n", "logging", ".", "info", "(", "summary_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.write_train_summary": [[178, 182], ["agent.Agent._global_step.numpy", "scripts.utils.write_summary"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_train_summary", "(", "self", ",", "summary_writer", ")", ":", "\n", "    ", "info", "=", "self", ".", "_train_info", "\n", "step", "=", "self", ".", "_global_step", ".", "numpy", "(", ")", "\n", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.save": [[183, 185], ["agent.Agent._checkpointer.write"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "ckpt_name", ")", ":", "\n", "    ", "self", ".", "_checkpointer", ".", "write", "(", "ckpt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore": [[186, 188], ["agent.Agent._checkpointer.restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore", "(", "self", ",", "ckpt_name", ")", ":", "\n", "    ", "self", ".", "_checkpointer", ".", "restore", "(", "ckpt_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.global_step": [[189, 192], ["agent.Agent._global_step.numpy"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_step", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_global_step", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.AgentModule.__init__": [[197, 204], ["tensorflow.Module.__init__", "agent.AgentModule._build_modules"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule._build_modules"], ["def", "__init__", "(", "\n", "self", ",", "\n", "modules", "=", "None", ",", "\n", ")", ":", "\n", "    ", "super", "(", "AgentModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_modules", "=", "modules", "\n", "self", ".", "_build_modules", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.AgentModule._build_modules": [[205, 207], ["None"], "methods", ["None"], ["", "def", "_build_modules", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Config.__init__": [[212, 215], ["agent.Config._get_agent_args"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Config._get_agent_args"], ["def", "__init__", "(", "self", ",", "agent_flags", ")", ":", "\n", "    ", "self", ".", "_agent_flags", "=", "agent_flags", "\n", "self", ".", "_agent_args", "=", "self", ".", "_get_agent_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Config._get_agent_args": [[216, 231], ["scripts.utils.Flags", "agent.Config._get_modules"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Config._get_modules"], ["", "def", "_get_agent_args", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets agent parameters associated with config.\"\"\"", "\n", "agent_flags", "=", "self", ".", "_agent_flags", "\n", "agent_args", "=", "utils", ".", "Flags", "(", "\n", "action_spec", "=", "agent_flags", ".", "action_spec", ",", "\n", "optimizers", "=", "agent_flags", ".", "optimizers", ",", "\n", "batch_size", "=", "agent_flags", ".", "batch_size", ",", "\n", "weight_decays", "=", "agent_flags", ".", "weight_decays", ",", "\n", "update_rate", "=", "agent_flags", ".", "update_rate", ",", "\n", "update_freq", "=", "agent_flags", ".", "update_freq", ",", "\n", "discount", "=", "agent_flags", ".", "discount", ",", "\n", "train_data", "=", "agent_flags", ".", "train_data", ",", "\n", ")", "\n", "agent_args", ".", "modules", "=", "self", ".", "_get_modules", "(", ")", "\n", "return", "agent_args", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Config._get_modules": [[232, 234], ["None"], "methods", ["None"], ["", "def", "_get_modules", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Config.agent_args": [[235, 238], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "agent_args", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_agent_args", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.train_offline.main": [[69, 139], ["absl.logging.set_verbosity", "gin.parse_config_files_and_bindings", "os.path.join", "scripts.path.abs_file_path", "os.path.join", "os.path.join", "scripts.utils.maybe_makedirs", "scripts.utils.maybe_makedirs", "os.path.join", "scripts.utils.get_datetime", "str", "ValueError", "rl_planning.train_eval_planning.train_eval_planning", "ValueError", "tensorflow.io.gfile.GFile", "numpy.save", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.path.abs_file_path", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.maybe_makedirs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.maybe_makedirs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_datetime", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.train_eval_planning.train_eval_planning", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.save"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "logging", ".", "INFO", ")", "\n", "gin", ".", "parse_config_files_and_bindings", "(", "FLAGS", ".", "gin_file", ",", "FLAGS", ".", "gin_bindings", ")", "\n", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "FLAGS", ".", "data_root_dir", ",", "\n", "FLAGS", ".", "benchmark_name", ",", "\n", "FLAGS", ".", "data_file_source", ",", "\n", "FLAGS", ".", "data_file_name", ",", "\n", ")", "\n", "\n", "data_file", "=", "path", ".", "abs_file_path", "(", "__file__", ",", "data_dir", ")", "\n", "\n", "# Setup summary_log dir & model_save dir.", "\n", "if", "FLAGS", ".", "sub_dir", "==", "'auto'", ":", "\n", "    ", "sub_dir", "=", "utils", ".", "get_datetime", "(", ")", "\n", "", "else", ":", "\n", "    ", "sub_dir", "=", "FLAGS", ".", "sub_dir", "\n", "", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "FLAGS", ".", "root_dir", ",", "\n", "FLAGS", ".", "env_name", ",", "\n", "FLAGS", ".", "data_file_source", "+", "'_'", "+", "FLAGS", ".", "data_file_name", ",", "\n", "str", "(", "FLAGS", ".", "num_transitions", ")", "+", "'_'", "+", "str", "(", "FLAGS", ".", "state_normalize", ")", ",", "\n", "FLAGS", ".", "agent_name", ",", "\n", "sub_dir", ",", "\n", "str", "(", "FLAGS", ".", "seed", ")", ",", "\n", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "'learn_model'", ",", "\n", "FLAGS", ".", "env_name", ",", "\n", "FLAGS", ".", "data_file_name", ",", "\n", "str", "(", "FLAGS", ".", "num_transitions", ")", "+", "'_'", "+", "str", "(", "FLAGS", ".", "state_normalize", ")", ",", "\n", ")", "\n", "utils", ".", "maybe_makedirs", "(", "log_dir", ")", "\n", "utils", ".", "maybe_makedirs", "(", "model_dir", ")", "\n", "\n", "if", "FLAGS", ".", "identifier", "==", "'planning'", ":", "\n", "# behavior, dynamic; b_out_ranks; d_out_ranks", "\n", "    ", "model_arch", "=", "(", "(", "(", "(", "300", ",", "300", ")", ",", "(", "300", ",", "100", ")", ")", ",", "\n", "(", "(", "300", ",", "300", ")", ",", "(", "300", ",", "100", ")", ")", ")", ",", "None", ",", "None", ")", "\n", "opt_params", "=", "(", "(", "'adam'", ",", "1e-3", ")", ",", "(", "'adam'", ",", "1e-3", ")", ",", "(", "'adam'", ",", "1e-3", ")", ",", "(", "'adam'", ",", "1e-3", ")", ",", "(", "'adam'", ",", "1e-3", ")", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Wrong identifier!\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "identifier", "==", "'planning'", ":", "\n", "    ", "eval_results", "=", "train_eval_planning", ".", "train_eval_planning", "(", "\n", "log_dir", "=", "log_dir", ",", "\n", "model_dir", "=", "model_dir", ",", "\n", "benchmark_name", "=", "FLAGS", ".", "benchmark_name", ",", "\n", "data_file_source", "=", "FLAGS", ".", "data_file_source", ",", "\n", "data_file", "=", "data_file", ",", "\n", "agent_module", "=", "agents", ".", "AGENT_MODULES_DICT", "[", "FLAGS", ".", "agent_name", "]", ",", "\n", "env_name", "=", "FLAGS", ".", "env_name", ",", "\n", "total_train_steps", "=", "FLAGS", ".", "total_train_steps", ",", "\n", "n_eval_episodes", "=", "FLAGS", ".", "n_eval_episodes", ",", "\n", "optimizers", "=", "opt_params", ",", "\n", "num_transitions", "=", "FLAGS", ".", "num_transitions", ",", "\n", "behavior_ckpt_name", "=", "FLAGS", ".", "b_ckpt", "[", "0", "]", ",", "\n", "dynamics_ckpt_name", "=", "FLAGS", ".", "f_ckpt", ",", "\n", "reward_normalize", "=", "FLAGS", ".", "reward_normalize", ",", "\n", "state_normalize", "=", "FLAGS", ".", "state_normalize", ",", "\n", "score_normalize", "=", "FLAGS", ".", "score_normalize", ",", "\n", "evaluate", "=", "FLAGS", ".", "env_evaluate", ",", "\n", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Wrong identifier!\"", ")", "\n", "\n", "", "results_file", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'results_reward.npy'", ")", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "results_file", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "np", ".", "save", "(", "f", ",", "eval_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.TD3ActorNetwork.__init__": [[46, 67], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.TD3ActorNetwork._layers.append", "networks.get_spec_means_mags", "tensorflow.keras.layers.Dense", "networks.TD3ActorNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "TD3ActorNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_action_spec", "=", "action_spec", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_action_spec", ".", "shape", "[", "0", "]", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_action_means", ",", "self", ".", "_action_mags", "=", "get_spec_means_mags", "(", "\n", "self", ".", "_action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.TD3ActorNetwork.action_spec": [[68, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.TD3ActorNetwork._get_outputs": [[72, 78], ["l", "tensorflow.tanh"], "methods", ["None"], ["", "def", "_get_outputs", "(", "self", ",", "state", ")", ":", "\n", "    ", "h", "=", "state", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "a_tanh", "=", "tf", ".", "tanh", "(", "h", ")", "*", "self", ".", "_action_mags", "+", "self", ".", "_action_means", "\n", "return", "a_tanh", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.TD3ActorNetwork.weights": [[79, 85], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.TD3ActorNetwork.__call__": [[86, 89], ["networks.TD3ActorNetwork._get_outputs"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "__call__", "(", "self", ",", "state", ")", ":", "\n", "#state = tf.cast(state, dtype=tf.float64)", "\n", "    ", "return", "self", ".", "_get_outputs", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.__init__": [[94, 115], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.ActorNetwork._layers.append", "networks.get_spec_means_mags", "tensorflow.keras.layers.Dense", "networks.ActorNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "ActorNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_action_spec", "=", "action_spec", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_action_spec", ".", "shape", "[", "0", "]", "*", "2", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_action_means", ",", "self", ".", "_action_mags", "=", "get_spec_means_mags", "(", "\n", "self", ".", "_action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.action_spec": [[116, 119], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork._get_outputs": [[120, 140], ["tensorflow.split", "tensorflow.tanh", "tensorflow.exp", "tfd.TransformedDistribution", "l", "tensorflow.tanh", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow_probability.bijectors.AffineScalar", "tensorflow_probability.bijectors.Tanh", "tensorflow_probability.bijectors.AffineScalar"], "methods", ["None"], ["", "def", "_get_outputs", "(", "self", ",", "state", ")", ":", "\n", "    ", "h", "=", "state", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "a_tanh_mode", "=", "tf", ".", "tanh", "(", "mean", ")", "*", "self", ".", "_action_mags", "+", "self", ".", "_action_means", "\n", "log_std", "=", "tf", ".", "tanh", "(", "log_std", ")", "\n", "log_std", "=", "LOG_STD_MIN", "+", "0.5", "*", "(", "LOG_STD_MAX", "-", "LOG_STD_MIN", ")", "*", "(", "log_std", "+", "1", ")", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "a_distribution", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "[", "\n", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "self", ".", "_action_means", ",", "\n", "scale", "=", "self", ".", "_action_mags", ")", ",", "\n", "tfp", ".", "bijectors", ".", "Tanh", "(", ")", ",", "\n", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "mean", ",", "scale", "=", "std", ")", ",", "\n", "]", ")", ",", "\n", "event_shape", "=", "[", "mean", ".", "shape", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "mean", ".", "shape", "[", "0", "]", "]", ")", "\n", "return", "a_distribution", ",", "a_tanh_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.get_log_density": [[141, 145], ["networks.ActorNetwork._get_outputs", "a_dist.log_prob"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "get_log_density", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "    ", "a_dist", ",", "_", "=", "self", ".", "_get_outputs", "(", "state", ")", "\n", "log_density", "=", "a_dist", ".", "log_prob", "(", "action", ")", "\n", "return", "log_density", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.weights": [[146, 152], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.__call__": [[153, 159], ["networks.ActorNetwork._get_outputs", "a_dist.sample", "a_dist.log_prob"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "__call__", "(", "self", ",", "state", ")", ":", "\n", "#state = tf.cast(state, dtype=tf.float64)", "\n", "    ", "a_dist", ",", "a_tanh_mode", "=", "self", ".", "_get_outputs", "(", "state", ")", "\n", "a_sample", "=", "a_dist", ".", "sample", "(", ")", "\n", "log_pi_a", "=", "a_dist", ".", "log_prob", "(", "a_sample", ")", "\n", "return", "a_tanh_mode", ",", "a_sample", ",", "log_pi_a", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.call_dist": [[160, 165], ["networks.ActorNetwork._get_outputs", "a_dist.sample", "a_dist.log_prob"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "call_dist", "(", "self", ",", "state", ")", ":", "\n", "    ", "a_dist", ",", "a_tanh_mode", "=", "self", ".", "_get_outputs", "(", "state", ")", "\n", "a_sample", "=", "a_dist", ".", "sample", "(", ")", "\n", "log_pi_a", "=", "a_dist", ".", "log_prob", "(", "a_sample", ")", "\n", "return", "a_tanh_mode", ",", "a_sample", ",", "log_pi_a", ",", "a_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.sample_n": [[166, 171], ["networks.ActorNetwork._get_outputs", "a_dist.sample", "a_dist.log_prob"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "sample_n", "(", "self", ",", "state", ",", "n", "=", "1", ")", ":", "\n", "    ", "a_dist", ",", "a_tanh_mode", "=", "self", ".", "_get_outputs", "(", "state", ")", "\n", "a_sample", "=", "a_dist", ".", "sample", "(", "n", ")", "\n", "log_pi_a", "=", "a_dist", ".", "log_prob", "(", "a_sample", ")", "\n", "return", "a_tanh_mode", ",", "a_sample", ",", "log_pi_a", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.sample": [[172, 174], ["networks.ActorNetwork.sample_n"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample_n"], ["", "def", "sample", "(", "self", ",", "state", ")", ":", "\n", "    ", "return", "self", ".", "sample_n", "(", "state", ",", "n", "=", "1", ")", "[", "1", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.CriticNetwork.__init__": [[179, 196], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.CriticNetwork._layers.append", "tensorflow.keras.layers.Dense", "networks.CriticNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "CriticNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "1", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.CriticNetwork.__call__": [[197, 204], ["tensorflow.concat", "tensorflow.reshape", "l"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "# state = tf.cast(state, dtype=tf.float64)", "\n", "# action = tf.cast(action, dtype=tf.float64)", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "tf", ".", "reshape", "(", "h", ",", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.CriticNetwork.weights": [[205, 211], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.EnsembleCriticNetwork.__init__": [[216, 235], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.EnsembleCriticNetwork._layers.append", "tensorflow.keras.layers.Dense", "networks.EnsembleCriticNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", "num_heads", "=", "2", ",", "\n", ")", ":", "\n", "    ", "super", "(", "EnsembleCriticNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "num_heads", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_num_heads", "=", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.EnsembleCriticNetwork.__call__": [[236, 243], ["tensorflow.concat", "l"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "# state = tf.cast(state, dtype=tf.float64)", "\n", "# action = tf.cast(action, dtype=tf.float64)", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.EnsembleCriticNetwork.get_q": [[244, 249], ["tensorflow.concat", "tensorflow.reduce_mean", "l"], "methods", ["None"], ["", "def", "get_q", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "h", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.EnsembleCriticNetwork.weights": [[250, 256], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ValueNetwork.__init__": [[261, 278], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.ValueNetwork._layers.append", "tensorflow.keras.layers.Dense", "networks.ValueNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "ValueNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "1", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ValueNetwork.__call__": [[279, 285], ["tensorflow.reshape", "l"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "state", ")", ":", "\n", "# state = tf.cast(state, dtype=tf.float64)", "\n", "    ", "h", "=", "state", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "tf", ".", "reshape", "(", "h", ",", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ValueNetwork.weights": [[286, 292], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DiscreteValuedCriticNetwork.__init__": [[297, 320], ["tensorflow.Module.__init__", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.linspace", "tensorflow.keras.layers.Dense", "networks.DiscreteValuedCriticNetwork._layers.append", "tensorflow.keras.layers.Dense", "networks.DiscreteValuedCriticNetwork._layers.append", "tensorflow.size"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.size"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vmin", ":", "Union", "[", "float", ",", "np", ".", "ndarray", ",", "tf", ".", "Tensor", "]", ",", "\n", "vmax", ":", "Union", "[", "float", ",", "np", ".", "ndarray", ",", "tf", ".", "Tensor", "]", ",", "\n", "num_atoms", ":", "int", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "DiscreteValuedCriticNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vmin", "=", "tf", ".", "convert_to_tensor", "(", "vmin", ")", "\n", "vmax", "=", "tf", ".", "convert_to_tensor", "(", "vmax", ")", "\n", "self", ".", "_values", "=", "tf", ".", "linspace", "(", "vmin", ",", "vmax", ",", "num_atoms", ")", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "tf", ".", "size", "(", "self", ".", "_values", ")", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DiscreteValuedCriticNetwork.__call__": [[321, 328], ["tensorflow.concat", "scripts.distributions.DiscreteValuedDistribution", "l"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "# state = tf.cast(state, dtype=tf.float64)", "\n", "# action = tf.cast(action, dtype=tf.float64)", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "DiscreteValuedDistribution", "(", "self", ".", "_values", ",", "logits", "=", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DiscreteValuedCriticNetwork.weights": [[329, 335], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.BCQActorNetwork.__init__": [[340, 361], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.BCQActorNetwork._layers.append", "networks.get_spec_means_mags", "tensorflow.keras.layers.Dense", "networks.BCQActorNetwork._layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", ")", ":", "\n", "    ", "super", "(", "BCQActorNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_action_spec", "=", "action_spec", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_action_spec", ".", "shape", "[", "0", "]", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_action_means", ",", "self", ".", "_action_mags", "=", "get_spec_means_mags", "(", "\n", "self", ".", "_action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.BCQActorNetwork.action_spec": [[362, 365], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.BCQActorNetwork._get_outputs": [[366, 374], ["tensorflow.concat", "tensorflow.clip_by_value", "l", "tensorflow.tanh"], "methods", ["None"], ["", "def", "_get_outputs", "(", "self", ",", "state", ",", "action", ",", "max_perturbation", ")", ":", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "a", "=", "tf", ".", "tanh", "(", "h", ")", "*", "self", ".", "_action_mags", "*", "max_perturbation", "+", "action", "\n", "a", "=", "tf", ".", "clip_by_value", "(", "\n", "a", ",", "self", ".", "_action_spec", ".", "minimum", ",", "self", ".", "_action_spec", ".", "maximum", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.BCQActorNetwork.weights": [[375, 381], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.BCQActorNetwork.__call__": [[382, 384], ["networks.BCQActorNetwork._get_outputs"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "__call__", "(", "self", ",", "state", ",", "action", ",", "max_perturbation", ")", ":", "\n", "    ", "return", "self", ".", "_get_outputs", "(", "state", ",", "action", ",", "max_perturbation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.__init__": [[389, 435], ["tensorflow.Module.__init__", "tensorflow.math.sqrt", "tensorflow.keras.initializers.Orthogonal", "tensorflow.keras.initializers.Orthogonal", "tensorflow.keras.layers.Dense", "networks.ConditionalVAENetwork._encoder_layers.append", "tensorflow.keras.layers.Dense", "networks.ConditionalVAENetwork._decoder_layers.append", "networks.get_spec_means_mags", "tensorflow.keras.layers.Dense", "networks.ConditionalVAENetwork._encoder_layers.append", "tensorflow.keras.layers.Dense", "networks.ConditionalVAENetwork._decoder_layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "\n", "self", ",", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", "latent_dim", "=", "None", ",", "\n", ")", ":", "\n", "    ", "super", "(", "ConditionalVAENetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "latent_dim", "is", "None", ":", "\n", "      ", "latent_dim", "=", "action_spec", ".", "shape", "[", "0", "]", "*", "2", "\n", "", "self", ".", "_action_spec", "=", "action_spec", "\n", "self", ".", "_encoder_layers", "=", "[", "]", "\n", "\n", "relu_gain", "=", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", "\n", "relu_orthogonal", "=", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", "relu_gain", ")", "\n", "near_zero_orthogonal", "=", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", "1e-2", ")", "\n", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "relu_orthogonal", ",", "\n", ")", "\n", "self", ".", "_encoder_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "latent_dim", "*", "2", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "near_zero_orthogonal", ",", "\n", ")", "\n", "self", ".", "_encoder_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_decoder_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "kernel_initializer", "=", "relu_orthogonal", ",", "\n", ")", "\n", "self", ".", "_decoder_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "action_spec", ".", "shape", "[", "0", "]", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "near_zero_orthogonal", ",", "\n", ")", "\n", "self", ".", "_decoder_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_action_means", ",", "self", ".", "_action_mags", "=", "get_spec_means_mags", "(", "\n", "self", ".", "_action_spec", ")", "\n", "self", ".", "_latent_dim", "=", "latent_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.action_spec": [[436, 439], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.forward": [[440, 453], ["tensorflow.concat", "tensorflow.split", "tensorflow.tanh", "tensorflow.exp", "networks.ConditionalVAENetwork.decode", "l", "tensorflow.random.normal"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.decode"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_encoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "# std = tf.exp(tf.clip_by_value(log_std, -4, 15))", "\n", "log_std", "=", "tf", ".", "tanh", "(", "log_std", ")", "\n", "log_std", "=", "LOG_STD_MIN", "+", "0.5", "*", "(", "LOG_STD_MAX", "-", "LOG_STD_MIN", ")", "*", "(", "log_std", "+", "1", ")", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "\n", "z", "=", "mean", "+", "std", "*", "tf", ".", "random", ".", "normal", "(", "shape", "=", "std", ".", "shape", ")", "\n", "a", "=", "self", ".", "decode", "(", "state", ",", "z", ")", "\n", "return", "a", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.get_latent_kl": [[454, 463], ["tensorflow.concat", "tensorflow.split", "tensorflow.exp", "l", "tensorflow.square", "tensorflow.square", "tensorflow.log", "tensorflow.square"], "methods", ["None"], ["", "def", "get_latent_kl", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_encoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "# std = tf.exp(tf.clip_by_value(log_std, -4, 15))", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "kl", "=", "-", "0.5", "*", "(", "1.0", "+", "tf", ".", "log", "(", "tf", ".", "square", "(", "std", ")", ")", "-", "tf", ".", "square", "(", "mean", ")", "-", "tf", ".", "square", "(", "std", ")", ")", "\n", "return", "kl", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.decode": [[464, 472], ["tensorflow.concat", "l", "tensorflow.tanh"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "state", ",", "z", ")", ":", "\n", "    ", "h", "=", "tf", ".", "concat", "(", "[", "state", ",", "z", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_decoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "a", "=", "tf", ".", "tanh", "(", "h", ")", "*", "self", ".", "_action_mags", "+", "self", ".", "_action_means", "\n", "# a = tf.clip_by_value(", "\n", "#     a, self._action_spec.minimum, self._action_spec.maximum)", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.decode_multiple": [[473, 486], ["tensorflow.reshape", "tensorflow.concat", "tensorflow.random.normal", "tensorflow.clip_by_value", "tensorflow.tile", "l", "tensorflow.tanh"], "methods", ["None"], ["", "def", "decode_multiple", "(", "self", ",", "state", ",", "z", "=", "None", ",", "n", "=", "10", ")", ":", "\n", "    ", "if", "z", "is", "None", ":", "\n", "      ", "z", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "(", "n", ",", "state", ".", "shape", "[", "0", "]", ",", "self", ".", "_latent_dim", ")", ")", "\n", "z", "=", "tf", ".", "clip_by_value", "(", "z", ",", "-", "0.5", ",", "0.5", ")", "\n", "# state_tile = tf.reshape(tf.tile(state, (1, n)), (state.shape[0], n, -1))", "\n", "", "state_tile", "=", "tf", ".", "reshape", "(", "tf", ".", "tile", "(", "state", ",", "(", "n", ",", "1", ")", ")", ",", "(", "n", ",", "state", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "h", "=", "tf", ".", "concat", "(", "[", "state_tile", ",", "z", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_decoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "a", "=", "tf", ".", "tanh", "(", "h", ")", "*", "self", ".", "_action_mags", "+", "self", ".", "_action_means", "\n", "# a = tf.clip_by_value(", "\n", "#     a, self._action_spec.minimum, self._action_spec.maximum)", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.sample": [[487, 491], ["tensorflow.random.normal", "tensorflow.clip_by_value", "networks.ConditionalVAENetwork.decode"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.decode"], ["", "def", "sample", "(", "self", ",", "state", ")", ":", "\n", "    ", "z", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "[", "state", ".", "shape", "[", "0", "]", ",", "self", ".", "_latent_dim", "]", ")", "\n", "z", "=", "tf", ".", "clip_by_value", "(", "z", ",", "-", "0.5", ",", "0.5", ")", "\n", "return", "self", ".", "decode", "(", "state", ",", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.sample_n": [[492, 496], ["networks.ConditionalVAENetwork.decode_multiple"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.decode_multiple"], ["", "def", "sample_n", "(", "self", ",", "state", ",", "n", "=", "10", ")", ":", "\n", "# used in computing divergence", "\n", "    ", "a_n", "=", "self", ".", "decode_multiple", "(", "state", ",", "n", "=", "n", ")", "\n", "return", "None", ",", "a_n", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.get_log_density": [[497, 512], ["networks.ConditionalVAENetwork.forward", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.log", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward"], ["", "def", "get_log_density", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "# variational lower bound", "\n", "    ", "a_recon", ",", "mean", ",", "std", "=", "self", ".", "forward", "(", "state", ",", "action", ")", "\n", "# log_2pi = tf.log(tf.constant(math.pi))", "\n", "# recon = - 0.5 * tf.reduce_mean(", "\n", "#     tf.square(a_recon - action) + log_2pi, axis=-1)", "\n", "# kl = 0.5 * tf.reduce_mean(", "\n", "#     - 1.0 - tf.log(tf.square(std)) + tf.square(mean) + tf.square(std),", "\n", "#     axis=-1)", "\n", "recon_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "a_recon", "-", "action", ")", ",", "axis", "=", "-", "1", ")", "\n", "kl_losses", "=", "-", "0.5", "*", "(", "1.0", "+", "tf", ".", "log", "(", "tf", ".", "square", "(", "std", ")", ")", "-", "tf", ".", "square", "(", "mean", ")", "-", "\n", "tf", ".", "square", "(", "std", ")", ")", "\n", "kl_loss", "=", "tf", ".", "reduce_mean", "(", "kl_losses", ",", "axis", "=", "-", "1", ")", "\n", "b_loss", "=", "recon_loss", "+", "kl_loss", "*", "0.5", "# Based on the pytorch implementation.", "\n", "return", "-", "b_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.weights": [[513, 521], ["w_list.append", "w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_encoder_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "for", "l", "in", "self", ".", "_decoder_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ConditionalVAENetwork.__call__": [[522, 524], ["networks.ConditionalVAENetwork.forward"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward"], ["", "def", "__call__", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "state", ",", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.__init__": [[529, 564], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.VAENetwork._encoder_layers.append", "tensorflow.keras.layers.Dense", "networks.VAENetwork._decoder_layers.append", "networks.get_spec_means_mags", "tensorflow.keras.layers.Dense", "networks.VAENetwork._encoder_layers.append", "tensorflow.keras.layers.Dense", "networks.VAENetwork._decoder_layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "\n", "self", ",", "\n", "state_spec", ",", "\n", "fc_layer_params", ",", "\n", "latent_dim", "=", "None", ",", "\n", ")", ":", "\n", "    ", "super", "(", "VAENetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "latent_dim", "is", "None", ":", "\n", "      ", "latent_dim", "=", "state_spec", ".", "shape", "[", "0", "]", "*", "2", "\n", "", "self", ".", "_state_spec", "=", "state_spec", "\n", "self", ".", "_encoder_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_encoder_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "latent_dim", "*", "2", ",", "\n", "activation", "=", "None", ")", "\n", "self", ".", "_encoder_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_decoder_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "_decoder_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "state_spec", ".", "shape", "[", "0", "]", ",", "\n", "activation", "=", "None", ")", "\n", "self", ".", "_decoder_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_state_means", ",", "self", ".", "_state_mags", "=", "get_spec_means_mags", "(", "\n", "self", ".", "_state_spec", ")", "\n", "self", ".", "_latent_dim", "=", "latent_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.state_spec": [[565, 568], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_state_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.forward": [[569, 578], ["tensorflow.split", "tensorflow.exp", "networks.VAENetwork.decode", "l", "tensorflow.clip_by_value", "tensorflow.random.normal"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.decode"], ["", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "    ", "h", "=", "state", "\n", "for", "l", "in", "self", ".", "_encoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "std", "=", "tf", ".", "exp", "(", "tf", ".", "clip_by_value", "(", "log_std", ",", "-", "4", ",", "15", ")", ")", "\n", "z", "=", "mean", "+", "std", "*", "tf", ".", "random", ".", "normal", "(", "shape", "=", "std", ".", "shape", ")", "\n", "s", "=", "self", ".", "decode", "(", "z", ")", "\n", "return", "s", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.decode": [[579, 587], ["l", "networks.VAENetwork._state_mags.numpy().mean", "networks.VAENetwork._state_mags.numpy", "tensorflow.tanh"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "    ", "h", "=", "z", "\n", "for", "l", "in", "self", ".", "_decoder_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "if", "self", ".", "_state_mags", ".", "numpy", "(", ")", ".", "mean", "(", ")", "==", "np", ".", "inf", ":", "\n", "      ", "return", "h", "\n", "", "else", ":", "\n", "      ", "return", "tf", ".", "tanh", "(", "h", ")", "*", "self", ".", "_state_mags", "+", "self", ".", "_state_means", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.get_log_density": [[611, 626], ["networks.VAENetwork.forward", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.log", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward"], ["", "", "def", "get_log_density", "(", "self", ",", "state", ")", ":", "\n", "# variational lower bound", "\n", "    ", "s_recon", ",", "mean", ",", "std", "=", "self", ".", "forward", "(", "state", ")", "\n", "# log_2pi = tf.log(tf.constant(math.pi))", "\n", "# recon = - 0.5 * tf.reduce_mean(", "\n", "#     tf.square(s_recon - state) + log_2pi, axis=-1)", "\n", "# kl = 0.5 * tf.reduce_mean(", "\n", "#     - 1.0 - tf.log(tf.square(std)) + tf.square(mean) + tf.square(std),", "\n", "#     axis=-1)", "\n", "recon_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "s_recon", "-", "state", ")", ",", "axis", "=", "-", "1", ")", "\n", "kl_losses", "=", "-", "0.5", "*", "(", "1.0", "+", "tf", ".", "log", "(", "tf", ".", "square", "(", "std", ")", ")", "-", "tf", ".", "square", "(", "mean", ")", "-", "\n", "tf", ".", "square", "(", "std", ")", ")", "\n", "kl_loss", "=", "tf", ".", "reduce_mean", "(", "kl_losses", ",", "axis", "=", "-", "1", ")", "\n", "b_loss", "=", "recon_loss", "+", "kl_loss", "*", "0.5", "# Based on the pytorch implementation.", "\n", "return", "-", "b_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.weights": [[627, 635], ["w_list.append", "w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_encoder_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "for", "l", "in", "self", ".", "_decoder_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.VAENetwork.__call__": [[636, 638], ["networks.VAENetwork.forward"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward"], ["", "def", "__call__", "(", "self", ",", "state", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.__init__": [[643, 659], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.DNNNetwork._dnn_layers.append", "tensorflow.keras.layers.Dense", "networks.DNNNetwork._dnn_layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "output_dim", ",", "\n", "fc_layer_params", ",", ")", ":", "\n", "        ", "super", "(", "DNNNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_dnn_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "            ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "swish", ",", "\n", ")", "\n", "self", ".", "_dnn_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "output_dim", ",", "\n", "activation", "=", "None", ")", "\n", "self", ".", "_dnn_layers", ".", "append", "(", "output_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward": [[660, 665], ["l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ")", ":", "\n", "        ", "h", "=", "state", "\n", "for", "l", "in", "self", ".", "_dnn_layers", ":", "\n", "            ", "h", "=", "l", "(", "h", ")", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.weights": [[666, 672], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "        ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_dnn_layers", ":", "\n", "            ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.__call__": [[673, 675], ["networks.DNNNetwork.forward"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.DNNNetwork.forward"], ["", "def", "__call__", "(", "self", ",", "state", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.__init__": [[679, 729], ["tensorflow.Module.__init__", "isinstance", "range", "networks.get_spec_means_mags", "numpy.arange", "tensorflow.keras.layers.Dense", "networks.ADMBehavior.shared_layer.append", "isinstance", "tensorflow.keras.layers.Dense", "_layers.append", "networks.ADMBehavior._layers_list.append", "len", "tensorflow.keras.layers.Dense", "networks.ADMBehavior.shared_layer.append", "tensorflow.keras.layers.Dense", "_layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags"], ["def", "__init__", "(", "self", ",", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", "out_reranking", "=", "None", ",", "\n", "latent_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_action_spec", "=", "action_spec", "\n", "if", "latent_dim", "is", "None", ":", "\n", "            ", "latent_dim", "=", "action_spec", ".", "shape", "[", "0", "]", "*", "2", "\n", "", "self", ".", "out_dim", "=", "action_spec", ".", "shape", "[", "0", "]", "\n", "if", "out_reranking", "is", "None", ":", "\n", "            ", "self", ".", "out_rank", "=", "np", ".", "arange", "(", "self", ".", "out_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_rank", "=", "out_reranking", "\n", "", "self", ".", "shared_layer_params", "=", "None", "\n", "self", ".", "indiv_layer_params", "=", "None", "\n", "if", "isinstance", "(", "fc_layer_params", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "fc_layer_params", ")", "==", "2", "\n", "self", ".", "shared_layer_params", "=", "fc_layer_params", "[", "0", "]", "\n", "self", ".", "indiv_layer_params", "=", "fc_layer_params", "[", "-", "1", "]", "\n", "self", ".", "shared_layer", "=", "[", "]", "\n", "for", "n_units", "in", "self", ".", "shared_layer_params", ":", "\n", "                ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "shared_layer", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "latent_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'latent_out'", ")", "\n", "self", ".", "shared_layer", ".", "append", "(", "output_layer", ")", "\n", "", "elif", "isinstance", "(", "fc_layer_params", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "self", ".", "indiv_layer_params", "=", "fc_layer_params", "\n", "", "self", ".", "_layers_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "out_dim", ")", ":", "\n", "            ", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "self", ".", "indiv_layer_params", ":", "\n", "                ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", "\n", ")", "\n", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "2", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "f'out_{i}'", ")", "# mean and std of single dimension", "\n", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_layers_list", ".", "append", "(", "_layers", ")", "\n", "", "self", ".", "_action_means", ",", "self", ".", "_action_mags", "=", "get_spec_means_mags", "(", "action_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.action_spec": [[730, 733], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_spec", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_action_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior._get_outputs": [[734, 754], ["tensorflow.split", "tensorflow.tanh", "tensorflow.exp", "tfd.TransformedDistribution", "l", "tensorflow.tanh", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow_probability.bijectors.AffineScalar", "tensorflow_probability.bijectors.Tanh", "tensorflow_probability.bijectors.AffineScalar", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "_get_outputs", "(", "self", ",", "state", ",", "_layers", ")", ":", "\n", "        ", "h", "=", "state", "\n", "for", "l", "in", "_layers", ":", "\n", "            ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "a_tanh_mode", "=", "tf", ".", "tanh", "(", "mean", ")", "*", "self", ".", "_action_mags", "+", "self", ".", "_action_means", "\n", "log_std", "=", "tf", ".", "tanh", "(", "log_std", ")", "\n", "log_std", "=", "(", "log_std", "+", "1", ")", "*", "0.5", "*", "(", "LOG_STD_MAX", "-", "LOG_STD_MIN", ")", "+", "LOG_STD_MIN", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "a_distribution", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "[", "\n", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "self", ".", "_action_means", ",", "scale", "=", "self", ".", "_action_mags", ")", ",", "\n", "tfp", ".", "bijectors", ".", "Tanh", "(", ")", ",", "\n", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "mean", ",", "scale", "=", "std", ")", ",", "\n", "]", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "return", "a_distribution", ",", "a_tanh_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.__call__": [[755, 790], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "enumerate", "out_dist.sample", "out_dist.log_prob", "networks.tensor_modified", "networks.tensor_modified", "networks.tensor_modified", "l", "networks.ADMBehavior._get_outputs", "tensorflow.concat", "networks.ADMBehavior._get_outputs", "tensorflow.concat", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "__call__", "(", "self", ",", "s", ")", ":", "\n", "        ", "if", "self", ".", "shared_layer_params", "is", "None", ":", "\n", "            ", "h", "=", "s", "\n", "", "else", ":", "\n", "            ", "h", "=", "s", "\n", "for", "l", "in", "self", ".", "shared_layer", ":", "\n", "                ", "h", "=", "l", "(", "h", ")", "\n", "", "", "batch_size", "=", "s", ".", "shape", "[", "0", "]", "\n", "out_tanh_mode", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "outs_sample", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "log_pi_outs", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "outs_dist", "=", "[", "None", "]", "*", "self", ".", "out_dim", "\n", "out_middle", "=", "None", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "self", ".", "out_rank", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "out_dist", ",", "out", "=", "self", ".", "_get_outputs", "(", "h", ",", "self", ".", "_layers_list", "[", "i", "]", ")", "\n", "out_middle", "=", "tf", ".", "concat", "(", "[", "h", ",", "out", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "out_dist", ",", "out", "=", "self", ".", "_get_outputs", "(", "out_middle", ",", "self", ".", "_layers_list", "[", "i", "]", ")", "\n", "out_middle", "=", "tf", ".", "concat", "(", "[", "out_middle", ",", "out", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "out_sample", "=", "out_dist", ".", "sample", "(", ")", "\n", "log_pi_out", "=", "out_dist", ".", "log_prob", "(", "out_sample", ")", "\n", "\n", "out_tanh_mode", "=", "tensor_modified", "(", "out_tanh_mode", ",", "\n", "out", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "outs_sample", "=", "tensor_modified", "(", "outs_sample", ",", "\n", "out_sample", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "log_pi_outs", "=", "tensor_modified", "(", "log_pi_outs", ",", "\n", "tf", ".", "reshape", "(", "log_pi_out", ",", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "outs_dist", "[", "index", "]", "=", "out_dist", "\n", "\n", "", "return", "out_tanh_mode", ",", "outs_sample", ",", "log_pi_outs", ",", "outs_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.get_log_density": [[791, 798], ["networks.ADMBehavior.", "enumerate", "log_density.append", "tensorflow.transpose", "out_dist.log_prob"], "methods", ["None"], ["", "def", "get_log_density", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "_", ",", "_", ",", "log_pi_out_pred", ",", "outs_dist", "=", "self", "(", "state", ")", "\n", "log_density", "=", "[", "]", "\n", "for", "i", ",", "out_dist", "in", "enumerate", "(", "outs_dist", ")", ":", "\n", "            ", "log_density", ".", "append", "(", "out_dist", ".", "log_prob", "(", "action", "[", ":", ",", "i", ":", "i", "+", "1", "]", ")", ")", "\n", "\n", "", "return", "tf", ".", "transpose", "(", "log_density", ")", ",", "log_pi_out_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.weights": [[799, 810], ["w_list.append", "w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "        ", "w_list", "=", "[", "]", "\n", "if", "self", ".", "shared_layer_params", "is", "not", "None", ":", "\n", "            ", "for", "l", "in", "self", ".", "shared_layer", ":", "\n", "                ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "", "for", "_layers", "in", "self", ".", "_layers_list", ":", "\n", "            ", "for", "l", "in", "_layers", ":", "\n", "                ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "\n", "", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.sample_n": [[811, 816], ["tensorflow.tile", "networks.ADMBehavior.", "tensorflow.reshape"], "methods", ["None"], ["", "def", "sample_n", "(", "self", ",", "state", ",", "n", "=", "1", ")", ":", "\n", "        ", "repeat_state", "=", "tf", ".", "tile", "(", "state", ",", "(", "n", ",", "1", ")", ")", "\n", "_", ",", "outs_sample", ",", "_", ",", "_", "=", "self", "(", "repeat_state", ")", "\n", "\n", "return", "outs_sample", ",", "tf", ".", "reshape", "(", "outs_sample", ",", "(", "n", ",", "state", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMBehavior.sample": [[817, 819], ["networks.ADMBehavior.sample_n"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample_n"], ["", "def", "sample", "(", "self", ",", "state", ")", ":", "\n", "        ", "return", "self", ".", "sample_n", "(", "state", ",", "n", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.__init__": [[824, 872], ["tensorflow.Module.__init__", "isinstance", "range", "numpy.arange", "tensorflow.keras.layers.Dense", "networks.ADMDynamic.shared_layer.append", "isinstance", "tensorflow.keras.layers.Dense", "_layers.append", "networks.ADMDynamic._layers_list.append", "len", "tensorflow.keras.layers.Dense", "networks.ADMDynamic.shared_layer.append", "tensorflow.keras.layers.Dense", "_layers.append"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "\n", "state_dim", ",", "\n", "fc_layer_params", "=", "(", ")", ",", "\n", "out_reranking", "=", "None", ",", "\n", "latent_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "latent_dim", "is", "None", ":", "\n", "            ", "latent_dim", "=", "state_dim", "\n", "", "self", ".", "out_dim", "=", "state_dim", "+", "1", "# state + reward", "\n", "if", "out_reranking", "is", "None", ":", "\n", "            ", "self", ".", "out_rank", "=", "np", ".", "arange", "(", "self", ".", "out_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_rank", "=", "out_reranking", "\n", "", "self", ".", "shared_layer_params", "=", "None", "\n", "self", ".", "indiv_layer_params", "=", "None", "\n", "if", "isinstance", "(", "fc_layer_params", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "fc_layer_params", ")", "==", "2", "\n", "self", ".", "shared_layer_params", "=", "fc_layer_params", "[", "0", "]", "\n", "self", ".", "indiv_layer_params", "=", "fc_layer_params", "[", "-", "1", "]", "\n", "self", ".", "shared_layer", "=", "[", "]", "\n", "for", "n_units", "in", "self", ".", "shared_layer_params", ":", "\n", "                ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", ")", "\n", "self", ".", "shared_layer", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "latent_dim", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "'latent_out'", ")", "\n", "self", ".", "shared_layer", ".", "append", "(", "output_layer", ")", "\n", "", "elif", "isinstance", "(", "fc_layer_params", "[", "0", "]", ",", "int", ")", ":", "\n", "            ", "self", ".", "indiv_layer_params", "=", "fc_layer_params", "\n", "", "self", ".", "_layers_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "out_dim", ")", ":", "\n", "            ", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "self", ".", "indiv_layer_params", ":", "\n", "                ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", "\n", ")", "\n", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "2", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "f'out_{i}'", ")", "# mean and std of single dimension", "\n", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_layers_list", ".", "append", "(", "_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic._get_outputs": [[873, 890], ["tensorflow.split", "tensorflow.tanh", "tensorflow.exp", "tfd.TransformedDistribution", "l", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow_probability.bijectors.AffineScalar", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_get_outputs", "(", "self", ",", "inputs", ",", "_layers", ")", ":", "\n", "        ", "h", "=", "inputs", "\n", "for", "l", "in", "_layers", ":", "\n", "            ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "log_std", "=", "tf", ".", "tanh", "(", "log_std", ")", "\n", "log_std", "=", "(", "log_std", "+", "1", ")", "*", "0.5", "*", "(", "LOG_STD_MAX", "-", "LOG_STD_MIN", ")", "+", "LOG_STD_MIN", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "a_distribution", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "[", "\n", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "mean", ",", "scale", "=", "std", ")", ",", "\n", "]", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "return", "a_distribution", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.__call__": [[891, 926], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "enumerate", "tensorflow.concat", "tensorflow.concat", "out_dist.sample", "out_dist.log_prob", "networks.tensor_modified", "networks.tensor_modified", "networks.tensor_modified", "l", "networks.ADMDynamic._get_outputs", "tensorflow.concat", "networks.ADMDynamic._get_outputs", "tensorflow.concat", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "__call__", "(", "self", ",", "s", ",", "a", ")", ":", "\n", "        ", "if", "self", ".", "shared_layer_params", "is", "None", ":", "\n", "            ", "h", "=", "tf", ".", "concat", "(", "[", "s", ",", "a", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "h", "=", "tf", ".", "concat", "(", "[", "s", ",", "a", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "shared_layer", ":", "\n", "                ", "h", "=", "l", "(", "h", ")", "\n", "", "", "batch_size", "=", "s", ".", "shape", "[", "0", "]", "\n", "out_mean", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "outs_sample", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "log_pi_outs", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "self", ".", "out_dim", "]", ")", "\n", "outs_dist", "=", "[", "None", "]", "*", "self", ".", "out_dim", "\n", "out_middle", "=", "None", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "self", ".", "out_rank", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "out_dist", ",", "out", "=", "self", ".", "_get_outputs", "(", "h", ",", "self", ".", "_layers_list", "[", "i", "]", ")", "\n", "out_middle", "=", "tf", ".", "concat", "(", "[", "h", ",", "out", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "out_dist", ",", "out", "=", "self", ".", "_get_outputs", "(", "out_middle", ",", "self", ".", "_layers_list", "[", "i", "]", ")", "\n", "out_middle", "=", "tf", ".", "concat", "(", "[", "out_middle", ",", "out", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "out_sample", "=", "out_dist", ".", "sample", "(", ")", "\n", "log_pi_out", "=", "out_dist", ".", "log_prob", "(", "out_sample", ")", "\n", "\n", "out_mean", "=", "tensor_modified", "(", "out_mean", ",", "\n", "out", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "outs_sample", "=", "tensor_modified", "(", "outs_sample", ",", "\n", "out_sample", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "log_pi_outs", "=", "tensor_modified", "(", "log_pi_outs", ",", "\n", "tf", ".", "reshape", "(", "log_pi_out", ",", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "[", "index", ",", "index", "+", "1", "]", ")", "\n", "outs_dist", "[", "index", "]", "=", "out_dist", "\n", "\n", "", "return", "out_mean", ",", "outs_sample", ",", "log_pi_outs", ",", "outs_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.get_log_density": [[927, 935], ["tensorflow.concat", "networks.ADMDynamic.", "enumerate", "log_density.append", "tensorflow.transpose", "tensorflow.reshape", "out_dist.log_prob"], "methods", ["None"], ["", "def", "get_log_density", "(", "self", ",", "state", ",", "action", ",", "next_state", ",", "reward", ")", ":", "\n", "        ", "_target", "=", "tf", ".", "concat", "(", "[", "next_state", ",", "tf", ".", "reshape", "(", "reward", ",", "(", "-", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "_", ",", "_", ",", "log_pi_out_pred", ",", "outs_dist", "=", "self", "(", "state", ",", "action", ")", "\n", "log_density", "=", "[", "]", "\n", "for", "i", ",", "out_dist", "in", "enumerate", "(", "outs_dist", ")", ":", "\n", "            ", "log_density", ".", "append", "(", "out_dist", ".", "log_prob", "(", "_target", "[", ":", ",", "i", ":", "i", "+", "1", "]", ")", ")", "\n", "\n", "", "return", "tf", ".", "transpose", "(", "log_density", ")", ",", "log_pi_out_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.weights": [[936, 947], ["w_list.append", "w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "        ", "w_list", "=", "[", "]", "\n", "if", "self", ".", "shared_layer_params", "is", "not", "None", ":", "\n", "            ", "for", "l", "in", "self", ".", "shared_layer", ":", "\n", "                ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "", "for", "_layers", "in", "self", ".", "_layers_list", ":", "\n", "            ", "for", "l", "in", "_layers", ":", "\n", "                ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "\n", "", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample_n": [[948, 954], ["tensorflow.tile", "tensorflow.tile", "networks.ADMDynamic.", "tensorflow.reshape"], "methods", ["None"], ["", "def", "sample_n", "(", "self", ",", "state", ",", "action", ",", "n", "=", "1", ")", ":", "\n", "        ", "repeat_state", "=", "tf", ".", "tile", "(", "state", ",", "(", "n", ",", "1", ")", ")", "\n", "repeat_action", "=", "tf", ".", "tile", "(", "action", ",", "(", "n", ",", "1", ")", ")", "\n", "_", ",", "outs_sample", ",", "_", ",", "_", "=", "self", "(", "repeat_state", ",", "repeat_action", ")", "\n", "\n", "return", "outs_sample", ",", "tf", ".", "reshape", "(", "outs_sample", ",", "(", "n", ",", "state", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample": [[955, 957], ["networks.ADMDynamic.sample_n"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample_n"], ["", "def", "sample", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "return", "self", ".", "sample_n", "(", "state", ",", "action", ",", "n", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.__init__": [[979, 998], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "networks.ProbDynamics._layers.append", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.keras.layers.Dense", "networks.ProbDynamics._layers.append", "numpy.ones", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "state_dim", ",", "fc_layer_params", "=", "(", ")", ",", "mode", "=", "'local'", ")", ":", "\n", "    ", "super", "(", "ProbDynamics", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_state_dime", "=", "state_dim", "\n", "output_dim", "=", "state_dim", "+", "1", "# add the dimension of the reward.", "\n", "self", ".", "_layers", "=", "[", "]", "\n", "for", "n_units", "in", "fc_layer_params", ":", "\n", "      ", "l", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "n_units", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "swish", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "l", ")", "\n", "", "output_layer", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "output_dim", "*", "2", ",", "\n", "activation", "=", "None", ",", "\n", ")", "\n", "self", ".", "_layers", ".", "append", "(", "output_layer", ")", "\n", "self", ".", "_max_logstd", "=", "tf", ".", "Variable", "(", "np", ".", "ones", "(", "[", "1", ",", "output_dim", "]", ")", "*", "1", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'max_log_std'", ",", "trainable", "=", "True", ")", "\n", "self", ".", "_min_logstd", "=", "tf", ".", "Variable", "(", "np", ".", "ones", "(", "[", "1", ",", "output_dim", "]", ")", "*", "(", "-", "5", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "'min_log_std'", ",", "trainable", "=", "True", ")", "\n", "self", ".", "_mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs": [[999, 1014], ["tensorflow.concat", "tensorflow.split", "tensorflow.exp", "tfd.Normal", "l", "tensorflow.nn.softplus", "tensorflow.nn.softplus", "tensorflow.split", "tensorflow.concat"], "methods", ["None"], ["", "def", "_get_outputs", "(", "self", ",", "s", ",", "a", ")", ":", "\n", "    ", "\"\"\"The last dimension of the output is reward.\"\"\"", "\n", "h", "=", "tf", ".", "concat", "(", "[", "s", ",", "a", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "h", "=", "l", "(", "h", ")", "\n", "", "mean", ",", "log_std", "=", "tf", ".", "split", "(", "h", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "-", "1", ")", "\n", "log_std", "=", "self", ".", "_max_logstd", "-", "tf", ".", "nn", ".", "softplus", "(", "self", ".", "_max_logstd", "-", "log_std", ")", "\n", "log_std", "=", "self", ".", "_min_logstd", "+", "tf", ".", "nn", ".", "softplus", "(", "log_std", "-", "self", ".", "_min_logstd", ")", "\n", "std", "=", "tf", ".", "exp", "(", "log_std", ")", "\n", "if", "self", ".", "_mode", "==", "'local'", ":", "\n", "      ", "obs", ",", "reward", "=", "tf", ".", "split", "(", "mean", ",", "[", "self", ".", "_state_dime", ",", "1", "]", ",", "axis", "=", "-", "1", ")", "\n", "obs", "=", "obs", "+", "s", "\n", "mean", "=", "tf", ".", "concat", "(", "[", "obs", ",", "reward", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "dist", "=", "tfd", ".", "Normal", "(", "loc", "=", "mean", ",", "scale", "=", "std", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.get_log_density": [[1015, 1029], ["networks.ProbDynamics._get_outputs", "tensorflow.reshape", "networks.ProbDynamics.log_prob", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs"], ["", "def", "get_log_density", "(", "self", ",", "s1", ",", "a1", ",", "s2", ",", "r", ")", ":", "\n", "    ", "\"\"\"Compute the log probability density of the real target\n    in the predict state distribution.\n\n    :param s1: the current state.\n    :param a1: the current action.\n    :param s2: the next state.\n    :param r: the reward.\n    :return log_density: log probability density.\n    \"\"\"", "\n", "dist", "=", "self", ".", "_get_outputs", "(", "s1", ",", "a1", ")", "\n", "r", "=", "tf", ".", "reshape", "(", "r", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "log_density", "=", "dist", ".", "log_prob", "(", "tf", ".", "concat", "(", "[", "s2", ",", "r", "]", ",", "axis", "=", "-", "1", ")", ")", "\n", "return", "log_density", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.weights": [[1030, 1036], ["w_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "weights", "(", "self", ")", ":", "\n", "    ", "w_list", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "      ", "w_list", ".", "append", "(", "l", ".", "weights", "[", "0", "]", ")", "\n", "", "return", "w_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.__call__": [[1037, 1042], ["networks.ProbDynamics._get_outputs", "networks.ProbDynamics.mean", "networks.ProbDynamics.sample"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics._get_outputs", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "__call__", "(", "self", ",", "s", ",", "a", ")", ":", "\n", "    ", "dist", "=", "self", ".", "_get_outputs", "(", "s", ",", "a", ")", "\n", "mean", "=", "dist", ".", "mean", "(", ")", "\n", "sample", "=", "dist", ".", "sample", "(", ")", "\n", "return", "mean", ",", "sample", ",", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.max_logstd": [[1043, 1046], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_logstd", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_max_logstd", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.min_logstd": [[1047, 1050], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "min_logstd", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_min_logstd", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.get_spec_means_mags": [[35, 41], ["tensorflow.constant", "tensorflow.constant"], "function", ["None"], ["def", "get_spec_means_mags", "(", "spec", ")", ":", "\n", "  ", "means", "=", "(", "spec", ".", "maximum", "+", "spec", ".", "minimum", ")", "/", "2.0", "\n", "mags", "=", "(", "spec", ".", "maximum", "-", "spec", ".", "minimum", ")", "/", "2.0", "\n", "means", "=", "tf", ".", "constant", "(", "means", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "mags", "=", "tf", ".", "constant", "(", "mags", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "means", ",", "mags", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.tensor_modified": [[959, 961], ["tensorflow.concat"], "function", ["None"], ["", "", "def", "tensor_modified", "(", "a", ",", "b", ",", "index", ")", ":", "\n", "    ", "return", "tf", ".", "concat", "(", "[", "a", "[", ":", ",", ":", "index", "[", "0", "]", "]", ",", "b", ",", "a", "[", ":", ",", "index", "[", "1", "]", ":", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.__init__": [[38, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "indices", ")", ":", "\n", "    ", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.get_batch": [[42, 45], ["dataset.DatasetView._dataset.get_batch"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch"], ["", "def", "get_batch", "(", "self", ",", "indices", ")", ":", "\n", "    ", "real_indices", "=", "self", ".", "_indices", "[", "indices", "]", "\n", "return", "self", ".", "_dataset", ".", "get_batch", "(", "real_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.get_all_data": [[46, 48], ["None"], "methods", ["None"], ["", "def", "get_all_data", "(", "self", ",", ")", ":", "\n", "    ", "return", "self", ".", "_dataset", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.size": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_indices", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.update_priorities": [[53, 55], ["dataset.DatasetView._dataset.update_priorities"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.update_priorities"], ["", "def", "update_priorities", "(", "self", ",", "inds", ",", "new_priorities", ")", ":", "\n", "    ", "return", "self", ".", "_dataset", ".", "update_priorities", "(", "inds", ",", "new_priorities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.__init__": [[73, 105], ["tensorflow.Module.__init__", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "dataset.Dataset._zeros", "Transition_model_free", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros"], ["def", "__init__", "(", "\n", "self", ",", "\n", "s_dim", ",", "\n", "a_dim", ",", "\n", "size", ",", "\n", "identifier", ",", "\n", "circular", "=", "True", ",", "\n", ")", ":", "\n", "    ", "super", "(", "Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_size", "=", "size", "\n", "self", ".", "_circular", "=", "circular", "\n", "self", ".", "_identifier", "=", "identifier", "\n", "obs_type", "=", "tf", ".", "float32", "# observation_spec.dtype", "\n", "action_type", "=", "tf", ".", "float32", "# action_spec.dtype", "\n", "self", ".", "_s1", "=", "self", ".", "_zeros", "(", "[", "size", "]", "+", "[", "s_dim", "]", ",", "obs_type", ")", "\n", "self", ".", "_s2", "=", "self", ".", "_zeros", "(", "[", "size", "]", "+", "[", "s_dim", "]", ",", "obs_type", ")", "\n", "self", ".", "_a1", "=", "self", ".", "_zeros", "(", "[", "size", "]", "+", "[", "a_dim", "]", ",", "action_type", ")", "\n", "self", ".", "_a2", "=", "self", ".", "_zeros", "(", "[", "size", "]", "+", "[", "a_dim", "]", ",", "action_type", ")", "\n", "self", ".", "_discount", "=", "self", ".", "_zeros", "(", "[", "size", "]", ",", "tf", ".", "float32", ")", "\n", "self", ".", "_reward", "=", "self", ".", "_zeros", "(", "[", "size", "]", ",", "tf", ".", "float32", ")", "\n", "self", ".", "_a1_prob", "=", "self", ".", "_zeros", "(", "[", "size", "]", ",", "tf", ".", "float32", ")", "\n", "self", ".", "_rollout_step", "=", "self", ".", "_zeros", "(", "[", "size", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "_data", "=", "Transition_model_free", "(", "\n", "s1", "=", "self", ".", "_s1", ",", "s2", "=", "self", ".", "_s2", ",", "a1", "=", "self", ".", "_a1", ",", "a2", "=", "self", ".", "_a2", ",", "\n", "discount", "=", "self", ".", "_discount", ",", "reward", "=", "self", ".", "_reward", ")", "\n", "\n", "self", ".", "_current_size", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "self", ".", "_current_idx", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "self", ".", "_capacity", "=", "tf", ".", "Variable", "(", "self", ".", "_size", ")", "\n", "self", ".", "_next_idx", "=", "0.0", "\n", "self", ".", "_np_size", "=", "size", "\n", "# self._R = tf.Variable(0)", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.create_view": [[117, 119], ["dataset.DatasetView"], "methods", ["None"], ["", "def", "create_view", "(", "self", ",", "indices", ")", ":", "\n", "    ", "return", "DatasetView", "(", "self", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.get_batch": [[120, 126], ["tensorflow.constant", "tensorflow.nest.map_structure", "tensorflow.gather"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "indices", ")", ":", "\n", "    ", "indices", "=", "tf", ".", "constant", "(", "indices", ")", "\n", "def", "get_batch_", "(", "data_", ")", ":", "\n", "      ", "return", "tf", ".", "gather", "(", "data_", ",", "indices", ")", "\n", "", "transition_batch", "=", "tf", ".", "nest", ".", "map_structure", "(", "get_batch_", ",", "self", ".", "_data", ")", "\n", "return", "transition_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.data": [[127, 130], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.capacity": [[131, 134], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "capacity", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.size": [[135, 138], ["dataset.Dataset._current_size.numpy"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_current_size", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset._zeros": [[139, 142], ["tensorflow.Variable", "tensorflow.zeros"], "methods", ["None"], ["", "def", "_zeros", "(", "self", ",", "shape", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Create a variable initialized with zeros.\"\"\"", "\n", "return", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "shape", ",", "dtype", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.Dataset.add_transitions": [[143, 163], ["tensorflow.minimum", "transitions._asdict().keys", "tensorflow.less", "dataset.Dataset._current_idx.assign_add", "dataset.Dataset._R.astype", "tensorflow.range", "getattr", "getattr", "tensorflow.scatter_update", "dataset.Dataset._current_size.assign_add", "tensorflow.greater_equal", "numpy.arange", "transitions._asdict", "dataset.Dataset._current_idx.assign"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "add_transitions", "(", "self", ",", "transitions", ")", ":", "\n", "    ", "batch_size", "=", "transitions", ".", "s1", ".", "shape", "[", "0", "]", "\n", "effective_batch_size", "=", "tf", ".", "minimum", "(", "\n", "batch_size", ",", "self", ".", "_size", "-", "self", ".", "_current_idx", ")", "\n", "indices", "=", "self", ".", "_current_idx", "+", "tf", ".", "range", "(", "effective_batch_size", ")", "\n", "for", "key", "in", "transitions", ".", "_asdict", "(", ")", ".", "keys", "(", ")", ":", "\n", "      ", "data", "=", "getattr", "(", "self", ".", "_data", ",", "key", ")", "\n", "batch", "=", "getattr", "(", "transitions", ",", "key", ")", "\n", "tf", ".", "scatter_update", "(", "data", ",", "indices", ",", "batch", "[", ":", "effective_batch_size", "]", ")", "\n", "# Update size and index.", "\n", "", "if", "tf", ".", "less", "(", "self", ".", "_current_size", ",", "self", ".", "_size", ")", ":", "\n", "      ", "self", ".", "_current_size", ".", "assign_add", "(", "effective_batch_size", ")", "\n", "", "self", ".", "_current_idx", ".", "assign_add", "(", "effective_batch_size", ")", "\n", "if", "self", ".", "_circular", ":", "\n", "      ", "if", "tf", ".", "greater_equal", "(", "self", ".", "_current_idx", ",", "self", ".", "_size", ")", ":", "\n", "        ", "self", ".", "_current_idx", ".", "assign", "(", "0", ")", "\n", "", "", "self", ".", "_R", "=", "np", ".", "arange", "(", "self", ".", "_next_idx", ",", "self", ".", "_next_idx", "+", "transitions", ".", "s1", ".", "shape", "[", "0", "]", ")", "%", "self", ".", "_np_size", "\n", "self", ".", "_R", "=", "self", ".", "_R", ".", "astype", "(", "'int64'", ")", "\n", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "transitions", ".", "s1", ".", "shape", "[", "0", "]", ")", "%", "self", ".", "_np_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.__init__": [[166, 183], ["dataset.Dataset.__init__", "SumSegmentTree", "MinSegmentTree"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["  ", "def", "__init__", "(", "\n", "self", ",", "state_shape", ",", "action_shape", ",", "size", ",", "identifier", ",", "state_dtype", "=", "float", ",", "alpha", "=", "0.6", ",", "beta", "=", "1.0", "\n", ")", ":", "\n", "    ", "super", "(", "PrioritizedReplayBuffer", ",", "self", ")", ".", "__init__", "(", "\n", "state_shape", ",", "action_shape", ",", "size", ",", "identifier", "\n", ")", "\n", "assert", "alpha", ">=", "0", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "it_capacity", "=", "1", "\n", "while", "it_capacity", "<", "size", ":", "\n", "      ", "it_capacity", "*=", "2", "\n", "\n", "", "self", ".", "_it_sum", "=", "SumSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_it_min", "=", "MinSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_max_priority", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.add_transitions": [[184, 190], ["dataset.Dataset.add_transitions"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.add_transitions"], ["", "def", "add_transitions", "(", "self", ",", "transitions", ",", "priorities", "=", "None", ")", ":", "\n", "    ", "super", "(", ")", ".", "add_transitions", "(", "transitions", ")", "\n", "if", "priorities", "is", "None", ":", "\n", "      ", "priorities", "=", "self", ".", "_max_priority", "\n", "", "self", ".", "_it_sum", "[", "self", ".", "_R", "]", "=", "priorities", "**", "self", ".", "alpha", "\n", "self", ".", "_it_min", "[", "self", ".", "_R", "]", "=", "priorities", "**", "self", ".", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer._sample_proportional": [[191, 196], ["dataset.PrioritizedReplayBuffer._it_sum.sum", "dataset.PrioritizedReplayBuffer._it_sum.find_prefixsum_idx", "numpy.random.random"], "methods", ["None"], ["", "def", "_sample_proportional", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "total", "=", "self", ".", "_it_sum", ".", "sum", "(", "0", ",", "self", ".", "_data", ".", "s1", ".", "shape", "[", "0", "]", "-", "1", ")", "\n", "mass", "=", "np", ".", "random", ".", "random", "(", "size", "=", "batch_size", ")", "*", "total", "\n", "idx", "=", "self", ".", "_it_sum", ".", "find_prefixsum_idx", "(", "mass", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer._sample_batch": [[197, 207], ["len", "dataset.PrioritizedReplayBuffer._sample_proportional", "dataset.Dataset.get_batch", "dataset.Dataset.get_batch", "dataset.PrioritizedReplayBuffer._it_min.min", "dataset.PrioritizedReplayBuffer._it_sum.sum", "dataset.PrioritizedReplayBuffer._it_sum.sum", "tensorflow.constant", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer._sample_proportional", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch"], ["", "def", "_sample_batch", "(", "self", ",", "indices", ")", ":", "\n", "    ", "batch_size", "=", "len", "(", "indices", ")", "\n", "idxes", "=", "self", ".", "_sample_proportional", "(", "batch_size", ")", "\n", "p_min", "=", "self", ".", "_it_min", ".", "min", "(", ")", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "max_weight", "=", "(", "p_min", "*", "len", "(", "self", ".", "_data", ")", ")", "**", "(", "-", "self", ".", "beta", ")", "\n", "p_sample", "=", "self", ".", "_it_sum", "[", "idxes", "]", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "weights", "=", "(", "p_sample", "*", "len", "(", "self", ".", "_data", ")", ")", "**", "(", "-", "self", ".", "beta", ")", "/", "max_weight", "\n", "actor_batch", "=", "super", "(", ")", ".", "get_batch", "(", "idxes", ")", "\n", "critic_batch", "=", "super", "(", ")", ".", "get_batch", "(", "indices", ")", "\n", "return", "[", "[", "critic_batch", ",", "actor_batch", "]", ",", "tf", ".", "constant", "(", "weights", ",", "tf", ".", "float32", ")", ",", "[", "indices", ",", "idxes", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch": [[208, 210], ["dataset.PrioritizedReplayBuffer._sample_batch"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer._sample_batch"], ["", "def", "get_batch", "(", "self", ",", "indices", ")", ":", "\n", "    ", "return", "self", ".", "_sample_batch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.sample_uniform": [[211, 213], ["dataset.Dataset.get_batch"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.get_batch"], ["", "def", "sample_uniform", "(", "self", ",", "indices", ")", ":", "\n", "    ", "return", "super", "(", ")", ".", "get_batch", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.PrioritizedReplayBuffer.update_priorities": [[214, 225], ["tensorflow.config.experimental_run_functions_eagerly", "priorities.numpy.numpy.numpy", "max", "len", "len", "numpy.min", "numpy.min", "numpy.max", "numpy.max"], "methods", ["None"], ["", "def", "update_priorities", "(", "self", ",", "idxes", ",", "priorities", ")", ":", "\n", "    ", "import", "tensorflow", ".", "compat", ".", "v1", "as", "tf", "\n", "tf", ".", "config", ".", "experimental_run_functions_eagerly", "(", "True", ")", "\n", "priorities", "=", "priorities", ".", "numpy", "(", ")", "\n", "assert", "len", "(", "idxes", ")", "==", "len", "(", "priorities", ")", "\n", "assert", "np", ".", "min", "(", "priorities", ")", ">", "0", "\n", "assert", "np", ".", "min", "(", "idxes", ")", ">=", "0", "\n", "assert", "np", ".", "max", "(", "idxes", ")", "<", "self", ".", "_data", ".", "s1", ".", "shape", "[", "0", "]", "\n", "self", ".", "_it_sum", "[", "idxes", "]", "=", "priorities", "**", "self", ".", "alpha", "\n", "self", ".", "_it_min", "[", "idxes", "]", "=", "priorities", "**", "self", ".", "alpha", "\n", "self", ".", "_max_priority", "=", "max", "(", "self", ".", "_max_priority", ",", "np", ".", "max", "(", "priorities", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.path.abs_file_path": [[5, 7], ["os.path.abspath", "os.path.join", "os.path.split", "os.path.abspath"], "function", ["None"], ["def", "abs_file_path", "(", "file", ",", "relative_path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "os", ".", "path", ".", "abspath", "(", "file", ")", ")", "[", "0", "]", ",", "relative_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution.__init__": [[34, 72], ["tensorflow.convert_to_tensor", "tfd.Categorical.__init__", "dict", "tensorflow.convert_to_tensor", "tensorflow.debugging.assert_equal", "tensorflow.convert_to_tensor", "tensorflow.debugging.assert_equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.rank", "tensorflow.rank"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "\n", "values", ":", "tf", ".", "Tensor", ",", "\n", "logits", ":", "tf", ".", "Tensor", "=", "None", ",", "\n", "probs", ":", "tf", ".", "Tensor", "=", "None", ",", "\n", "name", ":", "str", "=", "'DiscreteValuedDistribution'", ")", ":", "\n", "    ", "\"\"\"Initialization.\n\n    Args:\n      values: Values making up support of the distribution. Should have a shape\n        compatible with logits.\n      logits: An N-D Tensor, N >= 1, representing the log probabilities of a set\n        of Categorical distributions. The first N - 1 dimensions index into a\n        batch of independent distributions and the last dimension indexes into\n        the classes.\n      probs: An N-D Tensor, N >= 1, representing the probabilities of a set of\n        Categorical distributions. The first N - 1 dimensions index into a batch\n        of independent distributions and the last dimension represents a vector\n        of probabilities for each class. Only one of logits or probs should be\n        passed in.\n      name: Name of the distribution object.\n    \"\"\"", "\n", "self", ".", "_values", "=", "tf", ".", "convert_to_tensor", "(", "values", ")", "\n", "\n", "if", "logits", "is", "not", "None", ":", "\n", "      ", "logits", "=", "tf", ".", "convert_to_tensor", "(", "logits", ")", "\n", "tf", ".", "debugging", ".", "assert_equal", "(", "tf", ".", "shape", "(", "values", ")", ",", "\n", "tf", ".", "shape", "(", "logits", ")", "[", "-", "tf", ".", "rank", "(", "values", ")", ":", "]", ")", "\n", "", "if", "probs", "is", "not", "None", ":", "\n", "      ", "probs", "=", "tf", ".", "convert_to_tensor", "(", "probs", ")", "\n", "tf", ".", "debugging", ".", "assert_equal", "(", "tf", ".", "shape", "(", "values", ")", ",", "\n", "tf", ".", "shape", "(", "probs", ")", "[", "-", "tf", ".", "rank", "(", "probs", ")", ":", "]", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "logits", "=", "logits", ",", "probs", "=", "probs", ",", "name", "=", "name", ")", "\n", "\n", "self", ".", "_parameters", "=", "dict", "(", "values", "=", "values", ",", "\n", "logits", "=", "logits", ",", "\n", "probs", "=", "probs", ",", "\n", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution.values": [[73, 76], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "values", "(", "self", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "return", "self", ".", "_values", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._sample_n": [[77, 80], ["super()._sample_n", "tensorflow.gather"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._sample_n"], ["", "def", "_sample_n", "(", "self", ",", "n", ",", "seed", "=", "None", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "indices", "=", "super", "(", ")", ".", "_sample_n", "(", "n", ",", "seed", "=", "seed", ")", "\n", "return", "tf", ".", "gather", "(", "self", ".", "values", ",", "indices", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._mean": [[81, 84], ["tensorflow.reduce_sum", "distributions.DiscreteValuedDistribution.probs_parameter"], "methods", ["None"], ["", "def", "_mean", "(", "self", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Overrides the Categorical mean by incorporating category values.\"\"\"", "\n", "return", "tf", ".", "reduce_sum", "(", "self", ".", "probs_parameter", "(", ")", "*", "self", ".", "values", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._variance": [[85, 89], ["tensorflow.square", "tensorflow.reduce_sum", "tensorflow.expand_dims", "distributions.DiscreteValuedDistribution.probs_parameter", "distributions.DiscreteValuedDistribution.mean"], "methods", ["None"], ["", "def", "_variance", "(", "self", ")", "->", "tf", ".", "Tensor", ":", "\n", "    ", "\"\"\"Overrides the Categorical variance by incorporating category values.\"\"\"", "\n", "dist_squared", "=", "tf", ".", "square", "(", "tf", ".", "expand_dims", "(", "self", ".", "mean", "(", ")", ",", "-", "1", ")", "-", "self", ".", "values", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "self", ".", "probs_parameter", "(", ")", "*", "dist_squared", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._params_event_ndims": [[92, 95], ["dict"], "methods", ["None"], ["", "def", "_params_event_ndims", "(", "self", ")", ":", "\n", "    ", "values_rank", "=", "self", ".", "_values", ".", "shape", ".", "rank", "\n", "return", "dict", "(", "logits", "=", "values_rank", ",", "probs", "=", "values_rank", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._batch_shape": [[96, 99], ["None"], "methods", ["None"], ["", "def", "_batch_shape", "(", "self", ")", ":", "\n", "    ", "params", "=", "self", ".", "_probs", "if", "self", ".", "_logits", "is", "None", "else", "self", ".", "_logits", "\n", "return", "params", ".", "shape", "[", ":", "-", "self", ".", "_values", ".", "shape", ".", "rank", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._batch_shape_tensor": [[100, 106], ["tensorflow.convert_to_tensor", "tensorflow.shape", "tensorflow.rank"], "methods", ["None"], ["", "def", "_batch_shape_tensor", "(", "self", ",", "x", "=", "None", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "      ", "params", "=", "self", ".", "_probs", "if", "self", ".", "_logits", "is", "None", "else", "self", ".", "_logits", "\n", "x", "=", "tf", ".", "convert_to_tensor", "(", "params", ")", "\n", "\n", "", "return", "tf", ".", "shape", "(", "x", ")", "[", ":", "-", "tf", ".", "rank", "(", "self", ".", "_values", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._event_shape": [[107, 111], ["None"], "methods", ["None"], ["", "def", "_event_shape", "(", "self", ")", ":", "\n", "# Omit the atoms axis, to return just the shape of a single (i.e. unbatched)", "\n", "# sample value.", "\n", "    ", "return", "self", ".", "_values", ".", "shape", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.distributions.DiscreteValuedDistribution._event_shape_tensor": [[112, 114], ["tensorflow.shape"], "methods", ["None"], ["", "def", "_event_shape_tensor", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "shape", "(", "self", ".", "_values", ")", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.train_eval_utils.eval_policy_episodes": [[27, 41], ["range", "numpy.array", "env.reset", "np.array.append", "print", "float", "float", "env.step", "numpy.mean", "numpy.std", "env.step.is_last().numpy", "policy", "env.step.is_last"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.offline_env.OfflineEnvWrapper.reset"], ["def", "eval_policy_episodes", "(", "env", ",", "policy", ",", "n_episodes", ")", ":", "\n", "  ", "\"\"\"Evaluates policy performance.\"\"\"", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_episodes", ")", ":", "\n", "    ", "time_step", "=", "env", ".", "reset", "(", ")", "\n", "total_rewards", "=", "0.0", "\n", "while", "not", "time_step", ".", "is_last", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", ":", "\n", "      ", "action", "=", "policy", "(", "time_step", ".", "observation", ")", "[", "0", "]", "\n", "time_step", "=", "env", ".", "step", "(", "action", ")", "\n", "total_rewards", "+=", "time_step", ".", "reward", "\n", "", "results", ".", "append", "(", "total_rewards", ")", "\n", "print", "(", "f'Complete the episode {i}!'", ")", "\n", "", "results", "=", "np", ".", "array", "(", "results", ")", "\n", "return", "float", "(", "np", ".", "mean", "(", "results", ")", ")", ",", "float", "(", "np", ".", "std", "(", "results", ")", ")", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.train_eval_utils.eval_policies": [[42, 60], ["collections.OrderedDict", "policies.items", "train_eval_utils.eval_policy_episodes", "results_episode_return.append", "results_std.append", "complete_results.append", "collections.OrderedDict", "float", "numpy.std"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.train_eval_utils.eval_policy_episodes"], ["", "def", "eval_policies", "(", "env", ",", "policies", ",", "n_episodes", ",", "score_normalize", ",", "norm_min", ",", "norm_max", ")", ":", "\n", "  ", "results_episode_return", "=", "[", "]", "\n", "results_std", "=", "[", "]", "\n", "complete_results", "=", "[", "]", "\n", "infos", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "name", ",", "policy", "in", "policies", ".", "items", "(", ")", ":", "\n", "    ", "mean", ",", "std", ",", "comp_result", "=", "eval_policy_episodes", "(", "env", ",", "policy", ",", "n_episodes", ")", "\n", "if", "score_normalize", ":", "\n", "      ", "mean", "=", "100", "*", "(", "mean", "-", "norm_min", ")", "/", "(", "norm_max", "-", "norm_min", ")", "\n", "comp_result", "=", "100", "*", "(", "comp_result", "-", "norm_min", ")", "/", "(", "norm_max", "-", "norm_min", ")", "\n", "std", "=", "float", "(", "np", ".", "std", "(", "comp_result", ")", ")", "\n", "", "results_episode_return", ".", "append", "(", "mean", ")", "\n", "results_std", ".", "append", "(", "std", ")", "\n", "complete_results", ".", "append", "(", "comp_result", ")", "\n", "infos", "[", "name", "]", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "infos", "[", "name", "]", "[", "'episode_mean'", "]", "=", "mean", "\n", "", "results", "=", "[", "results_episode_return", "]", "+", "[", "results_std", "]", "+", "[", "complete_results", "]", "\n", "return", "results", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.Flags.__init__": [[130, 133], ["kwargs.items", "setattr"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "      ", "setattr", "(", "self", ",", "key", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str": [[30, 40], ["info.items", "isinstance", "isinstance"], "function", ["None"], ["def", "get_summary_str", "(", "step", "=", "None", ",", "info", "=", "None", ",", "prefix", "=", "''", ")", ":", "\n", "  ", "summary_str", "=", "prefix", "\n", "if", "step", "is", "not", "None", ":", "\n", "    ", "summary_str", "+=", "'Step %d; '", "%", "(", "step", ")", "\n", "", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "    ", "if", "isinstance", "(", "val", ",", "(", "int", ",", "np", ".", "int32", ",", "np", ".", "int64", ")", ")", ":", "\n", "      ", "summary_str", "+=", "'%s %d; '", "%", "(", "key", ",", "val", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "(", "float", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", ":", "\n", "      ", "summary_str", "+=", "'%s %.4g; '", "%", "(", "key", ",", "val", ")", "\n", "", "", "return", "summary_str", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary": [[42, 48], ["summary_writer.as_default", "info.items", "isinstance", "tensorflow.compat.v2.summary.scalar"], "function", ["None"], ["", "def", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "  ", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "\n", "val", ",", "(", "int", ",", "float", ",", "np", ".", "int32", ",", "np", ".", "int64", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", ":", "\n", "        ", "tf", ".", "compat", ".", "v2", ".", "summary", ".", "scalar", "(", "name", "=", "key", ",", "data", "=", "val", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.soft_variables_update": [[50, 53], ["zip", "v_t.assign"], "function", ["None"], ["", "", "", "", "def", "soft_variables_update", "(", "source_variables", ",", "target_variables", ",", "tau", "=", "1.0", ")", ":", "\n", "  ", "for", "(", "v_s", ",", "v_t", ")", "in", "zip", "(", "source_variables", ",", "target_variables", ")", ":", "\n", "    ", "v_t", ".", "assign", "(", "(", "1", "-", "tau", ")", "*", "v_t", "+", "tau", "*", "v_s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.shuffle_indices_with_steps": [[55, 69], ["int", "rand.permutation", "numpy.arange().reshape", "numpy.arange", "shuffled_batches.reshape", "numpy.arange", "numpy.arange"], "function", ["None"], ["", "", "def", "shuffle_indices_with_steps", "(", "n", ",", "steps", "=", "1", ",", "rand", "=", "None", ")", ":", "\n", "  ", "\"\"\"Randomly shuffling indices while keeping segments.\"\"\"", "\n", "if", "steps", "==", "0", ":", "\n", "    ", "return", "np", ".", "arange", "(", "n", ")", "\n", "", "if", "rand", "is", "None", ":", "\n", "    ", "rand", "=", "np", ".", "random", "\n", "", "n_segments", "=", "int", "(", "n", "//", "steps", ")", "\n", "n_effective", "=", "n_segments", "*", "steps", "\n", "batch_indices", "=", "rand", ".", "permutation", "(", "n_segments", ")", "\n", "batches", "=", "np", ".", "arange", "(", "n_effective", ")", ".", "reshape", "(", "[", "n_segments", ",", "steps", "]", ")", "\n", "shuffled_batches", "=", "batches", "[", "batch_indices", "]", "\n", "shuffled_indices", "=", "np", ".", "arange", "(", "n", ")", "\n", "shuffled_indices", "[", ":", "n_effective", "]", "=", "shuffled_batches", ".", "reshape", "(", "[", "-", "1", "]", ")", "\n", "return", "shuffled_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.clip_by_eps": [[71, 74], ["tensorflow.clip_by_value"], "function", ["None"], ["", "def", "clip_by_eps", "(", "x", ",", "spec", ",", "eps", "=", "0.0", ")", ":", "\n", "  ", "return", "tf", ".", "clip_by_value", "(", "\n", "x", ",", "spec", ".", "minimum", "+", "eps", ",", "spec", ".", "maximum", "-", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.add_gaussian_noise": [[76, 79], ["tensorflow.clip_by_value", "tensorflow.random.normal"], "function", ["None"], ["", "def", "add_gaussian_noise", "(", "actions", ",", "spec", ",", "std", ")", ":", "\n", "  ", "noise", "=", "spec", ".", "maximum", "*", "tf", ".", "random", ".", "normal", "(", "shape", "=", "actions", ".", "shape", ",", "stddev", "=", "std", ")", "\n", "return", "tf", ".", "clip_by_value", "(", "actions", "+", "noise", ",", "spec", ".", "minimum", ",", "spec", ".", "maximum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer": [[81, 89], ["ValueError", "tensorflow.keras.optimizers.Adam"], "function", ["None"], ["", "def", "get_optimizer", "(", "name", ")", ":", "\n", "  ", "\"\"\"Get an optimizer generator that returns an optimizer according to lr.\"\"\"", "\n", "if", "name", "==", "'adam'", ":", "\n", "    ", "def", "adam_opt_", "(", "lr", ")", ":", "\n", "      ", "return", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "lr", "=", "lr", ")", "\n", "", "return", "adam_opt_", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unknown optimizer %s.'", "%", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.load_variable_from_ckpt": [[91, 94], ["tensorflow.train.load_variable", "var_name.split"], "function", ["None"], ["", "", "def", "load_variable_from_ckpt", "(", "ckpt_name", ",", "var_name", ")", ":", "\n", "  ", "var_name_", "=", "'/'", ".", "join", "(", "var_name", ".", "split", "(", "'.'", ")", ")", "+", "'/.ATTRIBUTES/VARIABLE_VALUE'", "\n", "return", "tf", ".", "train", ".", "load_variable", "(", "ckpt_name", ",", "var_name_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.soft_relu": [[96, 102], ["tensorflow.log", "tensorflow.maximum", "tensorflow.exp", "tensorflow.abs"], "function", ["None"], ["", "def", "soft_relu", "(", "x", ")", ":", "\n", "  ", "\"\"\"Compute log(1 + exp(x)).\"\"\"", "\n", "# Note: log(sigmoid(x)) = x - soft_relu(x) = - soft_relu(-x).", "\n", "#       log(1 - sigmoid(x)) = - soft_relu(x)", "\n", "# tf.math.softplus", "\n", "return", "tf", ".", "log", "(", "1.0", "+", "tf", ".", "exp", "(", "-", "tf", ".", "abs", "(", "x", ")", ")", ")", "+", "tf", ".", "maximum", "(", "x", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.relu_v2": [[104, 113], ["tensorflow.nn.relu", "tensorflow.cast", "tensorflow.cast", "tensorflow.greater", "tensorflow.greater"], "function", ["None"], ["", "@", "tf", ".", "custom_gradient", "\n", "def", "relu_v2", "(", "x", ")", ":", "\n", "  ", "\"\"\"Relu with modified gradient behavior.\"\"\"", "\n", "value", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "def", "grad", "(", "dy", ")", ":", "\n", "    ", "if_y_pos", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "dy", ",", "0.0", ")", ",", "tf", ".", "float32", ")", "\n", "if_x_pos", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "x", ",", "0.0", ")", ",", "tf", ".", "float32", ")", "\n", "return", "(", "if_y_pos", "*", "if_x_pos", "+", "(", "1.0", "-", "if_y_pos", ")", ")", "*", "dy", "\n", "", "return", "value", ",", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.clip_v2": [[115, 126], ["tensorflow.minimum", "tensorflow.maximum", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.greater", "tensorflow.greater", "tensorflow.less"], "function", ["None"], ["", "@", "tf", ".", "custom_gradient", "\n", "def", "clip_v2", "(", "x", ",", "low", ",", "high", ")", ":", "\n", "  ", "\"\"\"Clipping with modified gradient behavior.\"\"\"", "\n", "value", "=", "tf", ".", "minimum", "(", "tf", ".", "maximum", "(", "x", ",", "low", ")", ",", "high", ")", "\n", "def", "grad", "(", "dy", ")", ":", "\n", "    ", "if_y_pos", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "dy", ",", "0.0", ")", ",", "tf", ".", "float32", ")", "\n", "if_x_g_low", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "x", ",", "low", ")", ",", "tf", ".", "float32", ")", "\n", "if_x_l_high", "=", "tf", ".", "cast", "(", "tf", ".", "less", "(", "x", ",", "high", ")", ",", "tf", ".", "float32", ")", "\n", "return", "(", "if_y_pos", "*", "if_x_g_low", "+", "\n", "(", "1.0", "-", "if_y_pos", ")", "*", "if_x_l_high", ")", "*", "dy", "\n", "", "return", "value", ",", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_datetime": [[135, 139], ["datetime.datetime.now().isoformat", "re.sub", "datetime.datetime.now"], "function", ["None"], ["", "", "", "def", "get_datetime", "(", ")", ":", "\n", "  ", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "isoformat", "(", ")", "\n", "now", "=", "re", ".", "sub", "(", "r'\\D'", ",", "''", ",", "now", ")", "[", ":", "-", "6", "]", "\n", "return", "now", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.maybe_makedirs": [[141, 144], ["tensorflow.io.gfile.exists", "tensorflow.io.gfile.makedirs"], "function", ["None"], ["", "def", "maybe_makedirs", "(", "log_dir", ")", ":", "\n", "  ", "if", "not", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "log_dir", ")", ":", "\n", "    ", "tf", ".", "io", ".", "gfile", ".", "makedirs", "(", "log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.subsample_trajectories": [[146, 219], ["range", "utils.subsample_trajectories.concat_trajectories"], "function", ["None"], ["", "", "def", "subsample_trajectories", "(", "expert_states", ",", "expert_actions", ",", "expert_next_states", ",", "expert_next_actions", ",", "\n", "expert_rewards", ",", "expert_dones", ",", "num_trajectories", "=", "None", ",", "rank_identifier", "=", "'reward'", ")", ":", "\n", "  ", "\"\"\"Extracts a (random) subset of trajectories.\n\n  Args:\n    expert_states: A numpy array with expert states.\n    expert_actions: A numpy array with expert states.\n    expert_next_states: A numpy array with expert states.\n    expert_dones: A numpy array with expert states.\n    num_trajectories: A number of trajectories to extract.\n\n  Returns:\n      Numpy arrays that contain states, actions, next_states and dones.\n  \"\"\"", "\n", "assert", "rank_identifier", "==", "'random'", "or", "'reward'", "or", "'origin'", ",", "'wrong rank identifier!!!'", "\n", "expert_states_traj", "=", "[", "[", "]", "]", "\n", "expert_actions_traj", "=", "[", "[", "]", "]", "\n", "expert_next_states_traj", "=", "[", "[", "]", "]", "\n", "expert_next_actions_traj", "=", "[", "[", "]", "]", "\n", "expert_rewards_traj", "=", "[", "[", "]", "]", "\n", "expert_dones_traj", "=", "[", "[", "]", "]", "\n", "traj_sum_rewards", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "expert_states", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "expert_states_traj", "[", "-", "1", "]", ".", "append", "(", "expert_states", "[", "i", "]", ")", "\n", "expert_actions_traj", "[", "-", "1", "]", ".", "append", "(", "expert_actions", "[", "i", "]", ")", "\n", "expert_next_states_traj", "[", "-", "1", "]", ".", "append", "(", "expert_next_states", "[", "i", "]", ")", "\n", "expert_next_actions_traj", "[", "-", "1", "]", ".", "append", "(", "expert_next_actions", "[", "i", "]", ")", "\n", "expert_rewards_traj", "[", "-", "1", "]", ".", "append", "(", "expert_rewards", "[", "i", "]", ")", "\n", "expert_dones_traj", "[", "-", "1", "]", ".", "append", "(", "expert_dones", "[", "i", "]", ")", "\n", "\n", "if", "expert_dones", "[", "i", "]", ":", "\n", "      ", "traj_sum_rewards", ".", "append", "(", "np", ".", "sum", "(", "expert_rewards_traj", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "if", "expert_dones", "[", "i", "]", "and", "i", "<", "expert_states", ".", "shape", "[", "0", "]", "-", "1", ":", "\n", "      ", "expert_states_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_actions_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_next_states_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_next_actions_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_rewards_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_dones_traj", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "", "if", "rank_identifier", "==", "'random'", ":", "\n", "    ", "shuffle_inds", "=", "list", "(", "range", "(", "len", "(", "expert_states_traj", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "shuffle_inds", ")", "\n", "", "elif", "rank_identifier", "==", "'reward'", ":", "\n", "    ", "sort_inds", "=", "np", ".", "argsort", "(", "traj_sum_rewards", ")", "[", ":", ":", "-", "1", "]", "\n", "shuffle_inds", "=", "list", "(", "sort_inds", ")", "\n", "", "elif", "rank_identifier", "==", "'origin'", ":", "\n", "    ", "shuffle_inds", "=", "list", "(", "range", "(", "len", "(", "expert_states_traj", ")", ")", ")", "\n", "\n", "", "if", "num_trajectories", "is", "None", ":", "\n", "    ", "num_trajectories", "=", "len", "(", "shuffle_inds", ")", "\n", "", "shuffle_inds", "=", "shuffle_inds", "[", ":", "num_trajectories", "]", "\n", "expert_states_traj", "=", "[", "expert_states_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "expert_actions_traj", "=", "[", "expert_actions_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "expert_next_states_traj", "=", "[", "expert_next_states_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "expert_next_actions_traj", "=", "[", "expert_next_actions_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "expert_rewards_traj", "=", "[", "expert_rewards_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "expert_dones_traj", "=", "[", "expert_dones_traj", "[", "i", "]", "for", "i", "in", "shuffle_inds", "]", "\n", "\n", "def", "concat_trajectories", "(", "trajectories", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "trajectories", ",", "0", ")", "\n", "\n", "", "expert_states", "=", "concat_trajectories", "(", "expert_states_traj", ")", "\n", "expert_actions", "=", "concat_trajectories", "(", "expert_actions_traj", ")", "\n", "expert_next_states", "=", "concat_trajectories", "(", "expert_next_states_traj", ")", "\n", "expert_next_actions", "=", "concat_trajectories", "(", "expert_next_actions_traj", ")", "\n", "expert_rewards", "=", "concat_trajectories", "(", "expert_rewards_traj", ")", "\n", "expert_dones", "=", "concat_trajectories", "(", "expert_dones_traj", ")", "\n", "\n", "return", "expert_states", ",", "expert_actions", ",", "expert_next_states", ",", "expert_next_actions", ",", "expert_rewards", ",", "expert_dones", ",", "traj_sum_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.trans2trajs": [[221, 268], ["range", "expert_states_traj[].append", "expert_actions_traj[].append", "expert_next_states_traj[].append", "expert_next_actions_traj[].append", "expert_rewards_traj[].append", "expert_dones_traj[].append", "traj_sum_rewards.append", "expert_states_traj.append", "expert_actions_traj.append", "expert_next_states_traj.append", "expert_next_actions_traj.append", "expert_rewards_traj.append", "expert_dones_traj.append", "numpy.sum"], "function", ["None"], ["", "def", "trans2trajs", "(", "expert_states", ",", "expert_actions", ",", "expert_next_states", ",", "\n", "expert_next_actions", ",", "expert_rewards", ",", "expert_dones", ",", "traj_len", "=", "1000", ")", ":", "\n", "  ", "\"\"\"Extracts trajectories from transitions.\n\n  Args:\n    expert_states: A numpy array with expert states.\n    expert_actions: A numpy array with expert states.\n    expert_next_states: A numpy array with expert states.\n    expert_dones: A numpy array with expert states.\n    num_trajectories: A number of trajectories to extract.\n\n  Returns:\n      Numpy arrays that contain states, actions, next_states and dones.\n  \"\"\"", "\n", "expert_states_traj", "=", "[", "[", "]", "]", "\n", "expert_actions_traj", "=", "[", "[", "]", "]", "\n", "expert_next_states_traj", "=", "[", "[", "]", "]", "\n", "expert_next_actions_traj", "=", "[", "[", "]", "]", "\n", "expert_rewards_traj", "=", "[", "[", "]", "]", "\n", "expert_dones_traj", "=", "[", "[", "]", "]", "\n", "traj_sum_rewards", "=", "[", "]", "\n", "len", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "expert_states", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "if", "len", "<", "traj_len", ":", "\n", "      ", "expert_states_traj", "[", "-", "1", "]", ".", "append", "(", "expert_states", "[", "i", "]", ")", "\n", "expert_actions_traj", "[", "-", "1", "]", ".", "append", "(", "expert_actions", "[", "i", "]", ")", "\n", "expert_next_states_traj", "[", "-", "1", "]", ".", "append", "(", "expert_next_states", "[", "i", "]", ")", "\n", "expert_next_actions_traj", "[", "-", "1", "]", ".", "append", "(", "expert_next_actions", "[", "i", "]", ")", "\n", "expert_rewards_traj", "[", "-", "1", "]", ".", "append", "(", "expert_rewards", "[", "i", "]", ")", "\n", "expert_dones_traj", "[", "-", "1", "]", ".", "append", "(", "expert_dones", "[", "i", "]", ")", "\n", "len", "+=", "1", "\n", "\n", "", "if", "expert_dones", "[", "i", "]", ":", "\n", "      ", "traj_sum_rewards", ".", "append", "(", "np", ".", "sum", "(", "expert_rewards_traj", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "if", "expert_dones", "[", "i", "]", "and", "i", "<", "expert_states", ".", "shape", "[", "0", "]", "-", "1", ":", "\n", "      ", "expert_states_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_actions_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_next_states_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_next_actions_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_rewards_traj", ".", "append", "(", "[", "]", ")", "\n", "expert_dones_traj", ".", "append", "(", "[", "]", ")", "\n", "len", "=", "0", "\n", "\n", "", "", "return", "expert_states_traj", ",", "expert_actions_traj", ",", "expert_next_states_traj", ",", "expert_next_actions_traj", ",", "expert_rewards_traj", ",", "expert_dones_traj", ",", "traj_sum_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.trajs2trans": [[270, 295], ["utils.subsample_trajectories.concat_trajectories"], "function", ["None"], ["", "def", "trajs2trans", "(", "expert_states_traj", ",", "expert_actions_traj", ",", "expert_next_states_traj", ",", "\n", "expert_next_actions_traj", ",", "expert_dones_traj", ")", ":", "\n", "  ", "\"\"\"Concat transitions back to trajectories.\n\n  Args:\n    expert_states: A numpy array with expert states.\n    expert_actions: A numpy array with expert states.\n    expert_next_states: A numpy array with expert states.\n    expert_dones: A numpy array with expert states.\n    num_trajectories: A number of trajectories to extract.\n\n  Returns:\n      Numpy arrays that contain states, actions, next_states and dones.\n  \"\"\"", "\n", "def", "concat_trajectories", "(", "trajectories", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "trajectories", ",", "0", ")", "\n", "\n", "", "expert_states", "=", "concat_trajectories", "(", "expert_states_traj", ")", "\n", "expert_actions", "=", "concat_trajectories", "(", "expert_actions_traj", ")", "\n", "expert_next_states", "=", "concat_trajectories", "(", "expert_next_states_traj", ")", "\n", "expert_next_actions", "=", "concat_trajectories", "(", "expert_next_actions_traj", ")", "\n", "expert_dones", "=", "concat_trajectories", "(", "expert_dones_traj", ")", "\n", "\n", "return", "expert_states", ",", "expert_actions", ",", "expert_next_states", ",", "expert_next_actions", ",", "expert_dones", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.set_seed": [[296, 302], ["random.seed", "numpy.random.seed", "tensorflow.set_random_seed", "print"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "  ", "seed", "%=", "4294967294", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "print", "(", "\"Using seed {}\"", ".", "format", "(", "seed", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.NormalizeBoxActionWrapper.__init__": [[28, 33], ["gym.ActionWrapper.__init__", "isinstance", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "env", ".", "action_space", ",", "spaces", ".", "Box", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'env %s does not use spaces.Box.'", "%", "str", "(", "env", ")", ")", "\n", "", "super", "(", "NormalizeBoxActionWrapper", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_max_episode_steps", "=", "env", ".", "_max_episode_steps", "# pylint: disable=protected-access", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.NormalizeBoxActionWrapper.action": [[34, 41], ["numpy.clip"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "action", ")", ":", "\n", "# rescale the action", "\n", "    ", "low", ",", "high", "=", "self", ".", "env", ".", "action_space", ".", "low", ",", "self", ".", "env", ".", "action_space", ".", "high", "\n", "scaled_action", "=", "low", "+", "(", "action", "+", "1.0", ")", "*", "(", "high", "-", "low", ")", "/", "2.0", "\n", "scaled_action", "=", "np", ".", "clip", "(", "scaled_action", ",", "low", ",", "high", ")", "\n", "\n", "return", "scaled_action", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.NormalizeBoxActionWrapper.reverse_action": [[42, 46], ["None"], "methods", ["None"], ["", "def", "reverse_action", "(", "self", ",", "scaled_action", ")", ":", "\n", "    ", "low", ",", "high", "=", "self", ".", "env", ".", "action_space", ".", "low", ",", "self", ".", "env", ".", "action_space", ".", "high", "\n", "action", "=", "(", "scaled_action", "-", "low", ")", "*", "2.0", "/", "(", "high", "-", "low", ")", "-", "1.0", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.check_and_normalize_box_actions": [[48, 60], ["isinstance", "absl.logging.info", "normalize_action_wrapper.NormalizeBoxActionWrapper", "numpy.abs().max", "numpy.abs().max", "numpy.abs", "numpy.abs", "numpy.ones_like", "numpy.ones_like"], "function", ["None"], ["", "", "def", "check_and_normalize_box_actions", "(", "env", ")", ":", "\n", "  ", "\"\"\"Wrap env to normalize actions if [low, high] != [-1, 1].\"\"\"", "\n", "low", ",", "high", "=", "env", ".", "action_space", ".", "low", ",", "env", ".", "action_space", ".", "high", "\n", "\n", "if", "isinstance", "(", "env", ".", "action_space", ",", "spaces", ".", "Box", ")", ":", "\n", "    ", "if", "(", "np", ".", "abs", "(", "low", "+", "np", ".", "ones_like", "(", "low", ")", ")", ".", "max", "(", ")", ">", "1e-6", "or", "\n", "np", ".", "abs", "(", "high", "-", "np", ".", "ones_like", "(", "high", ")", ")", ".", "max", "(", ")", ">", "1e-6", ")", ":", "\n", "      ", "logging", ".", "info", "(", "'Normalizing environment actions.'", ")", "\n", "return", "NormalizeBoxActionWrapper", "(", "env", ")", "\n", "\n", "# Environment does not need to be normalized.", "\n", "", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_state_wrapper.NormalizeStateWrapper.__init__": [[24, 28], ["gym.ObservationWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "shift", ",", "scale", ")", ":", "\n", "    ", "super", "(", "NormalizeStateWrapper", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "shift", "=", "shift", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_state_wrapper.NormalizeStateWrapper.observation": [[29, 31], ["None"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "    ", "return", "(", "observation", "+", "self", ".", "shift", ")", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_state_wrapper.NormalizeStateWrapper._max_episode_steps": [[32, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_max_episode_steps", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "_max_episode_steps", "# pylint: disable=protected-access", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper.__init__": [[36, 49], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "super", "(", "AbsorbingWrapper", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "obs_space", "=", "self", ".", "observation_space", "\n", "# self.observation_space = gym.spaces.Box(", "\n", "#     shape=(obs_space.shape[0] + 1,),", "\n", "#     low=obs_space.low[0],", "\n", "#     high=obs_space.high[0],", "\n", "#     dtype=obs_space.dtype)", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "shape", "=", "(", "obs_space", ".", "shape", "[", "0", "]", ",", ")", ",", "\n", "low", "=", "obs_space", ".", "low", "[", "0", "]", ",", "\n", "high", "=", "obs_space", ".", "high", "[", "0", "]", ",", "\n", "dtype", "=", "obs_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper.observation": [[50, 52], ["absorbing_wrapper.AbsorbingWrapper.get_non_absorbing_state"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper.get_non_absorbing_state"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "    ", "return", "self", ".", "get_non_absorbing_state", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper.get_non_absorbing_state": [[53, 64], ["None"], "methods", ["None"], ["", "def", "get_non_absorbing_state", "(", "self", ",", "obs", ")", ":", "\n", "    ", "\"\"\"Converts an original state of the environment into a non-absorbing state.\n\n    Args:\n      obs: a numpy array that corresponds to a state of unwrapped environment.\n\n    Returns:\n      A numpy array corresponding to a non-absorbing state obtained from input.\n    \"\"\"", "\n", "# return np.concatenate([obs, [0]], -1)", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper.get_absorbing_state": [[65, 74], ["numpy.zeros"], "methods", ["None"], ["", "def", "get_absorbing_state", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns an absorbing state that corresponds to the environment.\n\n    Returns:\n      A numpy array that corresponds to an absorbing state.\n    \"\"\"", "\n", "obs", "=", "np", ".", "zeros", "(", "self", ".", "observation_space", ".", "shape", ")", "\n", "# obs[-1] = 1", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.absorbing_wrapper.AbsorbingWrapper._max_episode_steps": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_max_episode_steps", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "_max_episode_steps", "# pylint: disable=protected-access", "\n", "", "", ""]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.__init__.wrapped_il_env": [[25, 43], ["scripts.wrappers.normalize_action_wrapper.check_and_normalize_box_actions", "scripts.wrappers.absorbing_wrapper.AbsorbingWrapper", "scripts.wrappers.normalize_state_wrapper.NormalizeStateWrapper"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.check_and_normalize_box_actions"], []], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.__init__.wrapped_env": [[45, 63], ["scripts.wrappers.normalize_action_wrapper.check_and_normalize_box_actions", "scripts.wrappers.normalize_state_wrapper.NormalizeStateWrapper"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.normalize_action_wrapper.check_and_normalize_box_actions"], []], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.__init__": [[23, 76], ["agent.Agent.__init__", "numpy.zeros", "float"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "train_b_alpha_entropy", "=", "False", ",", "\n", "train_d_alpha_entropy", "=", "False", ",", "\n", "b_alpha_entropy", "=", "0.0", ",", "\n", "d_alpha_entropy", "=", "0.0", ",", "\n", "b_target_entropy", "=", "None", ",", "\n", "d_target_entropy", "=", "None", ",", "\n", "ensemble_q_lambda", "=", "1.0", ",", "\n", "n_action_samples", "=", "10", ",", "\n", "use_value_fn", "=", "False", ",", "\n", "b_list", "=", "None", ",", "\n", "d_list", "=", "None", ",", "\n", "pred_len", "=", "10", ",", "\n", "beta", "=", "0.6", ",", "\n", "pop_size", "=", "1000", ",", "\n", "kappa", "=", "0.9", ",", "\n", "noise_sigma", "=", "0.08", ",", "\n", "behavior_init_coef", "=", "0.5", ",", "\n", "d_uncertainty_threshold", "=", "None", ",", "\n", "uncertainty_percentile", "=", "90", ",", "\n", "penalty_lambda", "=", "0", ",", "\n", "model_id", "=", "0", ",", "\n", "maxq", "=", "True", ",", "\n", "test_b_only", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_train_b_alpha_entropy", "=", "train_b_alpha_entropy", "\n", "self", ".", "_train_d_alpha_entropy", "=", "train_d_alpha_entropy", "\n", "self", ".", "_b_alpha_entropy", "=", "b_alpha_entropy", "\n", "self", ".", "_d_alpha_entropy", "=", "d_alpha_entropy", "\n", "self", ".", "_b_target_entropy", "=", "b_target_entropy", "\n", "self", ".", "_d_target_entropy", "=", "d_target_entropy", "\n", "self", ".", "_ensemble_q_lambda", "=", "ensemble_q_lambda", "\n", "self", ".", "_n_action_samples", "=", "n_action_samples", "\n", "self", ".", "_use_value_fn", "=", "use_value_fn", "# if add the predicted return to the cumulative rewards", "\n", "self", ".", "_b_list", "=", "b_list", "\n", "self", ".", "_d_list", "=", "d_list", "\n", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "maxq", "=", "maxq", "\n", "self", ".", "_test_b_only", "=", "test_b_only", "\n", "# offline MPPI parameters", "\n", "self", ".", "pred_len", "=", "pred_len", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "pop_size", "=", "pop_size", "\n", "self", ".", "kappa", "=", "kappa", "\n", "self", ".", "noise_sigma", "=", "noise_sigma", "\n", "self", ".", "behavior_init_coef", "=", "behavior_init_coef", "\n", "self", ".", "prev_sol", "=", "None", "\n", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "past_action", "=", "np", ".", "zeros", "(", "self", ".", "_a_dim", ")", "\n", "self", ".", "_a_min", "=", "float", "(", "self", ".", "_action_spec", ".", "minimum", ")", "\n", "self", ".", "d_uncertainty_threshold", "=", "d_uncertainty_threshold", "\n", "self", ".", "_uncertainty_percentile", "=", "uncertainty_percentile", "\n", "self", ".", "_penalty_lambda", "=", "penalty_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_fns": [[77, 105], ["mopp_bc_agent.AgentModule", "mopp_bc_agent.Agent._get_dynamic", "mopp_bc_agent.Agent._get_behavior", "mopp_bc_agent.Agent._get_behavior_sample", "mopp_bc_agent.Agent._get_dynamic_diff", "mopp_bc_agent.Agent._get_value_fn", "mopp_bc_agent.Agent._agent_module.assign_alpha_entropy", "numpy.arange", "numpy.arange", "mopp_bc_agent.Agent._get_behavior_sample", "mopp_bc_agent.Agent._get_behavior_sample_maxq", "len", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_diff", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_value_fn", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.assign_alpha_entropy", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample_maxq"], ["", "def", "_build_fns", "(", "self", ")", ":", "\n", "        ", "self", ".", "_agent_module", "=", "AgentModule", "(", "modules", "=", "self", ".", "_modules", ")", "\n", "self", ".", "_b_fns", "=", "self", ".", "_agent_module", ".", "b_nets", "\n", "self", ".", "_d_fns", "=", "self", ".", "_agent_module", ".", "d_nets", "\n", "self", ".", "_q_fns", "=", "self", ".", "_agent_module", ".", "q_nets", "\n", "if", "self", ".", "_b_list", "is", "None", ":", "\n", "            ", "self", ".", "_b_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_b_fns", ")", ")", "\n", "", "if", "self", ".", "_d_list", "is", "None", ":", "\n", "            ", "self", ".", "_d_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_d_fns", ")", ")", "\n", "", "self", ".", "dynamic", "=", "self", ".", "_get_dynamic", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "self", ".", "behavior", "=", "self", ".", "_get_behavior", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ")", "\n", "if", "not", "self", ".", "maxq", ":", "\n", "            ", "self", ".", "behavior_maxq", "=", "self", ".", "_get_behavior_sample", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "\n", "self", ".", "noise_sigma", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "behavior_maxq", "=", "self", ".", "_get_behavior_sample_maxq", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "\n", "self", ".", "noise_sigma", ")", "\n", "", "self", ".", "_behavior_sample", "=", "self", ".", "_get_behavior_sample", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "None", ")", "\n", "self", ".", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_diff", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "self", ".", "value_fn", "=", "self", ".", "_get_value_fn", "(", "[", "self", ".", "_agent_module", ".", "q_nets", "[", "i", "]", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_agent_module", ".", "q_nets", ")", ")", "]", ")", "\n", "if", "self", ".", "_b_target_entropy", "is", "None", ":", "\n", "            ", "self", ".", "_b_target_entropy", "=", "-", "self", ".", "_action_spec", ".", "shape", "[", "0", "]", "\n", "", "if", "self", ".", "_d_target_entropy", "is", "None", ":", "\n", "            ", "self", ".", "_d_target_entropy", "=", "-", "(", "self", ".", "_observation_spec", ".", "shape", "[", "0", "]", "+", "1", ")", "\n", "", "self", ".", "_get_b_alpha_entropy", "=", "self", ".", "_agent_module", ".", "get_b_alpha_entropy", "\n", "self", ".", "_get_d_alpha_entropy", "=", "self", ".", "_agent_module", ".", "get_d_alpha_entropy", "\n", "self", ".", "_agent_module", ".", "assign_alpha_entropy", "(", "self", ".", "_b_alpha_entropy", ",", "self", ".", "_d_alpha_entropy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_b_vars": [[106, 108], ["None"], "methods", ["None"], ["", "def", "_get_b_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "b_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_d_vars": [[109, 111], ["None"], "methods", ["None"], ["", "def", "_get_d_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "d_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_q_vars": [[112, 114], ["None"], "methods", ["None"], ["", "def", "_get_q_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "q_source_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_b_weight_norm": [[115, 122], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_b_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "b_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_d_weight_norm": [[123, 130], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_d_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "d_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_q_weight_norm": [[131, 138], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_q_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "q_source_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.ensemble_q": [[139, 143], ["tensorflow.reduce_min", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "ensemble_q", "(", "self", ",", "qs", ")", ":", "\n", "        ", "lambda_", "=", "self", ".", "_ensemble_q_lambda", "\n", "return", "(", "lambda_", "*", "tf", ".", "reduce_min", "(", "qs", ",", "axis", "=", "-", "1", ")", "\n", "+", "(", "1", "-", "lambda_", ")", "*", "tf", ".", "reduce_max", "(", "qs", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._ensemble_q2_target": [[144, 146], ["mopp_bc_agent.Agent.ensemble_q"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.ensemble_q"], ["", "def", "_ensemble_q2_target", "(", "self", ",", "q2_targets", ")", ":", "\n", "        ", "return", "self", ".", "ensemble_q", "(", "q2_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_b_loss": [[147, 168], ["scripts.utils.clip_by_eps", "tensorflow.add_n", "mopp_bc_agent.Agent._get_b_weight_norm", "collections.OrderedDict", "b_fn.get_log_density", "b_fn", "tensorflow.reduce_mean", "b_losses.append", "mopp_bc_agent.Agent._get_b_alpha_entropy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.clip_by_eps", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_weight_norm", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.get_log_density"], ["", "def", "_build_b_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "a_b", "=", "batch", "[", "'a1'", "]", "\n", "a_b", "=", "utils", ".", "clip_by_eps", "(", "a_b", ",", "self", ".", "_action_spec", ",", "CLIP_EPS", ")", "\n", "b_losses", "=", "[", "]", "\n", "for", "b_fn", "in", "self", ".", "_b_fns", ":", "\n", "            ", "log_pi_a_b", "=", "b_fn", ".", "get_log_density", "(", "s", ",", "a_b", ")", "\n", "_", ",", "_", ",", "log_pi_a_p", "=", "b_fn", "(", "s", ")", "\n", "b_loss_", "=", "tf", ".", "reduce_mean", "(", "\n", "self", ".", "_get_b_alpha_entropy", "(", ")", "*", "log_pi_a_p", "\n", "-", "log_pi_a_b", ")", "\n", "b_losses", ".", "append", "(", "b_loss_", ")", "\n", "", "b_loss", "=", "tf", ".", "add_n", "(", "b_losses", ")", "\n", "b_w_norm", "=", "self", ".", "_get_b_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "b_w_norm", "\n", "loss", "=", "b_loss", "+", "norm_loss", "\n", "# Construct information about current training.", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'b_loss'", "]", "=", "b_loss", "\n", "info", "[", "'b_norm'", "]", "=", "b_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_b_ae_loss": [[169, 182], ["mopp_bc_agent.Agent._get_b_alpha_entropy", "tensorflow.reduce_mean", "collections.OrderedDict", "b_fn", "tensorflow.reduce_mean.append", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_build_b_ae_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "b_ae_loss", "=", "[", "]", "\n", "alpha", "=", "self", ".", "_get_b_alpha_entropy", "(", ")", "\n", "for", "b_fn", "in", "self", ".", "_b_fns", ":", "\n", "            ", "_", ",", "_", ",", "log_pi_a", "=", "b_fn", "(", "s", ")", "\n", "b_ae_loss", ".", "append", "(", "tf", ".", "reduce_mean", "(", "alpha", "*", "(", "-", "log_pi_a", "-", "self", ".", "_b_target_entropy", ")", ")", ")", "\n", "", "b_ae_loss", "=", "tf", ".", "reduce_mean", "(", "b_ae_loss", ")", "\n", "# Construct information about current training.", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'b_ae_loss'", "]", "=", "b_ae_loss", "\n", "info", "[", "'b_alpha_entropy'", "]", "=", "alpha", "\n", "return", "b_ae_loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_d_loss": [[183, 204], ["tensorflow.add_n", "mopp_bc_agent.Agent._get_d_weight_norm", "collections.OrderedDict", "d_fn.get_log_density", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "d_losses.append", "mopp_bc_agent.Agent._get_d_alpha_entropy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_weight_norm", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.get_log_density"], ["", "def", "_build_d_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s1", "=", "batch", "[", "'s1'", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "r", "=", "batch", "[", "'r'", "]", "\n", "d_losses", "=", "[", "]", "\n", "for", "d_fn", "in", "self", ".", "_d_fns", ":", "\n", "            ", "log_pi_s_real", ",", "log_pi_s_pred", "=", "d_fn", ".", "get_log_density", "(", "s1", ",", "a1", ",", "s2", ",", "r", ")", "\n", "log_pi_s_real", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_real", ",", "axis", "=", "-", "1", ")", "\n", "log_pi_s_pred", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_pred", ",", "axis", "=", "-", "1", ")", "\n", "d_loss_", "=", "tf", ".", "reduce_mean", "(", "self", ".", "_get_d_alpha_entropy", "(", ")", "*", "log_pi_s_pred", "-", "log_pi_s_real", ")", "\n", "d_losses", ".", "append", "(", "d_loss_", ")", "\n", "", "d_loss", "=", "tf", ".", "add_n", "(", "d_losses", ")", "\n", "d_w_norm", "=", "self", ".", "_get_d_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "d_w_norm", "\n", "loss", "=", "d_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'d_loss'", "]", "=", "d_loss", "\n", "info", "[", "'d_norm'", "]", "=", "d_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_d_ae_loss": [[205, 220], ["mopp_bc_agent.Agent._get_d_alpha_entropy", "tensorflow.reduce_mean", "collections.OrderedDict", "d_fn", "tensorflow.reduce_sum", "tensorflow.reduce_mean.append", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_build_d_ae_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "a", "=", "batch", "[", "'a1'", "]", "\n", "d_ae_loss", "=", "[", "]", "\n", "alpha", "=", "self", ".", "_get_d_alpha_entropy", "(", ")", "\n", "for", "d_fn", "in", "self", ".", "_d_fns", ":", "\n", "            ", "_", ",", "_", ",", "log_pi_s_pred", ",", "_", "=", "d_fn", "(", "s", ",", "a", ")", "\n", "log_pi_s_pred", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_pred", ",", "axis", "=", "-", "1", ")", "\n", "d_ae_loss", ".", "append", "(", "tf", ".", "reduce_mean", "(", "alpha", "*", "(", "-", "log_pi_s_pred", "-", "self", ".", "_d_target_entropy", ")", ")", ")", "\n", "", "d_ae_loss", "=", "tf", ".", "reduce_mean", "(", "d_ae_loss", ")", "\n", "# Construct information about current training.", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'d_ae_loss'", "]", "=", "d_ae_loss", "\n", "info", "[", "'d_alpha_entropy'", "]", "=", "alpha", "\n", "return", "d_ae_loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_q_loss": [[221, 257], ["tensorflow.stack", "mopp_bc_agent.Agent._ensemble_q2_target", "tensorflow.stop_gradient", "tensorflow.add_n", "mopp_bc_agent.Agent._get_q_weight_norm", "collections.OrderedDict", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "q_fn_target", "q_fn", "q1_preds.append", "tensorflow.stack.append", "tensorflow.reduce_mean", "q_losses.append", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._ensemble_q2_target", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_weight_norm"], ["", "def", "_build_q_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s1", "=", "batch", "[", "'s1'", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "a2_b", "=", "batch", "[", "'a2'", "]", "\n", "r", "=", "batch", "[", "'r'", "]", "\n", "dsc", "=", "batch", "[", "'dsc'", "]", "\n", "\n", "q2_targets", "=", "[", "]", "\n", "q1_preds", "=", "[", "]", "\n", "for", "q_fn", ",", "q_fn_target", "in", "self", ".", "_q_fns", ":", "\n", "            ", "q2_target_", "=", "q_fn_target", "(", "s2", ",", "a2_b", ")", "\n", "q1_pred", "=", "q_fn", "(", "s1", ",", "a1", ")", "\n", "q1_preds", ".", "append", "(", "q1_pred", ")", "\n", "q2_targets", ".", "append", "(", "q2_target_", ")", "\n", "", "q2_targets", "=", "tf", ".", "stack", "(", "q2_targets", ",", "axis", "=", "-", "1", ")", "\n", "q2_target", "=", "self", ".", "_ensemble_q2_target", "(", "q2_targets", ")", "\n", "v2_target", "=", "q2_target", "\n", "q1_target", "=", "tf", ".", "stop_gradient", "(", "r", "+", "dsc", "*", "self", ".", "_discount", "*", "v2_target", ")", "\n", "q_losses", "=", "[", "]", "\n", "for", "q1_pred", "in", "q1_preds", ":", "\n", "            ", "q_loss_", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q1_pred", "-", "q1_target", ")", ")", "\n", "q_losses", ".", "append", "(", "q_loss_", ")", "\n", "", "q_loss", "=", "tf", ".", "add_n", "(", "q_losses", ")", "\n", "q_w_norm", "=", "self", ".", "_get_q_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "q_w_norm", "\n", "loss", "=", "q_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'q_loss'", "]", "=", "q_loss", "\n", "info", "[", "'q_norm'", "]", "=", "q_w_norm", "\n", "info", "[", "'r_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "r", ")", "\n", "info", "[", "'dsc_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "dsc", ")", "\n", "info", "[", "'q2_target_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "q2_target", ")", "\n", "info", "[", "'q1_target_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "q1_target", ")", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_source_target_vars": [[258, 261], ["None"], "methods", ["None"], ["", "def", "_get_source_target_vars", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "_agent_module", ".", "q_source_variables", ",", "\n", "self", ".", "_agent_module", ".", "q_target_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_optimizers": [[262, 269], ["scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer"], ["", "def", "_build_optimizers", "(", "self", ")", ":", "\n", "        ", "opts", "=", "self", ".", "_optimizers", "\n", "self", ".", "_b_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "0", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "0", "]", "[", "1", "]", ")", "\n", "self", ".", "_d_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "1", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "1", "]", "[", "1", "]", ")", "\n", "self", ".", "_b_ae_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "2", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "2", "]", "[", "1", "]", ")", "\n", "self", ".", "_d_ae_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "3", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "3", "]", "[", "1", "]", ")", "\n", "self", ".", "_q_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "4", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "4", "]", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_step": [[270, 273], ["None"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_b": [[274, 284], ["tape.gradient", "tuple", "mopp_bc_agent.Agent._b_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_bc_agent.Agent._build_b_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_b", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_b_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_b_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_d": [[285, 295], ["tape.gradient", "tuple", "mopp_bc_agent.Agent._d_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_bc_agent.Agent._build_d_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_d", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_d_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_d_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_q": [[296, 309], ["tensorflow.equal", "tape.gradient", "tuple", "mopp_bc_agent.Agent._q_optimizer.apply_gradients", "mopp_bc_agent.Agent._get_source_target_vars", "mopp_bc_agent.Agent._update_target_fns", "tensorflow.GradientTape", "tape.watch", "mopp_bc_agent.Agent._build_q_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_source_target_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._update_target_fns", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_q", "(", "self", ",", "batch", ",", "step", ")", ":", "\n", "        ", "if", "tf", ".", "equal", "(", "step", "%", "self", ".", "_update_freq", ",", "0", ")", ":", "\n", "            ", "source_vars", ",", "target_vars", "=", "self", ".", "_get_source_target_vars", "(", ")", "\n", "self", ".", "_update_target_fns", "(", "source_vars", ",", "target_vars", ")", "\n", "", "vars_", "=", "self", ".", "_q_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_q_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_q_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_b_ae": [[310, 320], ["tape.gradient", "tuple", "mopp_bc_agent.Agent._b_ae_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_bc_agent.Agent._build_b_ae_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_ae_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_b_ae", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_b_ae_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_b_ae_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_b_ae_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._optimize_d_ae": [[321, 331], ["tape.gradient", "tuple", "mopp_bc_agent.Agent._d_ae_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_bc_agent.Agent._build_d_ae_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_ae_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_d_ae", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_d_ae_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_d_ae_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_d_ae_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._init_vars": [[332, 342], ["mopp_bc_agent.Agent._build_b_loss", "mopp_bc_agent.Agent._build_d_loss", "mopp_bc_agent.Agent._build_q_loss", "mopp_bc_agent.Agent._get_b_vars", "mopp_bc_agent.Agent._get_d_vars", "mopp_bc_agent.Agent._get_q_vars"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_vars"], ["", "def", "_init_vars", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "# self._build_d_loss_dnn(batch)", "\n", "self", ".", "_build_q_loss", "(", "batch", ")", "\n", "self", ".", "_b_vars", "=", "self", ".", "_get_b_vars", "(", ")", "\n", "self", ".", "_d_vars", "=", "self", ".", "_get_d_vars", "(", ")", "\n", "self", ".", "_q_vars", "=", "self", ".", "_get_q_vars", "(", ")", "\n", "self", ".", "_b_ae_vars", "=", "self", ".", "_agent_module", ".", "b_ae_variables", "\n", "self", ".", "_d_ae_vars", "=", "self", ".", "_agent_module", ".", "d_ae_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_checkpointer": [[343, 362], ["tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "dict"], "methods", ["None"], ["", "def", "_build_checkpointer", "(", "self", ")", ":", "\n", "        ", "state_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "self", ".", "_agent_module", ",", "\n", "global_step", "=", "self", ".", "_global_step", ",", "\n", ")", "\n", "behavior_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "policy", "=", "self", ".", "_agent_module", ".", "b_nets", ",", "\n", ")", "\n", "dynamics_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "dynamics", "=", "self", ".", "_agent_module", ".", "d_nets", ",", "\n", ")", "\n", "q_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "q", "=", "self", ".", "_agent_module", ".", "q_nets", ",", "\n", ")", "\n", "return", "dict", "(", "\n", "state", "=", "state_ckpt", ",", "\n", "behavior", "=", "behavior_ckpt", ",", "\n", "dynamics", "=", "dynamics_ckpt", ",", "\n", "q_fn", "=", "q_ckpt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.train_behavior_step": [[363, 373], ["collections.OrderedDict", "mopp_bc_agent.Agent._get_train_batch", "mopp_bc_agent.Agent._optimize_b", "mopp_bc_agent.Agent.items", "mopp_bc_agent.Agent._optimize_b_ae", "mopp_bc_agent.Agent.update", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b_ae"], ["", "def", "train_behavior_step", "(", "self", ")", ":", "\n", "        ", "train_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_b", "(", "train_batch", ")", "\n", "if", "self", ".", "_train_b_alpha_entropy", ":", "\n", "            ", "ae_info", "=", "self", ".", "_optimize_b_ae", "(", "train_batch", ")", "\n", "info", ".", "update", "(", "ae_info", ")", "\n", "", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_b_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.test_behavior": [[374, 384], ["collections.OrderedDict", "enumerate", "b_fn", "tensorflow.reduce_mean", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_behavior", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "s", "=", "_batch", "[", "'s1'", "]", "\n", "a_b", "=", "_batch", "[", "'a1'", "]", "\n", "test_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "b_fn", "in", "enumerate", "(", "self", ".", "_b_fns", ")", ":", "\n", "            ", "a_p", ",", "_", ",", "_", "=", "b_fn", "(", "s", ")", "\n", "a_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "a_p", "-", "a_b", ")", ")", "\n", "test_b_info", "[", "f'b{i}_mse'", "]", "=", "a_error", "\n", "", "return", "test_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.write_b_train_summary": [[385, 391], ["mopp_bc_agent.Agent._get_train_batch", "mopp_bc_agent.Agent.test_behavior", "mopp_bc_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_b_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_b_info", "=", "self", ".", "test_behavior", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_b_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.save_behavior_model": [[392, 394], ["mopp_bc_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.restore_behavior_model": [[395, 397], ["mopp_bc_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.train_dynamics_step": [[398, 408], ["collections.OrderedDict", "mopp_bc_agent.Agent._get_train_batch", "mopp_bc_agent.Agent._optimize_d", "mopp_bc_agent.Agent.items", "mopp_bc_agent.Agent._optimize_d_ae", "mopp_bc_agent.Agent.update", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d_ae"], ["", "def", "train_dynamics_step", "(", "self", ")", ":", "\n", "        ", "train_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_d", "(", "train_batch", ")", "\n", "if", "self", ".", "_train_d_alpha_entropy", ":", "\n", "            ", "ae_info", "=", "self", ".", "_optimize_d_ae", "(", "train_batch", ")", "\n", "info", ".", "update", "(", "ae_info", ")", "\n", "", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_d_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.test_dynamics": [[409, 425], ["collections.OrderedDict", "enumerate", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "d_fn", "tensorflow.square", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_dynamics", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "test_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "d_fn", "in", "enumerate", "(", "self", ".", "_d_fns", ")", ":", "\n", "            ", "_p", "=", "d_fn", "(", "s1", ",", "a1", ")", "[", "0", "]", "\n", "s_p", "=", "_p", "[", ":", ",", ":", "-", "1", "]", "\n", "r_p", "=", "_p", "[", ":", ",", "-", "1", "]", "\n", "s_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "s_p", "-", "s2", ")", ")", "\n", "r_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "r_p", "-", "r", ")", ")", "\n", "test_d_info", "[", "f'd{i}_s_mse'", "]", "=", "s_error", "\n", "test_d_info", "[", "f'd{i}_r_mse'", "]", "=", "r_error", "\n", "", "return", "test_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.write_d_train_summary": [[426, 432], ["mopp_bc_agent.Agent._get_train_batch", "mopp_bc_agent.Agent.test_dynamics", "mopp_bc_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamics", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_d_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_d_info", "=", "self", ".", "test_dynamics", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_d_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.save_dynamics_model": [[433, 435], ["mopp_bc_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.restore_dynamics_model": [[436, 438], ["mopp_bc_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.train_q_step": [[439, 447], ["tensorflow.constant", "collections.OrderedDict", "mopp_bc_agent.Agent._get_train_batch", "mopp_bc_agent.Agent._optimize_q", "mopp_bc_agent.Agent.items", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_q"], ["", "def", "train_q_step", "(", "self", ",", "step", ")", ":", "\n", "        ", "step", "=", "tf", ".", "constant", "(", "step", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "train_q_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_q", "(", "train_batch", ",", "step", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_q_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_q_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.save_q_model": [[448, 450], ["mopp_bc_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.restore_q_model": [[451, 453], ["mopp_bc_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.test_behavior_all_data": [[454, 465], ["int", "range", "numpy.mean", "mopp_bc_agent.Agent._get_batch", "a_pred.append", "a_real.append", "numpy.square", "numpy.arange", "mopp_bc_agent.Agent.behavior().numpy", "a1.numpy", "numpy.array", "numpy.array", "mopp_bc_agent.Agent.behavior"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_behavior_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "a_pred", ",", "a_real", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "a_pred", ".", "append", "(", "self", ".", "behavior", "(", "s1", ",", "id", "=", "self", ".", "model_id", ")", ".", "numpy", "(", ")", ")", "\n", "a_real", ".", "append", "(", "a1", ".", "numpy", "(", ")", ")", "\n", "", "a_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "a_pred", ")", "-", "np", ".", "array", "(", "a_real", ")", ")", ")", "\n", "return", "a_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent.test_dynamic_all_data": [[466, 483], ["int", "range", "numpy.mean", "numpy.mean", "mopp_bc_agent.Agent._get_batch", "mopp_bc_agent.Agent.dynamic", "s_pred.append", "r_pred.append", "s_real.append", "r_real.append", "numpy.square", "numpy.square", "numpy.arange", "s_p.numpy", "r_p.numpy", "s2.numpy", "r.numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_dynamic_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "s_pred", ",", "r_pred", ",", "s_real", ",", "r_real", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "s_p", ",", "r_p", "=", "self", ".", "dynamic", "(", "s1", ",", "a1", ",", "id", "=", "0", ")", "\n", "s_pred", ".", "append", "(", "s_p", ".", "numpy", "(", ")", ")", "\n", "r_pred", ".", "append", "(", "r_p", ".", "numpy", "(", ")", ")", "\n", "s_real", ".", "append", "(", "s2", ".", "numpy", "(", ")", ")", "\n", "r_real", ".", "append", "(", "r", ".", "numpy", "(", ")", ")", "\n", "", "s_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "s_pred", ")", "-", "np", ".", "array", "(", "s_real", ")", ")", ")", "\n", "r_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "r_pred", ")", "-", "np", ".", "array", "(", "r_real", ")", ")", ")", "\n", "return", "s_mse", ",", "r_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._build_test_policies": [[484, 489], ["None"], "methods", ["None"], ["", "def", "_build_test_policies", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_b_only", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'bc'", "]", "=", "self", ".", "_behavior_policy", "\n", "", "else", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'MOPP-BC'", "]", "=", "self", ".", "_mopp_bc_sol", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._behavior_policy": [[490, 492], ["mopp_bc_agent.Agent.behavior", "numpy.random.randint", "len"], "methods", ["None"], ["", "", "def", "_behavior_policy", "(", "self", ",", "observation", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "return", "self", ".", "behavior", "(", "observation", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_value_fn": [[493, 501], ["tensorflow.reduce_mean", "out.append", "q_"], "methods", ["None"], ["", "def", "_get_value_fn", "(", "self", ",", "q_fn", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_value_fn", "(", "s", ",", "a", ")", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "q_", "in", "q_fn", ":", "\n", "                ", "out", ".", "append", "(", "q_", "(", "s", ",", "a", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "out", ",", "axis", "=", "0", ")", "\n", "", "return", "_value_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_behavior": [[502, 508], ["None"], "methods", ["None"], ["", "def", "_get_behavior", "(", "self", ",", "behavior", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "return", "behavior", "[", "id", "]", "(", "s", ")", "[", "0", "]", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_behavior_maxq": [[509, 529], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "q_fn", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.stack", "tensorflow.reshape", "tensorflow.gather_nd", "b", "tensorflow.random.normal", "tensorflow.range"], "methods", ["None"], ["", "def", "_get_behavior_maxq", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "q_fn", "=", "self", ".", "_q_fns", "[", "0", "]", "[", "0", "]", "\n", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b", "=", "behavior", "\n", "a", "=", "b", "(", "s", ")", "[", "0", "]", "\n", "s_n", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_n", "=", "tf", ".", "tile", "(", "a", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_n", "+=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "a_n", ".", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", "*", "sigma", "\n", "q_n", "=", "q_fn", "(", "s_n", ",", "a_n", ")", "\n", "q_n", "=", "tf", ".", "reshape", "(", "q_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ")", ")", "# shape: (n_sample, batch_size)", "\n", "a_indices", "=", "tf", ".", "argmax", "(", "q_n", ",", "axis", "=", "0", ")", "\n", "gather_indices", "=", "tf", ".", "stack", "(", "\n", "[", "a_indices", ",", "tf", ".", "range", "(", "s", ".", "shape", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "]", ",", "axis", "=", "-", "1", "\n", ")", "\n", "actions", "=", "tf", ".", "reshape", "(", "a_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "# shape: (n_sample, batch_size, a_dim)", "\n", "action", "=", "tf", ".", "gather_nd", "(", "actions", ",", "gather_indices", ")", "\n", "return", "action", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_behavior_sample_maxq": [[530, 568], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tfd.TransformedDistribution", "tfd.TransformedDistribution.sample", "tensorflow.tile", "q_fn", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.stack", "tensorflow.reshape", "tensorflow.gather_nd", "b_.call_dist", "tensorflow.reduce_max", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow.range", "tensorflow.shape", "tensorflow.shape", "tensorflow_probability.bijectors.AffineScalar"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.call_dist"], ["", "def", "_get_behavior_sample_maxq", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "\"\"\"Scaling the stddev of the behavior\"\"\"", "\n", "tfd", "=", "tfp", ".", "distributions", "\n", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "q_fn", "=", "self", ".", "_q_fns", "[", "0", "]", "[", "0", "]", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b_", "=", "behavior", "[", "id", "]", "\n", "_dist", "=", "b_", ".", "call_dist", "(", "s", ")", "[", "-", "1", "]", "\n", "affine_params", "=", "_dist", ".", "bijector", ".", "bijectors", "[", "-", "1", "]", "\n", "_mean", "=", "affine_params", ".", "shift", "\n", "_std", "=", "affine_params", ".", "scale", "\n", "_mean", "=", "tf", ".", "tile", "(", "_mean", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "_std", "=", "tf", ".", "tile", "(", "_std", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "_std", "=", "_std", "/", "(", "tf", ".", "reduce_max", "(", "_std", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "/", "sigma", ")", "\n", "_new_dist", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "\n", "_dist", "[", "0", "]", ".", "bijector", ".", "bijectors", "[", ":", "-", "1", "]", "\n", "+", "[", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "_mean", ",", "scale", "=", "_std", ")", ",", "]", "\n", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "a_n", "=", "_new_dist", ".", "sample", "(", ")", "\n", "s_n", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "q_n", "=", "q_fn", "(", "s_n", ",", "a_n", ")", "\n", "q_n", "=", "tf", ".", "reshape", "(", "q_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ")", ")", "# shape: (n_sample, batch_size)", "\n", "a_indices", "=", "tf", ".", "argmax", "(", "q_n", ",", "axis", "=", "0", ")", "\n", "gather_indices", "=", "tf", ".", "stack", "(", "\n", "[", "a_indices", ",", "tf", ".", "range", "(", "s", ".", "shape", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "]", ",", "axis", "=", "-", "1", "\n", ")", "\n", "actions", "=", "tf", ".", "reshape", "(", "a_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "# shape: (n_sample, batch_size, a_dim)", "\n", "action", "=", "tf", ".", "gather_nd", "(", "actions", ",", "gather_indices", ")", "\n", "return", "action", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_behavior_sample": [[569, 597], ["tensorflow.constant", "tfd.TransformedDistribution", "tfd.TransformedDistribution.sample", "b_.call_dist", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow.reduce_max", "tensorflow.shape", "tensorflow.shape", "tensorflow_probability.bijectors.AffineScalar"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ActorNetwork.call_dist"], ["", "def", "_get_behavior_sample", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "\"\"\"Scaling the stddev of the behavior\"\"\"", "\n", "tfd", "=", "tfp", ".", "distributions", "\n", "if", "sigma", "is", "not", "None", ":", "\n", "            ", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b_", "=", "behavior", "[", "id", "]", "\n", "_dist", "=", "b_", ".", "call_dist", "(", "s", ")", "[", "-", "1", "]", "\n", "affine_params", "=", "_dist", ".", "bijector", ".", "bijectors", "[", "-", "1", "]", "\n", "_mean", "=", "affine_params", ".", "shift", "\n", "_std", "=", "affine_params", ".", "scale", "\n", "if", "sigma", "is", "not", "None", ":", "\n", "                ", "_std", "=", "_std", "/", "(", "tf", ".", "reduce_max", "(", "_std", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "/", "sigma", ")", "\n", "", "_new_dist", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "\n", "_dist", "[", "0", "]", ".", "bijector", ".", "bijectors", "[", ":", "-", "1", "]", "\n", "+", "[", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "_mean", ",", "scale", "=", "_std", ")", ",", "]", "\n", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "\n", "return", "_new_dist", ".", "sample", "(", ")", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_dynamic": [[598, 608], ["s1.append", "tensorflow.reduce_mean", "d_"], "methods", ["None"], ["", "def", "_get_dynamic", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1", ".", "append", "(", "d_", "(", "s", ",", "a", ")", "[", "0", "]", ")", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._get_dynamic_diff": [[609, 626], ["enumerate", "tensorflow.reduce_max", "s1.append", "tensorflow.linalg.norm", "d_", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_get_dynamic_diff", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "\"\"\"Computing the diff between pairs of the outputs\"\"\"", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "diff", "=", "[", "]", "\n", "for", "i", ",", "d_", "in", "enumerate", "(", "dynamic", ")", ":", "\n", "                ", "s1_", "=", "d_", "(", "s", ",", "a", ")", "[", "0", "]", "\n", "if", "i", ">", "0", ":", "\n", "                    ", "diff", "+=", "[", "sx", "-", "s1_", "for", "sx", "in", "s1", "]", "\n", "", "s1", ".", "append", "(", "s1_", ")", "\n", "", "penalty", "=", "tf", ".", "reduce_max", "(", "tf", ".", "linalg", ".", "norm", "(", "diff", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", ",", "penalty", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._compute_uncertainty_threshold": [[627, 641], ["mopp_bc_agent.Agent._train_data.get_all_data", "all_data[].numpy", "all_data[].numpy", "numpy.array_split", "numpy.array_split", "range", "numpy.concatenate", "numpy.percentile", "print", "numpy.concatenate.append", "mopp_bc_agent.Agent.dynamic_uncertainty"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.get_all_data"], ["", "def", "_compute_uncertainty_threshold", "(", "self", ")", ":", "\n", "        ", "\"\"\"Computing the uncertainty threshold with the real data set\"\"\"", "\n", "all_data", "=", "self", ".", "_train_data", ".", "get_all_data", "(", ")", "\n", "all_s1_np", "=", "all_data", "[", "0", "]", ".", "numpy", "(", ")", "\n", "all_a1_np", "=", "all_data", "[", "2", "]", ".", "numpy", "(", ")", "\n", "penalty", "=", "[", "]", "\n", "num", "=", "5000", "\n", "s1_split", "=", "np", ".", "array_split", "(", "all_s1_np", ",", "num", ")", "\n", "a1_split", "=", "np", ".", "array_split", "(", "all_a1_np", ",", "num", ")", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "            ", "penalty", ".", "append", "(", "self", ".", "dynamic_uncertainty", "(", "s1_split", "[", "i", "]", ",", "a1_split", "[", "i", "]", ")", "[", "-", "1", "]", ")", "\n", "", "penalty", "=", "np", ".", "concatenate", "(", "penalty", ")", "\n", "self", ".", "d_uncertainty_threshold", "=", "np", ".", "percentile", "(", "penalty", ",", "self", ".", "_uncertainty_percentile", ")", "\n", "print", "(", "f'The dynamics uncertainty threshold that computed from the data set is {self.d_uncertainty_threshold}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._clear_sol": [[642, 645], ["None"], "methods", ["None"], ["", "def", "_clear_sol", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear prev sol\"\"\"", "\n", "self", ".", "prev_sol", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._init_sol": [[646, 656], ["numpy.expand_dims", "numpy.expand_dims.repeat", "mopp_bc_agent.Agent.behavior", "numpy.mean", "numpy.tile", "mean.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "_init_sol", "(", "self", ",", "curr_x", ")", ":", "\n", "        ", "\"\"\"Initialize the actions using the behavior policy\"\"\"", "\n", "curr_x", "=", "np", ".", "expand_dims", "(", "curr_x", ",", "0", ")", "\n", "repeat_curr_x", "=", "curr_x", ".", "repeat", "(", "self", ".", "pop_size", ",", "axis", "=", "0", ")", "\n", "actions", "=", "self", ".", "behavior", "(", "repeat_curr_x", ")", "\n", "mean", "=", "np", ".", "mean", "(", "actions", ",", "axis", "=", "0", ")", "\n", "mean", "=", "np", ".", "tile", "(", "mean", ",", "self", ".", "pred_len", ")", "\n", "mean", "=", "mean", ".", "reshape", "(", "self", ".", "pred_len", ",", "self", ".", "_a_dim", ")", "\n", "\n", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Agent._mopp_bc_sol": [[658, 736], ["noise.astype.astype.astype", "noise.astype.astype.copy", "numpy.tile", "tensorflow.convert_to_tensor", "range", "numpy.array", "numpy.where", "numpy.sum", "numpy.clip", "numpy.sum", "numpy.exp", "len", "mopp_bc_agent.Agent._init_sol", "numpy.random.normal", "mopp_bc_agent.Agent._compute_uncertainty_threshold", "mopp_bc_agent.Agent.behavior_maxq", "mopp_bc_agent.Agent.dynamic_uncertainty", "numpy.array.append", "numpy.concatenate.append", "numpy.where", "len", "numpy.sum", "numpy.percentile", "tensorflow.tile", "mopp_bc_agent.Agent._behavior_sample", "mopp_bc_agent.Agent.value_fn().numpy", "numpy.reshape", "numpy.concatenate", "numpy.array", "numpy.sum", "numpy.sum", "len", "numpy.random.randint", "tensorflow.convert_to_tensor", "numpy.random.randint", "penalty_.numpy", "r.numpy", "numpy.where", "numpy.array", "numpy.random.randint", "numpy.mean", "len", "mopp_bc_agent.Agent.numpy", "len", "len", "mopp_bc_agent.Agent.value_fn", "numpy.array", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_sol", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._compute_uncertainty_threshold"], ["", "def", "_mopp_bc_sol", "(", "self", ",", "observation", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "\"\"\" calculate the optimal inputs\"\"\"", "\n", "if", "len", "(", "observation", ".", "shape", ")", "==", "2", ":", "\n", "            ", "assert", "observation", ".", "shape", "[", "0", "]", "==", "1", "\n", "curr_x", "=", "observation", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "observation", ".", "shape", ")", "==", "1", "\n", "curr_x", "=", "observation", "\n", "# get prev_sol", "\n", "", "if", "self", ".", "prev_sol", "is", "None", ":", "\n", "            ", "self", ".", "prev_sol", "=", "self", ".", "_init_sol", "(", "curr_x", ")", "\n", "# get noised inputs", "\n", "", "noise", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1.0", ",", "size", "=", "(", "self", ".", "pop_size", ",", "self", ".", "pred_len", ",", "\n", "self", ".", "_a_dim", ")", ")", "*", "self", ".", "noise_sigma", "\n", "noise", "=", "noise", ".", "astype", "(", "'float32'", ")", "\n", "noised_inputs", "=", "noise", ".", "copy", "(", ")", "\n", "s", "=", "np", ".", "tile", "(", "curr_x", ",", "(", "self", ".", "pop_size", ",", "1", ")", ")", "\n", "s", "=", "tf", ".", "convert_to_tensor", "(", "s", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rewards", "=", "[", "]", "\n", "penalty", "=", "[", "]", "\n", "if", "self", ".", "d_uncertainty_threshold", "is", "None", ":", "\n", "            ", "self", ".", "_compute_uncertainty_threshold", "(", ")", "\n", "", "for", "t", "in", "range", "(", "self", ".", "pred_len", ")", ":", "\n", "# a_sample = self.behavior(s, np.random.randint(0, len(self._b_fns))) + noise[:, t, :]", "\n", "            ", "a_sample", "=", "self", ".", "behavior_maxq", "(", "s", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", "\n", "a_sample_mix", "=", "self", ".", "beta", "*", "self", ".", "prev_sol", "[", "t", ",", ":", "]", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "a_sample", ".", "numpy", "(", ")", "\n", "noised_inputs", "[", ":", ",", "t", ",", ":", "]", "=", "a_sample_mix", "\n", "s", ",", "r", ",", "penalty_", "=", "self", ".", "dynamic_uncertainty", "(", "s", ",", "\n", "tf", ".", "convert_to_tensor", "(", "a_sample_mix", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_d_list", ")", ")", ")", "\n", "penalty", ".", "append", "(", "penalty_", ".", "numpy", "(", ")", ")", "\n", "rewards", ".", "append", "(", "r", ".", "numpy", "(", ")", ")", "\n", "# filtrating the trajectories", "\n", "", "penalty", "=", "np", ".", "array", "(", "penalty", ")", "# shape: (pred_len, pop_size)", "\n", "penalty_label", "=", "np", ".", "where", "(", "penalty", ">", "self", ".", "d_uncertainty_threshold", ",", "penalty", ",", "0", ")", "# shape: (pred_len, pop_size)", "\n", "penalty_label_sum", "=", "np", ".", "sum", "(", "penalty_label", ",", "axis", "=", "0", ")", "\n", "select_ids", "=", "np", ".", "where", "(", "penalty_label_sum", "==", "0", ")", "[", "0", "]", "\n", "if", "len", "(", "select_ids", ")", "<", "0.2", "*", "self", ".", "pop_size", ":", "\n", "# choose the top trajectories that with low penalty", "\n", "            ", "traj_penalty", "=", "np", ".", "sum", "(", "penalty", ",", "axis", "=", "0", ")", "\n", "s_thres", "=", "np", ".", "percentile", "(", "traj_penalty", ",", "20", ")", "\n", "select_ids", "=", "np", ".", "where", "(", "traj_penalty", "<=", "s_thres", ")", "[", "0", "]", "\n", "rewards", "=", "np", ".", "array", "(", "rewards", ")", "-", "self", ".", "_penalty_lambda", "*", "penalty_label", "\n", "# print('All the trajectories exceed the uncertainty threshold!')", "\n", "# clip actions", "\n", "", "noised_inputs", "=", "noised_inputs", "[", "select_ids", "]", "\n", "noised_inputs", "=", "np", ".", "clip", "(", "\n", "noised_inputs", ",", "self", ".", "_a_min", ",", "self", ".", "_a_max", ")", "\n", "# calc reward", "\n", "if", "self", ".", "_use_value_fn", ":", "\n", "            ", "s", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_last", "=", "self", ".", "_behavior_sample", "(", "s", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", "\n", "q_last", "=", "self", ".", "value_fn", "(", "s", ",", "a_last", ")", ".", "numpy", "(", ")", "\n", "q_last", "=", "np", ".", "reshape", "(", "q_last", ",", "[", "self", ".", "_n_action_samples", ",", "-", "1", "]", ")", "\n", "v_last", "=", "np", ".", "mean", "(", "q_last", ",", "axis", "=", "0", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "rewards", "=", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "rewards", ")", ",", "v_last", "]", ",", "axis", "=", "0", ")", "# shape: (pred_len+1, pop_size)", "\n", "# a_last = self.behavior_maxq(s, np.random.randint(0, len(self._b_list)))", "\n", "# q_last = self.value_fn(s, a_last).numpy()", "\n", "# q_last = q_last[np.newaxis, :]", "\n", "# rewards = np.concatenate([np.array(rewards), q_last], axis=0)  # shape: (pred_len+1, pop_size)", "\n", "", "rewards", "=", "np", ".", "array", "(", "rewards", ")", "[", ":", ",", "select_ids", "]", "# shape: (pred_len, pop_size)", "\n", "rewards", "=", "np", ".", "sum", "(", "rewards", ",", "axis", "=", "0", ")", "\n", "# mppi update", "\n", "# normalize and get sum of reward", "\n", "# exp_rewards.shape = (N, )", "\n", "exp_rewards", "=", "np", ".", "exp", "(", "self", ".", "kappa", "*", "(", "rewards", "-", "np", ".", "max", "(", "rewards", ")", ")", ")", "\n", "denom", "=", "np", ".", "sum", "(", "exp_rewards", ")", "+", "1e-10", "# avoid numeric error", "\n", "# weight actions", "\n", "weighted_inputs", "=", "exp_rewards", "[", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "*", "noised_inputs", "\n", "sol", "=", "np", ".", "sum", "(", "weighted_inputs", ",", "0", ")", "/", "denom", "\n", "# update", "\n", "self", ".", "prev_sol", "[", ":", "-", "1", "]", "=", "sol", "[", "1", ":", "]", "\n", "self", ".", "prev_sol", "[", "-", "1", "]", "=", "sol", "[", "-", "1", "]", "# last use the terminal input", "\n", "# self.past_action = sol[0]", "\n", "\n", "return", "sol", "[", "0", "]", "[", "np", ".", "newaxis", ",", ":", "]", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule._build_modules": [[741, 760], ["range", "range", "tensorflow.Variable", "tensorflow.Variable", "mopp_bc_agent.AgentModule._b_nets.append", "mopp_bc_agent.AgentModule._d_nets.append", "mopp_bc_agent.AgentModule._q_nets.append", "mopp_bc_agent.AgentModule._modules.b_net_factory", "mopp_bc_agent.AgentModule._modules.d_net_factory", "mopp_bc_agent.AgentModule._modules.q_net_factory", "mopp_bc_agent.AgentModule._modules.q_net_factory"], "methods", ["None"], ["def", "_build_modules", "(", "self", ")", ":", "\n", "        ", "n_b_fns", "=", "self", ".", "_modules", ".", "n_b_fns", "\n", "self", ".", "_b_nets", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n_b_fns", ")", ":", "\n", "            ", "self", ".", "_b_nets", ".", "append", "(", "self", ".", "_modules", ".", "b_net_factory", "(", ")", ")", "\n", "", "self", ".", "_d_nets", "=", "[", "]", "\n", "self", ".", "_q_nets", "=", "[", "]", "\n", "n_q_fns", "=", "self", ".", "_modules", ".", "n_q_fns", "\n", "for", "_rank", "in", "self", ".", "_modules", ".", "d_out_ranks", ":", "\n", "            ", "self", ".", "_d_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "d_net_factory", "(", "_rank", ")", "\n", ")", "\n", "", "for", "_", "in", "range", "(", "n_q_fns", ")", ":", "\n", "            ", "self", ".", "_q_nets", ".", "append", "(", "\n", "[", "self", ".", "_modules", ".", "q_net_factory", "(", ")", ",", "\n", "self", ".", "_modules", ".", "q_net_factory", "(", ")", ",", "]", "# source and target", "\n", ")", "\n", "", "self", ".", "_b_alpha_entropy_var", "=", "tf", ".", "Variable", "(", "1.0", ")", "\n", "self", ".", "_d_alpha_entropy_var", "=", "tf", ".", "Variable", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.get_b_alpha_entropy": [[761, 763], ["scripts.utils.relu_v2"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.relu_v2"], ["", "def", "get_b_alpha_entropy", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "relu_v2", "(", "self", ".", "_b_alpha_entropy_var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.get_d_alpha_entropy": [[764, 766], ["scripts.utils.relu_v2"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.relu_v2"], ["", "def", "get_d_alpha_entropy", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "relu_v2", "(", "self", ".", "_d_alpha_entropy_var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.assign_alpha_entropy": [[767, 770], ["mopp_bc_agent.AgentModule._b_alpha_entropy_var.assign", "mopp_bc_agent.AgentModule._d_alpha_entropy_var.assign"], "methods", ["None"], ["", "def", "assign_alpha_entropy", "(", "self", ",", "b_alpha", ",", "d_alpha", ")", ":", "\n", "        ", "self", ".", "_b_alpha_entropy_var", ".", "assign", "(", "b_alpha", ")", "\n", "self", ".", "_d_alpha_entropy_var", ".", "assign", "(", "d_alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.d_ae_variables": [[771, 774], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_ae_variables", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "_d_alpha_entropy_var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.b_ae_variables": [[775, 778], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_ae_variables", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "_b_alpha_entropy_var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.b_nets": [[779, 782], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_b_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.b_weights": [[783, 789], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_weights", "(", "self", ")", ":", "\n", "        ", "b_weights", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "b_weights", "+=", "b_net", ".", "weights", "\n", "", "return", "b_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.b_variables": [[790, 796], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "vars_", "+=", "b_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.d_nets": [[797, 800], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_d_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.d_weights": [[801, 807], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_weights", "(", "self", ")", ":", "\n", "        ", "d_weights", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "d_weights", "+=", "d_net", ".", "weights", "\n", "", "return", "d_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.d_variables": [[808, 814], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "vars_", "+=", "d_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.q_nets": [[815, 818], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_q_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.q_source_weights": [[819, 825], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_source_weights", "(", "self", ")", ":", "\n", "        ", "q_weights", "=", "[", "]", "\n", "for", "q_net", ",", "_", "in", "self", ".", "_q_nets", ":", "\n", "            ", "q_weights", "+=", "q_net", ".", "weights", "\n", "", "return", "q_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.q_target_weights": [[826, 832], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_target_weights", "(", "self", ")", ":", "\n", "        ", "q_weights", "=", "[", "]", "\n", "for", "_", ",", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "q_weights", "+=", "q_net", ".", "weights", "\n", "", "return", "q_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.q_source_variables": [[833, 839], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_source_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "q_net", ",", "_", "in", "self", ".", "_q_nets", ":", "\n", "            ", "vars_", "+=", "q_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.AgentModule.q_target_variables": [[840, 846], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_target_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "_", ",", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "vars_", "+=", "q_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.Config._get_modules": [[885, 890], ["mopp_bc_agent.get_modules"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.get_modules"], ["    ", "def", "_get_modules", "(", "self", ")", ":", "\n", "        ", "return", "get_modules", "(", "\n", "self", ".", "_agent_flags", ".", "model_params", ",", "\n", "self", ".", "_agent_flags", ".", "action_spec", ",", "\n", "self", ".", "_agent_flags", ".", "observation_spec", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_bc_agent.get_modules": [[848, 881], ["scripts.utils.Flags", "len", "tuple", "scripts.networks.ActorNetwork", "scripts.networks.ADMDynamic", "scripts.networks.CriticNetwork", "numpy.arange", "numpy.arange"], "function", ["None"], ["", "", "def", "get_modules", "(", "model_params", ",", "action_spec", ",", "state_spec", ")", ":", "\n", "    ", "\"\"\"Get agent modules.\"\"\"", "\n", "model_params", ",", "_", ",", "d_out_ranks", "=", "model_params", "\n", "if", "d_out_ranks", "is", "None", ":", "\n", "        ", "d_out_ranks", "=", "[", "np", ".", "arange", "(", "state_spec", ".", "shape", "[", "0", "]", "+", "1", ")", ",", "\n", "np", ".", "arange", "(", "state_spec", ".", "shape", "[", "0", "]", "+", "1", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "", "if", "len", "(", "model_params", ")", "==", "1", ":", "\n", "        ", "model_params", "=", "tuple", "(", "[", "model_params", "[", "0", "]", "]", "*", "2", ")", "\n", "\n", "", "def", "b_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "ActorNetwork", "(", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "model_params", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "", "def", "d_net_factory", "(", "out_rank", ")", ":", "\n", "        ", "return", "networks", ".", "ADMDynamic", "(", "\n", "state_dim", "=", "state_spec", ".", "shape", "[", "0", "]", ",", "\n", "fc_layer_params", "=", "model_params", "[", "1", "]", ",", "\n", "out_reranking", "=", "out_rank", ")", "\n", "\n", "", "def", "q_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "CriticNetwork", "(", "\n", "fc_layer_params", "=", "model_params", "[", "2", "]", "[", "0", "]", ")", "\n", "\n", "", "modules", "=", "utils", ".", "Flags", "(", "\n", "b_net_factory", "=", "b_net_factory", ",", "\n", "d_net_factory", "=", "d_net_factory", ",", "\n", "q_net_factory", "=", "q_net_factory", ",", "\n", "d_out_ranks", "=", "d_out_ranks", ",", "\n", "n_b_fns", "=", "model_params", "[", "0", "]", "[", "1", "]", ",", "\n", "n_q_fns", "=", "model_params", "[", "2", "]", "[", "1", "]", ",", "\n", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.__init__": [[25, 52], ["agent.Agent.__init__", "numpy.zeros", "float"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["def", "__init__", "(", "self", ",", "\n", "use_value_fn", "=", "True", ",", "\n", "b_list", "=", "None", ",", "\n", "d_list", "=", "None", ",", "\n", "pred_len", "=", "10", ",", "\n", "beta", "=", "0.6", ",", "\n", "pop_size", "=", "1000", ",", "\n", "kappa", "=", "0.9", ",", "\n", "noise_sigma", "=", "0.08", ",", "\n", "model_id", "=", "0", ",", "\n", "test_b_only", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_use_value_fn", "=", "use_value_fn", "# if add the predicted return to the cumulative rewards", "\n", "self", ".", "_b_list", "=", "b_list", "\n", "self", ".", "_d_list", "=", "d_list", "\n", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "_test_b_only", "=", "test_b_only", "\n", "# offline MPPI parameters", "\n", "self", ".", "pred_len", "=", "pred_len", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "pop_size", "=", "pop_size", "\n", "self", ".", "kappa", "=", "kappa", "\n", "self", ".", "noise_sigma", "=", "noise_sigma", "\n", "self", ".", "prev_sol", "=", "None", "\n", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "past_action", "=", "np", ".", "zeros", "(", "self", ".", "_a_dim", ")", "\n", "self", ".", "_a_min", "=", "float", "(", "self", ".", "_action_spec", ".", "minimum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_fns": [[53, 65], ["mbop_agent.AgentModule", "mbop_agent.Agent._get_dynamic", "mbop_agent.Agent._get_behavior", "mbop_agent.Agent._get_value_fn", "numpy.arange", "numpy.arange", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_value_fn"], ["", "def", "_build_fns", "(", "self", ")", ":", "\n", "        ", "self", ".", "_agent_module", "=", "AgentModule", "(", "modules", "=", "self", ".", "_modules", ")", "\n", "self", ".", "_b_fns", "=", "self", ".", "_agent_module", ".", "b_nets", "\n", "self", ".", "_d_fns", "=", "self", ".", "_agent_module", ".", "d_nets", "\n", "self", ".", "_q_fns", "=", "self", ".", "_agent_module", ".", "q_nets", "\n", "if", "self", ".", "_b_list", "is", "None", ":", "\n", "            ", "self", ".", "_b_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_b_fns", ")", ")", "\n", "", "if", "self", ".", "_d_list", "is", "None", ":", "\n", "            ", "self", ".", "_d_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_d_fns", ")", ")", "\n", "", "self", ".", "dynamic", "=", "self", ".", "_get_dynamic", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "self", ".", "behavior", "=", "self", ".", "_get_behavior", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ")", "\n", "self", ".", "value_fn", "=", "self", ".", "_get_value_fn", "(", "self", ".", "_agent_module", ".", "q_nets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_b_vars": [[66, 68], ["None"], "methods", ["None"], ["", "def", "_get_b_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "b_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_d_vars": [[69, 71], ["None"], "methods", ["None"], ["", "def", "_get_d_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "d_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_q_vars": [[72, 74], ["None"], "methods", ["None"], ["", "def", "_get_q_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "q_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_b_weight_norm": [[75, 82], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_b_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "b_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_d_weight_norm": [[83, 90], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_d_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "d_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_q_weight_norm": [[91, 98], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_q_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "q_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_b_loss": [[99, 119], ["scripts.utils.clip_by_eps", "tensorflow.add_n", "mbop_agent.Agent._get_b_weight_norm", "collections.OrderedDict", "tensorflow.concat", "b_fn", "tensorflow.reduce_mean", "b_losses.append", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.clip_by_eps", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_weight_norm"], ["", "def", "_build_b_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "a0", "=", "batch", "[", "'a1'", "]", "\n", "s", "=", "batch", "[", "'s2'", "]", "\n", "a_b", "=", "batch", "[", "'a2'", "]", "\n", "a_b", "=", "utils", ".", "clip_by_eps", "(", "a_b", ",", "self", ".", "_action_spec", ",", "CLIP_EPS", ")", "\n", "b_losses", "=", "[", "]", "\n", "for", "b_fn", "in", "self", ".", "_b_fns", ":", "\n", "            ", "input_", "=", "tf", ".", "concat", "(", "(", "s", ",", "a0", ")", ",", "axis", "=", "-", "1", ")", "\n", "a_p", "=", "b_fn", "(", "input_", ")", "\n", "b_loss_", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "a_p", "-", "a_b", ")", ")", "\n", "b_losses", ".", "append", "(", "b_loss_", ")", "\n", "", "b_loss", "=", "tf", ".", "add_n", "(", "b_losses", ")", "\n", "b_w_norm", "=", "self", ".", "_get_b_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "b_w_norm", "\n", "loss", "=", "b_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'b_loss'", "]", "=", "b_loss", "\n", "info", "[", "'b_norm'", "]", "=", "b_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_d_loss": [[120, 141], ["tensorflow.add_n", "mbop_agent.Agent._get_d_weight_norm", "collections.OrderedDict", "tensorflow.concat", "d_fn", "tensorflow.concat", "tensorflow.reduce_mean", "d_losses.append", "tensorflow.square", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_weight_norm"], ["", "def", "_build_d_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s1", "=", "batch", "[", "'s1'", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "r", "=", "batch", "[", "'r'", "]", "\n", "d_losses", "=", "[", "]", "\n", "for", "d_fn", "in", "self", ".", "_d_fns", ":", "\n", "            ", "input_", "=", "tf", ".", "concat", "(", "(", "s1", ",", "a1", ")", ",", "axis", "=", "-", "1", ")", "\n", "output_", "=", "d_fn", "(", "input_", ")", "\n", "target_", "=", "tf", ".", "concat", "(", "[", "s2", ",", "tf", ".", "reshape", "(", "r", ",", "(", "-", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "d_loss_", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "output_", "-", "target_", ")", ")", "\n", "d_losses", ".", "append", "(", "d_loss_", ")", "\n", "", "d_loss", "=", "tf", ".", "add_n", "(", "d_losses", ")", "\n", "d_w_norm", "=", "self", ".", "_get_d_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "d_w_norm", "\n", "loss", "=", "d_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'d_loss'", "]", "=", "d_loss", "\n", "info", "[", "'d_norm'", "]", "=", "d_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_q_loss": [[143, 167], ["tensorflow.reduce_sum", "tensorflow.add_n", "mbop_agent.Agent._get_q_weight_norm", "collections.OrderedDict", "len", "tensorflow.reduce_sum.append", "q_fn", "tensorflow.reduce_mean", "q_losses.append", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_weight_norm"], ["", "def", "_build_q_loss", "(", "self", ",", "batch_list", ")", ":", "\n", "        ", "assert", "len", "(", "batch_list", ")", "==", "self", ".", "pred_len", "+", "1", "\n", "batch", "=", "batch_list", "[", "0", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "# Compute the truncated value function target.", "\n", "q_target", "=", "[", "]", "\n", "for", "batch_", "in", "batch_list", "[", "1", ":", "]", ":", "\n", "            ", "q_target", ".", "append", "(", "batch_", "[", "'r'", "]", ")", "\n", "", "q_target", "=", "tf", ".", "reduce_sum", "(", "q_target", ",", "axis", "=", "0", ")", "\n", "q_losses", "=", "[", "]", "\n", "for", "q_fn", "in", "self", ".", "_q_fns", ":", "\n", "            ", "q_pred", "=", "q_fn", "(", "s2", ",", "a1", ")", "\n", "q_loss_", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q_pred", "-", "q_target", ")", ")", "\n", "q_losses", ".", "append", "(", "q_loss_", ")", "\n", "", "q_loss", "=", "tf", ".", "add_n", "(", "q_losses", ")", "\n", "q_w_norm", "=", "self", ".", "_get_q_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "q_w_norm", "\n", "loss", "=", "q_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'q_loss'", "]", "=", "q_loss", "\n", "info", "[", "'q_norm'", "]", "=", "q_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_optimizers": [[168, 173], ["scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer"], ["", "def", "_build_optimizers", "(", "self", ")", ":", "\n", "        ", "opts", "=", "self", ".", "_optimizers", "\n", "self", ".", "_b_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "0", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "0", "]", "[", "1", "]", ")", "\n", "self", ".", "_d_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "1", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "1", "]", "[", "1", "]", ")", "\n", "self", ".", "_q_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "-", "1", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "-", "1", "]", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._optimize_step": [[174, 177], ["None"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._optimize_b": [[178, 188], ["tape.gradient", "tuple", "mbop_agent.Agent._b_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mbop_agent.Agent._build_b_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_b", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_b_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_b_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._optimize_d": [[189, 199], ["tape.gradient", "tuple", "mbop_agent.Agent._d_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mbop_agent.Agent._build_d_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_d", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_d_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_d_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._optimize_q": [[200, 210], ["tape.gradient", "tuple", "mbop_agent.Agent._q_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mbop_agent.Agent._build_q_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_q", "(", "self", ",", "batch_list", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_q_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_q_loss", "(", "batch_list", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_q_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._init_vars": [[211, 219], ["mbop_agent.Agent._build_b_loss", "mbop_agent.Agent._build_d_loss", "mbop_agent.Agent._get_train_batch_q", "mbop_agent.Agent._build_q_loss", "mbop_agent.Agent._get_b_vars", "mbop_agent.Agent._get_d_vars", "mbop_agent.Agent._get_q_vars"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_train_batch_q", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_vars"], ["", "def", "_init_vars", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "batch_q", "=", "self", ".", "_get_train_batch_q", "(", ")", "\n", "self", ".", "_build_q_loss", "(", "batch_q", ")", "\n", "self", ".", "_b_vars", "=", "self", ".", "_get_b_vars", "(", ")", "\n", "self", ".", "_d_vars", "=", "self", ".", "_get_d_vars", "(", ")", "\n", "self", ".", "_q_vars", "=", "self", ".", "_get_q_vars", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_checkpointer": [[220, 239], ["tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "dict"], "methods", ["None"], ["", "def", "_build_checkpointer", "(", "self", ")", ":", "\n", "        ", "state_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "self", ".", "_agent_module", ",", "\n", "global_step", "=", "self", ".", "_global_step", ",", "\n", ")", "\n", "behavior_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "policy", "=", "self", ".", "_agent_module", ".", "b_nets", ",", "\n", ")", "\n", "dynamics_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "dynamics", "=", "self", ".", "_agent_module", ".", "d_nets", ",", "\n", ")", "\n", "q_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "q", "=", "self", ".", "_agent_module", ".", "q_nets", ",", "\n", ")", "\n", "return", "dict", "(", "\n", "state", "=", "state_ckpt", ",", "\n", "behavior", "=", "behavior_ckpt", ",", "\n", "dynamics", "=", "dynamics_ckpt", ",", "\n", "q_fn", "=", "q_ckpt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.train_behavior_step": [[240, 247], ["collections.OrderedDict", "mbop_agent.Agent._get_train_batch", "mbop_agent.Agent._optimize_b", "mbop_agent.Agent.items", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b"], ["", "def", "train_behavior_step", "(", "self", ")", ":", "\n", "        ", "train_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_b", "(", "train_batch", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_b_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.test_behavior": [[248, 259], ["collections.OrderedDict", "enumerate", "b_fn", "tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_behavior", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "a0", "=", "_batch", "[", "'a1'", "]", "\n", "s", "=", "_batch", "[", "'s2'", "]", "\n", "a_b", "=", "_batch", "[", "'a2'", "]", "\n", "test_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "b_fn", "in", "enumerate", "(", "self", ".", "_b_fns", ")", ":", "\n", "            ", "a_p", "=", "b_fn", "(", "tf", ".", "concat", "(", "(", "s", ",", "a0", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "a_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "a_p", "-", "a_b", ")", ")", "\n", "test_b_info", "[", "f'b{i}_mse'", "]", "=", "a_error", "\n", "", "return", "test_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.write_b_train_summary": [[260, 266], ["mbop_agent.Agent._get_train_batch", "mbop_agent.Agent.test_behavior", "mbop_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_b_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_b_info", "=", "self", ".", "test_behavior", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_b_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.save_behavior_model": [[267, 269], ["mbop_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.restore_behavior_model": [[270, 272], ["mbop_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.train_dynamics_step": [[273, 280], ["collections.OrderedDict", "mbop_agent.Agent._get_train_batch", "mbop_agent.Agent._optimize_d", "mbop_agent.Agent.items", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d"], ["", "def", "train_dynamics_step", "(", "self", ")", ":", "\n", "        ", "train_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_d", "(", "train_batch", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_d_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.test_dynamics": [[281, 297], ["collections.OrderedDict", "enumerate", "d_fn", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.square", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_dynamics", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "test_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "d_fn", "in", "enumerate", "(", "self", ".", "_d_fns", ")", ":", "\n", "            ", "_p", "=", "d_fn", "(", "tf", ".", "concat", "(", "(", "s1", ",", "a1", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "s_p", "=", "_p", "[", ":", ",", ":", "-", "1", "]", "\n", "r_p", "=", "_p", "[", ":", ",", "-", "1", "]", "\n", "s_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "s_p", "-", "s2", ")", ")", "\n", "r_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "r_p", "-", "r", ")", ")", "\n", "test_d_info", "[", "f'd{i}_s_mse'", "]", "=", "s_error", "\n", "test_d_info", "[", "f'd{i}_r_mse'", "]", "=", "r_error", "\n", "", "return", "test_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.write_d_train_summary": [[298, 304], ["mbop_agent.Agent._get_train_batch", "mbop_agent.Agent.test_dynamics", "mbop_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamics", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_d_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_d_info", "=", "self", ".", "test_dynamics", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_d_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.save_dynamics_model": [[305, 307], ["mbop_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.restore_dynamics_model": [[308, 310], ["mbop_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.train_q_step": [[311, 318], ["collections.OrderedDict", "mbop_agent.Agent._get_train_batch_q", "mbop_agent.Agent._optimize_q", "mbop_agent.Agent.items", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_train_batch_q", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_q"], ["", "def", "train_q_step", "(", "self", ",", "step", ")", ":", "\n", "        ", "train_q_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch_list", "=", "self", ".", "_get_train_batch_q", "(", ")", "\n", "info", "=", "self", ".", "_optimize_q", "(", "train_batch_list", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_q_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_q_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_train_batch_q": [[319, 327], ["numpy.random.choice", "range", "mbop_agent.Agent._get_batch", "train_batch_q.append", "mbop_agent.Agent._get_batch"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "_get_train_batch_q", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the train batch for a truncated value function.\"\"\"", "\n", "batch_indices", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "_train_data", ".", "size", "-", "self", ".", "pred_len", ",", "self", ".", "_batch_size", ")", "\n", "train_batch_q", "=", "[", "self", ".", "_get_batch", "(", "batch_indices", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "pred_len", ")", ":", "\n", "            ", "batch_indices", "+=", "1", "\n", "train_batch_q", ".", "append", "(", "self", ".", "_get_batch", "(", "batch_indices", ")", ")", "\n", "", "return", "train_batch_q", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.save_q_model": [[328, 330], ["mbop_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.restore_q_model": [[331, 333], ["mbop_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.test_behavior_all_data": [[334, 346], ["int", "range", "numpy.mean", "mbop_agent.Agent._get_batch", "a_pred.append", "a_real.append", "numpy.square", "numpy.arange", "mbop_agent.Agent.behavior().numpy", "a2.numpy", "numpy.array", "numpy.array", "mbop_agent.Agent.behavior"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_behavior_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "a_pred", ",", "a_real", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a2", "=", "_batch", "[", "'a2'", "]", "\n", "a_pred", ".", "append", "(", "self", ".", "behavior", "(", "s2", ",", "a1", ",", "id", "=", "self", ".", "model_id", ")", ".", "numpy", "(", ")", ")", "\n", "a_real", ".", "append", "(", "a2", ".", "numpy", "(", ")", ")", "\n", "", "a_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "a_pred", ")", "-", "np", ".", "array", "(", "a_real", ")", ")", ")", "\n", "return", "a_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent.test_dynamic_all_data": [[347, 364], ["int", "range", "numpy.mean", "numpy.mean", "mbop_agent.Agent._get_batch", "mbop_agent.Agent.dynamic", "s_pred.append", "r_pred.append", "s_real.append", "r_real.append", "numpy.square", "numpy.square", "numpy.arange", "s_p.numpy", "r_p.numpy", "s2.numpy", "r.numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_dynamic_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "s_pred", ",", "r_pred", ",", "s_real", ",", "r_real", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "s_p", ",", "r_p", "=", "self", ".", "dynamic", "(", "s1", ",", "a1", ",", "id", "=", "self", ".", "model_id", ")", "\n", "s_pred", ".", "append", "(", "s_p", ".", "numpy", "(", ")", ")", "\n", "r_pred", ".", "append", "(", "r_p", ".", "numpy", "(", ")", ")", "\n", "s_real", ".", "append", "(", "s2", ".", "numpy", "(", ")", ")", "\n", "r_real", ".", "append", "(", "r", ".", "numpy", "(", ")", ")", "\n", "", "s_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "s_pred", ")", "-", "np", ".", "array", "(", "s_real", ")", ")", ")", "\n", "r_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "r_pred", ")", "-", "np", ".", "array", "(", "r_real", ")", ")", ")", "\n", "return", "s_mse", ",", "r_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._build_test_policies": [[365, 370], ["None"], "methods", ["None"], ["", "def", "_build_test_policies", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_b_only", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'bc'", "]", "=", "self", ".", "_behavior_policy", "\n", "", "else", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'mbop'", "]", "=", "self", ".", "_mbop_sol", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._behavior_policy": [[371, 373], ["mbop_agent.Agent.behavior", "numpy.random.randint", "len"], "methods", ["None"], ["", "", "def", "_behavior_policy", "(", "self", ",", "observation", ",", "action0", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "return", "self", ".", "behavior", "(", "observation", ",", "action0", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_value_fn": [[374, 382], ["tensorflow.reduce_mean", "out.append", "q_"], "methods", ["None"], ["", "def", "_get_value_fn", "(", "self", ",", "q_fn", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_value_fn", "(", "s", ",", "a0", ")", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "q_", "in", "q_fn", ":", "\n", "                ", "out", ".", "append", "(", "q_", "(", "s", ",", "a0", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "out", ",", "axis", "=", "0", ")", "\n", "", "return", "_value_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_behavior": [[383, 390], ["tensorflow.concat"], "methods", ["None"], ["", "def", "_get_behavior", "(", "self", ",", "behavior", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "a0", ",", "id", "=", "0", ")", ":", "\n", "            ", "input_", "=", "tf", ".", "concat", "(", "(", "s", ",", "a0", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "behavior", "[", "id", "]", "(", "input_", ")", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._get_dynamic": [[391, 401], ["tensorflow.concat", "s1.append", "d_", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_get_dynamic", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "input_", "=", "tf", ".", "concat", "(", "(", "s", ",", "a", ")", ",", "axis", "=", "-", "1", ")", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1", ".", "append", "(", "d_", "(", "input_", ")", ")", "\n", "", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._clear_sol": [[402, 405], ["None"], "methods", ["None"], ["", "def", "_clear_sol", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear prev sol\"\"\"", "\n", "self", ".", "prev_sol", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._init_sol": [[406, 410], ["numpy.zeros"], "methods", ["None"], ["", "def", "_init_sol", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize the actions using the behavior policy\"\"\"", "\n", "init_sol", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "pred_len", ",", "self", ".", "_a_dim", ")", ")", "\n", "return", "init_sol", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Agent._mbop_sol": [[412, 477], ["noise.astype.astype.astype", "noise.astype.astype.copy", "numpy.tile", "numpy.array_split", "numpy.tile", "numpy.array_split", "numpy.array_split", "numpy.array_split", "enumerate", "numpy.concatenate", "numpy.clip", "numpy.concatenate", "numpy.exp", "len", "mbop_agent.Agent._init_sol", "numpy.random.normal", "len", "tensorflow.convert_to_tensor", "len", "tensorflow.convert_to_tensor", "len", "len", "range", "numpy.concatenate.append", "tensorflow.concat.append", "tensorflow.concat", "tensorflow.convert_to_tensor", "mbop_agent.Agent.value_fn().numpy", "numpy.sum", "numpy.sum", "len", "mbop_agent.Agent.dynamic", "r.numpy", "mbop_agent.Agent.behavior", "tensorflow.convert_to_tensor", "mbop_agent.Agent.value_fn", "numpy.max", "numpy.tile.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_sol"], ["", "def", "_mbop_sol", "(", "self", ",", "observation", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "\"\"\" calculate the optimal inputs\"\"\"", "\n", "if", "len", "(", "observation", ".", "shape", ")", "==", "2", ":", "\n", "            ", "assert", "observation", ".", "shape", "[", "0", "]", "==", "1", "\n", "curr_x", "=", "observation", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "observation", ".", "shape", ")", "==", "1", "\n", "curr_x", "=", "observation", "\n", "# get prev_sol", "\n", "", "if", "self", ".", "prev_sol", "is", "None", ":", "\n", "            ", "self", ".", "prev_sol", "=", "self", ".", "_init_sol", "(", ")", "\n", "# get noised inputs", "\n", "", "noise", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1.0", ",", "size", "=", "(", "self", ".", "pop_size", ",", "self", ".", "pred_len", ",", "\n", "self", ".", "_a_dim", ")", ")", "*", "self", ".", "noise_sigma", "\n", "noise", "=", "noise", ".", "astype", "(", "'float32'", ")", "\n", "noised_inputs", "=", "noise", ".", "copy", "(", ")", "\n", "s", "=", "np", ".", "tile", "(", "curr_x", ",", "(", "self", ".", "pop_size", ",", "1", ")", ")", "\n", "s_list", "=", "np", ".", "array_split", "(", "s", ",", "len", "(", "self", ".", "_b_list", ")", ")", "\n", "s_list", "=", "[", "tf", ".", "convert_to_tensor", "(", "s", ",", "dtype", "=", "tf", ".", "float32", ")", "for", "s", "in", "s_list", "]", "\n", "a0", "=", "self", ".", "prev_sol", "[", "0", "]", "\n", "a0", "=", "np", ".", "tile", "(", "a0", ",", "(", "self", ".", "pop_size", ",", "1", ")", ")", "\n", "a0_list", "=", "np", ".", "array_split", "(", "a0", ",", "len", "(", "self", ".", "_b_list", ")", ")", "\n", "a0_list", "=", "[", "tf", ".", "convert_to_tensor", "(", "a0", ",", "dtype", "=", "tf", ".", "float32", ")", "for", "a0", "in", "a0_list", "]", "\n", "noise_list", "=", "np", ".", "array_split", "(", "noise", ",", "len", "(", "self", ".", "_b_list", ")", ")", "\n", "noised_inputs_list", "=", "np", ".", "array_split", "(", "noised_inputs", ",", "len", "(", "self", ".", "_b_list", ")", ")", "\n", "rewards", "=", "[", "]", "\n", "s_last", "=", "[", "]", "\n", "# Use consistent ensemble head throughout trajectory.", "\n", "for", "l", ",", "s", "in", "enumerate", "(", "s_list", ")", ":", "\n", "            ", "a0", ",", "noise", ",", "noised_inputs", "=", "a0_list", "[", "l", "]", ",", "noise_list", "[", "l", "]", ",", "noised_inputs_list", "[", "l", "]", "\n", "reward", "=", "0", "\n", "for", "t", "in", "range", "(", "self", ".", "pred_len", ")", ":", "\n", "                ", "a0", "=", "self", ".", "behavior", "(", "s", ",", "a0", ",", "id", "=", "l", ")", "+", "noise", "[", ":", ",", "t", ",", ":", "]", "\n", "a_sample_mix", "=", "self", ".", "beta", "*", "self", ".", "prev_sol", "[", "t", ",", ":", "]", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "a0", ".", "numpy", "(", ")", "\n", "noised_inputs", "[", ":", ",", "t", ",", ":", "]", "=", "a_sample_mix", "\n", "s", ",", "r", "=", "self", ".", "dynamic", "(", "s", ",", "tf", ".", "convert_to_tensor", "(", "a_sample_mix", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "id", "=", "l", ")", "\n", "reward", "+=", "r", ".", "numpy", "(", ")", "\n", "", "rewards", ".", "append", "(", "reward", ")", "\n", "s_last", ".", "append", "(", "s", ")", "\n", "# clip actions", "\n", "", "noised_inputs", "=", "np", ".", "concatenate", "(", "noised_inputs_list", ",", "axis", "=", "0", ")", "\n", "noised_inputs", "=", "np", ".", "clip", "(", "noised_inputs", ",", "self", ".", "_a_min", ",", "self", ".", "_a_max", ")", "\n", "rewards", "=", "np", ".", "concatenate", "(", "rewards", ")", "\n", "# calc reward", "\n", "if", "self", ".", "_use_value_fn", ":", "\n", "            ", "s_last", "=", "tf", ".", "concat", "(", "s_last", ",", "axis", "=", "0", ")", "\n", "a_last", "=", "tf", ".", "convert_to_tensor", "(", "noised_inputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "q_last", "=", "self", ".", "value_fn", "(", "s_last", ",", "a_last", ")", ".", "numpy", "(", ")", "\n", "rewards", "+=", "q_last", "\n", "# mppi update", "\n", "# normalize and get sum of reward", "\n", "# exp_rewards.shape = (N, )", "\n", "", "exp_rewards", "=", "np", ".", "exp", "(", "self", ".", "kappa", "*", "(", "rewards", "-", "np", ".", "max", "(", "rewards", ")", ")", ")", "\n", "denom", "=", "np", ".", "sum", "(", "exp_rewards", ")", "+", "1e-10", "# avoid numeric error", "\n", "# weight actions", "\n", "weighted_inputs", "=", "exp_rewards", "[", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "*", "noised_inputs", "\n", "sol", "=", "np", ".", "sum", "(", "weighted_inputs", ",", "0", ")", "/", "denom", "\n", "# update", "\n", "self", ".", "prev_sol", "[", ":", "-", "1", "]", "=", "sol", "[", "1", ":", "]", "\n", "self", ".", "prev_sol", "[", "-", "1", "]", "=", "sol", "[", "-", "1", "]", "# last use the terminal input", "\n", "# self.past_action = sol[0]", "\n", "\n", "return", "sol", "[", "0", "]", "[", "np", ".", "newaxis", ",", ":", "]", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule._build_modules": [[482, 500], ["range", "range", "range", "mbop_agent.AgentModule._b_nets.append", "mbop_agent.AgentModule._d_nets.append", "mbop_agent.AgentModule._q_nets.append", "mbop_agent.AgentModule._modules.b_net_factory", "mbop_agent.AgentModule._modules.d_net_factory", "mbop_agent.AgentModule._modules.q_net_factory"], "methods", ["None"], ["def", "_build_modules", "(", "self", ")", ":", "\n", "        ", "self", ".", "_b_nets", "=", "[", "]", "\n", "self", ".", "_d_nets", "=", "[", "]", "\n", "self", ".", "_q_nets", "=", "[", "]", "\n", "n_b_fns", "=", "self", ".", "_modules", ".", "n_b_fns", "\n", "n_d_fns", "=", "self", ".", "_modules", ".", "n_d_fns", "\n", "n_q_fns", "=", "self", ".", "_modules", ".", "n_q_fns", "\n", "for", "_", "in", "range", "(", "n_b_fns", ")", ":", "\n", "            ", "self", ".", "_b_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "b_net_factory", "(", ")", "\n", ")", "\n", "", "for", "_", "in", "range", "(", "n_d_fns", ")", ":", "\n", "            ", "self", ".", "_d_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "d_net_factory", "(", ")", "\n", ")", "\n", "", "for", "_", "in", "range", "(", "n_q_fns", ")", ":", "\n", "            ", "self", ".", "_q_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "q_net_factory", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.b_nets": [[502, 505], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "b_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_b_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.b_weights": [[506, 512], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_weights", "(", "self", ")", ":", "\n", "        ", "b_weights", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "b_weights", "+=", "b_net", ".", "weights", "\n", "", "return", "b_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.b_variables": [[513, 519], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "vars_", "+=", "b_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.d_nets": [[520, 523], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_d_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.d_weights": [[524, 530], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_weights", "(", "self", ")", ":", "\n", "        ", "d_weights", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "d_weights", "+=", "d_net", ".", "weights", "\n", "", "return", "d_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.d_variables": [[531, 537], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "vars_", "+=", "d_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.q_nets": [[538, 541], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_q_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.q_weights": [[542, 548], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_weights", "(", "self", ")", ":", "\n", "        ", "q_weights", "=", "[", "]", "\n", "for", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "q_weights", "+=", "q_net", ".", "weights", "\n", "", "return", "q_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.AgentModule.q_variables": [[549, 555], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "vars_", "+=", "q_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.Config._get_modules": [[591, 596], ["mbop_agent.get_modules"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.get_modules"], ["    ", "def", "_get_modules", "(", "self", ")", ":", "\n", "        ", "return", "get_modules", "(", "\n", "self", ".", "_agent_flags", ".", "model_params", ",", "\n", "self", ".", "_agent_flags", ".", "action_spec", ",", "\n", "self", ".", "_agent_flags", ".", "observation_spec", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mbop_agent.get_modules": [[557, 587], ["scripts.utils.Flags", "len", "scripts.networks.DNNNetwork", "scripts.networks.DNNNetwork", "scripts.networks.CriticNetwork"], "function", ["None"], ["", "", "def", "get_modules", "(", "model_params", ",", "action_spec", ",", "state_spec", ")", ":", "\n", "    ", "\"\"\"Get agent modules.\"\"\"", "\n", "model_params", ",", "_", ",", "_", "=", "model_params", "\n", "assert", "len", "(", "model_params", ")", "==", "3", "\n", "\n", "def", "b_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "DNNNetwork", "(", "\n", "action_spec", ".", "shape", "[", "0", "]", ",", "\n", "fc_layer_params", "=", "model_params", "[", "0", "]", "[", "0", "]", ",", "\n", ")", "\n", "\n", "", "def", "d_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "DNNNetwork", "(", "\n", "output_dim", "=", "state_spec", ".", "shape", "[", "0", "]", "+", "1", ",", "\n", "fc_layer_params", "=", "model_params", "[", "1", "]", "[", "0", "]", ",", "\n", ")", "\n", "\n", "", "def", "q_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "CriticNetwork", "(", "\n", "fc_layer_params", "=", "model_params", "[", "2", "]", "[", "0", "]", ")", "\n", "\n", "", "modules", "=", "utils", ".", "Flags", "(", "\n", "b_net_factory", "=", "b_net_factory", ",", "\n", "d_net_factory", "=", "d_net_factory", ",", "\n", "q_net_factory", "=", "q_net_factory", ",", "\n", "n_b_fns", "=", "model_params", "[", "0", "]", "[", "1", "]", ",", "\n", "n_d_fns", "=", "model_params", "[", "1", "]", "[", "1", "]", ",", "\n", "n_q_fns", "=", "model_params", "[", "2", "]", "[", "1", "]", ",", "\n", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__": [[24, 77], ["agent.Agent.__init__", "numpy.zeros", "float"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "train_b_alpha_entropy", "=", "False", ",", "\n", "train_d_alpha_entropy", "=", "False", ",", "\n", "b_alpha_entropy", "=", "0.0", ",", "\n", "d_alpha_entropy", "=", "0.0", ",", "\n", "b_target_entropy", "=", "None", ",", "\n", "d_target_entropy", "=", "None", ",", "\n", "ensemble_q_lambda", "=", "1.0", ",", "\n", "n_action_samples", "=", "10", ",", "\n", "use_value_fn", "=", "False", ",", "\n", "b_list", "=", "None", ",", "\n", "d_list", "=", "None", ",", "\n", "pred_len", "=", "10", ",", "\n", "beta", "=", "0.6", ",", "\n", "pop_size", "=", "1000", ",", "\n", "kappa", "=", "0.9", ",", "\n", "noise_sigma", "=", "0.08", ",", "\n", "behavior_init_coef", "=", "0.5", ",", "\n", "d_uncertainty_threshold", "=", "None", ",", "\n", "uncertainty_percentile", "=", "90", ",", "\n", "penalty_lambda", "=", "0", ",", "\n", "model_id", "=", "0", ",", "\n", "maxq", "=", "True", ",", "\n", "test_b_only", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_train_b_alpha_entropy", "=", "train_b_alpha_entropy", "\n", "self", ".", "_train_d_alpha_entropy", "=", "train_d_alpha_entropy", "\n", "self", ".", "_b_alpha_entropy", "=", "b_alpha_entropy", "\n", "self", ".", "_d_alpha_entropy", "=", "d_alpha_entropy", "\n", "self", ".", "_b_target_entropy", "=", "b_target_entropy", "\n", "self", ".", "_d_target_entropy", "=", "d_target_entropy", "\n", "self", ".", "_ensemble_q_lambda", "=", "ensemble_q_lambda", "\n", "self", ".", "_n_action_samples", "=", "n_action_samples", "\n", "self", ".", "_use_value_fn", "=", "use_value_fn", "# if add the predicted return to the cumulative rewards", "\n", "self", ".", "_b_list", "=", "b_list", "\n", "self", ".", "_d_list", "=", "d_list", "\n", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "maxq", "=", "maxq", "\n", "self", ".", "_test_b_only", "=", "test_b_only", "\n", "# offline MPPI parameters", "\n", "self", ".", "pred_len", "=", "pred_len", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "pop_size", "=", "pop_size", "\n", "self", ".", "kappa", "=", "kappa", "\n", "self", ".", "noise_sigma", "=", "noise_sigma", "\n", "self", ".", "behavior_init_coef", "=", "behavior_init_coef", "\n", "self", ".", "prev_sol", "=", "None", "\n", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "past_action", "=", "np", ".", "zeros", "(", "self", ".", "_a_dim", ")", "\n", "self", ".", "_a_min", "=", "float", "(", "self", ".", "_action_spec", ".", "minimum", ")", "\n", "self", ".", "d_uncertainty_threshold", "=", "d_uncertainty_threshold", "\n", "self", ".", "_uncertainty_percentile", "=", "uncertainty_percentile", "\n", "self", ".", "_penalty_lambda", "=", "penalty_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_fns": [[78, 106], ["mopp_agent.AgentModule", "mopp_agent.Agent._get_dynamic", "mopp_agent.Agent._get_behavior", "mopp_agent.Agent._get_behavior_sample", "mopp_agent.Agent._get_dynamic_diff", "mopp_agent.Agent._get_value_fn", "mopp_agent.Agent._agent_module.assign_alpha_entropy", "numpy.arange", "numpy.arange", "mopp_agent.Agent._get_behavior_sample", "mopp_agent.Agent._get_behavior_sample_maxq", "len", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_diff", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_value_fn", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.assign_alpha_entropy", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample_maxq"], ["", "def", "_build_fns", "(", "self", ")", ":", "\n", "        ", "self", ".", "_agent_module", "=", "AgentModule", "(", "modules", "=", "self", ".", "_modules", ")", "\n", "self", ".", "_b_fns", "=", "self", ".", "_agent_module", ".", "b_nets", "\n", "self", ".", "_d_fns", "=", "self", ".", "_agent_module", ".", "d_nets", "\n", "self", ".", "_q_fns", "=", "self", ".", "_agent_module", ".", "q_nets", "\n", "if", "self", ".", "_b_list", "is", "None", ":", "\n", "            ", "self", ".", "_b_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_b_fns", ")", ")", "\n", "", "if", "self", ".", "_d_list", "is", "None", ":", "\n", "            ", "self", ".", "_d_list", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "_d_fns", ")", ")", "\n", "", "self", ".", "dynamic", "=", "self", ".", "_get_dynamic", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "self", ".", "behavior", "=", "self", ".", "_get_behavior", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ")", "\n", "if", "not", "self", ".", "maxq", ":", "\n", "            ", "self", ".", "behavior_maxq", "=", "self", ".", "_get_behavior_sample", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "\n", "self", ".", "noise_sigma", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "behavior_maxq", "=", "self", ".", "_get_behavior_sample_maxq", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "\n", "self", ".", "noise_sigma", ")", "\n", "", "self", ".", "_behavior_sample", "=", "self", ".", "_get_behavior_sample", "(", "[", "self", ".", "_agent_module", ".", "b_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_b_list", "]", ",", "None", ")", "\n", "self", ".", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_diff", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "self", ".", "value_fn", "=", "self", ".", "_get_value_fn", "(", "[", "self", ".", "_agent_module", ".", "q_nets", "[", "i", "]", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_agent_module", ".", "q_nets", ")", ")", "]", ")", "\n", "if", "self", ".", "_b_target_entropy", "is", "None", ":", "\n", "            ", "self", ".", "_b_target_entropy", "=", "-", "self", ".", "_action_spec", ".", "shape", "[", "0", "]", "\n", "", "if", "self", ".", "_d_target_entropy", "is", "None", ":", "\n", "            ", "self", ".", "_d_target_entropy", "=", "-", "(", "self", ".", "_observation_spec", ".", "shape", "[", "0", "]", "+", "1", ")", "\n", "", "self", ".", "_get_b_alpha_entropy", "=", "self", ".", "_agent_module", ".", "get_b_alpha_entropy", "\n", "self", ".", "_get_d_alpha_entropy", "=", "self", ".", "_agent_module", ".", "get_d_alpha_entropy", "\n", "self", ".", "_agent_module", ".", "assign_alpha_entropy", "(", "self", ".", "_b_alpha_entropy", ",", "self", ".", "_d_alpha_entropy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_vars": [[107, 109], ["None"], "methods", ["None"], ["", "def", "_get_b_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "b_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_vars": [[110, 112], ["None"], "methods", ["None"], ["", "def", "_get_d_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "d_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_vars": [[113, 115], ["None"], "methods", ["None"], ["", "def", "_get_q_vars", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_agent_module", ".", "q_source_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_weight_norm": [[116, 123], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_b_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "b_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_weight_norm": [[124, 131], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_d_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "d_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_weight_norm": [[132, 139], ["tensorflow.add_n", "tensorflow.reduce_sum", "norms.append", "tensorflow.square"], "methods", ["None"], ["", "def", "_get_q_weight_norm", "(", "self", ")", ":", "\n", "        ", "weights", "=", "self", ".", "_agent_module", ".", "q_source_weights", "\n", "norms", "=", "[", "]", "\n", "for", "w", "in", "weights", ":", "\n", "            ", "norm", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "w", ")", ")", "\n", "norms", ".", "append", "(", "norm", ")", "\n", "", "return", "tf", ".", "add_n", "(", "norms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.ensemble_q": [[140, 144], ["tensorflow.reduce_min", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "ensemble_q", "(", "self", ",", "qs", ")", ":", "\n", "        ", "lambda_", "=", "self", ".", "_ensemble_q_lambda", "\n", "return", "(", "lambda_", "*", "tf", ".", "reduce_min", "(", "qs", ",", "axis", "=", "-", "1", ")", "\n", "+", "(", "1", "-", "lambda_", ")", "*", "tf", ".", "reduce_max", "(", "qs", ",", "axis", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._ensemble_q2_target": [[145, 147], ["mopp_agent.Agent.ensemble_q"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.ensemble_q"], ["", "def", "_ensemble_q2_target", "(", "self", ",", "q2_targets", ")", ":", "\n", "        ", "return", "self", ".", "ensemble_q", "(", "q2_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss": [[148, 168], ["scripts.utils.clip_by_eps", "tensorflow.add_n", "mopp_agent.Agent._get_b_weight_norm", "collections.OrderedDict", "b_fn.get_log_density", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "b_losses.append", "mopp_agent.Agent._get_b_alpha_entropy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.clip_by_eps", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_weight_norm", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.get_log_density"], ["", "def", "_build_b_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "a_b", "=", "batch", "[", "'a1'", "]", "\n", "a_b", "=", "utils", ".", "clip_by_eps", "(", "a_b", ",", "self", ".", "_action_spec", ",", "CLIP_EPS", ")", "\n", "b_losses", "=", "[", "]", "\n", "for", "b_fn", "in", "self", ".", "_b_fns", ":", "\n", "            ", "log_pi_a_b", ",", "log_pi_a_p", "=", "b_fn", ".", "get_log_density", "(", "s", ",", "a_b", ")", "\n", "log_pi_a_b", "=", "tf", ".", "reduce_sum", "(", "log_pi_a_b", ",", "axis", "=", "-", "1", ")", "\n", "log_pi_a_p", "=", "tf", ".", "reduce_sum", "(", "log_pi_a_p", ",", "axis", "=", "-", "1", ")", "\n", "b_loss_", "=", "tf", ".", "reduce_mean", "(", "self", ".", "_get_b_alpha_entropy", "(", ")", "*", "log_pi_a_p", "-", "log_pi_a_b", ")", "\n", "b_losses", ".", "append", "(", "b_loss_", ")", "\n", "", "b_loss", "=", "tf", ".", "add_n", "(", "b_losses", ")", "\n", "b_w_norm", "=", "self", ".", "_get_b_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "b_w_norm", "\n", "loss", "=", "b_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'b_loss'", "]", "=", "b_loss", "\n", "info", "[", "'b_norm'", "]", "=", "b_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss": [[169, 190], ["tensorflow.add_n", "mopp_agent.Agent._get_d_weight_norm", "collections.OrderedDict", "d_fn.get_log_density", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "d_losses.append", "mopp_agent.Agent._get_d_alpha_entropy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_weight_norm", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ProbDynamics.get_log_density"], ["", "def", "_build_d_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s1", "=", "batch", "[", "'s1'", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "r", "=", "batch", "[", "'r'", "]", "\n", "d_losses", "=", "[", "]", "\n", "for", "d_fn", "in", "self", ".", "_d_fns", ":", "\n", "            ", "log_pi_s_real", ",", "log_pi_s_pred", "=", "d_fn", ".", "get_log_density", "(", "s1", ",", "a1", ",", "s2", ",", "r", ")", "\n", "log_pi_s_real", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_real", ",", "axis", "=", "-", "1", ")", "\n", "log_pi_s_pred", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_pred", ",", "axis", "=", "-", "1", ")", "\n", "d_loss_", "=", "tf", ".", "reduce_mean", "(", "self", ".", "_get_d_alpha_entropy", "(", ")", "*", "log_pi_s_pred", "-", "log_pi_s_real", ")", "\n", "d_losses", ".", "append", "(", "d_loss_", ")", "\n", "", "d_loss", "=", "tf", ".", "add_n", "(", "d_losses", ")", "\n", "d_w_norm", "=", "self", ".", "_get_d_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "d_w_norm", "\n", "loss", "=", "d_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'d_loss'", "]", "=", "d_loss", "\n", "info", "[", "'d_norm'", "]", "=", "d_w_norm", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss": [[191, 227], ["tensorflow.stack", "mopp_agent.Agent._ensemble_q2_target", "tensorflow.stop_gradient", "tensorflow.add_n", "mopp_agent.Agent._get_q_weight_norm", "collections.OrderedDict", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "q_fn_target", "q_fn", "q1_preds.append", "tensorflow.stack.append", "tensorflow.reduce_mean", "q_losses.append", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._ensemble_q2_target", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_weight_norm"], ["", "def", "_build_q_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s1", "=", "batch", "[", "'s1'", "]", "\n", "s2", "=", "batch", "[", "'s2'", "]", "\n", "a1", "=", "batch", "[", "'a1'", "]", "\n", "a2_b", "=", "batch", "[", "'a2'", "]", "\n", "r", "=", "batch", "[", "'r'", "]", "\n", "dsc", "=", "batch", "[", "'dsc'", "]", "\n", "\n", "q2_targets", "=", "[", "]", "\n", "q1_preds", "=", "[", "]", "\n", "for", "q_fn", ",", "q_fn_target", "in", "self", ".", "_q_fns", ":", "\n", "            ", "q2_target_", "=", "q_fn_target", "(", "s2", ",", "a2_b", ")", "\n", "q1_pred", "=", "q_fn", "(", "s1", ",", "a1", ")", "\n", "q1_preds", ".", "append", "(", "q1_pred", ")", "\n", "q2_targets", ".", "append", "(", "q2_target_", ")", "\n", "", "q2_targets", "=", "tf", ".", "stack", "(", "q2_targets", ",", "axis", "=", "-", "1", ")", "\n", "q2_target", "=", "self", ".", "_ensemble_q2_target", "(", "q2_targets", ")", "\n", "v2_target", "=", "q2_target", "\n", "q1_target", "=", "tf", ".", "stop_gradient", "(", "r", "+", "dsc", "*", "self", ".", "_discount", "*", "v2_target", ")", "\n", "q_losses", "=", "[", "]", "\n", "for", "q1_pred", "in", "q1_preds", ":", "\n", "            ", "q_loss_", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q1_pred", "-", "q1_target", ")", ")", "\n", "q_losses", ".", "append", "(", "q_loss_", ")", "\n", "", "q_loss", "=", "tf", ".", "add_n", "(", "q_losses", ")", "\n", "q_w_norm", "=", "self", ".", "_get_q_weight_norm", "(", ")", "\n", "norm_loss", "=", "self", ".", "_weight_decays", "*", "q_w_norm", "\n", "loss", "=", "q_loss", "+", "norm_loss", "\n", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'q_loss'", "]", "=", "q_loss", "\n", "info", "[", "'q_norm'", "]", "=", "q_w_norm", "\n", "info", "[", "'r_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "r", ")", "\n", "info", "[", "'dsc_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "dsc", ")", "\n", "info", "[", "'q2_target_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "q2_target", ")", "\n", "info", "[", "'q1_target_mean'", "]", "=", "tf", ".", "reduce_mean", "(", "q1_target", ")", "\n", "return", "loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_ae_loss": [[228, 242], ["mopp_agent.Agent._get_b_alpha_entropy", "tensorflow.reduce_mean", "collections.OrderedDict", "b_fn", "tensorflow.reduce_sum", "tensorflow.reduce_mean.append", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_build_b_ae_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "b_ae_loss", "=", "[", "]", "\n", "alpha", "=", "self", ".", "_get_b_alpha_entropy", "(", ")", "\n", "for", "b_fn", "in", "self", ".", "_b_fns", ":", "\n", "            ", "_", ",", "_", ",", "log_pi_a_p", ",", "_", "=", "b_fn", "(", "s", ")", "\n", "log_pi_a_p", "=", "tf", ".", "reduce_sum", "(", "log_pi_a_p", ",", "axis", "=", "-", "1", ")", "\n", "b_ae_loss", ".", "append", "(", "tf", ".", "reduce_mean", "(", "alpha", "*", "(", "-", "log_pi_a_p", "-", "self", ".", "_b_target_entropy", ")", ")", ")", "\n", "", "b_ae_loss", "=", "tf", ".", "reduce_mean", "(", "b_ae_loss", ")", "\n", "# Construct information about current training.", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'b_ae_loss'", "]", "=", "b_ae_loss", "\n", "info", "[", "'b_alpha_entropy'", "]", "=", "alpha", "\n", "return", "b_ae_loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_ae_loss": [[243, 258], ["mopp_agent.Agent._get_d_alpha_entropy", "tensorflow.reduce_mean", "collections.OrderedDict", "d_fn", "tensorflow.reduce_sum", "tensorflow.reduce_mean.append", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_build_d_ae_loss", "(", "self", ",", "batch", ")", ":", "\n", "        ", "s", "=", "batch", "[", "'s1'", "]", "\n", "a", "=", "batch", "[", "'a1'", "]", "\n", "d_ae_loss", "=", "[", "]", "\n", "alpha", "=", "self", ".", "_get_d_alpha_entropy", "(", ")", "\n", "for", "d_fn", "in", "self", ".", "_d_fns", ":", "\n", "            ", "_", ",", "_", ",", "log_pi_s_pred", ",", "_", "=", "d_fn", "(", "s", ",", "a", ")", "\n", "log_pi_s_pred", "=", "tf", ".", "reduce_sum", "(", "log_pi_s_pred", ",", "axis", "=", "-", "1", ")", "\n", "d_ae_loss", ".", "append", "(", "tf", ".", "reduce_mean", "(", "alpha", "*", "(", "-", "log_pi_s_pred", "-", "self", ".", "_d_target_entropy", ")", ")", ")", "\n", "", "d_ae_loss", "=", "tf", ".", "reduce_mean", "(", "d_ae_loss", ")", "\n", "# Construct information about current training.", "\n", "info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "info", "[", "'d_ae_loss'", "]", "=", "d_ae_loss", "\n", "info", "[", "'d_alpha_entropy'", "]", "=", "alpha", "\n", "return", "d_ae_loss", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_source_target_vars": [[259, 262], ["None"], "methods", ["None"], ["", "def", "_get_source_target_vars", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "_agent_module", ".", "q_source_variables", ",", "\n", "self", ".", "_agent_module", ".", "q_target_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_optimizers": [[263, 270], ["scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer", "scripts.utils.get_optimizer"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_optimizer"], ["", "def", "_build_optimizers", "(", "self", ")", ":", "\n", "        ", "opts", "=", "self", ".", "_optimizers", "\n", "self", ".", "_b_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "0", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "0", "]", "[", "1", "]", ")", "\n", "self", ".", "_d_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "1", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "1", "]", "[", "1", "]", ")", "\n", "self", ".", "_b_ae_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "2", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "2", "]", "[", "1", "]", ")", "\n", "self", ".", "_d_ae_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "3", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "3", "]", "[", "1", "]", ")", "\n", "self", ".", "_q_optimizer", "=", "utils", ".", "get_optimizer", "(", "opts", "[", "4", "]", "[", "0", "]", ")", "(", "lr", "=", "opts", "[", "4", "]", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_step": [[271, 274], ["None"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b": [[275, 285], ["tape.gradient", "tuple", "mopp_agent.Agent._b_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_agent.Agent._build_b_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_b", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_b_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_b_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d": [[286, 296], ["tape.gradient", "tuple", "mopp_agent.Agent._d_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_agent.Agent._build_d_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_d", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_d_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_d_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_q": [[297, 310], ["tensorflow.equal", "tape.gradient", "tuple", "mopp_agent.Agent._q_optimizer.apply_gradients", "mopp_agent.Agent._get_source_target_vars", "mopp_agent.Agent._update_target_fns", "tensorflow.GradientTape", "tape.watch", "mopp_agent.Agent._build_q_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_source_target_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._update_target_fns", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_q", "(", "self", ",", "batch", ",", "step", ")", ":", "\n", "        ", "if", "tf", ".", "equal", "(", "step", "%", "self", ".", "_update_freq", ",", "0", ")", ":", "\n", "            ", "source_vars", ",", "target_vars", "=", "self", ".", "_get_source_target_vars", "(", ")", "\n", "self", ".", "_update_target_fns", "(", "source_vars", ",", "target_vars", ")", "\n", "", "vars_", "=", "self", ".", "_q_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_q_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_q_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b_ae": [[311, 321], ["tape.gradient", "tuple", "mopp_agent.Agent._b_ae_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_agent.Agent._build_b_ae_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_ae_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_b_ae", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_b_ae_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_b_ae_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_b_ae_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d_ae": [[322, 332], ["tape.gradient", "tuple", "mopp_agent.Agent._d_ae_optimizer.apply_gradients", "tensorflow.GradientTape", "tape.watch", "mopp_agent.Agent._build_d_ae_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_ae_loss"], ["", "@", "tf", ".", "function", "\n", "def", "_optimize_d_ae", "(", "self", ",", "batch", ")", ":", "\n", "        ", "vars_", "=", "self", ".", "_d_ae_vars", "\n", "with", "tf", ".", "GradientTape", "(", "watch_accessed_variables", "=", "False", ")", "as", "tape", ":", "\n", "            ", "tape", ".", "watch", "(", "vars_", ")", "\n", "loss", ",", "info", "=", "self", ".", "_build_d_ae_loss", "(", "batch", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "vars_", ")", "\n", "grads_and_vars", "=", "tuple", "(", "zip", "(", "grads", ",", "vars_", ")", ")", "\n", "self", ".", "_d_ae_optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_vars": [[333, 342], ["mopp_agent.Agent._build_b_loss", "mopp_agent.Agent._build_d_loss", "mopp_agent.Agent._build_q_loss", "mopp_agent.Agent._get_b_vars", "mopp_agent.Agent._get_d_vars", "mopp_agent.Agent._get_q_vars"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_b_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_d_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_q_loss", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_b_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_d_vars", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_q_vars"], ["", "def", "_init_vars", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "_build_b_loss", "(", "batch", ")", "\n", "self", ".", "_build_d_loss", "(", "batch", ")", "\n", "self", ".", "_build_q_loss", "(", "batch", ")", "\n", "self", ".", "_b_vars", "=", "self", ".", "_get_b_vars", "(", ")", "\n", "self", ".", "_d_vars", "=", "self", ".", "_get_d_vars", "(", ")", "\n", "self", ".", "_q_vars", "=", "self", ".", "_get_q_vars", "(", ")", "\n", "self", ".", "_b_ae_vars", "=", "self", ".", "_agent_module", ".", "b_ae_variables", "\n", "self", ".", "_d_ae_vars", "=", "self", ".", "_agent_module", ".", "d_ae_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_checkpointer": [[343, 362], ["tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint", "dict"], "methods", ["None"], ["", "def", "_build_checkpointer", "(", "self", ")", ":", "\n", "        ", "state_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "self", ".", "_agent_module", ",", "\n", "global_step", "=", "self", ".", "_global_step", ",", "\n", ")", "\n", "behavior_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "policy", "=", "self", ".", "_agent_module", ".", "b_nets", ",", "\n", ")", "\n", "dynamics_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "dynamics", "=", "self", ".", "_agent_module", ".", "d_nets", ",", "\n", ")", "\n", "q_ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "q", "=", "self", ".", "_agent_module", ".", "q_nets", ",", "\n", ")", "\n", "return", "dict", "(", "\n", "state", "=", "state_ckpt", ",", "\n", "behavior", "=", "behavior_ckpt", ",", "\n", "dynamics", "=", "dynamics_ckpt", ",", "\n", "q_fn", "=", "q_ckpt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_behavior_step": [[363, 373], ["collections.OrderedDict", "mopp_agent.Agent._get_train_batch", "mopp_agent.Agent._optimize_b", "mopp_agent.Agent.items", "mopp_agent.Agent._optimize_b_ae", "mopp_agent.Agent.update", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_b_ae"], ["", "def", "train_behavior_step", "(", "self", ")", ":", "\n", "        ", "train_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_b", "(", "train_batch", ")", "\n", "if", "self", ".", "_train_b_alpha_entropy", ":", "\n", "            ", "ae_info", "=", "self", ".", "_optimize_b_ae", "(", "train_batch", ")", "\n", "info", ".", "update", "(", "ae_info", ")", "\n", "", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_b_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior": [[374, 384], ["collections.OrderedDict", "enumerate", "tensorflow.reduce_mean", "b_fn", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_behavior", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "s", "=", "_batch", "[", "'s1'", "]", "\n", "a_b", "=", "_batch", "[", "'a1'", "]", "\n", "test_b_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "b_fn", "in", "enumerate", "(", "self", ".", "_b_fns", ")", ":", "\n", "            ", "a_p", "=", "b_fn", "(", "s", ")", "[", "0", "]", "\n", "a_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "a_p", "-", "a_b", ")", ")", "\n", "test_b_info", "[", "f'b{i}_mse'", "]", "=", "a_error", "\n", "", "return", "test_b_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.write_b_train_summary": [[385, 391], ["mopp_agent.Agent._get_train_batch", "mopp_agent.Agent.test_behavior", "mopp_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_b_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_b_info", "=", "self", ".", "test_behavior", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_b_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_behavior_model": [[392, 394], ["mopp_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_behavior_model": [[395, 397], ["mopp_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_behavior_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'behavior'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_dynamics_step": [[398, 408], ["collections.OrderedDict", "mopp_agent.Agent._get_train_batch", "mopp_agent.Agent._optimize_d", "mopp_agent.Agent.items", "mopp_agent.Agent._optimize_d_ae", "mopp_agent.Agent.update", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_d_ae"], ["", "def", "train_dynamics_step", "(", "self", ")", ":", "\n", "        ", "train_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_d", "(", "train_batch", ")", "\n", "if", "self", ".", "_train_d_alpha_entropy", ":", "\n", "            ", "ae_info", "=", "self", ".", "_optimize_d_ae", "(", "train_batch", ")", "\n", "info", ".", "update", "(", "ae_info", ")", "\n", "", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_d_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamics": [[409, 425], ["collections.OrderedDict", "enumerate", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "d_fn", "tensorflow.square", "tensorflow.square"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "test_dynamics", "(", "self", ",", "_batch", ")", ":", "\n", "        ", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "test_d_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "i", ",", "d_fn", "in", "enumerate", "(", "self", ".", "_d_fns", ")", ":", "\n", "            ", "_p", "=", "d_fn", "(", "s1", ",", "a1", ")", "[", "0", "]", "\n", "s_p", "=", "_p", "[", ":", ",", ":", "-", "1", "]", "\n", "r_p", "=", "_p", "[", ":", ",", "-", "1", "]", "\n", "s_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "s_p", "-", "s2", ")", ")", "\n", "r_error", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "r_p", "-", "r", ")", ")", "\n", "test_d_info", "[", "f'd{i}_s_mse'", "]", "=", "s_error", "\n", "test_d_info", "[", "f'd{i}_r_mse'", "]", "=", "r_error", "\n", "", "return", "test_d_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior_all_data": [[426, 437], ["int", "range", "numpy.mean", "mopp_agent.Agent._get_batch", "a_pred.append", "a_real.append", "numpy.square", "numpy.arange", "mopp_agent.Agent.behavior().numpy", "a1.numpy", "numpy.array", "numpy.array", "mopp_agent.Agent.behavior"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_behavior_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "a_pred", ",", "a_real", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "a_pred", ".", "append", "(", "self", ".", "behavior", "(", "s1", ",", "id", "=", "self", ".", "model_id", ")", ".", "numpy", "(", ")", ")", "\n", "a_real", ".", "append", "(", "a1", ".", "numpy", "(", ")", ")", "\n", "", "a_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "a_pred", ")", "-", "np", ".", "array", "(", "a_real", ")", ")", ")", "\n", "return", "a_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamic_all_data": [[438, 455], ["int", "range", "numpy.mean", "numpy.mean", "mopp_agent.Agent._get_batch", "mopp_agent.Agent.dynamic", "s_pred.append", "r_pred.append", "s_real.append", "r_real.append", "numpy.square", "numpy.square", "numpy.arange", "s_p.numpy", "r_p.numpy", "s2.numpy", "r.numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_batch"], ["", "def", "test_dynamic_all_data", "(", "self", ")", ":", "\n", "        ", "batch_num", "=", "int", "(", "self", ".", "_train_data", ".", "size", "/", "self", ".", "_batch_size", ")", "\n", "s_pred", ",", "r_pred", ",", "s_real", ",", "r_real", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "_batch", "=", "self", ".", "_get_batch", "(", "np", ".", "arange", "(", "i", "*", "self", ".", "_batch_size", ",", "i", "*", "self", ".", "_batch_size", "+", "self", ".", "_batch_size", ")", ")", "\n", "s1", "=", "_batch", "[", "'s1'", "]", "\n", "s2", "=", "_batch", "[", "'s2'", "]", "\n", "a1", "=", "_batch", "[", "'a1'", "]", "\n", "r", "=", "_batch", "[", "'r'", "]", "\n", "s_p", ",", "r_p", "=", "self", ".", "dynamic", "(", "s1", ",", "a1", ",", "id", "=", "self", ".", "model_id", ")", "\n", "s_pred", ".", "append", "(", "s_p", ".", "numpy", "(", ")", ")", "\n", "r_pred", ".", "append", "(", "r_p", ".", "numpy", "(", ")", ")", "\n", "s_real", ".", "append", "(", "s2", ".", "numpy", "(", ")", ")", "\n", "r_real", ".", "append", "(", "r", ".", "numpy", "(", ")", ")", "\n", "", "s_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "s_pred", ")", "-", "np", ".", "array", "(", "s_real", ")", ")", ")", "\n", "r_mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "np", ".", "array", "(", "r_pred", ")", "-", "np", ".", "array", "(", "r_real", ")", ")", ")", "\n", "return", "s_mse", ",", "r_mse", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.write_d_train_summary": [[456, 462], ["mopp_agent.Agent._get_train_batch", "mopp_agent.Agent.test_dynamics", "mopp_agent.Agent.items", "scripts.utils.write_summary", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamics", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary"], ["", "def", "write_d_train_summary", "(", "self", ",", "summary_writer", ",", "step", ",", "info", ")", ":", "\n", "        ", "_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "test_d_info", "=", "self", ".", "test_dynamics", "(", "_batch", ")", "\n", "for", "key", ",", "val", "in", "test_d_info", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "utils", ".", "write_summary", "(", "summary_writer", ",", "step", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_dynamics_model": [[463, 465], ["mopp_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_dynamics_model": [[466, 468], ["mopp_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_dynamics_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'dynamics'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_q_step": [[469, 477], ["tensorflow.constant", "collections.OrderedDict", "mopp_agent.Agent._get_train_batch", "mopp_agent.Agent._optimize_q", "mopp_agent.Agent.items", "val.numpy"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent._get_train_batch", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._optimize_q"], ["", "def", "train_q_step", "(", "self", ",", "step", ")", ":", "\n", "        ", "step", "=", "tf", ".", "constant", "(", "step", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "train_q_info", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_batch", "=", "self", ".", "_get_train_batch", "(", ")", "\n", "info", "=", "self", ".", "_optimize_q", "(", "train_batch", ",", "step", ")", "\n", "for", "key", ",", "val", "in", "info", ".", "items", "(", ")", ":", "\n", "            ", "train_q_info", "[", "key", "]", "=", "val", ".", "numpy", "(", ")", "\n", "", "return", "train_q_info", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_q_model": [[478, 480], ["mopp_agent.Agent._checkpointer[].write"], "methods", ["None"], ["", "def", "save_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "write", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_q_model": [[481, 483], ["mopp_agent.Agent._checkpointer[].restore"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.restore"], ["", "def", "restore_q_model", "(", "self", ",", "ckpt_dir", ")", ":", "\n", "        ", "self", ".", "_checkpointer", "[", "'q_fn'", "]", ".", "restore", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._build_test_policies": [[484, 489], ["None"], "methods", ["None"], ["", "def", "_build_test_policies", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_test_b_only", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'adm_bc'", "]", "=", "self", ".", "_behavior_policy", "\n", "", "else", ":", "\n", "            ", "self", ".", "_test_policies", "[", "'MOPP'", "]", "=", "self", ".", "_mopp_sol", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._behavior_policy": [[490, 492], ["mopp_agent.Agent.behavior", "numpy.random.randint", "len"], "methods", ["None"], ["", "", "def", "_behavior_policy", "(", "self", ",", "observation", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "return", "self", ".", "behavior", "(", "observation", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", ",", "state", "\n", "# return self.behavior(observation, self.model_id), state", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_value_fn": [[494, 502], ["tensorflow.reduce_mean", "out.append", "q_"], "methods", ["None"], ["", "def", "_get_value_fn", "(", "self", ",", "q_fn", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_value_fn", "(", "s", ",", "a", ")", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "q_", "in", "q_fn", ":", "\n", "                ", "out", ".", "append", "(", "q_", "(", "s", ",", "a", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "out", ",", "axis", "=", "0", ")", "\n", "", "return", "_value_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior": [[503, 514], ["None"], "methods", ["None"], ["", "def", "_get_behavior", "(", "self", ",", "behavior", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "# out = []", "\n", "# for b_ in behavior:", "\n", "#     out.append(b_(s)[0])", "\n", "# return tf.reduce_mean(out, axis=0)", "\n", "# choose a behavoir model randomly", "\n", "            ", "return", "behavior", "[", "id", "]", "(", "s", ")", "[", "0", "]", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_maxq": [[515, 535], ["tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "q_fn", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.stack", "tensorflow.reshape", "tensorflow.gather_nd", "b", "tensorflow.random.normal", "tensorflow.range"], "methods", ["None"], ["", "def", "_get_behavior_maxq", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "q_fn", "=", "self", ".", "_q_fns", "[", "0", "]", "[", "0", "]", "\n", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b", "=", "behavior", "[", "id", "]", "\n", "a", "=", "b", "(", "s", ")", "[", "0", "]", "\n", "s_n", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_n", "=", "tf", ".", "tile", "(", "a", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_n", "+=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "a_n", ".", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", "*", "sigma", "\n", "q_n", "=", "q_fn", "(", "s_n", ",", "a_n", ")", "\n", "q_n", "=", "tf", ".", "reshape", "(", "q_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ")", ")", "# shape: (n_sample, batch_size)", "\n", "a_indices", "=", "tf", ".", "argmax", "(", "q_n", ",", "axis", "=", "0", ")", "\n", "gather_indices", "=", "tf", ".", "stack", "(", "\n", "[", "a_indices", ",", "tf", ".", "range", "(", "s", ".", "shape", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "]", ",", "axis", "=", "-", "1", "\n", ")", "\n", "actions", "=", "tf", ".", "reshape", "(", "a_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "# shape: (n_sample, batch_size, a_dim)", "\n", "action", "=", "tf", ".", "gather_nd", "(", "actions", ",", "gather_indices", ")", "\n", "return", "action", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample_maxq": [[536, 577], ["tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "tensorflow.tile", "tensorflow.tile", "tfd.TransformedDistribution", "tfd.TransformedDistribution.sample", "tensorflow.tile", "q_fn", "tensorflow.reshape", "tensorflow.argmax", "tensorflow.stack", "tensorflow.reshape", "tensorflow.gather_nd", "b_", "tensorflow.tile.append", "tensorflow.tile.append", "tensorflow.reduce_max", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow.range", "tensorflow.shape", "tensorflow.shape", "tensorflow_probability.bijectors.AffineScalar"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "_get_behavior_sample_maxq", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "\"\"\"Scaling the stddev of the behavior\"\"\"", "\n", "tfd", "=", "tfp", ".", "distributions", "\n", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "q_fn", "=", "self", ".", "_q_fns", "[", "0", "]", "[", "0", "]", "\n", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b_", "=", "behavior", "[", "id", "]", "\n", "_dists", "=", "b_", "(", "s", ")", "[", "-", "1", "]", "\n", "_mean", ",", "_std", "=", "[", "]", ",", "[", "]", "\n", "for", "_dist", "in", "_dists", ":", "\n", "                ", "affine_params", "=", "_dist", ".", "bijector", ".", "bijectors", "[", "-", "1", "]", "\n", "_mean", ".", "append", "(", "affine_params", ".", "shift", ")", "\n", "_std", ".", "append", "(", "affine_params", ".", "scale", ")", "\n", "", "_mean", "=", "tf", ".", "concat", "(", "_mean", ",", "axis", "=", "-", "1", ")", "\n", "_std", "=", "tf", ".", "concat", "(", "_std", ",", "axis", "=", "-", "1", ")", "\n", "_mean", "=", "tf", ".", "tile", "(", "_mean", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "_std", "=", "tf", ".", "tile", "(", "_std", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "_std", "=", "_std", "/", "(", "tf", ".", "reduce_max", "(", "_std", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "/", "sigma", ")", "\n", "_new_dist", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "\n", "_dists", "[", "0", "]", ".", "bijector", ".", "bijectors", "[", ":", "-", "1", "]", "\n", "+", "[", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "_mean", ",", "scale", "=", "_std", ")", ",", "]", "\n", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "a_n", "=", "_new_dist", ".", "sample", "(", ")", "\n", "s_n", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "q_n", "=", "q_fn", "(", "s_n", ",", "a_n", ")", "\n", "q_n", "=", "tf", ".", "reshape", "(", "q_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ")", ")", "# shape: (n_sample, batch_size)", "\n", "a_indices", "=", "tf", ".", "argmax", "(", "q_n", ",", "axis", "=", "0", ")", "\n", "gather_indices", "=", "tf", ".", "stack", "(", "\n", "[", "a_indices", ",", "tf", ".", "range", "(", "s", ".", "shape", "[", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", "]", ",", "axis", "=", "-", "1", "\n", ")", "\n", "actions", "=", "tf", ".", "reshape", "(", "a_n", ",", "(", "self", ".", "_n_action_samples", ",", "s", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "# shape: (n_sample, batch_size, a_dim)", "\n", "action", "=", "tf", ".", "gather_nd", "(", "actions", ",", "gather_indices", ")", "\n", "return", "action", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_behavior_sample": [[578, 610], ["tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "tfd.TransformedDistribution", "tfd.TransformedDistribution.sample", "b_", "tensorflow.concat.append", "tensorflow.concat.append", "tfd.Normal", "tensorflow_probability.bijectors.Chain", "tensorflow.reduce_max", "tensorflow.shape", "tensorflow.shape", "tensorflow_probability.bijectors.AffineScalar"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.networks.ADMDynamic.sample"], ["", "def", "_get_behavior_sample", "(", "self", ",", "behavior", ",", "sigma", ")", ":", "\n", "        ", "\"\"\"Scaling the stddev of the behavior\"\"\"", "\n", "tfd", "=", "tfp", ".", "distributions", "\n", "if", "sigma", "is", "not", "None", ":", "\n", "            ", "sigma", "=", "tf", ".", "constant", "(", "sigma", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "_behavior", "(", "s", ",", "id", "=", "0", ")", ":", "\n", "            ", "b_", "=", "behavior", "[", "id", "]", "\n", "_dists", "=", "b_", "(", "s", ")", "[", "-", "1", "]", "\n", "_mean", ",", "_std", "=", "[", "]", ",", "[", "]", "\n", "for", "_dist", "in", "_dists", ":", "\n", "                ", "affine_params", "=", "_dist", ".", "bijector", ".", "bijectors", "[", "-", "1", "]", "\n", "_mean", ".", "append", "(", "affine_params", ".", "shift", ")", "\n", "_std", ".", "append", "(", "affine_params", ".", "scale", ")", "\n", "", "_mean", "=", "tf", ".", "concat", "(", "_mean", ",", "axis", "=", "-", "1", ")", "\n", "_std", "=", "tf", ".", "concat", "(", "_std", ",", "axis", "=", "-", "1", ")", "\n", "if", "sigma", "is", "not", "None", ":", "\n", "                ", "_std", "=", "_std", "/", "(", "tf", ".", "reduce_max", "(", "_std", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "/", "sigma", ")", "\n", "", "_new_dist", "=", "tfd", ".", "TransformedDistribution", "(", "\n", "distribution", "=", "tfd", ".", "Normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ")", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Chain", "(", "\n", "_dists", "[", "0", "]", ".", "bijector", ".", "bijectors", "[", ":", "-", "1", "]", "\n", "+", "[", "tfp", ".", "bijectors", ".", "AffineScalar", "(", "shift", "=", "_mean", ",", "scale", "=", "_std", ")", ",", "]", "\n", ")", ",", "\n", "event_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "-", "1", "]", "]", ",", "\n", "batch_shape", "=", "[", "tf", ".", "shape", "(", "_mean", ")", "[", "0", "]", "]", "\n", ")", "\n", "\n", "return", "_new_dist", ".", "sample", "(", ")", "\n", "\n", "", "return", "_behavior", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic": [[611, 621], ["s1.append", "tensorflow.reduce_mean", "d_"], "methods", ["None"], ["", "def", "_get_dynamic", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1", ".", "append", "(", "d_", "(", "s", ",", "a", ")", "[", "0", "]", ")", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_uncertainty": [[622, 643], ["tensorflow.reduce_max", "d_", "s1.append", "tensorflow.concat", "_stds.append", "tensorflow.linalg.norm", "tensorflow.concat.append", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_get_dynamic_uncertainty", "(", "self", ",", "dynamic", ")", ":", "\n", "\n", "        ", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", ",", "_stds", "=", "[", "]", ",", "[", "]", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1_", ",", "_", ",", "_", ",", "_dists", "=", "d_", "(", "s", ",", "a", ")", "\n", "s1", ".", "append", "(", "s1_", ")", "\n", "_std", "=", "[", "]", "\n", "for", "_dist", "in", "_dists", ":", "\n", "                    ", "affine_params", "=", "_dist", ".", "bijector", ".", "bijectors", "[", "-", "1", "]", "\n", "_std", ".", "append", "(", "affine_params", ".", "scale", ")", "\n", "", "_std", "=", "tf", ".", "concat", "(", "_std", ",", "axis", "=", "-", "1", ")", "\n", "_stds", ".", "append", "(", "_std", ")", "\n", "", "penalty", "=", "tf", ".", "reduce_max", "(", "tf", ".", "linalg", ".", "norm", "(", "_stds", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "# _g = tf.greater(penalty, threshold)", "\n", "# penalty_label = tf.where(_g, tf.ones(penalty.shape), tf.zeros(penalty.shape))", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", ",", "penalty", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_diff": [[644, 660], ["enumerate", "tensorflow.reduce_max", "s1.append", "tensorflow.linalg.norm", "d_", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_get_dynamic_diff", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "\"\"\"Computing the diff between pairs of the outputs\"\"\"", "\n", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "diff", "=", "[", "]", "\n", "for", "i", ",", "d_", "in", "enumerate", "(", "dynamic", ")", ":", "\n", "                ", "s1_", "=", "d_", "(", "s", ",", "a", ")", "[", "0", "]", "\n", "if", "i", ">", "0", ":", "\n", "                    ", "diff", "+=", "[", "sx", "-", "s1_", "for", "sx", "in", "s1", "]", "\n", "", "s1", ".", "append", "(", "s1_", ")", "\n", "", "penalty", "=", "tf", ".", "reduce_max", "(", "tf", ".", "linalg", ".", "norm", "(", "diff", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", ",", "penalty", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_dist": [[661, 675], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reduce_mean", "tensorflow.reduce_mean.append", "tensorflow.linalg.norm", "d_"], "methods", ["None"], ["", "def", "_get_dynamic_dist", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "\"\"\"Computing the max distances over models as the uncertainty\"\"\"", "\n", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1", ".", "append", "(", "d_", "(", "s", ",", "a", ")", "[", "0", "]", ")", "\n", "", "s1_mean", "=", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "# average predictions over models", "\n", "diffs", "=", "[", "sx", "-", "s1_mean", "for", "sx", "in", "s1", "]", "\n", "penalty", "=", "tf", ".", "reduce_max", "(", "tf", ".", "linalg", ".", "norm", "(", "diffs", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "0", ")", "# max distances over models", "\n", "s1", "=", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "\n", "return", "s1", "[", ":", ",", ":", "-", "1", "]", ",", "s1", "[", ":", ",", "-", "1", "]", ",", "penalty", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_sensitivity": [[676, 696], ["tensorflow.reduce_max", "s1.append", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.math.reduce_std", "sens.append", "tensorflow.linalg.norm", "tensorflow.random.normal", "d_", "tensorflow.reduce_mean", "d_"], "methods", ["None"], ["", "def", "_get_dynamic_sensitivity", "(", "self", ",", "dynamic", ")", ":", "\n", "        ", "\"\"\"Computing the sensitivity of the dynamics (adding noise into the input data)\"\"\"", "\n", "@", "tf", ".", "function", "\n", "def", "_dynamic", "(", "s", ",", "a", ",", "id", "=", "0", ")", ":", "\n", "            ", "s1", "=", "[", "]", "\n", "sens", "=", "[", "]", "\n", "for", "d_", "in", "dynamic", ":", "\n", "                ", "s1", ".", "append", "(", "d_", "(", "s", ",", "a", ")", "[", "0", "]", ")", "\n", "s_n", "=", "tf", ".", "tile", "(", "s", ",", "(", "10", ",", "1", ")", ")", "\n", "s_n", "=", "s_n", "+", "tf", ".", "random", ".", "normal", "(", "shape", "=", "s_n", ".", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "0.05", ")", "\n", "a_", "=", "tf", ".", "tile", "(", "a", ",", "(", "10", ",", "1", ")", ")", "\n", "s1_n", "=", "d_", "(", "s_n", ",", "a_", ")", "[", "0", "]", "\n", "s1_n", "=", "tf", ".", "reshape", "(", "s1_n", ",", "(", "10", ",", "s", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "std_", "=", "tf", ".", "math", ".", "reduce_std", "(", "s1_n", ",", "axis", "=", "0", ")", "\n", "sens", ".", "append", "(", "std_", ")", "\n", "", "penalty", "=", "tf", ".", "reduce_max", "(", "tf", ".", "linalg", ".", "norm", "(", "sens", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "# s1 = tf.reduce_mean(s1, axis=0)", "\n", "return", "s1", "[", "id", "]", "[", ":", ",", ":", "-", "1", "]", ",", "tf", ".", "reduce_mean", "(", "s1", ",", "axis", "=", "0", ")", "[", ":", ",", "-", "1", "]", ",", "penalty", "\n", "\n", "", "return", "_dynamic", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._dynamics_uncertainty_analysis": [[697, 725], ["mopp_agent.Agent._train_data.get_all_data", "all_data[].numpy", "all_data[].numpy", "numpy.array_split", "numpy.array_split", "numpy.array_split", "numpy.array_split", "range", "numpy.concatenate", "numpy.concatenate", "numpy.array", "mopp_agent.Agent._get_dynamic_uncertainty", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.io.gfile.GFile", "numpy.save", "mopp_agent.Agent._get_dynamic_diff", "numpy.random.normal().astype", "numpy.random.normal().astype", "mopp_agent.Agent._get_dynamic_dist", "mopp_agent.Agent.", "mopp_agent.Agent.", "mopp_agent.Agent._get_dynamic_sensitivity", "numpy.random.normal", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.get_all_data", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_uncertainty", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.save", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_diff", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_dist", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._get_dynamic_sensitivity"], ["", "def", "_dynamics_uncertainty_analysis", "(", "self", ",", "d_name", ",", "save_path", ",", "noise", "=", "0.1", ")", ":", "\n", "        ", "if", "d_name", "is", "'std'", ":", "\n", "            ", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_uncertainty", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "", "elif", "d_name", "is", "'diff'", ":", "\n", "            ", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_diff", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "", "elif", "d_name", "is", "'dist'", ":", "\n", "            ", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_dist", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "", "elif", "d_name", "is", "'sens'", ":", "\n", "            ", "dynamic_uncertainty", "=", "self", ".", "_get_dynamic_sensitivity", "(", "[", "self", ".", "_agent_module", ".", "d_nets", "[", "i", "]", "for", "i", "in", "self", ".", "_d_list", "]", ")", "\n", "", "all_data", "=", "self", ".", "_train_data", ".", "get_all_data", "(", ")", "\n", "all_s1", "=", "all_data", "[", "0", "]", ".", "numpy", "(", ")", "\n", "all_a1", "=", "all_data", "[", "2", "]", ".", "numpy", "(", ")", "\n", "all_s1_noise", "=", "all_s1", "+", "np", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ",", "size", "=", "all_s1", ".", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "*", "noise", "\n", "all_a1_noise", "=", "all_a1", "+", "np", ".", "random", ".", "normal", "(", "loc", "=", "0.0", ",", "scale", "=", "1.0", ",", "size", "=", "all_a1", ".", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "*", "noise", "\n", "penalty", ",", "penalty_noise", "=", "[", "]", ",", "[", "]", "\n", "num", "=", "5000", "\n", "s1_split", "=", "np", ".", "array_split", "(", "all_s1", ",", "num", ")", "\n", "a1_split", "=", "np", ".", "array_split", "(", "all_a1", ",", "num", ")", "\n", "s1_noise_split", "=", "np", ".", "array_split", "(", "all_s1_noise", ",", "num", ")", "\n", "a1_noise_split", "=", "np", ".", "array_split", "(", "all_a1_noise", ",", "num", ")", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "            ", "penalty", ".", "append", "(", "dynamic_uncertainty", "(", "s1_split", "[", "i", "]", ",", "a1_split", "[", "i", "]", ")", "[", "-", "1", "]", ")", "\n", "penalty_noise", ".", "append", "(", "dynamic_uncertainty", "(", "s1_noise_split", "[", "i", "]", ",", "a1_noise_split", "[", "i", "]", ")", "[", "-", "1", "]", ")", "\n", "", "penalty", "=", "np", ".", "concatenate", "(", "penalty", ")", "\n", "penalty_noise", "=", "np", ".", "concatenate", "(", "penalty_noise", ")", "\n", "penalty_results", "=", "np", ".", "array", "(", "[", "penalty", ",", "penalty_noise", "]", ")", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "save_path", "+", "f'/{d_name}-noise{noise}.npy'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "np", ".", "save", "(", "f", ",", "penalty_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._compute_uncertainty_threshold": [[726, 740], ["mopp_agent.Agent._train_data.get_all_data", "all_data[].numpy", "all_data[].numpy", "numpy.array_split", "numpy.array_split", "range", "numpy.concatenate", "numpy.percentile", "print", "numpy.concatenate.append", "mopp_agent.Agent.dynamic_uncertainty"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.dataset.DatasetView.get_all_data"], ["", "", "def", "_compute_uncertainty_threshold", "(", "self", ")", ":", "\n", "        ", "\"\"\"Computing the uncertainty threshold with the real data set\"\"\"", "\n", "all_data", "=", "self", ".", "_train_data", ".", "get_all_data", "(", ")", "\n", "all_s1_np", "=", "all_data", "[", "0", "]", ".", "numpy", "(", ")", "\n", "all_a1_np", "=", "all_data", "[", "2", "]", ".", "numpy", "(", ")", "\n", "penalty", "=", "[", "]", "\n", "num", "=", "5000", "\n", "s1_split", "=", "np", ".", "array_split", "(", "all_s1_np", ",", "num", ")", "\n", "a1_split", "=", "np", ".", "array_split", "(", "all_a1_np", ",", "num", ")", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "            ", "penalty", ".", "append", "(", "self", ".", "dynamic_uncertainty", "(", "s1_split", "[", "i", "]", ",", "a1_split", "[", "i", "]", ")", "[", "-", "1", "]", ")", "\n", "", "penalty", "=", "np", ".", "concatenate", "(", "penalty", ")", "\n", "self", ".", "d_uncertainty_threshold", "=", "np", ".", "percentile", "(", "penalty", ",", "self", ".", "_uncertainty_percentile", ")", "\n", "print", "(", "f'The dynamics uncertainty threshold that computed from the data set is {self.d_uncertainty_threshold}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._clear_sol": [[741, 744], ["None"], "methods", ["None"], ["", "def", "_clear_sol", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear prev sol\"\"\"", "\n", "self", ".", "prev_sol", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_sol": [[745, 755], ["numpy.expand_dims", "numpy.expand_dims.repeat", "mopp_agent.Agent.behavior", "numpy.mean", "numpy.tile", "mean.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "_init_sol", "(", "self", ",", "curr_x", ")", ":", "\n", "        ", "\"\"\"Initialize the actions using the behavior policy\"\"\"", "\n", "curr_x", "=", "np", ".", "expand_dims", "(", "curr_x", ",", "0", ")", "\n", "repeat_curr_x", "=", "curr_x", ".", "repeat", "(", "self", ".", "pop_size", ",", "axis", "=", "0", ")", "\n", "actions", "=", "self", ".", "behavior", "(", "repeat_curr_x", ")", "\n", "mean", "=", "np", ".", "mean", "(", "actions", ",", "axis", "=", "0", ")", "\n", "mean", "=", "np", ".", "tile", "(", "mean", ",", "self", ".", "pred_len", ")", "\n", "mean", "=", "mean", ".", "reshape", "(", "self", ".", "pred_len", ",", "self", ".", "_a_dim", ")", "\n", "\n", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._mopp_sol": [[757, 868], ["noise.astype.astype.astype", "noise.astype.astype.copy", "numpy.tile", "tensorflow.convert_to_tensor", "range", "numpy.array", "numpy.where", "numpy.sum", "numpy.clip", "numpy.sum", "numpy.exp", "len", "mopp_agent.Agent._init_sol", "numpy.random.normal", "mopp_agent.Agent._compute_uncertainty_threshold", "mopp_agent.Agent.behavior_maxq", "mopp_agent.Agent.dynamic_uncertainty", "numpy.array.append", "numpy.concatenate.append", "numpy.where", "len", "numpy.sum", "numpy.percentile", "tensorflow.tile", "mopp_agent.Agent._behavior_sample", "mopp_agent.Agent.value_fn().numpy", "numpy.reshape", "numpy.concatenate", "numpy.array", "numpy.sum", "numpy.sum", "len", "numpy.random.randint", "tensorflow.convert_to_tensor", "numpy.random.randint", "penalty_.numpy", "r.numpy", "numpy.where", "numpy.array", "numpy.random.randint", "numpy.mean", "len", "mopp_agent.Agent.numpy", "len", "len", "mopp_agent.Agent.value_fn", "numpy.array", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._init_sol", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent._compute_uncertainty_threshold"], ["", "def", "_mopp_sol", "(", "self", ",", "observation", ",", "state", "=", "(", ")", ")", ":", "\n", "        ", "\"\"\" calculate the optimal inputs\"\"\"", "\n", "if", "len", "(", "observation", ".", "shape", ")", "==", "2", ":", "\n", "            ", "assert", "observation", ".", "shape", "[", "0", "]", "==", "1", "\n", "curr_x", "=", "observation", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "observation", ".", "shape", ")", "==", "1", "\n", "curr_x", "=", "observation", "\n", "# get prev_sol", "\n", "", "if", "self", ".", "prev_sol", "is", "None", ":", "\n", "            ", "self", ".", "prev_sol", "=", "self", ".", "_init_sol", "(", "curr_x", ")", "\n", "# get noised inputs", "\n", "", "noise", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1.0", ",", "size", "=", "(", "self", ".", "pop_size", ",", "self", ".", "pred_len", ",", "\n", "self", ".", "_a_dim", ")", ")", "*", "self", ".", "noise_sigma", "\n", "noise", "=", "noise", ".", "astype", "(", "'float32'", ")", "\n", "noised_inputs", "=", "noise", ".", "copy", "(", ")", "\n", "s", "=", "np", ".", "tile", "(", "curr_x", ",", "(", "self", ".", "pop_size", ",", "1", ")", ")", "\n", "s", "=", "tf", ".", "convert_to_tensor", "(", "s", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rewards", "=", "[", "]", "\n", "penalty", "=", "[", "]", "\n", "if", "self", ".", "d_uncertainty_threshold", "is", "None", ":", "\n", "            ", "self", ".", "_compute_uncertainty_threshold", "(", ")", "\n", "", "for", "t", "in", "range", "(", "self", ".", "pred_len", ")", ":", "\n", "# a_sample = self.behavior(s, np.random.randint(0, len(self._b_fns))) + noise[:, t, :]", "\n", "            ", "a_sample", "=", "self", ".", "behavior_maxq", "(", "s", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", "\n", "a_sample_mix", "=", "self", ".", "beta", "*", "self", ".", "prev_sol", "[", "t", ",", ":", "]", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "a_sample", ".", "numpy", "(", ")", "\n", "noised_inputs", "[", ":", ",", "t", ",", ":", "]", "=", "a_sample_mix", "\n", "s", ",", "r", ",", "penalty_", "=", "self", ".", "dynamic_uncertainty", "(", "s", ",", "\n", "tf", ".", "convert_to_tensor", "(", "a_sample_mix", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_d_list", ")", ")", ")", "\n", "\n", "# For constrained control", "\n", "# Hard constrained", "\n", "# v_p_id = np.where(s.numpy()[:, 8] > 10)[0]", "\n", "# penalty_ = penalty_.numpy()", "\n", "# penalty_[v_p_id] = self.d_uncertainty_threshold + 0.1", "\n", "\n", "# Soft constrained", "\n", "# alpha = 100", "\n", "# v_p = s.numpy()[:, 8] - 10", "\n", "# v_p = np.where(v_p > 0, v_p, 0)", "\n", "# penalty_ = penalty_.numpy() + v_p * alpha", "\n", "\n", "penalty", ".", "append", "(", "penalty_", ".", "numpy", "(", ")", ")", "\n", "# penalty_label.append(np.where(penalty > self.d_uncertainty_threshold, 1, 0))", "\n", "# Relabel the reward", "\n", "# r_ctrl = - 0.1 * np.square(a_sample.numpy()).sum(axis=-1)", "\n", "# v_x = r.numpy() - r_ctrl", "\n", "# r = np.where(v_x > 3, 3, v_x) + r_ctrl + 15 * (s.numpy()[:, 0]-state)", "\n", "\n", "# old_r = r.numpy()", "\n", "# r = np.where(old_r > 3, 3, old_r) + 100 * (s.numpy()[:, 0] - state)", "\n", "\n", "# r = r.numpy() + 15 * (s.numpy()[:, 0]-state)", "\n", "\n", "# alpha = 0.4", "\n", "# r = r.numpy() * alpha + (1-alpha) * 100 * (s.numpy()[:, 0] - state)", "\n", "\n", "# For constrained control", "\n", "# alpha = 0.5", "\n", "# v_x_p = 10 - s.numpy()[:, 8]", "\n", "# v_penalty = np.where(v_x_p > 0, 0, v_x_p)", "\n", "# r = r.numpy() * alpha + (1-alpha) * 100 * v_penalty", "\n", "\n", "rewards", ".", "append", "(", "r", ".", "numpy", "(", ")", ")", "\n", "# filtrating the trajectories", "\n", "", "penalty", "=", "np", ".", "array", "(", "penalty", ")", "# shape: (pred_len, pop_size)", "\n", "penalty_label", "=", "np", ".", "where", "(", "penalty", ">", "self", ".", "d_uncertainty_threshold", ",", "penalty", ",", "0", ")", "# shape: (pred_len, pop_size)", "\n", "penalty_label_sum", "=", "np", ".", "sum", "(", "penalty_label", ",", "axis", "=", "0", ")", "\n", "select_ids", "=", "np", ".", "where", "(", "penalty_label_sum", "==", "0", ")", "[", "0", "]", "\n", "if", "len", "(", "select_ids", ")", "<", "0.2", "*", "self", ".", "pop_size", ":", "\n", "# choose the top trajectories that with low penalty", "\n", "            ", "traj_penalty", "=", "np", ".", "sum", "(", "penalty", ",", "axis", "=", "0", ")", "\n", "s_thres", "=", "np", ".", "percentile", "(", "traj_penalty", ",", "20", ")", "\n", "select_ids", "=", "np", ".", "where", "(", "traj_penalty", "<=", "s_thres", ")", "[", "0", "]", "\n", "rewards", "=", "np", ".", "array", "(", "rewards", ")", "-", "self", ".", "_penalty_lambda", "*", "penalty_label", "\n", "# print('All the trajectories exceed the uncertainty threshold!')", "\n", "# clip actions", "\n", "", "noised_inputs", "=", "noised_inputs", "[", "select_ids", "]", "\n", "noised_inputs", "=", "np", ".", "clip", "(", "\n", "noised_inputs", ",", "self", ".", "_a_min", ",", "self", ".", "_a_max", ")", "\n", "# calc reward", "\n", "if", "self", ".", "_use_value_fn", ":", "\n", "            ", "s", "=", "tf", ".", "tile", "(", "s", ",", "[", "self", ".", "_n_action_samples", ",", "1", "]", ")", "\n", "a_last", "=", "self", ".", "_behavior_sample", "(", "s", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_b_list", ")", ")", ")", "\n", "q_last", "=", "self", ".", "value_fn", "(", "s", ",", "a_last", ")", ".", "numpy", "(", ")", "\n", "q_last", "=", "np", ".", "reshape", "(", "q_last", ",", "[", "self", ".", "_n_action_samples", ",", "-", "1", "]", ")", "\n", "v_last", "=", "np", ".", "mean", "(", "q_last", ",", "axis", "=", "0", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "rewards", "=", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "rewards", ")", ",", "v_last", "]", ",", "axis", "=", "0", ")", "# shape: (pred_len+1, pop_size)", "\n", "# a_last = self.behavior_maxq(s, np.random.randint(0, len(self._b_list)))", "\n", "# q_last = self.value_fn(s, a_last).numpy()", "\n", "# q_last = q_last[np.newaxis, :]", "\n", "# rewards = np.concatenate([np.array(rewards), q_last], axis=0)  # shape: (pred_len+1, pop_size)", "\n", "", "rewards", "=", "np", ".", "array", "(", "rewards", ")", "[", ":", ",", "select_ids", "]", "# shape: (pred_len, pop_size)", "\n", "rewards", "=", "np", ".", "sum", "(", "rewards", ",", "axis", "=", "0", ")", "\n", "# mppi update", "\n", "# normalize and get sum of reward", "\n", "# exp_rewards.shape = (N, )", "\n", "exp_rewards", "=", "np", ".", "exp", "(", "self", ".", "kappa", "*", "(", "rewards", "-", "np", ".", "max", "(", "rewards", ")", ")", ")", "\n", "denom", "=", "np", ".", "sum", "(", "exp_rewards", ")", "+", "1e-10", "# avoid numeric error", "\n", "# weight actions", "\n", "weighted_inputs", "=", "exp_rewards", "[", ":", ",", "np", ".", "newaxis", ",", "np", ".", "newaxis", "]", "*", "noised_inputs", "\n", "sol", "=", "np", ".", "sum", "(", "weighted_inputs", ",", "0", ")", "/", "denom", "\n", "# update", "\n", "self", ".", "prev_sol", "[", ":", "-", "1", "]", "=", "sol", "[", "1", ":", "]", "\n", "self", ".", "prev_sol", "[", "-", "1", "]", "=", "sol", "[", "-", "1", "]", "# last use the terminal input", "\n", "# self.past_action = sol[0]", "\n", "\n", "return", "sol", "[", "0", "]", "[", "np", ".", "newaxis", ",", ":", "]", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule._build_modules": [[873, 894], ["range", "tensorflow.Variable", "tensorflow.Variable", "mopp_agent.AgentModule._b_nets.append", "mopp_agent.AgentModule._d_nets.append", "mopp_agent.AgentModule._q_nets.append", "mopp_agent.AgentModule._modules.b_net_factory", "mopp_agent.AgentModule._modules.d_net_factory", "mopp_agent.AgentModule._modules.q_net_factory", "mopp_agent.AgentModule._modules.q_net_factory"], "methods", ["None"], ["def", "_build_modules", "(", "self", ")", ":", "\n", "        ", "self", ".", "_b_nets", "=", "[", "]", "\n", "self", ".", "_d_nets", "=", "[", "]", "\n", "self", ".", "_q_nets", "=", "[", "]", "\n", "n_q_fns", "=", "self", ".", "_modules", ".", "n_q_fns", "\n", "for", "_rank", "in", "self", ".", "_modules", ".", "b_out_ranks", ":", "\n", "            ", "self", ".", "_b_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "b_net_factory", "(", "_rank", ")", "\n", ")", "\n", "", "for", "_rank", "in", "self", ".", "_modules", ".", "d_out_ranks", ":", "\n", "            ", "self", ".", "_d_nets", ".", "append", "(", "\n", "self", ".", "_modules", ".", "d_net_factory", "(", "_rank", ")", "\n", ")", "\n", "", "for", "_", "in", "range", "(", "n_q_fns", ")", ":", "\n", "            ", "self", ".", "_q_nets", ".", "append", "(", "\n", "[", "self", ".", "_modules", ".", "q_net_factory", "(", ")", ",", "\n", "self", ".", "_modules", ".", "q_net_factory", "(", ")", ",", "]", "# source and target", "\n", ")", "\n", "\n", "", "self", ".", "_b_alpha_entropy_var", "=", "tf", ".", "Variable", "(", "1.0", ")", "\n", "self", ".", "_d_alpha_entropy_var", "=", "tf", ".", "Variable", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.get_b_alpha_entropy": [[895, 897], ["scripts.utils.relu_v2"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.relu_v2"], ["", "def", "get_b_alpha_entropy", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "relu_v2", "(", "self", ".", "_b_alpha_entropy_var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.get_d_alpha_entropy": [[898, 900], ["scripts.utils.relu_v2"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.relu_v2"], ["", "def", "get_d_alpha_entropy", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "relu_v2", "(", "self", ".", "_d_alpha_entropy_var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.assign_alpha_entropy": [[901, 904], ["mopp_agent.AgentModule._b_alpha_entropy_var.assign", "mopp_agent.AgentModule._d_alpha_entropy_var.assign"], "methods", ["None"], ["", "def", "assign_alpha_entropy", "(", "self", ",", "b_alpha", ",", "d_alpha", ")", ":", "\n", "        ", "self", ".", "_b_alpha_entropy_var", ".", "assign", "(", "b_alpha", ")", "\n", "self", ".", "_d_alpha_entropy_var", ".", "assign", "(", "d_alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.b_ae_variables": [[905, 908], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_ae_variables", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "_b_alpha_entropy_var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.d_ae_variables": [[909, 912], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_ae_variables", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "_d_alpha_entropy_var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.b_nets": [[913, 916], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_b_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.b_weights": [[917, 923], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_weights", "(", "self", ")", ":", "\n", "        ", "b_weights", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "b_weights", "+=", "b_net", ".", "weights", "\n", "", "return", "b_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.b_variables": [[924, 930], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "b_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "b_net", "in", "self", ".", "_b_nets", ":", "\n", "            ", "vars_", "+=", "b_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.d_nets": [[931, 934], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_d_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.d_weights": [[935, 941], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_weights", "(", "self", ")", ":", "\n", "        ", "d_weights", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "d_weights", "+=", "d_net", ".", "weights", "\n", "", "return", "d_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.d_variables": [[942, 948], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "d_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "d_net", "in", "self", ".", "_d_nets", ":", "\n", "            ", "vars_", "+=", "d_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.q_nets": [[949, 952], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_nets", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_q_nets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.q_source_weights": [[953, 959], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_source_weights", "(", "self", ")", ":", "\n", "        ", "q_weights", "=", "[", "]", "\n", "for", "q_net", ",", "_", "in", "self", ".", "_q_nets", ":", "\n", "            ", "q_weights", "+=", "q_net", ".", "weights", "\n", "", "return", "q_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.q_target_weights": [[960, 966], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_target_weights", "(", "self", ")", ":", "\n", "        ", "q_weights", "=", "[", "]", "\n", "for", "_", ",", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "q_weights", "+=", "q_net", ".", "weights", "\n", "", "return", "q_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.q_source_variables": [[967, 973], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_source_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "q_net", ",", "_", "in", "self", ".", "_q_nets", ":", "\n", "            ", "vars_", "+=", "q_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.AgentModule.q_target_variables": [[974, 980], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "q_target_variables", "(", "self", ")", ":", "\n", "        ", "vars_", "=", "[", "]", "\n", "for", "_", ",", "q_net", "in", "self", ".", "_q_nets", ":", "\n", "            ", "vars_", "+=", "q_net", ".", "trainable_variables", "\n", "", "return", "tuple", "(", "vars_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Config._get_modules": [[1023, 1028], ["mopp_agent.get_modules"], "methods", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.get_modules"], ["    ", "def", "_get_modules", "(", "self", ")", ":", "\n", "        ", "return", "get_modules", "(", "\n", "self", ".", "_agent_flags", ".", "model_params", ",", "\n", "self", ".", "_agent_flags", ".", "action_spec", ",", "\n", "self", ".", "_agent_flags", ".", "observation_spec", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.get_modules": [[982, 1019], ["scripts.utils.Flags", "len", "tuple", "scripts.networks.ADMBehavior", "scripts.networks.ADMDynamic", "scripts.networks.CriticNetwork", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange"], "function", ["None"], ["", "", "def", "get_modules", "(", "model_params", ",", "action_spec", ",", "state_spec", ")", ":", "\n", "    ", "\"\"\"Get agent modules.\"\"\"", "\n", "model_params", ",", "b_out_ranks", ",", "d_out_ranks", "=", "model_params", "\n", "if", "b_out_ranks", "is", "None", ":", "\n", "        ", "b_out_ranks", "=", "[", "np", ".", "arange", "(", "action_spec", ".", "shape", "[", "0", "]", ")", ",", "\n", "np", ".", "arange", "(", "action_spec", ".", "shape", "[", "0", "]", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "", "if", "d_out_ranks", "is", "None", ":", "\n", "        ", "d_out_ranks", "=", "[", "np", ".", "arange", "(", "state_spec", ".", "shape", "[", "0", "]", "+", "1", ")", ",", "\n", "np", ".", "arange", "(", "state_spec", ".", "shape", "[", "0", "]", "+", "1", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "", "if", "len", "(", "model_params", ")", "==", "1", ":", "\n", "        ", "model_params", "=", "tuple", "(", "[", "model_params", "[", "0", "]", "]", "*", "2", ")", "\n", "\n", "", "def", "b_net_factory", "(", "out_rank", ")", ":", "\n", "        ", "return", "networks", ".", "ADMBehavior", "(", "\n", "action_spec", ",", "\n", "fc_layer_params", "=", "model_params", "[", "0", "]", ",", "\n", "out_reranking", "=", "out_rank", ")", "\n", "\n", "", "def", "d_net_factory", "(", "out_rank", ")", ":", "\n", "        ", "return", "networks", ".", "ADMDynamic", "(", "\n", "state_dim", "=", "state_spec", ".", "shape", "[", "0", "]", ",", "\n", "fc_layer_params", "=", "model_params", "[", "1", "]", ",", "\n", "out_reranking", "=", "out_rank", ")", "\n", "\n", "", "def", "q_net_factory", "(", ")", ":", "\n", "        ", "return", "networks", ".", "CriticNetwork", "(", "\n", "fc_layer_params", "=", "model_params", "[", "2", "]", "[", "0", "]", ")", "\n", "\n", "", "modules", "=", "utils", ".", "Flags", "(", "\n", "b_net_factory", "=", "b_net_factory", ",", "\n", "d_net_factory", "=", "d_net_factory", ",", "\n", "q_net_factory", "=", "q_net_factory", ",", "\n", "n_q_fns", "=", "model_params", "[", "2", "]", "[", "1", "]", ",", "\n", "b_out_ranks", "=", "b_out_ranks", ",", "\n", "d_out_ranks", "=", "d_out_ranks", ",", "\n", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.train_eval_planning.train_eval_planning": [[31, 272], ["int", "int", "print", "print", "print", "print", "print", "print", "print", "scripts.utils.Flags", "scripts.utils.Flags", "scripts.utils.Flags", "vars", "print", "agent_module.Agent", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "get_offline_data.get_data_env_d4rl", "ValueError", "gym.make", "gym.make.seed", "numpy.random.seed", "tensorflow.set_random_seed", "wrappers.wrapped_il_env", "tf_agents.environments.tf_py_environment.TFPyEnvironment", "sys.path.append", "importlib.import_module", "getattr", "getattr", "agent_module.Config", "tensorflow.io.gfile.exists", "agent_module.Agent.restore_dynamics_model", "tensorflow.io.gfile.exists", "agent_module.Agent.restore_behavior_model", "agent_module.Agent.test_behavior_all_data", "agent_module.Agent.test_dynamic_all_data", "os.path.join", "tensorflow.io.gfile.exists", "agent_module.Agent.restore_q_model", "os.path.join", "collections.OrderedDict", "agent_module.Agent.test_policies.keys", "time.time", "scripts.train_eval_utils.eval_policies", "eval_r_results.append", "eval_r_infos.items", "absl.logging.info", "absl.logging.info", "numpy.array", "tf_agents.environments.gym_wrapper.GymWrapper", "env_name.split", "vars", "absl.logging.info", "absl.logging.info", "tensorflow.compat.v2.summary.create_file_writer", "range", "agent_module.Agent.save_dynamics_model", "absl.logging.info", "absl.logging.info", "tensorflow.compat.v2.summary.create_file_writer", "range", "agent_module.Agent.save_behavior_model", "tensorflow.io.gfile.GFile", "numpy.save", "tensorflow.io.gfile.GFile", "numpy.save", "absl.logging.info", "absl.logging.info", "os.path.join", "tensorflow.compat.v2.summary.create_file_writer", "range", "agent_module.Agent.save_q_model", "tensorflow.compat.v2.summary.create_file_writer", "absl.logging.info", "scripts.utils.write_summary", "time.time", "agent_module.Agent.train_dynamics_step", "agent_module.Agent.train_behavior_step", "numpy.array", "numpy.array", "agent_module.Agent.train_q_step", "os.path.join", "scripts.utils.get_summary_str", "absl.logging.info", "agent_module.Agent.write_d_train_summary", "absl.logging.info", "agent_module.Agent.write_b_train_summary", "absl.logging.info", "scripts.utils.write_summary", "scripts.utils.get_summary_str", "scripts.utils.get_summary_str", "scripts.utils.get_summary_str"], "function", ["home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.get_offline_data.get_data_env_d4rl", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.wrappers.__init__.wrapped_il_env", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_dynamics_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_behavior_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_behavior_all_data", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.test_dynamic_all_data", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.restore_q_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.train_eval_utils.eval_policies", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_dynamics_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_behavior_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.save", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.None.agent.Agent.save", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.save_q_model", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_dynamics_step", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_behavior_step", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.train_q_step", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.write_d_train_summary", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.rl_planning.mopp_agent.Agent.write_b_train_summary", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.write_summary", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str", "home.repos.pwc.inspect_result.zhanzxy5_MOPP.scripts.utils.get_summary_str"], ["@", "gin", ".", "configurable", "\n", "def", "train_eval_planning", "(", "\n", "# Basic args.", "\n", "log_dir", ",", "\n", "benchmark_name", ",", "\n", "model_dir", ",", "\n", "data_file_source", ",", "\n", "data_file", ",", "\n", "agent_module", ",", "\n", "env_name", "=", "'HalfCheetah-v2'", ",", "\n", "seed", "=", "0", ",", "\n", "# Train and eval args.", "\n", "total_train_steps", "=", "int", "(", "5e4", ")", ",", "\n", "summary_freq", "=", "100", ",", "\n", "print_freq", "=", "1000", ",", "\n", "save_freq", "=", "int", "(", "2e4", ")", ",", "\n", "eval_freq", "=", "5000", ",", "\n", "n_eval_episodes", "=", "20", ",", "\n", "# Agent args.", "\n", "model_params", "=", "(", "(", "(", "(", "300", ",", "300", ")", ",", "(", "300", ",", "100", ")", ")", ",", "(", "(", "300", ",", "300", ")", ",", "(", "300", ",", "100", ")", ")", ")", ",", "None", ",", "None", ")", ",", "\n", "optimizers", "=", "(", "(", "'adam'", ",", "0.001", ")", ",", ")", ",", "\n", "batch_size", "=", "256", ",", "\n", "weight_decays", "=", "(", "0.0", ",", ")", ",", "\n", "update_freq", "=", "1", ",", "\n", "update_rate", "=", "0.005", ",", "\n", "discount", "=", "0.99", ",", "\n", "# num_trajectories=None,  # how many ep trajectories to use", "\n", "num_transitions", "=", "None", ",", "# how many ep transitions to use", "\n", "normalize_states", "=", "False", ",", "# whether normalize states.", "\n", "behavior_ckpt_name", "=", "None", ",", "\n", "dynamics_ckpt_name", "=", "None", ",", "\n", "q_net_ckpt_name", "=", "'placeholder'", ",", "\n", "testing_mode", "=", "False", ",", "\n", "model_id", "=", "0", ",", "\n", "score_normalize", "=", "False", ",", "\n", "state_normalize", "=", "False", ",", "\n", "reward_normalize", "=", "False", ",", "\n", "evaluate", "=", "False", ",", "\n", "per", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Training a policy with a fixed dataset.\"\"\"", "\n", "# Create tf_env to get specs.", "\n", "print", "(", "'[train_eval_offline.py] env_name='", ",", "env_name", ")", "\n", "print", "(", "'[train_eval_offline.py] data_file='", ",", "data_file", ")", "\n", "print", "(", "'[train_eval_offline.py] agent_module='", ",", "agent_module", ")", "\n", "print", "(", "'[train_eval_offline.py] model_params='", ",", "model_params", ")", "\n", "print", "(", "'[train_eval_offline.py] optimizers='", ",", "optimizers", ")", "\n", "print", "(", "'[train_eval_offline.py] bckpt_file='", ",", "behavior_ckpt_name", ")", "\n", "print", "(", "'[train_eval_offline.py] fckpt_file='", ",", "dynamics_ckpt_name", ")", "\n", "if", "q_net_ckpt_name", "is", "not", "None", ":", "\n", "        ", "print", "(", "'[train_eval_offline.py] q_net_ckpt_name='", ",", "q_net_ckpt_name", ")", "\n", "", "if", "env_name", "==", "'Hopper-v2'", ":", "\n", "        ", "s_dim", "=", "11", "\n", "s_max", "=", "np", ".", "inf", "\n", "a_dim", "=", "3", "\n", "a_max", "=", "1", "\n", "", "elif", "env_name", "==", "'HalfCheetah-v2'", ":", "\n", "        ", "s_dim", "=", "17", "\n", "s_max", "=", "np", ".", "inf", "\n", "a_dim", "=", "6", "\n", "a_max", "=", "1", "\n", "", "elif", "env_name", "==", "'Walker2d-v2'", ":", "\n", "        ", "s_dim", "=", "17", "\n", "s_max", "=", "np", ".", "inf", "\n", "a_dim", "=", "6", "\n", "a_max", "=", "1", "\n", "", "elif", "'pen'", "in", "env_name", ":", "\n", "        ", "s_dim", "=", "45", "\n", "a_dim", "=", "24", "\n", "a_max", "=", "1", "\n", "", "elif", "'hammer'", "in", "env_name", ":", "\n", "        ", "s_dim", "=", "46", "\n", "a_dim", "=", "26", "\n", "a_max", "=", "1", "\n", "", "elif", "'door'", "in", "env_name", ":", "\n", "        ", "s_dim", "=", "39", "\n", "a_dim", "=", "28", "\n", "a_max", "=", "1", "\n", "", "elif", "'relocate'", "in", "env_name", ":", "\n", "        ", "s_dim", "=", "39", "\n", "a_dim", "=", "30", "\n", "a_max", "=", "1", "\n", "", "observation_spec", "=", "utils", ".", "Flags", "(", "shape", "=", "(", "s_dim", ",", ")", ",", "minimum", "=", "-", "np", ".", "inf", ",", "maximum", "=", "np", ".", "inf", ")", "\n", "action_spec", "=", "utils", ".", "Flags", "(", "shape", "=", "(", "a_dim", ",", ")", ",", "minimum", "=", "-", "1", ",", "maximum", "=", "a_max", ")", "\n", "# Prepare offline data.", "\n", "if", "benchmark_name", "==", "'d4rl'", ":", "\n", "        ", "d4rl_data_file", "=", "data_file", "+", "'.hdf5'", "\n", "data", ",", "shift", ",", "scale", "=", "get_offline_data", ".", "get_data_env_d4rl", "(", "\n", "[", "s_dim", ",", "a_dim", "]", ",", "file_name", "=", "d4rl_data_file", ",", "identifier", "=", "'model_free'", ",", "\n", "num_transitions", "=", "num_transitions", ",", "normalize_states", "=", "state_normalize", ",", "\n", "scale_rewards", "=", "reward_normalize", ",", "per", "=", "per", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Wrong data file source or not supported currently!\"", ")", "\n", "\n", "# env", "\n", "", "if", "evaluate", ":", "\n", "        ", "import", "d4rl", "\n", "from", "tf_agents", ".", "environments", "import", "tf_py_environment", "\n", "from", "tf_agents", ".", "environments", "import", "gym_wrapper", "\n", "from", "scripts", "import", "wrappers", "\n", "gym_env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "gym_env", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "wrapped_env", "=", "wrappers", ".", "wrapped_il_env", "(", "gym_env", ",", "shift", "=", "shift", ",", "scale", "=", "scale", ")", "\n", "spec_dtype_map", "=", "{", "gym", ".", "spaces", ".", "Box", ":", "np", ".", "float32", "}", "# map to float32", "\n", "tf_env", "=", "tf_py_environment", ".", "TFPyEnvironment", "(", "\n", "gym_wrapper", ".", "GymWrapper", "(", "wrapped_env", ",", "spec_dtype_map", "=", "spec_dtype_map", ")", ")", "\n", "\n", "", "norm_min", "=", "-", "np", ".", "inf", "\n", "norm_max", "=", "np", ".", "inf", "\n", "if", "score_normalize", ":", "\n", "        ", "sys", ".", "path", ".", "append", "(", "'../'", ")", "\n", "import_path", "=", "'data'", "+", "'.'", "+", "benchmark_name", "+", "'.'", "+", "data_file_source", "\n", "module", "=", "importlib", ".", "import_module", "(", "import_path", ")", "\n", "domain", "=", "env_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "norm_min", "=", "getattr", "(", "module", ",", "(", "domain", "+", "'_random_score'", ")", ".", "upper", "(", ")", ")", "\n", "norm_max", "=", "getattr", "(", "module", ",", "(", "domain", "+", "'_expert_score'", ")", ".", "upper", "(", ")", ")", "\n", "\n", "# Create agent.", "\n", "", "agent_flags", "=", "utils", ".", "Flags", "(", "\n", "observation_spec", "=", "observation_spec", ",", "\n", "action_spec", "=", "action_spec", ",", "\n", "model_params", "=", "model_params", ",", "\n", "optimizers", "=", "optimizers", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "weight_decays", "=", "weight_decays", ",", "\n", "update_freq", "=", "update_freq", ",", "\n", "update_rate", "=", "update_rate", ",", "\n", "discount", "=", "discount", ",", "\n", "train_data", "=", "data", ",", "\n", ")", "\n", "agent_args", "=", "agent_module", ".", "Config", "(", "agent_flags", ")", ".", "agent_args", "\n", "my_agent_arg_dict", "=", "{", "}", "\n", "for", "k", "in", "vars", "(", "agent_args", ")", ":", "\n", "        ", "my_agent_arg_dict", "[", "k", "]", "=", "vars", "(", "agent_args", ")", "[", "k", "]", "\n", "", "my_agent_arg_dict", "[", "'observation_spec'", "]", "=", "observation_spec", "\n", "print", "(", "'agent_args:'", ",", "my_agent_arg_dict", ")", "\n", "agent", "=", "agent_module", ".", "Agent", "(", "**", "my_agent_arg_dict", ")", "\n", "# agent_ckpt_name = os.path.join(log_dir, 'agent')", "\n", "\n", "# Train and restore dynamics model.", "\n", "# if dynamics_ckpt_name == 'placeholder':", "\n", "#     raise ValueError(\"You must train a dynamic model in model-based RL\")", "\n", "dynamics_ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "dynamics_ckpt_name", ")", "\n", "train_d_summary_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "dynamics_ckpt_name", "+", "'_train_log'", ")", "\n", "if", "dynamics_ckpt_name", "!=", "'placeholder'", ":", "\n", "        ", "if", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "'{}.index'", ".", "format", "(", "dynamics_ckpt_dir", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Checkpoint found at %s.'", ",", "dynamics_ckpt_dir", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'No trained checkpoint, train the %s.'", ",", "dynamics_ckpt_name", ")", "\n", "train_d_summary_writer", "=", "tf0", ".", "compat", ".", "v2", ".", "summary", ".", "create_file_writer", "(", "\n", "train_d_summary_dir", ")", "\n", "for", "i", "in", "range", "(", "total_train_steps", ")", ":", "\n", "                ", "train_f_info", "=", "agent", ".", "train_dynamics_step", "(", ")", "\n", "if", "i", "%", "print_freq", "==", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "utils", ".", "get_summary_str", "(", "step", "=", "i", ",", "info", "=", "train_f_info", ")", ")", "\n", "", "if", "i", "%", "summary_freq", "==", "0", "or", "i", "==", "total_train_steps", ":", "\n", "                    ", "agent", ".", "write_d_train_summary", "(", "train_d_summary_writer", ",", "i", ",", "train_f_info", ")", "\n", "", "", "agent", ".", "save_dynamics_model", "(", "dynamics_ckpt_dir", ")", "\n", "", "agent", ".", "restore_dynamics_model", "(", "dynamics_ckpt_dir", ")", "\n", "\n", "# Train behavior model if needed.", "\n", "", "behavior_ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "behavior_ckpt_name", ")", "\n", "train_b_summary_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "behavior_ckpt_name", "+", "'_train_log'", ")", "\n", "if", "behavior_ckpt_name", "!=", "'placeholder'", ":", "\n", "        ", "if", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "'{}.index'", ".", "format", "(", "behavior_ckpt_dir", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Checkpoint found at %s.'", ",", "behavior_ckpt_dir", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'No trained checkpoint, train the %s.'", ",", "behavior_ckpt_name", ")", "\n", "train_b_summary_writer", "=", "tf0", ".", "compat", ".", "v2", ".", "summary", ".", "create_file_writer", "(", "\n", "train_b_summary_dir", ")", "\n", "for", "i", "in", "range", "(", "total_train_steps", ")", ":", "\n", "                ", "train_b_info", "=", "agent", ".", "train_behavior_step", "(", ")", "\n", "if", "i", "%", "print_freq", "==", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "utils", ".", "get_summary_str", "(", "step", "=", "i", ",", "info", "=", "train_b_info", ")", ")", "\n", "", "if", "i", "%", "summary_freq", "==", "0", "or", "i", "==", "total_train_steps", ":", "\n", "                    ", "agent", ".", "write_b_train_summary", "(", "train_b_summary_writer", ",", "i", ",", "train_b_info", ")", "\n", "", "", "agent", ".", "save_behavior_model", "(", "behavior_ckpt_dir", ")", "\n", "\n", "# Restore behavior model if needed.", "\n", "", "", "if", "behavior_ckpt_name", "!=", "'placeholder'", ":", "\n", "        ", "agent", ".", "restore_behavior_model", "(", "behavior_ckpt_dir", ")", "\n", "\n", "# dynamics_uncertainty_analysis", "\n", "# for d_name in ['diff', ]:", "\n", "#     agent._dynamics_uncertainty_analysis(d_name, train_d_summary_dir)", "\n", "# return", "\n", "\n", "", "if", "testing_mode", ":", "\n", "        ", "a_mse", "=", "agent", ".", "test_behavior_all_data", "(", ")", "\n", "s_mse", ",", "r_mse", "=", "agent", ".", "test_dynamic_all_data", "(", ")", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "train_b_summary_dir", "+", "f'/behavior{model_id}_test_results.npy'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "np", ".", "save", "(", "f", ",", "np", ".", "array", "(", "[", "a_mse", "]", ")", ")", "\n", "", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "train_d_summary_dir", "+", "f'/dynamics{model_id}_test_results.npy'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "np", ".", "save", "(", "f", ",", "np", ".", "array", "(", "[", "s_mse", ",", "r_mse", "]", ")", ")", "\n", "", "return", "\n", "\n", "# train Q-net", "\n", "", "if", "q_net_ckpt_name", "!=", "'placeholder'", ":", "\n", "        ", "q_net_ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "q_net_ckpt_name", ")", "\n", "if", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "'{}.index'", ".", "format", "(", "q_net_ckpt_dir", ")", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Checkpoint found at %s.'", ",", "q_net_ckpt_dir", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'No trained checkpoint, train the %s.'", ",", "q_net_ckpt_name", ")", "\n", "train_q_summary_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "q_net_ckpt_name", "+", "'_train_log'", ")", "\n", "train_q_summary_writer", "=", "tf0", ".", "compat", ".", "v2", ".", "summary", ".", "create_file_writer", "(", "\n", "train_q_summary_dir", ")", "\n", "for", "i", "in", "range", "(", "total_train_steps", ")", ":", "\n", "                ", "train_q_info", "=", "agent", ".", "train_q_step", "(", "i", ")", "\n", "if", "i", "%", "print_freq", "==", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "utils", ".", "get_summary_str", "(", "step", "=", "i", ",", "info", "=", "train_q_info", ")", ")", "\n", "", "if", "i", "%", "summary_freq", "==", "0", "or", "i", "==", "total_train_steps", ":", "\n", "                    ", "utils", ".", "write_summary", "(", "train_q_summary_writer", ",", "i", ",", "train_q_info", ")", "\n", "", "", "agent", ".", "save_q_model", "(", "q_net_ckpt_dir", ")", "\n", "", "agent", ".", "restore_q_model", "(", "q_net_ckpt_dir", ")", "\n", "\n", "# Evaluating agent.", "\n", "", "if", "evaluate", ":", "\n", "        ", "eval_summary_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'eval'", ")", "\n", "eval_summary_writers", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "policy_key", "in", "agent", ".", "test_policies", ".", "keys", "(", ")", ":", "\n", "            ", "eval_summary_writer", "=", "tf0", ".", "compat", ".", "v2", ".", "summary", ".", "create_file_writer", "(", "\n", "os", ".", "path", ".", "join", "(", "eval_summary_dir", ",", "policy_key", ")", ")", "\n", "eval_summary_writers", "[", "policy_key", "]", "=", "eval_summary_writer", "\n", "", "eval_r_results", "=", "[", "]", "\n", "time_st_total", "=", "time", ".", "time", "(", ")", "\n", "eval_r_result", ",", "eval_r_infos", "=", "train_eval_utils", ".", "eval_policies", "(", "\n", "tf_env", ",", "agent", ".", "test_policies", ",", "n_eval_episodes", ",", "\n", "score_normalize", ",", "norm_min", ",", "norm_max", ")", "\n", "step", "=", "0", "\n", "eval_r_results", ".", "append", "(", "[", "step", "]", "+", "eval_r_result", ")", "\n", "for", "policy_key", ",", "policy_info", "in", "eval_r_infos", ".", "items", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "utils", ".", "get_summary_str", "(", "\n", "step", "=", "None", ",", "info", "=", "policy_info", ",", "prefix", "=", "policy_key", "+", "': '", ")", ")", "\n", "utils", ".", "write_summary", "(", "eval_summary_writers", "[", "policy_key", "]", ",", "step", ",", "policy_info", ")", "\n", "", "logging", ".", "info", "(", "'Testing at step %d:'", ",", "step", ")", "\n", "\n", "time_cost", "=", "time", ".", "time", "(", ")", "-", "time_st_total", "\n", "logging", ".", "info", "(", "'Evaluating finished, time cost %.4gs.'", ",", "time_cost", ")", "\n", "return", "np", ".", "array", "(", "eval_r_results", ")", "\n", "", "", ""]]}