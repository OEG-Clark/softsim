{"home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.__init__": [[20, 23], ["subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.reset"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ",", "iou_threshold", ":", "float", ")", ":", "\n", "        ", "self", ".", "iou_threshold", "=", "iou_threshold", "\n", "self", ".", "reset", "(", ")", "\n", "", "def", "__call__", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.__call__": [[23, 67], ["len", "range", "range", "pred_filtered_tokens.append", "len", "range", "print", "set().intersection", "subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.f1s.append", "len", "subfigure_subcaption_metric.iou", "subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.f1s.append", "len", "set", "float", "float", "subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.f1s.append", "float", "float", "[].isalnum", "filtered_subcaption.append", "[].isalnum", "set", "len", "len", "len", "len", "gold_filtered_tokens.append", "len", "[].isalpha", "len", "[].isalpha"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.iou"], ["", "def", "__call__", "(", "self", ",", "\n", "predicted_subfigures", ":", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", ",", "# [batch_size, 4]", "\n", "predicted_tokens", ":", "List", "[", "List", "[", "List", "[", "int", "]", "]", "]", ",", "# [batch_size, sequence_length]", "\n", "gold_subfigures", ":", "List", "[", "List", "[", "List", "[", "float", "]", "]", "]", ",", "# [batch_size, 4]", "\n", "gold_tokens", ":", "List", "[", "List", "[", "List", "[", "int", "]", "]", "]", ",", "\n", "wordpieces", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "common_wordpieces", ":", "List", "[", "Set", "[", "int", "]", "]", ")", ":", "# [batch_size, sequence_length]", "\n", "        ", "batch_size", "=", "len", "(", "wordpieces", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "pred_filtered_tokens", "=", "[", "]", "\n", "for", "subcaption", "in", "predicted_tokens", "[", "i", "]", ":", "\n", "                ", "filtered_subcaption", "=", "[", "]", "\n", "for", "t", "in", "subcaption", ":", "\n", "                    ", "if", "wordpieces", "[", "i", "]", "[", "t", "]", "[", "0", "]", "!=", "\"#\"", "and", "wordpieces", "[", "i", "]", "[", "t", "]", ".", "isalnum", "(", ")", "and", "(", "len", "(", "wordpieces", "[", "i", "]", "[", "t", "]", ")", ">", "0", "or", "not", "wordpieces", "[", "i", "]", "[", "t", "]", ".", "isalpha", "(", ")", ")", ":", "\n", "# if t not in common_wordpieces[i]:", "\n", "                        ", "filtered_subcaption", ".", "append", "(", "t", ")", "\n", "", "", "pred_filtered_tokens", ".", "append", "(", "filtered_subcaption", ")", "\n", "", "for", "k", "in", "range", "(", "len", "(", "gold_subfigures", "[", "i", "]", ")", ")", ":", "\n", "                ", "max_iou", "=", "0", "\n", "max_iou_index", "=", "None", "\n", "for", "p", "in", "range", "(", "len", "(", "predicted_subfigures", "[", "i", "]", ")", ")", ":", "\n", "                    ", "iou_value", "=", "iou", "(", "predicted_subfigures", "[", "i", "]", "[", "p", "]", ",", "gold_subfigures", "[", "i", "]", "[", "k", "]", ")", "\n", "if", "iou_value", ">", "max_iou", ":", "\n", "                        ", "max_iou", "=", "iou_value", "\n", "max_iou_index", "=", "p", "\n", "", "", "if", "max_iou", "<", "self", ".", "iou_threshold", ":", "\n", "                    ", "self", ".", "f1s", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "gold_filtered_tokens", "=", "[", "]", "\n", "for", "t", "in", "gold_tokens", "[", "i", "]", "[", "k", "]", ":", "\n", "                    ", "if", "wordpieces", "[", "i", "]", "[", "t", "]", "[", "0", "]", "!=", "\"#\"", "and", "wordpieces", "[", "i", "]", "[", "t", "]", ".", "isalnum", "(", ")", "and", "(", "len", "(", "wordpieces", "[", "i", "]", "[", "t", "]", ")", ">", "0", "or", "not", "wordpieces", "[", "i", "]", "[", "t", "]", ".", "isalpha", "(", ")", ")", ":", "\n", "                        ", "if", "t", "not", "in", "common_wordpieces", "[", "i", "]", ":", "\n", "                            ", "gold_filtered_tokens", ".", "append", "(", "t", ")", "\n", "", "", "", "if", "len", "(", "gold_filtered_tokens", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "matching_pred_tokens", "=", "pred_filtered_tokens", "[", "max_iou_index", "]", "\n", "print", "(", "[", "wordpieces", "[", "i", "]", "[", "ind", "]", "for", "ind", "in", "matching_pred_tokens", "]", ")", "\n", "intersection", "=", "set", "(", "gold_filtered_tokens", ")", ".", "intersection", "(", "set", "(", "matching_pred_tokens", ")", ")", "\n", "recall", "=", "float", "(", "len", "(", "intersection", ")", ")", "/", "float", "(", "len", "(", "gold_filtered_tokens", ")", ")", "\n", "if", "recall", "==", "0", ":", "\n", "                    ", "self", ".", "f1s", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "precision", "=", "float", "(", "len", "(", "intersection", ")", ")", "/", "float", "(", "len", "(", "matching_pred_tokens", ")", ")", "\n", "self", ".", "f1s", ".", "append", "(", "2.0", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric": [[68, 75], ["numpy.mean", "len", "subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.reset"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.reset"], ["", "", "", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "f1s", ")", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "avg", "=", "np", ".", "mean", "(", "self", ".", "f1s", ")", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.reset": [[76, 78], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "f1s", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.iou": [[9, 18], ["max", "max", "min", "min", "max", "min", "max", "min"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["def", "iou", "(", "box1", ",", "box2", ")", ":", "\n", "    ", "if", "max", "(", "box1", "[", "0", "]", ",", "box2", "[", "0", "]", ")", ">", "min", "(", "box1", "[", "2", "]", ",", "box2", "[", "2", "]", ")", "or", "max", "(", "box1", "[", "1", "]", ",", "box2", "[", "1", "]", ")", ">", "min", "(", "box1", "[", "3", "]", ",", "box2", "[", "3", "]", ")", ":", "\n", "        ", "return", "0", "\n", "", "intersect_box", "=", "[", "max", "(", "box1", "[", "0", "]", ",", "box2", "[", "0", "]", ")", ",", "max", "(", "box1", "[", "1", "]", ",", "box2", "[", "1", "]", ")", ",", "min", "(", "box1", "[", "2", "]", ",", "box2", "[", "2", "]", ")", ",", "min", "(", "box1", "[", "3", "]", ",", "box2", "[", "3", "]", ")", "]", "\n", "intersect_area", "=", "(", "intersect_box", "[", "2", "]", "-", "intersect_box", "[", "0", "]", ")", "*", "(", "intersect_box", "[", "3", "]", "-", "intersect_box", "[", "1", "]", ")", "\n", "union_area", "=", "(", "box1", "[", "3", "]", "-", "box1", "[", "1", "]", ")", "*", "(", "box1", "[", "2", "]", "-", "box1", "[", "0", "]", ")", "+", "(", "box2", "[", "3", "]", "-", "box2", "[", "1", "]", ")", "*", "(", "box2", "[", "2", "]", "-", "box2", "[", "0", "]", ")", "-", "intersect_area", "\n", "if", "union_area", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "intersect_area", "/", "union_area", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_dataset_reader.ObjectDatasetReader.__init__": [[14, 26], ["allennlp.data.dataset_readers.DatasetReader.__init__", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "image_root", ":", "str", ",", "lazy", ":", "bool", "=", "False", ",", "pass_boxes", ":", "bool", "=", "True", ",", "start_line", ":", "int", "=", "0", ",", "end_line", ":", "int", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "image_root", "=", "image_root", "\n", "self", ".", "pass_boxes", "=", "pass_boxes", "\n", "self", ".", "start_line", "=", "start_line", "\n", "self", ".", "end_line", "=", "end_line", "\n", "expected_img_size", "=", "224", "\n", "self", ".", "image_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "# transforms.Resize(expected_img_size),", "\n", "# transforms.CenterCrop(expected_img_size),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "", "def", "_read", "(", "self", ",", "fname", ":", "str", ")", ":", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_dataset_reader.ObjectDatasetReader._read": [[26, 52], ["open", "open.readlines", "enumerate", "len", "json.loads", "PIL.Image.open().convert", "os.path.exists", "object_dataset_reader.ObjectDatasetReader.text_to_instance", "os.path.join", "PIL.Image.open", "len", "print", "print", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance"], ["", "def", "_read", "(", "self", ",", "fname", ":", "str", ")", ":", "\n", "        ", "f", "=", "open", "(", "fname", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "if", "self", ".", "end_line", "is", "None", ":", "\n", "            ", "self", ".", "end_line", "=", "len", "(", "lines", ")", "\n", "", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "[", "self", ".", "start_line", ":", "self", ".", "end_line", "]", "]", "\n", "for", "i", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "image_id", "=", "datum", "[", "'pdf_hash'", "]", "+", "'_'", "+", "datum", "[", "'fig_uri'", "]", "\n", "if", "datum", "[", "'answer'", "]", "==", "'ignore'", ":", "\n", "                ", "continue", "\n", "", "if", "self", ".", "image_root", "==", "\"\"", ":", "\n", "                ", "image_root", "=", "datum", "[", "'image_root'", "]", "\n", "", "else", ":", "\n", "                ", "image_root", "=", "self", ".", "image_root", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "image_root", ")", ")", ":", "\n", "                ", "continue", "\n", "", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "image_root", ",", "image_id", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "datum", "[", "'answer'", "]", "==", "'reject'", "or", "'spans'", "not", "in", "datum", "or", "len", "(", "datum", "[", "'spans'", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "# datum['spans'] = [{'points': [[0, 0], [0, datum['height']], [datum['width'], datum['height']], [datum['width'], 0]]}]", "\n", "", "for", "span", "in", "datum", "[", "'spans'", "]", ":", "\n", "                ", "if", "span", "[", "'points'", "]", "[", "2", "]", "[", "0", "]", "<", "span", "[", "'points'", "]", "[", "2", "]", "[", "0", "]", ":", "\n", "                    ", "print", "(", "'A'", ",", "span", ")", "\n", "", "if", "span", "[", "'points'", "]", "[", "2", "]", "[", "1", "]", "<", "span", "[", "'points'", "]", "[", "2", "]", "[", "1", "]", ":", "\n", "                    ", "print", "(", "'B'", ",", "span", ")", "\n", "", "", "yield", "self", ".", "text_to_instance", "(", "image", ",", "datum", "[", "'spans'", "]", ",", "image_id", ",", "datum", "[", "'width'", "]", ",", "datum", "[", "'height'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_dataset_reader.ObjectDatasetReader.text_to_instance": [[53, 71], ["object_dataset_reader.ObjectDatasetReader.image_transform", "numpy.array", "allennlp.data.instance.Instance", "allennlp.data.fields.MetadataField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "min", "min", "max", "max", "new_boxes.append", "max", "min", "max", "min"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "", "def", "text_to_instance", "(", "self", ",", "image", ",", "boxes", ",", "image_id", ",", "width", ",", "height", ")", ":", "\n", "        ", "image", "=", "self", ".", "image_transform", "(", "image", ")", "\n", "new_boxes", "=", "[", "]", "\n", "for", "box", "in", "boxes", ":", "\n", "            ", "x_coords", "=", "[", "point", "[", "0", "]", "for", "point", "in", "box", "[", "'points'", "]", "]", "\n", "y_coords", "=", "[", "point", "[", "1", "]", "for", "point", "in", "box", "[", "'points'", "]", "]", "\n", "coords", "=", "[", "min", "(", "x_coords", ")", ",", "min", "(", "y_coords", ")", ",", "max", "(", "x_coords", ")", ",", "max", "(", "y_coords", ")", "]", "\n", "if", "max", "(", "x_coords", ")", ">", "min", "(", "x_coords", ")", "and", "max", "(", "y_coords", ")", ">", "min", "(", "y_coords", ")", ":", "\n", "                ", "new_boxes", ".", "append", "(", "coords", ")", "\n", "", "", "boxes", "=", "np", ".", "array", "(", "new_boxes", ")", "\n", "fields", "=", "{", "'images'", ":", "MetadataField", "(", "image", ")", ",", "# , dtype=np.float32),", "\n", "'heights'", ":", "MetadataField", "(", "height", ")", ",", "\n", "'widths'", ":", "MetadataField", "(", "width", ")", ",", "\n", "'image_ids'", ":", "MetadataField", "(", "image_id", ")", "}", "\n", "if", "self", ".", "pass_boxes", ":", "\n", "            ", "fields", "[", "'boxes'", "]", "=", "ArrayField", "(", "boxes", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "fields", "[", "'num_boxes'", "]", "=", "MetadataField", "(", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.SubcaptionNerDatasetReader.__init__": [[40, 53], ["allennlp.data.dataset_readers.DatasetReader.__init__", "subcaption_ner_dataset_reader.SubcaptionNerDatasetReader.token_indexers.values", "subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "lazy", ":", "bool", "=", "False", ",", "do_lowercase", ":", "bool", "=", "False", ",", "box_predictions_file", ":", "str", "=", "None", ",", "box_predictions_threshold", ":", "float", "=", "0.7", ",", "max_seq_length", ":", "int", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "token_indexers", "=", "token_indexers", "\n", "model_name", "=", "None", "\n", "for", "token_indexer", "in", "self", ".", "token_indexers", ".", "values", "(", ")", ":", "\n", "            ", "model_name", "=", "token_indexer", ".", "_model_name", "\n", "break", "\n", "", "self", ".", "box_predictions_file", "=", "box_predictions_file", "\n", "self", ".", "box_predictions_threshold", "=", "box_predictions_threshold", "\n", "self", ".", "tokenizer", "=", "PretrainedTransformerTokenizer", "(", "model_name", "=", "model_name", ",", "do_lowercase", "=", "do_lowercase", ")", "\n", "# self.tag_map = {'B': 1, 'I': 2, 'L': 3, 'O': 4, 'U': 5}", "\n", "self", ".", "tag_map", "=", "{", "'B'", ":", "'B'", ",", "'I'", ":", "'I'", ",", "'L'", ":", "'L'", ",", "'O'", ":", "'O'", ",", "'U'", ":", "'U'", "}", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.SubcaptionNerDatasetReader._read": [[54, 150], ["open", "open.readlines", "enumerate", "json.loads", "open", "open.readlines", "len", "set", "set", "datum[].values", "common_tokens.intersection.intersection.union", "set", "json.loads", "len", "list", "list", "set", "common_tokens.intersection.intersection.intersection", "sorted", "spans.append", "span_lengths.append", "zip", "subcaption_ner_dataset_reader.SubcaptionNerDatasetReader.text_to_instance", "len", "range", "range", "len", "len", "set", "range", "gold_subfigures.append", "subcaptions_list.append", "single_span_subcaptions_list.append", "single_span_subcaptions_list.append", "pred_subfigures.append", "subcaption_tokens.intersection", "spans.append", "span_lengths.append", "list", "len", "set.add", "len", "pred_subfigures.append", "set", "range", "set.intersection", "len", "min", "min", "max", "max", "list", "len", "range", "set.intersection", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "def", "_read", "(", "self", ",", "fname", ":", "str", ")", ":", "\n", "        ", "f", "=", "open", "(", "fname", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "box_predictions", "=", "None", "\n", "if", "self", ".", "box_predictions_file", "is", "not", "None", ":", "\n", "            ", "box_predictions", "=", "{", "}", "\n", "f", "=", "open", "(", "self", ".", "box_predictions_file", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "box_predictions", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "box_predictions", "=", "{", "datum", "[", "'image_id'", "]", ":", "datum", "for", "datum", "in", "box_predictions", "}", "\n", "", "for", "i", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "# Don't include figures that were ignored or rejected in annotations", "\n", "            ", "if", "datum", "[", "\"answer\"", "]", "!=", "\"accept\"", ":", "\n", "                ", "continue", "\n", "# Don't include figures that don't have subfigures", "\n", "", "if", "len", "(", "datum", "[", "\"spans\"", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "# Don't include figures that lack subcaptions", "\n", "", "if", "\"subcaptions\"", "not", "in", "datum", "or", "len", "(", "datum", "[", "\"subcaptions\"", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "image_id", "=", "datum", "[", "\"pdf_hash\"", "]", "+", "\"_\"", "+", "datum", "[", "\"fig_uri\"", "]", "\n", "single_span_subcaptions", "=", "{", "}", "\n", "subcaptions", "=", "{", "}", "\n", "# First, collect the tokens common to all subcaptions", "\n", "# These tokens will be removed from all subcaptions", "\n", "num_tokens", "=", "len", "(", "datum", "[", "\"tokens\"", "]", ")", "\n", "common_tokens", "=", "set", "(", "list", "(", "range", "(", "num_tokens", ")", ")", ")", "\n", "excluded_tokens", "=", "set", "(", "list", "(", "range", "(", "num_tokens", ")", ")", ")", "\n", "for", "subcaption_key", "in", "datum", "[", "\"subcaptions\"", "]", ":", "\n", "                ", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", "=", "set", "(", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", ")", "\n", "", "for", "subcaption_tokens", "in", "datum", "[", "\"subcaptions\"", "]", ".", "values", "(", ")", ":", "\n", "                ", "common_tokens", "=", "common_tokens", ".", "intersection", "(", "subcaption_tokens", ")", "\n", "excluded_tokens", "-=", "subcaption_tokens", "\n", "", "common_tokens", "=", "common_tokens", ".", "union", "(", "excluded_tokens", ")", "\n", "prev_span_indices", "=", "set", "(", ")", "\n", "for", "subcaption_key", "in", "datum", "[", "\"subcaptions\"", "]", ":", "\n", "                ", "subcaption_tokens", "=", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", "\n", "spans", "=", "[", "]", "\n", "span_lengths", "=", "[", "]", "\n", "longest_span_index", "=", "None", "\n", "assert", "len", "(", "subcaption_tokens", ".", "intersection", "(", "excluded_tokens", ")", ")", "==", "0", "\n", "filtered_subcaption_tokens", "=", "subcaption_tokens", "-", "common_tokens", "\n", "if", "len", "(", "filtered_subcaption_tokens", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "sorted_tokens", "=", "sorted", "(", "filtered_subcaption_tokens", ")", "\n", "curr_start", "=", "sorted_tokens", "[", "0", "]", "\n", "curr_end", "=", "sorted_tokens", "[", "0", "]", "\n", "for", "token", "in", "sorted_tokens", "[", "1", ":", "]", ":", "\n", "                    ", "if", "token", ">", "curr_end", "+", "1", ":", "\n", "                        ", "spans", ".", "append", "(", "(", "curr_start", ",", "curr_end", ")", ")", "\n", "span_lengths", ".", "append", "(", "curr_end", "-", "curr_start", "+", "1", ")", "\n", "if", "longest_span_index", "is", "None", "or", "span_lengths", "[", "-", "1", "]", ">", "span_lengths", "[", "longest_span_index", "]", ":", "\n", "                            ", "span_set", "=", "set", "(", "list", "(", "range", "(", "curr_start", ",", "curr_end", "+", "1", ")", ")", ")", "\n", "# We want our single-span subcaptions to be disjoint from one another", "\n", "if", "len", "(", "span_set", ".", "intersection", "(", "prev_span_indices", ")", ")", "==", "0", ":", "\n", "                                ", "longest_span_index", "=", "len", "(", "span_lengths", ")", "-", "1", "\n", "", "", "curr_start", "=", "token", "\n", "curr_end", "=", "token", "\n", "", "else", ":", "\n", "                        ", "assert", "curr_end", "+", "1", "==", "token", "\n", "curr_end", "=", "token", "\n", "", "", "spans", ".", "append", "(", "(", "curr_start", ",", "curr_end", ")", ")", "\n", "span_lengths", ".", "append", "(", "curr_end", "-", "curr_start", "+", "1", ")", "\n", "if", "longest_span_index", "is", "None", "or", "span_lengths", "[", "-", "1", "]", ">", "span_lengths", "[", "longest_span_index", "]", ":", "\n", "                    ", "span_set", "=", "set", "(", "list", "(", "range", "(", "curr_start", ",", "curr_end", "+", "1", ")", ")", ")", "\n", "# We want our single-span subcaptions to be disjoint from one another", "\n", "if", "len", "(", "span_set", ".", "intersection", "(", "prev_span_indices", ")", ")", "==", "0", ":", "\n", "                        ", "longest_span_index", "=", "len", "(", "span_lengths", ")", "-", "1", "\n", "", "", "if", "longest_span_index", "is", "not", "None", ":", "\n", "                    ", "single_span_subcaptions", "[", "subcaption_key", "]", "=", "spans", "[", "longest_span_index", "]", "\n", "for", "token", "in", "range", "(", "spans", "[", "longest_span_index", "]", "[", "0", "]", ",", "spans", "[", "longest_span_index", "]", "[", "1", "]", "+", "1", ")", ":", "\n", "                        ", "prev_span_indices", ".", "add", "(", "token", ")", "\n", "", "", "subcaptions", "[", "subcaption_key", "]", "=", "filtered_subcaption_tokens", "\n", "", "gold_subfigures", "=", "[", "]", "\n", "pred_subfigures", "=", "[", "]", "\n", "subcaptions_list", "=", "[", "]", "\n", "single_span_subcaptions_list", "=", "[", "]", "\n", "for", "subfig", "in", "datum", "[", "\"spans\"", "]", ":", "\n", "                ", "xcoords", "=", "[", "point", "[", "0", "]", "for", "point", "in", "subfig", "[", "\"points\"", "]", "]", "\n", "ycoords", "=", "[", "point", "[", "1", "]", "for", "point", "in", "subfig", "[", "\"points\"", "]", "]", "\n", "if", "subfig", "[", "\"label\"", "]", "in", "subcaptions", "and", "len", "(", "subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ")", ">", "0", ":", "\n", "                    ", "gold_subfigures", ".", "append", "(", "[", "min", "(", "xcoords", ")", ",", "min", "(", "ycoords", ")", ",", "max", "(", "xcoords", ")", ",", "max", "(", "ycoords", ")", "]", ")", "\n", "subcaptions_list", ".", "append", "(", "subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ")", "\n", "", "if", "subfig", "[", "\"label\"", "]", "in", "single_span_subcaptions", ":", "\n", "                    ", "single_span_subcaptions_list", ".", "append", "(", "single_span_subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "single_span_subcaptions_list", ".", "append", "(", "None", ")", "\n", "", "", "if", "box_predictions", "is", "not", "None", ":", "\n", "                ", "for", "box", ",", "score", "in", "zip", "(", "box_predictions", "[", "image_id", "]", "[", "'predictions'", "]", "[", "'boxes'", "]", ",", "box_predictions", "[", "image_id", "]", "[", "'predictions'", "]", "[", "'scores'", "]", ")", ":", "\n", "                    ", "if", "score", ">", "self", ".", "box_predictions_threshold", ":", "\n", "                        ", "pred_subfigures", ".", "append", "(", "box", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "subfig", "in", "gold_subfigures", ":", "\n", "                    ", "pred_subfigures", ".", "append", "(", "subfig", ")", "\n", "", "", "yield", "self", ".", "text_to_instance", "(", "[", "token", "[", "\"text\"", "]", "for", "token", "in", "datum", "[", "\"tokens\"", "]", "]", ",", "image_id", ",", "pred_subfigures", ",", "common_tokens", ",", "single_span_subcaptions_list", ",", "subcaptions_list", ",", "gold_subfigures", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.SubcaptionNerDatasetReader.text_to_instance": [[151, 202], ["subcaption_ner_dataset_reader.convert_to_wordpieces", "set", "allennlp.data.fields.TextField", "set", "allennlp.data.fields.SequenceLabelField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "len", "set", "allennlp.data.Token", "set", "prev_span_indices.union.union.union", "set", "new_wordpiece_subcaptions.append", "list", "len", "range", "set.add", "new_wordpiece_spans.append", "sorted", "range", "set.intersection", "new_wordpiece_spans.append", "new_wordpiece_spans.append", "set.add", "min"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.convert_to_wordpieces"], ["", "", "def", "text_to_instance", "(", "self", ",", "tokens", ",", "image_id", ",", "predicted_boxes", "=", "None", ",", "common_tokens", "=", "None", ",", "single_span_subcaptions", "=", "None", ",", "subcaptions", "=", "None", ",", "gold_boxes", "=", "None", ")", ":", "\n", "        ", "wordpieces", ",", "common_wordpieces", ",", "wordpiece_spans", ",", "wordpiece_subcaptions", "=", "convert_to_wordpieces", "(", "self", ".", "tokenizer", ".", "_tokenizer", ",", "tokens", ",", "common_tokens", ",", "single_span_subcaptions", ",", "subcaptions", ")", "\n", "if", "len", "(", "wordpieces", ")", ">", "self", ".", "max_seq_length", "-", "2", ":", "\n", "            ", "new_common_wordpieces", "=", "set", "(", ")", "\n", "for", "token", "in", "common_wordpieces", ":", "\n", "                ", "if", "token", "<", "self", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "new_common_wordpieces", ".", "add", "(", "token", ")", "\n", "", "", "new_wordpiece_spans", "=", "[", "]", "\n", "for", "span", "in", "wordpiece_spans", ":", "\n", "                ", "if", "span", "is", "None", ":", "\n", "                    ", "new_wordpiece_spans", ".", "append", "(", "span", ")", "\n", "", "elif", "span", "[", "0", "]", "<", "self", ".", "max_seq_length", "-", "2", ":", "\n", "                    ", "new_wordpiece_spans", ".", "append", "(", "(", "span", "[", "0", "]", ",", "min", "(", "self", ".", "max_seq_length", "-", "3", ",", "span", "[", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_wordpiece_spans", ".", "append", "(", "None", ")", "\n", "", "", "new_wordpiece_subcaptions", "=", "[", "]", "\n", "for", "subcaption", "in", "wordpiece_subcaptions", ":", "\n", "                ", "new_subcaption", "=", "set", "(", ")", "\n", "for", "token", "in", "subcaption", ":", "\n", "                    ", "if", "token", "<", "self", ".", "max_seq_length", "-", "2", ":", "\n", "                        ", "new_subcaption", ".", "add", "(", "token", ")", "\n", "", "", "new_wordpiece_subcaptions", ".", "append", "(", "new_subcaption", ")", "\n", "", "wordpieces", "=", "wordpieces", "[", ":", "self", ".", "max_seq_length", "-", "2", "]", "\n", "wordpiece_spans", "=", "new_wordpiece_spans", "\n", "# wordpiece_subcaptions = new_wordpiece_subcaptions", "\n", "", "wordpieces", "=", "[", "\"[CLS]\"", "]", "+", "wordpieces", "+", "[", "\"[SEP]\"", "]", "\n", "# Account for CLS token", "\n", "wordpiece_spans", "=", "[", "(", "span", "[", "0", "]", "+", "1", ",", "span", "[", "1", "]", "+", "1", ")", "for", "span", "in", "wordpiece_spans", "if", "span", "is", "not", "None", "]", "\n", "wordpiece_subcaptions", "=", "[", "[", "wordpiece", "+", "1", "for", "wordpiece", "in", "sorted", "(", "subcaption", ")", "]", "for", "subcaption", "in", "wordpiece_subcaptions", "]", "\n", "common_wordpieces", "=", "set", "(", "[", "wordpiece_index", "+", "1", "for", "wordpiece_index", "in", "common_wordpieces", "]", ")", "\n", "wordpiece_tokens", "=", "[", "Token", "(", "wordpiece", ")", "for", "wordpiece", "in", "wordpieces", "]", "\n", "tokens_field", "=", "TextField", "(", "wordpiece_tokens", ",", "token_indexers", "=", "self", ".", "token_indexers", ")", "\n", "fields", "=", "{", "}", "\n", "tags", "=", "[", "self", ".", "tag_map", "[", "'O'", "]", "for", "_", "in", "wordpieces", "]", "\n", "prev_span_indices", "=", "set", "(", ")", "\n", "for", "span", "in", "wordpiece_spans", ":", "\n", "            ", "span_set", "=", "set", "(", "list", "(", "range", "(", "span", "[", "0", "]", ",", "span", "[", "1", "]", "+", "1", ")", ")", ")", "\n", "if", "len", "(", "span_set", ".", "intersection", "(", "prev_span_indices", ")", ")", ">", "0", ":", "\n", "                ", "continue", "\n", "", "prev_span_indices", "=", "prev_span_indices", ".", "union", "(", "span_set", ")", "\n", "if", "span", "[", "0", "]", "==", "span", "[", "1", "]", ":", "\n", "                ", "tags", "[", "span", "[", "0", "]", "]", "=", "self", ".", "tag_map", "[", "\"U\"", "]", "\n", "", "else", ":", "\n", "                ", "tags", "[", "span", "[", "0", "]", "]", "=", "self", ".", "tag_map", "[", "\"B\"", "]", "\n", "tags", "[", "span", "[", "1", "]", "]", "=", "self", ".", "tag_map", "[", "\"L\"", "]", "\n", "for", "index", "in", "range", "(", "span", "[", "0", "]", "+", "1", ",", "span", "[", "1", "]", ")", ":", "\n", "                    ", "tags", "[", "index", "]", "=", "self", ".", "tag_map", "[", "\"I\"", "]", "\n", "", "", "", "fields", "[", "\"tokens\"", "]", "=", "tokens_field", "\n", "fields", "[", "\"tags\"", "]", "=", "SequenceLabelField", "(", "tags", ",", "tokens_field", ",", "\"labels\"", ")", "\n", "fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "{", "\"image_id\"", ":", "image_id", ",", "\"words\"", ":", "wordpieces", ",", "\"common_wordpieces\"", ":", "common_wordpieces", ",", "\"gold_subcaptions\"", ":", "wordpiece_subcaptions", ",", "\"gold_subfigures\"", ":", "gold_boxes", ",", "\"predicted_subfigures\"", ":", "predicted_boxes", "}", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.convert_to_wordpieces": [[19, 37], ["enumerate", "len", "set", "len", "tokenizer.wordpiece_tokenizer.tokenize", "range", "len", "set", "set.add", "range"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize"], ["def", "convert_to_wordpieces", "(", "tokenizer", ",", "tokens", ",", "common_tokens", ",", "spans", ",", "full_subcaptions", ")", ":", "\n", "    ", "token_to_wordpiece_map", "=", "{", "}", "\n", "wordpieces", "=", "[", "]", "\n", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token_to_wordpiece_map", "[", "index", "]", "=", "len", "(", "wordpieces", ")", "\n", "wordpieces", "+=", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "", "token_to_wordpiece_map", "[", "len", "(", "tokens", ")", "]", "=", "len", "(", "wordpieces", ")", "\n", "new_spans", "=", "None", "\n", "if", "spans", "is", "not", "None", ":", "\n", "        ", "new_spans", "=", "[", "(", "token_to_wordpiece_map", "[", "span", "[", "0", "]", "]", ",", "token_to_wordpiece_map", "[", "span", "[", "1", "]", "+", "1", "]", "-", "1", ")", "if", "span", "is", "not", "None", "else", "None", "for", "span", "in", "spans", "]", "\n", "", "new_full_subcaptions", "=", "None", "\n", "if", "full_subcaptions", "is", "not", "None", ":", "\n", "        ", "new_full_subcaptions", "=", "[", "set", "(", "[", "wordpiece", "for", "token", "in", "subcaption", "for", "wordpiece", "in", "range", "(", "token_to_wordpiece_map", "[", "token", "]", ",", "token_to_wordpiece_map", "[", "token", "+", "1", "]", ")", "]", ")", "for", "subcaption", "in", "full_subcaptions", "]", "\n", "", "common_wordpieces", "=", "set", "(", ")", "\n", "for", "token", "in", "common_tokens", ":", "\n", "        ", "for", "index", "in", "range", "(", "token_to_wordpiece_map", "[", "token", "]", ",", "token_to_wordpiece_map", "[", "token", "+", "1", "]", ")", ":", "\n", "            ", "common_wordpieces", ".", "add", "(", "index", ")", "\n", "", "", "return", "wordpieces", ",", "common_wordpieces", ",", "new_spans", ",", "new_full_subcaptions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.__init__": [[52, 64], ["isinstance", "copy.deepcopy", "pycocotools.cocoeval.COCOeval"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "coco_gt", ",", "iou_types", ")", ":", "\n", "        ", "assert", "isinstance", "(", "iou_types", ",", "(", "list", ",", "tuple", ")", ")", "\n", "coco_gt", "=", "copy", ".", "deepcopy", "(", "coco_gt", ")", "\n", "self", ".", "coco_gt", "=", "coco_gt", "\n", "\n", "self", ".", "iou_types", "=", "iou_types", "\n", "self", ".", "coco_eval", "=", "{", "}", "\n", "for", "iou_type", "in", "iou_types", ":", "\n", "            ", "self", ".", "coco_eval", "[", "iou_type", "]", "=", "COCOeval", "(", "coco_gt", ",", "iouType", "=", "iou_type", ")", "\n", "\n", "", "self", ".", "img_ids", "=", "[", "]", "\n", "self", ".", "eval_imgs", "=", "{", "k", ":", "[", "]", "for", "k", "in", "iou_types", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.update": [[65, 79], ["list", "coco_eval.CocoEvaluator.img_ids.extend", "numpy.unique", "coco_eval.CocoEvaluator.prepare", "list", "coco_eval.evaluate", "coco_eval.CocoEvaluator.eval_imgs[].append", "list", "coco_eval.loadRes", "pycocotools.coco.COCO", "predictions.keys"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.evaluate", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.loadRes"], ["", "def", "update", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "img_ids", "=", "list", "(", "np", ".", "unique", "(", "list", "(", "predictions", ".", "keys", "(", ")", ")", ")", ")", "\n", "self", ".", "img_ids", ".", "extend", "(", "img_ids", ")", "\n", "\n", "for", "iou_type", "in", "self", ".", "iou_types", ":", "\n", "            ", "results", "=", "self", ".", "prepare", "(", "predictions", ",", "iou_type", ")", "\n", "coco_dt", "=", "loadRes", "(", "self", ".", "coco_gt", ",", "results", ")", "if", "results", "else", "COCO", "(", ")", "\n", "coco_eval", "=", "self", ".", "coco_eval", "[", "iou_type", "]", "\n", "\n", "coco_eval", ".", "cocoDt", "=", "coco_dt", "\n", "coco_eval", ".", "params", ".", "imgIds", "=", "list", "(", "img_ids", ")", "\n", "img_ids", ",", "eval_imgs", "=", "evaluate", "(", "coco_eval", ")", "\n", "\n", "self", ".", "eval_imgs", "[", "iou_type", "]", ".", "append", "(", "eval_imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.synchronize_between_processes": [[80, 84], ["numpy.concatenate", "coco_eval.create_common_coco_eval"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.create_common_coco_eval"], ["", "", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "for", "iou_type", "in", "self", ".", "iou_types", ":", "\n", "            ", "self", ".", "eval_imgs", "[", "iou_type", "]", "=", "np", ".", "concatenate", "(", "self", ".", "eval_imgs", "[", "iou_type", "]", ",", "2", ")", "\n", "create_common_coco_eval", "(", "self", ".", "coco_eval", "[", "iou_type", "]", ",", "self", ".", "img_ids", ",", "self", ".", "eval_imgs", "[", "iou_type", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.accumulate": [[85, 88], ["coco_eval.CocoEvaluator.coco_eval.values", "coco_eval.accumulate"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.accumulate"], ["", "", "def", "accumulate", "(", "self", ")", ":", "\n", "        ", "for", "coco_eval", "in", "self", ".", "coco_eval", ".", "values", "(", ")", ":", "\n", "            ", "coco_eval", ".", "accumulate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.summarize": [[89, 93], ["coco_eval.CocoEvaluator.coco_eval.items", "print", "coco_eval.summarize"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.summarize"], ["", "", "def", "summarize", "(", "self", ")", ":", "\n", "        ", "for", "iou_type", ",", "coco_eval", "in", "self", ".", "coco_eval", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "\"IoU metric: {}\"", ".", "format", "(", "iou_type", ")", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare": [[94, 103], ["coco_eval.CocoEvaluator.prepare_for_coco_detection", "coco_eval.CocoEvaluator.prepare_for_coco_segmentation", "coco_eval.CocoEvaluator.prepare_for_coco_keypoint", "ValueError"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_detection", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_segmentation", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_keypoint"], ["", "", "def", "prepare", "(", "self", ",", "predictions", ",", "iou_type", ")", ":", "\n", "        ", "if", "iou_type", "==", "\"bbox\"", ":", "\n", "            ", "return", "self", ".", "prepare_for_coco_detection", "(", "predictions", ")", "\n", "", "elif", "iou_type", "==", "\"segm\"", ":", "\n", "            ", "return", "self", ".", "prepare_for_coco_segmentation", "(", "predictions", ")", "\n", "", "elif", "iou_type", "==", "\"keypoints\"", ":", "\n", "            ", "return", "self", ".", "prepare_for_coco_keypoint", "(", "predictions", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown iou type {}\"", ".", "format", "(", "iou_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_detection": [[104, 127], ["predictions.items", "convert_to_xywh().tolist", "prediction[].tolist", "prediction[].tolist", "coco_results.extend", "len", "coco_eval.convert_to_xywh", "enumerate"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.convert_to_xywh"], ["", "", "def", "prepare_for_coco_detection", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "coco_results", "=", "[", "]", "\n", "for", "original_id", ",", "prediction", "in", "predictions", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "boxes", "=", "prediction", "[", "\"boxes\"", "]", "\n", "boxes", "=", "convert_to_xywh", "(", "boxes", ")", ".", "tolist", "(", ")", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", ".", "tolist", "(", ")", "\n", "\n", "coco_results", ".", "extend", "(", "\n", "[", "\n", "{", "\n", "\"image_id\"", ":", "original_id", ",", "\n", "\"category_id\"", ":", "labels", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "box", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "for", "k", ",", "box", "in", "enumerate", "(", "boxes", ")", "\n", "]", "\n", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_segmentation": [[128, 162], ["predictions.items", "prediction[].tolist", "prediction[].tolist", "coco_results.extend", "len", "rle[].decode", "pycocotools.encode", "numpy.array", "enumerate"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_crf_tagger.BertCrfTagger.decode"], ["", "def", "prepare_for_coco_segmentation", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "coco_results", "=", "[", "]", "\n", "for", "original_id", ",", "prediction", "in", "predictions", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "scores", "=", "prediction", "[", "\"scores\"", "]", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", "\n", "masks", "=", "prediction", "[", "\"masks\"", "]", "\n", "\n", "masks", "=", "masks", ">", "0.5", "\n", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", ".", "tolist", "(", ")", "\n", "\n", "rles", "=", "[", "\n", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", "0", ",", ":", ",", ":", ",", "np", ".", "newaxis", "]", ",", "dtype", "=", "np", ".", "uint8", ",", "order", "=", "\"F\"", ")", ")", "[", "0", "]", "\n", "for", "mask", "in", "masks", "\n", "]", "\n", "for", "rle", "in", "rles", ":", "\n", "                ", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "coco_results", ".", "extend", "(", "\n", "[", "\n", "{", "\n", "\"image_id\"", ":", "original_id", ",", "\n", "\"category_id\"", ":", "labels", "[", "k", "]", ",", "\n", "\"segmentation\"", ":", "rle", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "for", "k", ",", "rle", "in", "enumerate", "(", "rles", ")", "\n", "]", "\n", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.prepare_for_coco_keypoint": [[163, 188], ["predictions.items", "convert_to_xywh().tolist", "prediction[].tolist", "prediction[].tolist", "keypoints.flatten().tolist.flatten().tolist.flatten().tolist", "coco_results.extend", "len", "coco_eval.convert_to_xywh", "keypoints.flatten().tolist.flatten().tolist.flatten", "enumerate"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.convert_to_xywh"], ["", "def", "prepare_for_coco_keypoint", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "coco_results", "=", "[", "]", "\n", "for", "original_id", ",", "prediction", "in", "predictions", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "boxes", "=", "prediction", "[", "\"boxes\"", "]", "\n", "boxes", "=", "convert_to_xywh", "(", "boxes", ")", ".", "tolist", "(", ")", "\n", "scores", "=", "prediction", "[", "\"scores\"", "]", ".", "tolist", "(", ")", "\n", "labels", "=", "prediction", "[", "\"labels\"", "]", ".", "tolist", "(", ")", "\n", "keypoints", "=", "prediction", "[", "\"keypoints\"", "]", "\n", "keypoints", "=", "keypoints", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "coco_results", ".", "extend", "(", "\n", "[", "\n", "{", "\n", "\"image_id\"", ":", "original_id", ",", "\n", "\"category_id\"", ":", "labels", "[", "k", "]", ",", "\n", "'keypoints'", ":", "keypoint", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "for", "k", ",", "keypoint", "in", "enumerate", "(", "keypoints", ")", "\n", "]", "\n", ")", "\n", "", "return", "coco_results", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.convert_to_xywh": [[190, 193], ["boxes.unbind", "torch.stack", "torch.stack"], "function", ["None"], ["", "", "def", "convert_to_xywh", "(", "boxes", ")", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "boxes", ".", "unbind", "(", "1", ")", "\n", "return", "torch", ".", "stack", "(", "(", "xmin", ",", "ymin", ",", "xmax", "-", "xmin", ",", "ymax", "-", "ymin", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.merge": [[195, 215], ["subcaption.all_gather", "subcaption.all_gather", "numpy.array", "numpy.concatenate", "numpy.unique", "np.array.extend", "np.concatenate.append"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.all_gather", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.all_gather"], ["", "def", "merge", "(", "img_ids", ",", "eval_imgs", ")", ":", "\n", "    ", "all_img_ids", "=", "utils", ".", "all_gather", "(", "img_ids", ")", "\n", "all_eval_imgs", "=", "utils", ".", "all_gather", "(", "eval_imgs", ")", "\n", "\n", "merged_img_ids", "=", "[", "]", "\n", "for", "p", "in", "all_img_ids", ":", "\n", "        ", "merged_img_ids", ".", "extend", "(", "p", ")", "\n", "\n", "", "merged_eval_imgs", "=", "[", "]", "\n", "for", "p", "in", "all_eval_imgs", ":", "\n", "        ", "merged_eval_imgs", ".", "append", "(", "p", ")", "\n", "\n", "", "merged_img_ids", "=", "np", ".", "array", "(", "merged_img_ids", ")", "\n", "merged_eval_imgs", "=", "np", ".", "concatenate", "(", "merged_eval_imgs", ",", "2", ")", "\n", "\n", "# keep only unique (and in sorted order) images", "\n", "merged_img_ids", ",", "idx", "=", "np", ".", "unique", "(", "merged_img_ids", ",", "return_index", "=", "True", ")", "\n", "merged_eval_imgs", "=", "merged_eval_imgs", "[", "...", ",", "idx", "]", "\n", "\n", "return", "merged_img_ids", ",", "merged_eval_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.create_common_coco_eval": [[217, 225], ["coco_eval.merge", "list", "list", "copy.deepcopy", "list.flatten"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.merge"], ["", "def", "create_common_coco_eval", "(", "coco_eval", ",", "img_ids", ",", "eval_imgs", ")", ":", "\n", "    ", "img_ids", ",", "eval_imgs", "=", "merge", "(", "img_ids", ",", "eval_imgs", ")", "\n", "img_ids", "=", "list", "(", "img_ids", ")", "\n", "eval_imgs", "=", "list", "(", "eval_imgs", ".", "flatten", "(", ")", ")", "\n", "\n", "coco_eval", ".", "evalImgs", "=", "eval_imgs", "\n", "coco_eval", ".", "params", ".", "imgIds", "=", "img_ids", "\n", "coco_eval", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "coco_eval", ".", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.createIndex": [[235, 265], ["collections.defaultdict", "collections.defaultdict", "imgToAnns[].append", "catToImgs[].append"], "function", ["None"], ["", "def", "createIndex", "(", "self", ")", ":", "\n", "# create index", "\n", "# print('creating index...')", "\n", "    ", "anns", ",", "cats", ",", "imgs", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "imgToAnns", ",", "catToImgs", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "if", "'annotations'", "in", "self", ".", "dataset", ":", "\n", "        ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "            ", "imgToAnns", "[", "ann", "[", "'image_id'", "]", "]", ".", "append", "(", "ann", ")", "\n", "anns", "[", "ann", "[", "'id'", "]", "]", "=", "ann", "\n", "\n", "", "", "if", "'images'", "in", "self", ".", "dataset", ":", "\n", "        ", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "            ", "imgs", "[", "img", "[", "'id'", "]", "]", "=", "img", "\n", "\n", "", "", "if", "'categories'", "in", "self", ".", "dataset", ":", "\n", "        ", "for", "cat", "in", "self", ".", "dataset", "[", "'categories'", "]", ":", "\n", "            ", "cats", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "\n", "", "", "if", "'annotations'", "in", "self", ".", "dataset", "and", "'categories'", "in", "self", ".", "dataset", ":", "\n", "        ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "            ", "catToImgs", "[", "ann", "[", "'category_id'", "]", "]", ".", "append", "(", "ann", "[", "'image_id'", "]", ")", "\n", "\n", "# print('index created!')", "\n", "\n", "# create class members", "\n", "", "", "self", ".", "anns", "=", "anns", "\n", "self", ".", "imgToAnns", "=", "imgToAnns", "\n", "self", ".", "catToImgs", "=", "catToImgs", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "cats", "=", "cats", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.loadRes": [[270, 330], ["pycocotools.coco.COCO", "isinstance", "coco_eval.createIndex", "json.load", "type", "set", "enumerate", "open", "type", "coco_eval..loadNumpyAnnotations", "set", "set", "set", "set", "copy.deepcopy", "enumerate", "coco_eval..getImgIds", "copy.deepcopy", "enumerate", "maskUtils.area", "copy.deepcopy", "enumerate", "maskUtils.toBbox", "numpy.min", "numpy.max", "numpy.min", "numpy.max"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.createIndex", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["def", "loadRes", "(", "self", ",", "resFile", ")", ":", "\n", "    ", "\"\"\"\n    Load result file and return a result api object.\n    :param   resFile (str)     : file name of result file\n    :return: res (obj)         : result api object\n    \"\"\"", "\n", "res", "=", "COCO", "(", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", "]", "\n", "\n", "# print('Loading and preparing results...')", "\n", "# tic = time.time()", "\n", "if", "isinstance", "(", "resFile", ",", "torch", ".", "_six", ".", "string_classes", ")", ":", "\n", "        ", "anns", "=", "json", ".", "load", "(", "open", "(", "resFile", ")", ")", "\n", "", "elif", "type", "(", "resFile", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "anns", "=", "self", ".", "loadNumpyAnnotations", "(", "resFile", ")", "\n", "", "else", ":", "\n", "        ", "anns", "=", "resFile", "\n", "", "assert", "type", "(", "anns", ")", "==", "list", ",", "'results in not an array of objects'", "\n", "annsImgIds", "=", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", "\n", "assert", "set", "(", "annsImgIds", ")", "==", "(", "set", "(", "annsImgIds", ")", "&", "set", "(", "self", ".", "getImgIds", "(", ")", ")", ")", ",", "'Results do not correspond to current coco set'", "\n", "if", "'caption'", "in", "anns", "[", "0", "]", ":", "\n", "        ", "imgIds", "=", "set", "(", "[", "img", "[", "'id'", "]", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "]", ")", "&", "set", "(", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "if", "img", "[", "'id'", "]", "in", "imgIds", "]", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "            ", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "", "", "elif", "'bbox'", "in", "anns", "[", "0", "]", "and", "not", "anns", "[", "0", "]", "[", "'bbox'", "]", "==", "[", "]", ":", "\n", "        ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "            ", "bb", "=", "ann", "[", "'bbox'", "]", "\n", "x1", ",", "x2", ",", "y1", ",", "y2", "=", "[", "bb", "[", "0", "]", ",", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", ",", "bb", "[", "1", "]", ",", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "]", "\n", "if", "'segmentation'", "not", "in", "ann", ":", "\n", "                ", "ann", "[", "'segmentation'", "]", "=", "[", "[", "x1", ",", "y1", ",", "x1", ",", "y2", ",", "x2", ",", "y2", ",", "x2", ",", "y1", "]", "]", "\n", "", "ann", "[", "'area'", "]", "=", "bb", "[", "2", "]", "*", "bb", "[", "3", "]", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'segmentation'", "in", "anns", "[", "0", "]", ":", "\n", "        ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "# now only support compressed RLE format as segmentation results", "\n", "            ", "ann", "[", "'area'", "]", "=", "maskUtils", ".", "area", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "if", "'bbox'", "not", "in", "ann", ":", "\n", "                ", "ann", "[", "'bbox'", "]", "=", "maskUtils", ".", "toBbox", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'keypoints'", "in", "anns", "[", "0", "]", ":", "\n", "        ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "            ", "s", "=", "ann", "[", "'keypoints'", "]", "\n", "x", "=", "s", "[", "0", ":", ":", "3", "]", "\n", "y", "=", "s", "[", "1", ":", ":", "3", "]", "\n", "x1", ",", "x2", ",", "y1", ",", "y2", "=", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "min", "(", "y", ")", ",", "np", ".", "max", "(", "y", ")", "\n", "ann", "[", "'area'", "]", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'bbox'", "]", "=", "[", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "]", "\n", "# print('DONE (t={:0.2f}s)'.format(time.time()- tic))", "\n", "\n", "", "", "res", ".", "dataset", "[", "'annotations'", "]", "=", "anns", "\n", "createIndex", "(", "res", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.evaluate": [[332, 378], ["list", "sorted", "coco_eval.._prepare", "numpy.asarray().reshape", "copy.deepcopy", "print", "numpy.unique", "list", "computeIoU", "evaluateImg", "len", "len", "len", "numpy.unique", "numpy.asarray"], "function", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "    ", "'''\n    Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n    :return: None\n    '''", "\n", "# tic = time.time()", "\n", "# print('Running per image evaluation...')", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "p", ".", "useSegm", "is", "not", "None", ":", "\n", "        ", "p", ".", "iouType", "=", "'segm'", "if", "p", ".", "useSegm", "==", "1", "else", "'bbox'", "\n", "print", "(", "'useSegm (deprecated) is not None. Running {} evaluation'", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "# print('Evaluate annotation type *{}*'.format(p.iouType))", "\n", "", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "        ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "==", "'segm'", "or", "p", ".", "iouType", "==", "'bbox'", ":", "\n", "        ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "'keypoints'", ":", "\n", "        ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "self", ".", "ious", "=", "{", "\n", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "for", "catId", "in", "catIds", "}", "\n", "\n", "evaluateImg", "=", "self", ".", "evaluateImg", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "evalImgs", "=", "[", "\n", "evaluateImg", "(", "imgId", ",", "catId", ",", "areaRng", ",", "maxDet", ")", "\n", "for", "catId", "in", "catIds", "\n", "for", "areaRng", "in", "p", ".", "areaRng", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "# this is NOT in the pycocotools code, but could be done outside", "\n", "evalImgs", "=", "np", ".", "asarray", "(", "evalImgs", ")", ".", "reshape", "(", "len", "(", "catIds", ")", ",", "len", "(", "p", ".", "areaRng", ")", ",", "len", "(", "p", ".", "imgIds", ")", ")", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "# toc = time.time()", "\n", "# print('DONE (t={:0.2f}s).'.format(toc-tic))", "\n", "return", "p", ".", "imgIds", ",", "evalImgs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_box_crf_tagger.BertCrfTagger.__init__": [[68, 125], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "bert_box_crf_tagger.BertCrfTagger.vocab.get_vocab_size", "torch.nn.Dropout", "allennlp.modules.TimeDistributed", "torch.nn.Linear", "allennlp.modules.ConditionalRandomField", "torch.nn.Linear", "torch.nn.BCEWithLogitsLoss", "torch.nn.Sequential", "subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric", "initializer", "torch.nn.modules.linear.Linear", "transformers.BertModel", "bert_box_crf_tagger.BertCrfTagger.vocab.get_index_to_token_vocabulary", "allennlp.modules.conditional_random_field.allowed_transitions", "bert_box_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim", "bert_box_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim", "torch.nn.Linear", "torch.nn.ReLU", "bert_box_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim", "allennlp.common.checks.ConfigurationError", "bert_box_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim", "bert_box_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ",", "\n", "label_encoding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "include_start_end_transitions", ":", "bool", "=", "True", ",", "\n", "constrain_crf_decoding", ":", "bool", "=", "None", ",", "\n", "pretrained", ":", "bool", "=", "True", ",", "\n", "iou_threshold", ":", "float", "=", "0.5", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "verbose_metrics", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "label_namespace", "=", "label_namespace", "\n", "self", ".", "text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "num_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "label_namespace", ")", "\n", "# self.num_tags = 6", "\n", "self", ".", "_verbose_metrics", "=", "verbose_metrics", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "tag_projection_layer", "=", "TimeDistributed", "(", "\n", "Linear", "(", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ",", "self", ".", "num_tags", ")", "\n", ")", "\n", "\n", "if", "not", "pretrained", ":", "\n", "            ", "self", ".", "text_field_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "transformer_model", "=", "BertModel", "(", "config", "=", "self", ".", "text_field_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "transformer_model", ".", "config", ")", "\n", "\n", "# if  constrain_crf_decoding and calculate_span_f1 are not", "\n", "# provided, (i.e., they're None), set them to True", "\n", "# if label_encoding is provided and False if it isn't.", "\n", "", "if", "constrain_crf_decoding", "is", "None", ":", "\n", "            ", "constrain_crf_decoding", "=", "label_encoding", "is", "not", "None", "\n", "\n", "", "self", ".", "label_encoding", "=", "label_encoding", "\n", "if", "constrain_crf_decoding", ":", "\n", "            ", "if", "not", "label_encoding", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"constrain_crf_decoding is True, but \"", "\n", "\"no label_encoding was specified.\"", ")", "\n", "", "labels", "=", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "label_namespace", ")", "\n", "constraints", "=", "allowed_transitions", "(", "label_encoding", ",", "labels", ")", "\n", "", "else", ":", "\n", "            ", "constraints", "=", "None", "\n", "", "self", ".", "pos_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "4", ",", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ")", "\n", "\n", "self", ".", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", "self", ".", "crf", "=", "ConditionalRandomField", "(", "\n", "self", ".", "num_tags", ",", "constraints", ",", "\n", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", ")", "\n", "self", ".", "binary_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ",", "1", ")", "\n", "self", ".", "bce_loss", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ")", "\n", "self", ".", "output_layer", "=", "torch", ".", "nn", ".", "Sequential", "(", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ",", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "self", ".", "subcaption_metric", "=", "SubfigureSubcaptionAlignmentMetric", "(", "iou_threshold", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_box_crf_tagger.BertCrfTagger.forward": [[126, 228], ["bert_box_crf_tagger.BertCrfTagger.text_field_embedder", "bert_box_crf_tagger.BertCrfTagger.pos_layer", "allennlp.get_text_field_mask", "bert_box_crf_tagger.BertCrfTagger.output_layer", "bert_box_crf_tagger.BertCrfTagger.dropout", "bert_box_crf_tagger.BertCrfTagger.tag_projection_layer", "bert_box_crf_tagger.BertCrfTagger.crf.viterbi_tags", "range", "torch.cat", "range", "sorted", "batch_subcaptions.append", "bert_box_crf_tagger.BertCrfTagger.crf", "enumerate", "range", "len", "bert_box_crf_tagger.BertCrfTagger.vocab.get_token_from_index", "enumerate", "len", "bert_box_crf_tagger.BertCrfTagger.subcaption_metric", "output[].append", "list", "bert_box_crf_tagger.BertCrfTagger.unsqueeze().repeat", "pred_spans.append", "range", "range", "range", "[].split", "range", "[].split", "range", "pred_spans.append", "range", "len", "range", "range", "range", "range", "bert_box_crf_tagger.BertCrfTagger.unsqueeze"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "box", ":", "torch", ".", "Tensor", ",", "\n", "tags", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "# pylint: disable=unused-argument", "\n", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        tokens : ``Dict[str, torch.LongTensor]``, required\n            The output of ``TextField.as_array()``, which should typically be passed directly to a\n            ``TextFieldEmbedder``. This output is a dictionary mapping keys to ``TokenIndexer``\n            tensors.  At its most basic, using a ``SingleIdTokenIndexer`` this is: ``{\"tokens\":\n            Tensor(batch_size, num_tokens)}``. This dictionary will have the same keys as were used\n            for the ``TokenIndexers`` when you created the ``TextField`` representing your\n            sequence.  The dictionary is designed to be passed directly to a ``TextFieldEmbedder``,\n            which knows how to combine different word representations into a single vector per\n            token in your input.\n        tags : ``torch.LongTensor``, optional (default = ``None``)\n            A torch tensor representing the sequence of integer gold class labels of shape\n            ``(batch_size, num_tokens)``.\n        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n            metadata containg the original words in the sentence to be tagged under a 'words' key.\n        Returns\n        -------\n        An output dictionary consisting of:\n        logits : ``torch.FloatTensor``\n            The logits that are the output of the ``tag_projection_layer``\n        mask : ``torch.LongTensor``\n            The text field mask for the input tokens\n        tags : ``List[List[int]]``\n            The predicted tags using the Viterbi algorithm.\n        loss : ``torch.FloatTensor``, optional\n            A scalar loss to be optimised. Only computed if gold label ``tags`` are provided.\n        \"\"\"", "\n", "embedded_text_input", "=", "self", ".", "text_field_embedder", "(", "tokens", ")", "\n", "box_features", "=", "self", ".", "pos_layer", "(", "box", ")", "\n", "mask", "=", "util", ".", "get_text_field_mask", "(", "tokens", ")", "\n", "assert", "embedded_text_input", ".", "shape", "[", "1", "]", "==", "mask", ".", "shape", "[", "1", "]", "\n", "batch_size", "=", "mask", ".", "shape", "[", "0", "]", "\n", "\n", "embedded_text_input", "=", "self", ".", "output_layer", "(", "torch", ".", "cat", "(", "(", "embedded_text_input", ",", "box_features", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "embedded_text_input", ".", "shape", "[", "1", "]", ",", "1", ")", ")", ",", "dim", "=", "2", ")", ")", "\n", "embedded_text_input", "=", "self", ".", "dropout", "(", "embedded_text_input", ")", "\n", "\n", "logits", "=", "self", ".", "tag_projection_layer", "(", "embedded_text_input", ")", "\n", "best_paths", "=", "self", ".", "crf", ".", "viterbi_tags", "(", "logits", ",", "mask", ")", "\n", "\n", "# Just get the tags and ignore the score.", "\n", "predicted_tags", "=", "[", "x", "for", "x", ",", "y", "in", "best_paths", "]", "\n", "\n", "output", "=", "{", "\"logits\"", ":", "logits", ",", "\"mask\"", ":", "mask", ",", "\"tags\"", ":", "predicted_tags", "}", "\n", "\n", "batch_subcaptions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "pred_spans", "=", "[", "]", "\n", "pred_start", "=", "None", "\n", "for", "j", "in", "range", "(", "len", "(", "predicted_tags", "[", "i", "]", ")", ")", ":", "\n", "                ", "pred_tag", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "predicted_tags", "[", "i", "]", "[", "j", "]", ",", "namespace", "=", "\"labels\"", ")", "\n", "if", "pred_tag", "[", "0", "]", "==", "\"U\"", ":", "\n", "                    ", "pred_spans", ".", "append", "(", "(", "j", ",", "j", ")", ")", "\n", "", "if", "pred_start", "is", "None", "and", "pred_tag", "[", "0", "]", "==", "\"B\"", ":", "\n", "                    ", "pred_start", "=", "j", "\n", "", "elif", "pred_start", "is", "not", "None", "and", "pred_tag", "[", "0", "]", "==", "\"L\"", ":", "\n", "                    ", "pred_spans", ".", "append", "(", "(", "pred_start", ",", "j", ")", ")", "\n", "pred_start", "=", "None", "\n", "", "", "subcaption", "=", "sorted", "(", "[", "token", "for", "span", "in", "pred_spans", "for", "token", "in", "range", "(", "span", "[", "0", "]", ",", "span", "[", "1", "]", "+", "1", ")", "]", ")", "\n", "batch_subcaptions", ".", "append", "(", "[", "subcaption", "]", ")", "\n", "", "if", "tags", "is", "not", "None", ":", "\n", "# Add negative log-likelihood as loss", "\n", "            ", "log_likelihood", "=", "self", ".", "crf", "(", "logits", ",", "tags", ",", "mask", ")", "\n", "output", "[", "\"loss\"", "]", "=", "-", "log_likelihood", "\n", "\n", "# Represent viterbi tags as \"class probabilities\" that we can", "\n", "# feed into the metrics", "\n", "class_probabilities", "=", "logits", "*", "0.", "\n", "for", "i", ",", "instance_tags", "in", "enumerate", "(", "predicted_tags", ")", ":", "\n", "                ", "for", "j", ",", "tag_id", "in", "enumerate", "(", "instance_tags", ")", ":", "\n", "                    ", "class_probabilities", "[", "i", ",", "j", ",", "tag_id", "]", "=", "1", "\n", "", "", "output", "[", "\"f1\"", "]", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "current_num_f1s", "=", "len", "(", "self", ".", "subcaption_metric", ".", "f1s", ")", "\n", "self", ".", "subcaption_metric", "(", "gold_subfigures", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigure\"", "]", "]", "]", ",", "predicted_subfigures", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"predicted_subfigure\"", "]", "]", "]", ",", "gold_tokens", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaption\"", "]", "]", "]", ",", "predicted_tokens", "=", "[", "batch_subcaptions", "[", "i", "]", "]", ",", "common_wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", "]", ",", "wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "]", ")", "\n", "assert", "len", "(", "self", ".", "subcaption_metric", ".", "f1s", ")", "-", "current_num_f1s", "==", "1", "\n", "output", "[", "\"f1\"", "]", ".", "append", "(", "self", ".", "subcaption_metric", ".", "f1s", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"predicted_subfigures\"", "]", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"predicted_subfigure\"", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"predicted_subcaptions\"", "]", "=", "batch_subcaptions", "\n", "output", "[", "\"common_wordpieces\"", "]", "=", "[", "list", "(", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"wordpieces\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"pdf_hash\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"image_id\"", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"fig_uri\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"image_id\"", "]", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "if", "tags", "is", "None", ":", "\n", "                ", "output", "[", "\"gold_subfigures\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigure\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"gold_subcaptions\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaption\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "                ", "output", "[", "\"gold_subfigures\"", "]", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigure\"", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"gold_subcaptions\"", "]", "=", "[", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaption\"", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_box_crf_tagger.BertCrfTagger.decode": [[229, 242], ["bert_box_crf_tagger.BertCrfTagger.vocab.get_token_from_index"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Converts the tag ids to the actual tags.\n        ``output_dict[\"tags\"]`` is a list of lists of tag_ids,\n        so we use an ugly nested list comprehension.\n        \"\"\"", "\n", "output_dict", "[", "\"tags\"", "]", "=", "[", "\n", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "tag", ",", "namespace", "=", "self", ".", "label_namespace", ")", "\n", "for", "tag", "in", "instance_tags", "]", "\n", "for", "instance_tags", "in", "output_dict", "[", "\"tags\"", "]", "\n", "]", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_box_crf_tagger.BertCrfTagger.get_metrics": [[243, 247], ["bert_box_crf_tagger.BertCrfTagger.subcaption_metric.get_metric"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics_to_return", "=", "{", "\"subcaption_f1\"", ":", "self", ".", "subcaption_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "}", "\n", "return", "metrics_to_return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.predictor.GenericPredictor.__init__": [[11, 13], ["allennlp.predictors.predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.predictor.GenericPredictor.predict_instance": [[14, 18], ["predictor.GenericPredictor._model.forward_on_instance", "allennlp.common.util.sanitize"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "predict_instance", "(", "self", ",", "instance", ":", "Instance", ")", "->", "JsonDict", ":", "\n", "        ", "outputs", "=", "self", ".", "_model", ".", "forward_on_instance", "(", "instance", ")", "\n", "return", "sanitize", "(", "outputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.__init__": [[18, 25], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", "=", "20", ",", "fmt", "=", "None", ")", ":", "\n", "        ", "if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "\"{median:.4f} ({global_avg:.4f})\"", "\n", "", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "fmt", "=", "fmt", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.update": [[26, 30], ["torchvision_detection_utils.SmoothedValue.deque.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "total", "+=", "value", "*", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.synchronize_between_processes": [[31, 43], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.barrier", "torch.barrier", "torch.all_reduce", "torch.all_reduce", "t.tolist.tolist.tolist", "int", "torchvision_detection_utils.is_dist_avail_and_initialized"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_dist_avail_and_initialized"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Warning: does not synchronize the deque!\n        \"\"\"", "\n", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "            ", "return", "\n", "", "t", "=", "torch", ".", "tensor", "(", "[", "self", ".", "count", ",", "self", ".", "total", "]", ",", "dtype", "=", "torch", ".", "float64", ",", "device", "=", "'cuda'", ")", "\n", "dist", ".", "barrier", "(", ")", "\n", "dist", ".", "all_reduce", "(", "t", ")", "\n", "t", "=", "t", ".", "tolist", "(", ")", "\n", "self", ".", "count", "=", "int", "(", "t", "[", "0", "]", ")", "\n", "self", ".", "total", "=", "t", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.median": [[44, 48], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.median().item", "torch.tensor.median().item", "list", "torch.tensor.median", "torch.tensor.median"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.median", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.median"], ["", "@", "property", "\n", "def", "median", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ")", "\n", "return", "d", ".", "median", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.avg": [[49, 53], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.mean().item", "torch.tensor.mean().item", "list", "torch.tensor.mean", "torch.tensor.mean"], "methods", ["None"], ["", "@", "property", "\n", "def", "avg", "(", "self", ")", ":", "\n", "        ", "d", "=", "torch", ".", "tensor", "(", "list", "(", "self", ".", "deque", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "return", "d", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.global_avg": [[54, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max": [[58, 61], ["torchvision_detection_utils.SmoothedValue.max"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "@", "property", "\n", "def", "max", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.value": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "deque", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.__str__": [[66, 73], ["torchvision_detection_utils.SmoothedValue.fmt.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fmt", ".", "format", "(", "\n", "median", "=", "self", ".", "median", ",", "\n", "avg", "=", "self", ".", "avg", ",", "\n", "global_avg", "=", "self", ".", "global_avg", ",", "\n", "max", "=", "self", ".", "max", ",", "\n", "value", "=", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.__init__": [[146, 149], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "delimiter", "=", "\"\\t\"", ")", ":", "\n", "        ", "self", ".", "meters", "=", "defaultdict", "(", "SmoothedValue", ")", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.update": [[150, 156], ["kwargs.items", "isinstance", "isinstance", "torchvision_detection_utils.MetricLogger.meters[].update", "v.item.item.item"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.update"], ["", "def", "update", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "v", "=", "v", ".", "item", "(", ")", "\n", "", "assert", "isinstance", "(", "v", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.__getattr__": [[157, 164], ["AttributeError", "type"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "in", "self", ".", "meters", ":", "\n", "            ", "return", "self", ".", "meters", "[", "attr", "]", "\n", "", "if", "attr", "in", "self", ".", "__dict__", ":", "\n", "            ", "return", "self", ".", "__dict__", "[", "attr", "]", "\n", "", "raise", "AttributeError", "(", "\"'{}' object has no attribute '{}'\"", ".", "format", "(", "\n", "type", "(", "self", ")", ".", "__name__", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.__str__": [[165, 172], ["torchvision_detection_utils.MetricLogger.meters.items", "torchvision_detection_utils.MetricLogger.delimiter.join", "loss_str.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "loss_str", "=", "[", "]", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "loss_str", ".", "append", "(", "\n", "\"{}: {}\"", ".", "format", "(", "name", ",", "str", "(", "meter", ")", ")", "\n", ")", "\n", "", "return", "self", ".", "delimiter", ".", "join", "(", "loss_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.synchronize_between_processes": [[173, 176], ["torchvision_detection_utils.MetricLogger.meters.values", "meter.synchronize_between_processes"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.synchronize_between_processes"], ["", "def", "synchronize_between_processes", "(", "self", ")", ":", "\n", "        ", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "            ", "meter", ".", "synchronize_between_processes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.add_meter": [[177, 179], ["None"], "methods", ["None"], ["", "", "def", "add_meter", "(", "self", ",", "name", ",", "meter", ")", ":", "\n", "        ", "self", ".", "meters", "[", "name", "]", "=", "meter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.log_every": [[180, 233], ["time.time", "time.time", "torchvision_detection_utils.SmoothedValue", "torchvision_detection_utils.SmoothedValue", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "print", "torchvision_detection_utils.MetricLogger.delimiter.join", "torchvision_detection_utils.MetricLogger.delimiter.join", "torchvision_detection_utils.SmoothedValue.update", "torchvision_detection_utils.SmoothedValue.update", "time.time", "time.time", "datetime.timedelta", "str", "str", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "len", "time.time", "time.time", "datetime.timedelta", "print", "print", "int", "len", "str", "len", "len", "torchvision_detection_utils.MetricLogger.format", "torchvision_detection_utils.MetricLogger.format", "len", "int", "len", "len", "str", "str", "str", "str", "str", "str", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.update", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.update"], ["", "def", "log_every", "(", "self", ",", "iterable", ",", "print_freq", ",", "header", "=", "None", ")", ":", "\n", "        ", "i", "=", "0", "\n", "if", "not", "header", ":", "\n", "            ", "header", "=", "''", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "iter_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "data_time", "=", "SmoothedValue", "(", "fmt", "=", "'{avg:.4f}'", ")", "\n", "space_fmt", "=", "':'", "+", "str", "(", "len", "(", "str", "(", "len", "(", "iterable", ")", ")", ")", ")", "+", "'d'", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", ",", "\n", "'max mem: {memory:.0f}'", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "log_msg", "=", "self", ".", "delimiter", ".", "join", "(", "[", "\n", "header", ",", "\n", "'[{0'", "+", "space_fmt", "+", "'}/{1}]'", ",", "\n", "'eta: {eta}'", ",", "\n", "'{meters}'", ",", "\n", "'time: {time}'", ",", "\n", "'data: {data}'", "\n", "]", ")", "\n", "", "MB", "=", "1024.0", "*", "1024.0", "\n", "for", "obj", "in", "iterable", ":", "\n", "            ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "yield", "obj", "\n", "iter_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "if", "i", "%", "print_freq", "==", "0", "or", "i", "==", "len", "(", "iterable", ")", "-", "1", ":", "\n", "                ", "eta_seconds", "=", "iter_time", ".", "global_avg", "*", "(", "len", "(", "iterable", ")", "-", "i", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ",", "\n", "memory", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "MB", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "log_msg", ".", "format", "(", "\n", "i", ",", "len", "(", "iterable", ")", ",", "eta", "=", "eta_string", ",", "\n", "meters", "=", "str", "(", "self", ")", ",", "\n", "time", "=", "str", "(", "iter_time", ")", ",", "data", "=", "str", "(", "data_time", ")", ")", ")", "\n", "", "", "i", "+=", "1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "print", "(", "'{} Total time: {} ({:.4f} s / it)'", ".", "format", "(", "\n", "header", ",", "total_time_str", ",", "total_time", "/", "len", "(", "iterable", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.all_gather": [[75, 116], ["torchvision_detection_utils.get_world_size", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.all_gather", "zip", "torch.tensor", "torch.tensor", "int", "tensor_list.append", "torch.empty", "torch.empty", "torch.cat", "torch.cat", "data_list.append", "torch.ByteTensor", "torch.ByteTensor", "torch.cat.numel", "range", "size.item", "torch.empty", "torch.empty", "torch.cat.cpu().numpy().tobytes", "pickle.loads", "torch.cat.cpu().numpy", "torch.cat.cpu"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_world_size", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.all_gather", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.all_gather"], ["", "", "def", "all_gather", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors)\n    Args:\n        data: any picklable object\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "# serialized to a Tensor", "\n", "", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "\n", "# obtain Tensor size of each rank", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "size_list", "=", "[", "torch", ".", "tensor", "(", "[", "0", "]", ",", "device", "=", "\"cuda\"", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "tensor_list", "=", "[", "]", "\n", "for", "_", "in", "size_list", ":", "\n", "        ", "tensor_list", ".", "append", "(", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", ")", "\n", "", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "empty", "(", "size", "=", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.reduce_dict": [[118, 143], ["torchvision_detection_utils.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.all_reduce", "input_dict.keys", "names.append", "torch.stack.append", "zip"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_world_size"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input_dict (dict): all the values will be reduced\n        average (bool): whether to do average or sum\n    Reduce the values in the dictionary from all processes so that all processes\n    have the averaged results. Returns a dict with the same fields as\n    input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "all_reduce", "(", "values", ")", "\n", "if", "average", ":", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.collate_fn": [[235, 237], ["tuple", "zip"], "function", ["None"], ["", "", "def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "return", "tuple", "(", "zip", "(", "*", "batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.warmup_lr_scheduler": [[239, 248], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LambdaLR", "float"], "function", ["None"], ["", "def", "warmup_lr_scheduler", "(", "optimizer", ",", "warmup_iters", ",", "warmup_factor", ")", ":", "\n", "\n", "    ", "def", "f", "(", "x", ")", ":", "\n", "        ", "if", "x", ">=", "warmup_iters", ":", "\n", "            ", "return", "1", "\n", "", "alpha", "=", "float", "(", "x", ")", "/", "warmup_iters", "\n", "return", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "\n", "", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.mkdir": [[250, 256], ["os.makedirs"], "function", ["None"], ["", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.setup_for_distributed": [[258, 271], ["kwargs.pop", "builtin_print"], "function", ["None"], ["", "", "", "def", "setup_for_distributed", "(", "is_master", ")", ":", "\n", "    ", "\"\"\"\n    This function disables printing when not in master process\n    \"\"\"", "\n", "import", "builtins", "as", "__builtin__", "\n", "builtin_print", "=", "__builtin__", ".", "print", "\n", "\n", "def", "print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "force", "=", "kwargs", ".", "pop", "(", "'force'", ",", "False", ")", "\n", "if", "is_master", "or", "force", ":", "\n", "            ", "builtin_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "__builtin__", ".", "print", "=", "print", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_dist_avail_and_initialized": [[273, 279], ["torch.is_available", "torch.is_initialized"], "function", ["None"], ["", "def", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_world_size": [[281, 285], ["torch.get_world_size", "torchvision_detection_utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_world_size", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_dist_avail_and_initialized"], ["", "def", "get_world_size", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_rank": [[287, 291], ["torch.get_rank", "torchvision_detection_utils.is_dist_avail_and_initialized"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_rank", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_dist_avail_and_initialized"], ["", "def", "get_rank", "(", ")", ":", "\n", "    ", "if", "not", "is_dist_avail_and_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_main_process": [[293, 295], ["torchvision_detection_utils.get_rank"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.get_rank"], ["", "def", "is_main_process", "(", ")", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.save_on_master": [[297, 300], ["torchvision_detection_utils.is_main_process", "torch.save", "torch.save"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.is_main_process"], ["", "def", "save_on_master", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "is_main_process", "(", ")", ":", "\n", "        ", "torch", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.init_distributed_mode": [[302, 325], ["torch.cuda.set_device", "torch.cuda.set_device", "torchvision_detection_utils.setup_for_distributed.print", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.barrier", "torch.distributed.barrier", "torchvision_detection_utils.setup_for_distributed", "int", "int", "int", "int", "torchvision_detection_utils.setup_for_distributed.print", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.setup_for_distributed"], ["", "", "def", "init_distributed_mode", "(", "args", ")", ":", "\n", "    ", "if", "'RANK'", "in", "os", ".", "environ", "and", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", "\n", "args", ".", "gpu", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "", "elif", "'SLURM_PROCID'", "in", "os", ".", "environ", ":", "\n", "        ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "args", ".", "gpu", "=", "args", ".", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Not using distributed mode'", ")", "\n", "args", ".", "distributed", "=", "False", "\n", "return", "\n", "\n", "", "args", ".", "distributed", "=", "True", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "args", ".", "dist_backend", "=", "'nccl'", "\n", "print", "(", "'| distributed init (rank {}): {}'", ".", "format", "(", "\n", "args", ".", "rank", ",", "args", ".", "dist_url", ")", ",", "flush", "=", "True", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "args", ".", "dist_backend", ",", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "rank", "=", "args", ".", "rank", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "setup_for_distributed", "(", "args", ".", "rank", "==", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_box_dataset_reader.SubcaptionNerDatasetReader.__init__": [[22, 35], ["allennlp.data.dataset_readers.DatasetReader.__init__", "subcaption_box_dataset_reader.SubcaptionNerDatasetReader.token_indexers.values", "subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "lazy", ":", "bool", "=", "False", ",", "do_lowercase", ":", "bool", "=", "False", ",", "box_predictions_file", ":", "str", "=", "None", ",", "box_predictions_threshold", ":", "float", "=", "0.7", ",", "max_seq_length", ":", "int", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "token_indexers", "=", "token_indexers", "\n", "model_name", "=", "None", "\n", "for", "token_indexer", "in", "self", ".", "token_indexers", ".", "values", "(", ")", ":", "\n", "            ", "model_name", "=", "token_indexer", ".", "_model_name", "\n", "break", "\n", "", "self", ".", "box_predictions_file", "=", "box_predictions_file", "\n", "self", ".", "box_predictions_threshold", "=", "box_predictions_threshold", "\n", "self", ".", "tokenizer", "=", "PretrainedTransformerTokenizer", "(", "model_name", "=", "model_name", ",", "do_lowercase", "=", "do_lowercase", ")", "\n", "# self.tag_map = {'B': 1, 'I': 2, 'L': 3, 'O': 4, 'U': 5}", "\n", "self", ".", "tag_map", "=", "{", "'B'", ":", "'B'", ",", "'I'", ":", "'I'", ",", "'L'", ":", "'L'", ",", "'O'", ":", "'O'", ",", "'U'", ":", "'U'", "}", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_box_dataset_reader.SubcaptionNerDatasetReader._read": [[36, 137], ["open", "open.readlines", "enumerate", "json.loads", "open", "open.readlines", "len", "set", "set", "datum[].values", "common_tokens.intersection.intersection.union", "set", "json.loads", "len", "list", "list", "set", "common_tokens.intersection.intersection.intersection", "sorted", "spans.append", "span_lengths.append", "zip", "len", "range", "range", "len", "set", "range", "spans.append", "span_lengths.append", "list", "len", "set.add", "len", "gold_subfigures.append", "subcaptions_list.append", "subcaption_box_dataset_reader.SubcaptionNerDatasetReader.text_to_instance", "set", "range", "set.intersection", "len", "subcaption_box_dataset_reader.SubcaptionNerDatasetReader.text_to_instance", "list", "len", "min", "min", "max", "max", "min", "min", "max", "max", "range", "set.intersection", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "def", "_read", "(", "self", ",", "fname", ":", "str", ")", ":", "\n", "        ", "f", "=", "open", "(", "fname", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "box_predictions", "=", "None", "\n", "if", "self", ".", "box_predictions_file", "is", "not", "None", ":", "\n", "            ", "box_predictions", "=", "{", "}", "\n", "f", "=", "open", "(", "self", ".", "box_predictions_file", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "box_predictions", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "box_predictions", "=", "{", "datum", "[", "'image_id'", "]", ":", "datum", "for", "datum", "in", "box_predictions", "}", "\n", "", "for", "i", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "# Don't include figures that were ignored or rejected in annotations", "\n", "            ", "if", "datum", "[", "\"answer\"", "]", "!=", "\"accept\"", ":", "\n", "                ", "continue", "\n", "# Don't include figures that don't have subfigures", "\n", "", "if", "len", "(", "datum", "[", "\"spans\"", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "# Don't include figures that lack subcaptions", "\n", "", "if", "\"subcaptions\"", "not", "in", "datum", "or", "len", "(", "datum", "[", "\"subcaptions\"", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "subcaptions", "=", "{", "}", "\n", "image_id", "=", "datum", "[", "\"pdf_hash\"", "]", "+", "\"_\"", "+", "datum", "[", "\"fig_uri\"", "]", "\n", "# First, collect the tokens common to all subcaptions", "\n", "# These tokens will be removed from all subcaptions", "\n", "num_tokens", "=", "len", "(", "datum", "[", "\"tokens\"", "]", ")", "\n", "common_tokens", "=", "set", "(", "list", "(", "range", "(", "num_tokens", ")", ")", ")", "\n", "excluded_tokens", "=", "set", "(", "list", "(", "range", "(", "num_tokens", ")", ")", ")", "\n", "for", "subcaption_key", "in", "datum", "[", "\"subcaptions\"", "]", ":", "\n", "                ", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", "=", "set", "(", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", ")", "\n", "", "for", "subcaption_tokens", "in", "datum", "[", "\"subcaptions\"", "]", ".", "values", "(", ")", ":", "\n", "                ", "common_tokens", "=", "common_tokens", ".", "intersection", "(", "subcaption_tokens", ")", "\n", "excluded_tokens", "-=", "subcaption_tokens", "\n", "", "common_tokens", "=", "common_tokens", ".", "union", "(", "excluded_tokens", ")", "\n", "prev_span_indices", "=", "set", "(", ")", "\n", "single_span_subcaptions", "=", "{", "}", "\n", "for", "subcaption_key", "in", "datum", "[", "\"subcaptions\"", "]", ":", "\n", "                ", "subcaption_tokens", "=", "datum", "[", "\"subcaptions\"", "]", "[", "subcaption_key", "]", "\n", "spans", "=", "[", "]", "\n", "span_lengths", "=", "[", "]", "\n", "longest_span_index", "=", "None", "\n", "filtered_subcaption_tokens", "=", "subcaption_tokens", "-", "common_tokens", "\n", "if", "len", "(", "filtered_subcaption_tokens", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "sorted_tokens", "=", "sorted", "(", "filtered_subcaption_tokens", ")", "\n", "curr_start", "=", "sorted_tokens", "[", "0", "]", "\n", "curr_end", "=", "sorted_tokens", "[", "0", "]", "\n", "for", "token", "in", "sorted_tokens", "[", "1", ":", "]", ":", "\n", "                    ", "if", "token", ">", "curr_end", "+", "1", ":", "\n", "                        ", "spans", ".", "append", "(", "(", "curr_start", ",", "curr_end", ")", ")", "\n", "span_lengths", ".", "append", "(", "curr_end", "-", "curr_start", "+", "1", ")", "\n", "if", "longest_span_index", "is", "None", "or", "span_lengths", "[", "-", "1", "]", ">", "span_lengths", "[", "longest_span_index", "]", ":", "\n", "                            ", "span_set", "=", "set", "(", "list", "(", "range", "(", "curr_start", ",", "curr_end", "+", "1", ")", ")", ")", "\n", "# We want our single-span subcaptions to be disjoint from one another", "\n", "if", "len", "(", "span_set", ".", "intersection", "(", "prev_span_indices", ")", ")", "==", "0", ":", "\n", "                                ", "longest_span_index", "=", "len", "(", "span_lengths", ")", "-", "1", "\n", "", "", "curr_start", "=", "token", "\n", "curr_end", "=", "token", "\n", "", "else", ":", "\n", "                        ", "assert", "curr_end", "+", "1", "==", "token", "\n", "curr_end", "=", "token", "\n", "", "", "spans", ".", "append", "(", "(", "curr_start", ",", "curr_end", ")", ")", "\n", "span_lengths", ".", "append", "(", "curr_end", "-", "curr_start", "+", "1", ")", "\n", "if", "longest_span_index", "is", "None", "or", "span_lengths", "[", "-", "1", "]", ">", "span_lengths", "[", "longest_span_index", "]", ":", "\n", "                    ", "span_set", "=", "set", "(", "list", "(", "range", "(", "curr_start", ",", "curr_end", "+", "1", ")", ")", ")", "\n", "# We want our single-span subcaptions to be disjoint from one another", "\n", "if", "len", "(", "span_set", ".", "intersection", "(", "prev_span_indices", ")", ")", "==", "0", ":", "\n", "                        ", "longest_span_index", "=", "len", "(", "span_lengths", ")", "-", "1", "\n", "", "", "if", "longest_span_index", "is", "not", "None", ":", "\n", "                    ", "single_span_subcaptions", "[", "subcaption_key", "]", "=", "spans", "[", "longest_span_index", "]", "\n", "for", "token", "in", "range", "(", "spans", "[", "longest_span_index", "]", "[", "0", "]", ",", "spans", "[", "longest_span_index", "]", "[", "1", "]", "+", "1", ")", ":", "\n", "                        ", "prev_span_indices", ".", "add", "(", "token", ")", "\n", "", "", "subcaptions", "[", "subcaption_key", "]", "=", "filtered_subcaption_tokens", "\n", "", "gold_subfigures", "=", "[", "]", "\n", "pred_subfigures", "=", "[", "]", "\n", "subcaptions_list", "=", "[", "]", "\n", "for", "subfig", "in", "datum", "[", "\"spans\"", "]", ":", "\n", "                ", "xcoords", "=", "[", "point", "[", "0", "]", "for", "point", "in", "subfig", "[", "\"points\"", "]", "]", "\n", "ycoords", "=", "[", "point", "[", "1", "]", "for", "point", "in", "subfig", "[", "\"points\"", "]", "]", "\n", "if", "subfig", "[", "\"label\"", "]", "in", "subcaptions", "and", "len", "(", "subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ")", ">", "0", ":", "\n", "                    ", "if", "box_predictions", "is", "not", "None", ":", "\n", "                        ", "gold_subfigures", ".", "append", "(", "[", "min", "(", "xcoords", ")", ",", "min", "(", "ycoords", ")", ",", "max", "(", "xcoords", ")", ",", "max", "(", "ycoords", ")", "]", ")", "\n", "subcaptions_list", ".", "append", "(", "subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ")", "\n", "", "else", ":", "\n", "# span = single_span_subcaptions[subfig[\"label\"]]", "\n", "# subcaption = set([token for token in range(span[0], span[1]+1)])", "\n", "                        ", "instance", "=", "self", ".", "text_to_instance", "(", "[", "token", "[", "\"text\"", "]", "for", "token", "in", "datum", "[", "\"tokens\"", "]", "]", ",", "datum", "[", "\"pdf_hash\"", "]", "+", "\"_\"", "+", "datum", "[", "\"fig_uri\"", "]", ",", "datum", "[", "\"height\"", "]", ",", "datum", "[", "\"width\"", "]", ",", "common_tokens", ",", "subcaptions", "[", "subfig", "[", "\"label\"", "]", "]", ",", "[", "min", "(", "xcoords", ")", ",", "min", "(", "ycoords", ")", ",", "max", "(", "xcoords", ")", ",", "max", "(", "ycoords", ")", "]", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                            ", "yield", "instance", "\n", "", "", "", "", "if", "box_predictions", "is", "not", "None", ":", "\n", "                ", "first", "=", "False", "\n", "for", "box", ",", "score", "in", "zip", "(", "box_predictions", "[", "image_id", "]", "[", "'predictions'", "]", "[", "'boxes'", "]", ",", "box_predictions", "[", "image_id", "]", "[", "'predictions'", "]", "[", "'scores'", "]", ")", ":", "\n", "                    ", "if", "score", ">", "self", ".", "box_predictions_threshold", ":", "\n", "                        ", "if", "not", "first", ":", "\n", "                            ", "gold_subfigs", "=", "gold_subfigures", "\n", "gold_subcaps", "=", "subcaptions_list", "\n", "", "else", ":", "\n", "                            ", "gold_subfigs", "=", "[", "]", "\n", "gold_subcaps", "=", "[", "]", "\n", "", "yield", "self", ".", "text_to_instance", "(", "[", "token", "[", "\"text\"", "]", "for", "token", "in", "datum", "[", "\"tokens\"", "]", "]", ",", "datum", "[", "\"pdf_hash\"", "]", "+", "\"_\"", "+", "datum", "[", "\"fig_uri\"", "]", ",", "datum", "[", "\"height\"", "]", ",", "datum", "[", "\"width\"", "]", ",", "common_tokens", ",", "gold_subcaps", ",", "box", ",", "gold_subfigs", ")", "\n", "", "first", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_box_dataset_reader.SubcaptionNerDatasetReader.text_to_instance": [[138, 192], ["subcaption.subcaption_ner_dataset_reader.convert_to_wordpieces", "set", "allennlp.data.fields.TextField", "print", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.Instance", "len", "allennlp.data.Token", "print", "spans.append", "print", "print", "print", "allennlp.data.fields.SequenceLabelField", "numpy.array", "float", "float", "float", "float", "sorted", "spans.append", "range", "zip", "sorted"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subcaption_ner_dataset_reader.convert_to_wordpieces"], ["", "", "", "", "def", "text_to_instance", "(", "self", ",", "tokens", ",", "image_id", ",", "height", ",", "width", ",", "common_tokens", "=", "None", ",", "subcaption", "=", "None", ",", "box", "=", "None", ",", "gold_boxes", "=", "None", ")", ":", "\n", "        ", "subcaption_input", "=", "[", "subcaption", "]", "\n", "if", "gold_boxes", "is", "not", "None", ":", "\n", "            ", "subcaption_input", "=", "subcaption", "\n", "", "wordpieces", ",", "common_wordpieces", ",", "_", ",", "wordpiece_subcaption", "=", "convert_to_wordpieces", "(", "self", ".", "tokenizer", ".", "_tokenizer", ",", "tokens", ",", "common_tokens", ",", "None", ",", "subcaption_input", ")", "\n", "\n", "if", "len", "(", "wordpieces", ")", ">", "self", ".", "max_seq_length", "-", "2", ":", "\n", "            ", "wordpieces", "=", "wordpieces", "[", ":", "self", ".", "max_seq_length", "-", "2", "]", "\n", "# wordpiece_subcaptions = [new_subcaption]", "\n", "", "wordpieces", "=", "[", "\"[CLS]\"", "]", "+", "wordpieces", "+", "[", "\"[SEP]\"", "]", "\n", "common_wordpieces", "=", "set", "(", "[", "wordpiece_index", "+", "1", "for", "wordpiece_index", "in", "common_wordpieces", "]", ")", "\n", "wordpiece_tokens", "=", "[", "Token", "(", "wordpiece", ")", "for", "wordpiece", "in", "wordpieces", "]", "\n", "fields", "=", "{", "}", "\n", "tokens_field", "=", "TextField", "(", "wordpiece_tokens", ",", "token_indexers", "=", "self", ".", "token_indexers", ")", "\n", "fields", "[", "\"tokens\"", "]", "=", "tokens_field", "\n", "if", "gold_boxes", "is", "None", ":", "\n", "# Account for CLS token", "\n", "            ", "wordpiece_subcaption", "=", "[", "wordpiece", "+", "1", "for", "wordpiece", "in", "sorted", "(", "wordpiece_subcaption", "[", "0", "]", ")", "]", "\n", "print", "(", "[", "wordpieces", "[", "index", "]", "for", "index", "in", "wordpiece_subcaption", "]", ")", "\n", "spans", "=", "[", "]", "\n", "span_start", "=", "wordpiece_subcaption", "[", "0", "]", "\n", "span_end", "=", "wordpiece_subcaption", "[", "0", "]", "\n", "for", "token", "in", "wordpiece_subcaption", "[", "1", ":", "]", ":", "\n", "                ", "if", "token", ">", "span_end", "+", "1", ":", "\n", "                    ", "spans", ".", "append", "(", "(", "span_start", ",", "span_end", ")", ")", "\n", "span_start", "=", "token", "\n", "span_end", "=", "token", "\n", "", "else", ":", "\n", "                    ", "assert", "token", "==", "span_end", "+", "1", "\n", "span_end", "=", "token", "\n", "", "", "spans", ".", "append", "(", "(", "span_start", ",", "span_end", ")", ")", "\n", "# assert len(spans) == 1", "\n", "tags", "=", "[", "self", ".", "tag_map", "[", "'O'", "]", "for", "_", "in", "wordpieces", "]", "\n", "for", "span", "in", "spans", ":", "\n", "                ", "if", "span", "[", "0", "]", "==", "span", "[", "1", "]", ":", "\n", "                    ", "tags", "[", "span", "[", "0", "]", "]", "=", "self", ".", "tag_map", "[", "\"U\"", "]", "\n", "", "else", ":", "\n", "                    ", "tags", "[", "span", "[", "0", "]", "]", "=", "self", ".", "tag_map", "[", "\"B\"", "]", "\n", "tags", "[", "span", "[", "1", "]", "]", "=", "self", ".", "tag_map", "[", "\"L\"", "]", "\n", "for", "index", "in", "range", "(", "span", "[", "0", "]", "+", "1", ",", "span", "[", "1", "]", ")", ":", "\n", "                        ", "tags", "[", "index", "]", "=", "self", ".", "tag_map", "[", "\"I\"", "]", "\n", "", "", "", "print", "(", "[", "word", "for", "word", ",", "tag", "in", "zip", "(", "wordpieces", ",", "tags", ")", "if", "tag", "!=", "self", ".", "tag_map", "[", "\"O\"", "]", "]", ")", "\n", "print", "(", "tags", ")", "\n", "print", "(", "spans", ")", "\n", "fields", "[", "\"tags\"", "]", "=", "SequenceLabelField", "(", "tags", ",", "tokens_field", ",", "\"labels\"", ")", "\n", "", "else", ":", "\n", "            ", "wordpiece_subcaption", "=", "[", "[", "wordpiece", "+", "1", "for", "wordpiece", "in", "sorted", "(", "subcap", ")", "]", "for", "subcap", "in", "wordpiece_subcaption", "]", "\n", "# fields[\"start\"] = ArrayField(np.array(spans[0][0], dtype=np.int64), dtype=np.int64)", "\n", "# fields[\"end\"] = ArrayField(np.array(spans[0][1], dtype=np.int64), dtype=np.int64)", "\n", "", "normalized_box", "=", "[", "box", "[", "0", "]", "/", "float", "(", "width", ")", ",", "box", "[", "1", "]", "/", "float", "(", "height", ")", ",", "box", "[", "2", "]", "/", "float", "(", "width", ")", ",", "box", "[", "3", "]", "/", "float", "(", "height", ")", "]", "\n", "print", "(", "normalized_box", ")", "\n", "fields", "[", "\"box\"", "]", "=", "ArrayField", "(", "np", ".", "array", "(", "normalized_box", ",", "dtype", "=", "np", ".", "float32", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "{", "\"image_id\"", ":", "image_id", ",", "\"words\"", ":", "wordpieces", ",", "\"common_wordpieces\"", ":", "common_wordpieces", ",", "\"gold_subcaption\"", ":", "wordpiece_subcaption", ",", "\"gold_subfigure\"", ":", "box", "if", "gold_boxes", "is", "None", "else", "gold_boxes", ",", "\"predicted_subfigure\"", ":", "box", "}", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.__init__": [[40, 58], ["super().__init__", "transformers.AutoTokenizer.from_pretrained", "logger.info", "model_name.endswith", "logger.warning", "pretrained_transformer_indexer.PretrainedTransformerIndexer.tokenizer.convert_tokens_to_ids", "model_name.endswith", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model_name", ":", "str", ",", "\n", "do_lowercase", ":", "bool", ",", "\n", "namespace", ":", "str", "=", "\"tags\"", ",", "\n", "token_min_padding_length", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "token_min_padding_length", ")", "\n", "if", "model_name", ".", "endswith", "(", "\"-cased\"", ")", "and", "do_lowercase", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Your pretrained model appears to be cased, \"", "\n", "\"but your indexer is lowercasing tokens.\"", ")", "\n", "", "elif", "model_name", ".", "endswith", "(", "\"-uncased\"", ")", "and", "not", "do_lowercase", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Your pretrained model appears to be uncased, \"", "\n", "\"but your indexer is not lowercasing tokens.\"", ")", "\n", "", "self", ".", "_model_name", "=", "model_name", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ",", "do_lower_case", "=", "do_lowercase", ")", "\n", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_added_to_vocabulary", "=", "False", "\n", "self", ".", "_padding_value", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "self", ".", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", "\n", "logger", ".", "info", "(", "f\"Using token indexer padding value of {self._padding_value}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.count_vocab_items": [[59, 63], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If we only use pretrained models, we don't need to do anything here.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer._add_encoding_to_vocabulary": [[64, 69], ["pretrained_transformer_indexer.PretrainedTransformerIndexer.tokenizer.vocab.items"], "methods", ["None"], ["", "def", "_add_encoding_to_vocabulary", "(", "self", ",", "vocabulary", ":", "Vocabulary", ")", "->", "None", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "for", "word", ",", "idx", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "            ", "vocabulary", ".", "_token_to_index", "[", "self", ".", "_namespace", "]", "[", "word", "]", "=", "idx", "\n", "vocabulary", ".", "_index_to_token", "[", "self", ".", "_namespace", "]", "[", "idx", "]", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.tokens_to_indices": [[70, 82], ["pretrained_transformer_indexer.PretrainedTransformerIndexer.tokenizer.convert_tokens_to_ids", "hasattr", "pretrained_transformer_indexer.PretrainedTransformerIndexer._add_encoding_to_vocabulary"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer._add_encoding_to_vocabulary"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_added_to_vocabulary", "and", "hasattr", "(", "self", ".", "tokenizer", ",", "\"vocab\"", ")", ":", "\n", "            ", "self", ".", "_add_encoding_to_vocabulary", "(", "vocabulary", ")", "\n", "self", ".", "_added_to_vocabulary", "=", "True", "\n", "", "token_text", "=", "[", "token", ".", "text", "for", "token", "in", "tokens", "]", "\n", "indices", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "token_text", ")", "\n", "\n", "return", "{", "index_name", ":", "indices", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.get_padding_lengths": [[83, 86], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.as_padded_tensor": [[87, 96], ["torch.LongTensor", "allennlp.common.util.pad_sequence_to_length", "tokens.items"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_padded_tensor", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "torch", ".", "LongTensor", "(", "pad_sequence_to_length", "(", "val", ",", "\n", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "lambda", ":", "self", ".", "_padding_value", ")", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_indexer.PretrainedTransformerIndexer.__eq__": [[97, 108], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "other", ",", "PretrainedTransformerIndexer", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "__dict__", ":", "\n", "                ", "if", "key", "==", "'tokenizer'", ":", "\n", "# This is a reference to a function in the huggingface code, which we can't", "\n", "# really modify to make this clean.  So we special-case it.", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "__dict__", "[", "key", "]", "!=", "other", ".", "__dict__", "[", "key", "]", ":", "\n", "                    ", "return", "False", "\n", "", "", "return", "True", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_crf_tagger.BertCrfTagger.__init__": [[68, 128], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "bert_crf_tagger.BertCrfTagger.vocab.get_vocab_size", "torch.nn.Dropout", "allennlp.modules.TimeDistributed", "allennlp.modules.ConditionalRandomField", "subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric", "subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric", "subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric", "initializer", "torch.nn.modules.linear.Linear", "transformers.BertModel", "bert_crf_tagger.BertCrfTagger.vocab.get_index_to_token_vocabulary", "allennlp.modules.conditional_random_field.allowed_transitions", "bert_crf_tagger.BertCrfTagger.text_field_embedder.get_output_dim", "allennlp.common.checks.ConfigurationError"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ",", "\n", "label_encoding", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "include_start_end_transitions", ":", "bool", "=", "True", ",", "\n", "constrain_crf_decoding", ":", "bool", "=", "None", ",", "\n", "pretrained", ":", "bool", "=", "True", ",", "\n", "block_pixel_width", ":", "float", "=", "50", ",", "\n", "span_labels", ":", "bool", "=", "False", ",", "\n", "iou_threshold", ":", "float", "=", "0.5", ",", "\n", "show_oracle_f1", ":", "bool", "=", "True", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "verbose_metrics", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "label_namespace", "=", "label_namespace", "\n", "self", ".", "text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "num_tags", "=", "self", ".", "vocab", ".", "get_vocab_size", "(", "label_namespace", ")", "\n", "# self.num_tags = 6", "\n", "self", ".", "_verbose_metrics", "=", "verbose_metrics", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "tag_projection_layer", "=", "TimeDistributed", "(", "\n", "Linear", "(", "self", ".", "text_field_embedder", ".", "get_output_dim", "(", ")", ",", "self", ".", "num_tags", ")", "\n", ")", "\n", "self", ".", "block_pixel_width", "=", "block_pixel_width", "\n", "self", ".", "span_labels", "=", "span_labels", "\n", "\n", "if", "not", "pretrained", ":", "\n", "            ", "self", ".", "text_field_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "transformer_model", "=", "BertModel", "(", "config", "=", "self", ".", "text_field_embedder", ".", "_token_embedders", "[", "'bert'", "]", ".", "transformer_model", ".", "config", ")", "\n", "\n", "# if  constrain_crf_decoding and calculate_span_f1 are not", "\n", "# provided, (i.e., they're None), set them to True", "\n", "# if label_encoding is provided and False if it isn't.", "\n", "", "if", "constrain_crf_decoding", "is", "None", ":", "\n", "            ", "constrain_crf_decoding", "=", "label_encoding", "is", "not", "None", "\n", "\n", "", "self", ".", "label_encoding", "=", "label_encoding", "\n", "if", "constrain_crf_decoding", ":", "\n", "            ", "if", "not", "label_encoding", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\"constrain_crf_decoding is True, but \"", "\n", "\"no label_encoding was specified.\"", ")", "\n", "", "labels", "=", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "label_namespace", ")", "\n", "constraints", "=", "allowed_transitions", "(", "label_encoding", ",", "labels", ")", "\n", "", "else", ":", "\n", "            ", "constraints", "=", "None", "\n", "\n", "", "self", ".", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", "self", ".", "crf", "=", "ConditionalRandomField", "(", "\n", "self", ".", "num_tags", ",", "constraints", ",", "\n", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", ")", "\n", "\n", "self", ".", "subcaption_metric", "=", "SubfigureSubcaptionAlignmentMetric", "(", "iou_threshold", ")", "\n", "self", ".", "oracle_single_span_metric", "=", "SubfigureSubcaptionAlignmentMetric", "(", "iou_threshold", ")", "\n", "self", ".", "oracle_full_metric", "=", "SubfigureSubcaptionAlignmentMetric", "(", "iou_threshold", ")", "\n", "self", ".", "show_oracle_f1", "=", "show_oracle_f1", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_crf_tagger.BertCrfTagger.forward": [[129, 299], ["allennlp.get_text_field_mask", "bert_crf_tagger.BertCrfTagger.text_field_embedder", "bert_crf_tagger.BertCrfTagger.dropout", "bert_crf_tagger.BertCrfTagger.tag_projection_layer", "bert_crf_tagger.BertCrfTagger.crf.viterbi_tags", "bert_crf_tagger.BertCrfTagger.crf", "enumerate", "range", "range", "enumerate", "range", "range", "batch_subcaptions.append", "bert_crf_tagger.BertCrfTagger.subcaption_metric", "bert_crf_tagger.BertCrfTagger.oracle_single_span_metric", "bert_crf_tagger.BertCrfTagger.oracle_full_metric", "list", "batch_predicted_boxes.append", "batch_oracle_single_span_boxes.append", "batch_oracle_full_boxes.append", "len", "bert_crf_tagger.BertCrfTagger.vocab.get_token_from_index", "list", "subcaptions.append", "len", "len", "range", "batch_oracle_single_span_subcaptions.append", "sorted", "batch_oracle_full_subcaptions.append", "sorted", "range", "range", "range", "range", "[].split", "range", "[].split", "range", "range", "range", "sorted", "mask[].long().item", "print", "pred_spans.append", "pred_span_labels.append", "range", "len", "list", "oracle_single_span_subcaptions.append", "len", "len", "len", "len", "len", "any", "pred_spans.append", "bert_crf_tagger.BertCrfTagger.vocab.get_token_from_index", "pred_span_labels.append", "pred_spans.append", "pred_span_labels.append", "mask[].long().item", "bert_crf_tagger.BertCrfTagger.vocab.get_token_from_index", "range", "len", "list", "len", "blocks[].append", "len", "all", "mask[].long", "range", "tags[].item", "gold_spans.append", "range", "range", "range", "range", "range", "range", "range", "range", "mask[].long", "gold_spans.append", "range", "range", "abs", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "tags", ":", "torch", ".", "LongTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "# pylint: disable=unused-argument", "\n", "**", "kwargs", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        tokens : ``Dict[str, torch.LongTensor]``, required\n            The output of ``TextField.as_array()``, which should typically be passed directly to a\n            ``TextFieldEmbedder``. This output is a dictionary mapping keys to ``TokenIndexer``\n            tensors.  At its most basic, using a ``SingleIdTokenIndexer`` this is: ``{\"tokens\":\n            Tensor(batch_size, num_tokens)}``. This dictionary will have the same keys as were used\n            for the ``TokenIndexers`` when you created the ``TextField`` representing your\n            sequence.  The dictionary is designed to be passed directly to a ``TextFieldEmbedder``,\n            which knows how to combine different word representations into a single vector per\n            token in your input.\n        tags : ``torch.LongTensor``, optional (default = ``None``)\n            A torch tensor representing the sequence of integer gold class labels of shape\n            ``(batch_size, num_tokens)``.\n        metadata : ``List[Dict[str, Any]]``, optional, (default = None)\n            metadata containg the original words in the sentence to be tagged under a 'words' key.\n        Returns\n        -------\n        An output dictionary consisting of:\n        logits : ``torch.FloatTensor``\n            The logits that are the output of the ``tag_projection_layer``\n        mask : ``torch.LongTensor``\n            The text field mask for the input tokens\n        tags : ``List[List[int]]``\n            The predicted tags using the Viterbi algorithm.\n        loss : ``torch.FloatTensor``, optional\n            A scalar loss to be optimised. Only computed if gold label ``tags`` are provided.\n        \"\"\"", "\n", "mask", "=", "util", ".", "get_text_field_mask", "(", "tokens", ")", "\n", "batch_size", "=", "mask", ".", "shape", "[", "0", "]", "\n", "embedded_text_input", "=", "self", ".", "text_field_embedder", "(", "tokens", ")", "\n", "\n", "embedded_text_input", "=", "self", ".", "dropout", "(", "embedded_text_input", ")", "\n", "\n", "logits", "=", "self", ".", "tag_projection_layer", "(", "embedded_text_input", ")", "\n", "best_paths", "=", "self", ".", "crf", ".", "viterbi_tags", "(", "logits", ",", "mask", ")", "\n", "\n", "# Just get the tags and ignore the score.", "\n", "predicted_tags", "=", "[", "x", "for", "x", ",", "y", "in", "best_paths", "]", "\n", "\n", "output", "=", "{", "\"logits\"", ":", "logits", ",", "\"mask\"", ":", "mask", ",", "\"tags\"", ":", "predicted_tags", "}", "\n", "\n", "if", "tags", "is", "not", "None", ":", "\n", "# Add negative log-likelihood as loss", "\n", "            ", "log_likelihood", "=", "self", ".", "crf", "(", "logits", ",", "tags", ",", "mask", ")", "\n", "output", "[", "\"loss\"", "]", "=", "-", "log_likelihood", "\n", "\n", "# Represent viterbi tags as \"class probabilities\" that we can", "\n", "# feed into the metrics", "\n", "class_probabilities", "=", "logits", "*", "0.", "\n", "for", "i", ",", "instance_tags", "in", "enumerate", "(", "predicted_tags", ")", ":", "\n", "                ", "for", "j", ",", "tag_id", "in", "enumerate", "(", "instance_tags", ")", ":", "\n", "                    ", "class_probabilities", "[", "i", ",", "j", ",", "tag_id", "]", "=", "1", "\n", "\n", "", "", "if", "self", ".", "span_labels", ":", "\n", "                ", "batch_predicted_boxes", "=", "[", "metadata", "[", "i", "]", "[", "\"predicted_subfigures\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "", "else", ":", "\n", "                ", "batch_predicted_boxes", "=", "[", "]", "\n", "batch_oracle_single_span_boxes", "=", "[", "]", "\n", "batch_oracle_full_boxes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "blocks", "=", "[", "]", "\n", "for", "box", "in", "metadata", "[", "i", "]", "[", "\"predicted_subfigures\"", "]", ":", "\n", "                        ", "placed", "=", "False", "\n", "for", "j", "in", "range", "(", "len", "(", "blocks", ")", ")", ":", "\n", "                            ", "if", "any", "(", "[", "abs", "(", "b", "[", "1", "]", "-", "box", "[", "1", "]", ")", "<", "self", ".", "block_pixel_width", "for", "b", "in", "blocks", "[", "j", "]", "]", ")", ":", "\n", "                                ", "blocks", "[", "j", "]", ".", "append", "(", "box", ")", "\n", "placed", "=", "True", "\n", "break", "\n", "", "", "if", "not", "placed", ":", "\n", "                            ", "index", "=", "0", "\n", "while", "index", "<", "len", "(", "blocks", ")", ":", "\n", "                                ", "if", "all", "(", "[", "box", "[", "1", "]", "<", "b", "[", "1", "]", "for", "b", "in", "blocks", "[", "index", "]", "]", ")", ":", "\n", "                                    ", "break", "\n", "", "index", "+=", "1", "\n", "", "blocks", "=", "blocks", "[", ":", "index", "]", "+", "[", "[", "box", "]", "]", "+", "blocks", "[", "index", ":", "]", "\n", "", "", "blocks", "=", "[", "sorted", "(", "block", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "for", "block", "in", "blocks", "]", "\n", "predicted_boxes", "=", "[", "box", "for", "block", "in", "blocks", "for", "box", "in", "block", "]", "\n", "batch_predicted_boxes", ".", "append", "(", "predicted_boxes", ")", "\n", "batch_oracle_single_span_boxes", ".", "append", "(", "predicted_boxes", ")", "\n", "batch_oracle_full_boxes", ".", "append", "(", "predicted_boxes", ")", "\n", "", "", "batch_subcaptions", "=", "[", "]", "\n", "batch_oracle_single_span_subcaptions", "=", "[", "]", "\n", "batch_oracle_full_subcaptions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "pred_spans", "=", "[", "]", "\n", "pred_span_labels", "=", "[", "]", "\n", "pred_start", "=", "None", "\n", "for", "j", "in", "range", "(", "len", "(", "predicted_tags", "[", "i", "]", ")", ")", ":", "\n", "                    ", "if", "mask", "[", "i", ",", "j", "]", ".", "long", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                        ", "print", "(", "\"here\"", ")", "\n", "if", "pred_start", "is", "not", "None", ":", "\n", "                            ", "pred_spans", ".", "append", "(", "(", "pred_start", ",", "j", "-", "1", ")", ")", "\n", "pred_tag", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "predicted_tags", "[", "i", "]", "[", "j", "-", "1", "]", ",", "namespace", "=", "\"labels\"", ")", "\n", "pred_span_labels", ".", "append", "(", "pred_tag", "[", "1", ":", "]", ")", "\n", "pred_start", "=", "None", "\n", "", "break", "\n", "", "pred_tag", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "predicted_tags", "[", "i", "]", "[", "j", "]", ",", "namespace", "=", "\"labels\"", ")", "\n", "if", "pred_tag", "[", "0", "]", "==", "\"U\"", ":", "\n", "                        ", "pred_spans", ".", "append", "(", "(", "j", ",", "j", ")", ")", "\n", "pred_span_labels", ".", "append", "(", "pred_tag", "[", "1", ":", "]", ")", "\n", "", "if", "pred_start", "is", "None", "and", "pred_tag", "[", "0", "]", "==", "\"B\"", ":", "\n", "                        ", "pred_start", "=", "j", "\n", "", "elif", "pred_start", "is", "not", "None", "and", "pred_tag", "[", "0", "]", "==", "\"L\"", ":", "\n", "                        ", "pred_spans", ".", "append", "(", "(", "pred_start", ",", "j", ")", ")", "\n", "pred_span_labels", ".", "append", "(", "pred_tag", "[", "1", ":", "]", ")", "\n", "pred_start", "=", "None", "\n", "", "", "subcaptions", "=", "[", "]", "\n", "for", "span", "in", "pred_spans", ":", "\n", "                    ", "subcaption", "=", "list", "(", "range", "(", "span", "[", "0", "]", ",", "span", "[", "1", "]", "+", "1", ")", ")", "\n", "subcaptions", ".", "append", "(", "subcaption", ")", "\n", "", "if", "len", "(", "subcaptions", ")", "<", "len", "(", "batch_predicted_boxes", "[", "i", "]", ")", ":", "\n", "                    ", "if", "len", "(", "subcaptions", ")", ">", "0", ":", "\n", "                        ", "subcaptions", "+=", "[", "subcaptions", "[", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "batch_predicted_boxes", "[", "i", "]", ")", "-", "len", "(", "subcaptions", ")", ")", "]", "\n", "", "else", ":", "\n", "                        ", "batch_predicted_boxes", "[", "i", "]", "=", "[", "]", "\n", "", "", "batch_subcaptions", ".", "append", "(", "subcaptions", ")", "\n", "if", "self", ".", "show_oracle_f1", ":", "\n", "                    ", "gold_start", "=", "None", "\n", "gold_spans", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "tags", ".", "shape", "[", "1", "]", ")", ":", "\n", "                        ", "if", "mask", "[", "i", ",", "j", "]", ".", "long", "(", ")", ".", "item", "(", ")", ">", "0", ":", "\n", "                            ", "tag", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "tags", "[", "i", ",", "j", "]", ".", "item", "(", ")", ",", "namespace", "=", "\"labels\"", ")", "\n", "if", "tag", "==", "\"U\"", ":", "\n", "                                ", "gold_spans", ".", "append", "(", "(", "j", ",", "j", ")", ")", "\n", "", "if", "gold_start", "is", "None", "and", "tag", "[", "0", "]", "==", "\"B\"", ":", "\n", "                                ", "gold_start", "=", "j", "\n", "", "elif", "gold_start", "is", "not", "None", "and", "tag", "[", "0", "]", "==", "\"L\"", ":", "\n", "                                ", "gold_spans", ".", "append", "(", "(", "gold_start", ",", "j", ")", ")", "\n", "gold_start", "=", "None", "\n", "", "", "", "oracle_single_span_subcaptions", "=", "[", "]", "\n", "for", "span", "in", "gold_spans", ":", "\n", "                        ", "subcaption", "=", "list", "(", "range", "(", "span", "[", "0", "]", ",", "span", "[", "1", "]", "+", "1", ")", ")", "\n", "oracle_single_span_subcaptions", ".", "append", "(", "subcaption", ")", "\n", "", "if", "len", "(", "oracle_single_span_subcaptions", ")", "<", "len", "(", "batch_oracle_single_span_boxes", "[", "i", "]", ")", ":", "\n", "                        ", "if", "len", "(", "oracle_single_span_subcaptions", ")", ">", "0", ":", "\n", "                            ", "oracle_single_span_subcaptions", "+=", "[", "oracle_single_span_subcaptions", "[", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "batch_oracle_single_span_boxes", "[", "i", "]", ")", "-", "len", "(", "oracle_single_span_subcaptions", ")", ")", "]", "\n", "", "", "batch_oracle_single_span_subcaptions", ".", "append", "(", "oracle_single_span_subcaptions", ")", "\n", "oracle_full_subcaptions", "=", "sorted", "(", "[", "list", "(", "subcaption", ")", "for", "subcaption", "in", "metadata", "[", "i", "]", "[", "\"gold_subcaptions\"", "]", "]", ")", "\n", "if", "len", "(", "oracle_full_subcaptions", ")", "<", "len", "(", "batch_oracle_full_boxes", "[", "i", "]", ")", ":", "\n", "                        ", "if", "len", "(", "oracle_full_subcaptions", ")", ">", "0", ":", "\n", "                            ", "oracle_full_subcaptions", "+=", "[", "oracle_full_subcaptions", "[", "-", "1", "]", "for", "_", "in", "range", "(", "len", "(", "batch_oracle_full_boxes", "[", "i", "]", ")", "-", "len", "(", "oracle_full_subcaptions", ")", ")", "]", "\n", "", "", "batch_oracle_full_subcaptions", ".", "append", "(", "oracle_full_subcaptions", ")", "\n", "# self.subcaption_metric(gold_subfigures=[metadata[i][\"gold_subfigures\"] for i in range(batch_size)], predicted_subfigures=batch_predicted_boxes, gold_tokens=[metadata[i][\"gold_subcaptions\"] for i in range(batch_size)], predicted_tokens=batch_subcaptions, common_wordpieces=[metadata[i][\"common_wordpieces\"] for i in range(batch_size)], wordpieces=[metadata[i][\"words\"] for i in range(batch_size)])", "\n", "", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "self", ".", "subcaption_metric", "(", "gold_subfigures", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigures\"", "]", "]", ",", "predicted_subfigures", "=", "batch_predicted_boxes", "[", "i", ":", "i", "+", "1", "]", ",", "gold_tokens", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaptions\"", "]", "]", ",", "predicted_tokens", "=", "batch_subcaptions", "[", "i", ":", "i", "+", "1", "]", ",", "common_wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", "]", ",", "wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "]", ")", "\n", "", "if", "self", ".", "show_oracle_f1", ":", "\n", "                ", "self", ".", "oracle_single_span_metric", "(", "gold_subfigures", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigures\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "predicted_subfigures", "=", "batch_oracle_single_span_boxes", ",", "gold_tokens", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaptions\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "predicted_tokens", "=", "batch_oracle_single_span_subcaptions", ",", "common_wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "self", ".", "oracle_full_metric", "(", "gold_subfigures", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigures\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "predicted_subfigures", "=", "batch_oracle_full_boxes", ",", "gold_tokens", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subcaptions\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "predicted_tokens", "=", "batch_oracle_full_subcaptions", ",", "common_wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ",", "wordpieces", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "\n", "", "", "output", "[", "\"predicted_subcaptions\"", "]", "=", "batch_subcaptions", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "# output[\"metadata\"] = metadata", "\n", "            ", "output", "[", "\"gold_subcaptions\"", "]", "=", "[", "[", "sorted", "(", "subcaption", ")", "for", "subcaption", "in", "metadata", "[", "i", "]", "[", "\"gold_subcaptions\"", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"gold_subfigures\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"gold_subfigures\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"predicted_subfigures\"", "]", "=", "batch_predicted_boxes", "\n", "output", "[", "\"common_wordpieces\"", "]", "=", "[", "list", "(", "metadata", "[", "i", "]", "[", "\"common_wordpieces\"", "]", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"wordpieces\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"words\"", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"pdf_hash\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"image_id\"", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output", "[", "\"fig_uri\"", "]", "=", "[", "metadata", "[", "i", "]", "[", "\"image_id\"", "]", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_crf_tagger.BertCrfTagger.decode": [[300, 313], ["bert_crf_tagger.BertCrfTagger.vocab.get_token_from_index"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Converts the tag ids to the actual tags.\n        ``output_dict[\"tags\"]`` is a list of lists of tag_ids,\n        so we use an ugly nested list comprehension.\n        \"\"\"", "\n", "output_dict", "[", "\"tags\"", "]", "=", "[", "\n", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "tag", ",", "namespace", "=", "self", ".", "label_namespace", ")", "\n", "for", "tag", "in", "instance_tags", "]", "\n", "for", "instance_tags", "in", "output_dict", "[", "\"tags\"", "]", "\n", "]", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.bert_crf_tagger.BertCrfTagger.get_metrics": [[314, 321], ["bert_crf_tagger.BertCrfTagger.subcaption_metric.get_metric", "bert_crf_tagger.BertCrfTagger.oracle_single_span_metric.get_metric", "bert_crf_tagger.BertCrfTagger.oracle_full_metric.get_metric"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics_to_return", "=", "{", "\"subcaption_f1\"", ":", "self", ".", "subcaption_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "}", "\n", "if", "self", ".", "show_oracle_f1", ":", "\n", "            ", "metrics_to_return", "[", "\"oracle_single_span_f1\"", "]", "=", "self", ".", "oracle_single_span_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "\n", "metrics_to_return", "[", "\"oracle_full_f1\"", "]", "=", "self", ".", "oracle_full_metric", ".", "get_metric", "(", "reset", "=", "reset", ")", "\n", "", "return", "metrics_to_return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.__init__": [[37, 53], ["transformers.AutoTokenizer.from_pretrained", "pretrained_transformer_tokenizer._guess_start_and_end_token_defaults", "pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenizer_lowercases", "model_name.endswith", "logger.warning", "model_name.endswith", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer._guess_start_and_end_token_defaults", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenizer_lowercases"], ["def", "__init__", "(", "self", ",", "\n", "model_name", ":", "str", ",", "\n", "do_lowercase", ":", "bool", ",", "\n", "start_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "end_tokens", ":", "List", "[", "str", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "if", "model_name", ".", "endswith", "(", "\"-cased\"", ")", "and", "do_lowercase", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Your pretrained model appears to be cased, \"", "\n", "\"but your tokenizer is lowercasing tokens.\"", ")", "\n", "", "elif", "model_name", ".", "endswith", "(", "\"-uncased\"", ")", "and", "not", "do_lowercase", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Your pretrained model appears to be uncased, \"", "\n", "\"but your tokenizer is not lowercasing tokens.\"", ")", "\n", "", "self", ".", "_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ",", "do_lower_case", "=", "do_lowercase", ")", "\n", "default_start_tokens", ",", "default_end_tokens", "=", "_guess_start_and_end_token_defaults", "(", "model_name", ")", "\n", "self", ".", "_start_tokens", "=", "start_tokens", "if", "start_tokens", "is", "not", "None", "else", "default_start_tokens", "\n", "self", ".", "_end_tokens", "=", "end_tokens", "if", "end_tokens", "is", "not", "None", "else", "default_end_tokens", "\n", "self", ".", "_tokenizer_lowercases", "=", "self", ".", "tokenizer_lowercases", "(", "self", ".", "_tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenizer_lowercases": [[54, 62], ["tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize"], ["", "def", "tokenizer_lowercases", "(", "self", ",", "tokenizer", ")", "->", "bool", ":", "\n", "# Huggingface tokenizers have different ways of remembering whether they lowercase or not. Detecting it", "\n", "# this way seems like the least brittle way to do it.", "\n", "        ", "tokenized", "=", "tokenizer", ".", "tokenize", "(", "\n", "\"A\"", "\n", ")", "# Use a single character that won't be cut into word pieces.", "\n", "detokenized", "=", "\" \"", ".", "join", "(", "tokenized", ")", "\n", "return", "\"a\"", "in", "detokenized", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize": [[63, 74], ["pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._tokenizer.tokenize", "pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._tokenizer.convert_tokens_to_ids", "pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._estimate_character_indices", "len", "len", "allennlp.data.tokenizers.token.Token", "pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._tokenizer.tokenize", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._estimate_character_indices", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize"], ["", "@", "overrides", "\n", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "# TODO(mattg): track character offsets.  Might be too challenging to do it here, given that", "\n", "# pytorch-transformers is dealing with the whitespace...", "\n", "        ", "token_strings", "=", "self", ".", "_start_tokens", "+", "self", ".", "_tokenizer", ".", "tokenize", "(", "text", ")", "+", "self", ".", "_end_tokens", "\n", "tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "token_ids", "=", "self", ".", "_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "offsets", "=", "self", ".", "_estimate_character_indices", "(", "text", ",", "token_ids", ")", "\n", "offsets", "=", "[", "(", "0", ",", "0", ")", "]", "+", "offsets", "+", "[", "(", "len", "(", "text", ")", ",", "len", "(", "text", ")", ")", "]", "\n", "assert", "len", "(", "offsets", ")", "==", "len", "(", "token_strings", ")", "\n", "return", "[", "Token", "(", "t", ",", "idx", "=", "o", ")", "for", "t", ",", "o", "in", "zip", "(", "token_strings", ",", "offsets", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._estimate_character_indices": [[75, 136], ["pretrained_transformer_tokenizer.sanitize_wordpiece", "len", "text.lower.lower.lower", "text.lower.lower.find", "sum", "pretrained_transformer_tokenizer.PretrainedTransformerTokenizer._tokenizer.convert_ids_to_tokens", "t.lower", "len", "len", "len", "len", "c.isspace"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.sanitize_wordpiece"], ["", "def", "_estimate_character_indices", "(", "\n", "self", ",", "text", ":", "str", ",", "token_ids", ":", "List", "[", "int", "]", "\n", ")", "->", "List", "[", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        The huggingface tokenizers produce tokens that may or may not be slices from the\n        original text.  Differences arise from lowercasing, Unicode normalization, and other\n        kinds of normalization, as well as special characters that are included to denote\n        various situations, such as \"##\" in BERT for word pieces from the middle of a word, or\n        \"\u0120\" in RoBERTa for the beginning of words not at the start of a sentence.\n\n        This code attempts to calculate character offsets while being tolerant to these\n        differences. It scans through the text and the tokens in parallel, trying to match up\n        positions in both. If it gets out of sync, it backs off to not adding any token\n        indices, and attempts to catch back up afterwards. This procedure is approximate.\n        Don't rely on precise results, especially in non-English languages that are far more\n        affected by Unicode normalization.\n        \"\"\"", "\n", "\n", "token_texts", "=", "[", "\n", "sanitize_wordpiece", "(", "t", ")", "for", "t", "in", "self", ".", "_tokenizer", ".", "convert_ids_to_tokens", "(", "token_ids", ")", "\n", "]", "\n", "token_offsets", ":", "List", "[", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", "=", "[", "None", "]", "*", "len", "(", "token_ids", ")", "\n", "if", "self", ".", "_tokenizer_lowercases", ":", "\n", "            ", "text", "=", "text", ".", "lower", "(", ")", "\n", "token_texts", "=", "[", "t", ".", "lower", "(", ")", "for", "t", "in", "token_texts", "]", "\n", "\n", "", "min_allowed_skipped_whitespace", "=", "3", "\n", "allowed_skipped_whitespace", "=", "min_allowed_skipped_whitespace", "\n", "\n", "text_index", "=", "0", "\n", "token_index", "=", "0", "\n", "while", "text_index", "<", "len", "(", "text", ")", "and", "token_index", "<", "len", "(", "token_ids", ")", ":", "\n", "            ", "token_text", "=", "token_texts", "[", "token_index", "]", "\n", "token_start_index", "=", "text", ".", "find", "(", "token_text", ",", "text_index", ")", "\n", "\n", "# Did we not find it at all?", "\n", "if", "token_start_index", "<", "0", ":", "\n", "                ", "token_index", "+=", "1", "\n", "# When we skip a token, we increase our tolerance, so we have a chance of catching back up.", "\n", "allowed_skipped_whitespace", "+=", "1", "+", "min_allowed_skipped_whitespace", "\n", "continue", "\n", "\n", "# Did we jump too far?", "\n", "", "non_whitespace_chars_skipped", "=", "sum", "(", "\n", "1", "for", "c", "in", "text", "[", "text_index", ":", "token_start_index", "]", "if", "not", "c", ".", "isspace", "(", ")", "\n", ")", "\n", "if", "non_whitespace_chars_skipped", ">", "allowed_skipped_whitespace", ":", "\n", "# Too many skipped characters. Something is wrong. Ignore this token.", "\n", "                ", "token_index", "+=", "1", "\n", "# When we skip a token, we increase our tolerance, so we have a chance of catching back up.", "\n", "allowed_skipped_whitespace", "+=", "1", "+", "min_allowed_skipped_whitespace", "\n", "continue", "\n", "", "allowed_skipped_whitespace", "=", "min_allowed_skipped_whitespace", "\n", "\n", "token_offsets", "[", "token_index", "]", "=", "(", "\n", "token_start_index", ",", "\n", "token_start_index", "+", "len", "(", "token_text", ")", ",", "\n", ")", "\n", "text_index", "=", "token_start_index", "+", "len", "(", "token_text", ")", "\n", "token_index", "+=", "1", "\n", "", "return", "token_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer._guess_start_and_end_token_defaults": [[137, 142], ["None"], "function", ["None"], ["", "", "def", "_guess_start_and_end_token_defaults", "(", "model_name", ":", "str", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "if", "'bert'", "in", "model_name", ":", "\n", "        ", "return", "(", "[", "'[CLS]'", "]", ",", "[", "'[SEP]'", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "[", "]", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.sanitize_wordpiece": [[143, 155], ["wordpiece.startswith", "wordpiece.startswith", "wordpiece.startswith"], "function", ["None"], ["", "", "def", "sanitize_wordpiece", "(", "wordpiece", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Sanitizes wordpieces from BERT, RoBERTa or ALBERT tokenizers.\n    \"\"\"", "\n", "if", "wordpiece", ".", "startswith", "(", "\"##\"", ")", ":", "\n", "        ", "return", "wordpiece", "[", "2", ":", "]", "\n", "", "elif", "wordpiece", ".", "startswith", "(", "\"\u0120\"", ")", ":", "\n", "        ", "return", "wordpiece", "[", "1", ":", "]", "\n", "", "elif", "wordpiece", ".", "startswith", "(", "\"\u2581\"", ")", ":", "\n", "        ", "return", "wordpiece", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "        ", "return", "wordpiece", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.__init__": [[713, 715], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.reset": [[716, 721], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.update": [[722, 727], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.parse_annotation": [[48, 74], ["xml.parse", "ET.parse.getroot", "list", "list", "list", "tree.getroot.iter", "int", "object.find().text.lower().strip", "object.find", "list.append", "list.append", "list.append", "int", "int", "int", "int", "object.find().text.lower", "object.find", "object.find.find", "object.find.find", "object.find.find", "object.find.find", "object.find"], "function", ["None"], ["def", "parse_annotation", "(", "annotation_path", ")", ":", "\n", "    ", "tree", "=", "ET", ".", "parse", "(", "annotation_path", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "\n", "boxes", "=", "list", "(", ")", "\n", "labels", "=", "list", "(", ")", "\n", "difficulties", "=", "list", "(", ")", "\n", "for", "object", "in", "root", ".", "iter", "(", "'object'", ")", ":", "\n", "\n", "        ", "difficult", "=", "int", "(", "object", ".", "find", "(", "'difficult'", ")", ".", "text", "==", "'1'", ")", "\n", "\n", "label", "=", "object", ".", "find", "(", "'name'", ")", ".", "text", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "if", "label", "not", "in", "label_map", ":", "\n", "            ", "continue", "\n", "\n", "", "bbox", "=", "object", ".", "find", "(", "'bndbox'", ")", "\n", "xmin", "=", "int", "(", "bbox", ".", "find", "(", "'xmin'", ")", ".", "text", ")", "-", "1", "\n", "ymin", "=", "int", "(", "bbox", ".", "find", "(", "'ymin'", ")", ".", "text", ")", "-", "1", "\n", "xmax", "=", "int", "(", "bbox", ".", "find", "(", "'xmax'", ")", ".", "text", ")", "-", "1", "\n", "ymax", "=", "int", "(", "bbox", ".", "find", "(", "'ymax'", ")", ".", "text", ")", "-", "1", "\n", "\n", "boxes", ".", "append", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "labels", ".", "append", "(", "label_map", "[", "label", "]", ")", "\n", "difficulties", ".", "append", "(", "difficult", ")", "\n", "\n", "", "return", "{", "'boxes'", ":", "boxes", ",", "'labels'", ":", "labels", ",", "'difficulties'", ":", "difficulties", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.create_data_lists": [[76, 148], ["os.path.abspath", "os.path.abspath", "list", "list", "print", "list", "list", "print", "len", "len", "open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "f.read().splitlines", "utils.parse_annotation", "list.append", "len", "list.append", "len", "len", "open", "json.dump", "open", "json.dump", "open", "f.read().splitlines", "utils.parse_annotation", "len", "list.append", "list.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.join", "len", "os.path.abspath", "f.read", "len", "os.path.abspath", "f.read"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.parse_annotation", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.parse_annotation"], ["", "def", "create_data_lists", "(", "voc07_path", ",", "voc12_path", ",", "output_folder", ")", ":", "\n", "    ", "\"\"\"\n    Create lists of images, the bounding boxes and labels of the objects in these images, and save these to file.\n\n    :param voc07_path: path to the 'VOC2007' folder\n    :param voc12_path: path to the 'VOC2012' folder\n    :param output_folder: folder where the JSONs must be saved\n    \"\"\"", "\n", "voc07_path", "=", "os", ".", "path", ".", "abspath", "(", "voc07_path", ")", "\n", "voc12_path", "=", "os", ".", "path", ".", "abspath", "(", "voc12_path", ")", "\n", "\n", "train_images", "=", "list", "(", ")", "\n", "train_objects", "=", "list", "(", ")", "\n", "n_objects", "=", "0", "\n", "\n", "# Training data", "\n", "for", "path", "in", "[", "voc07_path", ",", "voc12_path", "]", ":", "\n", "\n", "# Find IDs of images in training data", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'ImageSets/Main/trainval.txt'", ")", ")", "as", "f", ":", "\n", "            ", "ids", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "for", "id", "in", "ids", ":", "\n", "# Parse annotation's XML file", "\n", "            ", "objects", "=", "parse_annotation", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'Annotations'", ",", "id", "+", "'.xml'", ")", ")", "\n", "if", "len", "(", "objects", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "n_objects", "+=", "len", "(", "objects", ")", "\n", "train_objects", ".", "append", "(", "objects", ")", "\n", "train_images", ".", "append", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'JPEGImages'", ",", "id", "+", "'.jpg'", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "train_objects", ")", "==", "len", "(", "train_images", ")", "\n", "\n", "# Save to file", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "'TRAIN_images.json'", ")", ",", "'w'", ")", "as", "j", ":", "\n", "        ", "json", ".", "dump", "(", "train_images", ",", "j", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "'TRAIN_objects.json'", ")", ",", "'w'", ")", "as", "j", ":", "\n", "        ", "json", ".", "dump", "(", "train_objects", ",", "j", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "'label_map.json'", ")", ",", "'w'", ")", "as", "j", ":", "\n", "        ", "json", ".", "dump", "(", "label_map", ",", "j", ")", "# save label map too", "\n", "\n", "", "print", "(", "'\\nThere are %d training images containing a total of %d objects. Files have been saved to %s.'", "%", "(", "\n", "len", "(", "train_images", ")", ",", "n_objects", ",", "os", ".", "path", ".", "abspath", "(", "output_folder", ")", ")", ")", "\n", "\n", "# Test data", "\n", "test_images", "=", "list", "(", ")", "\n", "test_objects", "=", "list", "(", ")", "\n", "n_objects", "=", "0", "\n", "\n", "# Find IDs of images in the test data", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "voc07_path", ",", "'ImageSets/Main/test.txt'", ")", ")", "as", "f", ":", "\n", "        ", "ids", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "for", "id", "in", "ids", ":", "\n", "# Parse annotation's XML file", "\n", "        ", "objects", "=", "parse_annotation", "(", "os", ".", "path", ".", "join", "(", "voc07_path", ",", "'Annotations'", ",", "id", "+", "'.xml'", ")", ")", "\n", "if", "len", "(", "objects", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "test_objects", ".", "append", "(", "objects", ")", "\n", "n_objects", "+=", "len", "(", "objects", ")", "\n", "test_images", ".", "append", "(", "os", ".", "path", ".", "join", "(", "voc07_path", ",", "'JPEGImages'", ",", "id", "+", "'.jpg'", ")", ")", "\n", "\n", "", "assert", "len", "(", "test_objects", ")", "==", "len", "(", "test_images", ")", "\n", "\n", "# Save to file", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "'TEST_images.json'", ")", ",", "'w'", ")", "as", "j", ":", "\n", "        ", "json", ".", "dump", "(", "test_images", ",", "j", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_folder", ",", "'TEST_objects.json'", ")", ",", "'w'", ")", "as", "j", ":", "\n", "        ", "json", ".", "dump", "(", "test_objects", ",", "j", ")", "\n", "\n", "", "print", "(", "'\\nThere are %d test images containing a total of %d objects. Files have been saved to %s.'", "%", "(", "\n", "len", "(", "test_images", ")", ",", "n_objects", ",", "os", ".", "path", ".", "abspath", "(", "output_folder", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.decimate": [[150, 167], ["range", "tensor.index_select.dim", "len", "tensor.index_select.dim", "tensor.index_select.index_select", "torch.arange().long", "torch.arange", "tensor.index_select.size"], "function", ["None"], ["", "def", "decimate", "(", "tensor", ",", "m", ")", ":", "\n", "    ", "\"\"\"\n    Decimate a tensor by a factor 'm', i.e. downsample by keeping every 'm'th value.\n\n    This is used when we convert FC layers to equivalent Convolutional layers, BUT of a smaller size.\n\n    :param tensor: tensor to be decimated\n    :param m: list of decimation factors for each dimension of the tensor; None if not to be decimated along a dimension\n    :return: decimated tensor\n    \"\"\"", "\n", "assert", "tensor", ".", "dim", "(", ")", "==", "len", "(", "m", ")", "\n", "for", "d", "in", "range", "(", "tensor", ".", "dim", "(", ")", ")", ":", "\n", "        ", "if", "m", "[", "d", "]", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", ".", "index_select", "(", "dim", "=", "d", ",", "\n", "index", "=", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "tensor", ".", "size", "(", "d", ")", ",", "step", "=", "m", "[", "d", "]", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.calculate_mAP": [[169, 302], ["list", "range", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "list", "range", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "range", "torch.zeros.mean().item", "len", "len", "len", "len", "len", "len", "len", "torch.LongTensor().to.extend", "torch.LongTensor().to.size", "torch.cat.size", "torch.cat.size", "len", "torch.LongTensor().to.extend", "torch.LongTensor().to.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros().to", "det_class_boxes.size", "torch.sort", "torch.zeros().to", "torch.zeros().to", "range", "torch.cumsum", "torch.cumsum", "torch.arange().tolist", "torch.zeros().to", "enumerate", "torch.zeros().to.mean", "torch.LongTensor", "torch.LongTensor", "det_class_boxes[].unsqueeze", "utils.find_jaccard_overlap", "torch.max", "recalls_above_t.any", "torch.zeros.mean", "enumerate", "true_labels[].size", "det_labels[].size", "torch.zeros", "torch.zeros", "torch.zeros", "object_boxes.size", "find_jaccard_overlap.squeeze", "max_overlap.item", "torch.arange", "torch.zeros", "cumul_precision[].max", "torch.zeros.tolist", "true_class_difficulties.size", "torch.LongTensor", "len", "range", "true_class_boxes.size"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.find_jaccard_overlap", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "def", "calculate_mAP", "(", "det_boxes", ",", "det_labels", ",", "det_scores", ",", "true_boxes", ",", "true_labels", ",", "true_difficulties", ")", ":", "\n", "    ", "\"\"\"\n    Calculate the Mean Average Precision (mAP) of detected objects.\n\n    See https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173 for an explanation\n\n    :param det_boxes: list of tensors, one tensor for each image containing detected objects' bounding boxes\n    :param det_labels: list of tensors, one tensor for each image containing detected objects' labels\n    :param det_scores: list of tensors, one tensor for each image containing detected objects' labels' scores\n    :param true_boxes: list of tensors, one tensor for each image containing actual objects' bounding boxes\n    :param true_labels: list of tensors, one tensor for each image containing actual objects' labels\n    :param true_difficulties: list of tensors, one tensor for each image containing actual objects' difficulty (0 or 1)\n    :return: list of average precisions for all classes, mean average precision (mAP)\n    \"\"\"", "\n", "assert", "len", "(", "det_boxes", ")", "==", "len", "(", "det_labels", ")", "==", "len", "(", "det_scores", ")", "==", "len", "(", "true_boxes", ")", "==", "len", "(", "\n", "true_labels", ")", "==", "len", "(", "\n", "true_difficulties", ")", "# these are all lists of tensors of the same length, i.e. number of images", "\n", "n_classes", "=", "2", "# len(label_map)", "\n", "\n", "# Store all (true) objects in a single continuous tensor while keeping track of the image it is from", "\n", "true_images", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "true_labels", ")", ")", ":", "\n", "        ", "true_images", ".", "extend", "(", "[", "i", "]", "*", "true_labels", "[", "i", "]", ".", "size", "(", "0", ")", ")", "\n", "", "true_images", "=", "torch", ".", "LongTensor", "(", "true_images", ")", ".", "to", "(", "\n", "device", ")", "# (n_objects), n_objects is the total no. of objects across all images", "\n", "true_boxes", "=", "torch", ".", "cat", "(", "true_boxes", ",", "dim", "=", "0", ")", "# (n_objects, 4)", "\n", "true_labels", "=", "torch", ".", "cat", "(", "true_labels", ",", "dim", "=", "0", ")", "# (n_objects)", "\n", "true_difficulties", "=", "torch", ".", "cat", "(", "true_difficulties", ",", "dim", "=", "0", ")", "# (n_objects)", "\n", "\n", "assert", "true_images", ".", "size", "(", "0", ")", "==", "true_boxes", ".", "size", "(", "0", ")", "==", "true_labels", ".", "size", "(", "0", ")", "\n", "\n", "# Store all detections in a single continuous tensor while keeping track of the image it is from", "\n", "det_images", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "det_labels", ")", ")", ":", "\n", "        ", "det_images", ".", "extend", "(", "[", "i", "]", "*", "det_labels", "[", "i", "]", ".", "size", "(", "0", ")", ")", "\n", "", "det_images", "=", "torch", ".", "LongTensor", "(", "det_images", ")", ".", "to", "(", "device", ")", "# (n_detections)", "\n", "det_boxes", "=", "torch", ".", "cat", "(", "det_boxes", ",", "dim", "=", "0", ")", "# (n_detections, 4)", "\n", "det_labels", "=", "torch", ".", "cat", "(", "det_labels", ",", "dim", "=", "0", ")", "# (n_detections)", "\n", "det_scores", "=", "torch", ".", "cat", "(", "det_scores", ",", "dim", "=", "0", ")", "# (n_detections)", "\n", "\n", "assert", "det_images", ".", "size", "(", "0", ")", "==", "det_boxes", ".", "size", "(", "0", ")", "==", "det_labels", ".", "size", "(", "0", ")", "==", "det_scores", ".", "size", "(", "0", ")", "\n", "\n", "# Calculate APs for each class (except background)", "\n", "average_precisions", "=", "torch", ".", "zeros", "(", "(", "n_classes", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float", ")", "# (n_classes - 1)", "\n", "for", "c", "in", "range", "(", "1", ",", "n_classes", ")", ":", "\n", "# Extract only objects with this class", "\n", "        ", "true_class_images", "=", "true_images", "[", "true_labels", "==", "c", "]", "# (n_class_objects)", "\n", "true_class_boxes", "=", "true_boxes", "[", "true_labels", "==", "c", "]", "# (n_class_objects, 4)", "\n", "true_class_difficulties", "=", "true_difficulties", "[", "true_labels", "==", "c", "]", "# (n_class_objects)", "\n", "n_easy_class_objects", "=", "(", "1", "-", "true_class_difficulties", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "# ignore difficult objects", "\n", "\n", "# Keep track of which true objects with this class have already been 'detected'", "\n", "# So far, none", "\n", "true_class_boxes_detected", "=", "torch", ".", "zeros", "(", "(", "true_class_difficulties", ".", "size", "(", "0", ")", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "to", "(", "\n", "device", ")", "# (n_class_objects)", "\n", "\n", "# Extract only detections with this class", "\n", "det_class_images", "=", "det_images", "[", "det_labels", "==", "c", "]", "# (n_class_detections)", "\n", "det_class_boxes", "=", "det_boxes", "[", "det_labels", "==", "c", "]", "# (n_class_detections, 4)", "\n", "det_class_scores", "=", "det_scores", "[", "det_labels", "==", "c", "]", "# (n_class_detections)", "\n", "n_class_detections", "=", "det_class_boxes", ".", "size", "(", "0", ")", "\n", "if", "n_class_detections", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "# Sort detections in decreasing order of confidence/scores", "\n", "", "det_class_scores", ",", "sort_ind", "=", "torch", ".", "sort", "(", "det_class_scores", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "# (n_class_detections)", "\n", "det_class_images", "=", "det_class_images", "[", "sort_ind", "]", "# (n_class_detections)", "\n", "det_class_boxes", "=", "det_class_boxes", "[", "sort_ind", "]", "# (n_class_detections, 4)", "\n", "\n", "# In the order of decreasing scores, check if true or false positive", "\n", "true_positives", "=", "torch", ".", "zeros", "(", "(", "n_class_detections", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "# (n_class_detections)", "\n", "false_positives", "=", "torch", ".", "zeros", "(", "(", "n_class_detections", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "# (n_class_detections)", "\n", "for", "d", "in", "range", "(", "n_class_detections", ")", ":", "\n", "            ", "this_detection_box", "=", "det_class_boxes", "[", "d", "]", ".", "unsqueeze", "(", "0", ")", "# (1, 4)", "\n", "this_image", "=", "det_class_images", "[", "d", "]", "# (), scalar", "\n", "\n", "# Find objects in the same image with this class, their difficulties, and whether they have been detected before", "\n", "object_boxes", "=", "true_class_boxes", "[", "true_class_images", "==", "this_image", "]", "# (n_class_objects_in_img)", "\n", "object_difficulties", "=", "true_class_difficulties", "[", "true_class_images", "==", "this_image", "]", "# (n_class_objects_in_img)", "\n", "# If no such object in this image, then the detection is a false positive", "\n", "if", "object_boxes", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "                ", "false_positives", "[", "d", "]", "=", "1", "\n", "continue", "\n", "\n", "# Find maximum overlap of this detection with objects in this image of this class", "\n", "", "overlaps", "=", "find_jaccard_overlap", "(", "this_detection_box", ",", "object_boxes", ")", "# (1, n_class_objects_in_img)", "\n", "max_overlap", ",", "ind", "=", "torch", ".", "max", "(", "overlaps", ".", "squeeze", "(", "0", ")", ",", "dim", "=", "0", ")", "# (), () - scalars", "\n", "\n", "# 'ind' is the index of the object in these image-level tensors 'object_boxes', 'object_difficulties'", "\n", "# In the original class-level tensors 'true_class_boxes', etc., 'ind' corresponds to object with index...", "\n", "original_ind", "=", "torch", ".", "LongTensor", "(", "range", "(", "true_class_boxes", ".", "size", "(", "0", ")", ")", ")", "[", "true_class_images", "==", "this_image", "]", "[", "ind", "]", "\n", "# We need 'original_ind' to update 'true_class_boxes_detected'", "\n", "\n", "# If the maximum overlap is greater than the threshold of 0.5, it's a match", "\n", "if", "max_overlap", ".", "item", "(", ")", ">", "0.5", ":", "\n", "# If the object it matched with is 'difficult', ignore it", "\n", "                ", "if", "object_difficulties", "[", "ind", "]", "==", "0", ":", "\n", "# If this object has already not been detected, it's a true positive", "\n", "                    ", "if", "true_class_boxes_detected", "[", "original_ind", "]", "==", "0", ":", "\n", "                        ", "true_positives", "[", "d", "]", "=", "1", "\n", "true_class_boxes_detected", "[", "original_ind", "]", "=", "1", "# this object has now been detected/accounted for", "\n", "# Otherwise, it's a false positive (since this object is already accounted for)", "\n", "", "else", ":", "\n", "                        ", "false_positives", "[", "d", "]", "=", "1", "\n", "# Otherwise, the detection occurs in a different location than the actual object, and is a false positive", "\n", "", "", "", "else", ":", "\n", "                ", "false_positives", "[", "d", "]", "=", "1", "\n", "\n", "# Compute cumulative precision and recall at each detection in the order of decreasing scores", "\n", "", "", "cumul_true_positives", "=", "torch", ".", "cumsum", "(", "true_positives", ",", "dim", "=", "0", ")", "# (n_class_detections)", "\n", "cumul_false_positives", "=", "torch", ".", "cumsum", "(", "false_positives", ",", "dim", "=", "0", ")", "# (n_class_detections)", "\n", "cumul_precision", "=", "cumul_true_positives", "/", "(", "\n", "cumul_true_positives", "+", "cumul_false_positives", "+", "1e-10", ")", "# (n_class_detections)", "\n", "cumul_recall", "=", "cumul_true_positives", "/", "n_easy_class_objects", "# (n_class_detections)", "\n", "\n", "# Find the mean of the maximum of the precisions corresponding to recalls above the threshold 't'", "\n", "recall_thresholds", "=", "torch", ".", "arange", "(", "start", "=", "0", ",", "end", "=", "1.1", ",", "step", "=", ".1", ")", ".", "tolist", "(", ")", "# (11)", "\n", "precisions", "=", "torch", ".", "zeros", "(", "(", "len", "(", "recall_thresholds", ")", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "# (11)", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "recall_thresholds", ")", ":", "\n", "            ", "recalls_above_t", "=", "cumul_recall", ">=", "t", "\n", "if", "recalls_above_t", ".", "any", "(", ")", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "cumul_precision", "[", "recalls_above_t", "]", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "                ", "precisions", "[", "i", "]", "=", "0.", "\n", "", "", "average_precisions", "[", "c", "-", "1", "]", "=", "precisions", ".", "mean", "(", ")", "# c is in [1, n_classes - 1]", "\n", "\n", "# Calculate Mean Average Precision (mAP)", "\n", "", "mean_average_precision", "=", "average_precisions", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Keep class-wise average precisions in a dictionary", "\n", "average_precisions", "=", "{", "rev_label_map", "[", "c", "+", "1", "]", ":", "v", "for", "c", ",", "v", "in", "enumerate", "(", "average_precisions", ".", "tolist", "(", ")", ")", "}", "\n", "\n", "return", "average_precisions", ",", "mean_average_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.xy_to_cxcy": [[304, 313], ["torch.cat"], "function", ["None"], ["", "def", "xy_to_cxcy", "(", "xy", ")", ":", "\n", "    ", "\"\"\"\n    Convert bounding boxes from boundary coordinates (x_min, y_min, x_max, y_max) to center-size coordinates (c_x, c_y, w, h).\n\n    :param xy: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\n    :return: bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\n    \"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "(", "xy", "[", ":", ",", "2", ":", "]", "+", "xy", "[", ":", ",", ":", "2", "]", ")", "/", "2", ",", "# c_x, c_y", "\n", "xy", "[", ":", ",", "2", ":", "]", "-", "xy", "[", ":", ",", ":", "2", "]", "]", ",", "1", ")", "# w, h", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.cxcy_to_xy": [[315, 324], ["torch.cat"], "function", ["None"], ["", "def", "cxcy_to_xy", "(", "cxcy", ")", ":", "\n", "    ", "\"\"\"\n    Convert bounding boxes from center-size coordinates (c_x, c_y, w, h) to boundary coordinates (x_min, y_min, x_max, y_max).\n\n    :param cxcy: bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\n    :return: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\n    \"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "cxcy", "[", ":", ",", ":", "2", "]", "-", "(", "cxcy", "[", ":", ",", "2", ":", "]", "/", "2", ")", ",", "# x_min, y_min", "\n", "cxcy", "[", ":", ",", ":", "2", "]", "+", "(", "cxcy", "[", ":", ",", "2", ":", "]", "/", "2", ")", "]", ",", "1", ")", "# x_max, y_max", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.cxcy_to_gcxgcy": [[326, 345], ["torch.cat", "torch.log"], "function", ["None"], ["", "def", "cxcy_to_gcxgcy", "(", "cxcy", ",", "priors_cxcy", ")", ":", "\n", "    ", "\"\"\"\n    Encode bounding boxes (that are in center-size form) w.r.t. the corresponding prior boxes (that are in center-size form).\n\n    For the center coordinates, find the offset with respect to the prior box, and scale by the size of the prior box.\n    For the size coordinates, scale by the size of the prior box, and convert to the log-space.\n\n    In the model, we are predicting bounding box coordinates in this encoded form.\n\n    :param cxcy: bounding boxes in center-size coordinates, a tensor of size (n_priors, 4)\n    :param priors_cxcy: prior boxes with respect to which the encoding must be performed, a tensor of size (n_priors, 4)\n    :return: encoded bounding boxes, a tensor of size (n_priors, 4)\n    \"\"\"", "\n", "\n", "# The 10 and 5 below are referred to as 'variances' in the original Caffe repo, completely empirical", "\n", "# They are for some sort of numerical conditioning, for 'scaling the localization gradient'", "\n", "# See https://github.com/weiliu89/caffe/issues/155", "\n", "return", "torch", ".", "cat", "(", "[", "(", "cxcy", "[", ":", ",", ":", "2", "]", "-", "priors_cxcy", "[", ":", ",", ":", "2", "]", ")", "/", "(", "priors_cxcy", "[", ":", ",", "2", ":", "]", "/", "10", ")", ",", "# g_c_x, g_c_y", "\n", "torch", ".", "log", "(", "cxcy", "[", ":", ",", "2", ":", "]", "/", "priors_cxcy", "[", ":", ",", "2", ":", "]", ")", "*", "5", "]", ",", "1", ")", "# g_w, g_h", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.gcxgcy_to_cxcy": [[347, 362], ["torch.cat", "torch.exp"], "function", ["None"], ["", "def", "gcxgcy_to_cxcy", "(", "gcxgcy", ",", "priors_cxcy", ")", ":", "\n", "    ", "\"\"\"\n    Decode bounding box coordinates predicted by the model, since they are encoded in the form mentioned above.\n\n    They are decoded into center-size coordinates.\n\n    This is the inverse of the function above.\n\n    :param gcxgcy: encoded bounding boxes, i.e. output of the model, a tensor of size (n_priors, 4)\n    :param priors_cxcy: prior boxes with respect to which the encoding is defined, a tensor of size (n_priors, 4)\n    :return: decoded bounding boxes in center-size form, a tensor of size (n_priors, 4)\n    \"\"\"", "\n", "\n", "return", "torch", ".", "cat", "(", "[", "gcxgcy", "[", ":", ",", ":", "2", "]", "*", "priors_cxcy", "[", ":", ",", "2", ":", "]", "/", "10", "+", "priors_cxcy", "[", ":", ",", ":", "2", "]", ",", "# c_x, c_y", "\n", "torch", ".", "exp", "(", "gcxgcy", "[", ":", ",", "2", ":", "]", "/", "5", ")", "*", "priors_cxcy", "[", ":", ",", "2", ":", "]", "]", ",", "1", ")", "# w, h", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.find_intersection": [[364, 378], ["torch.max", "torch.min", "torch.clamp", "set_1[].unsqueeze", "set_2[].unsqueeze", "set_1[].unsqueeze", "set_2[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "def", "find_intersection", "(", "set_1", ",", "set_2", ")", ":", "\n", "    ", "\"\"\"\n    Find the intersection of every box combination between two sets of boxes that are in boundary coordinates.\n\n    :param set_1: set 1, a tensor of dimensions (n1, 4)\n    :param set_2: set 2, a tensor of dimensions (n2, 4)\n    :return: intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n    \"\"\"", "\n", "\n", "# PyTorch auto-broadcasts singleton dimensions", "\n", "lower_bounds", "=", "torch", ".", "max", "(", "set_1", "[", ":", ",", ":", "2", "]", ".", "unsqueeze", "(", "1", ")", ",", "set_2", "[", ":", ",", ":", "2", "]", ".", "unsqueeze", "(", "0", ")", ")", "# (n1, n2, 2)", "\n", "upper_bounds", "=", "torch", ".", "min", "(", "set_1", "[", ":", ",", "2", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "set_2", "[", ":", ",", "2", ":", "]", ".", "unsqueeze", "(", "0", ")", ")", "# (n1, n2, 2)", "\n", "intersection_dims", "=", "torch", ".", "clamp", "(", "upper_bounds", "-", "lower_bounds", ",", "min", "=", "0", ")", "# (n1, n2, 2)", "\n", "return", "intersection_dims", "[", ":", ",", ":", ",", "0", "]", "*", "intersection_dims", "[", ":", ",", ":", ",", "1", "]", "# (n1, n2)", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.find_jaccard_overlap": [[380, 401], ["utils.find_intersection", "areas_set_1.unsqueeze", "areas_set_2.unsqueeze"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.find_intersection"], ["", "def", "find_jaccard_overlap", "(", "set_1", ",", "set_2", ")", ":", "\n", "    ", "\"\"\"\n    Find the Jaccard Overlap (IoU) of every box combination between two sets of boxes that are in boundary coordinates.\n\n    :param set_1: set 1, a tensor of dimensions (n1, 4)\n    :param set_2: set 2, a tensor of dimensions (n2, 4)\n    :return: Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, a tensor of dimensions (n1, n2)\n    \"\"\"", "\n", "\n", "# Find intersections", "\n", "intersection", "=", "find_intersection", "(", "set_1", ",", "set_2", ")", "# (n1, n2)", "\n", "\n", "# Find areas of each box in both sets", "\n", "areas_set_1", "=", "(", "set_1", "[", ":", ",", "2", "]", "-", "set_1", "[", ":", ",", "0", "]", ")", "*", "(", "set_1", "[", ":", ",", "3", "]", "-", "set_1", "[", ":", ",", "1", "]", ")", "# (n1)", "\n", "areas_set_2", "=", "(", "set_2", "[", ":", ",", "2", "]", "-", "set_2", "[", ":", ",", "0", "]", ")", "*", "(", "set_2", "[", ":", ",", "3", "]", "-", "set_2", "[", ":", ",", "1", "]", ")", "# (n2)", "\n", "\n", "# Find the union", "\n", "# PyTorch auto-broadcasts singleton dimensions", "\n", "union", "=", "areas_set_1", ".", "unsqueeze", "(", "1", ")", "+", "areas_set_2", ".", "unsqueeze", "(", "0", ")", "-", "intersection", "# (n1, n2)", "\n", "\n", "return", "intersection", "/", "union", "# (n1, n2)", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.expand": [[406, 443], ["image.size", "image.size", "random.uniform", "int", "int", "torch.FloatTensor", "random.randint", "random.randint", "torch.ones", "torch.FloatTensor.unsqueeze().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor.unsqueeze", "torch.FloatTensor"], "function", ["None"], ["", "def", "expand", "(", "image", ",", "boxes", ",", "filler", ")", ":", "\n", "    ", "\"\"\"\n    Perform a zooming out operation by placing the image in a larger canvas of filler material.\n\n    Helps to learn to detect smaller objects.\n\n    :param image: image, a tensor of dimensions (3, original_h, original_w)\n    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)\n    :param filler: RBG values of the filler material, a list like [R, G, B]\n    :return: expanded image, updated bounding box coordinates\n    \"\"\"", "\n", "# Calculate dimensions of proposed expanded (zoomed-out) image", "\n", "original_h", "=", "image", ".", "size", "(", "1", ")", "\n", "original_w", "=", "image", ".", "size", "(", "2", ")", "\n", "max_scale", "=", "4", "\n", "scale", "=", "random", ".", "uniform", "(", "1", ",", "max_scale", ")", "\n", "new_h", "=", "int", "(", "scale", "*", "original_h", ")", "\n", "new_w", "=", "int", "(", "scale", "*", "original_w", ")", "\n", "\n", "# Create such an image with the filler", "\n", "filler", "=", "torch", ".", "FloatTensor", "(", "filler", ")", "# (3)", "\n", "new_image", "=", "torch", ".", "ones", "(", "(", "3", ",", "new_h", ",", "new_w", ")", ",", "dtype", "=", "torch", ".", "float", ")", "*", "filler", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "# (3, new_h, new_w)", "\n", "# Note - do not use expand() like new_image = filler.unsqueeze(1).unsqueeze(1).expand(3, new_h, new_w)", "\n", "# because all expanded values will share the same memory, so changing one pixel will change all", "\n", "\n", "# Place the original image at random coordinates in this new image (origin at top-left of image)", "\n", "left", "=", "random", ".", "randint", "(", "0", ",", "new_w", "-", "original_w", ")", "\n", "right", "=", "left", "+", "original_w", "\n", "top", "=", "random", ".", "randint", "(", "0", ",", "new_h", "-", "original_h", ")", "\n", "bottom", "=", "top", "+", "original_h", "\n", "new_image", "[", ":", ",", "top", ":", "bottom", ",", "left", ":", "right", "]", "=", "image", "\n", "\n", "# Adjust bounding boxes' coordinates accordingly", "\n", "new_boxes", "=", "boxes", "+", "torch", ".", "FloatTensor", "(", "[", "left", ",", "top", ",", "left", ",", "top", "]", ")", ".", "unsqueeze", "(", "\n", "0", ")", "# (n_objects, 4), n_objects is the no. of objects in this image", "\n", "\n", "return", "new_image", ",", "new_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.random_crop": [[445, 529], ["image.size", "image.size", "random.choice", "range", "random.uniform", "random.uniform", "int", "int", "random.randint", "random.randint", "torch.FloatTensor", "utils.find_jaccard_overlap", "overlap.squeeze.squeeze", "torch.max", "torch.min", "torch.FloatTensor.unsqueeze", "overlap.squeeze.max().item", "centers_in_crop.any", "overlap.squeeze.max"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.find_jaccard_overlap", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max"], ["", "def", "random_crop", "(", "image", ",", "boxes", ",", "labels", ",", "difficulties", ")", ":", "\n", "    ", "\"\"\"\n    Performs a random crop in the manner stated in the paper. Helps to learn to detect larger and partial objects.\n\n    Note that some objects may be cut out entirely.\n\n    Adapted from https://github.com/amdegroot/ssd.pytorch/blob/master/utils/augmentations.py\n\n    :param image: image, a tensor of dimensions (3, original_h, original_w)\n    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)\n    :param labels: labels of objects, a tensor of dimensions (n_objects)\n    :param difficulties: difficulties of detection of these objects, a tensor of dimensions (n_objects)\n    :return: cropped image, updated bounding box coordinates, updated labels, updated difficulties\n    \"\"\"", "\n", "original_h", "=", "image", ".", "size", "(", "1", ")", "\n", "original_w", "=", "image", ".", "size", "(", "2", ")", "\n", "# Keep choosing a minimum overlap until a successful crop is made", "\n", "while", "True", ":", "\n", "# Randomly draw the value for minimum overlap", "\n", "        ", "min_overlap", "=", "random", ".", "choice", "(", "[", "0.", ",", ".1", ",", ".3", ",", ".5", ",", ".7", ",", ".9", ",", "None", "]", ")", "# 'None' refers to no cropping", "\n", "\n", "# If not cropping", "\n", "if", "min_overlap", "is", "None", ":", "\n", "            ", "return", "image", ",", "boxes", ",", "labels", ",", "difficulties", "\n", "\n", "# Try up to 50 times for this choice of minimum overlap", "\n", "# This isn't mentioned in the paper, of course, but 50 is chosen in paper authors' original Caffe repo", "\n", "", "max_trials", "=", "50", "\n", "for", "_", "in", "range", "(", "max_trials", ")", ":", "\n", "# Crop dimensions must be in [0.3, 1] of original dimensions", "\n", "# Note - it's [0.1, 1] in the paper, but actually [0.3, 1] in the authors' repo", "\n", "            ", "min_scale", "=", "0.3", "\n", "scale_h", "=", "random", ".", "uniform", "(", "min_scale", ",", "1", ")", "\n", "scale_w", "=", "random", ".", "uniform", "(", "min_scale", ",", "1", ")", "\n", "new_h", "=", "int", "(", "scale_h", "*", "original_h", ")", "\n", "new_w", "=", "int", "(", "scale_w", "*", "original_w", ")", "\n", "\n", "# Aspect ratio has to be in [0.5, 2]", "\n", "aspect_ratio", "=", "new_h", "/", "new_w", "\n", "if", "not", "0.5", "<", "aspect_ratio", "<", "2", ":", "\n", "                ", "continue", "\n", "\n", "# Crop coordinates (origin at top-left of image)", "\n", "", "left", "=", "random", ".", "randint", "(", "0", ",", "original_w", "-", "new_w", ")", "\n", "right", "=", "left", "+", "new_w", "\n", "top", "=", "random", ".", "randint", "(", "0", ",", "original_h", "-", "new_h", ")", "\n", "bottom", "=", "top", "+", "new_h", "\n", "crop", "=", "torch", ".", "FloatTensor", "(", "[", "left", ",", "top", ",", "right", ",", "bottom", "]", ")", "# (4)", "\n", "\n", "# Calculate Jaccard overlap between the crop and the bounding boxes", "\n", "overlap", "=", "find_jaccard_overlap", "(", "crop", ".", "unsqueeze", "(", "0", ")", ",", "\n", "boxes", ")", "# (1, n_objects), n_objects is the no. of objects in this image", "\n", "overlap", "=", "overlap", ".", "squeeze", "(", "0", ")", "# (n_objects)", "\n", "\n", "# If not a single bounding box has a Jaccard overlap of greater than the minimum, try again", "\n", "if", "overlap", ".", "max", "(", ")", ".", "item", "(", ")", "<", "min_overlap", ":", "\n", "                ", "continue", "\n", "\n", "# Crop image", "\n", "", "new_image", "=", "image", "[", ":", ",", "top", ":", "bottom", ",", "left", ":", "right", "]", "# (3, new_h, new_w)", "\n", "\n", "# Find centers of original bounding boxes", "\n", "bb_centers", "=", "(", "boxes", "[", ":", ",", ":", "2", "]", "+", "boxes", "[", ":", ",", "2", ":", "]", ")", "/", "2.", "# (n_objects, 2)", "\n", "\n", "# Find bounding boxes whose centers are in the crop", "\n", "centers_in_crop", "=", "(", "bb_centers", "[", ":", ",", "0", "]", ">", "left", ")", "*", "(", "bb_centers", "[", ":", ",", "0", "]", "<", "right", ")", "*", "(", "bb_centers", "[", ":", ",", "1", "]", ">", "top", ")", "*", "(", "\n", "bb_centers", "[", ":", ",", "1", "]", "<", "bottom", ")", "# (n_objects), a Torch uInt8/Byte tensor, can be used as a boolean index", "\n", "\n", "# If not a single bounding box has its center in the crop, try again", "\n", "if", "not", "centers_in_crop", ".", "any", "(", ")", ":", "\n", "                ", "continue", "\n", "\n", "# Discard bounding boxes that don't meet this criterion", "\n", "", "new_boxes", "=", "boxes", "[", "centers_in_crop", ",", ":", "]", "\n", "new_labels", "=", "labels", "[", "centers_in_crop", "]", "\n", "new_difficulties", "=", "difficulties", "[", "centers_in_crop", "]", "\n", "\n", "# Calculate bounding boxes' new coordinates in the crop", "\n", "new_boxes", "[", ":", ",", ":", "2", "]", "=", "torch", ".", "max", "(", "new_boxes", "[", ":", ",", ":", "2", "]", ",", "crop", "[", ":", "2", "]", ")", "# crop[:2] is [left, top]", "\n", "new_boxes", "[", ":", ",", ":", "2", "]", "-=", "crop", "[", ":", "2", "]", "\n", "new_boxes", "[", ":", ",", "2", ":", "]", "=", "torch", ".", "min", "(", "new_boxes", "[", ":", ",", "2", ":", "]", ",", "crop", "[", "2", ":", "]", ")", "# crop[2:] is [right, bottom]", "\n", "new_boxes", "[", ":", ",", "2", ":", "]", "-=", "crop", "[", ":", "2", "]", "\n", "\n", "return", "new_image", ",", "new_boxes", ",", "new_labels", ",", "new_difficulties", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.flip": [[531, 549], ["torchvision.hflip"], "function", ["None"], ["", "", "", "def", "flip", "(", "image", ",", "boxes", ")", ":", "\n", "    ", "\"\"\"\n    Flip image horizontally.\n\n    :param image: image, a PIL Image\n    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)\n    :return: flipped image, updated bounding box coordinates\n    \"\"\"", "\n", "# Flip image", "\n", "new_image", "=", "FT", ".", "hflip", "(", "image", ")", "\n", "\n", "# Flip boxes", "\n", "new_boxes", "=", "boxes", "\n", "new_boxes", "[", ":", ",", "0", "]", "=", "image", ".", "width", "-", "boxes", "[", ":", ",", "0", "]", "-", "1", "\n", "new_boxes", "[", ":", ",", "2", "]", "=", "image", ".", "width", "-", "boxes", "[", ":", ",", "2", "]", "-", "1", "\n", "new_boxes", "=", "new_boxes", "[", ":", ",", "[", "2", ",", "1", ",", "0", ",", "3", "]", "]", "\n", "\n", "return", "new_image", ",", "new_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.resize": [[551, 574], ["torchvision.resize", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.resize"], ["", "def", "resize", "(", "image", ",", "boxes", ",", "dims", "=", "(", "300", ",", "300", ")", ",", "return_percent_coords", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Resize image. For the SSD300, resize to (300, 300).\n\n    Since percent/fractional coordinates are calculated for the bounding boxes (w.r.t image dimensions) in this process,\n    you may choose to retain them.\n\n    :param image: image, a PIL Image\n    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)\n    :return: resized image, updated bounding box coordinates (or fractional coordinates, in which case they remain the same)\n    \"\"\"", "\n", "# Resize image", "\n", "new_image", "=", "FT", ".", "resize", "(", "image", ",", "dims", ")", "\n", "\n", "# Resize bounding boxes", "\n", "old_dims", "=", "torch", ".", "FloatTensor", "(", "[", "image", ".", "width", ",", "image", ".", "height", ",", "image", ".", "width", ",", "image", ".", "height", "]", ")", ".", "unsqueeze", "(", "0", ")", "\n", "new_boxes", "=", "boxes", "/", "old_dims", "# percent coordinates", "\n", "\n", "if", "not", "return_percent_coords", ":", "\n", "        ", "new_dims", "=", "torch", ".", "FloatTensor", "(", "[", "dims", "[", "1", "]", ",", "dims", "[", "0", "]", ",", "dims", "[", "1", "]", ",", "dims", "[", "0", "]", "]", ")", ".", "unsqueeze", "(", "0", ")", "\n", "new_boxes", "=", "new_boxes", "*", "new_dims", "\n", "\n", "", "return", "new_image", ",", "new_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.photometric_distort": [[576, 605], ["random.shuffle", "random.random", "d", "random.uniform", "random.uniform"], "function", ["None"], ["", "def", "photometric_distort", "(", "image", ")", ":", "\n", "    ", "\"\"\"\n    Distort brightness, contrast, saturation, and hue, each with a 50% chance, in random order.\n\n    :param image: image, a PIL Image\n    :return: distorted image\n    \"\"\"", "\n", "new_image", "=", "image", "\n", "\n", "distortions", "=", "[", "FT", ".", "adjust_brightness", ",", "\n", "FT", ".", "adjust_contrast", ",", "\n", "FT", ".", "adjust_saturation", ",", "\n", "FT", ".", "adjust_hue", "]", "\n", "\n", "random", ".", "shuffle", "(", "distortions", ")", "\n", "\n", "for", "d", "in", "distortions", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "if", "d", ".", "__name__", "is", "'adjust_hue'", ":", "\n", "# Caffe repo uses a 'hue_delta' of 18 - we divide by 255 because PyTorch needs a normalized value", "\n", "                ", "adjust_factor", "=", "random", ".", "uniform", "(", "-", "18", "/", "255.", ",", "18", "/", "255.", ")", "\n", "", "else", ":", "\n", "# Caffe repo uses 'lower' and 'upper' values of 0.5 and 1.5 for brightness, contrast, and saturation", "\n", "                ", "adjust_factor", "=", "random", ".", "uniform", "(", "0.5", ",", "1.5", ")", "\n", "\n", "# Apply this distortion", "\n", "", "new_image", "=", "d", "(", "new_image", ",", "adjust_factor", ")", "\n", "\n", "", "", "return", "new_image", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.transform": [[607, 663], ["utils.resize", "torchvision.to_tensor", "torchvision.normalize", "utils.photometric_distort", "torchvision.to_tensor", "utils.random_crop", "torchvision.to_pil_image", "random.random", "utils.expand", "random.random", "utils.flip"], "function", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.resize", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.photometric_distort", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.random_crop", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.expand", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.flip"], ["", "def", "transform", "(", "image", ",", "boxes", ",", "labels", ",", "difficulties", ",", "split", ")", ":", "\n", "    ", "\"\"\"\n    Apply the transformations above.\n\n    :param image: image, a PIL Image\n    :param boxes: bounding boxes in boundary coordinates, a tensor of dimensions (n_objects, 4)\n    :param labels: labels of objects, a tensor of dimensions (n_objects)\n    :param difficulties: difficulties of detection of these objects, a tensor of dimensions (n_objects)\n    :param split: one of 'TRAIN' or 'TEST', since different sets of transformations are applied\n    :return: transformed image, transformed bounding box coordinates, transformed labels, transformed difficulties\n    \"\"\"", "\n", "assert", "split", "in", "{", "'TRAIN'", ",", "'TEST'", "}", "\n", "\n", "# Mean and standard deviation of ImageNet data that our base VGG from torchvision was trained on", "\n", "# see: https://pytorch.org/docs/stable/torchvision/models.html", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n", "new_image", "=", "image", "\n", "new_boxes", "=", "boxes", "\n", "new_labels", "=", "labels", "\n", "new_difficulties", "=", "difficulties", "\n", "# Skip the following operations for evaluation/testing", "\n", "if", "split", "==", "'TRAIN'", ":", "\n", "# A series of photometric distortions in random order, each with 50% chance of occurrence, as in Caffe repo", "\n", "        ", "new_image", "=", "photometric_distort", "(", "new_image", ")", "\n", "\n", "# Convert PIL image to Torch tensor", "\n", "new_image", "=", "FT", ".", "to_tensor", "(", "new_image", ")", "\n", "\n", "# Expand image (zoom out) with a 50% chance - helpful for training detection of small objects", "\n", "# Fill surrounding space with the mean of ImageNet data that our base VGG was trained on", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "new_image", ",", "new_boxes", "=", "expand", "(", "new_image", ",", "boxes", ",", "filler", "=", "mean", ")", "\n", "\n", "# Randomly crop image (zoom in)", "\n", "", "new_image", ",", "new_boxes", ",", "new_labels", ",", "new_difficulties", "=", "random_crop", "(", "new_image", ",", "new_boxes", ",", "new_labels", ",", "\n", "new_difficulties", ")", "\n", "\n", "# Convert Torch tensor to PIL image", "\n", "new_image", "=", "FT", ".", "to_pil_image", "(", "new_image", ")", "\n", "\n", "# Flip image with a 50% chance", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "new_image", ",", "new_boxes", "=", "flip", "(", "new_image", ",", "new_boxes", ")", "\n", "\n", "# Resize image to (300, 300) - this also converts absolute boundary coordinates to their fractional form", "\n", "", "", "new_image", ",", "new_boxes", "=", "resize", "(", "new_image", ",", "new_boxes", ",", "dims", "=", "(", "300", ",", "300", ")", ")", "\n", "\n", "# Convert PIL image to Torch tensor", "\n", "new_image", "=", "FT", ".", "to_tensor", "(", "new_image", ")", "\n", "\n", "# Normalize by mean and standard deviation of ImageNet data that our base VGG was trained on", "\n", "new_image", "=", "FT", ".", "normalize", "(", "new_image", ",", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "\n", "return", "new_image", ",", "new_boxes", ",", "new_labels", ",", "new_difficulties", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.adjust_learning_rate": [[665, 675], ["print"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "scale", ")", ":", "\n", "    ", "\"\"\"\n    Scale learning rate by a specified factor.\n\n    :param optimizer: optimizer whose learning rate must be shrunk.\n    :param scale: factor to multiply learning rate with.\n    \"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "*", "scale", "\n", "", "print", "(", "\"DECAYING learning rate.\\n The new LR is %f\\n\"", "%", "(", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.accuracy": [[677, 691], ["targets.size", "scores.topk", "ind.eq", "ind.eq.view().float().sum", "targets.view().expand_as", "correct.view().float().sum.item", "ind.eq.view().float", "targets.view", "ind.eq.view"], "function", ["None"], ["", "def", "accuracy", "(", "scores", ",", "targets", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Computes top-k accuracy, from predicted and true labels.\n\n    :param scores: scores from the model\n    :param targets: true labels\n    :param k: k in top-k accuracy\n    :return: top-k accuracy\n    \"\"\"", "\n", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "_", ",", "ind", "=", "scores", ".", "topk", "(", "k", ",", "1", ",", "True", ",", "True", ")", "\n", "correct", "=", "ind", ".", "eq", "(", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "ind", ")", ")", "\n", "correct_total", "=", "correct", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "# 0D tensor", "\n", "return", "correct_total", ".", "item", "(", ")", "*", "(", "100.0", "/", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.save_checkpoint": [[693, 706], ["torch.save"], "function", ["None"], ["", "def", "save_checkpoint", "(", "epoch", ",", "model", ",", "optimizer", ")", ":", "\n", "    ", "\"\"\"\n    Save model checkpoint.\n\n    :param epoch: epoch number\n    :param model: model\n    :param optimizer: optimizer\n    \"\"\"", "\n", "state", "=", "{", "'epoch'", ":", "epoch", ",", "\n", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", "}", "\n", "filename", "=", "'checkpoint_ssd300.pth.tar'", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.clip_gradient": [[729, 740], ["param.grad.data.clamp_"], "function", ["None"], ["", "", "def", "clip_gradient", "(", "optimizer", ",", "grad_clip", ")", ":", "\n", "    ", "\"\"\"\n    Clips gradients computed during backpropagation to avoid explosion of gradients.\n\n    :param optimizer: optimizer with the gradients to be clipped\n    :param grad_clip: clip value\n    \"\"\"", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "for", "param", "in", "group", "[", "'params'", "]", ":", "\n", "            ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "param", ".", "grad", ".", "data", ".", "clamp_", "(", "-", "grad_clip", ",", "grad_clip", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_detector.ObjectDetector.__init__": [[16, 29], ["allennlp.models.Model.__init__", "torchvision.models.detection.fasterrcnn_resnet50_fpn", "pycocotools.coco.COCO", "torch.device"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "detection", ".", "fasterrcnn_resnet50_fpn", "(", "pretrained_backbone", "=", "True", ",", "num_classes", "=", "2", ")", "\n", "self", ".", "predicted_boxes", "=", "[", "]", "\n", "self", ".", "predicted_labels", "=", "[", "]", "\n", "self", ".", "predicted_scores", "=", "[", "]", "\n", "self", ".", "true_boxes", "=", "[", "]", "\n", "self", ".", "true_labels", "=", "[", "]", "\n", "self", ".", "true_difficulties", "=", "[", "]", "\n", "self", ".", "coco_ds", "=", "COCO", "(", ")", "\n", "self", ".", "dataset", "=", "{", "'images'", ":", "[", "]", ",", "'categories'", ":", "[", "{", "'id'", ":", "0", "}", ",", "{", "'id'", ":", "1", "}", "]", ",", "'annotations'", ":", "[", "]", "}", "\n", "self", ".", "outputs", "=", "{", "}", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_detector.ObjectDetector.forward": [[30, 87], ["range", "object_detector.ObjectDetector.model", "sys.stdout.flush", "zip", "print", "range", "len", "targets.append", "sum", "predictions.append", "print", "torch.ones_like", "torch.zeros_like().long().to", "len", "len", "object_detector.ObjectDetector.dataset[].append", "range", "torch.tensor().to", "range", "[].long", "range", "range", "ann[].tolist", "len", "object_detector.ObjectDetector.dataset[].append", "v.to", "torch.tensor().long().view().repeat().to", "object_detector.ObjectDetector.model", "len", "torch.zeros_like().long", "len", "predictions[].items", "torch.tensor", "object_detector.ObjectDetector.values", "torch.tensor().long().view().repeat", "torch.isnan().item", "torch.zeros_like", "torch.tensor().long().view", "torch.isnan", "torch.tensor().long", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "boxes", ":", "torch", ".", "Tensor", "=", "None", ",", "num_boxes", ":", "List", "[", "int", "]", "=", "None", ",", "image_ids", ":", "List", "[", "str", "]", "=", "None", ",", "widths", ":", "List", "[", "int", "]", "=", "None", ",", "heights", ":", "List", "[", "int", "]", "=", "None", ")", ":", "\n", "# print(images.shape)", "\n", "# image_list = [images[i] for i in range(images.shape[0])]", "\n", "        ", "image_list", "=", "images", "\n", "# image_list = list(image for image in images)", "\n", "if", "self", ".", "training", ":", "\n", "            ", "targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "                ", "targets", ".", "append", "(", "{", "'boxes'", ":", "boxes", "[", "i", ",", ":", "num_boxes", "[", "i", "]", ",", ":", "]", ",", "'labels'", ":", "torch", ".", "tensor", "(", "1", ")", ".", "long", "(", ")", ".", "view", "(", "1", ")", ".", "repeat", "(", "num_boxes", "[", "i", "]", ")", ".", "to", "(", "boxes", ".", "device", ")", "}", ")", "\n", "", "loss_dict", "=", "self", ".", "model", "(", "image_list", ",", "targets", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "outputs", "=", "{", "'loss'", ":", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", "if", "not", "torch", ".", "isnan", "(", "loss", ")", ".", "item", "(", ")", ")", "}", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "[", "]", "\n", "for", "image", ",", "image_id", ",", "h", ",", "w", "in", "zip", "(", "image_list", ",", "image_ids", ",", "heights", ",", "widths", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "self", ".", "model", "(", "[", "image", "]", ")", "[", "0", "]", ")", "\n", "print", "(", "image_id", ",", "predictions", "[", "-", "1", "]", ")", "\n", "# predictions = self.model(image_list)", "\n", "# predictions = [{k: v.to(cpu_device) for k, v in t.items()} for t in predictions]", "\n", "", "predicted_boxes", "=", "[", "pred", "[", "'boxes'", "]", "for", "pred", "in", "predictions", "]", "\n", "predicted_labels", "=", "[", "pred", "[", "'labels'", "]", "for", "pred", "in", "predictions", "]", "\n", "predicted_scores", "=", "[", "pred", "[", "'scores'", "]", "for", "pred", "in", "predictions", "]", "\n", "\"\"\"threshold_masks = [scores > 0.7 for scores in predicted_scores]\n            predicted_boxes = [pred[mask,:] for mask, pred in zip(threshold_masks, predicted_boxes)]\n            predicted_labels = [pred[mask] for mask, pred in zip(threshold_masks, predicted_labels)]\n            predicted_scores = [pred[mask] for mask, pred in zip(threshold_masks, predicted_scores)]\"\"\"", "\n", "# predictions = [{'boxes': b, 'labels': l, 'scores': s} for b, l, s in zip(predicted_boxes, predicted_labels, predicted_scores)]", "\n", "print", "(", "[", "b", ".", "shape", "for", "b", "in", "predicted_boxes", "]", ")", "\n", "true_boxes", "=", "[", "boxes", "[", "i", ",", ":", "num_boxes", "[", "i", "]", ",", ":", "]", "for", "i", "in", "range", "(", "boxes", ".", "shape", "[", "0", "]", ")", "]", "\n", "true_labels", "=", "[", "torch", ".", "ones_like", "(", "true_boxes", "[", "i", "]", "[", ":", ",", "0", "]", ".", "long", "(", ")", ")", "for", "i", "in", "range", "(", "len", "(", "true_boxes", ")", ")", "]", "\n", "true_difficulties", "=", "[", "torch", ".", "zeros_like", "(", "true_boxes", "[", "i", "]", "[", ":", ",", "0", "]", ")", ".", "long", "(", ")", ".", "to", "(", "boxes", ".", "device", ")", "for", "i", "in", "range", "(", "len", "(", "true_boxes", ")", ")", "]", "\n", "self", ".", "predicted_boxes", "+=", "predicted_boxes", "\n", "self", ".", "predicted_labels", "+=", "predicted_labels", "\n", "self", ".", "predicted_scores", "+=", "predicted_scores", "\n", "self", ".", "true_boxes", "+=", "true_boxes", "\n", "self", ".", "true_labels", "+=", "true_labels", "\n", "self", ".", "true_difficulties", "+=", "true_difficulties", "\n", "for", "i", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "                ", "img_dict", "=", "{", "}", "\n", "img_dict", "[", "'id'", "]", "=", "len", "(", "self", ".", "dataset", "[", "'images'", "]", ")", "\n", "img_dict", "[", "'height'", "]", "=", "heights", "[", "i", "]", "\n", "img_dict", "[", "'width'", "]", "=", "widths", "[", "i", "]", "\n", "self", ".", "dataset", "[", "'images'", "]", ".", "append", "(", "img_dict", ")", "\n", "for", "j", "in", "range", "(", "num_boxes", "[", "i", "]", ")", ":", "\n", "                    ", "ann", "=", "{", "}", "\n", "ann", "[", "'image_id'", "]", "=", "img_dict", "[", "'id'", "]", "\n", "ann", "[", "'bbox'", "]", "=", "boxes", "[", "i", ",", "j", "]", "\n", "ann", "[", "'bbox'", "]", "[", "2", ":", "]", "-=", "ann", "[", "'bbox'", "]", "[", ":", "2", "]", "\n", "ann", "[", "'bbox'", "]", "=", "ann", "[", "'bbox'", "]", ".", "tolist", "(", ")", "\n", "ann", "[", "'category_id'", "]", "=", "1", "\n", "ann", "[", "'area'", "]", "=", "(", "ann", "[", "'bbox'", "]", "[", "2", "]", "-", "ann", "[", "'bbox'", "]", "[", "0", "]", ")", "*", "(", "ann", "[", "'bbox'", "]", "[", "3", "]", "-", "ann", "[", "'bbox'", "]", "[", "1", "]", ")", "\n", "ann", "[", "'id'", "]", "=", "len", "(", "self", ".", "dataset", "[", "'annotations'", "]", ")", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "self", ".", "dataset", "[", "'annotations'", "]", ".", "append", "(", "ann", ")", "\n", "", "self", ".", "outputs", "[", "img_dict", "[", "'id'", "]", "]", "=", "{", "k", ":", "v", ".", "to", "(", "self", ".", "cpu_device", ")", "for", "k", ",", "v", "in", "predictions", "[", "i", "]", ".", "items", "(", ")", "}", "\n", "", "outputs", "=", "{", "'predictions'", ":", "predictions", ",", "'loss'", ":", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "boxes", ".", "device", ")", ",", "'gold'", ":", "boxes", ",", "'gold_num_boxes'", ":", "num_boxes", ",", "'image_id'", ":", "image_ids", "}", "\n", "", "return", "outputs", "\n", "", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.object_detector.ObjectDetector.get_metrics": [[87, 112], ["pycocotools.coco.COCO", "object_detector.ObjectDetector.coco_ds.createIndex", "subcaption.coco_eval.CocoEvaluator", "subcaption.coco_eval.CocoEvaluator.update", "subcaption.coco_eval.CocoEvaluator.synchronize_between_processes", "subcaption.coco_eval.CocoEvaluator.accumulate", "subcaption.coco_eval.CocoEvaluator.summarize"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.createIndex", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.AverageMeter.update", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.MetricLogger.synchronize_between_processes", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.accumulate", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.coco_eval.CocoEvaluator.summarize"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "if", "not", "self", ".", "training", ":", "\n", "# average_precisions, mAP = calculate_mAP(self.predicted_boxes, self.predicted_labels, self.predicted_scores, self.true_boxes, self.true_labels, self.true_difficulties)", "\n", "            ", "self", ".", "coco_ds", "=", "COCO", "(", ")", "\n", "self", ".", "coco_ds", ".", "dataset", "=", "self", ".", "dataset", "\n", "self", ".", "coco_ds", ".", "createIndex", "(", ")", "\n", "coco_evaluator", "=", "CocoEvaluator", "(", "self", ".", "coco_ds", ",", "[", "'bbox'", "]", ")", "\n", "coco_evaluator", ".", "update", "(", "self", ".", "outputs", ")", "\n", "coco_evaluator", ".", "synchronize_between_processes", "(", ")", "\n", "coco_evaluator", ".", "accumulate", "(", ")", "\n", "coco_evaluator", ".", "summarize", "(", ")", "\n", "stats", "=", "coco_evaluator", ".", "coco_eval", "[", "'bbox'", "]", ".", "stats", "\n", "mAP", "=", "stats", "[", "0", "]", "\n", "metrics", "=", "{", "'mAP'", ":", "mAP", ",", "'mAp@0.5'", ":", "stats", "[", "1", "]", "}", "\n", "if", "reset", ":", "\n", "                ", "self", ".", "predicted_boxes", "=", "[", "]", "\n", "self", ".", "predicted_labels", "=", "[", "]", "\n", "self", ".", "predicted_scores", "=", "[", "]", "\n", "self", ".", "true_boxes", "=", "[", "]", "\n", "self", ".", "true_labels", "=", "[", "]", "\n", "self", ".", "true_difficulties", "=", "[", "]", "\n", "self", ".", "dataset", "=", "{", "'images'", ":", "[", "]", ",", "'categories'", ":", "[", "{", "'id'", ":", "0", "}", ",", "{", "'id'", ":", "1", "}", "]", ",", "'annotations'", ":", "[", "]", "}", "\n", "self", ".", "outputs", "=", "{", "}", "\n", "", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.__init__": [[13, 19], ["allennlp.modules.token_embedders.token_embedder.TokenEmbedder.__init__", "transformers.AutoModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["def", "__init__", "(", "self", ",", "model_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transformer_model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "# I'm not sure if this works for all models; open an issue on github if you find a case", "\n", "# where it doesn't work.", "\n", "self", ".", "output_dim", "=", "self", ".", "transformer_model", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.get_output_dim": [[20, 23], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_embedder.PretrainedTransformerEmbedder.forward": [[24, 27], ["pretrained_transformer_embedder.PretrainedTransformerEmbedder.transformer_model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_ids", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "Tensor", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "return", "self", ".", "transformer_model", "(", "token_ids", ",", "attention_mask", "=", "(", "token_ids", "!=", "0", ")", ")", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.predictor.FigurePredictor.__init__": [[11, 13], ["allennlp.predictors.predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.predictor.FigurePredictor.predict_instance": [[14, 18], ["predictor.FigurePredictor._model.forward_on_instance", "allennlp.common.util.sanitize"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "predict_instance", "(", "self", ",", "instance", ":", "Instance", ")", "->", "JsonDict", ":", "\n", "        ", "outputs", "=", "self", ".", "_model", ".", "forward_on_instance", "(", "instance", ")", "\n", "return", "sanitize", "(", "outputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.model.ImageClassifier.__init__": [[12, 42], ["allennlp.models.model.Model.__init__", "torch.nn.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.F1Measure", "torchvision.models.resnet101", "torch.nn.Sequential", "torchvision.models.vgg16", "list", "list.pop", "list.append", "torch.nn.Sequential", "model.ImageClassifier.vocab.get_token_index", "torch.nn.Dropout", "torch.nn.Linear", "model.ImageClassifier.model.classifier.children", "torch.nn.Linear", "model.ImageClassifier.vocab.get_vocab_size", "model.ImageClassifier.vocab.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "backbone", ":", "str", ",", "\n", "dropout_prob", ":", "float", "=", "0.3", ",", "\n", "pretrained", ":", "bool", "=", "True", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_dropout_prob", "=", "dropout_prob", "\n", "if", "backbone", "==", "'resnet101'", ":", "\n", "            ", "self", ".", "model", "=", "torchvision", ".", "models", ".", "resnet101", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "feature_dim", "=", "2048", "\n", "self", ".", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "_dropout_prob", ",", "inplace", "=", "False", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "vocab", ".", "get_vocab_size", "(", "self", ".", "_label_namespace", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "backbone", "==", "'vgg16'", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "backbone_classifier", "=", "list", "(", "self", ".", "model", ".", "classifier", ".", "children", "(", ")", ")", "\n", "backbone_classifier", ".", "pop", "(", ")", "\n", "self", ".", "feature_dim", "=", "4096", "\n", "backbone_classifier", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "vocab", ".", "get_vocab_size", "(", "self", ".", "_label_namespace", ")", ")", ")", "\n", "self", ".", "model", ".", "classifier", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "backbone_classifier", ")", "\n", "self", ".", "_dropout_prob", "=", "0.0", "\n", "\n", "", "self", ".", "loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "f1", "=", "F1Measure", "(", "self", ".", "vocab", ".", "get_token_index", "(", "'Medical images'", ",", "self", ".", "_label_namespace", ")", ")", "\n", "", "def", "forward", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.model.ImageClassifier.forward": [[42, 55], ["model.ImageClassifier.model", "model.ImageClassifier.loss", "model.ImageClassifier.f1", "model.ImageClassifier.accuracy"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.accuracy"], ["", "def", "forward", "(", "self", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "image_id", ":", "List", "[", "str", "]", ",", "\n", "label", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "predictions", "=", "self", ".", "model", "(", "image", ")", "\n", "\n", "outputs", "=", "{", "'predictions'", ":", "predictions", ",", "'image_id'", ":", "image_id", "}", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "loss", "(", "predictions", ",", "label", ")", "\n", "outputs", "[", "'loss'", "]", "=", "loss", "\n", "self", ".", "f1", "(", "predictions", ",", "label", ")", "\n", "self", ".", "accuracy", "(", "predictions", ",", "label", ")", "\n", "", "return", "outputs", "\n", "", "def", "get_metrics", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.model.ImageClassifier.get_metrics": [[55, 62], ["model.ImageClassifier.f1.get_metric", "model.ImageClassifier.accuracy.get_metric"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "\n", "reset", ":", "bool", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "precision", ",", "recall", ",", "f1", "=", "self", ".", "f1", ".", "get_metric", "(", "reset", ")", "\n", "return", "{", "'medical_f1'", ":", "f1", ",", "\n", "'medical_precision'", ":", "precision", ",", "\n", "'medical_recall'", ":", "recall", ",", "\n", "'accuracy'", ":", "self", ".", "accuracy", ".", "get_metric", "(", "reset", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.dataset_reader.DocFigureDatasetReader.__init__": [[15, 26], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "image_root", ":", "str", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "image_root", "=", "image_root", "\n", "expected_img_size", "=", "224", "\n", "self", ".", "image_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "expected_img_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "expected_img_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.dataset_reader.DocFigureDatasetReader._read": [[27, 48], ["open", "open.readlines", "enumerate", "enumerate", "json.loads", "line.split", "parts[].strip", "parts[].strip", "dataset_reader.DocFigureDatasetReader.text_to_instance", "dataset_reader.DocFigureDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance", "home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "input_file", "=", "open", "(", "file_path", ")", "\n", "lines", "=", "input_file", ".", "readlines", "(", ")", "\n", "if", "'json'", "in", "file_path", ":", "\n", "            ", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "for", "i", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "image_id", "=", "datum", "[", "'pdf_hash'", "]", "+", "'_'", "+", "datum", "[", "'fig_uri'", "]", "\n", "label", "=", "\"\"", "\n", "image_root", "=", "self", ".", "image_root", "\n", "if", "'image_root'", "in", "datum", "and", "datum", "[", "'image_root'", "]", "is", "not", "None", ":", "\n", "                    ", "image_root", "=", "datum", "[", "'image_root'", "]", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "image_id", "=", "image_id", ",", "label", "=", "label", ",", "image_root", "=", "image_root", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                        ", "yield", "instance", "\n", "", "", "", "", "else", ":", "\n", "            ", "for", "index", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "parts", "=", "line", ".", "split", "(", "', '", ")", "\n", "image_id", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "label", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "yield", "self", ".", "text_to_instance", "(", "image_id", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.figure_classifier.dataset_reader.DocFigureDatasetReader.text_to_instance": [[49, 65], ["allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "PIL.Image.open().convert", "dataset_reader.DocFigureDatasetReader.image_transform().numpy", "len", "allennlp.data.fields.LabelField", "PIL.Image.open", "dataset_reader.DocFigureDatasetReader.image_transform", "os.path.join"], "methods", ["None"], ["", "", "", "def", "text_to_instance", "(", "self", ",", "\n", "image_id", ":", "str", ",", "\n", "label", ":", "str", ",", "\n", "image_root", ":", "str", "=", "None", ")", "->", "Instance", ":", "\n", "        ", "if", "image_root", "is", "None", ":", "\n", "            ", "image_root", "=", "self", ".", "image_root", "\n", "", "try", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "image_root", ",", "image_id", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "except", ":", "\n", "            ", "return", "None", "\n", "", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "fields", "[", "'image'", "]", "=", "ArrayField", "(", "self", ".", "image_transform", "(", "image", ")", ".", "numpy", "(", ")", ")", "\n", "if", "len", "(", "label", ")", ">", "0", ":", "\n", "            ", "fields", "[", "'label'", "]", "=", "LabelField", "(", "label", ")", "\n", "", "fields", "[", "'image_id'", "]", "=", "MetadataField", "(", "image_id", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.predictor.GenericPredictor.__init__": [[11, 13], ["allennlp.predictors.predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.predictor.GenericPredictor.predict_instance": [[14, 18], ["predictor.GenericPredictor._model.forward_on_instance", "allennlp.common.util.sanitize"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "predict_instance", "(", "self", ",", "instance", ":", "Instance", ")", "->", "JsonDict", ":", "\n", "        ", "outputs", "=", "self", ".", "_model", ".", "forward_on_instance", "(", "instance", ")", "\n", "return", "sanitize", "(", "outputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.__init__": [[39, 50], ["super().__init__", "transformers.BertTokenizer", "logger.info", "token_indexer.BertFromConfigIndexer.tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["def", "__init__", "(", "self", ",", "\n", "config", ":", "BertConfig", ",", "\n", "vocab_path", ":", "str", ",", "\n", "namespace", ":", "str", "=", "\"tags\"", ",", "\n", "token_min_padding_length", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "token_min_padding_length", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", "(", "config", "=", "config", ",", "vocab_file", "=", "vocab_path", ")", "\n", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_added_to_vocabulary", "=", "False", "\n", "self", ".", "_padding_value", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "self", ".", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", "\n", "logger", ".", "info", "(", "f\"Using token indexer padding value of {self._padding_value}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.count_vocab_items": [[51, 55], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If we only use pretrained models, we don't need to do anything here.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer._add_encoding_to_vocabulary": [[56, 61], ["token_indexer.BertFromConfigIndexer.tokenizer.vocab.items"], "methods", ["None"], ["", "def", "_add_encoding_to_vocabulary", "(", "self", ",", "vocabulary", ":", "Vocabulary", ")", "->", "None", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "for", "word", ",", "idx", "in", "self", ".", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "            ", "vocabulary", ".", "_token_to_index", "[", "self", ".", "_namespace", "]", "[", "word", "]", "=", "idx", "\n", "vocabulary", ".", "_index_to_token", "[", "self", ".", "_namespace", "]", "[", "idx", "]", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.tokens_to_indices": [[62, 74], ["token_indexer.BertFromConfigIndexer.tokenizer.convert_tokens_to_ids", "hasattr", "token_indexer.BertFromConfigIndexer._add_encoding_to_vocabulary"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer._add_encoding_to_vocabulary"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_added_to_vocabulary", "and", "hasattr", "(", "self", ".", "tokenizer", ",", "\"vocab\"", ")", ":", "\n", "            ", "self", ".", "_add_encoding_to_vocabulary", "(", "vocabulary", ")", "\n", "self", ".", "_added_to_vocabulary", "=", "True", "\n", "", "token_text", "=", "[", "token", ".", "text", "for", "token", "in", "tokens", "]", "\n", "indices", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "token_text", ")", "\n", "\n", "return", "{", "index_name", ":", "indices", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.get_padding_lengths": [[75, 78], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.as_padded_tensor": [[79, 88], ["torch.LongTensor", "allennlp.common.util.pad_sequence_to_length", "tokens.items"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_padded_tensor", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "key", ":", "torch", ".", "LongTensor", "(", "pad_sequence_to_length", "(", "val", ",", "\n", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "lambda", ":", "self", ".", "_padding_value", ")", ")", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.__eq__": [[89, 100], ["isinstance"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "isinstance", "(", "other", ",", "PretrainedTransformerIndexer", ")", ":", "\n", "            ", "for", "key", "in", "self", ".", "__dict__", ":", "\n", "                ", "if", "key", "==", "'tokenizer'", ":", "\n", "# This is a reference to a function in the huggingface code, which we can't", "\n", "# really modify to make this clean.  So we special-case it.", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "__dict__", "[", "key", "]", "!=", "other", ".", "__dict__", "[", "key", "]", ":", "\n", "                    ", "return", "False", "\n", "", "", "return", "True", "\n", "", "return", "NotImplemented", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.__init__": [[42, 282], ["allennlp.training.trainer_base.TrainerBase.__init__", "allennlp.training.metric_tracker.MetricTracker", "allennlp.training.tensorboard_writer.TensorboardWriter", "allennlp.training.checkpointer.Checkpointer", "trainer.MatchingTrainer._tensorboard.enable_activation_logging", "range", "range", "logger.warning", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "trainer.MatchingTrainer.train_text_db.append", "trainer.MatchingTrainer.train_segment_ids_db.append", "len", "len", "trainer.MatchingTrainer.train_image_db.append", "isinstance", "trainer.MatchingTrainer.val_text_db.append", "trainer.MatchingTrainer.val_segment_ids_db.append", "trainer.MatchingTrainer.val_image_db.append"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ":", "Model", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "train_dataset", ":", "Iterable", "[", "Instance", "]", ",", "\n", "validation_dataset", ":", "Optional", "[", "Iterable", "[", "Instance", "]", "]", "=", "None", ",", "\n", "patience", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "validation_metric", ":", "str", "=", "\"-loss\"", ",", "\n", "validation_iterator", ":", "DataIterator", "=", "None", ",", "\n", "retrieve_text", ":", "bool", "=", "True", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "num_epochs", ":", "int", "=", "20", ",", "\n", "serialization_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "num_serialized_models_to_keep", ":", "int", "=", "20", ",", "\n", "keep_serialized_model_every_num_seconds", ":", "int", "=", "None", ",", "\n", "checkpointer", ":", "Checkpointer", "=", "None", ",", "\n", "model_save_interval", ":", "float", "=", "None", ",", "\n", "cuda_device", ":", "Union", "[", "int", ",", "List", "]", "=", "-", "1", ",", "\n", "grad_norm", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "grad_clipping", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "learning_rate_scheduler", ":", "Optional", "[", "LearningRateScheduler", "]", "=", "None", ",", "\n", "momentum_scheduler", ":", "Optional", "[", "MomentumScheduler", "]", "=", "None", ",", "\n", "summary_interval", ":", "int", "=", "100", ",", "\n", "histogram_interval", ":", "int", "=", "None", ",", "\n", "should_log_parameter_statistics", ":", "bool", "=", "True", ",", "\n", "should_log_learning_rate", ":", "bool", "=", "False", ",", "\n", "log_batch_size_period", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "moving_average", ":", "Optional", "[", "MovingAverage", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        A trainer for doing supervised learning. It just takes a labeled dataset\n        and a ``DataIterator``, and uses the supplied ``Optimizer`` to learn the weights\n        for your model over some fixed number of epochs. You can also pass in a validation\n        dataset and enable early stopping. There are many other bells and whistles as well.\n\n        Parameters\n        ----------\n        model : ``Model``, required.\n            An AllenNLP model to be optimized. Pytorch Modules can also be optimized if\n            their ``forward`` method returns a dictionary with a \"loss\" key, containing a\n            scalar tensor representing the loss function to be optimized.\n\n            If you are training your model using GPUs, your model should already be\n            on the correct device. (If you use `Trainer.from_params` this will be\n            handled for you.)\n        optimizer : ``torch.nn.Optimizer``, required.\n            An instance of a Pytorch Optimizer, instantiated with the parameters of the\n            model to be optimized.\n        iterator : ``DataIterator``, required.\n            A method for iterating over a ``Dataset``, yielding padded indexed batches.\n        train_dataset : ``Dataset``, required.\n            A ``Dataset`` to train on. The dataset should have already been indexed.\n        validation_dataset : ``Dataset``, optional, (default = None).\n            A ``Dataset`` to evaluate on. The dataset should have already been indexed.\n        patience : Optional[int] > 0, optional (default=None)\n            Number of epochs to be patient before early stopping: the training is stopped\n            after ``patience`` epochs with no improvement. If given, it must be ``> 0``.\n            If None, early stopping is disabled.\n        validation_metric : str, optional (default=\"loss\")\n            Validation metric to measure for whether to stop training using patience\n            and whether to serialize an ``is_best`` model each epoch. The metric name\n            must be prepended with either \"+\" or \"-\", which specifies whether the metric\n            is an increasing or decreasing function.\n        validation_iterator : ``DataIterator``, optional (default=None)\n            An iterator to use for the validation set.  If ``None``, then\n            use the training `iterator`.\n        shuffle: ``bool``, optional (default=True)\n            Whether to shuffle the instances in the iterator or not.\n        num_epochs : int, optional (default = 20)\n            Number of training epochs.\n        serialization_dir : str, optional (default=None)\n            Path to directory for saving and loading model files. Models will not be saved if\n            this parameter is not passed.\n        num_serialized_models_to_keep : ``int``, optional (default=20)\n            Number of previous model checkpoints to retain.  Default is to keep 20 checkpoints.\n            A value of None or -1 means all checkpoints will be kept.\n        keep_serialized_model_every_num_seconds : ``int``, optional (default=None)\n            If num_serialized_models_to_keep is not None, then occasionally it's useful to\n            save models at a given interval in addition to the last num_serialized_models_to_keep.\n            To do so, specify keep_serialized_model_every_num_seconds as the number of seconds\n            between permanently saved checkpoints.  Note that this option is only used if\n            num_serialized_models_to_keep is not None, otherwise all checkpoints are kept.\n        checkpointer : ``Checkpointer``, optional (default=None)\n            An instance of class Checkpointer to use instead of the default. If a checkpointer is specified,\n            the arguments num_serialized_models_to_keep and keep_serialized_model_every_num_seconds should\n            not be specified. The caller is responsible for initializing the checkpointer so that it is\n            consistent with serialization_dir.\n        model_save_interval : ``float``, optional (default=None)\n            If provided, then serialize models every ``model_save_interval``\n            seconds within single epochs.  In all cases, models are also saved\n            at the end of every epoch if ``serialization_dir`` is provided.\n        cuda_device : ``Union[int, List[int]]``, optional (default = -1)\n            An integer or list of integers specifying the CUDA device(s) to use. If -1, the CPU is used.\n        grad_norm : ``float``, optional, (default = None).\n            If provided, gradient norms will be rescaled to have a maximum of this value.\n        grad_clipping : ``float``, optional (default = ``None``).\n            If provided, gradients will be clipped `during the backward pass` to have an (absolute)\n            maximum of this value.  If you are getting ``NaNs`` in your gradients during training\n            that are not solved by using ``grad_norm``, you may need this.\n        learning_rate_scheduler : ``LearningRateScheduler``, optional (default = None)\n            If specified, the learning rate will be decayed with respect to\n            this schedule at the end of each epoch (or batch, if the scheduler implements\n            the ``step_batch`` method). If you use :class:`torch.optim.lr_scheduler.ReduceLROnPlateau`,\n            this will use the ``validation_metric`` provided to determine if learning has plateaued.\n            To support updating the learning rate on every batch, this can optionally implement\n            ``step_batch(batch_num_total)`` which updates the learning rate given the batch number.\n        momentum_scheduler : ``MomentumScheduler``, optional (default = None)\n            If specified, the momentum will be updated at the end of each batch or epoch\n            according to the schedule.\n        summary_interval: ``int``, optional, (default = 100)\n            Number of batches between logging scalars to tensorboard\n        histogram_interval : ``int``, optional, (default = ``None``)\n            If not None, then log histograms to tensorboard every ``histogram_interval`` batches.\n            When this parameter is specified, the following additional logging is enabled:\n                * Histograms of model parameters\n                * The ratio of parameter update norm to parameter norm\n                * Histogram of layer activations\n            We log histograms of the parameters returned by\n            ``model.get_parameters_for_histogram_tensorboard_logging``.\n            The layer activations are logged for any modules in the ``Model`` that have\n            the attribute ``should_log_activations`` set to ``True``.  Logging\n            histograms requires a number of GPU-CPU copies during training and is typically\n            slow, so we recommend logging histograms relatively infrequently.\n            Note: only Modules that return tensors, tuples of tensors or dicts\n            with tensors as values currently support activation logging.\n        should_log_parameter_statistics : ``bool``, optional, (default = True)\n            Whether to send parameter statistics (mean and standard deviation\n            of parameters and gradients) to tensorboard.\n        should_log_learning_rate : ``bool``, optional, (default = False)\n            Whether to send parameter specific learning rate to tensorboard.\n        log_batch_size_period : ``int``, optional, (default = ``None``)\n            If defined, how often to log the average batch size.\n        moving_average: ``MovingAverage``, optional, (default = None)\n            If provided, we will maintain moving averages for all parameters. During training, we\n            employ a shadow variable for each parameter, which maintains the moving average. During\n            evaluation, we backup the original parameters and assign the moving averages to corresponding\n            parameters. Be careful that when saving the checkpoint, we will save the moving averages of\n            parameters. This is necessary because we want the saved model to perform as well as the validated\n            model if we load it later. But this may cause problems if you restart the training from checkpoint.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "serialization_dir", ",", "cuda_device", ")", "\n", "\n", "# I am not calling move_to_gpu here, because if the model is", "\n", "# not already on the GPU then the optimizer is going to be wrong.", "\n", "self", ".", "model", "=", "model", "\n", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "_validation_iterator", "=", "validation_iterator", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "train_data", "=", "train_dataset", "\n", "self", ".", "_validation_data", "=", "validation_dataset", "\n", "\n", "if", "patience", "is", "None", ":", "# no early stopping", "\n", "            ", "if", "validation_dataset", ":", "\n", "                ", "logger", ".", "warning", "(", "'You provided a validation dataset but patience was set to None, '", "\n", "'meaning that early stopping is disabled'", ")", "\n", "", "", "elif", "(", "not", "isinstance", "(", "patience", ",", "int", ")", ")", "or", "patience", "<=", "0", ":", "\n", "            ", "raise", "ConfigurationError", "(", "'{} is an invalid value for \"patience\": it must be a positive integer '", "\n", "'or None (if you want to disable early stopping)'", ".", "format", "(", "patience", ")", ")", "\n", "\n", "# For tracking is_best_so_far and should_stop_early", "\n", "", "self", ".", "_metric_tracker", "=", "MetricTracker", "(", "patience", ",", "validation_metric", ")", "\n", "# Get rid of + or -", "\n", "self", ".", "_validation_metric", "=", "validation_metric", "[", "1", ":", "]", "\n", "\n", "self", ".", "_num_epochs", "=", "num_epochs", "\n", "\n", "if", "checkpointer", "is", "not", "None", ":", "\n", "# We can't easily check if these parameters were passed in, so check against their default values.", "\n", "# We don't check against serialization_dir since it is also used by the parent class.", "\n", "            ", "if", "num_serialized_models_to_keep", "!=", "20", "or", "keep_serialized_model_every_num_seconds", "is", "not", "None", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"When passing a custom Checkpointer, you may not also pass in separate checkpointer \"", "\n", "\"args 'num_serialized_models_to_keep' or 'keep_serialized_model_every_num_seconds'.\"", ")", "\n", "", "self", ".", "_checkpointer", "=", "checkpointer", "\n", "", "else", ":", "\n", "            ", "self", ".", "_checkpointer", "=", "Checkpointer", "(", "serialization_dir", ",", "\n", "keep_serialized_model_every_num_seconds", ",", "\n", "num_serialized_models_to_keep", ")", "\n", "\n", "", "self", ".", "_model_save_interval", "=", "model_save_interval", "\n", "\n", "self", ".", "_grad_norm", "=", "grad_norm", "\n", "self", ".", "_grad_clipping", "=", "grad_clipping", "\n", "\n", "self", ".", "_learning_rate_scheduler", "=", "learning_rate_scheduler", "\n", "self", ".", "_momentum_scheduler", "=", "momentum_scheduler", "\n", "self", ".", "_moving_average", "=", "moving_average", "\n", "\n", "# We keep the total batch number as an instance variable because it", "\n", "# is used inside a closure for the hook which logs activations in", "\n", "# ``_enable_activation_logging``.", "\n", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "self", ".", "_tensorboard", "=", "TensorboardWriter", "(", "\n", "get_batch_num_total", "=", "lambda", ":", "self", ".", "_batch_num_total", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ")", "\n", "\n", "self", ".", "_log_batch_size_period", "=", "log_batch_size_period", "\n", "\n", "self", ".", "_last_log", "=", "0.0", "# time of last logging", "\n", "\n", "# Enable activation logging.", "\n", "if", "histogram_interval", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tensorboard", ".", "enable_activation_logging", "(", "self", ".", "model", ")", "\n", "", "self", ".", "retrieve_text", "=", "retrieve_text", "\n", "if", "retrieve_text", ":", "\n", "            ", "self", ".", "train_text_db", "=", "[", "]", "\n", "self", ".", "train_segment_ids_db", "=", "[", "]", "\n", "for", "instance", "in", "train_dataset", ":", "\n", "                ", "self", ".", "train_text_db", ".", "append", "(", "instance", ".", "fields", "[", "'token_ids'", "]", ".", "tokens", ")", "\n", "self", ".", "train_token_indexers", "=", "instance", ".", "fields", "[", "'token_ids'", "]", ".", "_token_indexers", "\n", "self", ".", "train_segment_ids_db", ".", "append", "(", "instance", ".", "fields", "[", "'segment_ids'", "]", ".", "array", ")", "\n", "", "self", ".", "train_indices", "=", "range", "(", "len", "(", "self", ".", "train_text_db", ")", ")", "\n", "if", "validation_dataset", ":", "\n", "                ", "self", ".", "val_text_db", "=", "[", "]", "\n", "self", ".", "val_segment_ids_db", "=", "[", "]", "\n", "for", "instance", "in", "validation_dataset", ":", "\n", "                    ", "self", ".", "val_text_db", ".", "append", "(", "instance", ".", "fields", "[", "'token_ids'", "]", ".", "tokens", ")", "\n", "self", ".", "val_token_indexers", "=", "instance", ".", "fields", "[", "'token_ids'", "]", ".", "_token_indexers", "\n", "self", ".", "val_segment_ids_db", ".", "append", "(", "instance", ".", "fields", "[", "'segment_ids'", "]", ".", "array", ")", "\n", "", "", "self", ".", "val_indices", "=", "range", "(", "len", "(", "self", ".", "val_text_db", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_image_db", "=", "[", "]", "\n", "# self.category_weights = defaultdict(int)", "\n", "for", "instance", "in", "train_dataset", ":", "\n", "                ", "if", "'category'", "in", "instance", ".", "fields", ":", "\n", "                    ", "self", ".", "category_weights", "[", "instance", ".", "fields", "[", "'category'", "]", ".", "metadata", "]", "+=", "1", "\n", "", "self", ".", "train_image_db", ".", "append", "(", "instance", ".", "fields", "[", "'images'", "]", ".", "array", ")", "\n", "# self.category_weights = {category: round(np.log(float(len(train_dataset))/self.category_weights[category]), 5) for category in self.category_weights}\"\"\"", "\n", "", "if", "validation_dataset", ":", "\n", "                ", "self", ".", "val_image_db", "=", "[", "]", "\n", "for", "instance", "in", "validation_dataset", ":", "\n", "                    ", "self", ".", "val_image_db", ".", "append", "(", "instance", ".", "fields", "[", "'images'", "]", ".", "array", ")", "\n", "", "", "", "self", ".", "num_negative_samples", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.rescale_gradients": [[283, 285], ["allennlp.training.util.rescale_gradients"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.rescale_gradients"], ["", "def", "rescale_gradients", "(", "self", ")", "->", "Optional", "[", "float", "]", ":", "\n", "        ", "return", "training_util", ".", "rescale_gradients", "(", "self", ".", "model", ",", "self", ".", "_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.batch_loss": [[286, 310], ["allennlp.training.util.data_parallel", "allennlp.nn.util.move_to_device", "trainer.MatchingTrainer.model", "len", "trainer.MatchingTrainer.model.get_regularization_penalty", "RuntimeError"], "methods", ["None"], ["", "def", "batch_loss", "(", "self", ",", "batch_group", ":", "List", "[", "TensorDict", "]", ",", "for_training", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Does a forward pass on the given batches and returns the ``loss`` value in the result.\n        If ``for_training`` is `True` also applies regularization penalty.\n        \"\"\"", "\n", "if", "self", ".", "_multiple_gpu", ":", "\n", "            ", "output_dict", "=", "training_util", ".", "data_parallel", "(", "batch_group", ",", "self", ".", "model", ",", "self", ".", "_cuda_devices", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "batch_group", ")", "==", "1", "\n", "batch", "=", "batch_group", "[", "0", "]", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "_cuda_devices", "[", "0", "]", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "\n", "", "try", ":", "\n", "            ", "loss", "=", "output_dict", "[", "\"loss\"", "]", "\n", "if", "for_training", ":", "\n", "                ", "loss", "+=", "self", ".", "model", ".", "get_regularization_penalty", "(", ")", "\n", "", "", "except", "KeyError", ":", "\n", "            ", "if", "for_training", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The model you are trying to optimize does not contain a\"", "\n", "\" 'loss' key in the output of model.forward(inputs).\"", ")", "\n", "", "loss", "=", "None", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._train_epoch": [[311, 474], ["logger.info", "allennlp.common.util.peak_memory_mb", "logger.info", "allennlp.common.util.gpu_memory_mb().items", "trainer.MatchingTrainer.model.train", "len", "trainer.MatchingTrainer.iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "time.time", "time.time", "set", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "allennlp.training.util.get_metrics", "gpu_usage.append", "logger.info", "trainer.MatchingTrainer.model.get_parameters_for_histogram_tensorboard_logging", "trainer.MatchingTrainer.optimizer.zero_grad", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "trainer.MatchingTrainer.batch_loss", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "trainer.MatchingTrainer.backward", "trainer.MatchingTrainer.item", "trainer.MatchingTrainer.rescale_gradients", "trainer.MatchingTrainer._tensorboard.should_log_histograms_this_batch", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "trainer.MatchingTrainer._tensorboard.should_log_this_batch", "trainer.MatchingTrainer._tensorboard.should_log_histograms_this_batch", "allennlp.common.util.gpu_memory_mb", "trainer.MatchingTrainer.iterator.get_num_batches", "len", "random.randint", "labels.append", "max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array", "ValueError", "trainer.MatchingTrainer._learning_rate_scheduler.step_batch", "trainer.MatchingTrainer._momentum_scheduler.step_batch", "trainer.MatchingTrainer.optimizer.step", "trainer.MatchingTrainer.model.named_parameters", "trainer.MatchingTrainer.optimizer.step", "trainer.MatchingTrainer._moving_average.apply", "trainer.MatchingTrainer._tensorboard.log_parameter_and_gradient_statistics", "trainer.MatchingTrainer._tensorboard.log_learning_rates", "trainer.MatchingTrainer._tensorboard.add_train_scalar", "trainer.MatchingTrainer._tensorboard.log_metrics", "trainer.MatchingTrainer._tensorboard.log_histograms", "sum", "time.time", "trainer.MatchingTrainer._save_checkpoint", "range", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.array", "numpy.vstack", "param.detach().cpu().clone", "param_updates[].sub_", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "torch.norm().cpu", "trainer.MatchingTrainer._tensorboard.add_train_scalar", "logger.info", "trainer.MatchingTrainer._tensorboard.add_train_scalar", "trainer.MatchingTrainer._tensorboard.add_train_scalar", "len", "trainer.MatchingTrainer.model.named_parameters", "param.detach().cpu", "param_updates[].view", "allennlp.training.util.get_batch_size", "time.time", "allennlp.training.util.time_to_str", "instance_text.append", "instance_segment_ids.append", "random.choice", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField.index", "allennlp.data.fields.TextField.get_padding_lengths", "instance_text.append", "instance_segment_ids.append", "range", "numpy.expand_dims", "numpy.expand_dims", "param.detach().cpu", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "allennlp.training.util.get_metrics.items", "int", "str", "[].tolist", "[].tolist", "[].tolist", "trainer.MatchingTrainer.train_segment_ids_db[].tolist", "[].numpy", "random.choice", "range", "range", "param.detach", "param.view", "param.detach", "len", "len", "allennlp.data.fields.TextField.as_tensor"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.train", "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.get_metrics", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.batch_loss", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.rescale_gradients", "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.get_metrics", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._save_checkpoint", "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.get_padding_lengths"], ["", "def", "_train_epoch", "(", "self", ",", "epoch", ":", "int", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Trains one epoch and returns metrics.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Epoch %d/%d\"", ",", "epoch", ",", "self", ".", "_num_epochs", "-", "1", ")", "\n", "peak_cpu_usage", "=", "peak_memory_mb", "(", ")", "\n", "logger", ".", "info", "(", "f\"Peak CPU memory usage MB: {peak_cpu_usage}\"", ")", "\n", "gpu_usage", "=", "[", "]", "\n", "for", "gpu", ",", "memory", "in", "gpu_memory_mb", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "gpu_usage", ".", "append", "(", "(", "gpu", ",", "memory", ")", ")", "\n", "logger", ".", "info", "(", "f\"GPU {gpu} memory usage MB: {memory}\"", ")", "\n", "\n", "", "train_loss", "=", "0.0", "\n", "# Set the model to \"train\" mode.", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "# Get tqdm for the training batches", "\n", "raw_train_generator", "=", "self", ".", "iterator", "(", "self", ".", "train_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "train_generator", "=", "lazy_groups_of", "(", "raw_train_generator", ",", "num_gpus", ")", "\n", "num_training_batches", "=", "math", ".", "ceil", "(", "self", ".", "iterator", ".", "get_num_batches", "(", "self", ".", "train_data", ")", "/", "num_gpus", ")", "\n", "self", ".", "_last_log", "=", "time", ".", "time", "(", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "batches_this_epoch", "=", "0", "\n", "if", "self", ".", "_batch_num_total", "is", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "0", "\n", "\n", "", "histogram_parameters", "=", "set", "(", "self", ".", "model", ".", "get_parameters_for_histogram_tensorboard_logging", "(", ")", ")", "\n", "\n", "\n", "logger", ".", "info", "(", "\"Training\"", ")", "\n", "train_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "train_generator", ",", "\n", "total", "=", "num_training_batches", ")", "\n", "cumulative_batch_size", "=", "0", "\n", "for", "batch_group", "in", "train_generator_tqdm", ":", "\n", "            ", "batches_this_epoch", "+=", "1", "\n", "self", ".", "_batch_num_total", "+=", "1", "\n", "batch_num_total", "=", "self", ".", "_batch_num_total", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "images", "=", "[", "]", "\n", "text", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "batch_group", "[", "0", "]", "[", "'images'", "]", ")", ")", ":", "\n", "                ", "positive_index", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "num_negative_samples", ")", "\n", "labels", ".", "append", "(", "positive_index", ")", "\n", "if", "self", ".", "retrieve_text", ":", "\n", "                    ", "instance_text", "=", "[", "]", "\n", "instance_segment_ids", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "num_negative_samples", "+", "1", ")", ":", "\n", "                        ", "if", "j", "==", "positive_index", ":", "\n", "                            ", "instance_text", ".", "append", "(", "batch_group", "[", "0", "]", "[", "'token_ids'", "]", "[", "'tokens'", "]", "[", "i", ",", ":", "]", ".", "tolist", "(", ")", ")", "\n", "instance_segment_ids", ".", "append", "(", "batch_group", "[", "0", "]", "[", "'segment_ids'", "]", "[", "i", "]", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "negative_sample_index", "=", "random", ".", "choice", "(", "self", ".", "train_indices", ")", "\n", "text_field", "=", "TextField", "(", "self", ".", "train_text_db", "[", "negative_sample_index", "]", ",", "self", ".", "train_token_indexers", ")", "\n", "text_field", ".", "index", "(", "self", ".", "model", ".", "vocab", ")", "\n", "padding_lengths", "=", "text_field", ".", "get_padding_lengths", "(", ")", "\n", "instance_text", ".", "append", "(", "text_field", ".", "as_tensor", "(", "padding_lengths", "=", "padding_lengths", ")", "[", "'tokens'", "]", ".", "tolist", "(", ")", ")", "\n", "instance_segment_ids", ".", "append", "(", "self", ".", "train_segment_ids_db", "[", "negative_sample_index", "]", ".", "tolist", "(", ")", ")", "\n", "", "", "text", "+=", "instance_text", "\n", "segment_ids", "+=", "instance_segment_ids", "\n", "", "else", ":", "\n", "                    ", "instance_images", "=", "[", "None", "for", "_", "in", "range", "(", "self", ".", "num_negative_samples", "+", "1", ")", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "num_negative_samples", "+", "1", ")", ":", "\n", "                        ", "if", "j", "==", "positive_index", ":", "\n", "                            ", "instance_images", "[", "j", "]", "=", "np", ".", "expand_dims", "(", "batch_group", "[", "0", "]", "[", "'images'", "]", "[", "i", "]", ".", "numpy", "(", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                            ", "instance_images", "[", "j", "]", "=", "np", ".", "expand_dims", "(", "random", ".", "choice", "(", "self", ".", "train_image_db", ")", ",", "0", ")", "\n", "", "", "images", "+=", "instance_images", "\n", "", "", "matching_label_field_name", "=", "\"labels\"", "\n", "if", "self", ".", "retrieve_text", ":", "\n", "                ", "max_text_len", "=", "max", "(", "[", "len", "(", "sequence", ")", "for", "sequence", "in", "text", "]", ")", "\n", "text", "=", "[", "sequence", "+", "[", "0", "for", "_", "in", "range", "(", "max_text_len", "-", "len", "(", "sequence", ")", ")", "]", "for", "sequence", "in", "text", "]", "\n", "batch_group", "[", "0", "]", "[", "'token_ids'", "]", "=", "{", "'tokens'", ":", "torch", ".", "LongTensor", "(", "text", ")", "}", "\n", "segment_ids", "=", "[", "sequence", "+", "[", "0", "for", "_", "in", "range", "(", "max_text_len", "-", "len", "(", "sequence", ")", ")", "]", "for", "sequence", "in", "segment_ids", "]", "\n", "batch_group", "[", "0", "]", "[", "'segment_ids'", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "segment_ids", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "", "else", ":", "\n", "                ", "batch_group", "[", "0", "]", "[", "'images'", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "images", ")", ")", "\n", "", "batch_group", "[", "0", "]", "[", "matching_label_field_name", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "labels", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "True", ")", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"nan loss encountered\"", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "batch_grad_norm", "=", "self", ".", "rescale_gradients", "(", ")", "\n", "\n", "# This does nothing if batch_num_total is None or you are using a", "\n", "# scheduler which doesn't update per batch.", "\n", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                ", "self", ".", "_learning_rate_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                ", "self", ".", "_momentum_scheduler", ".", "step_batch", "(", "batch_num_total", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "# get the magnitude of parameter updates for logging", "\n", "# We need a copy of current parameters to compute magnitude of updates,", "\n", "# and copy them to CPU so large models won't go OOM on the GPU.", "\n", "                ", "param_updates", "=", "{", "name", ":", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "clone", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "}", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "param_updates", "[", "name", "]", ".", "sub_", "(", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "update_norm", "=", "torch", ".", "norm", "(", "param_updates", "[", "name", "]", ".", "view", "(", "-", "1", ",", ")", ")", "\n", "param_norm", "=", "torch", ".", "norm", "(", "param", ".", "view", "(", "-", "1", ",", ")", ")", ".", "cpu", "(", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"gradient_update/\"", "+", "name", ",", "\n", "update_norm", "/", "(", "param_norm", "+", "1e-7", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update moving averages", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "                ", "self", ".", "_moving_average", ".", "apply", "(", "batch_num_total", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "metrics", ")", "\n", "\n", "train_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Log parameter values to Tensorboard", "\n", "if", "self", ".", "_tensorboard", ".", "should_log_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_parameter_and_gradient_statistics", "(", "self", ".", "model", ",", "batch_grad_norm", ")", "\n", "self", ".", "_tensorboard", ".", "log_learning_rates", "(", "self", ".", "model", ",", "self", ".", "optimizer", ")", "\n", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"loss/loss_train\"", ",", "metrics", "[", "\"loss\"", "]", ")", "\n", "self", ".", "_tensorboard", ".", "log_metrics", "(", "{", "\"epoch_metrics/\"", "+", "k", ":", "v", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "}", ")", "\n", "\n", "", "if", "self", ".", "_tensorboard", ".", "should_log_histograms_this_batch", "(", ")", ":", "\n", "                ", "self", ".", "_tensorboard", ".", "log_histograms", "(", "self", ".", "model", ",", "histogram_parameters", ")", "\n", "\n", "", "if", "self", ".", "_log_batch_size_period", ":", "\n", "                ", "cur_batch", "=", "sum", "(", "[", "training_util", ".", "get_batch_size", "(", "batch", ")", "for", "batch", "in", "batch_group", "]", ")", "\n", "cumulative_batch_size", "+=", "cur_batch", "\n", "if", "(", "batches_this_epoch", "-", "1", ")", "%", "self", ".", "_log_batch_size_period", "==", "0", ":", "\n", "                    ", "average", "=", "cumulative_batch_size", "/", "batches_this_epoch", "\n", "logger", ".", "info", "(", "f\"current batch size: {cur_batch} mean batch size: {average}\"", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"current_batch_size\"", ",", "cur_batch", ")", "\n", "self", ".", "_tensorboard", ".", "add_train_scalar", "(", "\"mean_batch_size\"", ",", "average", ")", "\n", "\n", "# Save model if needed.", "\n", "", "", "if", "self", ".", "_model_save_interval", "is", "not", "None", "and", "(", "\n", "time", ".", "time", "(", ")", "-", "last_save_time", ">", "self", ".", "_model_save_interval", "\n", ")", ":", "\n", "                ", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_save_checkpoint", "(", "\n", "'{0}.{1}'", ".", "format", "(", "epoch", ",", "training_util", ".", "time_to_str", "(", "int", "(", "last_save_time", ")", ")", ")", "\n", ")", "\n", "", "", "metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "train_loss", ",", "batches_this_epoch", ",", "reset", "=", "True", ")", "\n", "metrics", "[", "'cpu_memory_MB'", "]", "=", "peak_cpu_usage", "\n", "for", "(", "gpu_num", ",", "memory", ")", "in", "gpu_usage", ":", "\n", "            ", "metrics", "[", "'gpu_'", "+", "str", "(", "gpu_num", ")", "+", "'_memory_MB'", "]", "=", "memory", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._validation_loss": [[475, 567], ["logger.info", "trainer.MatchingTrainer.model.eval", "len", "val_iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "allennlp.common.tqdm.Tqdm.tqdm", "trainer.MatchingTrainer._moving_average.assign_average_value", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "trainer.MatchingTrainer.batch_loss", "allennlp.training.util.get_metrics", "allennlp.training.util.description_from_metrics", "allennlp.common.tqdm.Tqdm.tqdm.set_description", "trainer.MatchingTrainer._moving_average.restore", "val_iterator.get_num_batches", "len", "random.randint", "labels.append", "max", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array", "trainer.MatchingTrainer.detach().cpu().numpy", "range", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.array", "numpy.vstack", "len", "trainer.MatchingTrainer.detach().cpu", "instance_text.append", "instance_segment_ids.append", "random.choice", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField.index", "allennlp.data.fields.TextField.get_padding_lengths", "instance_text.append", "instance_segment_ids.append", "range", "numpy.expand_dims", "numpy.expand_dims", "[].tolist", "[].tolist", "[].tolist", "trainer.MatchingTrainer.val_segment_ids_db[].tolist", "[].numpy", "random.choice", "range", "range", "trainer.MatchingTrainer.detach", "len", "len", "allennlp.data.fields.TextField.as_tensor"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.batch_loss", "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.get_metrics", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.matching.token_indexer.BertFromConfigIndexer.get_padding_lengths"], ["", "def", "_validation_loss", "(", "self", ")", "->", "Tuple", "[", "float", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Computes the validation loss. Returns it and the number of batches.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Validating\"", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Replace parameter values with the shadow values from the moving averages.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "", "if", "self", ".", "_validation_iterator", "is", "not", "None", ":", "\n", "            ", "val_iterator", "=", "self", ".", "_validation_iterator", "\n", "", "else", ":", "\n", "            ", "val_iterator", "=", "self", ".", "iterator", "\n", "\n", "", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "raw_val_generator", "=", "val_iterator", "(", "self", ".", "_validation_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "val_generator", "=", "lazy_groups_of", "(", "raw_val_generator", ",", "num_gpus", ")", "\n", "num_validation_batches", "=", "math", ".", "ceil", "(", "val_iterator", ".", "get_num_batches", "(", "self", ".", "_validation_data", ")", "/", "num_gpus", ")", "\n", "val_generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "val_generator", ",", "\n", "total", "=", "num_validation_batches", ")", "\n", "batches_this_epoch", "=", "0", "\n", "val_loss", "=", "0", "\n", "for", "batch_group", "in", "val_generator_tqdm", ":", "\n", "            ", "images", "=", "[", "]", "\n", "text", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "num_negative_samples", "=", "self", ".", "num_negative_samples", "*", "10", "\n", "for", "i", "in", "range", "(", "len", "(", "batch_group", "[", "0", "]", "[", "'images'", "]", ")", ")", ":", "\n", "                ", "positive_index", "=", "random", ".", "randint", "(", "0", ",", "num_negative_samples", ")", "\n", "labels", ".", "append", "(", "positive_index", ")", "\n", "if", "self", ".", "retrieve_text", ":", "\n", "                    ", "instance_text", "=", "[", "]", "\n", "instance_segment_ids", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "num_negative_samples", "+", "1", ")", ":", "\n", "                        ", "if", "j", "==", "positive_index", ":", "\n", "                            ", "instance_text", ".", "append", "(", "batch_group", "[", "0", "]", "[", "'token_ids'", "]", "[", "'tokens'", "]", "[", "i", "]", ".", "tolist", "(", ")", ")", "\n", "instance_segment_ids", ".", "append", "(", "batch_group", "[", "0", "]", "[", "'segment_ids'", "]", "[", "i", "]", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "negative_sample_index", "=", "random", ".", "choice", "(", "self", ".", "val_indices", ")", "\n", "text_field", "=", "TextField", "(", "self", ".", "val_text_db", "[", "negative_sample_index", "]", ",", "self", ".", "val_token_indexers", ")", "\n", "text_field", ".", "index", "(", "self", ".", "model", ".", "vocab", ")", "\n", "padding_lengths", "=", "text_field", ".", "get_padding_lengths", "(", ")", "\n", "instance_text", ".", "append", "(", "text_field", ".", "as_tensor", "(", "padding_lengths", "=", "padding_lengths", ")", "[", "'tokens'", "]", ".", "tolist", "(", ")", ")", "\n", "instance_segment_ids", ".", "append", "(", "self", ".", "val_segment_ids_db", "[", "negative_sample_index", "]", ".", "tolist", "(", ")", ")", "\n", "", "", "text", "+=", "instance_text", "\n", "segment_ids", "+=", "instance_segment_ids", "\n", "", "else", ":", "\n", "                    ", "instance_images", "=", "[", "None", "for", "_", "in", "range", "(", "num_negative_samples", "+", "1", ")", "]", "\n", "for", "j", "in", "range", "(", "num_negative_samples", "+", "1", ")", ":", "\n", "                        ", "if", "j", "==", "positive_index", ":", "\n", "                            ", "instance_images", "[", "j", "]", "=", "np", ".", "expand_dims", "(", "batch_group", "[", "0", "]", "[", "'images'", "]", "[", "i", "]", ".", "numpy", "(", ")", ",", "0", ")", "\n", "", "else", ":", "\n", "                            ", "instance_images", "[", "j", "]", "=", "np", ".", "expand_dims", "(", "random", ".", "choice", "(", "self", ".", "val_image_db", ")", ",", "0", ")", "\n", "", "", "images", "+=", "instance_images", "\n", "", "", "matching_label_field_name", "=", "\"labels\"", "\n", "if", "self", ".", "retrieve_text", ":", "\n", "                ", "max_text_len", "=", "max", "(", "[", "len", "(", "sequence", ")", "for", "sequence", "in", "text", "]", ")", "\n", "text", "=", "[", "sequence", "+", "[", "0", "for", "_", "in", "range", "(", "max_text_len", "-", "len", "(", "sequence", ")", ")", "]", "for", "sequence", "in", "text", "]", "\n", "batch_group", "[", "0", "]", "[", "'token_ids'", "]", "=", "{", "'tokens'", ":", "torch", ".", "LongTensor", "(", "text", ")", "}", "\n", "segment_ids", "=", "[", "sequence", "+", "[", "0", "for", "_", "in", "range", "(", "max_text_len", "-", "len", "(", "sequence", ")", ")", "]", "for", "sequence", "in", "segment_ids", "]", "\n", "batch_group", "[", "0", "]", "[", "'segment_ids'", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "segment_ids", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "", "else", ":", "\n", "                ", "batch_group", "[", "0", "]", "[", "'images'", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "images", ")", ")", "\n", "", "batch_group", "[", "0", "]", "[", "matching_label_field_name", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "labels", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "\n", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "False", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "# You shouldn't necessarily have to compute a loss for validation, so we allow for", "\n", "# `loss` to be None.  We need to be careful, though - `batches_this_epoch` is", "\n", "# currently only used as the divisor for the loss function, so we can safely only", "\n", "# count those batches for which we actually have a loss.  If this variable ever", "\n", "# gets used for something else, we might need to change things around a bit.", "\n", "                ", "batches_this_epoch", "+=", "1", "\n", "val_loss", "+=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "batches_this_epoch", ")", "\n", "description", "=", "training_util", ".", "description_from_metrics", "(", "val_metrics", ")", "\n", "val_generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "# Now restore the original parameter values.", "\n", "", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n", "", "return", "val_loss", ",", "batches_this_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.train": [[568, 680], ["allennlp.training.util.enable_gradient_clipping", "logger.info", "time.time", "trainer.MatchingTrainer._metric_tracker.best_epoch_metrics.items", "range", "trainer.MatchingTrainer._tensorboard.close", "trainer.MatchingTrainer._checkpointer.best_model_state", "trainer.MatchingTrainer._restore_checkpoint", "time.time", "trainer.MatchingTrainer._train_epoch", "trainer.MatchingTrainer.items", "trainer.MatchingTrainer._tensorboard.log_metrics", "str", "trainer.MatchingTrainer.items", "allennlp.training.util.get_metrics.items", "trainer.MatchingTrainer._metric_tracker.is_best_so_far", "trainer.MatchingTrainer._save_checkpoint", "logger.info", "trainer.MatchingTrainer.model.load_state_dict", "traceback.print_exc", "allennlp.common.checks.ConfigurationError", "max", "key.startswith", "time.time", "datetime.timedelta", "allennlp.training.util.get_metrics.items", "allennlp.common.util.dump_metrics", "trainer.MatchingTrainer._learning_rate_scheduler.step", "trainer.MatchingTrainer._momentum_scheduler.step", "time.time", "datetime.timedelta", "str", "logger.info", "metrics.get", "max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "trainer.MatchingTrainer._validation_loss", "allennlp.training.util.get_metrics", "trainer.MatchingTrainer._metric_tracker.add_metric", "trainer.MatchingTrainer._metric_tracker.should_stop_early", "os.path.join", "time.time", "datetime.timedelta", "metrics.get", "logger.info", "float", "int"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._restore_checkpoint", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._train_epoch", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._save_checkpoint", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.torchvision_detection_utils.SmoothedValue.max", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._validation_loss", "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.get_metrics"], ["", "def", "train", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Trains the supplied model with the supplied parameters.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "epoch_counter", "=", "self", ".", "_restore_checkpoint", "(", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "ConfigurationError", "(", "\"Could not recover training from the checkpoint.  Did you mean to output to \"", "\n", "\"a different serialization directory or delete the existing serialization \"", "\n", "\"directory?\"", ")", "\n", "\n", "", "training_util", ".", "enable_gradient_clipping", "(", "self", ".", "model", ",", "self", ".", "_grad_clipping", ")", "\n", "\n", "logger", ".", "info", "(", "\"Beginning training.\"", ")", "\n", "\n", "train_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "val_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "this_epoch_val_metric", ":", "float", "=", "None", "\n", "metrics", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "epochs_trained", "=", "0", "\n", "training_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "metrics", "[", "'best_epoch'", "]", "=", "self", ".", "_metric_tracker", ".", "best_epoch", "\n", "for", "key", ",", "value", "in", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "for", "epoch", "in", "range", "(", "epoch_counter", ",", "self", ".", "_num_epochs", ")", ":", "\n", "            ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "train_metrics", "=", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "\n", "# get peak of memory usage", "\n", "if", "'cpu_memory_MB'", "in", "train_metrics", ":", "\n", "                ", "metrics", "[", "'peak_cpu_memory_MB'", "]", "=", "max", "(", "metrics", ".", "get", "(", "'peak_cpu_memory_MB'", ",", "0", ")", ",", "\n", "train_metrics", "[", "'cpu_memory_MB'", "]", ")", "\n", "", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "'gpu_'", ")", ":", "\n", "                    ", "metrics", "[", "\"peak_\"", "+", "key", "]", "=", "max", "(", "metrics", ".", "get", "(", "\"peak_\"", "+", "key", ",", "0", ")", ",", "value", ")", "\n", "\n", "", "", "if", "self", ".", "_validation_data", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# We have a validation set, so compute all the metrics on it.", "\n", "                    ", "val_loss", ",", "num_batches", "=", "self", ".", "_validation_loss", "(", ")", "\n", "val_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "val_loss", ",", "num_batches", ",", "reset", "=", "True", ")", "\n", "\n", "# Check validation metric for early stopping", "\n", "this_epoch_val_metric", "=", "val_metrics", "[", "self", ".", "_validation_metric", "]", "\n", "self", ".", "_metric_tracker", ".", "add_metric", "(", "this_epoch_val_metric", ")", "\n", "\n", "if", "self", ".", "_metric_tracker", ".", "should_stop_early", "(", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "", "", "", "self", ".", "_tensorboard", ".", "log_metrics", "(", "train_metrics", ",", "\n", "val_metrics", "=", "val_metrics", ",", "\n", "log_to_console", "=", "True", ",", "\n", "epoch", "=", "epoch", "+", "1", ")", "# +1 because tensorboard doesn't like 0", "\n", "\n", "# Create overall metrics dict", "\n", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "metrics", "[", "\"training_duration\"", "]", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "training_elapsed_time", ")", ")", "\n", "metrics", "[", "\"training_start_epoch\"", "]", "=", "epoch_counter", "\n", "metrics", "[", "\"training_epochs\"", "]", "=", "epochs_trained", "\n", "metrics", "[", "\"epoch\"", "]", "=", "epoch", "\n", "\n", "for", "key", ",", "value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "                ", "metrics", "[", "\"training_\"", "+", "key", "]", "=", "value", "\n", "", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                ", "metrics", "[", "\"validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "if", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ":", "\n", "# Update all the best_ metrics.", "\n", "# (Otherwise they just stay the same as they were.)", "\n", "                ", "metrics", "[", "'best_epoch'", "]", "=", "epoch", "\n", "for", "key", ",", "value", "in", "val_metrics", ".", "items", "(", ")", ":", "\n", "                    ", "metrics", "[", "\"best_validation_\"", "+", "key", "]", "=", "value", "\n", "\n", "", "self", ".", "_metric_tracker", ".", "best_epoch_metrics", "=", "val_metrics", "\n", "\n", "", "if", "self", ".", "_serialization_dir", ":", "\n", "                ", "dump_metrics", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_serialization_dir", ",", "f'metrics_epoch_{epoch}.json'", ")", ",", "metrics", ")", "\n", "\n", "# The Scheduler API is agnostic to whether your schedule requires a validation metric -", "\n", "# if it doesn't, the validation metric passed here is ignored.", "\n", "", "if", "self", ".", "_learning_rate_scheduler", ":", "\n", "                ", "self", ".", "_learning_rate_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", ":", "\n", "                ", "self", ".", "_momentum_scheduler", ".", "step", "(", "this_epoch_val_metric", ",", "epoch", ")", "\n", "\n", "", "self", ".", "_save_checkpoint", "(", "epoch", ")", "\n", "\n", "epoch_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "logger", ".", "info", "(", "\"Epoch duration: %s\"", ",", "datetime", ".", "timedelta", "(", "seconds", "=", "epoch_elapsed_time", ")", ")", "\n", "\n", "if", "epoch", "<", "self", ".", "_num_epochs", "-", "1", ":", "\n", "                ", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "training_start_time", "\n", "estimated_time_remaining", "=", "training_elapsed_time", "*", "(", "(", "self", ".", "_num_epochs", "-", "epoch_counter", ")", "/", "float", "(", "epoch", "-", "epoch_counter", "+", "1", ")", "-", "1", ")", "\n", "formatted_time", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "estimated_time_remaining", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Estimated training time remaining: %s\"", ",", "formatted_time", ")", "\n", "\n", "", "epochs_trained", "+=", "1", "\n", "\n", "# make sure pending events are flushed to disk and files are closed properly", "\n", "", "self", ".", "_tensorboard", ".", "close", "(", ")", "\n", "\n", "# Load the best model state before returning", "\n", "best_model_state", "=", "self", ".", "_checkpointer", ".", "best_model_state", "(", ")", "\n", "if", "best_model_state", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._save_checkpoint": [[681, 719], ["trainer.MatchingTrainer._checkpointer.save_checkpoint", "trainer.MatchingTrainer._moving_average.assign_average_value", "trainer.MatchingTrainer._metric_tracker.state_dict", "trainer.MatchingTrainer.optimizer.state_dict", "trainer.MatchingTrainer._learning_rate_scheduler.state_dict", "trainer.MatchingTrainer._momentum_scheduler.state_dict", "trainer.MatchingTrainer._moving_average.restore", "trainer.MatchingTrainer.model.state_dict", "trainer.MatchingTrainer._metric_tracker.is_best_so_far"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.save_checkpoint"], ["", "def", "_save_checkpoint", "(", "self", ",", "epoch", ":", "Union", "[", "int", ",", "str", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves a checkpoint of the model to self._serialization_dir.\n        Is a no-op if self._serialization_dir is None.\n\n        Parameters\n        ----------\n        epoch : Union[int, str], required.\n            The epoch of training.  If the checkpoint is saved in the middle\n            of an epoch, the parameter is a string with the epoch and timestamp.\n        \"\"\"", "\n", "# If moving averages are used for parameters, we save", "\n", "# the moving average values into checkpoint, instead of the current values.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "assign_average_value", "(", ")", "\n", "\n", "# These are the training states we need to persist.", "\n", "", "training_states", "=", "{", "\n", "\"metric_tracker\"", ":", "self", ".", "_metric_tracker", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"batch_num_total\"", ":", "self", ".", "_batch_num_total", "\n", "}", "\n", "\n", "# If we have a learning rate or momentum scheduler, we should persist them too.", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"learning_rate_scheduler\"", "]", "=", "self", ".", "_learning_rate_scheduler", ".", "state_dict", "(", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", ":", "\n", "            ", "training_states", "[", "\"momentum_scheduler\"", "]", "=", "self", ".", "_momentum_scheduler", ".", "state_dict", "(", ")", "\n", "\n", "", "self", ".", "_checkpointer", ".", "save_checkpoint", "(", "\n", "model_state", "=", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "epoch", "=", "epoch", ",", "\n", "training_states", "=", "training_states", ",", "\n", "is_best_so_far", "=", "self", ".", "_metric_tracker", ".", "is_best_so_far", "(", ")", ")", "\n", "\n", "# Restore the original values for parameters so that training will not be affected.", "\n", "if", "self", ".", "_moving_average", "is", "not", "None", ":", "\n", "            ", "self", ".", "_moving_average", ".", "restore", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer._restore_checkpoint": [[720, 775], ["trainer.MatchingTrainer._checkpointer.restore_checkpoint", "trainer.MatchingTrainer.model.load_state_dict", "trainer.MatchingTrainer.optimizer.load_state_dict", "allennlp.training.util.move_optimizer_to_cuda", "isinstance", "training_state.get", "trainer.MatchingTrainer._learning_rate_scheduler.load_state_dict", "trainer.MatchingTrainer._momentum_scheduler.load_state_dict", "trainer.MatchingTrainer._metric_tracker.load_state_dict", "trainer.MatchingTrainer._metric_tracker.clear", "trainer.MatchingTrainer._metric_tracker.add_metrics", "trainer.MatchingTrainer._metric_tracker.clear", "int", "training_state[].split"], "methods", ["None"], ["", "", "def", "_restore_checkpoint", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Restores the model and training state from the last saved checkpoint.\n        This includes an epoch count and optimizer state, which is serialized separately\n        from model parameters. This function should only be used to continue training -\n        if you wish to load a model for inference/load parts of a model into a new\n        computation graph, you should use the native Pytorch functions:\n        `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``\n\n        If ``self._serialization_dir`` does not exist or does not contain any checkpointed weights,\n        this function will do nothing and return 0.\n\n        Returns\n        -------\n        epoch: int\n            The epoch at which to resume training, which should be one after the epoch\n            in the saved training state.\n        \"\"\"", "\n", "model_state", ",", "training_state", "=", "self", ".", "_checkpointer", ".", "restore_checkpoint", "(", ")", "\n", "\n", "if", "not", "training_state", ":", "\n", "# No checkpoint to restore, start at 0", "\n", "            ", "return", "0", "\n", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "model_state", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "training_state", "[", "\"optimizer\"", "]", ")", "\n", "if", "self", ".", "_learning_rate_scheduler", "is", "not", "None", "and", "\"learning_rate_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_learning_rate_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"learning_rate_scheduler\"", "]", ")", "\n", "", "if", "self", ".", "_momentum_scheduler", "is", "not", "None", "and", "\"momentum_scheduler\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_momentum_scheduler", ".", "load_state_dict", "(", "training_state", "[", "\"momentum_scheduler\"", "]", ")", "\n", "", "training_util", ".", "move_optimizer_to_cuda", "(", "self", ".", "optimizer", ")", "\n", "\n", "# Currently the ``training_state`` contains a serialized ``MetricTracker``.", "\n", "if", "\"metric_tracker\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "load_state_dict", "(", "training_state", "[", "\"metric_tracker\"", "]", ")", "\n", "# It used to be the case that we tracked ``val_metric_per_epoch``.", "\n", "", "elif", "\"val_metric_per_epoch\"", "in", "training_state", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "self", ".", "_metric_tracker", ".", "add_metrics", "(", "training_state", "[", "\"val_metric_per_epoch\"", "]", ")", "\n", "# And before that we didn't track anything.", "\n", "", "else", ":", "\n", "            ", "self", ".", "_metric_tracker", ".", "clear", "(", ")", "\n", "\n", "", "if", "isinstance", "(", "training_state", "[", "\"epoch\"", "]", ",", "int", ")", ":", "\n", "            ", "epoch_to_return", "=", "training_state", "[", "\"epoch\"", "]", "+", "1", "\n", "", "else", ":", "\n", "            ", "epoch_to_return", "=", "int", "(", "training_state", "[", "\"epoch\"", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "+", "1", "\n", "\n", "# For older checkpoints with batch_num_total missing, default to old behavior where", "\n", "# it is unchanged.", "\n", "", "batch_num_total", "=", "training_state", ".", "get", "(", "'batch_num_total'", ")", "\n", "if", "batch_num_total", "is", "not", "None", ":", "\n", "            ", "self", ".", "_batch_num_total", "=", "batch_num_total", "\n", "\n", "", "return", "epoch_to_return", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params": [[777, 879], ["allennlp.training.trainer_pieces.TrainerPieces.from_params", "params.pop_int", "params.pop", "params.pop_bool", "params.pop_int", "allennlp.common.checks.parse_cuda_device", "params.pop_float", "params.pop_float", "params.pop", "params.pop", "params.pop", "isinstance", "allennlp.training.optimizers.Optimizer.from_params", "params.pop_float", "params.pop_int", "params.pop_int", "params.pop_bool", "params.pop_bool", "params.pop_int", "params.assert_empty", "cls", "params.pop", "model.cuda.cuda.cuda", "params.pop", "allennlp.training.moving_average.MovingAverage.from_params", "allennlp.training.learning_rate_schedulers.LearningRateScheduler.from_params", "allennlp.training.momentum_schedulers.MomentumScheduler.from_params", "allennlp.training.checkpointer.Checkpointer.from_params", "params.pop_int", "params.pop_int", "allennlp.training.checkpointer.Checkpointer", "model.cuda.cuda.named_parameters", "params.pop", "allennlp.common.checks.ConfigurationError", "params.pop"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params", "home.repos.pwc.inspect_result.allenai_medicat.matching.trainer.MatchingTrainer.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "# type: ignore", "\n", "params", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "recover", ":", "bool", ",", "\n", "cache_directory", ":", "str", ",", "\n", "cache_prefix", ":", "str", ")", "->", "'MatchingTrainer'", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "pieces", "=", "TrainerPieces", ".", "from_params", "(", "params", ",", "# pylint: disable=no-member", "\n", "serialization_dir", ",", "\n", "recover", ",", "\n", "cache_directory", ",", "\n", "cache_prefix", ")", "\n", "model", "=", "pieces", ".", "model", "\n", "iterator", "=", "pieces", ".", "iterator", "\n", "train_data", "=", "pieces", ".", "train_dataset", "\n", "validation_data", "=", "pieces", ".", "validation_dataset", "\n", "params", "=", "pieces", ".", "params", "\n", "validation_iterator", "=", "pieces", ".", "validation_iterator", "\n", "\n", "patience", "=", "params", ".", "pop_int", "(", "\"patience\"", ",", "None", ")", "\n", "validation_metric", "=", "params", ".", "pop", "(", "\"validation_metric\"", ",", "\"-loss\"", ")", "\n", "shuffle", "=", "params", ".", "pop_bool", "(", "\"shuffle\"", ",", "True", ")", "\n", "num_epochs", "=", "params", ".", "pop_int", "(", "\"num_epochs\"", ",", "20", ")", "\n", "cuda_device", "=", "parse_cuda_device", "(", "params", ".", "pop", "(", "\"cuda_device\"", ",", "-", "1", ")", ")", "\n", "grad_norm", "=", "params", ".", "pop_float", "(", "\"grad_norm\"", ",", "None", ")", "\n", "grad_clipping", "=", "params", ".", "pop_float", "(", "\"grad_clipping\"", ",", "None", ")", "\n", "lr_scheduler_params", "=", "params", ".", "pop", "(", "\"learning_rate_scheduler\"", ",", "None", ")", "\n", "momentum_scheduler_params", "=", "params", ".", "pop", "(", "\"momentum_scheduler\"", ",", "None", ")", "\n", "retrieve_text", "=", "params", ".", "pop", "(", "\"retrieve_text\"", ",", "True", ")", "\n", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "            ", "model_device", "=", "cuda_device", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "model_device", "=", "cuda_device", "\n", "", "if", "model_device", ">=", "0", ":", "\n", "# Moving model to GPU here so that the optimizer state gets constructed on", "\n", "# the right device.", "\n", "            ", "model", "=", "model", ".", "cuda", "(", "model_device", ")", "\n", "\n", "", "parameters", "=", "[", "[", "n", ",", "p", "]", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", "=", "Optimizer", ".", "from_params", "(", "parameters", ",", "params", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "if", "\"moving_average\"", "in", "params", ":", "\n", "            ", "moving_average", "=", "MovingAverage", ".", "from_params", "(", "params", ".", "pop", "(", "\"moving_average\"", ")", ",", "parameters", "=", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "moving_average", "=", "None", "\n", "\n", "", "if", "lr_scheduler_params", ":", "\n", "            ", "lr_scheduler", "=", "LearningRateScheduler", ".", "from_params", "(", "optimizer", ",", "lr_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "None", "\n", "", "if", "momentum_scheduler_params", ":", "\n", "            ", "momentum_scheduler", "=", "MomentumScheduler", ".", "from_params", "(", "optimizer", ",", "momentum_scheduler_params", ")", "\n", "", "else", ":", "\n", "            ", "momentum_scheduler", "=", "None", "\n", "\n", "", "if", "'checkpointer'", "in", "params", ":", "\n", "            ", "if", "'keep_serialized_model_every_num_seconds'", "in", "params", "or", "'num_serialized_models_to_keep'", "in", "params", ":", "\n", "                ", "raise", "ConfigurationError", "(", "\n", "\"Checkpointer may be initialized either from the 'checkpointer' key or from the \"", "\n", "\"keys 'num_serialized_models_to_keep' and 'keep_serialized_model_every_num_seconds'\"", "\n", "\" but the passed config uses both methods.\"", ")", "\n", "", "checkpointer", "=", "Checkpointer", ".", "from_params", "(", "params", ".", "pop", "(", "\"checkpointer\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "num_serialized_models_to_keep", "=", "params", ".", "pop_int", "(", "\"num_serialized_models_to_keep\"", ",", "20", ")", "\n", "keep_serialized_model_every_num_seconds", "=", "params", ".", "pop_int", "(", "\n", "\"keep_serialized_model_every_num_seconds\"", ",", "None", ")", "\n", "checkpointer", "=", "Checkpointer", "(", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "num_serialized_models_to_keep", ",", "\n", "keep_serialized_model_every_num_seconds", "=", "keep_serialized_model_every_num_seconds", ")", "\n", "", "model_save_interval", "=", "params", ".", "pop_float", "(", "\"model_save_interval\"", ",", "None", ")", "\n", "summary_interval", "=", "params", ".", "pop_int", "(", "\"summary_interval\"", ",", "100", ")", "\n", "histogram_interval", "=", "params", ".", "pop_int", "(", "\"histogram_interval\"", ",", "None", ")", "\n", "should_log_parameter_statistics", "=", "params", ".", "pop_bool", "(", "\"should_log_parameter_statistics\"", ",", "True", ")", "\n", "should_log_learning_rate", "=", "params", ".", "pop_bool", "(", "\"should_log_learning_rate\"", ",", "False", ")", "\n", "log_batch_size_period", "=", "params", ".", "pop_int", "(", "\"log_batch_size_period\"", ",", "None", ")", "\n", "\n", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "model", ",", "optimizer", ",", "iterator", ",", "\n", "train_data", ",", "validation_data", ",", "\n", "patience", "=", "patience", ",", "\n", "retrieve_text", "=", "retrieve_text", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_iterator", "=", "validation_iterator", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "cuda_device", "=", "cuda_device", ",", "\n", "grad_norm", "=", "grad_norm", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "\n", "learning_rate_scheduler", "=", "lr_scheduler", ",", "\n", "momentum_scheduler", "=", "momentum_scheduler", ",", "\n", "checkpointer", "=", "checkpointer", ",", "\n", "model_save_interval", "=", "model_save_interval", ",", "\n", "summary_interval", "=", "summary_interval", ",", "\n", "histogram_interval", "=", "histogram_interval", ",", "\n", "should_log_parameter_statistics", "=", "should_log_parameter_statistics", ",", "\n", "should_log_learning_rate", "=", "should_log_learning_rate", ",", "\n", "log_batch_size_period", "=", "log_batch_size_period", ",", "\n", "moving_average", "=", "moving_average", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.__init__": [[25, 77], ["allennlp.models.Model.__init__", "torchvision.models.resnet50", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "transformers.BertConfig.from_json_file", "transformers.BertTokenizer", "matching.visbert.VisBertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "allennlp.training.metrics.CategoricalAccuracy", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "model.ImageTextMatchingModel.bert.load_state_dict", "torchvision.transforms.Compose", "open", "open.readlines", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.CategoricalAccuracy", "os.path.join", "os.path.join", "PIL.Image.open().convert", "model.ImageTextMatchingModel.images.append", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "json.loads", "model.ImageTextMatchingModel.image_transform", "len", "PIL.Image.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["self", ".", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "_dropout_prob", ",", "inplace", "=", "False", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "vocab", ".", "get_vocab_size", "(", "self", ".", "_label_namespace", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "backbone", "==", "'vgg16'", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "backbone_classifier", "=", "list", "(", "self", ".", "model", ".", "classifier", ".", "children", "(", ")", ")", "\n", "backbone_classifier", ".", "pop", "(", ")", "\n", "self", ".", "feature_dim", "=", "4096", "\n", "backbone_classifier", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "self", ".", "vocab", ".", "get_vocab_size", "(", "self", ".", "_label_namespace", ")", ")", ")", "\n", "self", ".", "model", ".", "classifier", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "backbone_classifier", ")", "\n", "self", ".", "_dropout_prob", "=", "0.0", "\n", "\n", "", "self", ".", "loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "f1", "=", "F1Measure", "(", "self", ".", "vocab", ".", "get_token_index", "(", "'Medical images'", ",", "self", ".", "_label_namespace", ")", ")", "\n", "", "def", "forward", "(", "self", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "image_id", ":", "List", "[", "str", "]", ",", "\n", "label", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "predictions", "=", "self", ".", "model", "(", "image", ")", "\n", "\n", "outputs", "=", "{", "'predictions'", ":", "predictions", ",", "'image_id'", ":", "image_id", "}", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "loss", "(", "predictions", ",", "label", ")", "\n", "outputs", "[", "'loss'", "]", "=", "loss", "\n", "self", ".", "f1", "(", "predictions", ",", "label", ")", "\n", "self", ".", "accuracy", "(", "predictions", ",", "label", ")", "\n", "", "return", "outputs", "\n", "", "def", "get_metrics", "(", "self", ",", "\n", "reset", ":", "bool", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "precision", ",", "recall", ",", "f1", "=", "self", ".", "f1", ".", "get_metric", "(", "reset", ")", "\n", "return", "{", "'medical_f1'", ":", "f1", ",", "\n", "'medical_precision'", ":", "precision", ",", "\n", "'medical_recall'", ":", "recall", ",", "\n", "'accuracy'", ":", "self", ".", "accuracy", ".", "get_metric", "(", "reset", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.forward": [[78, 152], ["min", "model.ImageTextMatchingModel.image_feature_extractor", "visual_feats.view().repeat.view().repeat.view", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "model.ImageTextMatchingModel.bert", "allennlp.nn.util.get_text_field_mask", "token_ids.repeat().view.repeat().view.repeat().view", "input_mask.repeat().view.repeat().view.repeat().view", "segment_ids.repeat().view.repeat().view.repeat().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "joint_representation.view.view.view", "model.ImageTextMatchingModel.matching_classifier().view", "images.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat().view", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "model.ImageTextMatchingModel.loss", "model.ImageTextMatchingModel.accuracy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "set", "range", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "model.ImageTextMatchingModel.loss", "model.ImageTextMatchingModel.accuracy", "model.ImageTextMatchingModel.top5_accuracy", "model.ImageTextMatchingModel.top10_accuracy", "model.ImageTextMatchingModel.top20_accuracy", "token_ids.repeat().view.repeat().view.repeat", "input_mask.repeat().view.repeat().view.repeat", "segment_ids.repeat().view.repeat().view.repeat", "model.ImageTextMatchingModel.matching_classifier", "model.ImageTextMatchingModel.images[].to", "model.ImageTextMatchingModel.image_feature_extractor", "visual_feats.view().repeat.view().repeat.view().repeat", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "torch.zeros().to().float", "input_token_ids.repeat().view", "input_mask.repeat().view.repeat().view.repeat().view", "segment_ids.repeat().view.repeat().view.repeat().view", "model.ImageTextMatchingModel.bert", "joint_representation.view.view.view", "model.ImageTextMatchingModel.matching_classifier().view", "images.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "visual_feats.view().repeat.view().repeat.view", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "input_token_ids.repeat", "input_mask.repeat().view.repeat().view.repeat", "segment_ids.repeat().view.repeat().view.repeat", "model.ImageTextMatchingModel.matching_classifier", "images.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.accuracy", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.utils.accuracy"], []], "home.repos.pwc.inspect_result.allenai_medicat.matching.model.ImageTextMatchingModel.get_metrics": [[153, 160], ["model.ImageTextMatchingModel.accuracy.get_metric", "model.ImageTextMatchingModel.top5_accuracy.get_metric", "model.ImageTextMatchingModel.top10_accuracy.get_metric", "model.ImageTextMatchingModel.top20_accuracy.get_metric"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric", "home.repos.pwc.inspect_result.allenai_medicat.subcaption.subfigure_subcaption_metric.SubfigureSubcaptionAlignmentMetric.get_metric"], []], "home.repos.pwc.inspect_result.allenai_medicat.matching.visbert.BertEncoder.__init__": [[10, 17], ["super().__init__", "torch.nn.ModuleList", "transformers.modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "visual_start_layer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "False", "# config.output_attentions", "\n", "self", ".", "output_hidden_states", "=", "True", "# config.output_hidden_states", "\n", "self", ".", "visual_start_layer", "=", "visual_start_layer", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "layer", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.visbert.BertEncoder.forward": [[18, 64], ["enumerate", "layer_module", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "visual_states.unsqueeze", "attention_mask[].repeat", "attention_mask[].repeat"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "visual_states", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "exit_layer", "=", "None", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "if", "head_mask", "is", "None", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "i", "==", "self", ".", "visual_start_layer", "and", "visual_states", "is", "not", "None", ":", "\n", "                ", "if", "len", "(", "visual_states", ".", "shape", ")", "==", "3", ":", "\n", "                    ", "attention_mask", "=", "torch", ".", "cat", "(", "(", "attention_mask", ",", "torch", ".", "zeros_like", "(", "attention_mask", "[", ":", ",", ":", ",", ":", ",", ":", "1", "]", ".", "repeat", "(", "1", ",", "1", ",", "1", ",", "visual_states", ".", "shape", "[", "1", "]", ")", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "attention_mask", "=", "torch", ".", "cat", "(", "(", "attention_mask", ",", "torch", ".", "zeros_like", "(", "attention_mask", "[", ":", ",", ":", ",", ":", "1", ",", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "visual_states", ".", "shape", "[", "1", "]", ",", "1", ")", ")", ")", ",", "dim", "=", "-", "2", ")", "\n", "hidden_states", "=", "torch", ".", "cat", "(", "(", "hidden_states", ",", "visual_states", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "attention_mask", "=", "torch", ".", "cat", "(", "(", "attention_mask", ",", "torch", ".", "zeros_like", "(", "attention_mask", "[", ":", ",", ":", ",", ":", ",", ":", "1", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "hidden_states", "=", "torch", ".", "cat", "(", "(", "hidden_states", ",", "visual_states", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", "=", "hidden_states", ",", "attention_mask", "=", "attention_mask", ",", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "encoder_attention_mask", "=", "encoder_attention_mask", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "", "if", "exit_layer", "==", "i", ":", "\n", "                ", "break", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.visbert.VisBertModel.__init__": [[66, 84], ["transformers.BertPreTrainedModel.__init__", "transformers.modeling_bert.BertEmbeddings", "torch.nn.Linear", "visbert.BertEncoder", "transformers.modeling_bert.BertPooler", "torch.nn.Dropout", "visbert.VisBertModel.apply", "torch.nn.Embedding", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "visual_feat_size", ",", "visual_start_layer", ",", "num_visual_positions", ",", "use_pos_embedding", "=", "False", ",", "no_encoder_inputs", "=", "False", ",", "append_to_encoder_states", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "use_pos_embedding", "=", "use_pos_embedding", "\n", "if", "use_pos_embedding", ":", "\n", "            ", "self", ".", "visual_pos_embeddings", "=", "torch", ".", "nn", ".", "Embedding", "(", "num_visual_positions", ",", "config", ".", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visual_pos_embeddings", "=", "torch", ".", "nn", ".", "Linear", "(", "4", ",", "config", ".", "hidden_size", ")", "\n", "", "self", ".", "visual_feat_size", "=", "visual_feat_size", "\n", "self", ".", "visual_start_layer", "=", "visual_start_layer", "\n", "self", ".", "num_visual_positions", "=", "num_visual_positions", "\n", "self", ".", "visual_feat_projection", "=", "torch", ".", "nn", ".", "Linear", "(", "visual_feat_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ",", "visual_start_layer", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "dropout_layer", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "self", ".", "no_encoder_inputs", "=", "no_encoder_inputs", "\n", "self", ".", "append_to_encoder_states", "=", "append_to_encoder_states", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.visbert.VisBertModel.init_bert_weights": [[85, 97], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "torch", ".", "nn", ".", "Linear", ",", "torch", ".", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.visbert.VisBertModel.forward": [[98, 182], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "visbert.VisBertModel.embeddings", "visbert.VisBertModel.encoder", "torch.ones_like", "torch.zeros_like", "torch.zeros_like().float.unsqueeze().unsqueeze", "extended_visual_attention_mask.to.to.to", "torch.cat.size", "visbert.VisBertModel.invert_attention_mask", "visbert.VisBertModel.pooler", "torch.ones_like.unsqueeze", "torch.ones", "visbert.VisBertModel.dropout_layer", "visbert.VisBertModel.dropout_layer", "torch.zeros_like().float", "next", "torch.zeros_like().float.unsqueeze", "torch.cat", "torch.cat", "visbert.VisBertModel.parameters", "next", "visbert.VisBertModel.visual_pos_embeddings", "visbert.VisBertModel.visual_feat_projection", "visbert.VisBertModel.visual_pos_embeddings", "visbert.VisBertModel.visual_feat_projection", "torch.zeros_like", "visbert.VisBertModel.parameters"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "visual_inputs", "=", "None", ",", "visual_attention_mask", "=", "None", ",", "exit_layer", "=", "None", ",", "pool", "=", "True", ",", "\n", "encoder_hidden_states", "=", "None", ",", "encoder_attention_mask", "=", "None", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\"\"\"input_shape = input_ids.size()\n        extended_attention_mask = self.get_extended_attention_mask(attention_mask, input_shape, self.device)\"\"\"", "\n", "\n", "# Process the visual attention mask", "\n", "if", "visual_attention_mask", "is", "not", "None", ":", "\n", "            ", "extended_visual_attention_mask", "=", "visual_attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "extended_visual_attention_mask", "=", "extended_visual_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_visual_attention_mask", "=", "(", "1.0", "-", "extended_visual_attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "extended_visual_attention_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "", "if", "self", ".", "no_encoder_inputs", ":", "\n", "            ", "encoder_hidden_states", "=", "None", "\n", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Positional Word Embeddings", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "\n", "# Visual input projection", "\n", "if", "visual_inputs", ":", "\n", "            ", "pos", ",", "img_feats", "=", "visual_inputs", "\n", "if", "self", ".", "use_pos_embedding", ":", "\n", "                ", "visual_embeddings", "=", "self", ".", "dropout_layer", "(", "self", ".", "visual_pos_embeddings", "(", "pos", ")", "+", "self", ".", "visual_feat_projection", "(", "img_feats", ")", ")", "\n", "", "else", ":", "\n", "                ", "visual_embeddings", "=", "self", ".", "dropout_layer", "(", "self", ".", "visual_pos_embeddings", "(", "pos", ")", "+", "self", ".", "visual_feat_projection", "(", "img_feats", ")", ")", "\n", "", "if", "self", ".", "append_to_encoder_states", ":", "\n", "                ", "assert", "self", ".", "use_pos_embedding", "\n", "visual_attention_mask", "=", "torch", ".", "zeros_like", "(", "visual_embeddings", "[", ":", ",", ":", ",", "0", "]", ")", ".", "float", "(", ")", "\n", "visual_attention_mask", "=", "visual_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "if", "self", ".", "no_encoder_inputs", ":", "\n", "                    ", "encoder_hidden_states", "=", "visual_embeddings", "\n", "encoder_extended_attention_mask", "=", "visual_attention_mask", "\n", "", "else", ":", "\n", "                    ", "encoder_hidden_states", "=", "torch", ".", "cat", "(", "(", "encoder_hidden_states", ",", "visual_embeddings", ")", ",", "dim", "=", "1", ")", "\n", "encoder_extended_attention_mask", "=", "torch", ".", "cat", "(", "(", "encoder_extended_attention_mask", ",", "visual_attention_mask", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "visual_embeddings", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "visual_embeddings", "=", "None", "\n", "\n", "# Run LXRT backbone", "\n", "", "outputs", "=", "self", ".", "encoder", "(", "\n", "hidden_states", "=", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "visual_states", "=", "visual_embeddings", ",", "\n", "exit_layer", "=", "exit_layer", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", "\n", ")", "\n", "if", "pool", ":", "\n", "            ", "pooled_output", "=", "self", ".", "pooler", "(", "outputs", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "pooled_output", "=", "outputs", "[", "0", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "", "return", "outputs", "[", "0", "]", ",", "pooled_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__": [[28, 46], ["allennlp.data.dataset_readers.DatasetReader.__init__", "transformers.BertConfig.from_json_file", "transformers.BertTokenizer", "torchvision.transforms.Compose", "allennlp.data.tokenizers.WordTokenizer", "os.path.join", "matching.token_indexer.BertFromConfigIndexer", "os.path.join", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.__init__"], ["def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "input_file", "=", "open", "(", "file_path", ")", "\n", "lines", "=", "input_file", ".", "readlines", "(", ")", "\n", "if", "'json'", "in", "file_path", ":", "\n", "            ", "data", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "for", "i", ",", "datum", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "image_id", "=", "datum", "[", "'pdf_hash'", "]", "+", "'_'", "+", "datum", "[", "'fig_uri'", "]", "\n", "label", "=", "\"\"", "\n", "image_root", "=", "self", ".", "image_root", "\n", "if", "'image_root'", "in", "datum", "and", "datum", "[", "'image_root'", "]", "is", "not", "None", ":", "\n", "                    ", "image_root", "=", "datum", "[", "'image_root'", "]", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "image_id", "=", "image_id", ",", "label", "=", "label", ",", "image_root", "=", "image_root", ")", "\n", "if", "instance", "is", "not", "None", ":", "\n", "                        ", "yield", "instance", "\n", "", "", "", "", "else", ":", "\n", "            ", "for", "index", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                ", "parts", "=", "line", ".", "split", "(", "', '", ")", "\n", "image_id", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "label", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader._read": [[47, 73], ["isinstance", "open", "open.readlines", "enumerate", "json.loads", "os.path.join", "PIL.Image.open().convert", "zip", "PIL.Image.open", "dataset_reader.MatchingDatasetReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance"], ["yield", "self", ".", "text_to_instance", "(", "image_id", ",", "label", ")", "\n", "\n", "", "", "", "def", "text_to_instance", "(", "self", ",", "\n", "image_id", ":", "str", ",", "\n", "label", ":", "str", ",", "\n", "image_root", ":", "str", "=", "None", ")", "->", "Instance", ":", "\n", "        ", "if", "image_root", "is", "None", ":", "\n", "            ", "image_root", "=", "self", ".", "image_root", "\n", "", "try", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "image_root", ",", "image_id", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "except", ":", "\n", "            ", "return", "None", "\n", "", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "fields", "[", "'image'", "]", "=", "ArrayField", "(", "self", ".", "image_transform", "(", "image", ")", ".", "numpy", "(", ")", ")", "\n", "if", "len", "(", "label", ")", ">", "0", ":", "\n", "            ", "fields", "[", "'label'", "]", "=", "LabelField", "(", "label", ")", "\n", "", "fields", "[", "'image_id'", "]", "=", "MetadataField", "(", "image_id", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_medicat.matching.dataset_reader.MatchingDatasetReader.text_to_instance": [[74, 93], ["dataset_reader.MatchingDatasetReader.image_transform", "dataset_reader.MatchingDatasetReader.tokenizer.tokenize", "allennlp.data.fields.TextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "allennlp.data.Token", "dataset_reader.MatchingDatasetReader.numpy", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "numpy.zeros", "len", "numpy.ones", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_medicat.subcaption.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer.tokenize"], []]}