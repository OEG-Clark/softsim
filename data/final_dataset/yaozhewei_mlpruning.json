{"home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.set_seed": [[51, 57], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.remain_param_compute": [[59, 72], ["torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "fc1.type", "fc1.type", "fc1.type", "fc1.type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max().type", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "fc1.type", "fc1.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "", "def", "remain_param_compute", "(", "threshold_list", ")", ":", "\n", "    ", "output", "=", "0.", "\n", "\n", "attn", ",", "o_matrix", ",", "fc1", ",", "fc2", "=", "threshold_list", "\n", "output", "+=", "torch", ".", "max", "(", "attn", ",", "torch", ".", "tensor", "(", "1", "/", "12.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "*", "3", "\n", "output", "+=", "torch", ".", "max", "(", "attn", ",", "torch", ".", "tensor", "(", "1", "/", "12.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "*", "torch", ".", "max", "(", "o_matrix", ",", "torch", ".", "tensor", "(", "1", "/", "768.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "\n", "output", "+=", "torch", ".", "max", "(", "fc1", ",", "torch", ".", "tensor", "(", "1", "/", "3072.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "*", "4", "\n", "output", "+=", "torch", ".", "max", "(", "fc1", ",", "\n", "torch", ".", "tensor", "(", "1", "/", "3072.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "*", "torch", ".", "max", "(", "fc2", ",", "\n", "torch", ".", "tensor", "(", "1", "/", "768.", ")", ")", ".", "type", "(", "fc1", ".", "type", "(", ")", ")", "*", "4", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.regularization": [[74, 94], ["model.named_parameters", "range", "len", "masked_run_glue.remain_param_compute", "torch.square", "torch.square", "torch.square", "threshold_list.append", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.remain_param_compute"], ["", "def", "regularization", "(", "model", ":", "nn", ".", "Module", ",", "threshold", ":", "float", ")", ":", "\n", "    ", "threshold_list", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'threshold'", "in", "name", ":", "\n", "            ", "threshold_list", ".", "append", "(", "torch", ".", "sigmoid", "(", "param", ")", ")", "\n", "# BERT-base has 12 layers", "\n", "", "", "param_remain", "=", "0", "\n", "layer_num", "=", "12", "\n", "block_num", "=", "len", "(", "threshold_list", ")", "//", "layer_num", "\n", "for", "i", "in", "range", "(", "12", ")", ":", "\n", "        ", "param_remain", "+=", "remain_param_compute", "(", "\n", "threshold_list", "[", "i", "*", "block_num", ":", "(", "i", "+", "1", ")", "*", "block_num", "]", ")", "\n", "\n", "", "if", "param_remain", "/", "144.", "-", "threshold", "<=", "0", ":", "\n", "        ", "reg_loss", "=", "param_remain", "*", "0.", "\n", "", "else", ":", "\n", "# 144 comes from count, use simple sqaure loss", "\n", "        ", "reg_loss", "=", "torch", ".", "square", "(", "param_remain", "/", "144.", "-", "threshold", ")", "\n", "\n", "", "return", "reg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.train": [[96, 398], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "print", "print", "print", "print", "print", "print", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "masked_run_glue.set_seed", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "print", "int", "tqdm.tqdm", "enumerate", "len", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "loss.mean.item", "tqdm.trange.close", "len", "len", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel.", "masked_run_glue.regularization", "max", "loss.mean.mean", "scaler.scale().backward", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "t.to", "len", "len", "int", "zip", "enumerate", "regularization.item", "torch.nn.parallel.DistributedDataParallel.parameters", "scaler.step", "scaler.update", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.get_lr", "print", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "any", "torch.no_grad", "torch.no_grad", "torch.no_grad", "teacher", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.mse_loss", "zip", "torch.mse_loss", "torch.kl_div", "scaler.scale", "masked_run_glue.evaluate", "evaluate.items", "len", "enumerate", "loss_distill.item", "loss_logits.item", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "torch.save", "torch.save", "torch.save", "any", "range", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "range", "att_loss.item", "rep_loss.item", "scaler.state_dict", "os.path.join", "torch.log_softmax", "torch.softmax", "regularization.item", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.train", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.regularization", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.backward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.backward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "teacher", "=", "None", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "len", "(", "train_dataloader", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "\"mask_score\"", "in", "n", "or", "\"threshold\"", "in", "n", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"lr\"", ":", "args", ".", "mask_scores_learning_rate", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "\"mask_score\"", "not", "in", "n", "and", "\"threshold\"", "not", "in", "n", "and", "p", ".", "requires_grad", "and", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "\"mask_score\"", "not", "in", "n", "and", "\"threshold\"", "not", "in", "n", "and", "p", ".", "requires_grad", "and", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", "num_training_steps", "=", "t_total", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "print", "(", "\"***** Running training *****\"", ")", "\n", "print", "(", "f\"  Num examples = {len(train_dataset)}\"", ")", "\n", "print", "(", "f\"  Num Epochs = {args.num_train_epochs}\"", ")", "\n", "print", "(", "\n", "f\"  Instantaneous batch size per GPU = {args.per_gpu_train_batch_size}\"", ")", "\n", "print", "(", "\n", "f\"  Total train batch size (w. parallel, distributed) = {args.train_batch_size}\"", ",", "\n", "\n", ")", "\n", "print", "(", "f\"  Total optimization steps = {t_total}\"", ")", "\n", "# Distillation", "\n", "if", "teacher", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"  Training with distillation\"", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "\n", "int", "(", "args", ".", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"masked_bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "args", ".", "fp16", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# print(outputs)", "\n", "\n", "if", "\"masked\"", "not", "in", "args", ".", "model_type", ":", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "                    ", "loss", ",", "logits_stu", "=", "outputs", ".", "loss", ",", "outputs", ".", "logits", "\n", "", "else", ":", "\n", "                    ", "loss", ",", "logits_stu", ",", "reps_stu", ",", "attentions_stu", "=", "outputs", "\n", "\n", "# Distillation loss", "\n", "", "if", "teacher", "is", "not", "None", ":", "\n", "                    ", "if", "\"token_type_ids\"", "not", "in", "inputs", ":", "\n", "                        ", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "if", "args", ".", "teacher_type", "==", "\"xlm\"", "else", "batch", "[", "2", "]", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "outputs_tea", "=", "teacher", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "token_type_ids", "=", "inputs", "[", "\"token_type_ids\"", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", ")", "\n", "logits_tea", "=", "outputs_tea", ".", "logits", "\n", "reps_tea", ",", "attentions_tea", "=", "outputs_tea", ".", "hidden_states", ",", "outputs_tea", ".", "attentions", "\n", "\n", "", "teacher_layer_num", "=", "len", "(", "attentions_tea", ")", "\n", "student_layer_num", "=", "len", "(", "attentions_stu", ")", "\n", "assert", "teacher_layer_num", "%", "student_layer_num", "==", "0", "\n", "layers_per_block", "=", "int", "(", "\n", "teacher_layer_num", "/", "student_layer_num", ")", "\n", "new_attentions_tea", "=", "[", "attentions_tea", "[", "i", "*", "\n", "layers_per_block", "+", "\n", "layers_per_block", "-", "\n", "1", "]", "for", "i", "in", "range", "(", "student_layer_num", ")", "]", "\n", "\n", "att_loss", ",", "rep_loss", "=", "0", ",", "0", "\n", "for", "student_att", ",", "teacher_att", "in", "zip", "(", "\n", "attentions_stu", ",", "new_attentions_tea", ")", ":", "\n", "                        ", "student_att", "=", "torch", ".", "where", "(", "\n", "student_att", "<=", "-", "1e2", ",", "\n", "torch", ".", "zeros_like", "(", "student_att", ")", ".", "to", "(", "\n", "args", ".", "device", ")", ",", "\n", "student_att", ")", "\n", "teacher_att", "=", "torch", ".", "where", "(", "\n", "teacher_att", "<=", "-", "1e2", ",", "\n", "torch", ".", "zeros_like", "(", "teacher_att", ")", ".", "to", "(", "\n", "args", ".", "device", ")", ",", "\n", "teacher_att", ")", "\n", "\n", "tmp_loss", "=", "F", ".", "mse_loss", "(", "\n", "student_att", ",", "teacher_att", ",", "reduction", "=", "\"mean\"", ",", ")", "\n", "att_loss", "+=", "tmp_loss", "\n", "\n", "", "new_reps_tea", "=", "[", "reps_tea", "[", "i", "*", "layers_per_block", "]", "\n", "for", "i", "in", "range", "(", "student_layer_num", "+", "1", ")", "]", "\n", "new_reps_stu", "=", "reps_stu", "\n", "for", "i_threp", ",", "(", "student_rep", ",", "teacher_rep", ")", "in", "enumerate", "(", "\n", "zip", "(", "new_reps_stu", ",", "new_reps_tea", ")", ")", ":", "\n", "                        ", "tmp_loss", "=", "F", ".", "mse_loss", "(", "\n", "student_rep", ",", "teacher_rep", ",", "reduction", "=", "\"mean\"", ",", ")", "\n", "rep_loss", "+=", "tmp_loss", "\n", "\n", "", "loss_logits", "=", "F", ".", "kl_div", "(", "\n", "input", "=", "F", ".", "log_softmax", "(", "logits_stu", "/", "args", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "F", ".", "softmax", "(", "logits_tea", "/", "args", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "reduction", "=", "\"batchmean\"", ",", "\n", ")", "*", "(", "args", ".", "temperature", "**", "2", ")", "\n", "\n", "loss_distill", "=", "loss_logits", "+", "rep_loss", "+", "att_loss", "\n", "loss", "=", "args", ".", "alpha_distil", "*", "loss_distill", "+", "args", ".", "alpha_ce", "*", "loss", "\n", "\n", "", "", "if", "args", ".", "final_threshold", "<", "1", ":", "\n", "# for pruning", "\n", "                ", "regu_", "=", "regularization", "(", "\n", "model", "=", "model", ",", "threshold", "=", "args", ".", "final_threshold", ")", "\n", "regu_lambda", "=", "max", "(", "args", ".", "final_lambda", "*", "regu_", ".", "item", "(", ")", "/", "\n", "(", "1", "-", "args", ".", "final_threshold", ")", "/", "(", "1", "-", "args", ".", "final_threshold", ")", ",", "50", ")", "\n", "if", "regu_", ".", "item", "(", ")", "<", "0.0003", ":", "\n", "# when the loss is very small, no need to pubnish it too", "\n", "# much", "\n", "                    ", "regu_lambda", "=", "10.", "\n", "", "", "else", ":", "\n", "# For baseline training", "\n", "                ", "regu_", "=", "0", "\n", "regu_lambda", "=", "0", "\n", "\n", "", "loss", "=", "loss", "+", "regu_lambda", "*", "regu_", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "True", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "\n", "-", "1", ",", "\n", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "# Only evaluate when single GPU otherwise metrics may not", "\n", "# average well", "\n", "if", "(", "args", ".", "local_rank", "==", "-", "\n", "1", "and", "args", ".", "evaluate_during_training", ")", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "[", "0", "]", "\n", "if", "len", "(", "learning_rate_scalar", ")", ">", "1", ":", "\n", "                        ", "for", "idx", ",", "lr", "in", "enumerate", "(", "learning_rate_scalar", "[", "1", ":", "]", ")", ":", "\n", "                            ", "logs", "[", "f\"learning_rate/{idx+1}\"", "]", "=", "lr", "\n", "", "", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "if", "teacher", "is", "not", "None", ":", "\n", "                        ", "logs", "[", "\"loss/distil\"", "]", "=", "loss_distill", ".", "item", "(", ")", "\n", "logs", "[", "\"loss/distil_logits\"", "]", "=", "loss_logits", ".", "item", "(", ")", "\n", "try", ":", "\n", "                            ", "logs", "[", "\"loss/distil_attns\"", "]", "=", "att_loss", ".", "item", "(", ")", "\n", "", "except", "BaseException", ":", "\n", "                            ", "logs", "[", "\"loss/distil_attns\"", "]", "=", "0", "\n", "", "try", ":", "\n", "                            ", "logs", "[", "\"loss/distil_reps\"", "]", "=", "rep_loss", ".", "item", "(", ")", "\n", "", "except", "BaseException", ":", "\n", "                            ", "logs", "[", "\"loss/distil_reps\"", "]", "=", "0", "\n", "\n", "", "", "logging_loss", "=", "tr_loss", "\n", "print", "(", "f\"step: {global_step}: {logs}\"", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "\n", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "args", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "print", "(", "f\"Saving model checkpoint to {output_dir}\"", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "\n", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "save", "(", "\n", "scaler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"scaler.pt\"", ")", ")", "\n", "\n", "", "print", "(", "\n", "f\"Saving optimizer and scheduler states to {output_dir}\"", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.evaluate": [[400, 483], ["zip", "masked_run_glue.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel.eval", "tuple", "softmax", "numpy.exp", "numpy.argmax", "os.path.exists", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach", "numpy.log"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\n", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "\n", "\"/MM\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", "=", "load_and_cache_examples", "(", "\n", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "\n", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "# print(f\"***** Running evaluation {prefix} *****\")", "\n", "# print(f\"  Num examples = {len(eval_dataset)}\")", "\n", "# print(f\"  Batch size = {args.eval_batch_size}\")", "\n", "", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                    ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"masked_bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "\n", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "from", "scipy", ".", "special", "import", "softmax", "\n", "\n", "probs", "=", "softmax", "(", "preds", ",", "axis", "=", "-", "1", ")", "\n", "entropy", "=", "np", ".", "exp", "(", "(", "-", "probs", "*", "np", ".", "log", "(", "probs", ")", ")", ".", "sum", "(", "axis", "=", "-", "1", ")", ".", "mean", "(", ")", ")", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "entropy", "=", "None", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "if", "entropy", "is", "not", "None", ":", "\n", "            ", "result", "[", "\"eval_avg_entropy\"", "]", "=", "entropy", "\n", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.load_and_cache_examples": [[485, 551], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.exists", "torch.load", "torch.load", "torch.load", "processor.get_labels", "transformers.glue_convert_examples_to_features", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.tensor", "torch.tensor", "torch.tensor", "list().pop", "str", "str", "processor.get_dev_examples", "processor.get_train_examples", "torch.save", "torch.save", "torch.save", "torch.tensor", "torch.tensor", "torch.tensor", "list", "filter", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the", "\n", "# dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "\"dev\"", "if", "evaluate", "else", "\"train\"", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "task", "in", "[", "\"mnli\"", ",", "\n", "\"mnli-mm\"", "]", "and", "args", ".", "model_type", "in", "[", "\"roberta\"", ",", "\n", "\"xlmroberta\"", "]", ":", "\n", "# HACK(label indices are swapped in RoBERTa pretrained model)", "\n", "            ", "label_list", "[", "1", "]", ",", "label_list", "[", "2", "]", "=", "label_list", "[", "2", "]", ",", "label_list", "[", "1", "]", "\n", "", "examples", "=", "(", "\n", "processor", ".", "get_dev_examples", "(", "\n", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "\n", "args", ".", "data_dir", ")", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "label_list", "=", "label_list", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the", "\n", "# dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_attention_mask", ",", "\n", "all_token_type_ids", ",", "\n", "all_labels", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_run_glue.main": [[553, 925], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "masked_run_glue.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "print", "print", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "teacher_config_class.from_pretrained", "teacher_model_class.from_pretrained", "teacher_model_class.from_pretrained.to", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "masked_run_glue.load_and_cache_examples", "masked_run_glue.train", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "torch.save", "torch.save", "masked_run_glue.evaluate", "print", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "bool", "hasattr", "os.path.join", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "MODEL_CLASSES.keys", "transformers.glue_processors.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.load_and_cache_examples", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.train", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from huggingface.co\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_train\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_eval\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "\n", "# Pruning parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_scores_learning_rate\"", ",", "\n", "default", "=", "1e-2", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The Adam initial learning rate of the mask scores.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final_threshold\"", ",", "\n", "default", "=", "0.7", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Final value of the threshold (for scheduling).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--head_pruning\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Head Pruning or not\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pruning_method\"", ",", "\n", "default", "=", "\"topK\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pruning Method (topK = MLpruning).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_init\"", ",", "\n", "default", "=", "\"constant\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Initialization method for the mask scores. Choices: constant, uniform, kaiming.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_scale\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Initialization parameter for the chosen initialization method.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final_lambda\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Regularization intensity (used in conjunction with `regularization`.\"", ",", "\n", ")", "\n", "\n", "# Distillation parameters (optional)", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Teacher type. Teacher tokenizer and student (model) tokenizer must output the same tokenization. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the already fine-tuned teacher model. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_ce\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Cross entropy loss linear weight. Only for distillation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_distil\"", ",", "\n", "default", "=", "0.9", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation loss linear weight. Only for distillation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "default", "=", "2.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation temperature. Only for distillation.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight_decay\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adam_epsilon\"", ",", "\n", "default", "=", "1e-8", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_grad_norm\"", ",", "\n", "default", "=", "1.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "3.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "\n", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_steps\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--logging_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1000", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "\n", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Make sure only the first process in distributed training will", "\n", "# download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "args", ".", "mask_init", ",", "\n", "mask_scale", "=", "args", ".", "mask_scale", ",", "\n", "output_attentions", "=", "True", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", "head_pruning", "=", "args", ".", "head_pruning", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "teacher_type", "is", "not", "None", ":", "\n", "        ", "assert", "args", ".", "teacher_name_or_path", "is", "not", "None", "\n", "assert", "args", ".", "alpha_distil", ">", "0.0", "\n", "assert", "args", ".", "alpha_distil", "+", "args", ".", "alpha_ce", ">", "0.0", "\n", "teacher_config_class", ",", "teacher_model_class", ",", "_", "=", "MODEL_CLASSES", "[", "args", ".", "teacher_type", "]", "\n", "teacher_config", "=", "teacher_config_class", ".", "from_pretrained", "(", "\n", "args", ".", "teacher_name_or_path", ")", "\n", "teacher_config", ".", "output_attentions", "=", "True", "\n", "teacher_config", ".", "output_hidden_states", "=", "True", "\n", "teacher", "=", "teacher_model_class", ".", "from_pretrained", "(", "\n", "args", ".", "teacher_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "teacher", ".", "to", "(", "args", ".", "device", ")", "\n", "# teacher_result = evaluate(args, teacher, tokenizer, prefix=\"\")", "\n", "# print(\"Teacher's accuracy: \", teacher_result)", "\n", "", "else", ":", "\n", "        ", "teacher", "=", "None", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "# Make sure only the first process in distributed training will", "\n", "# download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "f\"Training/evaluation parameters {args}\"", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "\n", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "\n", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "teacher", "=", "teacher", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can", "\n", "# reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "\n", "args", ".", "local_rank", "==", "-", "\n", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "        ", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained", "\n", "# model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "tmp_result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", "\n", "print", "(", "f\"Final: {tmp_result}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_bert_parameter_count.set_seed": [[51, 57], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_bert_parameter_count.main": [[59, 253], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "masked_bert_parameter_count.set_seed", "parser.parse_args.model_type.lower", "model_class.from_pretrained", "model_class.from_pretrained.eval", "model_class.from_pretrained.named_parameters", "model_class.from_pretrained.to", "range", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.Event.record", "range", "torch.cuda.Event.record", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "print", "print", "print", "print", "print", "print", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "config_class.from_pretrained", "model_class.from_pretrained._make_structural_pruning", "model_class.from_pretrained._make_structural_pruning", "model_class.from_pretrained.modules", "model_class.from_pretrained.load_state_dict", "model_class.from_pretrained.modules", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.cuda.Event.elapsed_time", "total_num_params.item", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "print", "config_class.from_pretrained", "bool", "isinstance", "torch.load", "torch.load", "torch.load", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_class.from_pretrained.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_class.from_pretrained.", "module.enable_block_pruning", "module.make_block_wise_inference_pruning", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "MODEL_CLASSES.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "param.abs"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering._make_structural_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering._make_structural_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.enable_block_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_block_wise_inference_pruning"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pruning_method\"", ",", "\n", "default", "=", "\"topK\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pruning Method (l0 = L0 regularization, magnitude = Magnitude pruning, topK = Movement pruning, sigmoied_threshold = Soft movement pruning).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--head_pruning\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Head Pruning or not\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "\n", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_rows\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Number of rows in a block\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_cols\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Number of cols in a block\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to pretrained block wise model\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "if", "'qqp'", "in", "args", ".", "model_name_or_path", "or", "'mnli'", "in", "args", ".", "model_name_or_path", ":", "\n", "        ", "num_labels", "=", "2", "\n", "if", "'mnli'", "in", "args", ".", "model_name_or_path", ":", "\n", "            ", "num_labels", "=", "3", "\n", "", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "'mrpc'", ",", "\n", "cache_dir", "=", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "'constant'", ",", "\n", "mask_scale", "=", "0", ",", "\n", "head_pruning", "=", "args", ".", "head_pruning", "\n", ")", "\n", "", "elif", "'squad'", "in", "args", ".", "model_name_or_path", ":", "\n", "        ", "print", "(", "'This one is used!'", ")", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "'constant'", ",", "\n", "mask_scale", "=", "0", ",", "\n", "head_pruning", "=", "args", ".", "head_pruning", "\n", ")", "\n", "model_class", "=", "MaskedBertForQuestionAnswering", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "None", ",", "\n", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "args", ".", "block_path", "is", "None", ":", "\n", "        ", "model", ".", "_make_structural_pruning", "(", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "        ", "assert", "args", ".", "block_rows", ">=", "1", "and", "args", ".", "block_cols", ">=", "1", "\n", "model", ".", "_make_structural_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "MaskedLinear", ")", ":", "\n", "                ", "module", ".", "enable_block_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "", "", "model", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "f\"{args.block_path}/pytorch_model.bin\"", ")", ")", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "MaskedLinear", ")", ":", "\n", "                ", "module", ".", "make_block_wise_inference_pruning", "(", ")", "# block-sparse model", "\n", "\n", "", "", "", "total_num_params", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "total_num_params", "+=", "(", "param", ".", "abs", "(", ")", ">", "1e-8", ")", ".", "sum", "(", ")", "\n", "\n", "", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "batch_size", "=", "args", ".", "per_gpu_train_batch_size", "\n", "length", "=", "args", ".", "max_seq_length", "\n", "batch", "=", "{", "\n", "\"attention_mask\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "\"input_ids\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "\"token_type_ids\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "}", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "\"input_ids\"", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "\"attention_mask\"", "]", "}", "\n", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "        ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "\"token_type_ids\"", "]", "if", "args", ".", "model_type", "in", "[", "\n", "\"bert\"", ",", "\n", "\"masked_bert\"", ",", "\n", "\"xlnet\"", ",", "\n", "\"albert\"", "]", "else", "None", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "# warmup!!!", "\n", "", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "", "start", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "end", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "# do real measurement", "\n", "num_runs", "=", "100", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", ".", "record", "(", ")", "\n", "for", "i", "in", "range", "(", "num_runs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "", "", "end", ".", "record", "(", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "total_time", "=", "start", ".", "elapsed_time", "(", "end", ")", "/", "1000", "# s", "\n", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "'Num of Parameters: '", ",", "total_num_params", ".", "item", "(", ")", ")", "\n", "print", "(", "\n", "f'Remaining Parameters as compared to baseline: {(total_num_params/85054608*100):.2f}%'", ")", "\n", "print", "(", "f\"{num_runs/total_time * batch_size} Sentences / s\"", ")", "\n", "print", "(", "f\"{total_time/num_runs/batch_size * 1000} ms / Sentences \"", ")", "\n", "print", "(", "'*'", "*", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.set_seed": [[51, 57], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.regularization": [[59, 81], ["model.named_parameters", "sum", "zip", "torch.square", "torch.square", "torch.square", "threshold_list.append", "score_list.append", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "param.numel"], "function", ["None"], ["", "", "def", "regularization", "(", "model", ":", "nn", ".", "Module", ",", "threshold", ":", "float", ")", ":", "\n", "    ", "threshold_list", "=", "[", "]", "\n", "score_list", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'threshold'", "in", "name", ":", "\n", "            ", "threshold_list", ".", "append", "(", "torch", ".", "sigmoid", "(", "param", ")", ")", "\n", "", "if", "'score'", "in", "name", ":", "\n", "            ", "score_list", ".", "append", "(", "param", ".", "numel", "(", ")", ")", "\n", "\n", "", "", "total_num", "=", "sum", "(", "score_list", ")", "\n", "param_remain", "=", "0", "\n", "\n", "for", "i", ",", "j", "in", "zip", "(", "threshold_list", ",", "score_list", ")", ":", "\n", "        ", "param_remain", "+=", "i", "*", "j", "\n", "\n", "", "if", "param_remain", "/", "total_num", "-", "threshold", "<=", "0", ":", "\n", "        ", "reg_loss", "=", "param_remain", "*", "0.", "\n", "", "else", ":", "\n", "# 144 comes from count, use simple sqaure loss", "\n", "        ", "reg_loss", "=", "torch", ".", "square", "(", "param_remain", "/", "total_num", "-", "threshold", ")", "\n", "\n", "", "return", "reg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.train": [[83, 381], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "print", "print", "print", "print", "print", "print", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "masked_blockwise_run_glue.set_seed", "print", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "print", "int", "tqdm.tqdm", "enumerate", "len", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "masked_blockwise_run_glue.regularization", "max", "loss.mean.item", "tqdm.trange.close", "len", "len", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel.", "regularization.item", "loss.mean.mean", "scaler.scale().backward", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "t.to", "len", "len", "int", "enumerate", "torch.nn.parallel.DistributedDataParallel.parameters", "scaler.step", "scaler.update", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.get_lr", "print", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "torch.save", "torch.save", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "any", "torch.no_grad", "torch.no_grad", "torch.no_grad", "teacher", "zip", "zip", "torch.mse_loss", "torch.kl_div", "scaler.scale", "masked_blockwise_run_glue.evaluate", "evaluate.items", "len", "enumerate", "loss_distill.item", "loss_logits.item", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "torch.save", "torch.save", "torch.save", "any", "range", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.mse_loss", "range", "regularization.item", "att_loss.item", "rep_loss.item", "scaler.state_dict", "os.path.join", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.log_softmax", "torch.softmax", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.train", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.regularization", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.backward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.backward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "teacher", "=", "None", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "len", "(", "train_dataloader", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "\"mask_score\"", "in", "n", "or", "\"threshold\"", "in", "n", "and", "p", ".", "requires_grad", "]", ",", "\n", "\"lr\"", ":", "args", ".", "mask_scores_learning_rate", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "\"mask_score\"", "not", "in", "n", "and", "\"threshold\"", "not", "in", "n", "and", "p", ".", "requires_grad", "and", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "\"mask_score\"", "not", "in", "n", "and", "\"threshold\"", "not", "in", "n", "and", "p", ".", "requires_grad", "and", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", "num_training_steps", "=", "t_total", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "print", "(", "\"***** Running training *****\"", ")", "\n", "print", "(", "f\"  Num examples = {len(train_dataset)}\"", ")", "\n", "print", "(", "f\"  Num Epochs = {args.num_train_epochs}\"", ")", "\n", "print", "(", "\n", "f\"  Instantaneous batch size per GPU = {args.per_gpu_train_batch_size}\"", ")", "\n", "print", "(", "\n", "f\"  Total train batch size (w. parallel, distributed) = {args.train_batch_size}\"", ",", "\n", "\n", ")", "\n", "print", "(", "f\"  Total optimization steps = {t_total}\"", ")", "\n", "# Distillation", "\n", "if", "teacher", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"  Training with distillation\"", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "\n", "int", "(", "args", ".", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"masked_bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", "enabled", "=", "args", ".", "fp16", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# print(outputs)", "\n", "\n", "if", "\"masked\"", "not", "in", "args", ".", "model_type", ":", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "                    ", "loss", ",", "logits_stu", "=", "outputs", ".", "loss", ",", "outputs", ".", "logits", "\n", "", "else", ":", "\n", "                    ", "loss", ",", "logits_stu", ",", "reps_stu", ",", "attentions_stu", "=", "outputs", "\n", "\n", "# Distillation loss", "\n", "", "if", "teacher", "is", "not", "None", ":", "\n", "                    ", "if", "\"token_type_ids\"", "not", "in", "inputs", ":", "\n", "                        ", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "if", "args", ".", "teacher_type", "==", "\"xlm\"", "else", "batch", "[", "2", "]", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "outputs_tea", "=", "teacher", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "token_type_ids", "=", "inputs", "[", "\"token_type_ids\"", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", ")", "\n", "if", "\"masked\"", "not", "in", "args", ".", "teacher_type", ":", "\n", "                            ", "logits_tea", ",", "reps_tea", ",", "attentions_tea", "=", "outputs_tea", ".", "logits", ",", "outputs_tea", ".", "hidden_states", ",", "outputs_tea", ".", "attentions", "\n", "", "else", ":", "\n", "                            ", "logits_tea", ",", "reps_tea", ",", "attentions_tea", "=", "outputs_tea", "\n", "\n", "", "", "teacher_layer_num", "=", "len", "(", "attentions_tea", ")", "\n", "student_layer_num", "=", "len", "(", "attentions_stu", ")", "\n", "assert", "teacher_layer_num", "%", "student_layer_num", "==", "0", "\n", "layers_per_block", "=", "int", "(", "\n", "teacher_layer_num", "/", "student_layer_num", ")", "\n", "new_attentions_tea", "=", "[", "attentions_tea", "[", "i", "*", "\n", "layers_per_block", "+", "\n", "layers_per_block", "-", "\n", "1", "]", "for", "i", "in", "range", "(", "student_layer_num", ")", "]", "\n", "\n", "att_loss", ",", "rep_loss", "=", "0", ",", "0", "\n", "if", "\"masked\"", "in", "args", ".", "teacher_type", ":", "\n", "                        ", "for", "student_att", ",", "teacher_att", "in", "zip", "(", "\n", "attentions_stu", ",", "new_attentions_tea", ")", ":", "\n", "                            ", "student_att", "=", "torch", ".", "where", "(", "\n", "student_att", "<=", "-", "1e2", ",", "\n", "torch", ".", "zeros_like", "(", "student_att", ")", ".", "to", "(", "\n", "args", ".", "device", ")", ",", "\n", "student_att", ")", "\n", "teacher_att", "=", "torch", ".", "where", "(", "\n", "teacher_att", "<=", "-", "1e2", ",", "\n", "torch", ".", "zeros_like", "(", "teacher_att", ")", ".", "to", "(", "\n", "args", ".", "device", ")", ",", "\n", "teacher_att", ")", "\n", "\n", "tmp_loss", "=", "F", ".", "mse_loss", "(", "\n", "student_att", ",", "teacher_att", ",", "reduction", "=", "\"mean\"", ",", ")", "\n", "att_loss", "+=", "tmp_loss", "\n", "\n", "", "", "new_reps_tea", "=", "[", "reps_tea", "[", "i", "*", "layers_per_block", "]", "\n", "for", "i", "in", "range", "(", "student_layer_num", "+", "1", ")", "]", "\n", "new_reps_stu", "=", "reps_stu", "\n", "for", "i_threp", ",", "(", "student_rep", ",", "teacher_rep", ")", "in", "enumerate", "(", "\n", "zip", "(", "new_reps_stu", ",", "new_reps_tea", ")", ")", ":", "\n", "                        ", "tmp_loss", "=", "F", ".", "mse_loss", "(", "\n", "student_rep", ",", "teacher_rep", ",", "reduction", "=", "\"mean\"", ",", ")", "\n", "rep_loss", "+=", "tmp_loss", "\n", "\n", "", "loss_logits", "=", "F", ".", "kl_div", "(", "\n", "input", "=", "F", ".", "log_softmax", "(", "logits_stu", "/", "args", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", "=", "F", ".", "softmax", "(", "logits_tea", "/", "args", ".", "temperature", ",", "dim", "=", "-", "1", ")", ",", "\n", "reduction", "=", "\"batchmean\"", ",", "\n", ")", "*", "(", "args", ".", "temperature", "**", "2", ")", "\n", "\n", "loss_distill", "=", "loss_logits", "+", "rep_loss", "+", "att_loss", "\n", "\n", "loss", "=", "args", ".", "alpha_distil", "*", "loss_distill", "+", "args", ".", "alpha_ce", "*", "loss", "\n", "\n", "", "", "regu_", "=", "regularization", "(", "model", "=", "model", ",", "threshold", "=", "args", ".", "final_threshold", ")", "\n", "regu_lambda", "=", "max", "(", "args", ".", "final_lambda", "*", "regu_", ".", "item", "(", ")", "/", "\n", "(", "1", "-", "args", ".", "final_threshold", ")", "/", "(", "1", "-", "args", ".", "final_threshold", ")", ",", "50", ")", "\n", "if", "regu_", ".", "item", "(", ")", "<", "0.0003", ":", "\n", "# when the loss is very small, no need to pubnish it too much", "\n", "                ", "regu_lambda", "=", "10.", "\n", "\n", "", "loss", "=", "loss", "+", "regu_lambda", "*", "regu_", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "True", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                    ", "optimizer", ".", "step", "(", ")", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "\n", "-", "1", ",", "\n", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "# Only evaluate when single GPU otherwise metrics may not", "\n", "# average well", "\n", "if", "(", "args", ".", "local_rank", "==", "-", "\n", "1", "and", "args", ".", "evaluate_during_training", ")", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "\"eval_{}\"", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "\n", "logs", "[", "\"learning_rate\"", "]", "=", "learning_rate_scalar", "[", "0", "]", "\n", "if", "len", "(", "learning_rate_scalar", ")", ">", "1", ":", "\n", "                        ", "for", "idx", ",", "lr", "in", "enumerate", "(", "learning_rate_scalar", "[", "1", ":", "]", ")", ":", "\n", "                            ", "logs", "[", "f\"learning_rate/{idx+1}\"", "]", "=", "lr", "\n", "", "", "logs", "[", "\"loss\"", "]", "=", "loss_scalar", "\n", "if", "teacher", "is", "not", "None", ":", "\n", "                        ", "logs", "[", "\"loss/distil\"", "]", "=", "loss_distill", ".", "item", "(", ")", "\n", "logs", "[", "\"loss/distil_logits\"", "]", "=", "loss_logits", ".", "item", "(", ")", "\n", "try", ":", "\n", "                            ", "logs", "[", "\"loss/distil_attns\"", "]", "=", "att_loss", ".", "item", "(", ")", "\n", "", "except", "BaseException", ":", "\n", "                            ", "logs", "[", "\"loss/distil_attns\"", "]", "=", "0", "\n", "", "try", ":", "\n", "                            ", "logs", "[", "\"loss/distil_reps\"", "]", "=", "rep_loss", ".", "item", "(", ")", "\n", "", "except", "BaseException", ":", "\n", "                            ", "logs", "[", "\"loss/distil_reps\"", "]", "=", "0", "\n", "\n", "", "", "print", "(", "f\"step: {global_step}: {logs}\"", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "\n", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "args", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "print", "(", "f\"Saving model checkpoint to {output_dir}\"", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "\n", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "                        ", "torch", ".", "save", "(", "\n", "scaler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\"scaler.pt\"", ")", ")", "\n", "\n", "", "print", "(", "\n", "f\"Saving optimizer and scheduler states to {output_dir}\"", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "print", "(", "'Best Result: '", ",", "best_accuracy", ")", "\n", "\n", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.evaluate": [[383, 467], ["zip", "masked_blockwise_run_glue.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "transformers.glue_compute_metrics", "results.update", "os.path.join", "os.makedirs", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel.eval", "tuple", "softmax", "numpy.exp", "numpy.argmax", "os.path.exists", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach", "numpy.log"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\n", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "\n", "\"/MM\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", "=", "load_and_cache_examples", "(", "\n", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "\n", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "# print(f\"***** Running evaluation {prefix} *****\")", "\n", "# print(f\"  Num examples = {len(eval_dataset)}\")", "\n", "# print(f\"  Batch size = {args.eval_batch_size}\")", "\n", "", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                    ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"masked_bert\"", ",", "\"xlnet\"", ",", "\"albert\"", "]", "else", "None", "\n", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "\n", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "from", "scipy", ".", "special", "import", "softmax", "\n", "\n", "probs", "=", "softmax", "(", "preds", ",", "axis", "=", "-", "1", ")", "\n", "entropy", "=", "np", ".", "exp", "(", "(", "-", "probs", "*", "np", ".", "log", "(", "probs", ")", ")", ".", "sum", "(", "axis", "=", "-", "1", ")", ".", "mean", "(", ")", ")", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "entropy", "=", "None", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "if", "entropy", "is", "not", "None", ":", "\n", "            ", "result", "[", "\"eval_avg_entropy\"", "]", "=", "entropy", "\n", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.load_and_cache_examples": [[469, 535], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.exists", "torch.load", "torch.load", "torch.load", "processor.get_labels", "transformers.glue_convert_examples_to_features", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.tensor", "torch.tensor", "torch.tensor", "list().pop", "str", "str", "processor.get_dev_examples", "processor.get_train_examples", "torch.save", "torch.save", "torch.save", "torch.tensor", "torch.tensor", "torch.tensor", "list", "filter", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the", "\n", "# dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "\"dev\"", "if", "evaluate", "else", "\"train\"", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "task", "in", "[", "\"mnli\"", ",", "\n", "\"mnli-mm\"", "]", "and", "args", ".", "model_type", "in", "[", "\"roberta\"", ",", "\n", "\"xlmroberta\"", "]", ":", "\n", "# HACK(label indices are swapped in RoBERTa pretrained model)", "\n", "            ", "label_list", "[", "1", "]", ",", "label_list", "[", "2", "]", "=", "label_list", "[", "2", "]", ",", "label_list", "[", "1", "]", "\n", "", "examples", "=", "(", "\n", "processor", ".", "get_dev_examples", "(", "\n", "args", ".", "data_dir", ")", "if", "evaluate", "else", "processor", ".", "get_train_examples", "(", "\n", "args", ".", "data_dir", ")", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "label_list", "=", "label_list", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the", "\n", "# dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_attention_mask", ",", "\n", "all_token_type_ids", ",", "\n", "all_labels", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.training.masked_blockwise_run_glue.main": [[537, 929], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "masked_blockwise_run_glue.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "masked_blockwise_run_glue.main.make_block_pruning"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from huggingface.co\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_train\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_eval\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "\n", "# Pruning parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_scores_learning_rate\"", ",", "\n", "default", "=", "1e-2", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The Adam initial learning rate of the mask scores.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final_threshold\"", ",", "\n", "default", "=", "0.7", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Final value of the threshold (for scheduling).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pruning_method\"", ",", "\n", "default", "=", "\"topK\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pruning Method (topK = MLPruning).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_init\"", ",", "\n", "default", "=", "\"constant\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Initialization method for the mask scores. Choices: constant, uniform, kaiming.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mask_scale\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Initialization parameter for the chosen initialization method.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--final_lambda\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Regularization intensity (used in conjunction with `regularization`.\"", ",", "\n", ")", "\n", "\n", "# Distillation parameters (optional)", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Teacher type. Teacher tokenizer and student (model) tokenizer must output the same tokenization. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--teacher_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the already fine-tuned teacher model. Only for distillation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_ce\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Cross entropy loss linear weight. Only for distillation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--alpha_distil\"", ",", "\n", "default", "=", "0.9", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation loss linear weight. Only for distillation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "default", "=", "2.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Distillation temperature. Only for distillation.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight_decay\"", ",", "\n", "default", "=", "0.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adam_epsilon\"", ",", "\n", "default", "=", "1e-8", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_grad_norm\"", ",", "\n", "default", "=", "1.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "3.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "\n", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_steps\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--logging_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1000", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "\n", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_rows\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "32", ",", "\n", "help", "=", "\"Number of rows in a block\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_cols\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "32", ",", "\n", "help", "=", "\"Number of cols in a block\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Make sure only the first process in distributed training will", "\n", "# download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "args", ".", "mask_init", ",", "\n", "mask_scale", "=", "args", ".", "mask_scale", ",", "\n", "output_attentions", "=", "True", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "def", "make_block_pruning", "(", "model", ")", ":", "\n", "\n", "# we need to do a evaluation to see the performance matches!!!!", "\n", "        ", "if", "'mask'", "in", "args", ".", "model_type", ":", "\n", "            ", "model", ".", "_make_structural_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "\n", "# add block-wise pruning part", "\n", "", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "MaskedLinear", ")", ":", "\n", "                ", "module", ".", "enable_block_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "", "", "return", "model", "\n", "", "model", "=", "make_block_pruning", "(", "model", ")", "\n", "\n", "if", "args", ".", "teacher_type", "is", "not", "None", ":", "\n", "        ", "assert", "args", ".", "teacher_name_or_path", "is", "not", "None", "\n", "assert", "args", ".", "alpha_distil", ">", "0.0", "\n", "assert", "args", ".", "alpha_distil", "+", "args", ".", "alpha_ce", ">", "0.0", "\n", "teacher_config_class", ",", "teacher_model_class", ",", "_", "=", "MODEL_CLASSES", "[", "args", ".", "teacher_type", "]", "\n", "teacher_config", "=", "teacher_config_class", ".", "from_pretrained", "(", "\n", "args", ".", "teacher_name_or_path", ")", "\n", "teacher_config", ".", "output_attentions", "=", "True", "\n", "teacher_config", ".", "output_hidden_states", "=", "True", "\n", "teacher", "=", "teacher_model_class", ".", "from_pretrained", "(", "\n", "args", ".", "teacher_name_or_path", ",", "\n", "from_tf", "=", "False", ",", "\n", "config", "=", "teacher_config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "if", "'mask'", "in", "args", ".", "teacher_type", ":", "\n", "            ", "teacher", ".", "_make_structural_pruning", "(", "[", "None", ",", "None", "]", ")", "\n", "", "teacher", ".", "to", "(", "args", ".", "device", ")", "\n", "# result = evaluate(args, teacher, tokenizer, prefix=\"\")", "\n", "# print('Teacher Acc: ', result)", "\n", "", "else", ":", "\n", "        ", "teacher", "=", "None", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "# Make sure only the first process in distributed training will", "\n", "# download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "f\"Training/evaluation parameters {args}\"", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "\n", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "\n", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "teacher", "=", "teacher", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can", "\n", "# reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "\n", "args", ".", "local_rank", "==", "-", "\n", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "        ", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained", "\n", "# model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "tmp_result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", "\n", "print", "(", "f\"Final: {tmp_result}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.configuration_bert_masked.MaskedBertConfig.__init__": [[21, 60], ["transformers.configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "pad_token_id", "=", "0", ",", "\n", "pruning_method", "=", "\"topK\"", ",", "\n", "mask_init", "=", "\"constant\"", ",", "\n", "mask_scale", "=", "0.0", ",", "\n", "head_pruning", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "pad_token_id", "=", "pad_token_id", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "self", ".", "pruning_method", "=", "pruning_method", "\n", "self", ".", "mask_init", "=", "mask_init", "\n", "self", ".", "mask_scale", "=", "mask_scale", "\n", "self", ".", "head_pruning", "=", "head_pruning", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertEmbeddings.__init__": [[102, 116], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertEmbeddings.forward": [[117, 147], ["modeling_bert_masked.BertEmbeddings.position_embeddings", "modeling_bert_masked.BertEmbeddings.token_type_embeddings", "modeling_bert_masked.BertEmbeddings.LayerNorm", "modeling_bert_masked.BertEmbeddings.dropout", "input_ids.size", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.zeros", "modeling_bert_masked.BertEmbeddings.word_embeddings", "modeling_bert_masked.BertEmbeddings.size", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "\n", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "\n", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.__init__": [[150, 212], ["torch.nn.Module.__init__", "int", "emmental.modules.MaskedLinear", "emmental.modules.MaskedLinear", "emmental.modules.MaskedLinear", "torch.nn.Dropout", "ValueError", "hasattr"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "\n", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "\n", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "\n", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "MaskedLinear", "(", "\n", "config", ".", "hidden_size", ",", "\n", "self", ".", "all_head_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "head_split", "=", "config", ".", "num_attention_heads", ",", "\n", "bias_mask", "=", "True", ",", "\n", "head_pruning", "=", "config", ".", "head_pruning", ",", "\n", "row_pruning", "=", "False", "\n", ")", "\n", "self", ".", "key", "=", "MaskedLinear", "(", "\n", "config", ".", "hidden_size", ",", "\n", "self", ".", "all_head_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "head_split", "=", "config", ".", "num_attention_heads", ",", "\n", "bias_mask", "=", "True", ",", "\n", "head_pruning", "=", "config", ".", "head_pruning", ",", "\n", "row_pruning", "=", "False", "\n", ")", "\n", "\n", "# tie the score of query and key together if we do row pruning for MHA", "\n", "# self.key.mask_scores = self.query.mask_scores", "\n", "\n", "self", ".", "value", "=", "MaskedLinear", "(", "\n", "config", ".", "hidden_size", ",", "\n", "self", ".", "all_head_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "head_split", "=", "config", ".", "num_attention_heads", ",", "\n", "bias_mask", "=", "True", ",", "\n", "head_pruning", "=", "config", ".", "head_pruning", ",", "\n", "row_pruning", "=", "False", "\n", ")", "\n", "\n", "# If head pruning, we need to make the masking_score for qkv to be the", "\n", "# same", "\n", "if", "config", ".", "head_pruning", ":", "\n", "            ", "self", ".", "key", ".", "head_mask_scores", "=", "self", ".", "query", ".", "head_mask_scores", "\n", "self", ".", "value", ".", "head_mask_scores", "=", "self", ".", "query", ".", "head_mask_scores", "\n", "self", ".", "key", ".", "threshold_head", "=", "self", ".", "query", ".", "threshold_head", "\n", "self", ".", "value", ".", "threshold_head", "=", "self", ".", "query", ".", "threshold_head", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.transpose_for_scores": [[213, 218], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", "\n", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.forward": [[219, 278], ["modeling_bert_masked.BertSelfAttention.query", "modeling_bert_masked.BertSelfAttention.transpose_for_scores", "modeling_bert_masked.BertSelfAttention.transpose_for_scores", "modeling_bert_masked.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert_masked.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert_masked.BertSelfAttention.key", "modeling_bert_masked.BertSelfAttention.value", "modeling_bert_masked.BertSelfAttention.key", "modeling_bert_masked.BertSelfAttention.value", "modeling_bert_masked.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "encoder_hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw", "\n", "# attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "\n", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in", "\n", "# BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", "\n", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "\n", "context_layer", ",", "\n", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "\n", "context_layer", ",", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfOutput.__init__": [[281, 296], ["torch.nn.Module.__init__", "emmental.modules.MaskedLinear", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "MaskedLinear", "(", "\n", "config", ".", "hidden_size", ",", "\n", "config", ".", "hidden_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "bias_mask", "=", "True", ",", "\n", "head_pruning", "=", "False", ",", "\n", "row_pruning", "=", "True", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertSelfOutput.forward": [[297, 307], ["modeling_bert_masked.BertSelfOutput.dense", "modeling_bert_masked.BertSelfOutput.dropout", "modeling_bert_masked.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "res_mask", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "if", "res_mask", "is", "not", "None", ":", "\n", "            ", "input_tensor", "[", ":", ",", ":", ",", "res_mask", "]", "=", "input_tensor", "[", ":", ",", "\n", ":", ",", "res_mask", "]", "+", "hidden_states", "\n", "", "else", ":", "\n", "            ", "input_tensor", "=", "input_tensor", "+", "hidden_states", "\n", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertAttention.__init__": [[310, 316], ["torch.nn.Module.__init__", "modeling_bert_masked.BertSelfAttention", "modeling_bert_masked.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "output_mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertAttention.make_structural_pruning": [[317, 332], ["modeling_bert_masked.BertAttention.self.query.make_inference_pruning", "modeling_bert_masked.BertAttention.self.key.make_inference_pruning", "modeling_bert_masked.BertAttention.self.value.make_inference_pruning", "int", "modeling_bert_masked.BertAttention.output.dense.make_inference_pruning", "modeling_bert_masked.BertAttention.output.dense.make_column_purning", "modeling_bert_masked.BertAttention.sum"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_column_purning"], ["", "def", "make_structural_pruning", "(", "self", ",", "blocksize", ")", ":", "\n", "# make the structural pruning here for attention for inference", "\n", "        ", "self", ".", "self", ".", "query", ".", "make_inference_pruning", "(", "blocksize", ")", "\n", "self", ".", "self", ".", "key", ".", "make_inference_pruning", "(", "blocksize", ")", "\n", "value_mask", "=", "self", ".", "self", ".", "value", ".", "make_inference_pruning", "(", "blocksize", ")", "\n", "num_head", "=", "(", "value_mask", ".", "sum", "(", ")", "//", "64", ")", ".", "item", "(", ")", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "int", "(", "num_head", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "num_attention_heads", "*", "self", ".", "self", ".", "attention_head_size", "\n", "\n", "output_mask", "=", "self", ".", "output", ".", "dense", ".", "make_inference_pruning", "(", "\n", "blocksize", ")", "# we need this to do the residual connection", "\n", "self", ".", "output_mask", "=", "output_mask", "\n", "# we need to remove cols from O layer since heads are pruned", "\n", "self", ".", "output", ".", "dense", ".", "make_column_purning", "(", "value_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertAttention.forward": [[333, 355], ["modeling_bert_masked.BertAttention.self", "modeling_bert_masked.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "\n", "self_outputs", "[", "0", "]", ",", "\n", "hidden_states", ",", "\n", "res_mask", "=", "self", ".", "output_mask", ")", "\n", "# add attentions if we output them", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertIntermediate.__init__": [[358, 372], ["torch.nn.Module.__init__", "emmental.modules.MaskedLinear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "MaskedLinear", "(", "\n", "config", ".", "hidden_size", ",", "\n", "config", ".", "intermediate_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "bias_mask", "=", "True", ",", "\n", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertIntermediate.forward": [[373, 377], ["modeling_bert_masked.BertIntermediate.dense", "modeling_bert_masked.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertOutput.__init__": [[380, 393], ["torch.nn.Module.__init__", "emmental.modules.MaskedLinear", "torch.nn.LayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "MaskedLinear", "(", "\n", "config", ".", "intermediate_size", ",", "\n", "config", ".", "hidden_size", ",", "\n", "pruning_method", "=", "config", ".", "pruning_method", ",", "\n", "mask_init", "=", "config", ".", "mask_init", ",", "\n", "mask_scale", "=", "config", ".", "mask_scale", ",", "\n", "bias_mask", "=", "True", ",", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "\n", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertOutput.forward": [[394, 404], ["modeling_bert_masked.BertOutput.dense", "modeling_bert_masked.BertOutput.dropout", "modeling_bert_masked.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "res_mask", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "if", "res_mask", "is", "not", "None", ":", "\n", "            ", "input_tensor", "[", ":", ",", ":", ",", "res_mask", "]", "=", "input_tensor", "[", ":", ",", "\n", ":", ",", "res_mask", "]", "+", "hidden_states", "\n", "", "else", ":", "\n", "            ", "input_tensor", "=", "input_tensor", "+", "hidden_states", "\n", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.__init__": [[407, 416], ["torch.nn.Module.__init__", "modeling_bert_masked.BertAttention", "modeling_bert_masked.BertIntermediate", "modeling_bert_masked.BertOutput", "modeling_bert_masked.BertAttention"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "crossattention", "=", "BertAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "self", ".", "output_mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.make_structural_pruning": [[417, 426], ["modeling_bert_masked.BertLayer.attention.make_structural_pruning", "modeling_bert_masked.BertLayer.intermediate.dense.make_inference_pruning", "modeling_bert_masked.BertLayer.output.dense.make_inference_pruning", "modeling_bert_masked.BertLayer.output.dense.make_column_purning"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.make_structural_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_column_purning"], ["", "def", "make_structural_pruning", "(", "self", ",", "blocksize", ")", ":", "\n", "        ", "self", ".", "attention", ".", "make_structural_pruning", "(", "blocksize", ")", "\n", "# make self.intermediate and self.output to be structural prune", "\n", "intermediate_mask", "=", "self", ".", "intermediate", ".", "dense", ".", "make_inference_pruning", "(", "\n", "blocksize", ")", "# we need this to do the residual connection", "\n", "output_mask", "=", "self", ".", "output", ".", "dense", ".", "make_inference_pruning", "(", "blocksize", ")", "\n", "self", ".", "output_mask", "=", "output_mask", "\n", "# we need to do col pruning for FC2", "\n", "self", ".", "output", ".", "dense", ".", "make_column_purning", "(", "intermediate_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.forward": [[427, 459], ["modeling_bert_masked.BertLayer.attention", "modeling_bert_masked.BertLayer.intermediate", "modeling_bert_masked.BertLayer.output", "modeling_bert_masked.BertLayer.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "# add self attentions if we output attention weights", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "# add cross attentions if we output attention weights", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "\n", "\n", "", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "\n", "intermediate_output", ",", "\n", "attention_output", ",", "\n", "res_mask", "=", "self", ".", "output_mask", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertEncoder.__init__": [[462, 468], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "modeling_bert_masked.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "\n", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertEncoder.forward": [[469, 507], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "threshold", "=", "None", ",", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertPooler.__init__": [[510, 514], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertPooler.forward": [[515, 522], ["modeling_bert_masked.BertPooler.dense", "modeling_bert_masked.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertPreTrainedModel._init_weights": [[533, 545], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "\n", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertModel.__init__": [[615, 625], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bert_masked.BertEmbeddings", "modeling_bert_masked.MaskedBertModel.embeddings.requires_grad_", "modeling_bert_masked.BertEncoder", "modeling_bert_masked.BertPooler", "modeling_bert_masked.MaskedBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "embeddings", ".", "requires_grad_", "(", "requires_grad", "=", "False", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertModel.get_input_embeddings": [[626, 628], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertModel.set_input_embeddings": [[629, 631], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertModel.forward": [[632, 795], ["transformers.file_utils.add_start_docstrings_to_model_forward", "extended_attention_mask.to.to.to", "modeling_bert_masked.MaskedBertModel.embeddings", "modeling_bert_masked.MaskedBertModel.encoder", "modeling_bert_masked.MaskedBertModel.pooler", "ValueError", "torch.ones", "torch.zeros", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "modeling_bert_masked.MaskedBertModel.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_bert_masked.MaskedBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert_masked.MaskedBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "MASKED_BERT_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Return:\n            :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~emmental.MaskedBertConfig`) and inputs:\n            last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n                Sequence of hidden-states at the output of the last layer of the model.\n            pooler_output (:obj:`torch.FloatTensor`: of shape :obj:`(batch_size, hidden_size)`):\n                Last layer hidden-state of the first token of the sequence (classification token)\n                further processed by a Linear layer and a Tanh activation function. The Linear\n                layer weights are trained from the next sentence prediction (classification)\n                objective during pre-training.\n\n                This output is usually *not* a good summary\n                of the semantic content of the input, you're often better with averaging or pooling\n                the sequence of hidden-states for the whole input sequence.\n            hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n                of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n                Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n            attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n                :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n                Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n                heads.\n        \"\"\"", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "\n", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all", "\n", "# heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "\n", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "# causal and attention masks must have same type with pytorch", "\n", "# version < 1.3", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "attention_mask", ".", "dtype", ")", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", "\n", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", ")", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length,", "\n", "# seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "\n", "encoder_batch_size", ",", "\n", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "\n", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", ")", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "\n", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x", "\n", "# num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "\n", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "\n", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to float if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForSequenceClassification.__init__": [[801, 810], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bert_masked.MaskedBertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert_masked.MaskedBertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "MaskedBertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForSequenceClassification._make_structural_pruning": [[811, 814], ["range", "len", "modeling_bert_masked.MaskedBertForSequenceClassification.bert.encoder.layer[].make_structural_pruning"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.make_structural_pruning"], ["", "def", "_make_structural_pruning", "(", "self", ",", "blocksize", ")", ":", "\n", "        ", "for", "layer", "in", "range", "(", "len", "(", "self", ".", "bert", ".", "encoder", ".", "layer", ")", ")", ":", "\n", "            ", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "make_structural_pruning", "(", "blocksize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForSequenceClassification.forward": [[815, 883], ["transformers.file_utils.add_start_docstrings_to_model_forward", "modeling_bert_masked.MaskedBertForSequenceClassification.bert", "modeling_bert_masked.MaskedBertForSequenceClassification.dropout", "modeling_bert_masked.MaskedBertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert_masked.MaskedBertForSequenceClassification.view", "labels.view", "modeling_bert_masked.MaskedBertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "MASKED_BERT_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n            labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n                Labels for computing the sequence classification/regression loss.\n                Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n                If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n                If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n            threshold (:obj:`float`):\n                Threshold value (see :class:`~emmental.MaskedLinear`).\n\n        Returns:\n            :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~emmental.MaskedBertConfig`) and inputs:\n            loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n                Classification (or regression if config.num_labels==1) loss.\n            logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n                Classification (or regression if config.num_labels==1) scores (before SoftMax).\n            hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n                of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n                Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n            attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n                :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n                Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n                heads.\n        \"\"\"", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "# add hidden states and attention if they are here", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "\n", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering.__init__": [[891, 899], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_bert_masked.MaskedBertModel", "torch.nn.Linear", "modeling_bert_masked.MaskedBertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "MaskedBertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering._make_structural_pruning": [[900, 903], ["range", "len", "modeling_bert_masked.MaskedBertForQuestionAnswering.bert.encoder.layer[].make_structural_pruning"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.BertLayer.make_structural_pruning"], ["", "def", "_make_structural_pruning", "(", "self", ",", "blocksize", ")", ":", "\n", "        ", "for", "layer", "in", "range", "(", "len", "(", "self", ".", "bert", ".", "encoder", ".", "layer", ")", ")", ":", "\n", "            ", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "make_structural_pruning", "(", "blocksize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering.forward": [[904, 991], ["transformers.file_utils.add_start_docstrings_to_model_forward", "modeling_bert_masked.MaskedBertForQuestionAnswering.bert", "modeling_bert_masked.MaskedBertForQuestionAnswering.qa_outputs", "modeling_bert_masked.MaskedBertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "MASKED_BERT_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "threshold", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n            start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n                Labels for position (index) of the start of the labelled span for computing the token classification loss.\n                Positions are clamped to the length of the sequence (`sequence_length`).\n                Position outside of the sequence are not taken into account for computing the loss.\n            end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n                Labels for position (index) of the end of the labelled span for computing the token classification loss.\n                Positions are clamped to the length of the sequence (`sequence_length`).\n                Position outside of the sequence are not taken into account for computing the loss.\n            threshold (:obj:`float`):\n                Threshold value (see :class:`~emmental.MaskedLinear`).\n\n        Returns:\n            :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~emmental.MaskedBertConfig`) and inputs:\n            loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided):\n                Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.\n            start_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length,)`):\n                Span-start scores (before SoftMax).\n            end_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length,)`):\n                Span-end scores (before SoftMax).\n            hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n                of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n                Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n            attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n                :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n                Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n                heads.\n        \"\"\"", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "threshold", "=", "threshold", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "\n", "start_logits", ",", "\n", "end_logits", ",", "\n", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs,", "\n", "# we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.load_tf_weights_in_bert": [[23, 97], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Load tf checkpoints in a pytorch model.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "f\"Converting TensorFlow checkpoint from {tf_path}\"", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Loading TF weight {name} with shape {shape}\"", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "\n", "n", "in", "[", "\n", "\"adam_v\"", ",", "\n", "\"adam_m\"", ",", "\n", "\"AdamWeightDecayOptimizer\"", ",", "\n", "\"AdamWeightDecayOptimizer_1\"", ",", "\n", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Skipping {'/'.join(name)}\"", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Skipping {'/'.join(name)}\"", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "(", "\n", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", ")", ",", "f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\"", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "f\"Initialize PyTorch weight {name}\"", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__": [[54, 134], ["torch.nn.Linear.__init__", "torch.nn.Parameter", "masked_nn.MaskedLinear.init_mask", "torch.nn.Parameter", "torch.nn.Parameter", "masked_nn.MaskedLinear.init_mask", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "masked_nn.MaskedLinear.weight.size", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.__init__", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.init_mask", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.init_mask"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ":", "int", ",", "\n", "out_features", ":", "int", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "mask_init", ":", "str", "=", "\"constant\"", ",", "\n", "mask_scale", ":", "float", "=", "0.0", ",", "\n", "pruning_method", ":", "str", "=", "\"topK\"", ",", "\n", "head_split", ":", "int", "=", "-", "1", ",", "\n", "bias_mask", ":", "bool", "=", "False", ",", "\n", "head_pruning", ":", "bool", "=", "False", ",", "\n", "row_pruning", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            in_features (`int`)\n                Size of each input sample\n            out_features (`int`)\n                Size of each output sample\n            bias (`bool`)\n                If set to ``False``, the layer will not learn an additive bias.\n                Default: ``True``\n            mask_init (`str`)\n                The initialization method for the score matrix if a score matrix is needed.\n                Choices: [\"constant\", \"uniform\", \"kaiming\"]\n                Default: ``constant``\n            mask_scale (`float`)\n                The initialization parameter for the chosen initialization method `mask_init`.\n                Default: ``0.``\n            pruning_method (`str`)\n                Method to compute the mask.\n                Default: ``topK``\n            head_split:\n                The number of head in the layer. This can also used to make each head prune\n                out with same number of rows (so that we can do parallize forward with reshape)\n                Default: ``-1`` (means no need for head split)\n            bias_mask:\n                Prune bias or not\n                Default: False\n            head_pruning:\n                Do Head Pruning or not\n                Default: False\n            row_pruning:\n                Do Row Pruning or Not\n                Defualt: True\n        \"\"\"", "\n", "super", "(", "\n", "MaskedLinear", ",", "\n", "self", ")", ".", "__init__", "(", "\n", "in_features", "=", "in_features", ",", "\n", "out_features", "=", "out_features", ",", "\n", "bias", "=", "bias", ")", "\n", "\n", "self", ".", "pruning_method", "=", "pruning_method", "\n", "self", ".", "head_split", "=", "head_split", "\n", "self", ".", "bias_mask", "=", "bias_mask", "\n", "self", ".", "head_pruning", "=", "head_pruning", "\n", "self", ".", "row_pruning", "=", "row_pruning", "\n", "\n", "self", ".", "inference_mode", "=", "False", "\n", "# this is used for final block-wise pruning, for init we do not need to", "\n", "# worry about that!", "\n", "self", ".", "block_pruning", "=", "False", "# We will enable this when needed", "\n", "self", ".", "block_mask_scores", "=", "None", "# the mask for block wise pruning", "\n", "self", ".", "threshold_block", "=", "None", "# the threshold for block wise pruning", "\n", "\n", "self", ".", "mask_scale", "=", "mask_scale", "\n", "self", ".", "mask_init", "=", "mask_init", "\n", "if", "self", ".", "row_pruning", ":", "\n", "            ", "self", ".", "mask_scores", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "\n", "self", ".", "weight", ".", "size", "(", "0", ")", ",", "\n", "1", ")", ")", "# number of rows * 1", "\n", "self", ".", "init_mask", "(", "self", ".", "mask_scores", ")", "\n", "self", ".", "threshold_row", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", "+", "10.0", ")", "\n", "", "if", "self", ".", "head_pruning", ":", "\n", "            ", "self", ".", "head_mask_scores", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "self", ".", "head_split", ",", "1", ")", ")", "# number of heads * 1", "\n", "self", ".", "init_mask", "(", "self", ".", "head_mask_scores", ")", "\n", "self", ".", "threshold_head", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", "+", "10.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.init_mask": [[135, 142], ["torch.nn.init.constant_", "torch.nn.init.uniform_", "torch.nn.init.kaiming_uniform_", "math.sqrt"], "methods", ["None"], ["", "", "def", "init_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "if", "self", ".", "mask_init", "==", "\"constant\"", ":", "\n", "            ", "init", ".", "constant_", "(", "mask", ",", "val", "=", "self", ".", "mask_scale", ")", "\n", "", "elif", "self", ".", "mask_init", "==", "\"uniform\"", ":", "\n", "            ", "init", ".", "uniform_", "(", "mask", ",", "a", "=", "-", "self", ".", "mask_scale", ",", "b", "=", "self", ".", "mask_scale", ")", "\n", "", "elif", "self", ".", "mask_init", "==", "\"kaiming\"", ":", "\n", "            ", "init", ".", "kaiming_uniform_", "(", "mask", ",", "a", "=", "math", ".", "sqrt", "(", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_mask": [[143, 157], ["binarizer.TopKBinarizer.apply", "binarizer.TopKBinarizer.apply"], "methods", ["None"], ["", "", "def", "get_mask", "(", "self", ")", ":", "\n", "# get head mask", "\n", "        ", "if", "self", ".", "head_pruning", ":", "\n", "            ", "mask_head", "=", "TopKBinarizer", ".", "apply", "(", "\n", "self", ".", "head_mask_scores", ",", "self", ".", "threshold_head", ",", "-", "1", ")", "# for now, only support this", "\n", "", "else", ":", "\n", "            ", "mask_head", "=", "None", "\n", "\n", "", "if", "self", ".", "row_pruning", ":", "\n", "            ", "mask", "=", "TopKBinarizer", ".", "apply", "(", "\n", "self", ".", "mask_scores", ",", "self", ".", "threshold_row", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "None", "\n", "", "return", "mask_head", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_inference_pruning": [[158, 200], ["masked_nn.MaskedLinear.weight.size", "masked_nn.MaskedLinear.get_mask", "torch.ones_like.type().view", "torch.logical_and", "torch.nn.Parameter", "masked_nn.MaskedLinear.get_mask", "math.ceil", "torch.ones_like().type().view", "torch.repeat_interleave.type().view", "torch.repeat_interleave", "torch.ones_like", "torch.nn.Parameter", "math.log", "torch.ones_like.type", "torch.ones_like.sum().item", "torch.ones_like().type", "torch.repeat_interleave.type", "torch.ones_like.sum", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_mask", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_mask"], ["", "def", "make_inference_pruning", "(", "self", ",", "blocksize", ")", ":", "\n", "        ", "self", ".", "inference_mode", "=", "True", "\n", "weight_shape", "=", "self", ".", "weight", ".", "size", "(", ")", "\n", "# if there is no block wise pruning needed, we do not have to increase the", "\n", "# numner of rows/cols.", "\n", "# Otherwise, we need to pad the matrix so that the # of ros/cols is divided by", "\n", "# block size", "\n", "if", "blocksize", "[", "0", "]", "is", "not", "None", "and", "blocksize", "[", "1", "]", "is", "not", "None", "and", "self", ".", "row_pruning", ":", "\n", "            ", "rows", "=", "weight_shape", "[", "0", "]", "\n", "row_block", "=", "blocksize", "[", "0", "]", "\n", "# remain rows", "\n", "mask_head", ",", "mask", "=", "self", ".", "get_mask", "(", ")", "\n", "remaining_row_block", "=", "math", ".", "ceil", "(", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "row_block", ")", "\n", "remaining_row", "=", "remaining_row_block", "*", "row_block", "\n", "remaining_ratio", "=", "remaining_row", "/", "rows", "-", "1e-6", "\n", "self", ".", "threshold_row", ".", "data", "=", "self", ".", "threshold_row", ".", "data", "*", "0", "+", "math", ".", "log", "(", "remaining_ratio", "/", "(", "1", "-", "remaining_ratio", ")", ")", "\n", "\n", "", "mask_head", ",", "mask", "=", "self", ".", "get_mask", "(", ")", "\n", "if", "not", "self", ".", "head_pruning", ":", "\n", "            ", "mask_head", "=", "torch", ".", "ones_like", "(", "self", ".", "weight", "[", ":", ",", "0", "]", ")", ".", "type", "(", "\n", "'torch.BoolTensor'", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "mask_head", "=", "mask_head", ".", "type", "(", "'torch.BoolTensor'", ")", ".", "view", "(", "-", "1", ")", "\n", "mask_head", "=", "torch", ".", "repeat_interleave", "(", "\n", "mask_head", ",", "weight_shape", "[", "0", "]", "//", "self", ".", "head_split", ")", "\n", "", "if", "not", "self", ".", "row_pruning", ":", "\n", "            ", "mask", "=", "torch", ".", "ones_like", "(", "self", ".", "weight", "[", ":", ",", "0", "]", ")", "\n", "\n", "", "mask", "=", "mask", ".", "type", "(", "'torch.BoolTensor'", ")", ".", "view", "(", "-", "1", ")", "\n", "mask", "=", "torch", ".", "logical_and", "(", "mask_head", ",", "mask", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "self", ".", "weight", "[", "mask", ",", ":", "]", ")", "\n", "if", "self", ".", "bias_mask", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "self", ".", "bias", "[", "mask", "]", ")", "\n", "\n", "# we do not need those parameters!", "\n", "", "self", ".", "mask_scores", "=", "None", "\n", "self", ".", "head_mask_scores", "=", "None", "\n", "self", ".", "threshold_head", "=", "None", "\n", "self", ".", "threshold_row", "=", "None", "\n", "# we need this mask for some Layer O and FC2 pruning", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_column_purning": [[201, 204], ["torch.nn.Parameter"], "methods", ["None"], ["", "def", "make_column_purning", "(", "self", ",", "mask", ")", ":", "\n", "# make column pruning for Layer O and FC2", "\n", "        ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "self", ".", "weight", "[", ":", ",", "mask", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.enable_block_pruning": [[205, 220], ["torch.nn.Parameter", "masked_nn.MaskedLinear.init_mask", "torch.nn.Parameter", "masked_nn.MaskedLinear.weight.size", "masked_nn.MaskedLinear.weight.size", "torch.Tensor", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.init_mask"], ["", "def", "enable_block_pruning", "(", "self", ",", "block_size", ")", ":", "\n", "# As the name suggested, enable block wise pruning", "\n", "        ", "self", ".", "block_pruning", "=", "True", "\n", "self", ".", "block_rows", "=", "block_size", "[", "0", "]", "\n", "self", ".", "block_cols", "=", "block_size", "[", "1", "]", "\n", "mask_size_row", "=", "self", ".", "weight", ".", "size", "(", "0", ")", "//", "block_size", "[", "0", "]", "\n", "mask_size_col", "=", "self", ".", "weight", ".", "size", "(", "1", ")", "//", "block_size", "[", "1", "]", "\n", "self", ".", "block_mask_scores", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "\n", "mask_size_row", "*", "\n", "mask_size_col", ",", "\n", "1", ",", "\n", "1", ")", ")", "# number of row_block * col_block", "\n", "self", ".", "init_mask", "(", "self", ".", "block_mask_scores", ")", "\n", "self", ".", "threshold_block", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", "+", "10.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_block_wise_pruning": [[221, 226], ["binarizer.TopKBinarizer.apply"], "methods", ["None"], ["", "def", "get_block_wise_pruning", "(", "self", ")", ":", "\n", "# As the name suggested, get the block wise mask", "\n", "        ", "mask_block", "=", "TopKBinarizer", ".", "apply", "(", "\n", "self", ".", "block_mask_scores", ",", "self", ".", "threshold_block", ",", "-", "1", ")", "# for now, only support this", "\n", "return", "mask_block", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_block_wise_inference_pruning": [[227, 235], ["masked_nn.MaskedLinear._make_block_wise_inference_pruning_sparse", "masked_nn.MaskedLinear._make_block_wise_inference_pruning_base"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear._make_block_wise_inference_pruning_sparse", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear._make_block_wise_inference_pruning_base"], ["", "def", "make_block_wise_inference_pruning", "(", "self", ")", ":", "\n", "        ", "mask_block", "=", "self", ".", "get_block_wise_pruning", "(", ")", "\n", "rows", ",", "cols", "=", "self", ".", "weight", ".", "shape", "\n", "tmp_weight", "=", "blockshaped", "(", "\n", "self", ".", "weight", ",", "\n", "self", ".", "block_rows", ",", "\n", "self", ".", "block_cols", ")", "# n-block x 32 x 32", "\n", "tmp_weight", "=", "tmp_weight", "*", "mask_block", "# n-block x 1 x 1", "\n", "tmp_weight", "=", "unblockshaped", "(", "tmp_weight", ",", "rows", ",", "cols", ")", "# d x d", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.forward": [[299, 308], ["masked_nn.MaskedLinear.training_forward", "masked_nn.MaskedLinear.inference_forward", "masked_nn.MaskedLinear.block_pruning_forward"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.training_forward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.inference_forward", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.block_pruning_forward"], []], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.block_pruning_forward": [[309, 317], ["masked_nn.MaskedLinear.get_block_wise_pruning", "masked_nn.blockshaped", "masked_nn.unblockshaped", "torch.nn.functional.linear"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_block_wise_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.blockshaped", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.unblockshaped"], []], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.inference_forward": [[318, 327], ["input.view.view.view", "masked_nn.MaskedLinear.op", "out.view.view.view", "torch.nn.functional.linear"], "methods", ["None"], []], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.training_forward": [[328, 354], ["masked_nn.MaskedLinear.get_mask", "masked_nn.MaskedLinear.weight.size", "masked_nn.MaskedLinear.bias.size", "torch.nn.functional.linear", "mask.view", "masked_nn.MaskedLinear.weight.view", "masked_nn.MaskedLinear.bias.size", "masked_nn.MaskedLinear.bias.view"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_mask"], []], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.blockshaped": [[17, 29], ["arr.reshape().swapaxes().reshape", "arr.reshape().swapaxes", "arr.reshape"], "function", ["None"], ["def", "blockshaped", "(", "arr", ",", "nrows", ",", "ncols", ")", ":", "\n", "    ", "\"\"\"\n    Return an array of shape (n, nrows, ncols) where\n    n * nrows * ncols = arr.size\n\n    If arr is a 2D array, the returned array looks like n subblocks with\n    each subblock preserving the \"physical\" layout of arr.\n    \"\"\"", "\n", "h", ",", "w", "=", "arr", ".", "shape", "\n", "return", "(", "arr", ".", "reshape", "(", "h", "//", "nrows", ",", "nrows", ",", "-", "1", ",", "ncols", ")", "\n", ".", "swapaxes", "(", "1", ",", "2", ")", "\n", ".", "reshape", "(", "-", "1", ",", "nrows", ",", "ncols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.unblockshaped": [[34, 46], ["arr.reshape().swapaxes().reshape", "arr.reshape().swapaxes", "arr.reshape"], "function", ["None"], ["", "def", "unblockshaped", "(", "arr", ",", "h", ",", "w", ")", ":", "\n", "    ", "\"\"\"\n    Return an array of shape (h, w) where\n    h * w = arr.size\n\n    If arr is of shape (n, nrows, ncols), n sublocks of shape (nrows, ncols),\n    then the returned array preserves the \"physical\" layout of the sublocks.\n    \"\"\"", "\n", "n", ",", "nrows", ",", "ncols", "=", "arr", ".", "shape", "\n", "return", "(", "arr", ".", "reshape", "(", "h", "//", "nrows", ",", "-", "1", ",", "nrows", ",", "ncols", ")", "\n", ".", "swapaxes", "(", "1", ",", "2", ")", "\n", ".", "reshape", "(", "h", ",", "w", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.forward": [[22, 67], ["torch.sigmoid().item", "inputs.reshape.reshape.clone", "ctx.save_for_backward", "inputs.reshape.reshape.flatten().sort", "math.ceil", "inputs.reshape.clone.flatten", "inputs.reshape.reshape.reshape", "inputs.reshape.reshape.sort", "math.ceil", "inputs.reshape.clone.reshape", "range", "torch.sigmoid", "inputs.reshape.reshape.flatten", "inputs.reshape.reshape.numel", "inputs.reshape.reshape.size"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "inputs", ":", "torch", ".", "tensor", ",", "threshold", ":", "float", ",", "head_split", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`torch.FloatTensor`)\n                The input matrix from which the binarizer computes the binary mask.\n            threshold (`float`)\n                The percentage of weights to keep (the rest is pruned).\n                `threshold` is a float between 0 and 1.\n            head_split:\n\n                If we want to make each head remains the same number of rows (>=2)\n        Returns:\n            mask (`torch.FloatTensor`)\n                Binary matrix of the same size as `inputs` acting as a mask (1 - the associated weight is\n                retained, 0 - the associated weight is pruned).\n        \"\"\"", "\n", "# Get the subnetwork by sorting the inputs and using the top threshold", "\n", "# %", "\n", "threshold", "=", "torch", ".", "sigmoid", "(", "threshold", ")", ".", "item", "(", ")", "\n", "\n", "mask", "=", "inputs", ".", "clone", "(", ")", "\n", "if", "head_split", "<=", "1", ":", "\n", "            ", "_", ",", "idx", "=", "inputs", ".", "flatten", "(", ")", ".", "sort", "(", "descending", "=", "True", ")", "\n", "j", "=", "math", ".", "ceil", "(", "threshold", "*", "inputs", ".", "numel", "(", ")", ")", "\n", "\n", "# flat_out and mask access the same memory.", "\n", "flat_out", "=", "mask", ".", "flatten", "(", ")", "\n", "flat_out", "[", "idx", "[", "j", ":", "]", "]", "=", "0.", "\n", "flat_out", "[", "idx", "[", ":", "j", "]", "]", "=", "1.", "\n", "", "else", ":", "\n", "# make it as a 12 x 64 matrix! Then do the sorting!", "\n", "            ", "inputs", "=", "inputs", ".", "reshape", "(", "head_split", ",", "-", "1", ")", "\n", "# the default is column-wise", "\n", "_", ",", "idx", "=", "inputs", ".", "sort", "(", "-", "1", ",", "descending", "=", "True", ")", "\n", "j", "=", "math", ".", "ceil", "(", "threshold", "*", "inputs", ".", "size", "(", "1", ")", ")", "\n", "\n", "#", "\n", "flat_out", "=", "mask", ".", "reshape", "(", "head_split", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "head_split", ")", ":", "\n", "                ", "flat_out", "[", "i", ",", "idx", "[", "i", ",", "j", ":", "]", "]", "=", "0.", "\n", "flat_out", "[", "i", ",", "idx", "[", "i", ",", ":", "j", "]", "]", "=", "1.", "\n", "", "", "ctx", ".", "save_for_backward", "(", "mask", ")", "# we should try two things", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.binarizer.TopKBinarizer.backward": [[68, 72], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradOutput", ")", ":", "\n", "        ", "mask", ",", "=", "ctx", ".", "saved_tensors", "\n", "return", "gradOutput", ",", "(", "(", "gradOutput", "*", "mask", ")", ".", "sum", "(", ")", ")", ".", "view", "(", "-", "1", ")", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear._make_block_wise_inference_pruning_sparse": [[236, 283], ["masked_nn.MaskedLinear.get_block_wise_pruning", "masked_nn.MaskedLinear.weight.size", "masked_nn.MaskedLinear.weight.size", "torch.transpose().reshape.reshape().type", "torch.transpose().reshape", "triton.ops.blocksparse.matmul", "torch.transpose().reshape", "triton.testing.sparsify_tensor", "torch.nn.Parameter", "masked_nn.blockshaped", "masked_nn.unblockshaped", "torch.nn.Parameter", "torch.transpose().reshape.sum", "torch.transpose().reshape.reshape", "torch.transpose", "torch.transpose"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_block_wise_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.blockshaped", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.unblockshaped"], ["self", ".", "weight", "=", "nn", ".", "Parameter", "(", "tmp_weight", ")", "\n", "# we do not need those values anymore", "\n", "self", ".", "block_pruning", "=", "False", "\n", "self", ".", "block_mask_scores", "=", "None", "\n", "self", ".", "threshold_block", "=", "None", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "tensor", ")", ":", "\n", "        ", "if", "not", "self", ".", "inference_mode", ":", "\n", "            ", "output", "=", "self", ".", "training_forward", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "block_pruning", ":", "\n", "                ", "output", "=", "self", ".", "inference_forward", "(", "input", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "block_pruning_forward", "(", "input", ")", "\n", "", "", "return", "output", "\n", "\n", "", "def", "block_pruning_forward", "(", "self", ",", "input", ":", "torch", ".", "tensor", ")", ":", "\n", "        ", "mask_block", "=", "self", ".", "get_block_wise_pruning", "(", ")", "\n", "rows", ",", "cols", "=", "self", ".", "weight", ".", "shape", "\n", "tmp_weight", "=", "blockshaped", "(", "self", ".", "weight", ",", "self", ".", "block_rows", ",", "self", ".", "block_cols", ")", "\n", "tmp_weight", "=", "tmp_weight", "*", "mask_block", "\n", "tmp_weight", "=", "unblockshaped", "(", "tmp_weight", ",", "rows", ",", "cols", ")", "\n", "\n", "return", "F", ".", "linear", "(", "input", ",", "tmp_weight", ",", "self", ".", "bias", ")", "\n", "\n", "", "def", "inference_forward", "(", "self", ",", "input", ":", "torch", ".", "tensor", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", ",", "self", ".", "bias", ")", "\n", "\n", "", "def", "training_forward", "(", "self", ",", "input", ":", "torch", ".", "tensor", ")", ":", "\n", "        ", "mask_head", ",", "mask", "=", "self", ".", "get_mask", "(", ")", "\n", "\n", "weight_shape", "=", "self", ".", "weight", ".", "size", "(", ")", "\n", "bias_shape", "=", "self", ".", "bias", ".", "size", "(", ")", "\n", "if", "self", ".", "head_pruning", ":", "\n", "            ", "weight_thresholded", "=", "(", "\n", "self", ".", "weight", ".", "view", "(", "\n", "self", ".", "head_split", ",", "-", "1", ")", "*", "mask_head", ")", ".", "view", "(", "weight_shape", ")", "\n", "if", "self", ".", "bias_mask", ":", "\n", "                ", "bias_thresholded", "=", "(", "\n", "self", ".", "bias", ".", "view", "(", "\n", "self", ".", "head_split", ",", "-", "1", ")", "*", "mask_head", ")", ".", "view", "(", "bias_shape", ")", "\n", "", "", "else", ":", "\n", "            ", "weight_thresholded", "=", "self", ".", "weight", "\n", "bias_thresholded", "=", "self", ".", "bias", "\n", "# Mask weights with computed mask", "\n", "", "if", "self", ".", "row_pruning", ":", "\n", "            ", "weight_thresholded", "=", "mask", "*", "weight_thresholded", "\n", "if", "self", ".", "bias_mask", ":", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear._make_block_wise_inference_pruning_base": [[284, 298], ["masked_nn.MaskedLinear.get_block_wise_pruning", "masked_nn.blockshaped", "masked_nn.unblockshaped", "torch.nn.Parameter"], "methods", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.get_block_wise_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.blockshaped", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.unblockshaped"], ["                ", "bias_thresholded", "=", "mask", ".", "view", "(", "\n", "self", ".", "bias", ".", "size", "(", ")", ")", "*", "bias_thresholded", "\n", "", "else", ":", "\n", "                ", "bias_thresholded", "=", "bias_thresholded", "\n", "\n", "", "", "return", "F", ".", "linear", "(", "input", ",", "weight_thresholded", ",", "bias_thresholded", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed": [[51, 57], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.main": [[59, 253], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "masked_bert_inference.set_seed", "parser.parse_args.model_type.lower", "model_class.from_pretrained", "model_class.from_pretrained.eval", "model_class.from_pretrained.named_parameters", "model_class.from_pretrained.to", "range", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.Event", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.Event.record", "range", "torch.cuda.Event.record", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "print", "print", "print", "print", "print", "print", "torch.device", "torch.device", "torch.device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "config_class.from_pretrained", "model_class.from_pretrained._make_structural_pruning", "model_class.from_pretrained._make_structural_pruning", "model_class.from_pretrained.modules", "model_class.from_pretrained.load_state_dict", "model_class.from_pretrained.modules", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.cuda.Event.elapsed_time", "total_num_params.item", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "print", "config_class.from_pretrained", "bool", "isinstance", "torch.load", "torch.load", "torch.load", "isinstance", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_class.from_pretrained.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_class.from_pretrained.", "module.enable_block_pruning", "module.make_block_wise_inference_pruning", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "MODEL_CLASSES.keys", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "param.abs"], "function", ["home.repos.pwc.inspect_result.yaozhewei_mlpruning.inference.masked_bert_inference.set_seed", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering._make_structural_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.emmental.modeling_bert_masked.MaskedBertForQuestionAnswering._make_structural_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.enable_block_pruning", "home.repos.pwc.inspect_result.yaozhewei_mlpruning.modules.masked_nn.MaskedLinear.make_block_wise_inference_pruning"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\n", "\", \"", ".", "join", "(", "\n", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pruning_method\"", ",", "\n", "default", "=", "\"topK\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pruning Method (l0 = L0 regularization, magnitude = Magnitude pruning, topK = Movement pruning, sigmoied_threshold = Soft movement pruning).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--head_pruning\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Head Pruning or not\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "\n", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_rows\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Number of rows in a block\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_cols\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Number of cols in a block\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to pretrained block wise model\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "if", "'qqp'", "in", "args", ".", "model_name_or_path", "or", "'mnli'", "in", "args", ".", "model_name_or_path", ":", "\n", "        ", "num_labels", "=", "2", "\n", "if", "'mnli'", "in", "args", ".", "model_name_or_path", ":", "\n", "            ", "num_labels", "=", "3", "\n", "", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "'mrpc'", ",", "\n", "cache_dir", "=", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "'constant'", ",", "\n", "mask_scale", "=", "0", ",", "\n", "head_pruning", "=", "args", ".", "head_pruning", "\n", ")", "\n", "", "elif", "'squad'", "in", "args", ".", "model_name_or_path", ":", "\n", "        ", "print", "(", "'This one is used!'", ")", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "None", ",", "\n", "pruning_method", "=", "args", ".", "pruning_method", ",", "\n", "mask_init", "=", "'constant'", ",", "\n", "mask_scale", "=", "0", ",", "\n", "head_pruning", "=", "args", ".", "head_pruning", "\n", ")", "\n", "model_class", "=", "MaskedBertForQuestionAnswering", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "None", ",", "\n", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "args", ".", "block_path", "is", "None", ":", "\n", "        ", "model", ".", "_make_structural_pruning", "(", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "        ", "assert", "args", ".", "block_rows", ">=", "1", "and", "args", ".", "block_cols", ">=", "1", "\n", "model", ".", "_make_structural_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "MaskedLinear", ")", ":", "\n", "                ", "module", ".", "enable_block_pruning", "(", "[", "args", ".", "block_rows", ",", "args", ".", "block_cols", "]", ")", "\n", "", "", "model", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "f\"{args.block_path}/pytorch_model.bin\"", ")", ")", "\n", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "MaskedLinear", ")", ":", "\n", "                ", "module", ".", "make_block_wise_inference_pruning", "(", ")", "# block-sparse model", "\n", "\n", "", "", "", "total_num_params", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "total_num_params", "+=", "(", "param", ".", "abs", "(", ")", ">", "1e-8", ")", ".", "sum", "(", ")", "\n", "\n", "", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "batch_size", "=", "args", ".", "per_gpu_train_batch_size", "\n", "length", "=", "args", ".", "max_seq_length", "\n", "batch", "=", "{", "\n", "\"attention_mask\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "\"input_ids\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "\"token_type_ids\"", ":", "torch", ".", "ones", "(", "[", "batch_size", ",", "length", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", ",", "\n", "}", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "\"input_ids\"", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "\"attention_mask\"", "]", "}", "\n", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "        ", "inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "batch", "[", "\"token_type_ids\"", "]", "if", "args", ".", "model_type", "in", "[", "\n", "\"bert\"", ",", "\n", "\"masked_bert\"", ",", "\n", "\"xlnet\"", ",", "\n", "\"albert\"", "]", "else", "None", ")", "# XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids", "\n", "\n", "# warmup!!!", "\n", "", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "", "start", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "end", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "# do real measurement", "\n", "num_runs", "=", "100", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", ".", "record", "(", ")", "\n", "for", "i", "in", "range", "(", "num_runs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "", "", "end", ".", "record", "(", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "total_time", "=", "start", ".", "elapsed_time", "(", "end", ")", "/", "1000", "# s", "\n", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "'Num of Parameters: '", ",", "total_num_params", ".", "item", "(", ")", ")", "\n", "print", "(", "\n", "f'Remaining Parameters as compared to baseline: {(total_num_params/85054608*100):.2f}%'", ")", "\n", "print", "(", "f\"{num_runs/total_time * batch_size} Sentences / s\"", ")", "\n", "print", "(", "f\"{total_time/num_runs/batch_size * 1000} ms / Sentences \"", ")", "\n", "print", "(", "'*'", "*", "100", ")", "\n", "\n"]]}