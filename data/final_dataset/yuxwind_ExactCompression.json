{"home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.AverageMeter.__init__": [[680, 682], ["train_fcnn.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.AverageMeter.reset": [[683, 688], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.AverageMeter.update": [[689, 694], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.main": [[94, 474], ["parser.parse_args", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.NLLLoss", "model.to.to", "criterion.to.to", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torchvision.Normalize", "os.path.exists", "os.makedirs", "train_fcnn.get_net_width", "print", "print", "print", "print", "print", "print", "os.path.isfile", "print", "torchvision.Normalize", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.lr_scheduler.StepLR", "tqdm.tqdm", "os.path.dirname", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.load_state_dict", "print", "print", "torchvision.Grayscale", "torchvision.ToTensor", "print", "torchvision.Normalize", "print", "print", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "transform_list.append", "print", "print", "torchvision.RandomHorizontalFlip", "torchvision.RandomRotation", "torchvision.RandomAffine", "torchvision.ColorJitter", "transform_train.extend", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.to.parameters", "model.to.half", "criterion.to.half", "range", "optim.lr_scheduler.StepLR.step", "train_fcnn.train", "max", "torchvision.ToTensor", "str", "str", "torchvision.ToTensor", "transform_list.append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_fcnn.test_adversarial", "accuracies.append", "examples.append", "print", "transform_list.append", "print", "torchvision.ToTensor", "transform_list.append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "train_fcnn.validate", "print", "print", "train_fcnn.eval_active_state", "train_fcnn.find_stable_neurons", "numpy.save", "torchvision.Grayscale", "torchvision.ToTensor", "torchvision.CIFAR10", "torchvision.Grayscale", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.CIFAR10", "torchvision.ToTensor", "torchvision.ToTensor", "torchvision.CIFAR100", "torchvision.ToTensor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "torchvision.Lambda", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_fcnn.validate", "train_fcnn.save_checkpoint", "train_fcnn.save_weights_in_cplex_format", "torchvision.Grayscale", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Lambda", "torchvision.Grayscale", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.join", "torchvision.ToTensor", "torchvision.MNIST", "torchvision.ToTensor", "str", "torchvision.Grayscale", "torchvision.ToTensor", "torchvision.MNIST", "transform_train.extend", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "sys.exit", "print", "train_fcnn.eval_active_state", "train_fcnn.find_stable_neurons", "numpy.save", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "str", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.dirname", "stably_active_ind.numpy", "stably_inactive_ind.numpy", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.CIFAR10", "transform_train.extend", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "os.path.join", "model.to.state_dict", "os.path.join", "torchvision.Compose", "torchvision.ToTensor", "torchvision.CIFAR100", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "torchvision.Compose", "torchvision.CIFAR100", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "torchvision.Compose", "torch.distributions.normal.Normal.sample", "torchvision.Compose", "torchvision.ToTensor", "torchvision.CIFAR100", "stably_active_ind.numpy", "stably_inactive_ind.numpy", "str", "torchvision.Compose", "torchvision.MNIST", "torch.distributions.normal.Normal.sample", "torchvision.Compose", "torchvision.MNIST", "torchvision.Compose", "torchvision.ToTensor", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_net_width", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.train", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.test_adversarial", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.validate", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.eval_active_state", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.find_stable_neurons", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.validate", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.save_checkpoint", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.save_weights_in_cplex_format", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.eval_active_state", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.find_stable_neurons"], ["def", "main", "(", ")", ":", "\n", "    ", "global", "args", ",", "best_prec1", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "dataset", "=", "args", ".", "dataset", "\n", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "use_cuda", "=", "True", "# True", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "fcnn_flag", "=", "True", "\n", "sep", "=", "\",\"", "#This is used for separating in weights.dat file", "\n", "save_frequency", "=", "120", "\n", "\n", "\n", "# Check the save_dir exists or not", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_dir", ")", "\n", "\n", "", "if", "(", "dataset", "==", "\"CIFAR10-gray\"", ")", ":", "\n", "        ", "input_dim", "=", "1024", "\n", "class_num", "=", "10", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "        ", "input_dim", "=", "784", "\n", "class_num", "=", "10", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR10-rgb\"", ")", ":", "\n", "        ", "input_dim", "=", "1024", "*", "3", "\n", "class_num", "=", "10", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR100-rgb\"", ")", ":", "\n", "        ", "input_dim", "=", "1024", "*", "3", "\n", "class_num", "=", "100", "\n", "\n", "", "if", "args", ".", "arch", "==", "'fcnn_prune'", ":", "\n", "\n", "        ", "cfg", "=", "get_net_width", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "resume", ")", ")", "\n", "model", "=", "fcnn", ".", "__dict__", "[", "args", ".", "arch", "]", "(", "cfg", ",", "input_dim", ",", "class_num", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "fcnn", ".", "__dict__", "[", "args", ".", "arch", "]", "(", "input_dim", ",", "class_num", ")", "\n", "\n", "", "model", ".", "features", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ".", "features", ")", "\n", "\n", "# define loss function (criterion)", "\n", "# If there is no softmax, use CrossEntropyLoss()", "\n", "# If there is softmax   , use NLLLoss()", "\n", "# https://pytorch.org/docs/stable/nn.html#crossentropyloss", "\n", "# criterion = nn.CrossEntropyLoss()", "\n", "criterion", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n", "if", "not", "args", ".", "evaluate", ":", "\n", "        ", "print", "(", "\"===============================================================================\"", ")", ";", "\n", "print", "(", "\"Model :\"", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "\"\\nCriterion :\"", ")", "\n", "print", "(", "criterion", ")", "\n", "print", "(", "\"\\n===============================================================================\"", ")", ";", "\n", "\n", "# optionally resume from a checkpoint", "\n", "", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_prec1", "=", "checkpoint", "[", "'best_prec1'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "args", ".", "evaluate", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "# Transfer model and criterion to default device", "\n", "", "", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "criterion", ".", "to", "(", "device", ")", "\n", "\n", "stddev", "=", "args", ".", "std_dev", "\n", "distbn", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "0", ",", "stddev", ")", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0", "]", ",", "std", "=", "[", "1", "]", ")", "\n", "if", "(", "dataset", "==", "\"CIFAR10\"", ")", ":", "\n", "        ", "print", "(", "\"Running on CIFAR10\"", ")", "\n", "input_dim", "=", "1024", "\n", "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0", "]", ",", "std", "=", "[", "1", "]", ")", "\n", "transform_list", "=", "[", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "        ", "print", "(", "\"Running on MNIST\"", ")", "\n", "input_dim", "=", "784", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0", "]", ",", "std", "=", "[", "1", "]", ")", "#Images are already loaded in [0,1]", "\n", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "\n", "\n", "", "if", "(", "args", ".", "fix_activations", ")", ":", "\n", "        ", "print", "(", "\"Beta = \"", "+", "str", "(", "args", ".", "beta", ")", ")", "\n", "print", "(", "\"Using preactivations file \"", "+", "str", "(", "args", ".", "activation_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "beta", "=", "0", "\n", "print", "(", "\"Beta = 0\"", ")", "\n", "\n", "\n", "", "if", "args", ".", "evaluate", ":", "\n", "# For evaluation mode", "\n", "\n", "        ", "if", "args", ".", "adversarial", ":", "\n", "            ", "print", "(", "\"Carrying out adversarial attacks\"", ")", "\n", "epsilons", "=", "[", "0", ",", ".05", ",", ".1", ",", ".15", ",", ".2", ",", ".25", ",", ".3", "]", "\n", "accuracies", "=", "[", "]", "\n", "examples", "=", "[", "]", "\n", "\n", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "if", "(", "dataset", "==", "\"CIFAR10-gray\"", ")", ":", "\n", "                ", "transform_list", ".", "append", "(", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR10-rgb\"", ")", ":", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR100-rgb\"", ")", ":", "\n", "# Transform list for validation", "\n", "                ", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "root", "=", "'../data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "\n", "# Run test for each epsilon", "\n", "", "for", "eps", "in", "epsilons", ":", "\n", "                ", "acc", ",", "ex", "=", "test_adversarial", "(", "model", ",", "criterion", ",", "device", ",", "val_loader", ",", "eps", ")", "\n", "accuracies", ".", "append", "(", "acc", ")", "\n", "examples", ".", "append", "(", "ex", ")", "\n", "", "return", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "augmentation", ":", "\n", "                ", "print", "(", "\"Using augmentation. Std deviation of the noise while testing/evaluation = \"", "+", "str", "(", "stddev", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "img", "+", "distbn", ".", "sample", "(", "img", ".", "shape", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"No augmentation used in testing\"", ")", "\n", "\n", "", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "if", "(", "dataset", "==", "\"CIFAR10-gray\"", ")", ":", "\n", "                ", "transform_list", ".", "append", "(", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "args", ".", "eval_train_data", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "#features, acc = get_features(val_loader, model, criterion)", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR10-rgb\"", ")", ":", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"CIFAR100-rgb\"", ")", ":", "\n", "# Transform list for validation", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "args", ".", "eval_train_data", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "", "print", "(", "'datasize:'", ",", "len", "(", "val_loader", ".", "dataset", ")", ")", "\n", "if", "not", "args", ".", "eval_stable", ":", "\n", "                ", "acc", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "1", ",", "device", ",", "fcnn_flag", ")", "\n", "print", "(", "'acc:'", ",", "acc", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'load checkpoints: '", ",", "args", ".", "resume", ")", "\n", "active_states", ",", "acc", "=", "eval_active_state", "(", "val_loader", ",", "model", ",", "criterion", ",", "fcnn_flag", ")", "\n", "# Get the index of stable neurons, the input is layer 0 and the layer index starts from 1  ", "\n", "stably_active_ind", ",", "stably_inactive_ind", "=", "find_stable_neurons", "(", "active_states", ")", "\n", "# write the index into the checkpoints' folder", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "resume", ")", ",", "'stable_neurons.npy'", ")", ",", "{", "\n", "'stably_active'", ":", "stably_active_ind", ".", "numpy", "(", ")", ",", "\n", "'stably_inactive'", ":", "stably_inactive_ind", ".", "numpy", "(", ")", "\n", "}", ")", "\n", "# Write model weights in CPLEX Format", "\n", "#save_weights_in_cplex_format(model, os.path.dirname(args.resume), os.path.basename(args.resume), input_dim, acc, sep)", "\n", "\n", "\n", "# Write tensor to csv file for future use in the same directory as save", "\n", "#features_folder       = os.path.dirname(args.resume)", "\n", "\n", "\n", "#print(\"\\nFeatures [{0}x{1}]\".format(features.shape[0],features.shape[1]))", "\n", "#features_folder      = 'features/'", "\n", "#activations_file_name = dataset + args.arch + \"_noise_\" + str(stddev) + \"_smx.txt\"", "\n", "#activations_file_path = os.path.join(features_folder,activations_file_name)", "\n", "#write_tensor_to_csv_file(features, activations_file_path)", "\n", "#print(\"Saved to \" + activations_file_path + \"\\n\")", "\n", "\n", "", "return", "\n", "\n", "\n", "", "", "else", ":", "\n", "#For training mode", "\n", "\n", "\n", "        ", "if", "(", "dataset", "==", "\"CIFAR10-gray\"", ")", ":", "\n", "# Transform list for validation", "\n", "            ", "transform_list", "=", "[", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Transform list for training", "\n", "transform_list", "=", "[", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "", "if", "(", "dataset", "==", "\"CIFAR10-rgb\"", ")", ":", "\n", "# Transform list for validation", "\n", "            ", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Transform list for training", "\n", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "", "if", "(", "dataset", "==", "\"CIFAR100-rgb\"", ")", ":", "\n", "# Transform list for validation", "\n", "            ", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Transform list for training", "\n", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "# Transform list for validation", "\n", "            ", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Transform list for training", "\n", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "\n", "\n", "\n", "", "if", "args", ".", "augmentation", ":", "\n", "            ", "print", "(", "\"Using augmentation. Std deviation of the noise while training = \"", "+", "str", "(", "stddev", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "img", "+", "distbn", ".", "sample", "(", "img", ".", "shape", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"No data augmentation added in training\"", ")", "\n", "\n", "", "if", "args", ".", "adversarial", ":", "\n", "            ", "print", "(", "\"Using adversarial training with lr = %0.2f, epsilon = %0.2f, iterations = %d\"", "%", "(", "adversarial_step_size", ",", "adversarial_epsilon", ",", "adversarial_iterations", ")", ")", "\n", "\n", "", "print", "(", "\"\\nModel save folder  = %s\"", "%", "(", "args", ".", "save_dir", ")", ")", "\n", "print", "(", "\"-------------------------------\"", ")", "\n", "print", "(", "\"Optimisation Parameters\"", ")", "\n", "print", "(", "\"-------------------------------\"", ")", "\n", "print", "(", "\"lr                 = %.4f\"", "%", "(", "args", ".", "lr", ")", ")", "\n", "print", "(", "\"momentum           = %.4f\"", "%", "(", "args", ".", "momentum", ")", ")", "\n", "print", "(", "\"weight decay       = %.4f\"", "%", "(", "args", ".", "wd", ")", ")", "\n", "print", "(", "\"l1 regul           = %.4f\"", "%", "(", "args", ".", "l1", ")", ")", "\n", "print", "(", "\"epochs             = %d\"", "%", "(", "args", ".", "epochs", ")", ")", "\n", "print", "(", "\"lr decay step size = %d\"", "%", "(", "lr_decay_step_size", ")", ")", "\n", "print", "(", "\"lr decay gamma     = %.2f\"", "%", "(", "lr_decay_gamma", ")", ")", "\n", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "transform_train", "=", "[", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "# FLips the image w.r.t horizontal axis", "\n", "transforms", ".", "RandomRotation", "(", "10", ")", ",", "#Rotates the image to a specified angel", "\n", "transforms", ".", "RandomAffine", "(", "0", ",", "shear", "=", "10", ",", "scale", "=", "(", "0.8", ",", "1.2", ")", ")", ",", "#Performs actions like zooms, change shear angles.", "\n", "transforms", ".", "ColorJitter", "(", "brightness", "=", "0.2", ",", "contrast", "=", "0.2", ",", "saturation", "=", "0.2", ")", ",", "# Set the color params", "\n", "]", "\n", "if", "(", "dataset", "==", "\"CIFAR10-gray\"", ")", ":", "\n", "            ", "transform_train", ".", "extend", "(", "[", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_train", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "            ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "'CIFAR10-rgb'", ")", ":", "\n", "            ", "transform_train", ".", "extend", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_train", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "elif", "(", "dataset", "==", "'CIFAR100-rgb'", ")", ":", "\n", "            ", "transform_train", ".", "extend", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR100", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_train", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "#import pdb;pdb.set_trace()", "\n", "# Optimizer", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ",", "weight_decay", "=", "args", ".", "wd", ")", "\n", "\n", "# Learning Rate Scheduler", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "lr_decay_step_size", ",", "gamma", "=", "lr_decay_gamma", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "model", ".", "half", "(", ")", "\n", "criterion", ".", "half", "(", ")", "\n", "\n", "# Start training", "\n", "", "for", "epoch", "in", "tqdm", "(", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ")", ":", "\n", "\n", "#TODO: adjust for the CIFAR10-rgb, cifar100-rgb ", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "## adjust the learning rate", "\n", "#if (dataset == \"CIFAR10\"):", "\n", "#    scheduler.step()", "\n", "#    #adjust_learning_rate(optimizer, epoch)", "\n", "#elif (dataset == \"MNIST\"):", "\n", "#    scheduler.step()", "\n", "#else:", "\n", "#    print(\"Unknown Dataset\")", "\n", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "device", ",", "fcnn_flag", ",", "args", ")", "\n", "\n", "# evaluate on validation set", "\n", "if", "(", "epoch", "%", "save_frequency", "==", "0", ")", ":", "\n", "                ", "prec1", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "epoch", ",", "device", ",", "fcnn_flag", ")", "\n", "\n", "# For MNIST dataset, if accuracy is close to 10%, the model did not converge.", "\n", "# Stop training it further. Saves some time especially with adversarial training.", "\n", "if", "(", "epoch", ">", "0", "and", "dataset", "==", "\"MNIST\"", "and", "prec1", "<", "12", ")", ":", "\n", "                    ", "sys", ".", "exit", "(", "\"Model DNC!!!\"", ")", "\n", "", "if", "args", ".", "eval_stable", ":", "\n", "                    ", "print", "(", "'===========eval_stable============'", ")", "\n", "active_states", ",", "acc", "=", "eval_active_state", "(", "train_loader", ",", "model", ",", "criterion", ",", "fcnn_flag", ")", "\n", "# Get the index of stable neurons, the input is layer 0 and the layer index starts from 1  ", "\n", "stably_active_ind", ",", "stably_inactive_ind", "=", "find_stable_neurons", "(", "active_states", ")", "\n", "# write the index into the checkpoints' folder", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "f'stable_neurons.npy'", ")", ",", "{", "\n", "'stably_active'", ":", "stably_active_ind", ".", "numpy", "(", ")", ",", "\n", "'stably_inactive'", ":", "stably_inactive_ind", ".", "numpy", "(", ")", "\n", "}", ")", "\n", "\n", "# remember best prec@1", "\n", "", "", "is_best", "=", "prec1", ">", "best_prec1", "\n", "best_prec1", "=", "max", "(", "prec1", ",", "best_prec1", ")", "\n", "\n", "# save the model and write weights in CPLEX Format", "\n", "if", "(", "epoch", ">", "0", "and", "epoch", "%", "save_frequency", "==", "0", ")", ":", "\n", "                ", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_prec1'", ":", "best_prec1", ",", "\n", "}", ",", "is_best", ",", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "'checkpoint_{}.tar'", ".", "format", "(", "epoch", ")", ")", ")", "\n", "\n", "save_weights_in_cplex_format", "(", "model", ",", "args", ".", "save_dir", ",", "\"checkpoint_\"", "+", "str", "(", "epoch", ")", "+", "\".tar\"", ",", "input_dim", ",", "prec1", ",", "sep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.train": [[479, 618], ["train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "model.train", "time.time", "enumerate", "train_fcnn.AverageMeter.update", "model", "optimizer.zero_grad", "loss.float.backward", "optimizer.step", "output.float.float", "loss.float.float", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "time.time", "data.half.to", "target.to", "data.half.view", "data.half.half", "train_fcnn.get_prior_activations", "prior.type.type", "mask.type.type", "model.modules", "train_fcnn.accuracy", "loss.float.item", "data.half.size", "prec1.item", "data.half.size", "train_fcnn.pgd_attack", "model", "optimizer.zero_grad", "loss.float.backward", "optimizer.step", "output.float.float", "loss.float.float", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "time.time", "time.time", "act.type", "act.type", "criterion", "isinstance", "criterion", "time.time", "train_fcnn.get_prior_activations", "prior.type.type", "mask.type.type", "model.modules", "train_fcnn.accuracy", "loss.float.item", "data.half.size", "prec1.item", "data.half.size", "torch.l1_loss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "act.type", "act.type", "criterion", "isinstance", "criterion", "time.time", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.l1_loss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.train", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_prior_activations", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.pgd_attack", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_prior_activations", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy"], ["", "", "", "", "def", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "device", ",", "fcnn_flag", ",", "args", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "adv_losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "adv_top1", "=", "AverageMeter", "(", ")", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "i", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "# Send the data and label to the device", "\n", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "\n", "if", "fcnn_flag", ":", "\n", "            ", "data", "=", "data", ".", "view", "(", "data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "", "if", "args", ".", "half", ":", "\n", "            ", "data", "=", "data", ".", "half", "(", ")", "\n", "\n", "# Carry out adeversarial training as well", "\n", "", "if", "args", ".", "adversarial", ":", "\n", "# Set requires_grad attribute of tensor. Important for Adversarial Training", "\n", "            ", "data", ".", "requires_grad", "=", "True", "\n", "\n", "# compute output", "\n", "", "output", ",", "act", "=", "model", "(", "data", ")", "\n", "\n", "if", "(", "args", ".", "fix_activations", ")", ":", "\n", "#read csv file", "\n", "            ", "prior", ",", "mask", "=", "get_prior_activations", "(", "target", ",", "args", ".", "activation_path", ")", "\n", "prior", "=", "prior", ".", "type", "(", "act", ".", "type", "(", ")", ")", "\n", "mask", "=", "mask", ".", "type", "(", "act", ".", "type", "(", ")", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "+", "args", ".", "beta", "*", "F", ".", "l1_loss", "(", "act", "*", "mask", ",", "prior", "*", "mask", ")", "#Check the loss here", "\n", "", "else", ":", "\n", "            ", "regularization_loss", "=", "0", "\n", "# compute the l1 loss", "\n", "# https://discuss.pytorch.org/t/how-to-create-compound-loss-mse-l1-norm-regularization/17171/4", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                    ", "regularization_loss", "+=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "m", ".", "weight", ")", ")", "\n", "#break # for the l1 regularization on the first layer itself break", "\n", "", "", "loss", "=", "criterion", "(", "output", ",", "target", ")", "+", "args", ".", "l1", "*", "regularization_loss", "\n", "\n", "# compute gradient and do SGD step", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Calculate gradients of model in backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target", ")", "[", "0", "]", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "\"\"\"\n        if i % args.print_freq == 0:\n            print('Epoch Gen: [{0}][{1}/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                      epoch, i, len(train_loader), batch_time=batch_time,\n                      data_time=data_time, loss=losses, top1=top1))\n        \"\"\"", "\n", "\n", "# Carry out adeversarial training as well", "\n", "if", "args", ".", "adversarial", ":", "\n", "# Collect datagrad", "\n", "            ", "data_grad", "=", "data", ".", "grad", ".", "data", "\n", "\n", "# *************************************** Check Here ****************************", "\n", "# Call FGSM Attack or PGD", "\n", "#perturbed_data = fgsm_attack(data, adversarial_epsilon, data_grad)", "\n", "perturbed_data", "=", "pgd_attack", "(", "data", ",", "adversarial_epsilon", ",", "data_grad", ",", "adversarial_step_size", ",", "adversarial_iterations", ")", "\n", "\n", "# compute output", "\n", "output", ",", "act", "=", "model", "(", "perturbed_data", ")", "\n", "\n", "if", "(", "args", ".", "fix_activations", ")", ":", "\n", "#read csv file", "\n", "                ", "prior", ",", "mask", "=", "get_prior_activations", "(", "target", ",", "args", ".", "activation_path", ")", "\n", "prior", "=", "prior", ".", "type", "(", "act", ".", "type", "(", ")", ")", "\n", "mask", "=", "mask", ".", "type", "(", "act", ".", "type", "(", ")", ")", "\n", "# ****************************** Check Loss Here ****************************", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "+", "args", ".", "beta", "*", "F", ".", "l1_loss", "(", "act", "*", "mask", ",", "prior", "*", "mask", ")", "#Check the loss here", "\n", "", "else", ":", "\n", "                ", "regularization_loss", "=", "0", "\n", "# compute the l1 loss", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                        ", "regularization_loss", "+=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "m", ".", "weight", ")", ")", "\n", "break", "# for the l1 regularization on the first layer itself", "\n", "", "", "loss", "=", "criterion", "(", "output", ",", "target", ")", "+", "args", ".", "l1", "*", "regularization_loss", "\n", "\n", "# compute gradient and do SGD step", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Calculate gradients of model in backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target", ")", "[", "0", "]", "\n", "adv_losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "adv_top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "\"\"\"\n            if i % args.print_freq == 0:\n                print('Epoch Adv: [{0}][{1}/{2}]\\t'\n                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n                          epoch, i, len(train_loader), batch_time=batch_time,\n                          data_time=data_time, loss=adv_losses, top1=adv_top1))\n            \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.validate": [[624, 673], ["train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "model.eval", "time.time", "enumerate", "print", "model", "criterion", "output.float.float", "loss.float.float", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "time.time", "data.view.to", "target.to", "data.view.half", "data.view.view", "train_fcnn.accuracy", "loss.float.item", "data.view.size", "prec1.item", "data.view.size", "print", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy"], ["", "", "", "def", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "epoch", ",", "device", ",", "fcnn_flag", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "\n", "# Send the data and label to the device", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "data", "=", "data", ".", "half", "(", ")", "\n", "\n", "", "if", "fcnn_flag", ":", "\n", "            ", "data", "=", "data", ".", "view", "(", "data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# compute output", "\n", "", "output", ",", "_", "=", "model", "(", "data", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target", ")", "[", "0", "]", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "print", "(", "'Test: [{0}/{1}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'", ".", "format", "(", "\n", "i", ",", "len", "(", "val_loader", ")", ",", "batch_time", "=", "batch_time", ",", "loss", "=", "losses", ",", "\n", "top1", "=", "top1", ")", ")", "\n", "\n", "", "", "print", "(", "'Epoch: [{0}] * Prec@1 {top1.avg:.3f}'", "\n", ".", "format", "(", "epoch", ",", "top1", "=", "top1", ")", ")", "\n", "\n", "return", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.accuracy": [[700, 714], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "\n", "    ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.save_checkpoint": [[721, 723], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.save_weights_in_cplex_format": [[728, 789], ["os.path.join", "model.state_dict", "model.state_dict.items", "open", "my_file.write", "my_file.write", "my_file.write", "my_file.write", "my_file.write", "range", "my_file.write", "my_file.write", "range", "my_file.write", "hidden.append", "weights.append", "bias.append", "len", "range", "len", "my_file.write", "value.cpu().detach().numpy", "value.cpu().detach().numpy", "my_file.write", "os.path.join", "str", "str", "value.cpu().detach", "value.cpu().detach", "map", "sep.join", "sep.join", "map", "value.cpu", "value.cpu", "map"], "function", ["None"], ["", "def", "save_weights_in_cplex_format", "(", "model", ",", "folder", ",", "file_name", ",", "input_dim", ",", "acc", ",", "sep", ")", ":", "\n", "\n", "# Writing weights and bias to a file", "\n", "    ", "dat_file_path", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "\"weights.dat\"", ")", "\n", "\n", "# Use a list to store the weights. We donot unravel it here since we will be", "\n", "# writing one row in one line in the dat file.", "\n", "weights", "=", "[", "]", "\n", "bias", "=", "[", "]", "\n", "\n", "params", "=", "model", ".", "state_dict", "(", ")", "\n", "layers", "=", "0", "\n", "hidden", "=", "[", "input_dim", "]", "\n", "\n", "\n", "# Python3 uses params.items()", "\n", "# Python2 uses params.iteritems()", "\n", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "if", "(", "'weight'", "in", "key", ")", ":", "\n", "            ", "layers", "+=", "1", "\n", "hidden", ".", "append", "(", "value", ".", "shape", "[", "0", "]", ")", "\n", "weights", ".", "append", "(", "value", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "if", "(", "'bias'", "in", "key", ")", ":", "\n", "            ", "bias", ".", "append", "(", "value", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "with", "open", "(", "dat_file_path", ",", "'w'", ")", "as", "my_file", ":", "\n", "\n", "        ", "my_file", ".", "write", "(", "\"//Model path = \"", "+", "os", ".", "path", ".", "join", "(", "folder", ",", "file_name", ")", "+", "\"\\n\"", ")", "\n", "my_file", ".", "write", "(", "\"//Classification accuracy = \"", "+", "str", "(", "acc", ")", "+", "\"%\\n\\n\"", ")", "\n", "my_file", ".", "write", "(", "\"levels = \"", "+", "str", "(", "layers", ")", "+", "\";\\n\\n\"", ")", "\n", "my_file", ".", "write", "(", "\"n = [\"", "+", "', '", ".", "join", "(", "map", "(", "str", ",", "hidden", ")", ")", "+", "\"];\\n\\n\"", ")", "\n", "\n", "# Write weights", "\n", "my_file", ".", "write", "(", "\"W = [\"", "+", "\"\\n\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "weights", ")", ")", ":", "\n", "            ", "temp", "=", "weights", "[", "i", "]", "\n", "row", ",", "col", "=", "temp", ".", "shape", "\n", "for", "j", "in", "range", "(", "row", ")", ":", "\n", "                ", "if", "(", "i", "+", "j", "==", "0", ")", ":", "\n", "                    ", "prefix", "=", "\"\"", "\n", "", "else", ":", "\n", "                    ", "prefix", "=", "sep", "\n", "", "my_file", ".", "write", "(", "prefix", "+", "sep", ".", "join", "(", "map", "(", "str", ",", "temp", "[", "j", "]", ")", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "my_file", ".", "write", "(", "\"];\"", "+", "\"\\n\\n\"", ")", "\n", "\n", "# Write bias", "\n", "my_file", ".", "write", "(", "\"B = [\"", "+", "\"\\n\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "bias", ")", ")", ":", "\n", "            ", "temp", "=", "bias", "[", "i", "]", "\n", "row", ",", "=", "temp", ".", "shape", "\n", "\n", "if", "(", "i", "==", "0", ")", ":", "\n", "                ", "prefix", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "prefix", "=", "sep", "\n", "\n", "", "my_file", ".", "write", "(", "prefix", "+", "sep", ".", "join", "(", "map", "(", "str", ",", "temp", ")", ")", "+", "\"\\n\"", ")", "\n", "", "my_file", ".", "write", "(", "\"];\"", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_features": [[794, 868], ["train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.eval", "time.time", "enumerate", "print", "len", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.classifier[].register_forward_hook", "model.classifier[].register_forward_hook", "model", "model.classifier[].register_forward_hook.remove", "model.classifier[].register_forward_hook.remove", "target.squeeze", "pred.squeeze", "torch.relu().reshape", "torch.relu().reshape", "criterion", "output.float.float", "loss.float.float", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "time.time", "input_var.half.half", "torch.zeros.copy_", "torch.zeros.copy_", "output.float.max", "train_fcnn.accuracy", "input.size", "input.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.relu", "torch.relu", "time.time"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy"], ["", "", "def", "get_features", "(", "val_loader", ",", "model", ",", "criterion", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "\n", "shift", "=", "2", "\n", "activations", "=", "torch", ".", "zeros", "(", "len", "(", "val_loader", ".", "dataset", ")", ",", "shift", "+", "1024", ")", "\n", "#print(len(val_loader.dataset))", "\n", "itr", "=", "0", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "# target = target.cuda(async=True)", "\n", "        ", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ")", ".", "cuda", "(", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "target", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "input_var", "=", "input_var", ".", "half", "(", ")", "\n", "\n", "\n", "# output of feature boxes to contain the activations", "\n", "", "fc1_features", "=", "torch", ".", "zeros", "(", "input_var", ".", "shape", "[", "0", "]", ",", "512", ")", "\n", "fc2_features", "=", "torch", ".", "zeros", "(", "input_var", ".", "shape", "[", "0", "]", ",", "512", ")", "\n", "\n", "def", "copy_1", "(", "m", ",", "i", ",", "o", ")", ":", "\n", "            ", "fc1_features", ".", "copy_", "(", "o", ".", "data", ")", "\n", "", "def", "copy_2", "(", "m", ",", "i", ",", "o", ")", ":", "\n", "            ", "fc2_features", ".", "copy_", "(", "o", ".", "data", ")", "\n", "\n", "\n", "# attach hooks", "\n", "", "h1", "=", "model", ".", "classifier", "[", "1", "]", ".", "register_forward_hook", "(", "copy_1", ")", "\n", "h2", "=", "model", ".", "classifier", "[", "4", "]", ".", "register_forward_hook", "(", "copy_2", ")", "\n", "\n", "# compute output", "\n", "output", ",", "_", "=", "model", "(", "input_var", ")", "\n", "\n", "# remove hooks", "\n", "h1", ".", "remove", "(", ")", "\n", "h2", ".", "remove", "(", ")", "\n", "\n", "start_id", "=", "i", "*", "args", ".", "test_batch_size", "\n", "end_id", "=", "(", "i", "+", "1", ")", "*", "args", ".", "test_batch_size", "\n", "\n", "pred", "=", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "# get the index of the max log-probability", "\n", "\n", "activations", "[", "start_id", ":", "end_id", ",", "0", "]", "=", "target", ".", "squeeze", "(", ")", "\n", "activations", "[", "start_id", ":", "end_id", ",", "1", "]", "=", "pred", ".", "squeeze", "(", ")", "\n", "activations", "[", "start_id", ":", "end_id", ",", "(", "shift", "+", "0", ")", ":", "(", "shift", "+", "512", ")", "]", "=", "F", ".", "relu", "(", "fc1_features", ")", ".", "reshape", "(", "input", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "activations", "[", "start_id", ":", "end_id", ",", "(", "shift", "+", "512", ")", ":", "(", "shift", "+", "1024", ")", "]", "=", "F", ".", "relu", "(", "fc2_features", ")", ".", "reshape", "(", "input", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "target_var", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target", ")", "[", "0", "]", "\n", "losses", ".", "update", "(", "loss", ".", "data", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "\n", "", "print", "(", "' * Prec@1 {top1.avg:.3f}'", "\n", ".", "format", "(", "top1", "=", "top1", ")", ")", "\n", "\n", "return", "activations", ",", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.eval_active_state": [[872, 941], ["train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "train_fcnn.AverageMeter", "model.eval", "time.time", "enumerate", "print", "model.features.module.__len__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "model", "range", "range", "criterion", "output.float.float", "loss.float.float", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "train_fcnn.AverageMeter.update", "time.time", "range", "len", "range", "input_var.view.half", "input_var.view.view", "hooks.append", "hooks[].remove", "output.float.max", "train_fcnn.accuracy", "input.size", "input.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "o.detach().cpu", "model.features.module[].register_forward_hook", "time.time", "train_fcnn.eval_active_state.get_linear"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy"], ["", "def", "eval_active_state", "(", "val_loader", ",", "model", ",", "criterion", ",", "fcnn_flag", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "\n", "shift", "=", "2", "\n", "linear_cnt", "=", "model", ".", "features", ".", "module", ".", "__len__", "(", ")", "//", "3", "\n", "linear_width", "=", "[", "model", ".", "features", ".", "module", "[", "i", "*", "3", "]", ".", "out_features", "for", "i", "in", "range", "(", "linear_cnt", ")", "]", "\n", "active_states", "=", "[", "torch", ".", "zeros", "(", "len", "(", "val_loader", ".", "dataset", ")", ",", "linear_width", "[", "i", "]", ")", "for", "i", "in", "range", "(", "linear_cnt", ")", "]", "\n", "batch_size", "=", "val_loader", ".", "batch_size", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "# target = target.cuda(async=True)", "\n", "        ", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "input", ")", ".", "cuda", "(", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "target", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "input_var", "=", "input_var", ".", "half", "(", ")", "\n", "\n", "", "if", "fcnn_flag", ":", "\n", "            ", "input_var", "=", "input_var", ".", "view", "(", "input_var", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "", "linear", "=", "{", "}", "\n", "def", "get_linear", "(", "name", ")", ":", "\n", "            ", "def", "hook", "(", "m", ",", "i", ",", "o", ")", ":", "\n", "                ", "linear", "[", "name", "]", "=", "o", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "return", "hook", "\n", "\n", "# attach hooks", "\n", "", "hooks", "=", "[", "]", "\n", "for", "layer_i", "in", "range", "(", "linear_cnt", ")", ":", "\n", "            ", "hooks", ".", "append", "(", "model", ".", "features", ".", "module", "[", "layer_i", "*", "3", "]", ".", "register_forward_hook", "(", "get_linear", "(", "f'fc{layer_i+1}'", ")", ")", ")", "\n", "\n", "# compute output", "\n", "", "output", ",", "_", "=", "model", "(", "input_var", ")", "\n", "\n", "# remove hooks", "\n", "for", "layer_i", "in", "range", "(", "linear_cnt", ")", ":", "\n", "            ", "hooks", "[", "layer_i", "]", ".", "remove", "(", ")", "\n", "\n", "\n", "", "pred", "=", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "# get the index of the max log-probability", "\n", "\n", "start_id", "=", "i", "*", "batch_size", "\n", "end_id", "=", "start_id", "+", "input_var", ".", "shape", "[", "0", "]", "\n", "for", "layer_i", "in", "range", "(", "linear_cnt", ")", ":", "\n", "            ", "active_states", "[", "layer_i", "]", "[", "start_id", ":", "end_id", "]", "=", "linear", "[", "f'fc{layer_i+1}'", "]", ">=", "0", "\n", "", "loss", "=", "criterion", "(", "output", ",", "target_var", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target_var", ")", "[", "0", "]", "\n", "losses", ".", "update", "(", "loss", ".", "data", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "print", "(", "f' * Prec@1 {top1.avg:.3f}  Elapsed time: {batch_time.sum:.3f}s'", ")", "\n", "\n", "return", "active_states", ",", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.find_stable_neurons": [[946, 974], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "torch.cat.append", "torch.cat.append", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "layer_state.sum", "layer_state.sum"], "function", ["None"], ["", "def", "find_stable_neurons", "(", "active_states", ")", ":", "\n", "    ", "stably_active_neurons", "=", "[", "]", "\n", "stably_inactive_neurons", "=", "[", "]", "\n", "for", "layer_idx", ",", "layer_state", "in", "enumerate", "(", "active_states", ")", ":", "\n", "# width is the neuron number in this layer", "\n", "        ", "data_size", ",", "width", "=", "layer_state", ".", "shape", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "# get the index of stable neurons in this layer ", "\n", "stably_active_idx", "=", "(", "layer_state", ".", "sum", "(", "dim", "=", "0", ")", "==", "data_size", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "[", ":", ",", "None", "]", "\n", "stably_inactive_idx", "=", "(", "layer_state", ".", "sum", "(", "dim", "=", "0", ")", "==", "0", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", "[", ":", ",", "None", "]", "\n", "\n", "# concatenate the layer index", "\n", "stably_active_idx", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "ones_like", "(", "stably_active_idx", ")", "*", "(", "layer_idx", "+", "1", ")", ",", "stably_active_idx", "]", ",", "dim", "=", "1", ")", "\n", "stably_inactive_idx", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "ones_like", "(", "stably_inactive_idx", ")", "*", "(", "layer_idx", "+", "1", ")", ",", "stably_inactive_idx", "]", ",", "dim", "=", "1", ")", "\n", "\n", "print", "(", "f'{layer_idx}-th layer: stably_active={stably_active_idx.shape[0]}, stably_inactive={stably_inactive_idx.shape[0]}'", ")", "\n", "stably_active_neurons", ".", "append", "(", "stably_active_idx", ")", "\n", "stably_inactive_neurons", ".", "append", "(", "stably_inactive_idx", ")", "\n", "\n", "", "stably_active_neurons", "=", "torch", ".", "cat", "(", "stably_active_neurons", ",", "dim", "=", "0", ")", "\n", "stably_inactive_neurons", "=", "torch", ".", "cat", "(", "stably_inactive_neurons", ",", "dim", "=", "0", ")", "\n", "\n", "print", "(", "f'Overall stably active: {stably_active_neurons.shape[0]}, stably inactive: {stably_inactive_neurons.shape[0]}'", ")", "\n", "\n", "return", "stably_active_neurons", ",", "stably_inactive_neurons", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.write_tensor_to_csv_file": [[978, 980], ["numpy.savetxt", "numpy.asarray"], "function", ["None"], ["", "def", "write_tensor_to_csv_file", "(", "subtensor", ",", "file_path", ")", ":", "\n", "    ", "np", ".", "savetxt", "(", "file_path", ",", "np", ".", "asarray", "(", "subtensor", ")", ",", "delimiter", "=", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_prior_activations": [[986, 1001], ["numpy.loadtxt", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "get_prior_activations", "(", "labels", ",", "activations_file_path", ")", ":", "\n", "    ", "activations", "=", "np", ".", "loadtxt", "(", "activations_file_path", ",", "delimiter", "=", "','", ")", "\n", "\n", "mask", "=", "np", ".", "zeros", "(", "activations", ".", "shape", ")", "\n", "mask", "[", "activations", "==", "1.0", "]", "=", "1", "\n", "mask", "[", "activations", "==", "0.0", "]", "=", "1", "\n", "\n", "# get the tensors now", "\n", "activations", "=", "torch", ".", "from_numpy", "(", "activations", ")", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "\n", "output1", "=", "activations", "[", "labels", ",", ":", "]", "\n", "output2", "=", "mask", "[", "labels", ",", ":", "]", "\n", "\n", "return", "output1", ",", "output2", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.basic_fgsm_attack": [[1007, 1014], ["data_grad.sign"], "function", ["None"], ["", "def", "basic_fgsm_attack", "(", "image", ",", "step_size", ",", "data_grad", ")", ":", "\n", "# Collect the element-wise sign of the data gradient", "\n", "    ", "sign_data_grad", "=", "data_grad", ".", "sign", "(", ")", "\n", "# Create the perturbed image", "\n", "perturbed_image", "=", "image", "+", "step_size", "*", "sign_data_grad", "\n", "\n", "return", "perturbed_image", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.fgsm_attack": [[1019, 1027], ["train_fcnn.basic_fgsm_attack", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.basic_fgsm_attack"], ["", "def", "fgsm_attack", "(", "image", ",", "step_size", ",", "data_grad", ")", ":", "\n", "    ", "perturbed_image", "=", "basic_fgsm_attack", "(", "image", ",", "step_size", ",", "data_grad", ")", "\n", "\n", "# Adding clipping to maintain [0,1] range", "\n", "perturbed_image", "=", "torch", ".", "clamp", "(", "perturbed_image", ",", "0", ",", "1", ")", "\n", "\n", "# Return the perturbed image", "\n", "return", "perturbed_image", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.pgd_attack": [[1035, 1053], ["image.clone", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.zeros().type", "torch.ones().type", "torch.ones().type", "torch.ones().type", "torch.ones().type", "torch.ones().type", "torch.ones().type", "torch.ones().type", "range", "image.type", "image.type", "train_fcnn.basic_fgsm_attack", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.basic_fgsm_attack"], ["", "def", "pgd_attack", "(", "image", ",", "epsilon", ",", "data_grad", ",", "step_size", ",", "n_iterations", ")", ":", "\n", "\n", "    ", "perturbed_image", "=", "image", ".", "clone", "(", ")", "\n", "zero_tensor", "=", "torch", ".", "zeros", "(", "image", ".", "shape", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "ones_tensor", "=", "torch", ".", "ones", "(", "image", ".", "shape", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_iterations", ")", ":", "\n", "        ", "perturbed_image_new", "=", "basic_fgsm_attack", "(", "perturbed_image", ",", "step_size", ",", "data_grad", ")", "\n", "\n", "# Adding clipping to remain in epsilon neighbourhood of the original image", "\n", "temp", "=", "torch", ".", "max", "(", "perturbed_image_new", ",", "image", "-", "epsilon", ")", "\n", "temp", "=", "torch", ".", "max", "(", "temp", ",", "zero_tensor", ")", "\n", "\n", "temp", "=", "torch", ".", "min", "(", "temp", ",", "image", "+", "epsilon", ")", "\n", "perturbed_image", "=", "torch", ".", "min", "(", "temp", ",", "ones_tensor", ")", "\n", "\n", "# Return the perturbed image", "\n", "", "return", "perturbed_image", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.test_adversarial": [[1059, 1130], ["model.eval", "enumerate", "print", "model", "torch.nll_loss", "output.float.float", "loss.float.float", "model.zero_grad", "loss.float.backward", "train_fcnn.fgsm_attack", "model", "float", "data.half.to", "target.to", "data.half.half", "output.float.max", "init_pred.item", "target.item", "output.float.max", "final_pred.item", "target.item", "len", "len", "fgsm_attack.squeeze().detach().cpu().numpy", "adv_examples.append", "len", "fgsm_attack.squeeze().detach().cpu().numpy", "adv_examples.append", "len", "fgsm_attack.squeeze().detach().cpu", "init_pred.item", "final_pred.item", "fgsm_attack.squeeze().detach().cpu", "init_pred.item", "final_pred.item", "fgsm_attack.squeeze().detach", "fgsm_attack.squeeze().detach", "fgsm_attack.squeeze", "fgsm_attack.squeeze"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.fgsm_attack"], ["", "def", "test_adversarial", "(", "model", ",", "criterion", ",", "device", ",", "test_loader", ",", "epsilon", ")", ":", "\n", "\n", "# Accuracy counter", "\n", "    ", "correct", "=", "0", "\n", "adv_examples", "=", "[", "]", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "i", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "\n", "# Send the data and label to the device", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "\n", "# Set requires_grad attribute of tensor. Important for Attack", "\n", "data", ".", "requires_grad", "=", "True", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "data", "=", "data", ".", "half", "(", ")", "\n", "\n", "# compute output", "\n", "", "output", ",", "_", "=", "model", "(", "data", ")", "\n", "\n", "init_pred", "=", "(", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", ")", "# get the index of the max log-probability", "\n", "\n", "# If the initial prediction is wrong, dont bother attacking, just move on", "\n", "if", "init_pred", ".", "item", "(", ")", "!=", "target", ".", "item", "(", ")", ":", "\n", "            ", "continue", "\n", "\n", "# Calculate the loss", "\n", "", "loss", "=", "F", ".", "nll_loss", "(", "output", ",", "target", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# Zero all existing gradients", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "# Calculate gradients of model in backward pass", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Collect datagrad", "\n", "data_grad", "=", "data", ".", "grad", ".", "data", "\n", "\n", "# Call FGSM Attack", "\n", "perturbed_data", "=", "fgsm_attack", "(", "data", ",", "epsilon", ",", "data_grad", ")", "\n", "\n", "# Re-classify the perturbed image", "\n", "output", ",", "_", "=", "model", "(", "perturbed_data", ")", "\n", "\n", "# Check for success", "\n", "final_pred", "=", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", "# get the index of the max log-probability", "\n", "\n", "if", "final_pred", ".", "item", "(", ")", "==", "target", ".", "item", "(", ")", ":", "\n", "            ", "correct", "+=", "1", "\n", "# Special case for saving 0 epsilon examples", "\n", "if", "(", "epsilon", "==", "0", ")", "and", "(", "len", "(", "adv_examples", ")", "<", "5", ")", ":", "\n", "                ", "adv_ex", "=", "perturbed_data", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "adv_examples", ".", "append", "(", "(", "init_pred", ".", "item", "(", ")", ",", "final_pred", ".", "item", "(", ")", ",", "adv_ex", ")", ")", "\n", "", "", "else", ":", "\n", "# Save some adv examples for visualization later", "\n", "            ", "if", "len", "(", "adv_examples", ")", "<", "5", ":", "\n", "                ", "adv_ex", "=", "perturbed_data", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "adv_examples", ".", "append", "(", "(", "init_pred", ".", "item", "(", ")", ",", "final_pred", ".", "item", "(", ")", ",", "adv_ex", ")", ")", "\n", "\n", "# Calculate final accuracy for this epsilon", "\n", "", "", "", "final_acc", "=", "correct", "/", "float", "(", "len", "(", "test_loader", ")", ")", "\n", "print", "(", "\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\"", ".", "format", "(", "epsilon", ",", "correct", ",", "len", "(", "test_loader", ")", ",", "final_acc", ")", ")", "\n", "\n", "# Return the accuracy and an adversarial example", "\n", "return", "final_acc", ",", "adv_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.get_net_width": [[1132, 1143], ["os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "sorted", "os.path.exists", "print", "widths.append", "ckp[].keys"], "function", ["None"], ["", "def", "get_net_width", "(", "model_path", ")", ":", "\n", "    ", "ckp_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'pruned_checkpoint_120.tar'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "ckp_path", ")", ":", "\n", "        ", "print", "(", "f'No pruned model for {ckp_path}'", ")", "\n", "", "ckp", "=", "torch", ".", "load", "(", "ckp_path", ")", "\n", "w_names", "=", "sorted", "(", "[", "name", "for", "name", "in", "ckp", "[", "'state_dict'", "]", ".", "keys", "(", ")", "\n", "if", "'weight'", "in", "name", "and", "'features'", "in", "name", "]", ")", "\n", "widths", "=", "[", "]", "\n", "for", "name", "in", "w_names", ":", "\n", "        ", "widths", ".", "append", "(", "ckp", "[", "'state_dict'", "]", "[", "name", "]", ".", "shape", "[", "0", "]", ")", "\n", "", "return", "widths", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.train_fcnn.adjust_learning_rate": [[1148, 1153], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "\n", "    ", "lr", "=", "args", ".", "lr", "*", "(", "0.5", "**", "(", "epoch", "//", "30", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.prune_inactive_per_layer": [[53, 62], ["numpy.delete", "numpy.delete"], "function", ["None"], ["def", "prune_inactive_per_layer", "(", "w1", ",", "w2", ",", "ind_inact", ")", ":", "\n", "    ", "\"\"\"\n    w1: [c1, c0] the weights before the current layer\n    w2: [c2, c1] the weithgs after the current layer\n    ind_inact: a list of the index of the stably inactive neurons\n    \"\"\"", "\n", "w1", "=", "np", ".", "delete", "(", "w1", ",", "ind_inact", ",", "axis", "=", "0", ")", "\n", "w2", "=", "np", ".", "delete", "(", "w2", ",", "ind_inact", ",", "axis", "=", "1", ")", "\n", "return", "w1", ",", "w2", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.prune_active_per_layer": [[68, 114], ["numpy.array", "numpy.linalg.matrix_rank", "pdb.set_trace", "print", "prune_network.solve_linearly_depend", "w1_a.astype", "range", "numpy.random.randn", "numpy.allclose", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.solve_linearly_depend"], ["", "def", "prune_active_per_layer", "(", "w1", ",", "w2", ",", "b1", ",", "b2", ",", "ind_act", ")", ":", "\n", "    ", "\"\"\"\n    w1: [c1, c0] the weights before the current layer\n    w2: [c2, c1] the weithgs after the current layer\n    ind_inact: a list of the index of the stably inactive neurons\n    b1: [c1] \n    b2: [c2]\n    \"\"\"", "\n", "ind_act", "=", "np", ".", "array", "(", "ind_act", ")", "\n", "w1_a", "=", "w1", "[", "ind_act", ",", ":", "]", "\n", "b1_a", "=", "b1", "[", "ind_act", "]", "\n", "r1", "=", "np", ".", "linalg", ".", "matrix_rank", "(", "w1_a", ".", "astype", "(", "np", ".", "float64", ")", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "if", "r1", "==", "w1_a", ".", "shape", "[", "0", "]", ":", "\n", "        ", "return", "w2", ",", "b2", ",", "[", "]", "\n", "\n", "", "print", "(", "'Start to solve linearly dependent row vectors'", ")", "\n", "K1", ",", "is_indep", "=", "solve_linearly_depend", "(", "w1_a", ")", "\n", "#timer.stop('solve_linearly_depend is done')", "\n", "w2_a", "=", "w2", "[", ":", ",", "ind_act", "]", "\n", "b2_old", "=", "b2", "[", ":", "]", "\n", "b11", "=", "b1_a", "[", "is_indep", "]", "\n", "b12", "=", "b1_a", "[", "is_indep", "==", "0", "]", "\n", "w21", "=", "w2_a", "[", ":", ",", "is_indep", "]", "\n", "w22", "=", "w2_a", "[", ":", ",", "is_indep", "==", "0", "]", "\n", "#   1. remove w12_a from w1_a", "\n", "#w1 = np.delete(w1, ind_act[is_indep==0], axis = 0)", "\n", "#    2. merge w22_a into w21_a:", "\n", "#       w21_a' = w21_a + w22_a * K1", "\n", "#    3. update b2:", "\n", "#       b2'    = b2 + w22_a * (b12_a - K1 * b11_a)", "\n", "w2", "[", ":", ",", "ind_act", "[", "is_indep", "]", "]", "=", "w21", "+", "w22", "@", "K1", "\n", "b2", "=", "b2", "+", "w22", "@", "(", "b12", "-", "K1", "@", "b11", ")", "\n", "#    4. remove w22", "\n", "#w2 = np.delete(w2, ind_act[is_indep==0])", "\n", "if", "DEBUG", ":", "\n", "        ", "for", "run", "in", "range", "(", "10", ")", ":", "\n", "            ", "h", "=", "np", ".", "random", ".", "randn", "(", "w1", ".", "shape", "[", "1", "]", ")", "\n", "x", "=", "w1", "@", "h", "+", "b1", "\n", "x", "=", "x", "[", "ind_act", "]", "\n", "y_old", "=", "w2_a", "@", "x", "+", "b2_old", "\n", "y_new", "=", "w2", "[", ":", ",", "ind_act", "[", "is_indep", "]", "]", "@", "x", "[", "is_indep", "]", "+", "b2", "\n", "if", "not", "np", ".", "allclose", "(", "y_old", ",", "y_new", ")", ":", "\n", "                ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "#import pdb;pdb.set_trace()", "\n", "", "", "", "return", "w2", ",", "b2", ",", "ind_act", "[", "is_indep", "==", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.find_independ_rows": [[119, 132], ["prune_network.find_independ_rows2"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.find_independ_rows2"], ["", "def", "find_independ_rows", "(", "A", ")", ":", "\n", "# find the independent row vectors", "\n", "# only work for square matrix", "\n", "#lambdas, V = np.linalg.eig(A.T)", "\n", "#return lambdas!=0", "\n", "\n", "#import pdb;pdb.set_trace()", "\n", "    ", "inds", "=", "find_independ_rows2", "(", "A", ")", "\n", "\n", "# too slow", "\n", "#_, inds = sympy.Matrix(A).T.rref()", "\n", "#import pdb;pdb.set_trace()", "\n", "return", "inds", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.find_independ_rows2": [[133, 148], ["numpy.linalg.matrix_rank", "A.astype", "numpy.linalg.matrix_rank", "base.append", "base_ind.append", "numpy.stack().astype", "numpy.stack"], "function", ["None"], ["", "def", "find_independ_rows2", "(", "A", ")", ":", "\n", "    ", "r", "=", "np", ".", "linalg", ".", "matrix_rank", "(", "A", ".", "astype", "(", "np", ".", "float64", ")", ")", "\n", "base", "=", "[", "A", "[", "0", ",", ":", "]", "]", "\n", "base_ind", "=", "[", "0", "]", "\n", "row", "=", "1", "\n", "cur_r", "=", "1", "\n", "while", "cur_r", "<", "r", ":", "\n", "        ", "tmp", "=", "base", "+", "[", "A", "[", "row", ",", ":", "]", "]", "\n", "#import pdb;pdb.set_trace()", "\n", "if", "np", ".", "linalg", ".", "matrix_rank", "(", "np", ".", "stack", "(", "tmp", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float64", ")", ")", ">", "cur_r", ":", "\n", "            ", "cur_r", "+=", "1", "\n", "base", ".", "append", "(", "A", "[", "row", ",", ":", "]", ")", "\n", "base_ind", ".", "append", "(", "row", ")", "\n", "", "row", "+=", "1", "\n", "", "return", "base_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.solve_linearly_depend": [[154, 185], ["prune_network.find_independ_rows", "numpy.array", "range", "numpy.stack", "numpy.array", "numpy.linalg.solve", "numpy.allclose", "np.stack.append", "numpy.concatenate", "prune_network.find_independ_rows", "numpy.dot", "range"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.find_independ_rows", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.find_independ_rows"], ["", "def", "solve_linearly_depend", "(", "w11", ")", ":", "\n", "    ", "\"\"\"\n        Args:\n            w11: [c1_a, c0]\n        Returns:\n            K  : [c1_a -rank(w11), rank(w11)]\n            is_indep: [rank(w11),]\n    \"\"\"", "\n", "##timer.stop('start find_independ_rows')", "\n", "# find the independent row vectors", "\n", "is_indep", "=", "find_independ_rows", "(", "w11", ")", "\n", "##timer.stop('finsh find_independ_rows')", "\n", "is_indep", "=", "np", ".", "array", "(", "[", "i", "in", "is_indep", "for", "i", "in", "range", "(", "w11", ".", "shape", "[", "0", "]", ")", "]", ")", "\n", "#ind_indep    = find_li_vectors(w11)", "\n", "dep", "=", "w11", "[", "is_indep", "==", "0", ",", ":", "]", "# the linearly dependent row vectors", "\n", "base", "=", "w11", "[", "is_indep", ",", ":", "]", "# the independent row vectors", "\n", "# solve a linear equation: dep = K * base", "\n", "K", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "dep", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "y", "=", "dep", "[", "i", ",", ":", "]", "\n", "A", "=", "np", ".", "concatenate", "(", "[", "base", ",", "y", "[", "None", ",", ":", "]", "]", ",", "axis", "=", "0", ")", ".", "T", "\n", "is_indep_A", "=", "np", ".", "array", "(", "find_independ_rows", "(", "A", ")", ")", "\n", "#print('base[:,is_indep_A]: ', base[:,is_indep_A].shape)", "\n", "##timer.stop(f'start np.linalg.solve: {i} ')", "\n", "#import pdb;pdb.set_trace()", "\n", "k", "=", "np", ".", "linalg", ".", "solve", "(", "base", "[", ":", ",", "is_indep_A", "]", ".", "T", ",", "y", "[", "is_indep_A", "]", ")", "\n", "##timer.stop(f'start np.linalg.solve: {i}')", "\n", "assert", "(", "np", ".", "allclose", "(", "np", ".", "dot", "(", "base", ".", "T", ",", "k", ")", ",", "y", ")", ")", "\n", "K", ".", "append", "(", "k", ")", "\n", "", "K", "=", "np", ".", "stack", "(", "K", ",", "axis", "=", "0", ")", "\n", "return", "K", ",", "is_indep", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.sanity_ckp": [[187, 202], ["numpy.array", "numpy.arange", "numpy.arange().reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.arange"], "function", ["None"], ["", "def", "sanity_ckp", "(", ")", ":", "\n", "    ", "w1", "=", "np", ".", "array", "(", "\n", "[", "[", "1", ",", "0", ",", "2", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "2", ",", "1", ",", "2", ",", "1", "]", ",", "\n", "[", "1", ",", "2", ",", "3", ",", "0", "]", ",", "\n", "[", "11", ",", "12", ",", "13", ",", "0", "]", "]", ")", "\n", "b1", "=", "np", ".", "arange", "(", "5", ")", "\n", "w2", "=", "np", ".", "arange", "(", "10", ")", ".", "reshape", "(", "2", ",", "5", ")", "\n", "b2", "=", "np", ".", "array", "(", "[", "11", ",", "12", "]", ")", "\n", "act_neurons", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "2", "]", "]", ")", ".", "T", "\n", "inact_neurons", "=", "np", ".", "array", "(", "[", "[", "1", ",", "4", "]", "]", ")", ".", "T", "\n", "w_names", "=", "[", "'w1'", ",", "'w2'", "]", "\n", "b_names", "=", "[", "'b1'", ",", "'b2'", "]", "\n", "return", "[", "w1", ",", "w2", "]", ",", "[", "b1", ",", "b2", "]", ",", "act_neurons", ",", "inact_neurons", ",", "w_names", ",", "b_names", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.prune_ckp": [[206, 274], ["range", "enumerate", "enumerate", "torch.save", "prune_network.sanity_ckp", "timer.start", "os.path.join", "os.path.join", "os.path.join", "torch.load", "sorted", "sorted", "sorted.append", "sorted.append", "numpy.load().item", "len", "print", "print", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "weights.append", "bias.append", "stb_neurons[].squeeze", "stb_neurons[].squeeze", "len", "prune_network.prune_active_per_layer", "prune_ind.extend", "len", "prune_ind.extend", "len", "numpy.delete", "numpy.delete", "numpy.delete", "[].cpu().numpy", "[].cpu().numpy", "numpy.load", "torch.from_numpy", "torch.from_numpy", "ckp[].keys", "ckp[].keys", "len", "len", "[].cpu", "[].cpu"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.sanity_ckp", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.start", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.prune_network.prune_active_per_layer"], ["", "def", "prune_ckp", "(", "model_path", ")", ":", "\n", "\n", "    ", "if", "DEBUG", ":", "\n", "        ", "weights", ",", "bias", ",", "act_neurons", ",", "inact_neurons", ",", "w_names", ",", "b_names", "=", "sanity_ckp", "(", ")", "\n", "", "else", ":", "\n", "        ", "timer", ".", "start", "(", ")", "\n", "ckp_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'checkpoint_120.tar'", ")", "\n", "pruned_ckp_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'pruned_checkpoint_120.tar'", ")", "\n", "stb_path", "=", "os", ".", "path", ".", "join", "(", "model_path", ",", "'stable_neurons.npy'", ")", "\n", "ckp", "=", "torch", ".", "load", "(", "ckp_path", ")", "\n", "weights", "=", "[", "]", "\n", "bias", "=", "[", "]", "\n", "\n", "w_names", "=", "sorted", "(", "[", "name", "for", "name", "in", "ckp", "[", "'state_dict'", "]", ".", "keys", "(", ")", "\n", "if", "'weight'", "in", "name", "and", "'features'", "in", "name", "]", ")", "\n", "b_names", "=", "sorted", "(", "[", "name", "for", "name", "in", "ckp", "[", "'state_dict'", "]", ".", "keys", "(", ")", "\n", "if", "'bias'", "in", "name", "and", "'features'", "in", "name", "]", ")", "\n", "w_names", ".", "append", "(", "'classifier.0.weight'", ")", "\n", "b_names", ".", "append", "(", "'classifier.0.bias'", ")", "\n", "\n", "device", "=", "ckp", "[", "'state_dict'", "]", "[", "w_names", "[", "0", "]", "]", ".", "device", "\n", "\n", "for", "name", "in", "w_names", ":", "\n", "            ", "weights", ".", "append", "(", "ckp", "[", "'state_dict'", "]", "[", "name", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "for", "name", "in", "b_names", ":", "\n", "            ", "bias", ".", "append", "(", "ckp", "[", "'state_dict'", "]", "[", "name", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "stb_neurons", "=", "np", ".", "load", "(", "stb_path", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "act_neurons", "=", "stb_neurons", "[", "'stably_active'", "]", ".", "squeeze", "(", "axis", "=", "2", ")", ".", "T", "\n", "inact_neurons", "=", "stb_neurons", "[", "'stably_inactive'", "]", ".", "squeeze", "(", "axis", "=", "2", ")", ".", "T", "\n", "##timer.stop('loaded the checkpoint')", "\n", "#import pdb;pdb.set_trace()", "\n", "", "for", "l", "in", "range", "(", "1", ",", "len", "(", "weights", ")", ")", ":", "\n", "        ", "ind_act", "=", "act_neurons", "[", "1", ",", "act_neurons", "[", "0", ",", ":", "]", "==", "l", "]", "\n", "ind_inact", "=", "inact_neurons", "[", "1", ",", "inact_neurons", "[", "0", ",", ":", "]", "==", "l", "]", "\n", "w1", "=", "weights", "[", "l", "-", "1", "]", "\n", "w2", "=", "weights", "[", "l", "]", "\n", "b1", "=", "bias", "[", "l", "-", "1", "]", "\n", "b2", "=", "bias", "[", "l", "]", "\n", "prune_ind", "=", "[", "]", "\n", "if", "len", "(", "ind_act", ")", ">", "0", ":", "\n", "#import pdb;pdb.set_trace()", "\n", "            ", "w2", ",", "b2", ",", "prune_ind_act", "=", "prune_active_per_layer", "(", "w1", ",", "w2", ",", "b1", ",", "b2", ",", "ind_act", ")", "\n", "prune_ind", ".", "extend", "(", "prune_ind_act", ")", "\n", "", "else", ":", "\n", "            ", "prune_ind_act", "=", "[", "]", "\n", "", "if", "len", "(", "ind_inact", ")", ">", "0", ":", "\n", "            ", "prune_ind", ".", "extend", "(", "ind_inact", ")", "\n", "", "if", "len", "(", "prune_ind", ")", ">", "0", ":", "\n", "            ", "w1", "=", "np", ".", "delete", "(", "w1", ",", "prune_ind", ",", "axis", "=", "0", ")", "\n", "b1", "=", "np", ".", "delete", "(", "b1", ",", "prune_ind", ",", "axis", "=", "0", ")", "\n", "w2", "=", "np", ".", "delete", "(", "w2", ",", "prune_ind", ",", "axis", "=", "1", ")", "\n", "", "print", "(", "f'Layer-{l}: prune {len(prune_ind_act)} stably active neurons'", ")", "\n", "print", "(", "f'layer-{l}: prune {len(ind_inact)} stably inactive neurons'", ")", "\n", "# update the weights and bias", "\n", "weights", "[", "l", "-", "1", "]", "=", "w1", "\n", "bias", "[", "l", "-", "1", "]", "=", "b1", "\n", "weights", "[", "l", "]", "=", "w2", "\n", "bias", "[", "l", "]", "=", "b2", "\n", "##timer.stop(f'{l} layer is pruned')", "\n", "#import pdb;pdb.set_trace()", "\n", "# update the ckeckpoints", "\n", "", "for", "i", ",", "name", "in", "enumerate", "(", "w_names", ")", ":", "\n", "        ", "ckp", "[", "'state_dict'", "]", "[", "name", "]", "=", "torch", ".", "from_numpy", "(", "weights", "[", "i", "]", ")", ".", "cuda", "(", "device", "=", "device", ")", "\n", "", "for", "i", ",", "name", "in", "enumerate", "(", "b_names", ")", ":", "\n", "        ", "ckp", "[", "'state_dict'", "]", "[", "name", "]", "=", "torch", ".", "from_numpy", "(", "bias", "[", "i", "]", ")", ".", "cuda", "(", "device", "=", "device", ")", "\n", "# save the checkpoint ", "\n", "", "torch", ".", "save", "(", "ckp", ",", "pruned_ckp_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.parse_line": [[55, 69], ["re.split", "numpy.array", "len", "new_list.append"], "function", ["None"], ["def", "parse_line", "(", "line", ")", ":", "\n", "    ", "my_list", "=", "re", ".", "split", "(", "', |,| |\\[|\\]|\\];'", ",", "line", ")", "\n", "# Ignore empty strings", "\n", "# my_list = filter(None, my_list)", "\n", "# <THIAGO>", "\n", "new_list", "=", "[", "]", "\n", "for", "i", "in", "my_list", ":", "\n", "        ", "if", "len", "(", "i", ")", ">", "0", ":", "\n", "            ", "new_list", ".", "append", "(", "i", ")", "\n", "", "", "my_list", "=", "new_list", "\n", "# </THIAGO>", "\n", "output", "=", "np", ".", "array", "(", "my_list", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.parse_file": [[74, 159], ["open", "enumerate", "line.strip.strip", "len", "line.strip.split", "float", "word1.lower", "int", "word2.lower", "parse_line().astype", "numpy.cumsum", "tokens[].split", "word3.lower", "line.strip.lower", "len", "len", "get_activation_patterns.parse_line", "word4.lower", "line.strip.lower", "numpy.digitize", "parse_line().astype", "weights.append", "parse_line().astype", "bias.append", "numpy.zeros", "get_activation_patterns.parse_line", "numpy.transpose", "get_activation_patterns.parse_line"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.parse_line", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.parse_line", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.parse_line"], ["", "def", "parse_file", "(", "input", ")", ":", "\n", "\n", "    ", "word1", "=", "\"levels = \"", "\n", "word2", "=", "\"n = [\"", "\n", "word3", "=", "\"W =\"", "\n", "word4", "=", "\"B =\"", "\n", "word5", "=", "\"];\"", "\n", "\n", "\n", "# Output variables", "\n", "layers", "=", "0", "# layer number at which we have the output", "\n", "weights", "=", "[", "]", "# list whose each elements contains weight matrices", "\n", "bias", "=", "[", "]", "# list whose each element contain biases", "\n", "\n", "# IMP NOTE -", "\n", "# Bias should be in the form of matrices. eg if we have 2 bias term", "\n", "# for a layer, the bias element shape should be (2,1) and not (2, )", "\n", "\n", "# Assumes that each row of each weight matrix is written in 1 line", "\n", "weight_flag", "=", "False", "\n", "weight_line_cnt", "=", "0", "\n", "\n", "# Assumes that bias for 1 layer is written in 1 line", "\n", "bias_flag", "=", "True", "\n", "bias_layer_cnt", "=", "0", "\n", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "for", "cnt", ",", "line", "in", "enumerate", "(", "fp", ")", ":", "\n", "# Remove trailing characters", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "\n", "# if not an empty line", "\n", "if", "(", "len", "(", "line", ")", ">", "0", ")", ":", "\n", "\n", "# Comment found. Skip", "\n", "                ", "if", "(", "line", "[", "0", ":", "2", "]", "==", "\"//\"", ")", ":", "\n", "                    ", "if", "(", "line", "[", "0", ":", "3", "]", "==", "\"//C\"", ")", ":", "\n", "                        ", "tokens", "=", "line", ".", "split", "(", ")", "\n", "global", "accuracy", "\n", "accuracy", "=", "float", "(", "tokens", "[", "3", "]", ".", "split", "(", "\"%\"", ")", "[", "0", "]", ")", "\n", "", "pass", "\n", "\n", "", "elif", "(", "word1", ".", "lower", "(", ")", "in", "line", ")", ":", "\n", "                    ", "layers", "=", "int", "(", "line", "[", "len", "(", "word1", ")", "]", ")", "\n", "\n", "", "elif", "(", "word2", ".", "lower", "(", ")", "in", "line", ")", ":", "\n", "                    ", "temp", "=", "line", "[", "len", "(", "word2", ")", ":", "-", "2", "]", "\n", "nodes_per_layer", "=", "parse_line", "(", "temp", ")", ".", "astype", "(", "int", ")", "\n", "line_bins", "=", "np", ".", "cumsum", "(", "nodes_per_layer", "[", "1", ":", "]", ")", "\n", "\n", "", "elif", "(", "word3", ".", "lower", "(", ")", "in", "line", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "weight_flag", "=", "True", "\n", "\n", "", "elif", "(", "word4", ".", "lower", "(", ")", "in", "line", ".", "lower", "(", ")", ")", ":", "\n", "                    ", "bias_flag", "=", "True", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "(", "weight_flag", ")", ":", "\n", "                        ", "if", "(", "word5", "in", "line", ")", ":", "\n", "                            ", "weight_flag", "=", "False", "\n", "", "else", ":", "\n", "# These will be weights", "\n", "# Get which weight matrix the current line goes", "\n", "                            ", "index", "=", "np", ".", "digitize", "(", "weight_line_cnt", ",", "line_bins", ")", "#np digitize is 1 ordered", "\n", "\n", "# Need a new weight matrix", "\n", "if", "(", "weight_line_cnt", "==", "0", "or", "weight_line_cnt", "in", "line_bins", ")", ":", "\n", "                                ", "weights", ".", "append", "(", "np", ".", "zeros", "(", "(", "nodes_per_layer", "[", "index", "+", "1", "]", ",", "nodes_per_layer", "[", "index", "]", ")", ")", ")", "\n", "row_cnt", "=", "0", "\n", "\n", "# row_cnt keeps track of the row of the weight matrix to write this line", "\n", "", "weights", "[", "index", "]", "[", "row_cnt", ",", ":", "]", "=", "parse_line", "(", "line", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "row_cnt", "+=", "1", "\n", "weight_line_cnt", "+=", "1", "\n", "\n", "", "", "elif", "(", "bias_flag", ")", ":", "\n", "                        ", "if", "(", "word5", "in", "line", ")", ":", "\n", "                            ", "bias_flag", "=", "False", "\n", "", "else", ":", "\n", "# These will be biases", "\n", "                            ", "temp", "=", "parse_line", "(", "line", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "bias", ".", "append", "(", "np", ".", "transpose", "(", "[", "temp", "]", ")", ")", "\n", "\n", "", "", "", "", "", "", "return", "layers", ",", "nodes_per_layer", ",", "weights", ",", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.print_bounds": [[164, 198], ["numpy.max", "numpy.set_printoptions", "print", "print", "print", "print", "numpy.where", "print", "numpy.where", "print", "print", "open", "range", "print", "print", "os.path.join", "the_file.write", "os.path.dirname", "str", "str"], "function", ["None"], ["", "def", "print_bounds", "(", "tot_layers", ",", "nodes_per_layer", ",", "bounds", ")", ":", "\n", "    ", "max_nodes", "=", "np", ".", "max", "(", "nodes_per_layer", "[", "1", ":", "]", ")", "\n", "\n", "np", ".", "set_printoptions", "(", "threshold", "=", "np", ".", "inf", ",", "formatter", "=", "{", "'float'", ":", "lambda", "x", ":", "\"{0:0.2f}\"", ".", "format", "(", "x", ")", "}", ")", "\n", "print", "(", "\"\\nMaxima for the nodes\"", ")", "\n", "print", "(", "bounds", "[", "1", ":", ",", "0", ":", "max_nodes", ",", "0", "]", ")", "\n", "print", "(", "\"Minima of the nodes\"", ")", "\n", "print", "(", "bounds", "[", "1", ":", ",", "0", ":", "max_nodes", ",", "1", "]", ")", "\n", "\n", "r", ",", "c", "=", "np", ".", "where", "(", "bounds", "[", "1", ":", ",", "0", ":", "max_nodes", ",", "0", "]", "<=", "0", ")", "\n", "\n", "print", "(", "\"\"", ")", "\n", "#print(\"------------------------------------------------------------------------\")", "\n", "if", "(", "r", ".", "shape", "[", "0", "]", ">", "0", ")", ":", "\n", "        ", "print", "(", "\"Number_stably_inactive_nodes {}\"", ".", "format", "(", "r", ".", "shape", "[", "0", "]", ")", ")", "\n", "#print(\"------------------------------------------------------------------------\")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Number_stably_inactive_nodes {}\"", ".", "format", "(", "0", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "input", ")", ",", "inactive_nodes_file", ")", ",", "'w'", ")", "as", "the_file", ":", "\n", "        ", "for", "i", "in", "range", "(", "r", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "l", "=", "r", "[", "i", "]", "+", "1", "#+1 since we have ignored the input nodes while printing", "\n", "u", "=", "c", "[", "i", "]", "\n", "#print(\"(%d, %d)\" %(l, u))", "\n", "the_file", ".", "write", "(", "str", "(", "l", ")", "+", "\" \"", "+", "str", "(", "u", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "r", ",", "c", "=", "np", ".", "where", "(", "bounds", "[", "1", ":", ",", "0", ":", "max_nodes", ",", "1", "]", "<=", "0", ")", "\n", "\n", "#print(\"------------------------------------------------------------------------\")", "\n", "if", "(", "r", ".", "shape", "[", "0", "]", ">", "0", ")", ":", "\n", "        ", "print", "(", "\"Number_stably_active_nodes   {}\"", ".", "format", "(", "r", ".", "shape", "[", "0", "]", ")", ")", "\n", "#print(\"------------------------------------------------------------------------\")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Number_stably_active_nodes   {}\"", ".", "format", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.mycallback": [[942, 1016], ["model.cbGet", "print", "model.terminate", "model.cbGet", "model.cbGetSolution", "LinExpr", "range", "model._my_file.write", "model.cbLazy", "sys.stdout.write", "sys.stdout.flush", "range", "sys.stdout.write", "sys.stdout.flush", "LinExpr.add", "LinExpr.add", "int", "time.time"], "function", ["None"], ["def", "mycallback", "(", "model", ",", "where", ")", ":", "\n", "# General MIP callback", "\n", "    ", "if", "where", "==", "GRB", ".", "Callback", ".", "MIP", ":", "\n", "        ", "obj_bnd", "=", "model", ".", "cbGet", "(", "GRB", ".", "Callback", ".", "MIP_OBJBND", ")", "\n", "if", "(", "obj_bnd", "<", "0", ")", ":", "\n", "            ", "print", "(", "\"Objective bound (Soln of relaxed LP) < 0\"", ")", "\n", "model", ".", "terminate", "(", ")", "\n", "\n", "# If an MIP solution is found", "\n", "", "", "elif", "where", "==", "GRB", ".", "Callback", ".", "MIPSOL", ":", "\n", "        ", "model", ".", "_sol_count", "+=", "1", "\n", "obj_val", "=", "model", ".", "cbGet", "(", "GRB", ".", "Callback", ".", "MIPSOL_OBJ", ")", "\n", "\n", "#print(\"\\nObjective f = %f\" %(obj_val))", "\n", "\n", "if", "(", "obj_val", ">", "0", ")", ":", "\n", "            ", "model", ".", "_val_sol_count", "+=", "1", "\n", "\n", "if", "(", "model", ".", "_val_sol_count", "%", "print_freq", "==", "0", ")", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "\"Valid/Total Solutions %d / %d Time %d s\\n\"", "%", "(", "model", ".", "_val_sol_count", ",", "model", ".", "_sol_count", ",", "int", "(", "time", ".", "time", "(", ")", "-", "now", ")", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "#print (\"g = \")", "\n", "#print (model.cbGetSolution(g))", "\n", "#print (\"h = \")", "\n", "#print (model.cbGetSolution(h))", "\n", "#print (\"hBar = \")", "\n", "#print (model.cbGetSolution(hbar))", "\n", "#print (\"Binary Variables z = \")", "\n", "#print (model.cbGetSolution(z))", "\n", "\n", "# We want to remove the solution that we just found, so that it does", "\n", "# not repeat and also to avoid the solver from finishing before", "\n", "# enumerating all positive solutions because it found a solution", "\n", "# that provably maximizes f", "\n", "#", "\n", "# The current solution will have", "\n", "# Sum of variables which are 1 - Sum of variables which are 0 = #Variables that are 1", "\n", "# So, we add a lazy cut", "\n", "# Sum of variables which are 1 - Sum of variables which are 0 <= #Variables that are 1 - 1", "\n", "\n", "# https://groups.google.com/forum/#!topic/gurobi/d38iycxUIps", "\n", "", "vals", "=", "model", ".", "cbGetSolution", "(", "z", ")", "\n", "expr", "=", "LinExpr", "(", "0.0", ")", "\n", "ones_cnt", "=", "0", "\n", "\n", "line_to_write", "=", "\"\"", "\n", "\n", "# No need for input activations", "\n", "for", "m", "in", "range", "(", "1", ",", "run_till_layer_index", ")", ":", "\n", "                ", "for", "n", "in", "range", "(", "nodes_per_layer", "[", "m", "]", ")", ":", "\n", "                    ", "if", "(", "vals", "[", "m", ",", "n", "]", ">", "0.9", ")", ":", "\n", "                        ", "expr", ".", "add", "(", "model", ".", "_z", "[", "m", ",", "n", "]", ",", "1.0", ")", "\n", "ones_cnt", "+=", "1", "\n", "term", "=", "\"1 \"", "\n", "", "else", ":", "\n", "                        ", "expr", ".", "add", "(", "model", ".", "_z", "[", "m", ",", "n", "]", ",", "-", "1.0", ")", "\n", "term", "=", "\"0 \"", "\n", "\n", "", "line_to_write", "+=", "term", "\n", "\n", "", "", "line_to_write", "+=", "\"\\n\"", "\n", "# Write the line to the file", "\n", "model", ".", "_my_file", ".", "write", "(", "line_to_write", ")", "\n", "if", "(", "show_activations", ")", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "line_to_write", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "# Add a lazy constraint so that this solution does not appear again", "\n", "", "constraint", "=", "model", ".", "cbLazy", "(", "expr", "<=", "ones_cnt", "-", "1", ")", "\n", "# print(\"Ones_cnt = %d\" %(ones_cnt))", "\n", "# print(expr)", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# print(\"Invalid Solution Found\")", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.layercallback": [[353, 394], ["print", "model.cbGetSolution", "model.cbGetSolution", "model.cbGetSolution", "range", "model.cbGet", "print", "positive_units.add", "model.cbLazy", "model.terminate", "print", "negative_units.add", "model.cbLazy", "range", "model.cbGetNodeRel", "model.cbSetSolution", "vars.append", "range", "model.cbSetSolution", "vars.append", "model.cbGetNodeRel.append", "random.random", "random.random"], "function", ["None"], ["", "", "", "def", "layercallback", "(", "model", ",", "where", ")", ":", "\n", "    ", "global", "p", ",", "q", ",", "i", ",", "nodes_per_layer", ",", "positive_units", ",", "negative_units", "\n", "global", "h", ",", "g", "\n", "\n", "if", "where", "==", "GRB", ".", "Callback", ".", "MIPSOL", ":", "\n", "        ", "print", "(", "\"FOUND A SOLUTION\"", ")", "\n", "p_value", "=", "model", ".", "cbGetSolution", "(", "p", ")", "\n", "q_value", "=", "model", ".", "cbGetSolution", "(", "q", ")", "\n", "g_value", "=", "model", ".", "cbGetSolution", "(", "g", ")", "\n", "for", "n", "in", "range", "(", "nodes_per_layer", "[", "i", "]", ")", ":", "\n", "            ", "if", "p_value", "[", "n", "]", "==", "1", ":", "\n", "                ", "positive_units", ".", "add", "(", "n", ")", "\n", "model", ".", "cbLazy", "(", "p", "[", "n", "]", "==", "0", ")", "\n", "#print(\"+\",n,g_value[i,n])", "\n", "", "elif", "q_value", "[", "n", "]", "==", "1", ":", "\n", "                ", "negative_units", ".", "add", "(", "n", ")", "\n", "model", ".", "cbLazy", "(", "q", "[", "n", "]", "==", "0", ")", "\n", "#print(\"-\",n,g_value[i,n])", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "#print(\"?\",n,g_value[i,n])", "\n", "", "", "", "elif", "where", "==", "GRB", ".", "Callback", ".", "MIP", ":", "\n", "        ", "objbnd", "=", "model", ".", "cbGet", "(", "GRB", ".", "Callback", ".", "MIP_OBJBND", ")", "\n", "print", "(", "\"BOUND:\"", ",", "objbnd", ")", "\n", "if", "objbnd", "<", "0.5", ":", "\n", "            ", "model", ".", "terminate", "(", ")", "\n", "", "", "elif", "where", "==", "GRB", ".", "Callback", ".", "MIPNODE", ":", "\n", "        ", "print", "(", "\"MIPNODE\"", ")", "\n", "vars", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "\n", "if", "inject_relaxed_solution", ":", "\n", "            ", "for", "input", "in", "range", "(", "nodes_per_layer", "[", "0", "]", ")", ":", "\n", "                ", "vars", ".", "append", "(", "h", "[", "0", ",", "input", "]", ")", "\n", "", "values", "=", "model", ".", "cbGetNodeRel", "(", "vars", ")", "\n", "model", ".", "cbSetSolution", "(", "vars", ",", "values", ")", "\n", "", "elif", "inject_random_solution", ":", "\n", "            ", "for", "input", "in", "range", "(", "nodes_per_layer", "[", "0", "]", ")", ":", "\n", "                ", "vars", ".", "append", "(", "h", "[", "0", ",", "input", "]", ")", "\n", "values", ".", "append", "(", "bounds", "[", "0", ",", "input", ",", "0", "]", "+", "random", ".", "random", "(", ")", "*", "(", "bounds", "[", "0", ",", "input", ",", "1", "]", "-", "bounds", "[", "0", ",", "input", ",", "0", "]", ")", ")", "\n", "", "model", ".", "cbSetSolution", "(", "vars", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.None.get_activation_patterns.networkcallback": [[398, 437], ["print", "model.cbGetSolution", "model.cbGetSolution", "model.cbGet", "print", "positive_units.add", "model.cbLazy", "negative_units.add", "model.cbLazy", "model.terminate", "print", "range", "model.cbGetNodeRel", "model.cbSetSolution", "vars.append", "range", "model.cbSetSolution", "vars.append", "model.cbGetNodeRel.append", "random.random", "random.random"], "function", ["None"], ["", "", "", "def", "networkcallback", "(", "model", ",", "where", ")", ":", "\n", "    ", "global", "p", ",", "q", ",", "i", ",", "nodes_per_layer", ",", "positive_units", ",", "negative_units", "\n", "global", "h", "\n", "global", "lst", "\n", "\n", "if", "where", "==", "GRB", ".", "Callback", ".", "MIPSOL", ":", "\n", "        ", "print", "(", "\"FOUND A SOLUTION\"", ")", "\n", "p_value", "=", "model", ".", "cbGetSolution", "(", "p", ")", "\n", "q_value", "=", "model", ".", "cbGetSolution", "(", "q", ")", "\n", "for", "(", "m", ",", "n", ")", "in", "p_lst", ":", "\n", "            ", "if", "p_value", "[", "m", ",", "n", "]", "==", "1", ":", "\n", "                ", "positive_units", ".", "add", "(", "(", "m", ",", "n", ")", ")", "\n", "model", ".", "cbLazy", "(", "p", "[", "m", ",", "n", "]", "==", "0", ")", "\n", "#print(\"+\",m,n)", "\n", "", "", "for", "(", "m", ",", "n", ")", "in", "q_lst", ":", "\n", "            ", "if", "q_value", "[", "m", ",", "n", "]", "==", "1", ":", "\n", "                ", "negative_units", ".", "add", "(", "(", "m", ",", "n", ")", ")", "\n", "model", ".", "cbLazy", "(", "q", "[", "m", ",", "n", "]", "==", "0", ")", "\n", "#print(\"-\",m,n)", "\n", "", "", "", "elif", "where", "==", "GRB", ".", "Callback", ".", "MIP", ":", "\n", "        ", "objbnd", "=", "model", ".", "cbGet", "(", "GRB", ".", "Callback", ".", "MIP_OBJBND", ")", "\n", "print", "(", "\"BOUND:\"", ",", "objbnd", ")", "\n", "if", "objbnd", "<", "0.5", ":", "\n", "            ", "model", ".", "terminate", "(", ")", "\n", "", "", "elif", "where", "==", "GRB", ".", "Callback", ".", "MIPNODE", ":", "\n", "        ", "print", "(", "\"MIPNODE\"", ")", "\n", "vars", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "\n", "if", "inject_relaxed_solution", ":", "\n", "            ", "for", "input", "in", "range", "(", "nodes_per_layer", "[", "0", "]", ")", ":", "\n", "                ", "vars", ".", "append", "(", "h", "[", "0", ",", "input", "]", ")", "\n", "", "values", "=", "model", ".", "cbGetNodeRel", "(", "vars", ")", "\n", "model", ".", "cbSetSolution", "(", "vars", ",", "values", ")", "\n", "", "elif", "inject_random_solution", ":", "\n", "            ", "for", "input", "in", "range", "(", "nodes_per_layer", "[", "0", "]", ")", ":", "\n", "                ", "vars", ".", "append", "(", "h", "[", "0", ",", "input", "]", ")", "\n", "values", ".", "append", "(", "bounds", "[", "0", ",", "input", ",", "0", "]", "+", "random", ".", "random", "(", ")", "*", "(", "bounds", "[", "0", ",", "input", ",", "1", "]", "-", "bounds", "[", "0", ",", "input", ",", "0", "]", ")", ")", "\n", "", "model", ".", "cbSetSolution", "(", "vars", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.custom_blocks.AffineReLU.__init__": [[5, 13], ["super().__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "m", "=", "1", ",", "c", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        In the constructor we instantiate a relu on affine value\n        \"\"\"", "\n", "super", "(", "AffineReLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "c", "=", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.custom_blocks.AffineReLU.forward": [[14, 21], ["custom_blocks.AffineReLU.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        In the forward function we accept a Tensor of input data and we must return\n        a Tensor of output data. \n        \"\"\"", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "m", "*", "x", "+", "self", ".", "c", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.custom_blocks.Thresholder.__init__": [[24, 29], ["torch.Module.__init__", "custom_blocks.AffineReLU", "custom_blocks.AffineReLU", "custom_blocks.AffineReLU"], "methods", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "b", "=", "0", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "Thresholder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "arelu1", "=", "AffineReLU", "(", "c", "=", "-", "(", "b", "+", "eps", ")", ")", "\n", "self", ".", "arelu2", "=", "AffineReLU", "(", "m", "=", "-", "1000", ",", "c", "=", "1", ")", "\n", "self", ".", "arelu3", "=", "AffineReLU", "(", "m", "=", "-", "1000", ",", "c", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.custom_blocks.Thresholder.forward": [[30, 35], ["custom_blocks.Thresholder.arelu1", "custom_blocks.Thresholder.arelu2", "custom_blocks.Thresholder.arelu3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "arelu1", "(", "x", ")", "\n", "x", "=", "self", ".", "arelu2", "(", "x", ")", "\n", "x", "=", "self", ".", "arelu3", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.FCNN.__init__": [[19, 35], ["torch.Module.__init__", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "fcnn.FCNN.modules", "torch.Linear", "torch.Linear", "torch.Linear", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "m.bias.data.fill_"], "methods", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "class_num", "=", "10", ")", ":", "\n", "        ", "super", "(", "FCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "features", "=", "features", "\n", "\n", "num_blocks", "=", "len", "(", "self", ".", "features", ")", "\n", "output_dim", "=", "self", ".", "features", "[", "num_blocks", "-", "3", "]", ".", "out_features", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "output_dim", ",", "class_num", ")", "\n", ")", "\n", "#self.th         = custom_blocks.Thresholder()", "\n", "\n", "# Initialize weights and bias", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.FCNN.forward": [[37, 45], ["fcnn.FCNN.features", "fcnn.FCNN.classifier", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "\n", "#a = self.th(x)", "\n", "a", "=", "x", "\n", "#x = self.smax(x)", "\n", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers": [[47, 70], ["len", "torch.Sequential", "torch.Linear", "torch.MaxPool2d", "torch.ReLU", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "function", ["None"], ["", "", "def", "make_layers", "(", "cfg", ",", "dropout", "=", "False", ",", "in_channels", "=", "784", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "#in_channels = 784 #1024 #784", "\n", "num_linear", "=", "len", "(", "cfg", ")", "\n", "\n", "i", "=", "0", "\n", "for", "v", "in", "cfg", ":", "\n", "        ", "if", "v", "==", "'M'", ":", "\n", "            ", "layers", "+=", "[", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "]", "\n", "", "else", ":", "\n", "            ", "conv", "=", "nn", ".", "Linear", "(", "in_channels", ",", "v", ")", "\n", "i", "+=", "1", "\n", "\n", "if", "dropout", ":", "\n", "                ", "p_d", "=", "0", "\n", "if", "(", "i", ">", "num_linear", "-", "1", ")", ":", "\n", "                    ", "p_d", "=", "0.3", "*", "i", "/", "num_linear", "\n", "\n", "", "layers", "+=", "[", "conv", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "p_d", ")", "]", "\n", "", "else", ":", "\n", "                ", "layers", "+=", "[", "conv", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "nn", ".", "Dropout", "(", "p", "=", "0", ")", "]", "\n", "", "in_channels", "=", "v", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn_prune": [[131, 133], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["def", "fcnn_prune", "(", "cfg", ",", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1": [[134, 136], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'A'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1_d": [[137, 139], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'A'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1a": [[140, 142], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Aa'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1a_d": [[143, 145], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Aa'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1b": [[146, 148], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ab'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1b_d": [[149, 151], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ab'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1c_d": [[152, 154], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1c_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ac'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1d_d": [[155, 157], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1d_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ad'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1e_d": [[158, 160], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1e_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ae'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn1f_d": [[161, 163], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn1f_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Af'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2": [[164, 166], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'B'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2_d": [[167, 169], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'B'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2a": [[170, 172], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ba'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2a_d": [[173, 175], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ba'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2b": [[176, 178], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bb'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2b_d": [[179, 181], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bb'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2c": [[182, 184], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2c", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bc'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2c_d": [[185, 187], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2c_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bc'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2d": [[188, 190], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bd'", "]", ",", "dropout", "=", "False", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2d_d": [[191, 193], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2d_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bd'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2e": [[194, 196], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2e", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Be'", "]", ",", "dropout", "=", "False", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2e_d": [[197, 199], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2e_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Be'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2f": [[200, 202], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2f", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bf'", "]", ",", "dropout", "=", "False", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2g": [[203, 205], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2g", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bg'", "]", ",", "dropout", "=", "False", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn2h": [[206, 208], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn2h", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Bh'", "]", ",", "dropout", "=", "False", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3": [[209, 211], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'C'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3_d": [[212, 214], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'C'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3a": [[215, 217], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ca'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3a_d": [[218, 220], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ca'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3b": [[221, 223], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Cb'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3b_d": [[224, 226], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Cb'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn3c": [[227, 229], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn3c", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Cc'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4": [[230, 232], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'D'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4_d": [[233, 235], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'D'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4a": [[236, 238], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Da'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4a_d": [[239, 241], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Da'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4b": [[242, 244], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Db'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4b_d": [[245, 247], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Db'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4c": [[248, 250], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4c", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dc'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4c_d": [[251, 253], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4c_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dc'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4d": [[254, 256], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dd'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4d_d": [[257, 259], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4d_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dd'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4e": [[260, 262], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4e", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'De'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4e_d": [[263, 265], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4e_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'De'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4f": [[266, 268], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4f", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Df'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4f_d": [[269, 271], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4f_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Df'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4g_d": [[272, 274], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4g_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dg'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4h_d": [[275, 277], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4h_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dh'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4i_d": [[278, 280], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4i_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Di'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4j_d": [[281, 283], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4j_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dj'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4l_d": [[284, 286], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4l_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dl'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4m_d": [[287, 289], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4m_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dm'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn4n_d": [[290, 292], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn4n_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Dn'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5": [[293, 295], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'E'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5_d": [[296, 298], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'E'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5a": [[299, 301], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ea'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5a_d": [[302, 304], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ea'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5b": [[305, 307], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Eb'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5b_d": [[308, 310], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Eb'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5c": [[311, 313], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5c", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ec'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5c_d": [[314, 316], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5c_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ec'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn5d": [[317, 319], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn5d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Ed'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6": [[320, 322], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'F'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6_d": [[323, 325], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'F'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6a": [[326, 328], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6a", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Fa'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6a_d": [[329, 331], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6a_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Fa'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6b": [[332, 334], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6b", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Fb'", "]", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.fcnn6b_d": [[335, 337], ["fcnn.FCNN", "fcnn.make_layers"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.fcnn.make_layers"], ["", "def", "fcnn6b_d", "(", "input_dim", "=", "784", ",", "class_num", "=", "10", ")", ":", "\n", "    ", "return", "FCNN", "(", "make_layers", "(", "cfg", "[", "'Fb'", "]", ",", "dropout", "=", "True", ",", "in_channels", "=", "input_dim", ")", ",", "class_num", "=", "class_num", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.__init__": [[271, 273], ["prune_and_evaluate_fcnn.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.reset": [[274, 279], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update": [[280, 285], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.main": [[63, 215], ["parser.parse_args", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "print", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "model.to", "print", "print", "torch.CrossEntropyLoss().to", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "os.path.isfile", "print", "torchvision.Normalize", "torchvision.ToTensor", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model.load_state_dict", "print", "print", "torch.CrossEntropyLoss", "print", "torchvision.Normalize", "print", "print", "print", "print", "prune_and_evaluate_fcnn.validate", "numpy.genfromtxt().astype", "print", "print", "numpy.unique", "model.state_dict", "model.state_dict.items", "print", "model.state_dict", "model.state_dict.items", "print", "print", "print", "prune_and_evaluate_fcnn.validate", "print", "transform_list.append", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.Lambda", "torchvision.Grayscale", "torchvision.ToTensor", "torchvision.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "numpy.genfromtxt", "str", "torchvision.MNIST", "os.path.join", "range", "range", "print", "range", "range", "torchvision.Compose", "os.path.dirname", "torch.distributions.normal.Normal.sample", "torchvision.Compose"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.validate", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.validate"], ["def", "main", "(", ")", ":", "\n", "    ", "global", "args", ",", "best_prec1", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "use_cuda", "=", "True", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "fcnn_flag", "=", "True", "\n", "inactive_file", "=", "\"inactive_input_0_1.dat\"", "\n", "\n", "model", "=", "fcnn", ".", "__dict__", "[", "args", ".", "arch", "]", "(", ")", "\n", "print", "(", "model", ")", "\n", "\n", "model", ".", "features", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ".", "features", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "print", "(", "\"*************************************************************************************************\"", ")", ";", "\n", "print", "(", "\"*************************************************************************************************\"", ")", ";", "\n", "# optionally resume from a checkpoint", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_prec1", "=", "checkpoint", "[", "'best_prec1'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "args", ".", "evaluate", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "stddev", "=", "args", ".", "std_dev", "\n", "distbn", "=", "torch", ".", "distributions", ".", "normal", ".", "Normal", "(", "0", ",", "stddev", ")", "\n", "\n", "\n", "if", "(", "dataset", "==", "\"CIFAR10\"", ")", ":", "\n", "        ", "print", "(", "\"Running on CIFAR10\"", ")", "\n", "input_dim", "=", "1024", "\n", "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0", "]", ",", "std", "=", "[", "1", "]", ")", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "        ", "print", "(", "\"Running on MNIST\"", ")", "\n", "input_dim", "=", "784", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0", "]", ",", "std", "=", "[", "1", "]", ")", "#Images are already loaded in [0,1]", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "\n", "\n", "", "transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "\n", "if", "args", ".", "evaluate", ":", "\n", "        ", "if", "args", ".", "adversarial", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "augmentation", ":", "\n", "                ", "print", "(", "\"Using augmentation. Std deviation of the noise while testing/evaluation = \"", "+", "str", "(", "stddev", ")", ")", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "img", "+", "distbn", ".", "sample", "(", "img", ".", "shape", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"No augmentation used in testing\"", ")", "\n", "\n", "", "if", "(", "dataset", "==", "\"CIFAR10\"", ")", ":", "\n", "                ", "transform_list", "=", "[", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "elif", "(", "dataset", "==", "\"MNIST\"", ")", ":", "\n", "                ", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", ",", "download", "=", "True", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Unknown Dataset\"", ")", "\n", "\n", "\n", "# Before Pruning", "\n", "", "print", "(", "\"\\n\\n-----------------------------------------------------------\"", ")", "\n", "print", "(", "\"               Before Pruning\"", ")", "\n", "print", "(", "\"-----------------------------------------------------------\"", ")", "\n", "acc", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "1", ",", "device", ",", "fcnn", ")", "\n", "\n", "\n", "# In Pruning, we read the file \"inactive.dat\" and set the weights and biases for the", "\n", "# corresponding units to be zero", "\n", "inactive_units", "=", "np", ".", "genfromtxt", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "args", ".", "resume", ")", ",", "inactive_file", ")", ",", "delimiter", "=", "' '", ")", ".", "astype", "(", "int", ")", "\n", "# sort in increasing index            ", "\n", "#inactive_units      = inactive_units[inactive_units[:,0].argsort()]", "\n", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "#print(\"-----------------------------------------------------------\")", "\n", "print", "(", "\"Pruning %d inactive nodes\"", "%", "(", "inactive_units", ".", "shape", "[", "0", "]", ")", ")", "\n", "#print(\"-----------------------------------------------------------\")            ", "\n", "uniq_layers_index", "=", "np", ".", "unique", "(", "inactive_units", "[", ":", ",", "0", "]", ")", "\n", "\n", "wt_layers", "=", "0", "\n", "bias_layers", "=", "0", "\n", "\n", "params", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "(", "'weight'", "in", "key", ")", ":", "\n", "                    ", "wt_layers", "+=", "1", "\n", "\n", "if", "(", "wt_layers", "in", "uniq_layers_index", ")", ":", "\n", "                        ", "indices", "=", "inactive_units", "[", "inactive_units", "[", ":", ",", "0", "]", "==", "wt_layers", ",", "1", "]", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "value", "[", "indices", "[", "i", "]", ",", ":", "]", "=", "0", "\n", "\n", "", "", "", "if", "(", "'bias'", "in", "key", ")", ":", "\n", "                    ", "bias_layers", "+=", "1", "\n", "if", "(", "bias_layers", "in", "uniq_layers_index", ")", ":", "\n", "                        ", "indices", "=", "inactive_units", "[", "inactive_units", "[", ":", ",", "0", "]", "==", "bias_layers", ",", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "value", "[", "indices", "[", "i", "]", "]", "=", "0", "\n", "\n", "#print(\"-----------------------------------------------------------\")", "\n", "", "", "", "", "print", "(", "\"Print values to double check if the weight and bias values for pruned nodes are zero\"", ")", "\n", "params", "=", "model", ".", "state_dict", "(", ")", "\n", "wt_layers", "=", "0", "\n", "bias_layers", "=", "0", "\n", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "(", "'weight'", "in", "key", ")", ":", "\n", "                    ", "wt_layers", "+=", "1", "\n", "\n", "if", "(", "wt_layers", "in", "uniq_layers_index", ")", ":", "\n", "                        ", "print", "(", "value", ".", "shape", ")", "\n", "indices", "=", "inactive_units", "[", "inactive_units", "[", ":", ",", "0", "]", "==", "wt_layers", ",", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "pass", "\n", "#print(value[indices[i],:])", "\n", "\n", "", "", "", "if", "(", "'bias'", "in", "key", ")", ":", "\n", "                    ", "bias_layers", "+=", "1", "\n", "if", "(", "bias_layers", "in", "uniq_layers_index", ")", ":", "\n", "                        ", "indices", "=", "inactive_units", "[", "inactive_units", "[", ":", ",", "0", "]", "==", "bias_layers", ",", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "indices", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "pass", "\n", "#print(value[indices[i]])", "\n", "\n", "\n", "", "", "", "", "print", "(", "\"\\n\\n-----------------------------------------------------------\"", ")", "\n", "print", "(", "\"               After Pruning\"", ")", "\n", "print", "(", "\"-----------------------------------------------------------\"", ")", "\n", "acc", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "1", ",", "device", ",", "fcnn", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.validate": [[219, 268], ["prune_and_evaluate_fcnn.AverageMeter", "prune_and_evaluate_fcnn.AverageMeter", "prune_and_evaluate_fcnn.AverageMeter", "model.eval", "time.time", "enumerate", "print", "model", "criterion", "output.float.float", "loss.float.float", "prune_and_evaluate_fcnn.AverageMeter.update", "prune_and_evaluate_fcnn.AverageMeter.update", "prune_and_evaluate_fcnn.AverageMeter.update", "time.time", "data.view.to", "target.to", "data.view.half", "data.view.view", "prune_and_evaluate_fcnn.accuracy", "loss.float.item", "data.view.size", "prec1.item", "data.view.size", "print", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.AverageMeter.update", "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy"], ["", "", "", "def", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "epoch", ",", "device", ",", "fcnn", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "\n", "# Send the data and label to the device", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "\n", "if", "args", ".", "half", ":", "\n", "            ", "data", "=", "data", ".", "half", "(", ")", "\n", "\n", "", "if", "fcnn", ":", "\n", "            ", "data", "=", "data", ".", "view", "(", "data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# compute output", "\n", "", "output", ",", "_", "=", "model", "(", "data", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "output", "=", "output", ".", "float", "(", ")", "\n", "loss", "=", "loss", ".", "float", "(", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", "=", "accuracy", "(", "output", ".", "data", ",", "target", ")", "[", "0", "]", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "print", "(", "'Test: [{0}/{1}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'", ".", "format", "(", "\n", "i", ",", "len", "(", "val_loader", ")", ",", "batch_time", "=", "batch_time", ",", "loss", "=", "losses", ",", "\n", "top1", "=", "top1", ")", ")", "\n", "\n", "", "", "print", "(", "'Epoch: [{0}] * Prec@1 {top1.avg:.3f}'", "\n", ".", "format", "(", "epoch", ",", "top1", "=", "top1", ")", ")", "\n", "\n", "return", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.train.prune_and_evaluate_fcnn.accuracy": [[290, 304], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "\n", "    ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io.mkdir": [[9, 12], ["os.makedirs"], "function", ["None"], ["def", "mkdir", "(", "d", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "d", ",", "exist_ok", "=", "True", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io.mkpath": [[13, 16], ["os.makedirs", "os.path.dirname"], "function", ["None"], ["", "def", "mkpath", "(", "path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ",", "exist_ok", "=", "True", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io._get_suffix": [[17, 23], ["filename.rfind"], "function", ["None"], ["", "def", "_get_suffix", "(", "filename", ")", ":", "\n", "    ", "\"\"\"a.jpg -> jpg\"\"\"", "\n", "pos", "=", "filename", ".", "rfind", "(", "'.'", ")", "\n", "if", "pos", "==", "-", "1", ":", "\n", "        ", "return", "''", "\n", "", "return", "filename", "[", "pos", "+", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io._load": [[25, 34], ["io._get_suffix", "numpy.load", "pickle.load", "numpy.load", "open"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io._get_suffix"], ["", "def", "_load", "(", "fp", ")", ":", "\n", "    ", "suffix", "=", "_get_suffix", "(", "fp", ")", "\n", "if", "suffix", "==", "'npy'", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "np", ".", "load", "(", "fp", ")", "\n", "", "except", ":", "\n", "            ", "return", "np", ".", "load", "(", "fp", ",", "allow_pickle", "=", "True", ")", "\n", "", "", "elif", "suffix", "==", "'pkl'", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "fp", ",", "'rb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io._dump": [[36, 44], ["io._get_suffix", "numpy.save", "pickle.dump", "Exception", "open"], "function", ["home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io._get_suffix"], ["", "", "def", "_dump", "(", "wfp", ",", "obj", ")", ":", "\n", "    ", "suffix", "=", "_get_suffix", "(", "wfp", ")", "\n", "if", "suffix", "==", "'npy'", ":", "\n", "        ", "np", ".", "save", "(", "wfp", ",", "obj", ")", "\n", "", "elif", "suffix", "==", "'pkl'", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "open", "(", "wfp", ",", "'wb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Unknown Type: {}'", ".", "format", "(", "suffix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.io.find_float_in_str": [[45, 60], ["re.compile", "re.compile.findall", "numpy.array"], "function", ["None"], ["", "", "def", "find_float_in_str", "(", "str_", ")", ":", "\n", "    ", "numeric_const_pattern", "=", "r\"\"\"\n            [-+]? # optional sign\n            (?:\n                (?: \\d* \\. \\d+ ) # .1 .12 .123 etc 9.1 etc 98.1 etc\n                |\n                (?: \\d+ \\.? ) # 1. 12. 123. etc 1 12 123 etc\n            )\n            # followed by optional exponent part if desired\n            (?: [Ee] [+-]? \\d+ ) ?\n            \"\"\"", "\n", "rx", "=", "re", ".", "compile", "(", "numeric_const_pattern", ",", "re", ".", "VERBOSE", ")", "\n", "f_", "=", "rx", ".", "findall", "(", "str_", ")", "\n", "f_", "=", "np", ".", "array", "(", "f_", ",", "dtype", "=", "float", ")", "\n", "return", "f_", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_start_time", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.start": [[12, 18], ["time.perf_counter", "timer.TimerError"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Start a new timer\"\"\"", "\n", "if", "self", ".", "_start_time", "is", "not", "None", ":", "\n", "            ", "raise", "TimerError", "(", "f\"Timer is running. Use .stop() to stop it\"", ")", "\n", "\n", "", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.timer.Timer.stop": [[19, 30], ["print", "timer.TimerError", "time.perf_counter", "time.perf_counter"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "msg", "=", "''", ",", "restart", "=", "True", ")", ":", "\n", "        ", "\"\"\"Stop the timer, and report the elapsed time\"\"\"", "\n", "if", "self", ".", "_start_time", "is", "None", ":", "\n", "            ", "raise", "TimerError", "(", "f\"Timer is not running. Use .start() to start it\"", ")", "\n", "\n", "", "elapsed_time", "=", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_start_time", "\n", "if", "restart", ":", "\n", "            ", "self", ".", "_start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_start_time", "=", "None", "\n", "", "print", "(", "f\"{msg:s} Elapsed time: {elapsed_time:0.4f} seconds\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.time.today_": [[3, 6], ["datetime.date.today", "date.today.strftime"], "function", ["None"], ["def", "today_", "(", ")", ":", "\n", "    ", "today", "=", "date", ".", "today", "(", ")", "\n", "return", "today", ".", "strftime", "(", "\"%Y%m%d\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuxwind_ExactCompression.common.time.now_": [[7, 10], ["datetime.datetime.now", "datetime.now.strftime"], "function", ["None"], ["", "def", "now_", "(", ")", ":", "\n", "    ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "return", "now", ".", "strftime", "(", "\"%Y%m%d.%H:%M:%S\"", ")", "\n", "", ""]]}