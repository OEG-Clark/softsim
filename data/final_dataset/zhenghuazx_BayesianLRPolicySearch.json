{"home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.plot_approximation.plot_approximation": [[3, 13], ["matplotlib.fill_between", "matplotlib.fill_between", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "X.ravel", "X.ravel", "Y[].ravel", "Y[].ravel", "Y[].ravel", "Y[].ravel"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.plot", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.plot", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.plot", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.plot"], ["def", "plot_approximation", "(", "X", ",", "Y", ",", "X_sample", ",", "Y_sample", ",", "std", ")", ":", "\n", "    ", "plt", ".", "fill_between", "(", "X", ".", "ravel", "(", ")", ",", "Y", "[", ":", ",", "0", "]", ".", "ravel", "(", ")", "+", "1.96", "*", "std", ",", "Y", "[", ":", ",", "0", "]", ".", "ravel", "(", ")", "-", "1.96", "*", "std", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "fill_between", "(", "X", ".", "ravel", "(", ")", ",", "Y", "[", ":", ",", "1", "]", ".", "ravel", "(", ")", "+", "1.96", "*", "std", ",", "Y", "[", ":", ",", "1", "]", ".", "ravel", "(", ")", "-", "1.96", "*", "std", ",", "alpha", "=", "0.1", ")", "\n", "plt", ".", "plot", "(", "X", ",", "Y", "[", ":", ",", "0", "]", ",", "'b-'", ",", "lw", "=", "3", ",", "label", "=", "'True bioreactor biomass trajectory'", ")", "\n", "plt", ".", "plot", "(", "X", ",", "Y", "[", ":", ",", "1", "]", ",", "'r-'", ",", "lw", "=", "3", ",", "label", "=", "'True bioreactor substrate trajectory'", ")", "\n", "plt", ".", "xlabel", "(", "'time'", ",", "fontsize", "=", "10", ")", "\n", "# plt.plot(X, mu, 'b-', lw=3, label='GP Surrogate function')", "\n", "plt", ".", "plot", "(", "X_sample", ",", "Y_sample", "[", ":", ",", "0", "]", ",", "'kx'", ",", "mew", "=", "3", ",", "ms", "=", "3", ",", "label", "=", "'Noisy samples of biomass'", ")", "\n", "plt", ".", "plot", "(", "X_sample", ",", "Y_sample", "[", ":", ",", "1", "]", ",", "'ko'", ",", "mew", "=", "3", ",", "ms", "=", "3", ",", "label", "=", "'Noisy samples of substrate'", ")", "\n", "plt", ".", "legend", "(", "fontsize", "=", "5", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.__init__": [[19, 57], ["policy_gradient.Agent.build_model", "policy_gradient.Agent.build_model", "policy_gradient.Agent.__build_train_fn"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.build_model", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.build_model", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.__build_train_fn"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "learning_rate", "=", "0.01", ",", "hidden_dims", "=", "[", "16", ",", "32", "]", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_dim (int): the dimension of state.\n                Same as `env.observation_space.shape[0]`\n            output_dim (int): the number of discrete actions\n                Same as `env.action_space.n`\n            hidden_dims (list): hidden dimensions\n        Methods:\n            private:\n                __build_train_fn -> None\n                    It creates a train function\n                    It's similar to defining `train_op` in Tensorflow\n                __build_network -> None\n                    It create a base model\n                    Its output is each action probability\n            public:\n                get_action(state) -> action\n                fit(state, action, reward) -> None\n        \"\"\"", "\n", "\n", "self", ".", "state_size", "=", "input_dim", "\n", "self", ".", "action_size", "=", "output_dim", "\n", "self", ".", "discount_factor", "=", "0.99", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "rolling_window_length", "=", "500", "\n", "self", ".", "states", "=", "[", "]", "\n", "self", ".", "gradients", "=", "[", "]", "\n", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "probs", "=", "[", "]", "\n", "self", ".", "actions", "=", "[", "]", "\n", "self", ".", "posteriors", "=", "[", "]", "\n", "self", ".", "models", "=", "[", "]", "\n", "self", ".", "_model_hist", "=", "self", ".", "build_model", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "build_model", "(", ")", "\n", "self", ".", "__build_train_fn", "(", ")", "\n", "self", ".", "normalizer", "=", "30", "\n", "self", ".", "normalized_states", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.build_model": [[58, 65], ["keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.summary", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "16", ",", "input_dim", "=", "self", ".", "state_size", ",", "activation", "=", "'tanh'", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.2", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "self", ".", "action_size", ",", "activation", "=", "'softmax'", ")", ")", "\n", "model", ".", "summary", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.__build_train_fn": [[66, 95], ["keras.backend.placeholder", "keras.backend.placeholder", "keras.backend.sum", "keras.optimizers.Adam", "keras.optimizers.Adam.get_updates", "keras.backend.function", "keras.backend.log", "keras.backend.mean"], "methods", ["None"], ["", "def", "__build_train_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create a train function\n        It replaces `model.fit(X, y)` because we use the output of model and use it for training.\n        For example, we need action placeholder\n        called `action_one_hot` that stores, which action we took at state `s`.\n        Hence, we can update the same action.\n        This function will create\n        `self.train_fn([state, action_one_hot, discount_reward])`\n        which would train the model.\n        \"\"\"", "\n", "action_onehot_placeholder", "=", "K", ".", "placeholder", "(", "shape", "=", "(", "None", ",", "self", ".", "action_size", ")", ",", "\n", "name", "=", "\"action_onehot\"", ")", "\n", "discount_reward_placeholder", "=", "K", ".", "placeholder", "(", "shape", "=", "(", "None", ",", ")", ",", "\n", "name", "=", "\"discount_reward\"", ")", "\n", "\n", "action_prob", "=", "K", ".", "sum", "(", "action_onehot_placeholder", "*", "self", ".", "model", ".", "output", ",", "axis", "=", "1", ")", "\n", "cross_entropy", "=", "K", ".", "log", "(", "action_prob", ")", "*", "discount_reward_placeholder", "\n", "loss", "=", "-", "K", ".", "mean", "(", "cross_entropy", ")", "\n", "\n", "adam", "=", "optimizers", ".", "Adam", "(", "lr", "=", "self", ".", "learning_rate", ")", "\n", "\n", "updates", "=", "adam", ".", "get_updates", "(", "params", "=", "self", ".", "model", ".", "trainable_weights", ",", "\n", "loss", "=", "loss", ")", "\n", "\n", "self", ".", "train_fn", "=", "K", ".", "function", "(", "inputs", "=", "[", "self", ".", "model", ".", "input", ",", "\n", "action_onehot_placeholder", ",", "\n", "discount_reward_placeholder", "]", ",", "\n", "outputs", "=", "[", "]", ",", "\n", "updates", "=", "updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.memorize": [[96, 105], ["policy_gradient.Agent.actions.append", "policy_gradient.Agent.states.append", "policy_gradient.Agent.normalized_states.append", "policy_gradient.Agent.rewards.append", "policy_gradient.Agent.posteriors.append", "policy_gradient.Agent.models.append"], "methods", ["None"], ["", "def", "memorize", "(", "self", ",", "state", ",", "action", ",", "reward", ",", "posterior", ",", "model_weight", ",", "normalized_states", ")", ":", "\n", "        ", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "if", "posterior", "is", "not", "None", ":", "\n", "            ", "self", ".", "posteriors", ".", "append", "(", "posterior", ")", "\n", "self", ".", "models", ".", "append", "(", "model_weight", ")", "\n", "\n", "", "self", ".", "states", ".", "append", "(", "state", ")", "\n", "self", ".", "normalized_states", ".", "append", "(", "normalized_states", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.get_action": [[106, 122], ["numpy.squeeze", "len", "numpy.expand_dims", "policy_gradient.Agent.model.predict", "len", "len", "numpy.random.choice", "len", "TypeError", "numpy.arange"], "methods", ["None"], ["", "def", "get_action", "(", "self", ",", "state", ")", ":", "\n", "        ", "shape", "=", "state", ".", "shape", "\n", "\n", "if", "len", "(", "shape", ")", "==", "1", ":", "\n", "            ", "assert", "shape", "==", "(", "self", ".", "state_size", ",", ")", ",", "\"{} != {}\"", ".", "format", "(", "shape", ",", "self", ".", "state_size", ")", "\n", "state", "=", "np", ".", "expand_dims", "(", "state", ",", "axis", "=", "0", ")", "\n", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "assert", "shape", "[", "1", "]", "==", "(", "self", ".", "state_size", ")", ",", "\"{} != {}\"", ".", "format", "(", "shape", ",", "self", ".", "state_size", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"Wrong state shape is given: {}\"", ".", "format", "(", "state", ".", "shape", ")", ")", "\n", "\n", "", "action_prob", "=", "np", ".", "squeeze", "(", "self", ".", "model", ".", "predict", "(", "state", ")", ")", "\n", "assert", "len", "(", "action_prob", ")", "==", "self", ".", "action_size", ",", "\"{} != {}\"", ".", "format", "(", "len", "(", "action_prob", ")", ",", "self", ".", "action_size", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "action_size", ")", ",", "p", "=", "action_prob", ")", ",", "action_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.fit": [[123, 142], ["range", "numpy.reshape", "numpy.reshape", "numpy.asarray", "numpy.reshape", "policy_gradient.Agent.train_fn", "len", "len", "policy_gradient.compute_discounted_R", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_discounted_R"], ["", "def", "fit", "(", "self", ",", "S", ",", "A", ",", "R", ",", "chroma", ",", "posterior", ",", "normalized_states", ")", ":", "\n", "        ", "\"\"\" simple policy gradient (PG)\n        Args:\n            S (2-D Array): `state` array of shape (n_samples, state_dimension)\n            A (1-D Array): `action` array of shape (n_samples,)\n                It's simply a list of int that stores which actions the agent chose\n            R (1-D Array): `reward` array of shape (n_samples,)\n                A reward is given after each action.\n        \"\"\"", "\n", "discount_reward", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "A", ")", ")", ":", "\n", "            ", "discount_reward", "[", "i", "]", "=", "compute_discounted_R", "(", "R", "[", "i", "]", ")", "\n", "normalized_states", "[", "i", "]", "=", "normalized_states", "[", "i", "]", "[", ":", "-", "1", ",", "]", "\n", "\n", "", "S", "=", "np", ".", "reshape", "(", "np", ".", "asarray", "(", "normalized_states", ")", ",", "(", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "0", "]", "*", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "1", "]", ",", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "2", "]", ")", ")", "\n", "A", "=", "np", ".", "reshape", "(", "np", ".", "asarray", "(", "A", ")", ",", "(", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "0", "]", "*", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "1", "]", ",", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "2", "]", ")", ")", "\n", "W", "=", "np", ".", "asarray", "(", "discount_reward", ")", "\n", "W", "=", "np", ".", "reshape", "(", "W", ",", "(", "W", ".", "shape", "[", "0", "]", "*", "W", ".", "shape", "[", "1", "]", ")", ")", "\n", "self", ".", "train_fn", "(", "[", "S", ",", "A", ",", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.fit2": [[143, 204], ["range", "numpy.reshape", "numpy.reshape", "numpy.asarray", "numpy.reshape", "policy_gradient.Agent.train_fn", "len", "len", "len", "len", "len", "len", "policy_gradient.Agent.model.predict", "policy_gradient.compute_discounted_R", "policy_gradient.compute_forward_ratio", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "policy_gradient.likelihood", "len", "int", "len", "policy_gradient.Agent._model_hist.set_weights", "policy_gradient.Agent._model_hist.predict", "numpy.asarray.append", "numpy.multiply", "range", "policy_gradient.likelihood", "numpy.sum", "range", "len", "range", "policy_gradient.compute_forward_ratio", "len", "numpy.asarray", "numpy.asarray", "numpy.argmax", "len", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.argmax", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_discounted_R", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_forward_ratio", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.likelihood", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.likelihood", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_forward_ratio"], ["", "def", "fit2", "(", "self", ",", "S", ",", "A", ",", "R", ",", "chroma", ",", "posterior", ",", "normalized_states", ",", "method", "=", "\"LR\"", ")", ":", "\n", "        ", "\"\"\" likelihood ratio based gradient (GS-RL) or LR\n        Args:\n            S list(2-D Array): `state` list of array of shape [(timestamp, state_dimension)]\n            A list(1-D Array): `action` array of shape [(timestamp,actions)]\n                It's simply a list of int that stores which actions the agent chose\n            R list(1-D Array): `list of reward` array of shape [(timestamp,reward)]\n                A reward is given after each action.\n        \"\"\"", "\n", "action_probs", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "discount_reward", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "likelihoods", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "trajectory_dists", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "weighted_discount_reward", "=", "[", "0", "]", "*", "len", "(", "A", ")", "\n", "# BLR1 = 0", "\n", "# BLR2 = 0", "\n", "# BLR3 = 0", "\n", "for", "i", "in", "range", "(", "len", "(", "A", ")", ")", ":", "\n", "            ", "action_prob", "=", "self", ".", "model", ".", "predict", "(", "normalized_states", "[", "i", "]", ")", "\n", "action_probs", "[", "i", "]", "=", "action_prob", "\n", "discount_reward", "[", "i", "]", "=", "compute_discounted_R", "(", "R", "[", "i", "]", ")", "\n", "likelihoods", "[", "i", "]", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", "if", "method", "==", "\"true_model\"", "else", "likelihood", "(", "chroma", ".", "posterior", ",", "posterior", ",", "S", "[", "i", "]", ",", "A", "[", "i", "]", ")", "\n", "trajectory_dist", "=", "[", "action_prob", "[", "k", "]", "[", "np", ".", "argmax", "(", "A", "[", "i", "]", "[", "k", ",", "]", ")", "]", "*", "likelihoods", "[", "i", "]", "[", "k", "]", "for", "k", "in", "range", "(", "len", "(", "likelihoods", "[", "i", "]", ")", ")", "]", "\n", "trajectory_dist", "=", "compute_forward_ratio", "(", "trajectory_dist", ")", "\n", "trajectory_dists", "[", "i", "]", "=", "trajectory_dist", "\n", "\n", "mixture_trajectory_dist_hist", "=", "[", "]", "\n", "lagging", "=", "len", "(", "self", ".", "posteriors", ")", "-", "int", "(", "self", ".", "rolling_window_length", "/", "50", ")", "\n", "start_likelihood", "=", "0", "if", "lagging", "<", "0", "else", "lagging", "\n", "for", "hist_idx", "in", "range", "(", "start_likelihood", ",", "len", "(", "self", ".", "posteriors", ")", ")", ":", "\n", "                ", "self", ".", "_model_hist", ".", "set_weights", "(", "self", ".", "models", "[", "hist_idx", "]", ")", "\n", "mixture_action_probs", "=", "self", ".", "_model_hist", ".", "predict", "(", "normalized_states", "[", "i", "]", ")", "\n", "mixture_action_prob", "=", "[", "mixture_action_probs", "[", "step", ",", "np", ".", "argmax", "(", "A", "[", "i", "]", "[", "step", ",", "]", ")", "]", "for", "step", "in", "range", "(", "len", "(", "A", "[", "i", "]", ")", ")", "]", "\n", "if", "method", "==", "\"true_model\"", ":", "\n", "                    ", "mixture_trajectory_dist", "=", "mixture_action_prob", "\n", "", "else", ":", "\n", "                    ", "mixture_likelihoods", "=", "likelihood", "(", "chroma", ".", "posterior", ",", "self", ".", "posteriors", "[", "hist_idx", "]", ",", "S", "[", "i", "]", ",", "A", "[", "i", "]", ")", "\n", "mixture_trajectory_dist", "=", "[", "mixture_action_prob", "[", "k", "]", "*", "mixture_likelihoods", "[", "k", "]", "for", "k", "\n", "in", "range", "(", "len", "(", "mixture_likelihoods", ")", ")", "]", "\n", "", "mixture_trajectory_dist_hist", ".", "append", "(", "1", "/", "(", "len", "(", "self", ".", "posteriors", ")", "-", "start_likelihood", ")", "*", "compute_forward_ratio", "(", "mixture_trajectory_dist", ")", ")", "\n", "\n", "", "mixture_trajectory_dist_hist", "=", "np", ".", "asarray", "(", "mixture_trajectory_dist_hist", ")", "\n", "BLR", "=", "[", "trajectory_dist", "[", "k", "]", "/", "(", "np", ".", "sum", "(", "mixture_trajectory_dist_hist", "[", ":", ",", "k", "]", ")", ")", "for", "k", "in", "range", "(", "len", "(", "trajectory_dist", ")", ")", "]", "\n", "if", "method", "==", "\"LR\"", ":", "\n", "                ", "weighted_discount_reward", "[", "i", "]", "=", "discount_reward", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "weighted_discount_reward", "[", "i", "]", "=", "np", ".", "multiply", "(", "BLR", ",", "discount_reward", "[", "i", "]", ")", "\n", "", "normalized_states", "[", "i", "]", "=", "normalized_states", "[", "i", "]", "[", ":", "-", "1", ",", "]", "\n", "#print(\"trajectory_dist: {}\".format(trajectory_dist))", "\n", "#print(\"mixture_trajectory_dist: {}\".format(mixture_trajectory_dist_hist))", "\n", "# BLR1 += BLR[0]", "\n", "# BLR2 += BLR[1]", "\n", "# BLR3 += BLR[2]", "\n", "#print(\"BLR: {}\".format(BLR))", "\n", "#print(BLR1/len(A), BLR2/len(A), BLR2/len(A))", "\n", "", "S", "=", "np", ".", "reshape", "(", "np", ".", "asarray", "(", "normalized_states", ")", ",", "(", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "0", "]", "*", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "1", "]", ",", "np", ".", "asarray", "(", "normalized_states", ")", ".", "shape", "[", "2", "]", ")", ")", "\n", "A", "=", "np", ".", "reshape", "(", "np", ".", "asarray", "(", "A", ")", ",", "(", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "0", "]", "*", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "1", "]", ",", "np", ".", "asarray", "(", "A", ")", ".", "shape", "[", "2", "]", ")", ")", "\n", "W", "=", "np", ".", "asarray", "(", "weighted_discount_reward", ")", "\n", "W", "=", "np", ".", "reshape", "(", "W", ",", "(", "W", ".", "shape", "[", "0", "]", "*", "W", ".", "shape", "[", "1", "]", ")", ")", "\n", "\n", "self", ".", "train_fn", "(", "[", "S", ",", "A", ",", "W", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.likelihood": [[205, 211], ["range", "likelihoods.append", "policy_gradient.single_step_likelihood"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.single_step_likelihood"], ["", "", "def", "likelihood", "(", "probability", ",", "posterior_sample_idx", ",", "state", ",", "action", ")", ":", "\n", "    ", "H", "=", "state", ".", "shape", "[", "0", "]", "\n", "likelihoods", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "H", "-", "1", ")", ":", "\n", "        ", "likelihoods", ".", "append", "(", "single_step_likelihood", "(", "probability", ",", "posterior_sample_idx", ",", "state", "[", "i", "+", "1", ",", "]", ",", "state", "[", "i", ",", "]", ",", "action", "[", "i", ",", "]", ",", "i", ")", ")", "\n", "", "return", "likelihoods", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.single_step_likelihood": [[212, 220], ["scipy.stats.beta.pdf", "scipy.stats.beta.pdf", "numpy.isscalar", "numpy.argmax"], "function", ["None"], ["", "def", "single_step_likelihood", "(", "probability", ",", "posterior_sample_idx", ",", "next_state", ",", "state", ",", "action", ",", "t", ")", ":", "\n", "    ", "if", "np", ".", "isscalar", "(", "action", ")", "is", "not", "True", ":", "\n", "        ", "action", "=", "np", ".", "argmax", "(", "action", ")", "\n", "", "prob_protein", "=", "probability", "[", "t", "]", "[", "0", "]", "[", "action", "]", "[", ":", ",", "posterior_sample_idx", "]", "\n", "prob_impurity", "=", "probability", "[", "t", "]", "[", "1", "]", "[", "action", "]", "[", ":", ",", "posterior_sample_idx", "]", "\n", "protein_likelihood", "=", "beta", ".", "pdf", "(", "next_state", "[", "0", "]", "/", "state", "[", "0", "]", ",", "a", "=", "prob_protein", "[", "0", "]", ",", "b", "=", "prob_protein", "[", "1", "]", ")", "\n", "impurity_likelihood", "=", "beta", ".", "pdf", "(", "next_state", "[", "1", "]", "/", "state", "[", "1", "]", ",", "a", "=", "prob_impurity", "[", "0", "]", ",", "b", "=", "prob_impurity", "[", "1", "]", ")", "\n", "return", "protein_likelihood", "*", "impurity_likelihood", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_discounted_R": [[222, 245], ["numpy.zeros_like", "reversed", "range", "len"], "function", ["None"], ["", "def", "compute_discounted_R", "(", "R", ",", "discount_rate", "=", "1", ")", ":", "\n", "    ", "\"\"\"Returns discounted rewards\n    Args:\n        R (1-D array): a list of `reward` at each time step\n        discount_rate (float): Will discount the future value by this rate\n    Returns:\n        discounted_r (1-D array): same shape as input `R`\n            but the values are normalized and discounted\n    Examples:\n        #>>> R = [1, 1, 1]\n        #>>> compute_discounted_R(R, .99) # before normalization\n        [1 + 0.99 + 0.99**2, 1 + 0.99, 1]\n    \"\"\"", "\n", "discounted_r", "=", "np", ".", "zeros_like", "(", "R", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "running_add", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "len", "(", "R", ")", ")", ")", ":", "\n", "\n", "        ", "running_add", "=", "running_add", "*", "discount_rate", "+", "R", "[", "t", "]", "\n", "discounted_r", "[", "t", "]", "=", "running_add", "\n", "", "discounted_r", "+=", "68", "\n", "discounted_r", "/=", "88", "\n", "\n", "return", "discounted_r", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.compute_forward_ratio": [[246, 253], ["numpy.zeros_like", "range", "len"], "function", ["None"], ["", "def", "compute_forward_ratio", "(", "L", ")", ":", "\n", "    ", "discounted_r", "=", "np", ".", "zeros_like", "(", "L", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "running_prod", "=", "1", "\n", "for", "t", "in", "range", "(", "len", "(", "L", ")", ")", ":", "\n", "        ", "running_prod", "=", "running_prod", "*", "L", "[", "t", "]", "\n", "discounted_r", "[", "t", "]", "=", "running_prod", "\n", "", "return", "discounted_r", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.reward_function": [[255, 265], ["max"], "function", ["None"], ["", "def", "reward_function", "(", "protein", ",", "impurity", ",", "required_ratio", "=", "0.85", ",", "required_protein", "=", "8", ")", ":", "\n", "    ", "Cf", "=", "48", "\n", "Cl", "=", "6", "\n", "price_prod", "=", "5", "\n", "if", "protein", "/", "(", "protein", "+", "max", "(", "impurity", ",", "0", ")", ")", "<", "required_ratio", ":", "\n", "        ", "return", "-", "Cf", "\n", "", "elif", "protein", "<", "required_protein", ":", "\n", "        ", "return", "price_prod", "*", "protein", "-", "Cl", "*", "(", "required_protein", "-", "protein", ")", "\n", "", "else", ":", "\n", "        ", "return", "price_prod", "*", "required_protein", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.run_episode": [[268, 353], ["numpy.linspace", "range", "numpy.linspace", "int", "numpy.random.seed", "simulation_model.fermentation_simulator", "numpy.append", "np.array.append", "range", "int", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "len", "simulation_model.fermentation_simulator.simulate", "numpy.random.normal", "numpy.array", "agent.get_action", "numpy.zeros", "numpy.append", "numpy.array", "np.array.append", "np.array.append", "np.array.append", "np.array.append", "A_prob.append", "int", "numpy.array", "numpy.squeeze", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "agent.fit", "agent.fit2", "str", "str", "chroma.simulate", "numpy.squeeze", "numpy.squeeze", "policy_gradient.reward_function", "agent.model.get_weights", "agent.memorize", "agent.memorize", "str", "str", "chroma.simulate", "chroma.simulate", "int", "int", "int", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.get_action", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.fit", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.fit2", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.reward_function", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.memorize", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.memorize", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate"], ["", "", "def", "run_episode", "(", "chroma", ",", "agent", ",", "seed", ",", "save_model", ",", "nj", "=", "50", ",", "algo", "=", "'PG'", ")", ":", "\n", "    ", "normalizer", "=", "30", "\n", "# set up environment", "\n", "time_span", "=", "10.", "\n", "t", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "501", ")", "\n", "t_realization", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "51", ")", "*", "time_span", "\n", "sample_idx", "=", "[", "int", "(", "i", ")", "for", "i", "in", "t_realization", "]", "\n", "total_reward", "=", "0", "\n", "total_reward_dp", "=", "0", "\n", "for", "episode", "in", "range", "(", "nj", ")", ":", "\n", "# simulate from environment", "\n", "        ", "np", ".", "random", ".", "seed", "(", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", ")", ")", "\n", "alpha1", ",", "alpha2", "=", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", ",", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", "\n", "Feed", "=", "30", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "5", ")", "\n", "Si", "=", "780", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "40", ")", "\n", "S", "=", "40", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "2", ")", "\n", "action", "=", "[", "Feed", "]", "*", "len", "(", "sample_idx", ")", "\n", "\n", "fs", "=", "fermentation_simulator", "(", "action", ",", "time_span", "=", "time_span", ",", "N", "=", "100", ")", "\n", "fs", ".", "s0", "=", "[", "0.5", ",", "S", "]", "\n", "fs", ".", "Si", "=", "Si", "\n", "simulation_out", "=", "fs", ".", "simulate", "(", "t", ",", "Feed", ",", "sample_idx", ",", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", ")", ")", "[", "1", "]", "\n", "upstream_out", "=", "simulation_out", "[", "-", "1", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "simulation_out", "[", "-", "1", ",", "0", "]", "/", "256", ")", "\n", "initial_state", "=", "[", "upstream_out", "*", "alpha1", ",", "upstream_out", "*", "alpha2", "]", "\n", "\n", "S", "=", "[", "]", "\n", "A", "=", "[", "]", "\n", "R", "=", "[", "]", "\n", "A_prob", "=", "[", "]", "\n", "s", "=", "np", ".", "append", "(", "initial_state", ",", "0", ")", "\n", "S", ".", "append", "(", "s", ")", "\n", "normalized_states", "=", "[", "np", ".", "array", "(", "[", "s", "[", "0", "]", "/", "normalizer", ",", "s", "[", "1", "]", "/", "normalizer", ",", "s", "[", "2", "]", "]", ")", "]", "\n", "\n", "for", "h", "in", "range", "(", "chroma", ".", "horizon", ")", ":", "\n", "# on-policy", "\n", "            ", "action", ",", "action_prob", "=", "agent", ".", "get_action", "(", "np", ".", "array", "(", "[", "s", "[", "0", "]", "/", "normalizer", ",", "s", "[", "1", "]", "/", "normalizer", ",", "s", "[", "2", "]", "]", ")", ")", "\n", "a", "=", "np", ".", "zeros", "(", "[", "agent", ".", "action_size", "]", ")", "\n", "a", "[", "action", "]", "=", "1", "\n", "if", "algo", "==", "'PG'", ":", "\n", "                ", "s", "=", "np", ".", "squeeze", "(", "chroma", ".", "simulate", "(", "action", ",", "s", ",", "h", ",", "rand_seed", "=", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", "+", "str", "(", "h", ")", ")", ",", "\n", "use_true_model", "=", "False", ",", "fixed_transition_model", "=", "True", ")", ")", "\n", "", "elif", "algo", "==", "'true_model'", ":", "\n", "                ", "s", "=", "np", ".", "squeeze", "(", "chroma", ".", "simulate", "(", "action", ",", "s", ",", "h", ",", "rand_seed", "=", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", "+", "str", "(", "h", ")", ")", ",", "\n", "use_true_model", "=", "True", ",", "fixed_transition_model", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "                ", "s", "=", "np", ".", "squeeze", "(", "chroma", ".", "simulate", "(", "action", ",", "s", ",", "h", ",", "rand_seed", "=", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", "+", "str", "(", "h", ")", ")", ",", "\n", "use_true_model", "=", "False", ",", "fixed_transition_model", "=", "False", ")", ")", "\n", "", "s", "=", "np", ".", "append", "(", "s", ",", "h", "+", "1", ")", "\n", "normalized_s", "=", "np", ".", "array", "(", "[", "s", "[", "0", "]", "/", "normalizer", ",", "s", "[", "1", "]", "/", "normalizer", ",", "s", "[", "2", "]", "]", ")", "\n", "if", "h", "==", "chroma", ".", "horizon", "-", "1", ":", "\n", "                ", "r", "=", "-", "10", "+", "reward_function", "(", "s", "[", "0", "]", ",", "s", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "r", "=", "-", "10", "\n", "\n", "", "total_reward", "+=", "r", "\n", "S", ".", "append", "(", "s", ")", "\n", "A", ".", "append", "(", "a", ")", "\n", "R", ".", "append", "(", "r", ")", "\n", "normalized_states", ".", "append", "(", "normalized_s", ")", "\n", "A_prob", ".", "append", "(", "action_prob", "[", "action", "]", ")", "\n", "if", "h", "==", "chroma", ".", "horizon", "-", "1", ":", "\n", "                ", "S", "=", "np", ".", "array", "(", "S", ")", "\n", "A", "=", "np", ".", "array", "(", "A", ")", "\n", "R", "=", "np", ".", "array", "(", "R", ")", "\n", "normalized_states", "=", "np", ".", "array", "(", "normalized_states", ")", "\n", "if", "episode", "==", "nj", "-", "1", ":", "\n", "                    ", "old_weights", "=", "agent", ".", "model", ".", "get_weights", "(", ")", "\n", "agent", ".", "memorize", "(", "S", ",", "A", ",", "R", ",", "chroma", ".", "posterior_sample_idx", ",", "old_weights", ",", "normalized_states", ")", "\n", "", "else", ":", "\n", "                    ", "agent", ".", "memorize", "(", "S", ",", "A", ",", "R", ",", "None", ",", "None", ",", "normalized_states", ")", "\n", "\n", "", "", "", "if", "episode", "==", "nj", "-", "1", ":", "\n", "                ", "if", "algo", "==", "'PG'", ":", "\n", "                    ", "S_backward", "=", "agent", ".", "states", "[", "-", "nj", ":", "]", "\n", "A_backward", "=", "agent", ".", "actions", "[", "-", "nj", ":", "]", "\n", "R_backward", "=", "agent", ".", "rewards", "[", "-", "nj", ":", "]", "\n", "normalized_states_backward", "=", "agent", ".", "normalized_states", "[", "-", "nj", ":", "]", "\n", "agent", ".", "fit", "(", "S_backward", ",", "A_backward", ",", "R_backward", ",", "chroma", ",", "chroma", ".", "posterior_sample_idx", ",", "normalized_states_backward", ")", "\n", "", "else", ":", "\n", "                    ", "S_backward", "=", "agent", ".", "states", "[", "-", "agent", ".", "rolling_window_length", ":", "]", "\n", "A_backward", "=", "agent", ".", "actions", "[", "-", "agent", ".", "rolling_window_length", ":", "]", "\n", "R_backward", "=", "agent", ".", "rewards", "[", "-", "agent", ".", "rolling_window_length", ":", "]", "\n", "normalized_states_backward", "=", "agent", ".", "normalized_states", "[", "-", "agent", ".", "rolling_window_length", ":", "]", "\n", "agent", ".", "fit2", "(", "S_backward", ",", "A_backward", ",", "R_backward", ",", "chroma", ",", "chroma", ".", "posterior_sample_idx", ",", "normalized_states_backward", ",", "algo", ")", "\n", "", "", "", "return", "total_reward", "/", "nj", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.initialize_env": [[355, 379], ["numpy.linspace", "numpy.random.seed", "simulation_model.fermentation_simulator", "numpy.append", "numpy.linspace", "int", "int", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "len", "simulation_model.fermentation_simulator.simulate", "numpy.random.normal", "int", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate"], ["", "def", "initialize_env", "(", "seed", ",", "episode", ")", ":", "\n", "    ", "normalizer", "=", "30", "\n", "# set up environment", "\n", "time_span", "=", "10.", "\n", "t", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "501", ")", "\n", "t_realization", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "51", ")", "*", "time_span", "\n", "sample_idx", "=", "[", "int", "(", "i", ")", "for", "i", "in", "t_realization", "]", "\n", "# Setting up our environment", "\n", "np", ".", "random", ".", "seed", "(", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", ")", ")", "\n", "alpha1", ",", "alpha2", "=", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", ",", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", "\n", "Feed", "=", "30", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "5", ")", "\n", "Si", "=", "780", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "40", ")", "\n", "S", "=", "40", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "2", ")", "\n", "action", "=", "[", "Feed", "]", "*", "len", "(", "sample_idx", ")", "\n", "\n", "fs", "=", "fermentation_simulator", "(", "action", ",", "time_span", "=", "time_span", ",", "N", "=", "100", ")", "\n", "fs", ".", "s0", "=", "[", "0.5", ",", "S", "]", "\n", "fs", ".", "Si", "=", "Si", "\n", "simulation_out", "=", "fs", ".", "simulate", "(", "t", ",", "Feed", ",", "sample_idx", ",", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "episode", ")", ")", ")", "[", "1", "]", "\n", "upstream_out", "=", "simulation_out", "[", "-", "1", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "simulation_out", "[", "-", "1", ",", "0", "]", "/", "256", ")", "\n", "observation", "=", "[", "upstream_out", "*", "alpha1", ",", "upstream_out", "*", "alpha2", "]", "\n", "#print(observation)", "\n", "observation", "=", "np", ".", "append", "(", "observation", ",", "0", ")", "\n", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.score_model": [[381, 406], ["range", "policy_gradient.initialize_env", "range", "scores.append", "numpy.mean", "numpy.std", "agent.get_action", "int", "numpy.squeeze", "numpy.append", "numpy.array", "chroma.simulate", "str", "str", "policy_gradient.reward_function"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.initialize_env", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.Agent.get_action", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.reward_function"], ["", "def", "score_model", "(", "chroma", ",", "agent", ",", "num_tests", ",", "seed", ")", ":", "\n", "    ", "normalizer", "=", "30", "\n", "scores", "=", "[", "]", "\n", "current", "=", "chroma", ".", "posterior_sample_idx", "\n", "chroma", ".", "posterior_sample_idx", "=", "3000", "-", "chroma", ".", "posterior_sample_idx", "\n", "for", "num_test", "in", "range", "(", "num_tests", ")", ":", "\n", "        ", "s", "=", "initialize_env", "(", "seed", ",", "num_test", ")", "\n", "reward_sum", "=", "0", "\n", "for", "h", "in", "range", "(", "chroma", ".", "horizon", ")", ":", "\n", "\n", "            ", "action", ",", "action_prob", "=", "agent", ".", "get_action", "(", "np", ".", "array", "(", "[", "s", "[", "0", "]", "/", "normalizer", ",", "s", "[", "1", "]", "/", "normalizer", ",", "s", "[", "2", "]", "]", ")", ")", "\n", "\n", "# Determine the outcome of our action", "\n", "rand_seed", "=", "int", "(", "str", "(", "seed", ")", "+", "str", "(", "num_test", ")", ")", "\n", "s", "=", "np", ".", "squeeze", "(", "chroma", ".", "simulate", "(", "action", ",", "s", ",", "h", ",", "rand_seed", ",", "True", ")", ")", "\n", "s", "=", "np", ".", "append", "(", "s", ",", "h", "+", "1", ")", "\n", "if", "h", "==", "chroma", ".", "horizon", "-", "1", ":", "\n", "                ", "reward", "=", "-", "10", "+", "reward_function", "(", "s", "[", "0", "]", ",", "s", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "reward", "=", "-", "10", "\n", "", "reward_sum", "+=", "reward", "\n", "\n", "", "scores", ".", "append", "(", "reward_sum", ")", "\n", "chroma", ".", "posterior_sample_idx", "=", "current", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "np", ".", "std", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.main2": [[408, 424], ["range", "range", "chroma.generate_new_data", "chroma.build_posterior", "policy_gradient.run_episode", "chroma.update_posterior_sample", "reward_result.append", "test_reward_result.append", "print", "int", "policy_gradient.score_model", "int", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.generate_new_data", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.build_posterior", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.run_episode", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.update_posterior_sample", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.policy_gradient.score_model"], ["", "def", "main2", "(", "chroma", ",", "agent", ",", "algo", ",", "runlength", "=", "260", ",", "macro", "=", "10", ",", "num_period", "=", "2", ")", ":", "\n", "    ", "reward_result", "=", "[", "]", "\n", "test_reward_result", "=", "[", "]", "\n", "for", "period", "in", "range", "(", "num_period", ")", ":", "\n", "        ", "if", "period", ">", "0", ":", "\n", "            ", "chroma", ".", "generate_new_data", "(", "40", ")", "\n", "chroma", ".", "build_posterior", "(", ")", "\n", "", "for", "batch", "in", "range", "(", "runlength", ")", ":", "\n", "            ", "reward", "=", "run_episode", "(", "chroma", ",", "agent", ",", "int", "(", "str", "(", "batch", ")", "+", "str", "(", "macro", ")", "+", "str", "(", "period", ")", ")", ",", "batch", "%", "100", "==", "0", ",", "50", ",", "algo", ")", "\n", "chroma", ".", "update_posterior_sample", "(", ")", "\n", "reward_result", ".", "append", "(", "reward", ")", "\n", "test_reward", "=", "score_model", "(", "chroma", ",", "agent", ",", "200", ",", "int", "(", "str", "(", "batch", ")", "+", "str", "(", "macro", ")", "+", "str", "(", "period", ")", ")", ")", "[", "0", "]", "\n", "test_reward_result", ".", "append", "(", "test_reward", ")", "\n", "print", "(", "\"iteration: {}, reward: {:0.2f}, test reward: {:0.2f}\"", ".", "format", "(", "batch", ",", "reward", ",", "test_reward", ")", ")", "\n", "\n", "", "", "return", "reward_result", ",", "test_reward_result", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.__init__": [[20, 45], ["numpy.log"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "action", ",", "\n", "time_span", ",", "\n", "std", "=", "5", ",", "\n", "N", "=", "50", ",", "\n", "Y_em", "=", "0.3", ",", "\n", "q_s_max", "=", "0.57", ",", "\n", "q_m", "=", "0.013", ",", "\n", "Ks", "=", "0.1", ")", ":", "\n", "# define parameters in bioreactor model", "\n", "        ", "self", ".", "N", "=", "N", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "action", "=", "action", "\n", "self", ".", "time_span", "=", "time_span", "\n", "self", ".", "Y_em", "=", "Y_em", "# [0.1,0.9]", "\n", "self", ".", "q_s_max", "=", "q_s_max", "# [0.2,0.8]", "\n", "self", ".", "q_m", "=", "q_m", "# [0,0.05]", "\n", "self", ".", "Ks", "=", "Ks", "\n", "# define initial state, [biomass, substrate]", "\n", "self", ".", "s0", "=", "[", "0.5", ",", "40", "]", "\n", "self", ".", "V", "=", "1000", "\n", "self", ".", "Si", "=", "780", "\n", "self", ".", "LN2PI", "=", "np", ".", "log", "(", "2.", "*", "np", ".", "pi", ")", "\n", "self", ".", "X", "=", "None", "\n", "self", ".", "S", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.feed_rate": [[46, 49], ["int"], "methods", ["None"], ["", "def", "feed_rate", "(", "self", ",", "t", ")", ":", "\n", "\n", "        ", "return", "self", ".", "action", "[", "int", "(", "t", "/", "self", ".", "time_span", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.bioreactor": [[50, 59], ["simulation_model.fermentation_simulator.feed_rate", "int"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.feed_rate"], ["", "def", "bioreactor", "(", "self", ",", "z", ",", "t", ",", "feed", ")", ":", "\n", "        ", "X", ",", "S", "=", "z", "\n", "# rate of change", "\n", "q_s", "=", "self", ".", "q_s_max", "*", "S", "/", "(", "S", "+", "self", ".", "Ks", ")", "\n", "mu", "=", "(", "q_s", "-", "self", ".", "q_m", ")", "*", "self", ".", "Y_em", "\n", "\n", "dX", "=", "(", "-", "self", ".", "action", "[", "int", "(", "t", "/", "self", ".", "time_span", ")", "]", "/", "self", ".", "V", "+", "mu", ")", "*", "X", "\n", "dS", "=", "self", ".", "feed_rate", "(", "t", ")", "/", "self", ".", "V", "*", "(", "self", ".", "Si", "-", "S", ")", "-", "q_s", "*", "X", "\n", "return", "[", "dX", ",", "dS", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.simulate": [[60, 69], ["numpy.random.seed", "scipy.integrate.odeint", "numpy.transpose", "numpy.random.normal", "numpy.random.normal", "numpy.array"], "methods", ["None"], ["", "def", "simulate", "(", "self", ",", "t", ",", "feed", ",", "sample_idx", ",", "seed", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "true_trajectories", "=", "scipy", ".", "integrate", ".", "odeint", "(", "self", ".", "bioreactor", ",", "self", ".", "s0", ",", "t", ",", "args", "=", "(", "feed", ",", ")", ")", "\n", "substrate", "=", "true_trajectories", "[", "sample_idx", ",", "1", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "std", ",", "true_trajectories", "[", "sample_idx", ",", "1", "]", ".", "shape", ")", "\n", "biomass", "=", "true_trajectories", "[", "sample_idx", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "std", ",", "true_trajectories", "[", "sample_idx", ",", "1", "]", ".", "shape", ")", "\n", "substrate", "[", "substrate", "<", "0", "]", "=", "0.", "\n", "biomass", "[", "biomass", "<", "0", "]", "=", "0.", "\n", "sample_trajectories", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "[", "biomass", ",", "substrate", "]", ")", ")", "\n", "return", "true_trajectories", ",", "sample_trajectories", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.posterior_sampler": [[70, 86], ["numpy.zeros", "numpy.zeros", "range", "dynesty.DynamicNestedSampler", "dynesty.DynamicNestedSampler.run_nested", "numpy.exp", "dynesty.utils.resample_equal", "simulation_model.fermentation_simulator.simulate", "len", "len"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate"], ["", "def", "posterior_sampler", "(", "self", ",", "t", ",", "sample_idx", ",", "ndims", "=", "2", ")", ":", "\n", "        ", "nlive", "=", "1024", "# number of (initial) live points", "\n", "bound", "=", "'multi'", "# use MutliNest algorithm", "\n", "sample", "=", "'rwalk'", "\n", "self", ".", "X", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "N", ",", "len", "(", "sample_idx", ")", ")", ")", "\n", "self", ".", "S", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "N", ",", "len", "(", "sample_idx", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "N", ")", ":", "\n", "            ", "_", ",", "sample_trajectories", "=", "self", ".", "simulate", "(", "t", ",", "self", ".", "action", ",", "sample_idx", ")", "\n", "self", ".", "X", "[", "i", ",", ":", "]", "=", "sample_trajectories", "[", ":", ",", "0", "]", "\n", "self", ".", "S", "[", "i", ",", ":", "]", "=", "sample_trajectories", "[", ":", ",", "1", "]", "\n", "", "dsampler", "=", "DynamicNestedSampler", "(", "self", ".", "loglikelihood", ",", "self", ".", "prior_transform", ",", "ndims", ",", "bound", "=", "bound", ")", "\n", "dsampler", ".", "run_nested", "(", "nlive_init", "=", "nlive", ")", "\n", "res", "=", "dsampler", ".", "results", "\n", "weights", "=", "np", ".", "exp", "(", "res", "[", "'logwt'", "]", "-", "res", "[", "'logz'", "]", "[", "-", "1", "]", ")", "\n", "samples_dynesty", "=", "resample_equal", "(", "res", ".", "samples", ",", "weights", ")", "\n", "return", "dsampler", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.plot": [[88, 93], ["simulation_model.fermentation_simulator.simulate", "plot_approximation.plot_approximation.plot_approximation"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.plot_approximation.plot_approximation"], ["", "def", "plot", "(", "self", ",", "t", ",", "feed", ",", "sample_idx", ")", ":", "\n", "# simulate the system for different values of feed rate.", "\n", "        ", "[", "true_trajectories", ",", "sample_trajectories", "]", "=", "self", ".", "simulate", "(", "t", ",", "feed", ",", "sample_idx", ")", "\n", "# plot the trajectories.", "\n", "plot_approximation", "(", "t", ",", "true_trajectories", ",", "t", "[", "sample_idx", "]", ",", "sample_trajectories", ",", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood": [[94, 101], ["range", "simulation_model.fermentation_simulator.loglikelihood_single_data"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood_single_data"], ["", "def", "loglikelihood", "(", "self", ",", "theta", ")", ":", "\n", "        ", "Y_em", ",", "q_s_max", "=", "theta", "\n", "loglike", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "N", ")", ":", "\n", "            ", "loglike", "+=", "self", ".", "loglikelihood_single_data", "(", "self", ".", "action", ",", "Y_em", ",", "q_s_max", ",", "self", ".", "X", "[", "i", ",", ":", "]", ",", "self", ".", "S", "[", "i", ",", ":", "]", ",", "self", ".", "time_span", ")", "\n", "\n", "", "return", "loglike", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood_single_data": [[102, 124], ["len", "range", "simulation_model.fermentation_simulator.loglikelihood_single_normal", "simulation_model.fermentation_simulator.loglikelihood_single_normal", "numpy.abs", "abs", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood_single_normal", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood_single_normal"], ["", "def", "loglikelihood_single_data", "(", "self", ",", "action", ",", "Y_em", ",", "q_s_max", ",", "X", ",", "S", ",", "time_span", ")", ":", "\n", "        ", "epsilon", "=", "0.1", "\n", "horizon", "=", "len", "(", "S", ")", "\n", "q_m", "=", "self", ".", "q_m", "\n", "# rate of change", "\n", "for", "i", "in", "range", "(", "horizon", ")", ":", "\n", "            ", "mean_S", "=", "(", "S", "[", "i", "+", "1", "]", "+", "S", "[", "i", "]", ")", "/", "2", "\n", "mean_X", "=", "(", "X", "[", "i", "+", "1", "]", "+", "X", "[", "i", "]", ")", "/", "2", "\n", "increment_X", "=", "X", "[", "i", "+", "1", "]", "-", "X", "[", "i", "]", "\n", "increment_S", "=", "S", "[", "i", "+", "1", "]", "-", "S", "[", "i", "]", "\n", "feed", "=", "action", "[", "i", "]", "\n", "\n", "q_s", "=", "q_s_max", "*", "mean_S", "/", "(", "mean_S", "+", "self", ".", "Ks", ")", "\n", "mu", "=", "(", "q_s", "-", "q_m", ")", "*", "Y_em", "\n", "\n", "muX", "=", "(", "-", "feed", "/", "self", ".", "V", "+", "mu", ")", "*", "mean_X", "*", "time_span", "\n", "sigmaX", "=", "(", "feed", "/", "self", ".", "V", "+", "abs", "(", "mu", ")", ")", "*", "np", ".", "abs", "(", "mean_X", ")", "*", "time_span", "\n", "muS", "=", "(", "feed", "/", "self", ".", "V", "*", "(", "self", ".", "Si", "-", "mean_S", ")", "-", "q_s", "*", "mean_X", ")", "*", "time_span", "\n", "sigmaS", "=", "(", "feed", "/", "self", ".", "V", "*", "(", "self", ".", "Si", "+", "abs", "(", "mean_S", ")", ")", "+", "q_s", "*", "abs", "(", "mean_X", ")", ")", "*", "time_span", "\n", "sigmaX", "=", "epsilon", "if", "sigmaX", "==", "0", "else", "sigmaX", "\n", "sigmaS", "=", "epsilon", "if", "sigmaS", "==", "0", "else", "sigmaS", "\n", "return", "self", ".", "loglikelihood_single_normal", "(", "muX", ",", "sigmaX", ",", "increment_X", ")", "+", "self", ".", "loglikelihood_single_normal", "(", "muS", ",", "sigmaS", ",", "increment_S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.loglikelihood_single_normal": [[125, 136], ["numpy.log"], "methods", ["None"], ["", "", "def", "loglikelihood_single_normal", "(", "self", ",", "mu", ",", "sigma", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        The log-likelihood function for single normal\n        \"\"\"", "\n", "# normalisation", "\n", "LNSIGMA", "=", "np", ".", "log", "(", "sigma", ")", "\n", "norm", "=", "-", "0.5", "*", "self", ".", "LN2PI", "-", "LNSIGMA", "\n", "# chi-squared (data, sigma and x are global variables defined early on in this notebook)", "\n", "chisq", "=", "(", "(", "x", "-", "mu", ")", "/", "sigma", ")", "**", "2", "\n", "\n", "return", "norm", "-", "0.5", "*", "chisq", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.fermentation_simulator.prior_transform": [[137, 162], ["None"], "methods", ["None"], ["", "def", "prior_transform", "(", "self", ",", "theta", ")", ":", "\n", "        ", "\"\"\"\n        A function defining the tranform between the parameterisation in the unit hypercube\n        to the true parameters.\n\n        Args:\n            theta (tuple): a tuple containing the parameters.\n\n        Returns:\n            tuple: a new tuple or array with the transformed parameters.\n        \"\"\"", "\n", "\n", "Y_em", ",", "q_s_max", "=", "theta", "\n", "\n", "Y_em_min", "=", "0.1", "# lower bound on uniform prior on c", "\n", "Y_em_max", "=", "0.5", "# upper bound on uniform prior on c", "\n", "q_s_max_min", "=", "0.3", "# lower bound on uniform prior on c", "\n", "q_s_max_max", "=", "0.8", "# upper bound on uniform prior on c", "\n", "#q_m_min = -10.  # lower bound on uniform prior on c", "\n", "#q_m_max = 10.  # upper bound on uniform prior on c", "\n", "Y_em", "=", "Y_em", "*", "(", "Y_em_max", "-", "Y_em_min", ")", "+", "Y_em_min", "# convert back to c", "\n", "q_s_max", "=", "q_s_max", "*", "(", "q_s_max_max", "-", "q_s_max_min", ")", "+", "q_s_max_min", "# convert back to c", "\n", "#q_m = q_m * (q_m_max - q_m_min) + q_m_min  # convert back to c", "\n", "\n", "return", "Y_em", ",", "q_s_max", "#, q_m", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.__init__": [[166, 199], ["simulation_model.chromatography.generate_data", "simulation_model.chromatography.get_alpha_beta", "simulation_model.chromatography.get_alpha_beta", "simulation_model.chromatography.get_alpha_beta", "simulation_model.chromatography.get_alpha_beta", "simulation_model.chromatography.get_alpha_beta", "simulation_model.chromatography.get_alpha_beta", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.generate_data", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta", "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta"], ["    ", "def", "__init__", "(", "self", ",", "\n", "data_size", "=", "200", ",", "\n", "horizon", "=", "3", ",", "\n", "N", "=", "50", ")", ":", "\n", "# define parameters in bioreactor model", "\n", "        ", "purity_coef", "=", "[", "0.48", ",", "0.28", "]", "\n", "self", ".", "chrom1_protein", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "0", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "0", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "self", ".", "chrom1_impurity", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "1", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "1", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "\n", "#self.chrom1_protein = [[purity - 0.1 * purity_coef[0], purity + 0.1 * purity_coef[0]] for purity in [(1 + pool / 11) * purity_coef[0] for pool in range(10)]]", "\n", "#self.chrom1_impurity = [[purity - 0.1 * purity_coef[1], purity + 0.1 * purity_coef[1]] for purity in [(1 + pool / 11) * purity_coef[1] for pool in range(10)]]", "\n", "\n", "purity_coef", "=", "[", "0.5", ",", "0.25", "]", "\n", "self", ".", "chrom2_protein", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "0", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "0", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "self", ".", "chrom2_impurity", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "1", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "1", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "\n", "purity_coef", "=", "[", "0.5", ",", "0.22", "]", "\n", "self", ".", "chrom3_protein", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "0", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "0", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "self", ".", "chrom3_impurity", "=", "[", "self", ".", "get_alpha_beta", "(", "mu", "=", "purity", ",", "sigma", "=", "0.08", "*", "purity_coef", "[", "1", "]", ")", "for", "purity", "in", "[", "(", "1", "+", "pool", "/", "12", ")", "*", "purity_coef", "[", "1", "]", "for", "pool", "in", "range", "(", "10", ")", "]", "]", "\n", "\n", "self", ".", "true_model_params", "=", "{", "1", ":", "{", "'protein'", ":", "self", ".", "chrom1_protein", ",", "'impurity'", ":", "self", ".", "chrom1_impurity", "}", ",", "\n", "2", ":", "{", "'protein'", ":", "self", ".", "chrom2_protein", ",", "'impurity'", ":", "self", ".", "chrom2_impurity", "}", ",", "\n", "3", ":", "{", "'protein'", ":", "self", ".", "chrom3_protein", ",", "'impurity'", ":", "self", ".", "chrom3_impurity", "}", "}", "\n", "\n", "self", ".", "sim_size", "=", "10", "\n", "self", ".", "horizon", "=", "horizon", "\n", "self", ".", "posterior", "=", "{", "}", "\n", "self", ".", "posterior_pareto", "=", "{", "}", "\n", "self", ".", "N", "=", "N", "\n", "self", ".", "data_state", ",", "self", ".", "data_action", "=", "self", ".", "generate_data", "(", "data_size", ")", "\n", "self", ".", "k", "=", "3", "\n", "self", ".", "leftover_sample", "=", "{", "}", "# self.cur_sample_idx[step][0][window]", "\n", "self", ".", "posterior_sample_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.get_alpha_beta": [[200, 212], ["ValueError"], "methods", ["None"], ["", "def", "get_alpha_beta", "(", "self", ",", "alpha", "=", "None", ",", "beta", "=", "None", ",", "mu", "=", "None", ",", "sigma", "=", "None", ")", ":", "\n", "        ", "if", "(", "alpha", "is", "not", "None", ")", "and", "(", "beta", "is", "not", "None", ")", ":", "\n", "            ", "pass", "\n", "", "elif", "(", "mu", "is", "not", "None", ")", "and", "(", "sigma", "is", "not", "None", ")", ":", "\n", "            ", "kappa", "=", "mu", "*", "(", "1", "-", "mu", ")", "/", "sigma", "**", "2", "-", "1", "\n", "alpha", "=", "mu", "*", "kappa", "\n", "beta", "=", "(", "1", "-", "mu", ")", "*", "kappa", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Incompatible parameterization. Either use alpha '", "\n", "'and beta, or mu and sigma to specify distribution.'", ")", "\n", "\n", "", "return", "alpha", ",", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.posterior_generator": [[213, 224], ["numpy.array", "pymc3.Model", "pymc3.Uniform", "pymc3.Uniform", "pymc3.Beta", "pymc3.sample", "pymc3.sample.get_values", "pymc3.sample.get_values"], "methods", ["None"], ["", "def", "posterior_generator", "(", "self", ",", "data", ",", "size", "=", "1000", ")", ":", "\n", "# data = np.random.beta(5, 6, 100)", "\n", "        ", "with", "pm", ".", "Model", "(", ")", "as", "model_g", ":", "\n", "# alpha = pm.TruncatedNormal(mu=3,sigma=2,lower=0.1,name='alpha')", "\n", "# beta = pm.TruncatedNormal(mu=7,sigma=2,lower=0.1,name='beta')", "\n", "            ", "alpha", "=", "pm", ".", "Uniform", "(", "lower", "=", "0", ",", "upper", "=", "300", ",", "name", "=", "'alpha'", ")", "\n", "beta", "=", "pm", ".", "Uniform", "(", "lower", "=", "0", ",", "upper", "=", "300", ",", "name", "=", "'beta'", ")", "\n", "y", "=", "pm", ".", "Beta", "(", "'y'", ",", "alpha", "=", "alpha", ",", "beta", "=", "beta", ",", "observed", "=", "data", ")", "\n", "trace_g", "=", "pm", ".", "sample", "(", "size", ",", "tune", "=", "1000", ",", "cores", "=", "4", ")", "\n", "#az.summary(trace_g)", "\n", "", "return", "np", ".", "array", "(", "[", "trace_g", ".", "get_values", "(", "'alpha'", ")", ",", "trace_g", ".", "get_values", "(", "'beta'", ")", "]", ")", "# 2 * size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate": [[226, 256], ["numpy.random.seed", "numpy.random.seed", "numpy.random.beta", "numpy.random.beta", "int", "numpy.random.beta", "numpy.random.beta", "numpy.random.beta", "numpy.random.beta", "str", "str", "str", "int", "int"], "methods", ["None"], ["", "def", "simulate", "(", "self", ",", "window", ",", "initial_state", ",", "step", ",", "rand_seed", "=", "None", ",", "use_true_model", "=", "False", ",", "fixed_transition_model", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "posterior_sample_idx", ">=", "4000", ":", "\n", "            ", "return", "\n", "", "if", "rand_seed", "==", "None", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", "int", "(", "str", "(", "window", ")", "+", "str", "(", "step", ")", "+", "str", "(", "int", "(", "(", "initial_state", "[", "0", "]", "-", "int", "(", "initial_state", "[", "0", "]", ")", ")", "*", "10", "**", "6", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", "rand_seed", ")", "\n", "\n", "", "if", "use_true_model", ":", "\n", "            ", "protein_param", "=", "self", ".", "true_model_params", "[", "step", "+", "1", "]", "[", "'protein'", "]", "[", "window", "]", "\n", "impurity_param", "=", "self", ".", "true_model_params", "[", "step", "+", "1", "]", "[", "'impurity'", "]", "[", "window", "]", "\n", "removal_rate_protein", "=", "np", ".", "random", ".", "beta", "(", "protein_param", "[", "0", "]", ",", "protein_param", "[", "1", "]", ")", "\n", "removal_rate_impurity", "=", "np", ".", "random", ".", "beta", "(", "impurity_param", "[", "0", "]", ",", "impurity_param", "[", "1", "]", ")", "\n", "", "elif", "fixed_transition_model", ":", "\n", "            ", "protein_param", "=", "self", ".", "posterior", "[", "step", "]", "[", "0", "]", "[", "window", "]", "[", ":", ",", "-", "1", "]", "\n", "impurity_param", "=", "self", ".", "posterior", "[", "step", "]", "[", "1", "]", "[", "window", "]", "[", ":", ",", "-", "1", "]", "\n", "removal_rate_protein", "=", "np", ".", "random", ".", "beta", "(", "protein_param", "[", "0", "]", ",", "protein_param", "[", "1", "]", ")", "\n", "removal_rate_impurity", "=", "np", ".", "random", ".", "beta", "(", "impurity_param", "[", "0", "]", ",", "impurity_param", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "protein_param", "=", "self", ".", "posterior", "[", "step", "]", "[", "0", "]", "[", "window", "]", "[", ":", ",", "self", ".", "posterior_sample_idx", "]", "\n", "impurity_param", "=", "self", ".", "posterior", "[", "step", "]", "[", "1", "]", "[", "window", "]", "[", ":", ",", "self", ".", "posterior_sample_idx", "]", "\n", "removal_rate_protein", "=", "np", ".", "random", ".", "beta", "(", "protein_param", "[", "0", "]", ",", "protein_param", "[", "1", "]", ")", "\n", "removal_rate_impurity", "=", "np", ".", "random", ".", "beta", "(", "impurity_param", "[", "0", "]", ",", "impurity_param", "[", "1", "]", ")", "\n", "\n", "\n", "\n", "", "protein", "=", "initial_state", "[", "0", "]", "*", "removal_rate_protein", "\n", "impurity", "=", "initial_state", "[", "1", "]", "*", "removal_rate_impurity", "\n", "state", "=", "[", "protein", ",", "impurity", "]", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.build_posterior": [[257, 279], ["range", "len", "numpy.unique", "simulation_model.chromatography.posterior_generator"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.posterior_generator"], ["", "def", "build_posterior", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "posterior", ")", "!=", "0", ":", "\n", "            ", "self", ".", "posterior", "=", "{", "}", "\n", "", "for", "i", "in", "range", "(", "self", ".", "horizon", ")", ":", "\n", "            ", "actions", "=", "self", ".", "data_action", "[", ":", ",", "i", "]", "\n", "unique_actions", "=", "np", ".", "unique", "(", "actions", ")", "\n", "for", "j", "in", "[", "0", ",", "1", "]", ":", "\n", "                ", "state", "=", "self", ".", "data_state", "[", ":", ",", "i", ",", "j", "]", "\n", "next_state", "=", "self", ".", "data_state", "[", ":", ",", "i", "+", "1", ",", "j", "]", "\n", "for", "a", "in", "unique_actions", ":", "\n", "                    ", "action_index", "=", "actions", "==", "a", "\n", "data", "=", "next_state", "[", "action_index", "]", "/", "state", "[", "action_index", "]", "\n", "posteriors", "=", "self", ".", "posterior_generator", "(", "data", ")", "\n", "if", "i", "in", "self", ".", "posterior", ":", "\n", "                        ", "if", "j", "in", "self", ".", "posterior", "[", "i", "]", ":", "\n", "                            ", "self", ".", "posterior", "[", "i", "]", "[", "j", "]", "[", "a", "]", "=", "posteriors", "\n", "#self.leftover_sample[i][j][a] = posteriors.shape[1] - 1", "\n", "", "else", ":", "\n", "                            ", "self", ".", "posterior", "[", "i", "]", "[", "j", "]", "=", "{", "a", ":", "posteriors", "}", "\n", "#self.leftover_sample[i][j] = {a: posteriors.shape[1] - 1}", "\n", "", "", "else", ":", "\n", "                        ", "self", ".", "posterior", "[", "i", "]", "=", "{", "j", ":", "{", "a", ":", "posteriors", "}", "}", "\n", "#self.leftover_sample[i] = {j: {a: posteriors.shape[1] - 1}}", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.update_posterior_sample": [[281, 283], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "update_posterior_sample", "(", "self", ")", ":", "\n", "        ", "self", ".", "posterior_sample_idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.generate_data": [[284, 317], ["numpy.linspace", "range", "numpy.linspace", "int", "simulation_model.fermentation_simulator", "range", "data_state.append", "data_action.append", "numpy.array", "numpy.array", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "len", "simulation_model.fermentation_simulator.simulate", "numpy.random.normal", "int", "numpy.random.beta", "numpy.random.beta", "S.append", "A.append", "int", "numpy.random.uniform", "str", "str"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.simulate"], ["", "def", "generate_data", "(", "self", ",", "data_size", "=", "1000", ")", ":", "\n", "        ", "time_span", "=", "10.", "\n", "t", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "501", ")", "\n", "t_realization", "=", "np", ".", "linspace", "(", "0.", ",", "50.", ",", "51", ")", "*", "time_span", "\n", "sample_idx", "=", "[", "int", "(", "i", ")", "for", "i", "in", "t_realization", "]", "\n", "data_state", "=", "[", "]", "\n", "data_action", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data_size", ")", ":", "\n", "            ", "alpha1", ",", "alpha2", "=", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", ",", "np", ".", "random", ".", "normal", "(", "0.11", ",", "0.01", ")", "\n", "Feed", "=", "30", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "5", ")", "\n", "Si", "=", "780", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "40", ")", "\n", "S", "=", "40", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "2", ")", "\n", "action", "=", "[", "Feed", "]", "*", "len", "(", "sample_idx", ")", "\n", "fs", "=", "fermentation_simulator", "(", "action", ",", "time_span", "=", "time_span", ",", "N", "=", "100", ")", "\n", "fs", ".", "s0", "=", "[", "0.5", ",", "S", "]", "\n", "fs", ".", "Si", "=", "Si", "\n", "simulation_out", "=", "fs", ".", "simulate", "(", "t", ",", "Feed", ",", "sample_idx", ",", "int", "(", "str", "(", "data_size", ")", "+", "str", "(", "i", ")", ")", ")", "[", "1", "]", "\n", "upstream_out", "=", "simulation_out", "[", "-", "1", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "simulation_out", "[", "-", "1", ",", "0", "]", "/", "256", ")", "\n", "state", "=", "[", "upstream_out", "*", "alpha1", ",", "upstream_out", "*", "alpha2", "]", "\n", "S", "=", "[", "state", "]", "\n", "A", "=", "[", "]", "\n", "for", "h", "in", "range", "(", "self", ".", "horizon", ")", ":", "\n", "                ", "action", "=", "int", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "10", ")", ")", "\n", "protein_model_param", "=", "self", ".", "true_model_params", "[", "h", "+", "1", "]", "[", "'protein'", "]", "[", "action", "]", "\n", "protein_removal_rate", "=", "np", ".", "random", ".", "beta", "(", "a", "=", "protein_model_param", "[", "0", "]", ",", "b", "=", "protein_model_param", "[", "1", "]", ")", "\n", "impurity_model_param", "=", "self", ".", "true_model_params", "[", "h", "+", "1", "]", "[", "'impurity'", "]", "[", "action", "]", "\n", "impurity_removal_rate", "=", "np", ".", "random", ".", "beta", "(", "a", "=", "impurity_model_param", "[", "0", "]", ",", "b", "=", "impurity_model_param", "[", "1", "]", ")", "\n", "state", "=", "[", "state", "[", "0", "]", "*", "protein_removal_rate", ",", "state", "[", "1", "]", "*", "impurity_removal_rate", "]", "\n", "S", ".", "append", "(", "state", ")", "\n", "A", ".", "append", "(", "action", ")", "\n", "", "data_state", ".", "append", "(", "S", ")", "\n", "data_action", ".", "append", "(", "A", ")", "\n", "", "return", "np", ".", "array", "(", "data_state", ")", ",", "np", ".", "array", "(", "data_action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.generate_new_data": [[318, 322], ["simulation_model.chromatography.generate_data", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.zhenghuazx_BayesianLRPolicySearch.None.simulation_model.chromatography.generate_data"], ["", "def", "generate_new_data", "(", "self", ",", "data_size", "=", "40", ")", ":", "\n", "        ", "add_data_state", ",", "add_data_action", "=", "self", ".", "generate_data", "(", "data_size", ")", "\n", "self", ".", "data_action", "=", "np", ".", "concatenate", "(", "(", "self", ".", "data_action", ",", "add_data_action", ")", ")", "\n", "self", ".", "data_state", "=", "np", ".", "concatenate", "(", "(", "self", ".", "data_state", ",", "add_data_state", ")", ")", "\n", "", "", ""]]}